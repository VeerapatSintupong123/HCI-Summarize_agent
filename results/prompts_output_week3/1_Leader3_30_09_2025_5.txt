
    CRITICAL: Your entire response MUST be a single, valid JSON object and nothing else. Your response must begin with '{' and end with '}'.

    You are an expert financial analyst and strategist. Your goal is to evaluate the *quality, insight, and utility* of a "Candidate Summary".

    **Reference Context (Documents provided as a *starting point*):**
    The summary was generated using these documents as a starting point. The summary *is allowed* to include relevant, verifiable external information not present in these references.

    1.  **Current News (`base`):**
        ### Nvidia ###
    NXPort eGPU integrates 650W power in a small dock  Thunderbolt and USB4 connections may bottleneck even the most powerful GPUs  Open-frame design leaves components vulnerable to damage  The pursuit of transforming business laptops into desktop-grade powerhouses has long relied on external GPU enclosures.  Traditional solutions have often been bulky, cumbersome, and required separate power supplies or complex assembly.  NXPort claims to be the “world’s smallest eGPU dock,” promising 650W of integrated power in a palm-sized form factor measuring 169mm x 102mm x 82mm.  Compact form, big questions  The central claim of NXPort is that it houses a built-in power supply within a tiny, open-frame chassis.  On paper, this allows compatibility with nearly all consumer-grade GPUs and simplifies connectivity by supporting Thunderbolt 3/4/5 or USB4.  However, a compact, exposed design introduces concerns about heat management and physical protection.  Expensive components, including GPUs like the $1,999 GeForce RTX 5090, would sit exposed to dust, accidental contact, and variable cooling conditions.  Are you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors  The device meets the ATX 3.1 spec for stable power delivery, but real-world performance under sustained load is unverified, leaving potential users cautious about long-term reliability.  The company presents NXPort as a plug-and-play solution that can greatly improve GPU performance.  In the company’s tests, pairing a budget laptop with an Nvidia RTX 4060 reportedly produced a “6X Gaming Benchmark” improvement.  The dock is also described as suitable for intensive creative workloads and AI model training, capable of handling tasks requiring “thousands of parallel operations.”  Yet, it is important to note that performance may be limited by the bandwidth of Thunderbolt or USB4 connections.  This could restrict the throughput of high-end graphics cards despite the dock’s internal power.  The dock also supports GPUs with various power connectors, including 12V-2x6, 8-pin, dual 8-pin, triple 8-pin, and quad 8-pin (12VHPWR).  This provides flexibility for future upgrades without enclosure limitations.  Although NXPort claims to be the “world’s smallest eGPU dock,” its 1.3kg weight is well above that of the GDP G1, a former smallest, which weighs only 867g.  The company states that the device is budget-friendly, as an NXPort paired with an RTX 3050 costs $459 ($239 for the base dock + $220 for the GPU).  Compared with $1,599 for a laptop featuring a similar RTX 4050 GPU, this offers a cost-efficient way to achieve desktop-level graphics without replacing the existing laptop.  The NXPort project is currently listed on Kickstarter, where it has raised $57,618 from 211 backers, surpassing its $3,856 goal.  With 21 days remaining in the campaign, the funding trajectory suggests strong early interest, although the final product has yet to reach backers for independent evaluation.  Disclaimer: We do not recommend or endorse any crowdfunding project. All crowdfunding campaigns carry inherent risks, including the possibility of delays, changes, or non-delivery of products. Potential backers should carefully evaluate the details and proceed at their own discretion.
    JavaScript is disabled in your browser. Please enable JavaScript to proceed.  A required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.
    We use cookies to improve user experience, and analyze website traffic.  For these reasons, we may share your site usage data with our analytics partners. By clicking "Accept Cookies" you consent to store on your device all the technologies described in our Cookie Policy.
    What Happened?  Shares of leading designer of graphics chips Nvidia (NASDAQ:NVDA) jumped 2.3% in the afternoon session after several Wall Street firms raised their price targets on the stock and reports surfaced of a major deal involving its advanced AI systems.  The positive sentiment was fueled by a reported deal where cloud provider CoreWeave agreed to supply Meta Platforms with up to $14.2 billion in AI computing power using Nvidia's latest GB300 systems. This agreement highlighted the immense and sustained demand for AI infrastructure from major tech companies. Further boosting investor confidence, several financial firms, including KeyBanc, Barclays, and Citi, increased their price targets for Nvidia. Analysts pointed to an improving supply of key components and strong, continued spending in the AI sector as the primary reasons for their optimistic outlook, which helped push the stock to a record high.  After the initial pop the shares cooled down to $186.21, up 2.4% from previous close.  Is now the time to buy Nvidia? Access our full analysis report here, it’s free.  What Is The Market Telling Us  Nvidia’s shares are quite volatile and have had 18 moves greater than 5% over the last year. In that context, today’s move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.  The previous big move we wrote about was 8 days ago when the stock gained 4.1% on the news that the company announced a partnership with OpenAI that included plans for a potential investment of up to $100 billion.  The deal aimed to supply OpenAI with advanced AI hardware for its next generation of AI models and the buildout of massive data centers. According to the announcement, the partnership involved deploying at least 10 gigawatts of Nvidia's systems for OpenAI's AI infrastructure. This news solidified Nvidia's central role in the future of artificial intelligence.  Nvidia is up 34.6% since the beginning of the year, and at $186.21 per share, has set a new 52-week high. Investors who bought $1,000 worth of Nvidia’s shares 5 years ago would now be looking at an investment worth $13,762.  Unless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.
    We recently compiled a list of the 12 Best Stocks to Own for Grandchildren. NVIDIA Corporation is one of them.  NVIDIA Corporation (NASDAQ:NVDA) tops our list for being one of the best stocks to buy . It continues to dominate the AI and data center markets with groundbreaking developments in September 2025. The company posted second-quarter fiscal 2026 revenue of $46.7 billion, a 56% year-over-year increase, driven by strong demand for its Blackwell Data Center products, which grew 17% sequentially. CEO Jensen Huang described the Blackwell AI platform as a “generational leap” in infrastructure, with production scaling quickly to meet demand from advanced reasoning AI models.  A major highlight this month is NVDA’s strategic partnership with OpenAI, involving up to $100 billion in investment and a commitment to supply advanced data center chips for next-generation AI systems. This alliance strengthens the firm’s central role in the AI ecosystem and significantly expands its long-term market potential. In addition, the company announced a $5 billion investment in Intel stock, with plans to co-develop custom AI infrastructure for data centers and PCs, aiming at a $50 billion market opportunity.  NVIDIA Corporation (NVDA) and OpenAI Forge $100B Partnership to Power Next-Gen AI Systems  NVIDIA Corporation (NASDAQ:NVDA) also introduced Rubin CPX, a new GPU designed to handle massive-context inference tasks, enabling million-token coding and generative video at unprecedented speed and efficiency. This innovation supports its vision of transforming data centers into fully integrated “AI factories.”  While we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.  READ NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy NOW  Disclosure: None.
    JavaScript is disabled in your browser. Please enable JavaScript to proceed.  A required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.
    We recently published 10 Buzzing Tech and AI Stocks Everyone’s Talking About. Micron Technology Inc. (NASDAQ:MU) is one of the stocks analysts were recently talking about.  Mehdi Hosseini, senior equity research analyst at Susquehanna, said in a latest program on CNBC that Nvidia “has to buy” from Micron, and this places the memory company in a strong position in terms of pricing power.  “I think the most important takeaway here, which I don’t think Sanjay (Micron CEO) is going to elaborate on a live interview, is who is actually doing a lot of buying. Unlike prior cycles, which were driven by distributors and the OEMs and ODMs, this cycle it is Nvidia, it is AMD, it is Broadcom that are actually doing the buying. And when you look at the AI, what Nvidia charges, which is about 80% of the AI server, the majority of that is going towards memory. So it is Nvidia that has to buy from Micron Technology Inc (NASDAQ:MU), and this is what gives Sanjay pricing power. The future of AI compute requires advanced memory, and that’s where the premium comes in, which is why this cycle is sustainable throughout 2016 and may even sustain into 2027.”  Photo by L N on Unsplash  Parnassus Investments, an investment management firm that focuses on owning a concentrated portfolio of U.S. large-cap stocks, released its Parnassus Value Equity Fund second-quarter 2025 investor letter. Here is what they have to say about Micron Technology Inc. (NASDAQ:MU) in their investor letter:  “Micron Technology Inc. (NASDAQ:MU) shares advanced due to the company’s strong position in the AI-driven memory market. Management noted robust demand in its latest quarter.”  While we acknowledge the potential of MU as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.  READ NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.
    For more information about the NVIDIA NeMo Agent toolkit, please visit the NeMo Agent toolkit GitHub Repo .  This is a subpackage for Weights and Biases Weave integration for observability.  Download files  Download the file for your platform. If you're not sure which to choose, learn more about installing packages.  Source Distributions  No source distribution files available for this release.See tutorial on generating distribution archives  Built Distribution  Filter files by name, interpreter, ABI, and platform.  If you're not sure about the file name format, learn more about wheel file names.  The dropdown lists show the available interpreters, ABIs, and platforms. Enable javascript to be able to filter the list of wheel files.  Copy a direct link to the current filters Copy
    We recently published 15 Stocks Jim Cramer Mentioned As He Said Quantum Computing Worried Him. Oracle Corporation (NYSE:ORCL) is one of the stocks Jim Cramer recently discussed.  Oracle Corporation (NYSE:ORCL) has been the talk of the town recently after it revealed a whopping $455 billion in cloud backlog as part of its fiscal first quarter earnings release. In this episde, Cramer critically evaluated the announcement:  Jim Cramer Shares Very Important Analysis About Oracle Corporation (ORCL)  “[On shares being down at open] Well Oracle is the fundament of what happened. That was the, that was the straw because everybody else had been self funding. You know because cash flow, Mark Zuckerberg had a cash flow, Google had a cash flow. And suddenly Oracle comes in. Where are they going to get all the money? Well they’re going to get it from OpenAI, but where’s OpenAI going to get all the money? They’re going to get it from NVIDIA. . .  While we acknowledge the potential of ORCL as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.  READ NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.
    The technical storage or access that is used exclusively for statistical purposes.  The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.
    Visible Noise Nine months after Nvidia ships a feature, AMD produces a paper about their equivalent, and btw it doesn’t work with any of their existing products. Looks like 90XX is a dead end product.  Visible Noise Why are people so surprised and angry at Nvidia’s success?  Visible Noise They literally have no competition. Nvidia is still delivering features years ahead of AMD.  Hecate91 As usual Nvidia fans whine that AMD cards don't have a proprietary to Nvidia feature, then whine anyways when AMD develops something similar because they've never bought an AMD and never have any intention to do anything but mindlessly bash the brand.  Anyway unless the feature does something groundbreaking then it's just another optional feature, I wouldn't expect this to make RDNA4 cards obsolete, and perhaps it could be processed at a driver level or on existing hardware.  Nvidia shipped Ray Tracing, it wasn't supported on GTX cards. They shipped MFG, it's not supported on cards prior to RTX50. You don't consider GeForce a dead end lineup, do you ?Because Nvidia is using their success to push their agenda of making the entire planet dependent on their dogshit AI tech that nobody neither wants nor needs.100% AI generated raster ? Miss me with that shit.The latest AMD has been on an Nvidia feature is Ray Reconstruction/Redstone and they barely have a full year of latency on this.Also, I'd like to point out that if you read the article a little bit closer, AMD's tech seems to be better since hitting broader, not just RT perf.And since if could run on raster, it would be hardware agnostic instead of vendor locked.I noticed that so far, when AMD follows, they might be later on delivery, but they follow with better.I'm curious about that "potential performance hit" mentioned on the article, how much of a hit are we talking about ? How much variance in outcome can we expect ? How is it behaving at different resolutions and different tiers of details complexity ? Is it hardware agnostic ? How would it run on other brands of cards ?I gotta say, I'm looking forward to this, even if if looks to be hardware dependent to get the intended performance, it kinda sounds like a new "FSR moment" to me when they make something that just works for everyone and improves X or Y factor.
    We came across a bullish thesis on Microsoft Corporation on The Edge of Power’s Substack. In this article, we will summarize the bulls’ thesis on MSFT. Microsoft Corporation's share was trading at $507.03 as of September 25th. MSFT’s trailing and forward P/E were 37.17 and 32.79 respectively according to Yahoo Finance.  dennizn/Shutterstock.com  Microsoft’s AI strategy is transforming it into a critical global infrastructure player, with investments and partnerships positioning it far beyond a conventional software vendor. The adoption of Microsoft Copilot by the U.S. House of Representatives illustrates this shift, as AI moves from a productivity tool to essential infrastructure capable of supporting state-scale operations. Globally, Microsoft is deploying more than $56 billion in AI-focused projects, including sovereign cloud regions and supercomputing hubs in the U.K., Norway, and the U.S., with total CapEx for fiscal 2025 expected to approach $80 billion.  These initiatives combine renewable energy, GPU clusters, and strategic partnerships, creating a distributed, resilient infrastructure network that spans continents and aligns with sovereign priorities. In the Middle East, alliances with G42 in the UAE and sovereign cloud regions in Saudi Arabia extend Microsoft’s influence into fast-growing AI markets, effectively tying its growth to politically aligned, capital-rich projects and providing a strategic counterweight to Chinese technology influence. Despite this scale, the market has largely overlooked Microsoft’s moves, favoring smaller, unprofitable AI players.  The company’s embedded presence in government, sovereign partnerships, and global cloud infrastructure provides durable pricing power and revenue visibility, supporting a potential stock valuation of $600 by year-end. Beyond commercial returns, Microsoft’s investments represent soft power, shaping AI adoption, digital infrastructure, and geopolitical influence, while enabling NVIDIA and other tech partners to thrive.  With unmatched scale, innovation leadership, and embeddedness across governments and enterprises, Microsoft is building the global rails of the AI economy, offering long-term, resilient upside for investors and anchoring portfolios in a way smaller startups cannot replicate. Its global AI infrastructure positions the company as a quasi-state actor, securing both technological and strategic advantage for decades.  Previously we covered a bullish thesis on Microsoft Corporation (MSFT) by Ray Myers in May 2025, which highlighted the company’s strong enterprise software position, cloud growth via Azure, gaming expansion, and AI integration. The stock has appreciated approximately 11.9% since our coverage. The thesis still stands as Microsoft’s fundamentals remain robust. The Edge of Power shares a similar view but emphasizes Microsoft’s global AI infrastructure and geopolitical influence.
    Tower Research Capital, a New York-based high-frequency trading (HFT) firm, is under fire by Chinese authorities for allegedly smuggling high-tech hardware into the country for the purpose of using it in the Shanghai Futures Exchange (SHFE). The report comes by way of Financial Times, which notes the Chinese customs authorities are determining whether Tower installed illicit "customized processors and networking hardware" that didn't match its customs declaration.  Tower allegedly brought in $17 million worth of hardware into the country. Although the hardware hasn't been seized, the authority handling the case has instructed Tower not to remove any of it from the SHFE server room until the investigation is concluded. Should the allegations ring true, Tower could face "significant fines" and even criminal charges.  High-frequency trading is automated and algorithm-based, and reliant on highly specialized FPGAs and ASICs to do millisecond-quick (or even sub-millisecond) trades. HFT firms go as far as designing their own network cards and software stacks, complementing the operating systems' functionality or bypassing it entirely.  Taking the recent U.S. hardware export controls into context, it may seem odd that China itself would be raising an eyebrow against advanced hardware going into the country, but there's a logical reason. The Shanghai Futures Exchange reportedly only allows "certified brokers" to connect directly to its servers, therefore bypassing precious milliseconds in network latency if they were located farther away.  If Tower employed customized hardware that's faster than expected, that would be seen as a no-no by the SHFE, as the regulatory agency apparently wants an even playing field among all traders. This move comes after the Chinese market regulator announced "comprehensive and systematic regulation" after a big market sell-off in 2024.  The regulation makes sense in theory, but the Financial Times remarks that "people familiar" with the Chinese HFT market state that firms have been abusing a legal loophole by rolling their own custom servers and installing them under the name of approved Chinese brokers.  The report contains no information on exactly what type of hardware is involved in this story, but the recently introduced U.S. export controls cover not just high-end Nvidia GPUs, but all sorts of high-end FPGAs, ASICs, even HBM and standard Intel and AMD processors. It's not hard to imagine that $17 million worth of highly optimized servers have one, multiple, or all of the aforementioned bits of silicon.  Stay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors  Follow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.
    Key Takeaways Citigroup analysts on Tuesday forecast hyperscalers would spend even more on AI infrastructure next year than previously expected.  The AI data center buildout is increasingly being financed by debt rather than cash flows, an evolution that exposes the AI boom to new vulnerabilities like default and interest rate risk.  Other financing methods, like the investment agreement announced by OpenAI and Nvidia last week, have worried some onlookers fearful of an AI bubble.  After a series of big cloud computing deals this month, Citigroup analysts now expect AI spending to exceed their already eye-watering forecast.  Citi analysts on Tuesday estimated that hyperscalers—including Microsoft (MSFT), Alphabet (GOOG), Amazon (AMZN), Oracle (ORCL), and CoreWeave (CRWV)—will spend $490 billion on infrastructure and other capital goods next year, up from a prior estimate of $420 billion. Citi’s forecasts are slightly above the Wall Street consensus.  Why This Matters To You The AI infrastructure boom has been a major force behind U.S. stock market gains and economic growth in recent years. If tech companies rely on debt to fund their massive AI investments, they could expose the AI buildout—and the broader economy—to greater risk.  The analysts pointed to an onslaught of announced partnerships, investments, and products in recent weeks as evidence of strong AI demand. They said their recent conversations with CIOs and CTOs at a range of companies “reflect a similar increase in urgency around adoption at the enterprise level.”  Citi expects AI infrastructure providers like Nvidia (NVDA) to benefit from higher spending. As such, the firm’s analysts raised their price target on Nvidia shares to $210 from $200 on Tuesday.    Debt, Not Cash Flows, May Fund Future Spending  The hyperscalers are among the world’s largest, most profitable companies, a fact that has enabled them to increase their infrastructure spending exponentially over the past few years. But not even hugely profitable tech giants can undertake this level of investment on their own.  “It is notable that we have gone from the cash flow funded stage of this investment cycle to the debt funded stage, with the incremental risks that come with it,” Citi’s analysts wrote.  Oracle last week sold $18 billion of bonds in the second-largest U.S. debt deal this year, according to a Bloomberg report. Oracle, which has spent more than it's made in each of the last two quarters, is expected to use the debt to increase its cloud capacity so it can deliver on a five-year, $300 billion deal with OpenAI. Adding that much capacity will be expensive. Citi sees Oracle’s capital expenditures ballooning to $58 billion in fiscal year 2027, nearly three times what it spent in the fiscal year that ended in May.  OpenAI, another company that will need to spend a lot to support its ambitions, took a different approach to raising money. Last week, the company struck a deal with Nvidia to deploy 10 GW of Nvidia systems over the next five years in exchange for an incremental $100 billion equity investment. OpenAI is reportedly discussing leasing—not buying—the chips from Nvidia, a novel arrangement that could cut its hardware costs by 10 to 15%, according to The Information.  The deal raised eyebrows on Wall Street, where some analysts and investors expressed concern about the “circularity” and concentration of the AI ecosystem. Some skeptics likened it to a bailout, with Nvidia stepping in as an investor of last resort to support a cash-starved OpenAI. It has also inspired comparisons to the Dotcom Bubble, when telecom equipment providers lent to and invested in their own customers, fueling speculative fervor.  But analysts see important differences between the 1990s and today. “The critical distinction, in our view, is the ‘off-ramp’ created by growing external demand for AI services driven by enterprise adoption,” write Citi analysts.  Companies like OpenAI and Meta (META), they say, are rolling out AI-driven applications and services with clear monetization prospects. And the rate of AI’s technological progress, they argue, is quickly expanding the scope of potential applications.
    CoreWeave Inc. (NASDAQ:CRWV) surged after it disclosed in a regulatory filing that it has entered into a multibillion-dollar agreement with Meta Platforms Inc. (NASDAQ:META) for cloud computing capacity valued at up to $14.2 billion.  According to an 8-K filing with the SEC, the agreement was executed on September 25 under the companies' existing Master Services Agreement, effective as of December 2023.  Meta has committed to payments of approximately $14.2 billion through December 14, 2031, with the option to significantly expand the order through 2032.  Also Read: CoreWeave Expands Agreement With OpenAI To Train Next-Gen Models  CoreWeave will provide reserved capacity orders, subject to delivery and service availability requirements. The agreement includes provisions for termination, indemnification, and limitations of liability.  The company determined that the Master Services Agreement qualifies as a material definitive agreement under SEC rules. It will remain effective until all orders are fulfilled, expired, or terminated in accordance with its terms.  Part Of Larger Growth Push  The new contract builds on CoreWeave's rapid expansion in 2025 as demand for artificial intelligence infrastructure accelerates.  Earlier this year, the company announced a $6.3 billion arrangement with Nvidia (NASDAQ:NVDA) to purchase unused cloud capacity through 2032.  It also expanded its agreement with OpenAI by up to $6.5 billion, in addition to an earlier $11.9 billion commitment.  Since its March IPO, CoreWeave's shares have more than tripled, lifted by contracts with Microsoft (NASDAQ:MSFT), Nvidia, OpenAI, and now Meta. However, trading has been volatile.  In August, insiders sold shares as lock-up restrictions expired, even as institutional investors added positions. Analysts tracked by Benzinga list price forecasts ranging widely, from below current levels to as high as $200 per share, with consensus near $127.  Price Action: CRWV shares were trading higher by 15.20% to $141.14 at last check Tuesday. META was down 1.53%.  Read Next:  Photo by T. Schneider via Shutterstock  Up Next: Transform your trading with Benzinga Edge's one-of-a-kind market trade ideas and tools. Click now to access unique insights that can set you ahead in today's competitive market.  Get the latest stock analysis from Benzinga?  This article CoreWeave Extends Hot Streak With Meta's $14 Billion Cloud Deal originally appeared on Benzinga.com  © 2025 Benzinga.com. Benzinga does not provide investment advice. All rights reserved.
    IonQ’s IONQ path to profitability is anchored by both strong revenue performance and strategic capital allocation. In the last-reported second quarter of 2025, the company’s revenues surpassed the high end of the guidance by 15%, demonstrating the ability to accelerate project implementation with existing customers. Its substantial $1 billion equity investment, coupled with pro forma cash and investments of $1.6 billion, provides a solid financial foundation to fund ongoing research, acquisitions and global expansion without immediate pressure to achieve near-term profitability. These resources also enable IonQ to execute on its ambitious roadmap for scaling quantum computing capacity while maintaining operational flexibility.  A primary pillar of IonQ’s profitability strategy is its accelerated technology roadmap, enhanced by acquisitions and strategic partnerships. The acquisitions of Oxford Ionics, Lightsynq and Capella position the company to achieve 800 logical qubits by 2027 and 80,000 logical qubits by 2030. These milestones, combined with Lightsynq’s photonic interconnect technology and Capella’s space-based quantum networking capabilities, allow IonQ to target scalable, cost-efficient quantum computing systems with low unit costs, providing a clear pathway to attractive unit economics once large-scale deployment is achieved.  IonQ is also building a diversified commercial ecosystem to drive recurring revenue streams. Collaborations with global organizations, such as AstraZeneca, AWS, NVIDIA, Oak Ridge National Laboratory and the U.S. Department of Energy, highlight practical applications where IonQ’s quantum systems provide measurable advantages, including a 20x speed-up in drug development workflows. In addition, the development of production-grade Quantum Key Distribution (QKD) networks, used by governments, financial institutions and telecoms, establishes a parallel revenue engine from quantum networking.  With its vertical integration, experience in trapped-ion technology and a patent portfolio of over 1,000, IonQ is well-positioned to sustain competitive advantage as it scales its quantum and networking businesses worldwide.  IONQ’s Peer Update  Rigetti RGTI: Technologically, Rigetti is advancing superconducting gate-based hardware via its chiplet architecture, with a 36-qubit system available and a 100+ qubit system at 99.5% two-qubit fidelity expected by year-end 2025. This leaves the company well-positioned to scale while retaining optionality for partnerships or acquisitions.
    Nvidia is poised for further upside as it ramps up initiatives to improve artificial intelligence infrastructure, including new products and partnerships, according to Citi. The investment bank, which has a buy rating on shares, raised its price target for Nvidia to $210 from $200,…  This story appeared on cnbc.com , 2025-09-30 18:21:37.273000.
    TrendForce reports that following the completion of inventory digestion in the downstream consumer market concluded at the end of Q4 2023, DRAM suppliers shifted focus towards HBM and server DDR5 products, leading to tighter supply for other DRAM types. This increase in demand pushed overall DRAM prices higher, encouraging module manufacturers to replenish stocks and boost procurement. Consequently, the global DRAM module market achieved USD 13.3 billion in revenue in 2024, a 7% YoY increase that reversed the 28% decline experienced in 2023.In the latter half of 2024, demand momentum declined due to rising module prices. Module manufacturers struggled to transfer these high chip costs to distribution channels, limiting sales. To stay competitive, some aimed to enhance costs structure by increasing their purchase of cheaper server reball chips.TrendForce observes that, with the overall market recovering in 2024, most module manufacturers experienced year-over-year revenue growth. However, the extent of growth differed depending on target markets and operational strategies.In 2024, the leading five DRAM module manufacturers captured 81% of the total global revenue, with the top eight accounting for 83%. Kingston retained a strong 66% market share, maintaining its leading position. However, its revenue growth was slower compared to competitors, due to weaker demand in the consumer segment during the second half of 2024. Kingston remained focused on its high-end brand image, emphasizing profitability.ADATA utilized inexpensive inventory accumulated during the 2Q23-3Q23 rebound, aggressively increasing shipments in the first half of 2024. This approach contributed to a 20% rise in revenue, earning it the second spot in the global rankings.Kimtigo actively broadened its domestic and international channels, leveraging the 2H23 rebound to capitalize on recovery opportunities and projecting a 10% revenue increase in 2024.Team Group concentrated on the gaming market, increasing its presence in North American e-commerce and distributor channels, while also expanding its enterprise server DRAM projects. These initiatives resulted in a 59% revenue increase, elevating the company to fourth place.Patriot Memory utilized a diversified portfolio across consumer, gaming, and industrial control sectors, achieving a 12% YoY growth and securing the fifth position.Innodisk has solidified its position in the industrial sector and is actively growing its edge AI product offerings. By partnering with NVIDIA platforms, it has expanded into new markets, increasing revenue and climbing to sixth place.Apacer also concentrated on industrial markets and increased operational flexibility by outsourcing manufacturing to partners in India, leading to a modest recovery and securing seventh place.Agile Gear International (AGI) quickly expanded by entering Amazon Japan, boosting brand awareness and sales. It broke into the top eight globally and achieved the highest revenue growth rate among leading companies.

    ### AMD ###
    Popular PC vendor Maingear has today debuted a brand new line-up of extremely potent performance PCs with an eye-watering price tag to match. New this week are the Apex Force and Apex Rush models, starting at a cool $7,469/$6,259 respectively.  First up is the new Apex Force, a full-tower chassis housed inside the Phanteks NV9 case. Maingear touts a dual-loop hardline cooling system with offset tubing, upgradable RGB, and more. Support for dual 420mm radiators with three 140mm fans keeps everything cool, which is important given the components on offer.  Maingear Apex Force specs  Chassis: Phanteks NV9 (Full-tower)  Phanteks NV9 (Full-tower) Motherboard: Top-tier Z890 and X870E motherboards from Asrock and MSI  Top-tier Z890 and X870E motherboards from Asrock and MSI CPU: AMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K  AMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K GPU: NVIDIA GeForce RTX 5080 and 5090 GPUs  NVIDIA GeForce RTX 5080 and 5090 GPUs RAM: Up to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz)  Up to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz) Storage: Up to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs  Up to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs Cooling: 2x 420mm x 60mm radiators, 6x 140mm x 30mm RGB fans, Custom APEX Integrated Cooling System, Separate GPU and CPU dual loop system, Easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance  2x 420mm x 60mm radiators, 6x 140mm x 30mm RGB fans, Custom APEX Integrated Cooling System, Separate GPU and CPU dual loop system, Easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance Power: Up to 1650W 80+ Titanium PSU  Up to 1650W 80+ Titanium PSU Aesthetics: Acrylic and metal hard tubing with 10-degree offset to match case design, premium metal fittings in various colors, dual coolant color options, multiple translucent coolant colors available, diffused RGB trim kit, motherboard and case RGB control with separate cooling loop zones.  All of that will set you back a cool $7,469, but that's just the starting price, with upgrade options for beefier processor, GPU, RAM, and storage likely to run you more.  The new Apex Rush is cheaper (relatively speaking), starting at just $6,259. The dual-chamber mid-tower has panoramic tempered glass, and customization for water cooling with options for hard and soft tubing. Cooling is less prolific at just dual 360mm radiators with six 120mm fans. There are also screwless panels for the cooling system to make draining and filling easier.  (Image credit: Maingear)  Maingear Apex Rush specs  Chassis: Lian-Li O11 EVO RGB (Mid-tower)  Lian-Li O11 EVO RGB (Mid-tower) Motherboard: Top-tier Z890 and X870E motherboards from Asrock and MSI  Top-tier Z890 and X870E motherboards from Asrock and MSI CPU: AMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K  AMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K GPU: NVIDIA GeForce RTX 5080 and 5090 GPUs  NVIDIA GeForce RTX 5080 and 5090 GPUs RAM: Up to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz)  Up to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz) Storage: Up to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs  Up to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs Cooling: 2x 360mm radiators, 7x 120mm RGB fans, Custom APEX Integrated Cooling System, easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance  2x 360mm radiators, 7x 120mm RGB fans, Custom APEX Integrated Cooling System, easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance Power: Up to 1650W 80+ Titanium PSU  Up to 1650W 80+ Titanium PSU Aesthetics: Soft vinyl or Neoprene tubing with optional braided sleeving or Acrylic and Metal hard tubing, Premium metal fittings in various colors, multiple translucent coolant color options, braided cable sleeving, motherboard and case RGB control with diffused lighting  Like the rest of the lineup, the new Apex Force and Apex Rush PCs come with a one-year warranty, extendable to three years, with financing options also available. Maingear's latest PCs can be found on its website.  Follow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.
    What Happened?  Shares of leading designer of graphics chips Nvidia (NASDAQ:NVDA) jumped 2.3% in the afternoon session after several Wall Street firms raised their price targets on the stock and reports surfaced of a major deal involving its advanced AI systems.  The positive sentiment was fueled by a reported deal where cloud provider CoreWeave agreed to supply Meta Platforms with up to $14.2 billion in AI computing power using Nvidia's latest GB300 systems. This agreement highlighted the immense and sustained demand for AI infrastructure from major tech companies. Further boosting investor confidence, several financial firms, including KeyBanc, Barclays, and Citi, increased their price targets for Nvidia. Analysts pointed to an improving supply of key components and strong, continued spending in the AI sector as the primary reasons for their optimistic outlook, which helped push the stock to a record high.  After the initial pop the shares cooled down to $186.21, up 2.4% from previous close.  Is now the time to buy Nvidia? Access our full analysis report here, it’s free.  What Is The Market Telling Us  Nvidia’s shares are quite volatile and have had 18 moves greater than 5% over the last year. In that context, today’s move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.  The previous big move we wrote about was 8 days ago when the stock gained 4.1% on the news that the company announced a partnership with OpenAI that included plans for a potential investment of up to $100 billion.  The deal aimed to supply OpenAI with advanced AI hardware for its next generation of AI models and the buildout of massive data centers. According to the announcement, the partnership involved deploying at least 10 gigawatts of Nvidia's systems for OpenAI's AI infrastructure. This news solidified Nvidia's central role in the future of artificial intelligence.  Nvidia is up 34.6% since the beginning of the year, and at $186.21 per share, has set a new 52-week high. Investors who bought $1,000 worth of Nvidia’s shares 5 years ago would now be looking at an investment worth $13,762.  Unless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.
    A group of academics from KU Leuven and the University of Birmingham has demonstrated a new vulnerability called Battering RAM to bypass the latest defenses on Intel and AMD cloud processors.  "We built a simple, $50 interposer that sits quietly in the memory path, behaving transparently during startup and passing all trust checks," researchers Jesse De Meulemeester, David Oswald, Ingrid Verbauwhede, and Jo Van Bulck said on a website publicizing the findings. "Later, with just a flip of a switch, our interposer turns malicious and silently redirects protected addresses to attacker-controlled locations, allowing corruption or replay of encrypted memory."  Battering RAM compromises Intel's Software Guard Extensions (SGX) and AMD's Secure Encrypted Virtualization with Secure Nested Paging (SEV-SNP) hardware security features, which ensure that customer data remains encrypted in memory and protected during use.  It affects all systems using DDR4 memory, specifically those relying on confidential computing workloads running in public cloud environments to secure data from the cloud service provider using hardware-level access control and memory encryption.  The attack, in a nutshell, involves leveraging a custom-built, low-cost DDR4 interposer hardware hack to stealthily redirect physical addresses and gain unauthorized access to protected memory regions. The interposer makes use of simple analog switches to actively manipulate signals between the processor and memory, and can be built for less than $50.  On Intel platforms, Battering RAM achieves arbitrary read access to victim plaintext or write plaintext into victim enclaves, whereas on AMD systems, the attack can be used to sidestep recent firmware mitigations against BadRAM, which was documented by the researchers back in December 2024, and introduce arbitrary backdoors into the virtual machine without raising any suspicion.  Successful exploitation of the vulnerability can allow a rogue cloud infrastructure provider or insider with limited physical access to compromise remote attestation and enable the insertion of arbitrary backdoors into protected workloads.  Battering RAM was reported to the vendors earlier this year, following which Intel, AMD, and Arm have responded that physical attacks are currently considered out of scope of their product's threat model. However, defending against Battering RAM would require a fundamental redesign of memory encryption itself, the researchers noted.  "Battering RAM exposes the fundamental limits of the scalable memory encryption designs currently used by Intel and AMD, which omit cryptographic freshness checks in favor of larger protected memory sizes," they added. "Battering RAM [...] is capable of introducing memory aliases dynamically at runtime. As a result, Battering RAM can circumvent Intel's and AMD's boot-time alias checks."  The disclosure comes as AMD released mitigations for attacks dubbed Heracles and Relocate-Vote disclosed by the University of Toronto and ETH Zürich, respectively, that can leak sensitive data from cloud environments and confidential virtual machines that rely on AMD's SEV-SNP technology by means of a malicious hypervisor.  "The system lets the hypervisor move data around to manage memory efficiently," David Lie, director of the Schwartz Reisman Institute (SRI) at the University of Toronto, said. "So when data is relocated, AMD's hardware decrypts it from the old location and re-encrypts it for the new location. But, what we found was that by doing this over and over again, a malicious hypervisor can learn recurring patterns from within the data, which could lead to privacy breaches."  Last month, ETH Zürich researchers also demonstrated that a CPU optimization known as the stack engine can be abused as a side channel for attacks that lead to information leakage. A proof-of-concept (PoC) has been developed for AMD Zen 5 machines, although it's believed that all models have this "abusable hardware feature."  The discovery of Battering RAM also follows a report from Vrije Universiteit Amsterdam researchers about a new, realistic attack technique referred to as L1TF Reloaded that combines L1 Terminal Fault (aka Foreshadow) and Half-Spectre gadgets (aka incomplete Spectre-like code patterns) to leak memory from virtual machines running on public cloud services.  "L1TF is a CPU vulnerability that allows an (attacker) VM to speculatively read any data residing in the (core-local) L1 data cache – including data the VM shouldn't have access to," VUSec researchers said. "At a high level, L1TF Reloaded abuses this to obtain an arbitrary RAM read primitive."  Google, which provided the researchers with a sole-tenant node in order to conduct the research safely without potentially affecting any other customers, awarded a $151,515 bug bounty and "applied fixes to the affected assets." Amazon said the L1TF Reloaded vulnerability does not impact the guest data of AWS customers running on the AWS Nitro System or Nitro Hypervisor.  Spectre, which first came to light in early 2018, continues to haunt modern CPUs, albeit in the form of different variants. As recently as two weeks ago, academics from ETH Zürich devised a new attack known as VMScape (CVE-2025-40300, CVSS score: 6.5) that breaks virtualization boundaries in AMD Zen CPUs and Intel Coffee Lake processors.  Described as a Spectre branch target injection (Spectre-BTI) attack targeting the cloud, it exploits isolation gaps across host and guest in user and supervisor modes to leak arbitrary memory from an unmodified QEMU process. A software fix has been introduced in the Linux kernel to counter the cross-virtualization BTI (vBTI) attack primitive.  "VMScape can leak the memory of the QEMU process at the rate of 32 B/s on AMD Zen 4," the authors said in a study. "We use VMScape to find the location of secret data and leak the secret data, all within 772 s, extracting the cryptographic key used for disk encryption/decryption as an example."
    Introduction Sure, computing Deep Neural Networks (DNNs) is a computationally expensive endeavour. Luckily, their computation can be parallelized on Graphics Processing Units (GPUs), which excel at performing numerous small tasks concurrently. To enable programmability of this hardware, several frameworks have been released for General Purpose (GPGPU) computing such as CUDA – but remain complex for easy adoption and implementation. This is irksome for researchers and deep learning practitioners who need to iterate through algorithms quickly to achieve optimal performance. Domain Specific Languages (DSLs) and compilers like Triton are excellent for enhancing productivity when writing GPU kernels to accelerate training and inference for AI workloads. Note that this article is covering the Triton DSL and not the Triton Inference Server.  Key Takeaways Triton is a python DSL and compiler initially designed for GPU kernels but has been expanding to support other hardware, including CPUs and AI accelerators.  initially designed for GPU kernels but has been expanding to support other hardware, including CPUs and AI accelerators. Before Triton, developers primarily used high-level frameworks (like PyTorch) or low-level languages (like CUDA). Triton provides an abstraction layer that simplifies GPU programming compared to low-level languages, while offering more control than high-level frameworks.  The triton.jit decorator ( @triton.jit ) decorator defines Triton kernels.  ) decorator defines Triton kernels. Pointer arithmetic is used for computing memory locations, ensuring that memory accesses are fast.  Why was Triton Developed? Before Triton, developers had two main options for programming machine learning tasks on different hardware: (1) High-Level Frameworks (like PyTorch) and (2) Low-Level Languages (like CUDA or PTX). The philosophy behind Triton is to let the compiler do the work you don’t want to do, while still giving you control over critical aspects like algorithms and tuning parameters. You still define your algorithm, data types, and precision, but you don’t have to worry about complex tasks such as shared memory management, using tensor cores, and load coalescing and optimizing memory access patterns. The Triton compiler handles all of this automatically, saving the developer significant effort.  The above diagram and the table below was presented in a talk by Thomas Raoux from OpenAI at the PyTorch 2023 conference :“Triton tries to find an abstraction sweet spot between what you want to expose to users and what you want the compiler to do… Compilers are productivity tools…the goal of Triton is to have the compiler do the work you don’t want to do … but still leaves control on things like algorithms and any knob you want to use to be able to do tuning.” CUDA Triton Torch Op Algorithm User User Compiler Shared memory User Compiler Compiler Barriers User Compiler Compiler Distribution to blocks User User Compiler Grid size User User Compiler Distribution to Warps/threads User Compiler Compiler Tensor Core usage User Compiler Compiler Coalescing User Compiler Compiler Intermediate data layout User Compiler Compiler Workgroup size User User Compiler In this tutorial, we’re going to implement matrix multiplication with Triton. There are a number of other tutorials available in the official documentation including vector addition, fused softmax, low-memory dropout, layer normalization, fused attention (FlashAttention v2), invoking a custom function from an external library, group GEMM, persistent matmul, block scaled matrix multiplication.  Anatomy of a Triton Kernel  The above figure was presented in the Triton 2024 conference in the Tools for Triton talk by Keren Zhou. It may also be worthwhile to familiarize yourself with the triton.language page in the Triton documentation.  Kernel decorator: A @triton.jit decorator defines a triton kernel.  Pointers: These are passed into the function and specify the memory location where the elements of value are stored.  Program IDs: tl.program_id() is used to specify the current program instance  Memory Operations: tl.load and tl.store handle moving tensor values between global memory and Triton’s registers  Primer on Matrix Multiplication Matrix A with shape (M, K)  Matrix B with shape (K, N)  Resulting matrix C has shape (M, N) When implementing matrix multiplication, we want to break it down into smaller chunks – often referred to as tiles or blocks. If we look at the code, we have a doubly nested for loop where one loop is placed inside another. We would use this structure to iterate over two-dimensional data, like a grid, matrix, or table. The outer loops parallelize the work across blocks while the inner loops accumulate the dot products for each tile. A Triton program instance is performing each iteration of the doubly-nested for-loop. for m in range ( 0 , M , BLOCK_SIZE_M ) : for n in range ( 0 , N , BLOCK_SIZE_N ) : acc = zeros ( ( BLOCK_SIZE_M , BLOCK_SIZE_N ) , dtype = float32 ) for k in range ( 0 , K , BLOCK_SIZE_K ) : a = A [ m : m + BLOCK_SIZE_M , k : k + BLOCK_SIZE_K ] b = B [ k : k + BLOCK_SIZE_K , n : n + BLOCK_SIZE_N ] acc += dot ( a , b ) C [ m : m + BLOCK_SIZE_M , n : n + BLOCK_SIZE_N ] = acc For more context on the code:  The line below extracts a horizontal tile of matrix A with dimensions BLOCK_SIZE_M by BLOCK_SIZE_K. a = A [ m : m + BLOCK_SIZE_M , k : k + BLOCK_SIZE_K ] A : The full matrix  m: m+BLOCK_SIZE_M : This is the row slice. Here, we select a block of rows starting at index m and ending index m+BLOCK_SIZE_M . The outer for loop, for m in range(0,M,BLOCK_SIZE_M): , increments in m steps of BLOCK_SIZE_M, moving the starting point for each new row block. k : k+BLOCK_SIZE_K : This is the column size. Here, we are selecting a block of column that begin with index k and ends at k+BLOCK_SIZE_K. This is addressed by the inner inner for loop, for k in range(0, K, BLOCK_SIZE_K), which iterates through the columns of matrix A in blocks of BLOCK_SIZE_K. The line below extracts a vertical tile of matrix B with dimensions BLOCK_SIZE_K by BLOCK_SIZE_N. b = B [ k : k + BLOCK_SIZE_K , n : n + BLOCK_SIZE_N ] B: The second full matrix  k : k+BLOCK_SIZE_K : In matrix B , this is the row slice. A block of rows is selected from matrix B starting at k and ending at k+BLOCK_SIZE_K .  n : n+BLOCK_SIZE_N : This is the column size. Here, we are selecting a block of columns in matrix B that begin with index n and ends at n+BLOCK_SIZE_N. This is addressed by the inner for loop, for n in range(0, N, BLOCK_SIZE_N), which iterates through the columns of matrix B in blocks of BLOCK_SIZE_N. The core idea here is that by taking slices of our matrices, we can perform calculations – in this case the dot product – on smaller manageable chunks of data that can be loaded on to faster GPU memory leading to better GPU performance.  Getting Started with Triton on DigitalOcean DigitalOcean has AI accelerators and Virtual Machines available as GPU Droplets and Droplets respectively. With respect to GPUs, we offer many solutions including NVIDIA H100 and H200 as well as AMD MI300 and MI325.Create a GPU Droplet and in the web console: git clone https : // github . com / triton - lang / triton . git cd triton pip install - r python / requirements . txt pip install - e . If LLVM isn’t installed on your system, the setup.py script will automatically fetch the official LLVM static libraries and use those for linking. To build using your own LLVM version, check the “Building with a custom LLVM” section on GitHub. After installation, you can verify everything works by running the test suite. make dev - install make test make test - nogpu  Conclusion In this tutorial, we covered the motivation behind and the fundamentals of Triton. Additionally, we walked you through a Triton matrix multiplication implementation and benchmarking. Be sure to check out the links scattered throughout the article and the references section for supplementary content.  Final Thoughts Triton strikes a balance by allowing its users to define and manipulate tensors in SRAM and modify them with the use of torch-like operators, making it possible to write efficient GPU code without extensive CUDA experience. There’s a lot we’re curious about. Particularly, how software and hardware co-evolves. How do open-source languages like Triton affect the CUDA moat? How does Triton compare to CuTe-DSL, Nvidia’s python DSL for kernel programming? What languages does the developer community and industry gravitate toward? And critically, how do these choices shape what gets built: do accessible abstractions democratize AI development, or do they introduce performance ceilings that matter at scale?
    William Shatner and Tom Bergeron are joining forces for a new holiday dramedy titled Family Tree, which is currently in pre-production and gearing up to begin filming in 2026. The project is being produced by Pathway Pictures.  The series was created by Shatner and Bergeron, with both set to star and executive-produce alongside Nat Bernstein. The script comes from Katie Amanda Keane and Marla Sokoloff, with Sokoloff also stepping behind the camera to direct.  Family Tree tells the story of three estranged siblings who reunite during Christmas to sell their rundown childhood home, only to realize that restoring the house could also help mend their broken relationships. Shatner will play Frank, while Bergeron will take on the role of Jeff.  Sokoloff, who fans will recognize from her roles in The Practice and Fuller House, shared her excitement about the project, saying:  “Family Tree is about the kind of healing that only happens when you’re stuck together with the people who know you best, and challenge you the most. It’s a story with grief, growth, and humor, wrapped in holiday warmth.  “Katie Amanda Keane and I have always wanted to collaborate on a holiday movie that is rooted in family reality with a touch of holiday magic, and I think we accomplished that with this script.”  Shatner also spoke about the project, adding: “I am so pleased to be involved in this magical mysterious Christmas show that celebrates love!”  With a heartfelt story, a mix of comedy and drama, and Shatner and Bergeron leading the charge, Family Tree looks like it’s shaping up to be a charming addition to the holiday season lineup when it eventually arrives.  Source: Deadline
    Intel’s original 64bit extensions for x86  Introduction  In the late 1900s, Intel was fully invested in Itanium (IA-64) being their future 64bit architecture.  At that time (allegedly around 1997-1998), some Intel engineers – who were more cautious than their management – built a 64bit extension for their x86 processors as a backstop. It never shipped:  Intel’s Pentium 4 had our own internal version of x86–64. But you could not use it: we were forced to “fuse it off”, meaning that even though the functionality was in there, it could not be exercised by a user.  This was a marketing decision by Intel — they believed, probably rightly, that bringing out a new 64-bit feature in the x86 would be perceived as betting against their own native-64-bit Itanium, and might well severely damage Itanium’s chances.  – Bob Colwell  AMD announced AMD64, their own 64bit extension to x86, in 1999 (and shipped it in 2003), condemning both Itanium and Intel’s own x86 extension to obscurity.  Intel implemented AMD’s design in Project Yamhill and shipped its first processors with AMD64 in 2004.  How did Intel’s design look like?  While AMD’s 64bit extension design that repurposed inc/dec instructions as the REX prefix is well-documented, there is very little known about Intel’s own 64bit extension design.  Here is what can be reconstructed from Intel’s patent applications from 2000 and 2003:  An instruction having [a] format […] — where the mode field is 01B , the R/M field is 100B , the index field is 100B — has addressing mode information that is currently unsupported in the IA-32 architecture regardless of the value of the scale field.  An instruction of [that] format […] thereby includes heretofore unused bit fields (e.g., the two bits of scale field, bits of displacement, etc.), that can support an expanded logical register set for existing instructions formats and legacy operands.  Material from the Bristol Community College also mentions this specific combination of bits:  Note that this addressing mode does not allow the use of the ESP register as an index register.  Presumably, Intel left this particular mode undefined to provide the ability to extend the addressing modes in a future version of the CPU.  Differences from AMD64  AMD’s REX prefix introduced 1 bit R to extend the 3-bit register to 4 bits, allowing access to 16 registers.  The prefix also added 1 bit W to extend operand size, 1 bit X to extend SIB byte’s index and 1 bit B to extend SIB byte’s base.  Intel’s approach would have added 2 additional bits to the existing 3-bit register encoding, and introduced a second, additional 5-bit register encoding.  It appears this encoding would have provided a future expansion possibility to 32 registers, even if the implementation may have been limited to 16 registers at first.  It is unclear what the equivalent of (or the alternative to) AMD64’s W , X and B bits would have been under Intel’s design.  Conclusion  Sadly, there is no definitive information on how close the patents were to what was shipped (fused-off) in Intel processors of that specific time period.
    Visible Noise Nine months after Nvidia ships a feature, AMD produces a paper about their equivalent, and btw it doesn’t work with any of their existing products. Looks like 90XX is a dead end product.  Visible Noise Why are people so surprised and angry at Nvidia’s success?  Visible Noise They literally have no competition. Nvidia is still delivering features years ahead of AMD.  Hecate91 As usual Nvidia fans whine that AMD cards don't have a proprietary to Nvidia feature, then whine anyways when AMD develops something similar because they've never bought an AMD and never have any intention to do anything but mindlessly bash the brand.  Anyway unless the feature does something groundbreaking then it's just another optional feature, I wouldn't expect this to make RDNA4 cards obsolete, and perhaps it could be processed at a driver level or on existing hardware.  Nvidia shipped Ray Tracing, it wasn't supported on GTX cards. They shipped MFG, it's not supported on cards prior to RTX50. You don't consider GeForce a dead end lineup, do you ?Because Nvidia is using their success to push their agenda of making the entire planet dependent on their dogshit AI tech that nobody neither wants nor needs.100% AI generated raster ? Miss me with that shit.The latest AMD has been on an Nvidia feature is Ray Reconstruction/Redstone and they barely have a full year of latency on this.Also, I'd like to point out that if you read the article a little bit closer, AMD's tech seems to be better since hitting broader, not just RT perf.And since if could run on raster, it would be hardware agnostic instead of vendor locked.I noticed that so far, when AMD follows, they might be later on delivery, but they follow with better.I'm curious about that "potential performance hit" mentioned on the article, how much of a hit are we talking about ? How much variance in outcome can we expect ? How is it behaving at different resolutions and different tiers of details complexity ? Is it hardware agnostic ? How would it run on other brands of cards ?I gotta say, I'm looking forward to this, even if if looks to be hardware dependent to get the intended performance, it kinda sounds like a new "FSR moment" to me when they make something that just works for everyone and improves X or Y factor.
    Zhaoxin may not produce the best CPUs for gaming, but the leading Chinese fabless semiconductor enterprise is undoubtedly preparing to unleash a highly impressive server chip. Zhaoxin has unveiled its next-generation Kaisheng KH-50000 processors, which the company describes in its press release as "presenting a 'technological gift' on the eve of the 76th anniversary of the founding of the People's Republic of China."  The KH-50000 utilizes Zhaoxin's latest Century Avenue architecture, named after a famous road in Shanghai. The company is fond of naming its architectures after famous locations within Shanghai because, after all, Zhaoxin is a joint venture between VIA Technologies and the Shanghai government. Century Avenue is the current architecture used by the company for its mainstream KaiXian KX-7000 processors; consequently, it is logical for Zhaoxin to align its latest server processors accordingly. Although Century Avenue is an internally developed architecture by Zhaoxin, many speculate that Century Avenue derives from Centaur Technology's CNS core, prior to the company's split from VIA Technologies in 2021.  Zhaoxin utilizes a chiplet design for the KH-50000, similar to AMD's Ryzen and EPYC processors, with a greater emphasis on the latter, given the high number of cores. A chiplet design would enable Zhaoxin to push the core boundary on the KH-50000, effectively matching AMD's EPYC 9004 (codenamed Genoa) series that tops out at 96 cores. Zhaoxin has planned two variants of the KH-50000: the flagship 96-core SKU and a more affordable 72-core SKU, both of which lack simultaneous multithreading (SMT). The KH-50000 represents a monumental leap forward for Zhaoxin, as it provides 3X more cores than the company's existing KH-40000.  Zhaoxin's photograph of the KH-50000 reveals that the chipset layout exhibits minor differences from that of AMD; the core design remains consistent, however. The gargantuan I/O die is centrally positioned on the processor, encircled by four clusters of compute dies. Each cluster contains three compute dies, totaling twelve. Each die incorporates eight cores and 32MB of L3 cache. When assembled, the resulting processor comprises a 96-core configuration with 384MB of L3 cache.  Zhaoxin Kaisheng KH-50000 Specifications  Swipe to scroll horizontally Processor Architecture Cores / Threads Base / Boost Clock (GHz) L3 Cache (MB) Memory Support PCIe Lanes SATA 3.2 Ports USB Ports Socket Package Size (mm) KH-50000 Century Avenue 96 / 96 2.2 / 3.0 384 12 Channel DDR5-5200 128 PCIe 5.0 + 16 PCIe 4.0 12 4 x USB 3.2 Gen 2 LGA 72 x 76 KH-50000 Century Avenue 72 / 72 2.6 / 3.0 384 12 Channel DDR5-5200 128 PCIe 5.0 + 16 PCIe 4.0 12 4 x USB 3.2 Gen 2 LGA 72 x 76 KH-40000/32 Yongfeng 32 / 32 2.5 / N/A 64 8 Channel DDR4-3200 128 PCIe 3.0 16 8 x USB 3.2 Gen 1 LGA 77.5 x 56.5  The clock speeds on the KH-50000 aren't too shabby and fall in line with what you'd expect from a server chip. The 96-core variant has a 2.2 GHz base clock and 3.0 GHz boost clock. Since the 72-core chip has fewer cores, Zhaoxin could push the base clock to 2.6 GHz but maintained the same boost clock.  Although the company has taken the wraps off the KH-50000, it didn't reveal the TDP or other power metrics for the upcoming server chip. The thing with a chiplet design is that Zhaoxin can effectively utilize older process nodes for the KH-50000. Sanctions don't hurt as much if you don't care about power consumption.  For comparison, AMD has historically kept its top EPYC chips around the 300-350W range, and that's with SMT. Nonetheless, the chipmaker has recently pushed the power envelope up to 500W, which is understandable when its EPYC processors are maxing out at 192 cores.  Stay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors  In addition to core count, the KH-50000 advances the development of Chinese server processors. It now supports up to 12 channels of DDR5-5200 RAM, allowing for a maximum of 3TB of memory, in contrast to the 2TB supported by DDR4-3200 on the KH-40000. Zhaoxin has added Compute Express Link (CXL) interconnect support. Furthermore, the expansion capabilities of the KH-50000 have enjoyed an upgrade to include 128 PCIe 5.0 lanes and 16 PCIe 4.0 lanes, compared to the 128 PCIe 3.0 lanes available on the KH-40000.  The SATA and USB ports experienced a slight decrease in numbers when comparing the KH-50000 to the KH-40000. However, Zhaoxin has upgraded the latter to support the latest USB 3.2 Gen 2 specification.  (Image credit: Zhaoxin)  The KH-50000 supports x86 32-bit and 64-bit instructions, including SSE4.2, AVX, and AVX2. Support for virtualization is also present. To adhere to China's security guidelines, the KH-5000 supports the country's proprietary SM2, SM3, and SM4 encryption standards. Notably, Zhaoxin has integrated National Technology's fourth-generation trusted computing chip (likely the NS350) beneath the KH-50000, where the contacts are situated. This chip meets the security requirements of China's GM/T 0012-2020 cryptographic module standard and complies with the international TPM 2.0 (SPEC 1.59) standard.  The footprint of the KH-50000 measures 72 x 76 mm, which is considerably larger than that of the KH-40000. Notably, it shares dimensions with AMD's Genoa and Bergamo processors, which measure 72 x 75.4 mm and are compatible with the socket SP5. Therefore, the size of the KH-50000 is precisely the same as that of AMD's more recent EPYC chips.  The KH-50000 slots into a socket with a Land Grid Array (LGA) design, meaning the pins are located on the motherboard rather than on the processor. Zhaoxin's latest server chips are scalable, similar to AMD's EPYC and Intel's Xeon chips. The KH-50000 embraces 2S and 4S systems, where you can accumulate up to 384 cores on the latter. Zhaoxin built its own ZPI (Zhaoxin Processor Interconnect) 5.0 for inter-chip communication.  Contrary to AI GPUs, companies in China can still acquire server chips without significant difficulty, albeit potentially at increased costs. Nonetheless, Zhaoxin continues to make considerable progress in the domestic market, and with Chinese authorities firmly committed to utilizing domestically produced technology, the company could achieve success even if the KH-50000 does not rival AMD or Intel's latest server chips.  Follow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!
    Switch the Market flag  Open the menu and switch the  Market flag for targeted data from your country of choice.  for targeted data from your country of choice.
    So far on this last day of Q3'2025 we are at just over 800 original Linux news articles for the quarter on Linux hardware and open-source software. Here is a look back at what proved to be most popular for the quarter.There was a lot of interesting developments for the Linux kernel this quarter both of technical merit as well as Linux kernel mailing list (LKML) drama. The ongoing Intel layoffs/restructurings have also led to a number of unfortunate setbacks in their Linux/open-source support. Plus a wide array of other interesting Linux/FLOSS developments.Before getting to the Q3'2025 news highlight list (see yesterday's Q3 review / featured article highlights as well)... As one last reminder, if you enjoy all of the daily original content on Phoronix over the past 21 years, today is the last day of the Phoronix.com autumn deal to help with the site by enjoying a discounted rate on Phoronix Premium . Thank you for your support consideration amid these ongoing difficult times for the web/ad industry and rampant ad-block usage and other issues continuing to hamper operations.With that said, here's a look at the most popular Q3'2025 news on Phoronix:Linus Torvalds has grown frustrated enough with seeing "Link: " tags within Git commits/patches that often times they are of no value and he's had enough of it. For Linux kernel activity moving forward he's going to be more strict over "useless" link tags in Git commit messages.The most depressing news of the week: Intel is ending their performance-optimized Clear Linux distribution. Over the past decade the Clear Linux operating system has shown what's possible with out-of-the-box performance on x86_64 hardware... Not just for Intel platforms but even showing extremely great performance results on AMD x86_64 too. But with the cost-cutting going on at Intel, Clear Linux is now being sunset.Linus Torvalds has used his authority to reject the RISC-V architecture changes for the Linux 6.17 kernel. The RISC-V updates won't land this cycle and will need to try again for v6.18 later in the year. Linus refers to at least some of the proposed RISC-V code as garbage along with being submitted rather late during the merge window.XTX Markets as one of the largest algorithmic trading firms that handles $250 billion in daily traded volume and relies on around 650+ petabytes of storage for its price forecasts and other algorithmic trading data has open-sourced its Linux file-system. XTX developed TernFS for distributed storage after they outgrew their original NFS usage and other file-system alternatives.Amid the ongoing discussion over what will happen too Bcachefs in the mainline Linux kernel, an interesting anecdote around Btrfs was mentioned.Code was open-sourced this week and posted to the Linux kernel mailing list as a "request for comments" (RFC) for a multi-kernel architecture. This proposal could allow for multiple independent kernel instances to co-exist on a single physical machine. Each kernel could run on dedicated CPU Cores while sharing underlying hardware resources. This could also allow for some complex use-cases such as real-time (RT) kernels running on select CPU cores.Linus Torvalds has finally come to a decision following his plans to part ways with the Bcachefs file-system and then not merging any Bcachefs updates for Linux 6.17.The newest hardware offering from Raspberry Pi announced today is... a 1TB SSD.Developers behind the Git distributed revision control system are debating whether to make Rust programming language support mandatory.Well, it's an unpleasant afternoon in Linux land with more signs of the ongoing impact from Intel's corporate-wide restructuring. Just after writing about Intel's CPU temperature monitoring driver now left unmaintained/orphaned, more patches hit the public Linux kernel mailing list to mark additional Intel drivers as orphaned and removing maintainer entries for Linux developers no longer at Intel.Ubuntu 25.10's transition to using Rust Coreutils in place of GNU Coreutils has uncovered a few performance issues so far with the Rust version being slower than the C-based GNU Coreutils. Fortunately there still are a few weeks to go until Ubuntu 25.10 releases as stable and upstream developers are working to address these performance gaps.KDE Plasma 6.5 is introducing a change that has been "years in the wanting" and that is rounded bottom corners for windows.The Debian release team today shared their final release plans for Debian 13 "Trixie" that aims to be out as stable in less than one month's time.The upcoming FFmpeg 8.0 multimedia library release continues to get more exciting almost by the day. The newest feature being squeezed into this next release is a Whisper audio filter for making use of OpenAI's Whisper model for providing automatic speech recognition / transcription capabilities.Several years ago Google engineers began exploring address space isolation for the Linux kernel and ultimately proposing Linux ASI for better dealing with CPU speculative execution attacks. While the hope was it would better cope with the ever growing list of CPU speculative execution vulnerabilities, the effort was thwarted initially by I/O throughput seeing a 70% performance hit. That level of performance cost was unsustainable. But now that I/O overhead has been reduced to just 13%.Amid Intel's ongoing financial difficulties and multiple rounds of layoffs some Linux engineers at Intel left last year and there's been at least one prominent departure this week amid the latest round of challenges at the company.There is yet more apparent fallout from Intel's recent layoffs/restructurings as it impacts the Linux kernel... The coretemp driver that provides CPU core temperature monitoring support for all Intel processors going back many years is now set to an orphaned state with the former driver maintainer no longer at Intel and no one immediately available to serve as its new maintainer.Josef Bacik who is a long-time Btrfs developer and active co-maintainer alongside David Sterba is leaving Meta. Additionally, he's also stepping back from Linux kernel development as his primary job.Just over one year after the Amarok 3.0 release after a six year hiatus that brought it to Qt5 and KDE Frameworks 5, Amarok 3.3 is out today as the first version taking it to Qt6 and KDE Frameworks 6.The latest round of cost-cutting at Intel seems to be having a larger impact on their software engineering efforts than some of their previous rounds of layoffs. In addition to a prominent Linux kernel developer veteran leaving Intel last week where he worked for the past 14 years and responsible for many great upstream improvements, other Intel software engineers working on their Linux/open-source affairs have also been departing. In just the latest instance, one of the upstream Intel Linux kernel drivers is now "orphaned" due to the developer departing and no one experienced left to maintain the code.
    This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.  Hisense continues to step up its game with the release of the U8QG, its latest flagship QLED 4K TV. The display boasts one of the brightest pictures on the market while costing less than dimmer models from brands like Samsung and Sony.  But Hisense didn't stop at just making a bright TV. The U8QG also boasts excellent backlight control, which produces impressive black levels for a TV of this type, along with sparkling specular highlights.  Its color performance is better than last year's U8N, too, but there are some inaccuracies here and there. And though the TV's gaming capabilities are stacked with features like a 165Hz refresh rate, it's a bit disappointing that there are only three HDMI ports. Likewise, the U8QG has some tough competition from the TCL QM8K, which offers similar performance.  Choosing between the Hisense U8QG and the TCL QM8K is challenging, as both have their strengths and weaknesses. However, the Hisense U8QG is often on sale for less, and the incredible brightness it achieves is hard to ignore. This is easily one of the best-performing QLED 4K TVs of the year.  Hisense 65-inch U8QG QLED 4K TV The Hisense U8QG impresses with one of the brightest pictures on the market, and pairs that searing luminance with excellent contrast for a dynamic, punchy picture. Check price at Amazon Check price at Walmart Check price at Best Buy What we like Check mark icon A check mark. It indicates a confirmation of your intended interaction. Blazingly bright  Check mark icon A check mark. It indicates a confirmation of your intended interaction. Excellent contrast for a QLED  Check mark icon A check mark. It indicates a confirmation of your intended interaction. Includes great gaming features What we don’t like con icon Two crossed lines that form an 'X'. Some color inaccuracies in reds  con icon Two crossed lines that form an 'X'. Only three HDMI ports  con icon Two crossed lines that form an 'X'. USB-C DisplayPort doesn’t support HDR or VRR Specifics Resolution: 4K Ultra HD (3840 x 2160)  4K Ultra HD (3840 x 2160) Panel type: QLED, 165Hz with PC  QLED, 165Hz with PC Backlight: Mini LED with local dimming  Mini LED with local dimming HDR formats: HDR10, HDR10+, Dolby Vision, HLG  HDR10, HDR10+, Dolby Vision, HLG Smart TV OS: Google TV  Google TV HDMI ports: Three HDMI 2.1  The U8QG has a solid design, but its connection options are a mixed bag  The U8QG comes with a sturdy pedestal stand. John Higgins/Business Insider  The Hisense U8QG is available in five sizes: 55, 65, 75, 85, and 100 inches. Hisense provided a 65-inch model for this review. According to reports, the 65- and 85-inch models use a VA panel, while the other three sizes use an ADS Pro panel. VA panels tend to have better contrast, while ADS panels have better viewing angles. This means that the 55-, 75-, and 100-inch models likely offer worse black-level performance than the 65- and 85-inch editions. All sizes have a native 165Hz panel and use the new Hisense Hi-View AI Engine Pro processor.  The TV comes with a pedestal stand featuring a metal base (the 100-inch size includes left and right feet instead). It supports the TV well and can be attached in two positions, with the higher one offering a little over three inches of clearance to place a soundbar in front. A back panel on the stand covers a cable management channel to keep cords nice and tidy.  In comparison to other TVs released this year, the U8QG looks rather chunky. The panel measures 1.75 inches thick, and while that is technically less than the thickest point of its predecessor, the previous model got thinner in certain areas. There isn't a central electronics housing that protrudes, so the U8QG's thickness is uniform.  This chunkier build does allow room for an integrated 4.1.2 sound system, featuring side-firing and up-firing speakers. Although beefier than most tiny TV speakers, the sound still lacks oomph (particularly in the bass), and dialogue clarity suffers as the volume increases. I still recommend pairing the TV with a soundbar for an improved sonic experience.  The TV has three HDMI ports, instead of the typical four found on most displays in this class. John Higgins/Business Insider  Also housed on the side of the panel is a USB-C DisplayPort input, a unique inclusion not commonly found on many TVs. This connection is designed for PCs and, at first glance, appears to be geared toward gamers. However, this input doesn't support HDR or VRR (variable refresh rate). I also don't love its position, since a connected cable will be visible protruding from the side of the TV. Not a slick look. For a cleaner appearance and expanded gaming capabilities, the TV's three HDMI 2.1 inputs, located on the back of the panel, remain your best option.  You'll notice I said three HDMI ports instead of the four found on most TVs in this class. Unfortunately, it seems that including the USB-C input resulted in the removal of one of the HDMI ports. While having three HDMI 2.1 ports with 165Hz VRR is nice, it still limits the maximum number of sources that can be connected to the U8QG.  If you're using a soundbar connected to the eARC port and have three other sources to connect — perhaps an Xbox, PlayStation, and Apple TV — then you'll have to choose your favorites or play musical inputs when you want to use whichever source is left out. Admittedly, this won't affect the majority of people, but for those it will, it's important to note.  The remote is the same one Hisense introduced last year. It has a long, silver metallic design with backlit keys. It includes direct buttons for input selection and settings, a feature not offered by every manufacturer, and fits relatively well in the hand (those with smaller hands will need to slide it around in their palm to easily reach all the buttons).  The U8QG is incredibly bright, but it has some color issues  The U8QG's QLED panel and Mini LED backlight enable high brightness, creating a vibrant and bold image. John Higgins/Business Insider  Hisense is known for underselling its TVs' brightness performance. For years, it's basically been a guarantee that its TVs would measure at least a few hundred nits higher than advertised. But with such a strong push across the industry to increase brightness, I wondered how long its TVs would be able to keep overperforming on their promises. Well, they haven't stopped yet.  According to its specifications, the U8QG has a brightness of up to 5,000 nits across all sizes, except for the 55-inch model, which tops out at 3,000 nits. In my measurements — using a Portrait Displays C6 HDR5000, Murideo Seven-G 8K pattern generator, and Calman calibration software — the TV blasted past that number. In HDR Filmmaker mode, it achieved 5,759 nits from a 5% window. Even a 10% window was impressively bright, with a reading of 4,094 nits.  Those are the brightest measurements I've seen on those windows from any TV this year. In comparison, the TCL QM8K, another exceptionally bright TV, came in at 4,999 nits from a 5% window and 3,648 nits from a 10% window. With the default Filmmaker setting in SDR (which has brightness at 45), the U8QG measured 1,512 nits on a 10% window. Increasing the brightness to 100 results in a measurement of 3,297 nits.  With such a bright image, ambient light is of no consequence. Even if you have large windows in your living room, as I do, the image easily holds up to the sunlight. To a certain extent, the TV is even able to handle reflective light from lamps, as I found it to be less distracting on the U8QG than on other TVs with glossy panels.  The TV's luminance can be a bit overwhelming in certain settings, but you can adjust it to your preference. John Higgins/Business Insider  The question is, how much brightness do you actually need? It's true that there are some HDR movies on 4K Blu-ray and streaming that are mastered for 4,000 nits or more — "The Meg" and "Alpha" are two that us reviewers have been using for a few years to check high-brightness performance. For those kinds of movies, the U8QG's brightness is a boon.  In "Alpha," one of the final scenes includes a vista with a blazing sun. On lesser TVs, the sun lacks definition, and its yellow blends into the oranges of the evening sky. But on the Hisense U8QG, you can clearly see the circular shape of the sun as it illuminates the sky with rich yellows and oranges.  In a dark room, however, those bright moments can feel a bit oppressive, and some might prefer to dial down the TV's luminance. Thankfully, the Hisense U8QG affords you the possibility. Although the TV can surpass 5,000 nits, you can also adjust settings to reduce the brightness to a level that's comfortable for you. If you find the luminance too much, I suggest changing the TV's Peak Brightness mode to medium or low.  In addition to the high brightness, the U8QG has excellent black levels when its local dimming mode is set to high. Blooming (halos around bright objects) is well controlled by the dimming zones, which keep dark sections of the screen inky black while coming close to rivaling the performance of an OLED. The U8QG's blooming performance doesn't quite match that of the TCL QM8K, particularly when viewing subtitles or credits on a dark screen, but in other situations, the difference is negligible.  That said, the TV does have a tendency to crush black levels in some scenes. "Blade Runner 2049" frequently utilizes shadow detail to establish its tone. The walls and corners of Sapper Morton's small home are enshrouded in shadow, but they should still have some definition — the wall by the piano and the corner of the kitchen counter, in particular. On the U8QG, the home appears appropriately dark, but there's some detail missing in the shadows.  A dedicated gaming bar is available for quick adjustments, and the TV features a high 165Hz refresh rate for PCs. John Higgins/Business Insider  The U8QG's color performance is vibrant with decent accuracy, and the QLED panel covers nearly all of the P3 color gamut. However, there are some issues with oversaturation, particularly in reds. The explosions in "Mad Max: Fury Road" appear spectacularly bright and vibrant, but the reds are a bit too intense, causing them to look slightly artificial. The yellow and orange tones of the desert scenes are less affected by the oversaturated reds, and skin tones appear natural without the sunburned look that oversaturation can sometimes cause. But as the TV's grayscale gets closer to white, it leans toward a red tint.  The U8QG offers a range of gaming features, including AMD FreeSync Premium Pro VRR with a refresh rate of up to 165Hz for PCs and 120Hz for consoles, low input lag, Dolby Vision gaming support, and good motion handling. I noticed some minor smearing while using VRR, but it was nothing excessive that distracted me. My time gaming on the U8QG was enjoyable.  QLED TVs, such as the U8QG, often struggle with viewing angles, particularly those with VA panels, like my review sample. The U8QG does indeed start to lose color vibrancy and veer toward a slightly washed-out appearance when viewed at an angle of approximately 30 degrees. That's similar to the performance I saw on the TCL QM8K. A family sitting on the couch for a movie night won't notice much of a difference, but if a large group is over watching the game, those on the sides will see the loss in quality.  It's also important to reiterate that my experience with the 65-inch model may not be representative of other sizes, as the U8 series uses different panel types for certain sizes. Sizes with an ADS panel will likely perform better off-angle at the expense of overall contrast.  Google TV OS continues to be a great interface  The Google TV OS is one of our favorites, thanks to its straightforward layout and seamless integration with Google accounts. John Higgins/Business Insider  The U8QG utilizes the Google TV OS, which works great, offering smooth operation and easy integration with an existing Google account. There are, of course, ads within the Google interface, but they're not too obtrusive, and navigation is fast.  The Google Store offers thousands of apps for download, including ones you'd expect, such as HBO Max, Disney Plus, and Prime Video, as well as more niche options that aren't available on all built-in streaming OS platforms. F1 fans will be able to follow the season with F1 TV, and comedy fans can revel in the world of Dropout.  Google Assistant voice control is supported with the included remote or through hands-free commands via the TV's built-in microphones. Later this year, the U8QG is also set to receive an update to enable support for Gemini, Google's AI chatbot. Compared to Google Assistant, Gemini offers more conversational search functions and provides more extensive information across a wider range of topics.  Should you buy the Hisense U8QG?  The Hisense U8QG has a few drawbacks, but it's a great fit for buyers who crave a high-brightness TV. John Higgins/Business Insider  The Hisense U8QG is as good or better than its predecessor, the U8N, in every way. It's brighter, has better HDR color accuracy, excellent contrast — especially for a Mini LED display — and has strong gaming support. Its impressive performance for the price puts it in the mix as one of the top 4K QLED TVs of the year.  But not everything about the U8QG is perfect. There are some issues with oversaturated color that can make things look off, and the grayscale tracks a bit warm. The decision to replace one of the HDMI inputs with a USB-C DisplayPort is only beneficial to a select few, and the input's placement on the edge of the TV's frame detracts from a sleek, clean installation.  The U8QG's main competitor is the TCL QM8K, another fantastic, and (not quite as) bright flagship QLED 4K TV. The QM8K has slightly better color and grayscale accuracy, and thanks to TCL's Halo Control System, it's even better at reducing blooming than the Hisense. The QM8K also has four HDMI inputs, but only two of them are version 2.1. You can learn more in our TCL QM8K QLED 4K TV review.  However, the Hisense is often discounted for less than the QM8K, and it's available in an additional 55-inch size. If prices were all equal, I'd lean toward the TCL, but if you want to save a bit of money, the Hisense U8QG offers a slightly brighter picture while still maintaining a colorful and punchy image.  For more display recommendations, be sure to check out our complete guide to the best TVs.
    DimaSobko/iStock/Getty Images Plus  Follow ZDNET: Add us as a preferred source on Google.  ZDNET's key takeaways  Windows 10 support ends on Oct. 14, 2025.  You have free and paid options for extended updates.  Doing nothing is not a safe option.  Have you decided what to do with your old Windows 10 PCs when they reach their official end-of-support date in two weeks?  The official deadline is October 14, 2025. Microsoft is not going to back down at the last minute and offer an extension. The hardware requirements aren't going to change, either. So, if you have a laptop or desktop PC that doesn't pass the compatibility checks, Microsoft will block you from upgrading through Windows Update, and they will encourage you to buy a new PC instead.  But you have other alternatives, including some new ways to continue getting security updates for an extra year at no cost. Don't procrastinate, though -- if you're responsible for one or more Windows 10 PCs that fail Microsoft's Windows 11 compatibility tests, you need to choose one of these five options soon.  Also: How to get free Windows 10 security updates through Oct. 2026  Even if you and your business aren't affected by this deadline, it's likely that you have friends and family members who own older PCs that are still perfectly functional but can't be upgraded to Windows 11. They've probably been ignoring warning messages for a few months now, but those messages are going to get more insistent as the deadline approaches. You can help them out by sending them a link to this article.  1. Sign up for extended security updates  Microsoft will continue developing security updates for Windows 10, but they won't be free for everyone. Extended Security Updates (ESUs) for Windows 10 will be available on a subscription basis for up to three years.  Also: Consumer Reports calls Microsoft 'hypocritical' for stranding millions of Windows 10 PCs  How much are these paid-for updates going to cost? That depends.  Consumers have the option to receive security updates for one additional year after the end-of-support date, with the deadline pushing out to October 2026. The list price for that subscription is $30 a year, but you can cut the cost to zero by using Microsoft Rewards points earned by using the Bing search engine or the Windows Backup tool. (For details, see How to get Windows 10 extended security updates for free.) That's the obvious choice if you simply want to postpone the decision. Just be aware that the consumer ESU subscription is only good for one year. At the end of that year, you'll have an unsupported PC once again, so make sure you use that time to figure out your exit strategy for October 2026.  Also: I replaced my Microsoft account password with a passkey - and you should, too  If you're an administrator at an educational institution with a deployment of Windows 10 Education edition, you're in luck. You can purchase extended updates for up to three years, and the cost will bea mere pittance: $1 per machine for the first year, $2 for the second year, and $4 for the third and final year, taking you all the way to October 2028.  IT pros who manage a fleet of business PCs aren't so lucky and will need to pay dearly to stick with Windows 10. A license for the Extended Security Updates program is sold as a per-device subscription. For the first year, the cost is $61 per PC. For year two, the price doubles, and it doubles again for year three. Do the math, and the cost is staggering: a three-year ESU subscription will cost $61 + $122 + $244, for a total of $427.  2. Buy a new PC (or rent a virtual PC)  Microsoft and its partners would like you to replace that unsupported hardware with a new PC. You might even be tempted by one of the shiny new Copilot+ PCs, with their dedicated neural processing units, or maybe a powerful gaming PC. But throwing away a perfectly good computer seems wasteful, and it's not an option if you're hanging on to Windows 10 because you have mission-critical software or an expensive hardware device that's incompatible with Windows 11.  Also: I never pay full price for PCs or Macs, thanks to these 7 money-saving tricks  You also have the option to rent a new virtual PC by signing up for Windows 365, which allows you to connect remotely to your own Windows 11-powered virtual PC in Microsoft's cloud. A Windows 365 subscription works on Windows 10 and includes extended security updates for the host PC for up to three years. Windows 365 isn't cheap (plans start at $28 a month), but that option probably costs less than a new PC.  For businesses, replacing a PC that is more than six years old is absolutely the correct option. Ask your CPA about depreciation deductions.  3. Upgrade your 'incompatible' hardware to Windows 11  That pesky compatibility checker might insist that you can't upgrade your Windows 10 PC to Windows 11, but there are indeed documented ways to bypass those restrictions. You just have to jump through a few technical hoops. Frankly, if you have a PC that is less than 10 years old, this is the easiest, cheapest, and most reliable option.  Also: The 10 apps I can't live or work without - on Windows, Mac, and mobile  You can find all the details in this article: How to upgrade your 'incompatible' Windows 10 PC to Windows 11. Here's the short version:  For PCs originally designed for Windows 10 (basically anything designed in 2016 or later), you need to make one small registry edit and then ensure that your PC is configured to use Secure Boot with the Trusted Platform Module (TPM) enabled. Even an old TPM 1.2 chip will do. As many readers have confirmed via email, this process works seamlessly as long as you've got those configuration details set properly. This option will work even with PCs that are 10 years old.  For older PCs originally designed for Windows 7 or Windows 8.1, you might need to use a third-party tool called Rufus to bypass installation challenges. That's especially true on PCs that use a legacy BIOS instead of UEFI firmware and for those that don't have access to a TPM. Make sure you have the most recent version of Rufus (version 4.9 or later) to keep up with Microsoft's latest compatibility checks.  Those upgrade options can't save a device whose CPU lacks support for two specific instruction sets -- POPCNT and SSE 4.2. Most PCs built using Intel CPUs from 2009 or later will pass this test; AMD CPUs from 2015 or later should also be OK. As I note in this article, there is no workaround if you own one of those very old PCs that fail this test.  Also: How to upgrade from Windows 11 Home to Pro - without overpaying  If you do use one of these upgrade hacks, don't be alarmed by the threatening message you might see when trying to do an unsupported upgrade: "If you proceed with installing Windows 11, your PC will no longer be supported and won't be entitled to receive updates. Damages to your PC due to lack of compatibility aren't covered under the manufacturer warranty."  That's deliberately misleading language from Microsoft. As I've noted before, that warning doesn't really say that Microsoft is going to cut off your access to updates; it simply says your PC is no longer supported, and you're no longer "entitled" to those updates. That bit of legalese is a tell on Microsoft's part, disclaiming corporate responsibility without actually saying what it will do.  If you don't want to mess with the registry and you're willing to do a clean install on a system that has a TPM but fails the CPU check, just use Rufus to create a bootable Windows 11 installation drive, which bypasses the compatibility checker completely. You'll need to restore your data files from a backup or from the cloud, and you'll also need to install your software from scratch, but that's no more difficult than setting up a new PC.  4. Ditch Windows completely  You could keep your old hardware and replace Windows 10 with the flavor of Linux you prefer. If you've got the technical know-how and experience to manage the transition, that option is worth considering. Thanks to Google Workspace, Microsoft 365, and a million or so web-based services, you can do just about all your basic work in a web browser these days. You might not even notice what operating system is running that browser.  Also: Yes, you can run Windows apps on Linux - here are my top 5 ways  Switching to Google's free ChromeOS Flex might also be possible, although the compatibility requirements for that alternative are just as likely to get in your way. I wrote about my experience here: Installing ChromeOS Flex? 5 things you need to do first to avoid headaches. As I pointed out, "If you've got an old PC or Mac and you're thinking of installing ChromeOS Flex on it, don't do anything until you check Google's official ChromeOS Flex certified models list."  Pay special attention to the end-of-support date for the PC you're thinking of upgrading. It doesn't make much sense to replace Windows 10 with a release of ChromeOS Flex that's also set to end support in the next year.  Also: 7 most Windows-like Linux distros - if you're ready to ditch Microsoft  Switching to Linux or some derivative of Linux might be a good way to repurpose an old PC. For consumers and businesses with existing investments in Windows software, it might not be a realistic alternative, but it's worth considering.  5. Ignore the end-of-support deadline completely  You could do nothing at all -- just continue running your unsupported operating system and hope for the best. That's a bad idea that exposes you to the very real possibility that you'll fall prey to a security exploit. Unfortunately, a lot of people are going to do just that. Some percentage of them will end up regretting their decision.  I've heard from some folks who believe that being extra careful and using third-party antivirus software will protect them from harm. I wouldn't bet my business on that strategy.  Also: Stop paying for antivirus software. Here's why you don't need it  If you're intent on doing so, consider installing the third-party 0patch agent to deal with any security issues that aren't addressed by Microsoft. The free 0patch personal plan includes patches for known 0-day vulnerabilities, but if you want all Windows 10 patches, or if the PC is used for business or enterprise tasks, you'll need to pay for a 0patch Pro plan at a per-PC rate of €24.95 per year -- for customers in the US, at current exchange rates, that equates to less than $2.50 a month.  I wouldn't recommend that for a PC that you use for business, but if you have a device you use for casual tasks at home, you might be willing to take the risk.  What does 'end of support' mean?  For nearly a quarter-century, Microsoft has had a formal policy of supporting each major operating system release for 10 years. Windows 10 was released in 2015, so its 10 years are up, as expected, in 2025.  The end date is right there on the Microsoft Support document that lists products retiring or reaching the end of support in 2025. Every retail edition of Windows, as well as the Enterprise and Education editions, is slated for retirement.  If you have a Windows 10 PC, it faces mandatory retirement in 2025 Screenshot by Ed Bott/ZDNET  That schedule is defined by Microsoft's Modern Lifecycle Policy, which is documented on the Microsoft Lifecycle page: "Windows 10 will reach end of support on Oct. 14, 2025. The current version, 22H2, will be the final version of Windows 10, and all editions will remain in support with monthly security update releases through that date." In a separate support article, Microsoft reiterates that as of Oct. 14, 2025, it will no longer provide technical support or security and reliability fixes for PCs running Windows 10.  Also: How to upgrade your 'incompatible' Windows 10 PC to Windows 11 - for free  When a Windows version reaches its end-of-support date, the software keeps working, but Windows Update stops delivering security and reliability fixes:  [There] will be no new security updates, non-security updates, or assisted support. Customers are encouraged to migrate to the latest version of the product or service. Paid programs may be available for applicable products.  That part in the middle sounds encouraging, doesn't it? "Customers are encouraged to migrate to the latest version of the product or service." Unfortunately, that's not a supported option for customers running Windows 10 on hardware that doesn't meet the stringent hardware compatibility requirements of Windows 11. If you try to upgrade one of those PCs to Windows 11, you'll encounter an error message.  And then you'll have to choose one of the five options above.
    At the heart of Nvidia’s success is its co-founder and CEO, Jensen Huang. Born in Taiwan and raised in the United States, Huang washed dishes and cleaned bathrooms at Denny’s as a teenager, eventually earning a master’s degree in electrical engineering from Stanford.  Under his guidance, Nvidia has transformed from a graphics company into a global leader in parallel computing and AI. When most saw the GPU as a tool with limited applications, Huang continued to invest huge amounts into R&D while many analysts and investors queried whether or not there would ever be an acceptable return on investment.  Nvidia’s leadership was propelled even further through the release of CUDA (Compute Unified Device Architecture) – a programming platform that helps users write software algorithms on top of Nvidia’s GPUs. Launched in 2006, CUDA opened the GPU’s raw computing power to researchers and developers beyond the world of graphics. Suddenly, scientists in fields ranging from genomics to astrophysics could run complex simulations hundreds of times faster than before. But the true inflection point came when AI researchers discovered that Nvidia GPUs could dramatically improve the process of training deep neural networks, enabling breakthroughs in computer vision, natural language processing, and autonomous systems.  Today, Nvidia is the undisputed king of AI hardware. Its GPUs power everything from data centres and high-performance computers to self-driving cars and personal devices. The company’s hardware is the engine behind OpenAI’s Chat GPT models, Google’s vast AI infrastructure, and the world’s most advanced robotics. In addition, Nvidia’s software has become the dominant platform for AI development.  Because of the market’s insatiable demand for its GPUs the company has seen its market capitalisation soar, recently surpassing the US$4 trillion-dollar mark and becoming the most valuable company in the world. This rise in value has been staggering as it only surpassed the US$1 trillion mark in May of 2023, equating to a 4x increase in value in a little over two years.  In the process Nvidia has made thousands of its employees millionaires – a recent survey found that a third of Nvidia’s staff have a net wealth in excess of US$20 million. This is easy to understand when you consider that only 10 years ago Nvidia’s shares were trading at less than US$0.60 per share versus the current price of US$175.  But Nvidia’s rise is not unchallenged. Competition is fierce, with rivals like AMD and Broadcom racing to catch up. And as AI becomes more powerful, there are ethical dilemmas about privacy, job displacement, and the potential misuse of autonomous systems.  In an age when AI is everywhere, Nvidia is the company quietly making it all possible. From its humble origins as a graphics chip startup, it’s become the backbone of the world’s AI revolution.  Generate is a New Zealand-owned KiwiSaver and Managed Fund provider managing over $8 billion on behalf of more than 175,000 New Zealanders.  This article is intended for general information only and should not be considered financial advice. The views expressed are those of the author. All investments carry risk, and past performance is not indicative of future results.  To see Generate’s Financial Advice Provider Disclosure Statement or Product Disclosure Statement, go to www.generatewealth.co.nz/advertising-disclosures/. The issuer is Generate Investment Management Limited. Past performance is not indicative of future performance.  Sign up to Herald Premium Editor’s Picks, delivered straight to your inbox every Friday. Editor-in-Chief Murray Kirkness picks the week’s best features, interviews and investigations. Sign up for Herald Premium here.
    China's Zhaoxin breaks into healthcare: 6,000+ hospital PCs run x86 chips against Intel, AMD  Shanghai Zhaoxin Semiconductor has scored a breakthrough in China's healthcare sector. On September 23, the x86 chipmaker announced that over 6,000 of its processor-powered desktops won a major hospital procurement bid, an important step for Chinese x86 CPUs in mission-critical medical deployments.  China's healthcare system is in the midst of rapid digital transformation, with ambitious goals to modernize core hospital information systems by 2025. The transition requires computing platforms that are both powerful and easy to deploy, critical traits in an industry long burdened by fragmented IT ecosystems.  China's healthcare IT fragmentation  Fragmentation remains one of healthcare IT's biggest challenges. Core systems such as hospital information systems (HIS), laboratory information systems (LIS), and picture archiving and communication systems (PACS) still depend on foreign databases like Oracle and SQL Server, which command over 80% market share. Domestic databases account for less than 15%, and migrating decades of records is complicated by format incompatibility and strict real-time demands.  At one leading provincial hospital, 40% of legacy HIS systems still run on outdated VB6 architecture, with upgrades costing up to CNY800,000 (approx. US$112,500) per system. Provinces are now piloting phased adaptation, rushing "emergency fixes" for critical platforms like PACS, while allowing a three-year transition for non-core systems such as office software. The dual-track approach underscores the clash between policy mandates and technical realities.  Smaller hospitals face even sharper challenges: nearly 30% of their systems are too old to run domestic operating systems or new applications, leaving them stuck between costly legacy reuse and risky data migration.  Zhaoxin's processor ecosystem strategy  Zhaoxin is tackling these pain points with processors that combine compatibility and performance. The firm has independently developed six generations of high-performance CPUs, including the KaiXian desktop and KaiSheng server lines, with products spanning AI PCs, desktops, notebooks, all-in-ones, servers, and embedded platforms.  The chips support both domestic operating systems: UnionTech Software UOS, NeoKylin, Zhongkefangde Software, and Microsoft Windows. They are compatible with mainstream applications, cloud platforms, databases, development tools, and AI models, while keeping software migration costs low.  For healthcare, Zhaoxin has introduced "seamless migration" and "one-stop support" solutions. It has also set up medical application innovation centers with partners, offering hospitals end-to-end guidance from chips to operating systems and applications.  Today, Zhaoxin works with nearly 4,000 partners across systems integration, software, and hardware. Together with domestic OS vendors, it has completed more than 200,000 software-hardware adaptation projects, building a full-stack ecosystem from processors to databases and applications.  From 2022 to 2024, Zhaoxin recorded revenues of CNY340 million, CNY555 million, and CNY889 million, respectively, with a compound annual growth rate of 61.71%.  Rivaling Intel and AMD in hospitals  Beating out Intel and AMD in a high-profile bid highlights Zhaoxin's progress in performance, compatibility, and cost efficiency. Its processors are built to handle demanding healthcare workloads — from electronic medical records to telemedicine platforms — while maintaining stable operations.  With integrated security, Zhaoxin CPUs protect patient data across its lifecycle: collection, transmission, storage, and use. This meets China's strict compliance standards, as hospitals lean on secure, high-performance platforms for data-heavy applications.  As digitalization accelerates, medical data will expand from text records and lab reports to imaging archives and real-time vital signs. Zhaoxin's processors can manage these workloads, minimizing downtime and enabling use cases such as AI diagnostics and cross-regional data sharing.  China's x86 chips gain traction  The hospital bid underscores the rising role of Chinese x86 chips in public welfare sectors. By offering strong performance and ecosystem compatibility, Zhaoxin is gaining ground in healthcare digitalization, an arena once dominated by foreign technology.  If sustained, these gains could speed the localization of hospital IT infrastructure, supporting China's drive for tech independence while laying the groundwork for smarter, more secure healthcare systems.  Article edited by Jack Wu
    A rift appears to be forming in the desktop PC market, with full-size desktops on one side and mini PCs on the other side. Of course, there is small, but dedicated community that has sprung up around SFF PCs, but those are often limited, with many calling for flex PSUs and other compromises. The Wee Beastie, a new project on Kickstarter , is a small form-factor PC that hopes to cut back on the compromises, claiming to offer a powerful gaming and LLM-oriented system with an upgradeable dGPU in just 4.75 L volume—this is just 0.25 L more than the Framework Desktop PC , which uses an AMD Ryzen AI+ 395 Max with an iGPU. That said, even the pre-release Kickstarter marketing leaves some questions.The Wee Beastie Super Mini Fishtank, as it is called, is a mini PC with up to an Intel Core Ultra 7 255H CPU and NVIDIA GeForce RTX 4070 12 GB GPU. It will also be available with up to 128 GB of DDR5 RAM and a 16 TB SSD, and it boasts Wi-Fi 7 and room for up to 13 case fans. It will also contain an internal PSU capable of 400 W, which technically falls well below the 550 W we recommend for a desktop RTX 4070. Although the GPU shown on the Kickstarter page has the " AD104-251-A1" associated with the desktop variants of the RTX 4070 , the PSU output suggests that there will be some power throttling or down-tuning at play, so RTX 4070 Mobile performance might be what's to be expected here. Often, the most challenging part of projects like these, as was the case with the custom expansion modules on the Framework Laptop 16 until recently, is supporting the MXM standard for future hardware revisions. Although MXM modules are technically an open standard, like ATX, it is not commonly used due to limited demand and size constraints. Currently, the Kickstarter has completed funding, having reached $53,763 of its $2,570 goal, and the SFF PC looks to be going into production as soon as 2026.
    index 6607dbb1be441f..bf1e6ca6aeb82f 100644  --- a/  +++ b/ diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txtindex 6607dbb1be441f..bf1e6ca6aeb82f 100644--- a/ Documentation/admin-guide/kernel-parameters.txt +++ b/ Documentation/admin-guide/kernel-parameters.txt @@ -6163,7 +6163,7 @@ rdt= [HW,X86,RDT] Turn on/off individual RDT features. List is: cmt, mbmtotal, mbmlocal, l3cat, l3cdp, l2cat, l2cdp, - mba, smba, bmec. + mba, smba, bmec, abmc. E.g. to turn on cmt and turn off mba use: rdt=cmt,!mba  index c7949dd44f2f3a..006d23af66e19f 100644  --- a/  +++ b/ diff --git a/Documentation/filesystems/resctrl.rst b/Documentation/filesystems/resctrl.rstindex c7949dd44f2f3a..006d23af66e19f 100644--- a/ Documentation/filesystems/resctrl.rst +++ b/ Documentation/filesystems/resctrl.rst @@ -26,6 +26,7 @@ MBM (Memory Bandwidth Monitoring) "cqm_mbm_total", "cqm_mbm_local" MBA (Memory Bandwidth Allocation) "mba" SMBA (Slow Memory Bandwidth Allocation) "" BMEC (Bandwidth Monitoring Event Configuration) "" +ABMC (Assignable Bandwidth Monitoring Counters) "" =============================================== ================================ Historically, new features were made visible by default in /proc/cpuinfo. This @@ -256,6 +257,144 @@ with the following files: # cat /sys/fs/resctrl/info/L3_MON/mbm_local_bytes_config 0=0x30;1=0x30;3=0x15;4=0x15 +"mbm_assign_mode": + The supported counter assignment modes. The enclosed brackets indicate which mode + is enabled. The MBM events associated with counters may reset when "mbm_assign_mode" + is changed. + :: + + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + [mbm_event] + default + + "mbm_event": + + mbm_event mode allows users to assign a hardware counter to an RMID, event + pair and monitor the bandwidth usage as long as it is assigned. The hardware + continues to track the assigned counter until it is explicitly unassigned by + the user. Each event within a resctrl group can be assigned independently. + + In this mode, a monitoring event can only accumulate data while it is backed + by a hardware counter. Use "mbm_L3_assignments" found in each CTRL_MON and MON + group to specify which of the events should have a counter assigned. The number + of counters available is described in the "num_mbm_cntrs" file. Changing the + mode may cause all counters on the resource to reset. + + Moving to mbm_event counter assignment mode requires users to assign the counters + to the events. Otherwise, the MBM event counters will return 'Unassigned' when read. + + The mode is beneficial for AMD platforms that support more CTRL_MON + and MON groups than available hardware counters. By default, this + feature is enabled on AMD platforms with the ABMC (Assignable Bandwidth + Monitoring Counters) capability, ensuring counters remain assigned even + when the corresponding RMID is not actively used by any processor. + + "default": + + In default mode, resctrl assumes there is a hardware counter for each + event within every CTRL_MON and MON group. On AMD platforms, it is + recommended to use the mbm_event mode, if supported, to prevent reset of MBM + events between reads resulting from hardware re-allocating counters. This can + result in misleading values or display "Unavailable" if no counter is assigned + to the event. + + * To enable "mbm_event" counter assignment mode: + :: + + # echo "mbm_event" > /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + + * To enable "default" monitoring mode: + :: + + # echo "default" > /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + +"num_mbm_cntrs": + The maximum number of counters (total of available and assigned counters) in + each domain when the system supports mbm_event mode. + + For example, on a system with maximum of 32 memory bandwidth monitoring + counters in each of its L3 domains: + :: + + # cat /sys/fs/resctrl/info/L3_MON/num_mbm_cntrs + 0=32;1=32 + +"available_mbm_cntrs": + The number of counters available for assignment in each domain when mbm_event + mode is enabled on the system. + + For example, on a system with 30 available [hardware] assignable counters + in each of its L3 domains: + :: + + # cat /sys/fs/resctrl/info/L3_MON/available_mbm_cntrs + 0=30;1=30 + +"event_configs": + Directory that exists when "mbm_event" counter assignment mode is supported. + Contains a sub-directory for each MBM event that can be assigned to a counter. + + Two MBM events are supported by default: mbm_local_bytes and mbm_total_bytes. + Each MBM event's sub-directory contains a file named "event_filter" that is + used to view and modify which memory transactions the MBM event is configured + with. The file is accessible only when "mbm_event" counter assignment mode is + enabled. + + List of memory transaction types supported: + + ========================== ======================================================== + Name Description + ========================== ======================================================== + dirty_victim_writes_all Dirty Victims from the QOS domain to all types of memory + remote_reads_slow_memory Reads to slow memory in the non-local NUMA domain + local_reads_slow_memory Reads to slow memory in the local NUMA domain + remote_non_temporal_writes Non-temporal writes to non-local NUMA domain + local_non_temporal_writes Non-temporal writes to local NUMA domain + remote_reads Reads to memory in the non-local NUMA domain + local_reads Reads to memory in the local NUMA domain + ========================== ======================================================== + + For example:: + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + local_reads,remote_reads,local_non_temporal_writes,remote_non_temporal_writes, + local_reads_slow_memory,remote_reads_slow_memory,dirty_victim_writes_all + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + local_reads,local_non_temporal_writes,local_reads_slow_memory + + Modify the event configuration by writing to the "event_filter" file within + the "event_configs" directory. The read/write "event_filter" file contains the + configuration of the event that reflects which memory transactions are counted by it. + + For example:: + + # echo "local_reads, local_non_temporal_writes" > + /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + local_reads,local_non_temporal_writes + +"mbm_assign_on_mkdir": + Exists when "mbm_event" counter assignment mode is supported. Accessible + only when "mbm_event" counter assignment mode is enabled. + + Determines if a counter will automatically be assigned to an RMID, MBM event + pair when its associated monitor group is created via mkdir. Enabled by default + on boot, also when switched from "default" mode to "mbm_event" counter assignment + mode. Users can disable this capability by writing to the interface. + + "0": + Auto assignment is disabled. + "1": + Auto assignment is enabled. + + Example:: + + # echo 0 > /sys/fs/resctrl/info/L3_MON/mbm_assign_on_mkdir + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_on_mkdir + 0 + "max_threshold_occupancy": Read/write file provides the largest value (in bytes) at which a previously used LLC_occupancy @@ -380,10 +519,77 @@ When monitoring is enabled all MON groups will also contain: for the L3 cache they occupy). These are named "mon_sub_L3_YY" where "YY" is the node number. + When the 'mbm_event' counter assignment mode is enabled, reading + an MBM event of a MON group returns 'Unassigned' if no hardware + counter is assigned to it. For CTRL_MON groups, 'Unassigned' is + returned if the MBM event does not have an assigned counter in the + CTRL_MON group nor in any of its associated MON groups. + "mon_hw_id": Available only with debug option. The identifier used by hardware for the monitor group. On x86 this is the RMID. +When monitoring is enabled all MON groups may also contain: + +"mbm_L3_assignments": + Exists when "mbm_event" counter assignment mode is supported and lists the + counter assignment states of the group. + + The assignment list is displayed in the following format: + + <Event>:<Domain ID>=<Assignment state>;<Domain ID>=<Assignment state> + + Event: A valid MBM event in the + /sys/fs/resctrl/info/L3_MON/event_configs directory. + + Domain ID: A valid domain ID. When writing, '*' applies the changes + to all the domains. + + Assignment states: + + _ : No counter assigned. + + e : Counter assigned exclusively. + + Example: + + To display the counter assignment states for the default group. + :: + + # cd /sys/fs/resctrl + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + + Assignments can be modified by writing to the interface. + + Examples: + + To unassign the counter associated with the mbm_total_bytes event on domain 0: + :: + + # echo "mbm_total_bytes:0=_" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=_;1=e + mbm_local_bytes:0=e;1=e + + To unassign the counter associated with the mbm_total_bytes event on all the domains: + :: + + # echo "mbm_total_bytes:*=_" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=_;1=_ + mbm_local_bytes:0=e;1=e + + To assign a counter associated with the mbm_total_bytes event on all domains in + exclusive mode: + :: + + # echo "mbm_total_bytes:*=e" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + When the "mba_MBps" mount option is used all CTRL_MON groups will also contain: "mba_MBps_event": @@ -1429,6 +1635,125 @@ View the llc occupancy snapshot:: # cat /sys/fs/resctrl/p1/mon_data/mon_L3_00/llc_occupancy 11234000 + +Examples on working with mbm_assign_mode +======================================== + +a. Check if MBM counter assignment mode is supported. +:: + + # mount -t resctrl resctrl /sys/fs/resctrl/ + + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + [mbm_event] + default + +The "mbm_event" mode is detected and enabled. + +b. Check how many assignable counters are supported. +:: + + # cat /sys/fs/resctrl/info/L3_MON/num_mbm_cntrs + 0=32;1=32 + +c. Check how many assignable counters are available for assignment in each domain. +:: + + # cat /sys/fs/resctrl/info/L3_MON/available_mbm_cntrs + 0=30;1=30 + +d. To list the default group's assign states. +:: + + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + +e. To unassign the counter associated with the mbm_total_bytes event on domain 0. +:: + + # echo "mbm_total_bytes:0=_" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=_;1=e + mbm_local_bytes:0=e;1=e + +f. To unassign the counter associated with the mbm_total_bytes event on all domains. +:: + + # echo "mbm_total_bytes:*=_" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignment + mbm_total_bytes:0=_;1=_ + mbm_local_bytes:0=e;1=e + +g. To assign a counter associated with the mbm_total_bytes event on all domains in +exclusive mode. +:: + + # echo "mbm_total_bytes:*=e" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + +h. Read the events mbm_total_bytes and mbm_local_bytes of the default group. There is +no change in reading the events with the assignment. +:: + + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_total_bytes + 779247936 + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_total_bytes + 562324232 + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_local_bytes + 212122123 + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_local_bytes + 121212144 + +i. Check the event configurations. +:: + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + local_reads,remote_reads,local_non_temporal_writes,remote_non_temporal_writes, + local_reads_slow_memory,remote_reads_slow_memory,dirty_victim_writes_all + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + local_reads,local_non_temporal_writes,local_reads_slow_memory + +j. Change the event configuration for mbm_local_bytes. +:: + + # echo "local_reads, local_non_temporal_writes, local_reads_slow_memory, remote_reads" > + /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + local_reads,local_non_temporal_writes,local_reads_slow_memory,remote_reads + +k. Now read the local events again. The first read may come back with "Unavailable" +status. The subsequent read of mbm_local_bytes will display the current value. +:: + + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_local_bytes + Unavailable + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_local_bytes + 2252323 + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_local_bytes + Unavailable + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_local_bytes + 1566565 + +l. Users have the option to go back to 'default' mbm_assign_mode if required. This can be +done using the following command. Note that switching the mbm_assign_mode may reset all +the MBM counters (and thus all MBM events) of all the resctrl groups. +:: + + # echo "default" > /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + mbm_event + [default] + +m. Unmount the resctrl filesystem. +:: + + # umount /sys/fs/resctrl/ + Intel RDT Errata ================  index a80cca9aa6ff2b..62d16c20a888eb 100644  --- a/  +++ b/ diff --git a/MAINTAINERS b/MAINTAINERSindex a80cca9aa6ff2b..62d16c20a888eb 100644--- a/ MAINTAINERS +++ b/ MAINTAINERS @@ -21186,6 +21186,7 @@ M: Tony Luck <tony.luck@intel.com> M: Reinette Chatre <reinette.chatre@intel.com> R: Dave Martin <Dave.Martin@arm.com> R: James Morse <james.morse@arm.com> +R: Babu Moger <babu.moger@amd.com> L: linux-kernel@vger.kernel.org S: Supported F: Documentation/filesystems/resctrl.rst  index 751ca35386b0ef..b2a562217d3ffc 100644  --- a/  +++ b/ diff --git a/arch/x86/include/asm/cpufeatures.h b/arch/x86/include/asm/cpufeatures.hindex 751ca35386b0ef..b2a562217d3ffc 100644--- a/ arch/x86/include/asm/cpufeatures.h +++ b/ arch/x86/include/asm/cpufeatures.h @@ -496,6 +496,7 @@ #define X86_FEATURE_TSA_L1_NO (21*32+12) /* AMD CPU not vulnerable to TSA-L1 */ #define X86_FEATURE_CLEAR_CPU_BUF_VM (21*32+13) /* Clear CPU buffers using VERW before VMRUN */ #define X86_FEATURE_IBPB_EXIT_TO_USER (21*32+14) /* Use IBPB on exit-to-userspace, see VMSCAPE bug */ +#define X86_FEATURE_ABMC (21*32+15) /* Assignable Bandwidth Monitoring Counters */ /* * BUG word(s)  index b60d3711a7089e..73393a66d3ab05 100644  --- a/  +++ b/ diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.hindex b60d3711a7089e..73393a66d3ab05 100644--- a/ arch/x86/include/asm/msr-index.h +++ b/ arch/x86/include/asm/msr-index.h @@ -1230,6 +1230,8 @@ /* - AMD: */ #define MSR_IA32_MBA_BW_BASE 0xc0000200 #define MSR_IA32_SMBA_BW_BASE 0xc0000280 +#define MSR_IA32_L3_QOS_ABMC_CFG 0xc00003fd +#define MSR_IA32_L3_QOS_EXT_CFG 0xc00003ff #define MSR_IA32_EVT_CFG_BASE 0xc0000400 /* AMD-V MSRs */  index feb93b50e990ac..575f8408a9e7c6 100644  --- a/  +++ b/ diff --git a/arch/x86/include/asm/resctrl.h b/arch/x86/include/asm/resctrl.hindex feb93b50e990ac..575f8408a9e7c6 100644--- a/ arch/x86/include/asm/resctrl.h +++ b/ arch/x86/include/asm/resctrl.h @@ -44,7 +44,6 @@ DECLARE_PER_CPU(struct resctrl_pqr_state, pqr_state); extern bool rdt_alloc_capable; extern bool rdt_mon_capable; -extern unsigned int rdt_mon_features; DECLARE_STATIC_KEY_FALSE(rdt_enable_key); DECLARE_STATIC_KEY_FALSE(rdt_alloc_enable_key); @@ -84,21 +83,6 @@ static inline void resctrl_arch_disable_mon(void) static_branch_dec_cpuslocked(&rdt_enable_key); } -static inline bool resctrl_arch_is_llc_occupancy_enabled(void) -{ - return (rdt_mon_features & (1 << QOS_L3_OCCUP_EVENT_ID)); -} - -static inline bool resctrl_arch_is_mbm_total_enabled(void) -{ - return (rdt_mon_features & (1 << QOS_L3_MBM_TOTAL_EVENT_ID)); -} - -static inline bool resctrl_arch_is_mbm_local_enabled(void) -{ - return (rdt_mon_features & (1 << QOS_L3_MBM_LOCAL_EVENT_ID)); -} - /* * __resctrl_sched_in() - Writes the task's CLOSid/RMID to IA32_PQR_MSR *  index 187d527ef73b6e..06ca5a30140c2f 100644  --- a/  +++ b/ diff --git a/arch/x86/kernel/cpu/resctrl/core.c b/arch/x86/kernel/cpu/resctrl/core.cindex 187d527ef73b6e..06ca5a30140c2f 100644--- a/ arch/x86/kernel/cpu/resctrl/core.c +++ b/ arch/x86/kernel/cpu/resctrl/core.c @@ -107,7 +107,7 @@ u32 resctrl_arch_system_num_rmid_idx(void) struct rdt_resource *r = &rdt_resources_all[RDT_RESOURCE_L3].r_resctrl; /* RMID are independent numbers for x86. num_rmid_idx == num_rmid */ - return r->num_rmid; + return r->mon.num_rmid; } struct rdt_resource *resctrl_arch_get_resource(enum resctrl_res_level l) @@ -365,8 +365,10 @@ static void ctrl_domain_free(struct rdt_hw_ctrl_domain *hw_dom) static void mon_domain_free(struct rdt_hw_mon_domain *hw_dom) { - kfree(hw_dom->arch_mbm_total); - kfree(hw_dom->arch_mbm_local); + int idx; + + for_each_mbm_idx(idx) + kfree(hw_dom->arch_mbm_states[idx]); kfree(hw_dom); } @@ -400,25 +402,27 @@ static int domain_setup_ctrlval(struct rdt_resource *r, struct rdt_ctrl_domain * */ static int arch_domain_mbm_alloc(u32 num_rmid, struct rdt_hw_mon_domain *hw_dom) { - size_t tsize; - - if (resctrl_arch_is_mbm_total_enabled()) { - tsize = sizeof(*hw_dom->arch_mbm_total); - hw_dom->arch_mbm_total = kcalloc(num_rmid, tsize, GFP_KERNEL); - if (!hw_dom->arch_mbm_total) - return -ENOMEM; - } - if (resctrl_arch_is_mbm_local_enabled()) { - tsize = sizeof(*hw_dom->arch_mbm_local); - hw_dom->arch_mbm_local = kcalloc(num_rmid, tsize, GFP_KERNEL); - if (!hw_dom->arch_mbm_local) { - kfree(hw_dom->arch_mbm_total); - hw_dom->arch_mbm_total = NULL; - return -ENOMEM; - } + size_t tsize = sizeof(*hw_dom->arch_mbm_states[0]); + enum resctrl_event_id eventid; + int idx; + + for_each_mbm_event_id(eventid) { + if (!resctrl_is_mon_event_enabled(eventid)) + continue; + idx = MBM_STATE_IDX(eventid); + hw_dom->arch_mbm_states[idx] = kcalloc(num_rmid, tsize, GFP_KERNEL); + if (!hw_dom->arch_mbm_states[idx]) + goto cleanup; } return 0; +cleanup: + for_each_mbm_idx(idx) { + kfree(hw_dom->arch_mbm_states[idx]); + hw_dom->arch_mbm_states[idx] = NULL; + } + + return -ENOMEM; } static int get_domain_id_from_scope(int cpu, enum resctrl_scope scope) @@ -516,6 +520,9 @@ static void domain_add_cpu_mon(int cpu, struct rdt_resource *r) d = container_of(hdr, struct rdt_mon_domain, hdr); cpumask_set_cpu(cpu, &d->hdr.cpu_mask); + /* Update the mbm_assign_mode state for the CPU if supported */ + if (r->mon.mbm_cntr_assignable) + resctrl_arch_mbm_cntr_assign_set_one(r); return; } @@ -535,9 +542,13 @@ static void domain_add_cpu_mon(int cpu, struct rdt_resource *r) d->ci_id = ci->id; cpumask_set_cpu(cpu, &d->hdr.cpu_mask); + /* Update the mbm_assign_mode state for the CPU if supported */ + if (r->mon.mbm_cntr_assignable) + resctrl_arch_mbm_cntr_assign_set_one(r); + arch_mon_domain_online(r, d); - if (arch_domain_mbm_alloc(r->num_rmid, hw_dom)) { + if (arch_domain_mbm_alloc(r->mon.num_rmid, hw_dom)) { mon_domain_free(hw_dom); return; } @@ -707,6 +718,7 @@ enum { RDT_FLAG_MBA, RDT_FLAG_SMBA, RDT_FLAG_BMEC, + RDT_FLAG_ABMC, }; #define RDT_OPT(idx, n, f) \ @@ -732,6 +744,7 @@ static struct rdt_options rdt_options[] __ro_after_init = { RDT_OPT(RDT_FLAG_MBA, "mba", X86_FEATURE_MBA), RDT_OPT(RDT_FLAG_SMBA, "smba", X86_FEATURE_SMBA), RDT_OPT(RDT_FLAG_BMEC, "bmec", X86_FEATURE_BMEC), + RDT_OPT(RDT_FLAG_ABMC, "abmc", X86_FEATURE_ABMC), }; #define NUM_RDT_OPTIONS ARRAY_SIZE(rdt_options) @@ -863,15 +876,24 @@ static __init bool get_rdt_alloc_resources(void) static __init bool get_rdt_mon_resources(void) { struct rdt_resource *r = &rdt_resources_all[RDT_RESOURCE_L3].r_resctrl; + bool ret = false; - if (rdt_cpu_has(X86_FEATURE_CQM_OCCUP_LLC)) - rdt_mon_features |= (1 << QOS_L3_OCCUP_EVENT_ID); - if (rdt_cpu_has(X86_FEATURE_CQM_MBM_TOTAL)) - rdt_mon_features |= (1 << QOS_L3_MBM_TOTAL_EVENT_ID); - if (rdt_cpu_has(X86_FEATURE_CQM_MBM_LOCAL)) - rdt_mon_features |= (1 << QOS_L3_MBM_LOCAL_EVENT_ID); + if (rdt_cpu_has(X86_FEATURE_CQM_OCCUP_LLC)) { + resctrl_enable_mon_event(QOS_L3_OCCUP_EVENT_ID); + ret = true; + } + if (rdt_cpu_has(X86_FEATURE_CQM_MBM_TOTAL)) { + resctrl_enable_mon_event(QOS_L3_MBM_TOTAL_EVENT_ID); + ret = true; + } + if (rdt_cpu_has(X86_FEATURE_CQM_MBM_LOCAL)) { + resctrl_enable_mon_event(QOS_L3_MBM_LOCAL_EVENT_ID); + ret = true; + } + if (rdt_cpu_has(X86_FEATURE_ABMC)) + ret = true; - if (!rdt_mon_features) + if (!ret) return false; return !rdt_get_mon_l3_config(r); @@ -965,7 +987,7 @@ static enum cpuhp_state rdt_online; /* Runs once on the BSP during boot. */ void resctrl_cpu_detect(struct cpuinfo_x86 *c) { - if (!cpu_has(c, X86_FEATURE_CQM_LLC)) { + if (!cpu_has(c, X86_FEATURE_CQM_LLC) && !cpu_has(c, X86_FEATURE_ABMC)) { c->x86_cache_max_rmid = -1; c->x86_cache_occ_scale = -1; c->x86_cache_mbm_width_offset = -1; @@ -977,7 +999,8 @@ void resctrl_cpu_detect(struct cpuinfo_x86 *c) if (cpu_has(c, X86_FEATURE_CQM_OCCUP_LLC) || cpu_has(c, X86_FEATURE_CQM_MBM_TOTAL) || - cpu_has(c, X86_FEATURE_CQM_MBM_LOCAL)) { + cpu_has(c, X86_FEATURE_CQM_MBM_LOCAL) || + cpu_has(c, X86_FEATURE_ABMC)) { u32 eax, ebx, ecx, edx; /* QoS sub-leaf, EAX=0Fh, ECX=1 */  index 5e3c41b3643737..9f4c2f0aaf5c80 100644  --- a/  +++ b/ diff --git a/arch/x86/kernel/cpu/resctrl/internal.h b/arch/x86/kernel/cpu/resctrl/internal.hindex 5e3c41b3643737..9f4c2f0aaf5c80 100644--- a/ arch/x86/kernel/cpu/resctrl/internal.h +++ b/ arch/x86/kernel/cpu/resctrl/internal.h @@ -37,6 +37,15 @@ struct arch_mbm_state { u64 prev_msr; }; +/* Setting bit 0 in L3_QOS_EXT_CFG enables the ABMC feature. */ +#define ABMC_ENABLE_BIT 0 + +/* + * Qos Event Identifiers. + */ +#define ABMC_EXTENDED_EVT_ID BIT(31) +#define ABMC_EVT_ID BIT(0) + /** * struct rdt_hw_ctrl_domain - Arch private attributes of a set of CPUs that share * a resource for a control function @@ -54,15 +63,15 @@ struct rdt_hw_ctrl_domain { * struct rdt_hw_mon_domain - Arch private attributes of a set of CPUs that share * a resource for a monitor function * @d_resctrl: Properties exposed to the resctrl file system - * @arch_mbm_total: arch private state for MBM total bandwidth - * @arch_mbm_local: arch private state for MBM local bandwidth + * @arch_mbm_states: Per-event pointer to the MBM event's saved state. + * An MBM event's state is an array of struct arch_mbm_state + * indexed by RMID on x86. * * Members of this structure are accessed via helpers that provide abstraction. */ struct rdt_hw_mon_domain { struct rdt_mon_domain d_resctrl; - struct arch_mbm_state *arch_mbm_total; - struct arch_mbm_state *arch_mbm_local; + struct arch_mbm_state *arch_mbm_states[QOS_NUM_L3_MBM_EVENTS]; }; static inline struct rdt_hw_ctrl_domain *resctrl_to_arch_ctrl_dom(struct rdt_ctrl_domain *r) @@ -102,6 +111,7 @@ struct msr_param { * @mon_scale: cqm counter * mon_scale = occupancy in bytes * @mbm_width: Monitor width, to detect and correct for overflow. * @cdp_enabled: CDP state of this resource + * @mbm_cntr_assign_enabled: ABMC feature is enabled * * Members of this structure are either private to the architecture * e.g. mbm_width, or accessed via helpers that provide abstraction. e.g. @@ -115,6 +125,7 @@ struct rdt_hw_resource { unsigned int mon_scale; unsigned int mbm_width; bool cdp_enabled; + bool mbm_cntr_assign_enabled; }; static inline struct rdt_hw_resource *resctrl_to_arch_res(struct rdt_resource *r) @@ -159,6 +170,42 @@ union cpuid_0x10_x_edx { unsigned int full; }; +/* + * ABMC counters are configured by writing to MSR_IA32_L3_QOS_ABMC_CFG. + * + * @bw_type : Event configuration that represents the memory + * transactions being tracked by the @cntr_id. + * @bw_src : Bandwidth source (RMID or CLOSID). + * @reserved1 : Reserved. + * @is_clos : @bw_src field is a CLOSID (not an RMID). + * @cntr_id : Counter identifier. + * @reserved : Reserved. + * @cntr_en : Counting enable bit. + * @cfg_en : Configuration enable bit. + * + * Configuration and counting: + * Counter can be configured across multiple writes to MSR. Configuration + * is applied only when @cfg_en = 1. Counter @cntr_id is reset when the + * configuration is applied. + * @cfg_en = 1, @cntr_en = 0 : Apply @cntr_id configuration but do not + * count events. + * @cfg_en = 1, @cntr_en = 1 : Apply @cntr_id configuration and start + * counting events. + */ +union l3_qos_abmc_cfg { + struct { + unsigned long bw_type :32, + bw_src :12, + reserved1: 3, + is_clos : 1, + cntr_id : 5, + reserved : 9, + cntr_en : 1, + cfg_en : 1; + } split; + unsigned long full; +}; + void rdt_ctrl_update(void *arg); int rdt_get_mon_l3_config(struct rdt_resource *r); @@ -168,5 +215,6 @@ bool rdt_cpu_has(int flag); void __init intel_rdt_mbm_apply_quirk(void); void rdt_domain_reconfigure_cdp(struct rdt_resource *r); +void resctrl_arch_mbm_cntr_assign_set_one(struct rdt_resource *r); #endif /* _ASM_X86_RESCTRL_INTERNAL_H */  index c261558276cdd4..c8945610d45550 100644  --- a/  +++ b/ diff --git a/arch/x86/kernel/cpu/resctrl/monitor.c b/arch/x86/kernel/cpu/resctrl/monitor.cindex c261558276cdd4..c8945610d45550 100644--- a/ arch/x86/kernel/cpu/resctrl/monitor.c +++ b/ arch/x86/kernel/cpu/resctrl/monitor.c @@ -31,11 +31,6 @@ */ bool rdt_mon_capable; -/* - * Global to indicate which monitoring events are enabled. - */ -unsigned int rdt_mon_features; - #define CF(cf) ((unsigned long)(1048576 * (cf) + 0.5)) static int snc_nodes_per_l3_cache = 1; @@ -135,7 +130,7 @@ static int logical_rmid_to_physical_rmid(int cpu, int lrmid) if (snc_nodes_per_l3_cache == 1) return lrmid; - return lrmid + (cpu_to_node(cpu) % snc_nodes_per_l3_cache) * r->num_rmid; + return lrmid + (cpu_to_node(cpu) % snc_nodes_per_l3_cache) * r->mon.num_rmid; } static int __rmid_read_phys(u32 prmid, enum resctrl_event_id eventid, u64 *val) @@ -166,18 +161,14 @@ static struct arch_mbm_state *get_arch_mbm_state(struct rdt_hw_mon_domain *hw_do u32 rmid, enum resctrl_event_id eventid) { - switch (eventid) { - case QOS_L3_OCCUP_EVENT_ID: - return NULL; - case QOS_L3_MBM_TOTAL_EVENT_ID: - return &hw_dom->arch_mbm_total[rmid]; - case QOS_L3_MBM_LOCAL_EVENT_ID: - return &hw_dom->arch_mbm_local[rmid]; - default: - /* Never expect to get here */ - WARN_ON_ONCE(1); + struct arch_mbm_state *state; + + if (!resctrl_is_mbm_event(eventid)) return NULL; - } + + state = hw_dom->arch_mbm_states[MBM_STATE_IDX(eventid)]; + + return state ? &state[rmid] : NULL; } void resctrl_arch_reset_rmid(struct rdt_resource *r, struct rdt_mon_domain *d, @@ -206,14 +197,16 @@ void resctrl_arch_reset_rmid(struct rdt_resource *r, struct rdt_mon_domain *d, void resctrl_arch_reset_rmid_all(struct rdt_resource *r, struct rdt_mon_domain *d) { struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); - - if (resctrl_arch_is_mbm_total_enabled()) - memset(hw_dom->arch_mbm_total, 0, - sizeof(*hw_dom->arch_mbm_total) * r->num_rmid); - - if (resctrl_arch_is_mbm_local_enabled()) - memset(hw_dom->arch_mbm_local, 0, - sizeof(*hw_dom->arch_mbm_local) * r->num_rmid); + enum resctrl_event_id eventid; + int idx; + + for_each_mbm_event_id(eventid) { + if (!resctrl_is_mon_event_enabled(eventid)) + continue; + idx = MBM_STATE_IDX(eventid); + memset(hw_dom->arch_mbm_states[idx], 0, + sizeof(*hw_dom->arch_mbm_states[0]) * r->mon.num_rmid); + } } static u64 mbm_overflow_count(u64 prev_msr, u64 cur_msr, unsigned int width) @@ -224,15 +217,33 @@ static u64 mbm_overflow_count(u64 prev_msr, u64 cur_msr, unsigned int width) return chunks >> shift; } +static u64 get_corrected_val(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 rmid, enum resctrl_event_id eventid, u64 msr_val) +{ + struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); + struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); + struct arch_mbm_state *am; + u64 chunks; + + am = get_arch_mbm_state(hw_dom, rmid, eventid); + if (am) { + am->chunks += mbm_overflow_count(am->prev_msr, msr_val, + hw_res->mbm_width); + chunks = get_corrected_mbm_count(rmid, am->chunks); + am->prev_msr = msr_val; + } else { + chunks = msr_val; + } + + return chunks * hw_res->mon_scale; +} + int resctrl_arch_rmid_read(struct rdt_resource *r, struct rdt_mon_domain *d, u32 unused, u32 rmid, enum resctrl_event_id eventid, u64 *val, void *ignored) { - struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); - struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); int cpu = cpumask_any(&d->hdr.cpu_mask); - struct arch_mbm_state *am; - u64 msr_val, chunks; + u64 msr_val; u32 prmid; int ret; @@ -243,17 +254,76 @@ int resctrl_arch_rmid_read(struct rdt_resource *r, struct rdt_mon_domain *d, if (ret) return ret; + *val = get_corrected_val(r, d, rmid, eventid, msr_val); + + return 0; +} + +static int __cntr_id_read(u32 cntr_id, u64 *val) +{ + u64 msr_val; + + /* + * QM_EVTSEL Register definition: + * ======================================================= + * Bits Mnemonic Description + * ======================================================= + * 63:44 -- Reserved + * 43:32 RMID RMID or counter ID in ABMC mode + * when reading an MBM event + * 31 ExtendedEvtID Extended Event Identifier + * 30:8 -- Reserved + * 7:0 EvtID Event Identifier + * ======================================================= + * The contents of a specific counter can be read by setting the + * following fields in QM_EVTSEL.ExtendedEvtID(=1) and + * QM_EVTSEL.EvtID = L3CacheABMC (=1) and setting QM_EVTSEL.RMID + * to the desired counter ID. Reading the QM_CTR then returns the + * contents of the specified counter. The RMID_VAL_ERROR bit is set + * if the counter configuration is invalid, or if an invalid counter + * ID is set in the QM_EVTSEL.RMID field. The RMID_VAL_UNAVAIL bit + * is set if the counter data is unavailable. + */ + wrmsr(MSR_IA32_QM_EVTSEL, ABMC_EXTENDED_EVT_ID | ABMC_EVT_ID, cntr_id); + rdmsrl(MSR_IA32_QM_CTR, msr_val); + + if (msr_val & RMID_VAL_ERROR) + return -EIO; + if (msr_val & RMID_VAL_UNAVAIL) + return -EINVAL; + + *val = msr_val; + return 0; +} + +void resctrl_arch_reset_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 unused, u32 rmid, int cntr_id, + enum resctrl_event_id eventid) +{ + struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); + struct arch_mbm_state *am; + am = get_arch_mbm_state(hw_dom, rmid, eventid); if (am) { - am->chunks += mbm_overflow_count(am->prev_msr, msr_val, - hw_res->mbm_width); - chunks = get_corrected_mbm_count(rmid, am->chunks); - am->prev_msr = msr_val; - } else { - chunks = msr_val; + memset(am, 0, sizeof(*am)); + + /* Record any initial, non-zero count value. */ + __cntr_id_read(cntr_id, &am->prev_msr); } +} + +int resctrl_arch_cntr_read(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 unused, u32 rmid, int cntr_id, + enum resctrl_event_id eventid, u64 *val) +{ + u64 msr_val; + int ret; + + ret = __cntr_id_read(cntr_id, &msr_val); + if (ret) + return ret; - *val = chunks * hw_res->mon_scale; + *val = get_corrected_val(r, d, rmid, eventid, msr_val); return 0; } @@ -346,12 +416,13 @@ int __init rdt_get_mon_l3_config(struct rdt_resource *r) unsigned int mbm_offset = boot_cpu_data.x86_cache_mbm_width_offset; struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); unsigned int threshold; + u32 eax, ebx, ecx, edx; snc_nodes_per_l3_cache = snc_get_config(); resctrl_rmid_realloc_limit = boot_cpu_data.x86_cache_size * 1024; hw_res->mon_scale = boot_cpu_data.x86_cache_occ_scale / snc_nodes_per_l3_cache; - r->num_rmid = (boot_cpu_data.x86_cache_max_rmid + 1) / snc_nodes_per_l3_cache; + r->mon.num_rmid = (boot_cpu_data.x86_cache_max_rmid + 1) / snc_nodes_per_l3_cache; hw_res->mbm_width = MBM_CNTR_WIDTH_BASE; if (mbm_offset > 0 && mbm_offset <= MBM_CNTR_WIDTH_OFFSET_MAX) @@ -366,7 +437,7 @@ int __init rdt_get_mon_l3_config(struct rdt_resource *r) * * For a 35MB LLC and 56 RMIDs, this is ~1.8% of the LLC. */ - threshold = resctrl_rmid_realloc_limit / r->num_rmid; + threshold = resctrl_rmid_realloc_limit / r->mon.num_rmid; /* * Because num_rmid may not be a power of two, round the value @@ -375,12 +446,17 @@ int __init rdt_get_mon_l3_config(struct rdt_resource *r) */ resctrl_rmid_realloc_threshold = resctrl_arch_round_mon_val(threshold); - if (rdt_cpu_has(X86_FEATURE_BMEC)) { - u32 eax, ebx, ecx, edx; - + if (rdt_cpu_has(X86_FEATURE_BMEC) || rdt_cpu_has(X86_FEATURE_ABMC)) { /* Detect list of bandwidth sources that can be tracked */ cpuid_count(0x80000020, 3, &eax, &ebx, &ecx, &edx); - r->mbm_cfg_mask = ecx & MAX_EVT_CONFIG_BITS; + r->mon.mbm_cfg_mask = ecx & MAX_EVT_CONFIG_BITS; + } + + if (rdt_cpu_has(X86_FEATURE_ABMC)) { + r->mon.mbm_cntr_assignable = true; + cpuid_count(0x80000020, 5, &eax, &ebx, &ecx, &edx); + r->mon.num_mbm_cntrs = (ebx & GENMASK(15, 0)) + 1; + hw_res->mbm_cntr_assign_enabled = true; } r->mon_capable = true; @@ -401,3 +477,91 @@ void __init intel_rdt_mbm_apply_quirk(void) mbm_cf_rmidthreshold = mbm_cf_table[cf_index].rmidthreshold; mbm_cf = mbm_cf_table[cf_index].cf; } + +static void resctrl_abmc_set_one_amd(void *arg) +{ + bool *enable = arg; + + if (*enable) + msr_set_bit(MSR_IA32_L3_QOS_EXT_CFG, ABMC_ENABLE_BIT); + else + msr_clear_bit(MSR_IA32_L3_QOS_EXT_CFG, ABMC_ENABLE_BIT); +} + +/* + * ABMC enable/disable requires update of L3_QOS_EXT_CFG MSR on all the CPUs + * associated with all monitor domains. + */ +static void _resctrl_abmc_enable(struct rdt_resource *r, bool enable) +{ + struct rdt_mon_domain *d; + + lockdep_assert_cpus_held(); + + list_for_each_entry(d, &r->mon_domains, hdr.list) { + on_each_cpu_mask(&d->hdr.cpu_mask, resctrl_abmc_set_one_amd, + &enable, 1); + resctrl_arch_reset_rmid_all(r, d); + } +} + +int resctrl_arch_mbm_cntr_assign_set(struct rdt_resource *r, bool enable) +{ + struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); + + if (r->mon.mbm_cntr_assignable && + hw_res->mbm_cntr_assign_enabled != enable) { + _resctrl_abmc_enable(r, enable); + hw_res->mbm_cntr_assign_enabled = enable; + } + + return 0; +} + +bool resctrl_arch_mbm_cntr_assign_enabled(struct rdt_resource *r) +{ + return resctrl_to_arch_res(r)->mbm_cntr_assign_enabled; +} + +static void resctrl_abmc_config_one_amd(void *info) +{ + union l3_qos_abmc_cfg *abmc_cfg = info; + + wrmsrl(MSR_IA32_L3_QOS_ABMC_CFG, abmc_cfg->full); +} + +/* + * Send an IPI to the domain to assign the counter to RMID, event pair. + */ +void resctrl_arch_config_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + enum resctrl_event_id evtid, u32 rmid, u32 closid, + u32 cntr_id, bool assign) +{ + struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); + union l3_qos_abmc_cfg abmc_cfg = { 0 }; + struct arch_mbm_state *am; + + abmc_cfg.split.cfg_en = 1; + abmc_cfg.split.cntr_en = assign ? 1 : 0; + abmc_cfg.split.cntr_id = cntr_id; + abmc_cfg.split.bw_src = rmid; + if (assign) + abmc_cfg.split.bw_type = resctrl_get_mon_evt_cfg(evtid); + + smp_call_function_any(&d->hdr.cpu_mask, resctrl_abmc_config_one_amd, &abmc_cfg, 1); + + /* + * The hardware counter is reset (because cfg_en == 1) so there is no + * need to record initial non-zero counts. + */ + am = get_arch_mbm_state(hw_dom, rmid, evtid); + if (am) + memset(am, 0, sizeof(*am)); +} + +void resctrl_arch_mbm_cntr_assign_set_one(struct rdt_resource *r) +{ + struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); + + resctrl_abmc_set_one_amd(&hw_res->mbm_cntr_assign_enabled); +}  index 6b868afb26c319..4cee6213d66738 100644  --- a/  +++ b/ diff --git a/arch/x86/kernel/cpu/scattered.c b/arch/x86/kernel/cpu/scattered.cindex 6b868afb26c319..4cee6213d66738 100644--- a/ arch/x86/kernel/cpu/scattered.c +++ b/ arch/x86/kernel/cpu/scattered.c @@ -51,6 +51,7 @@ static const struct cpuid_bit cpuid_bits[] = { { X86_FEATURE_COHERENCY_SFW_NO, CPUID_EBX, 31, 0x8000001f, 0 }, { X86_FEATURE_SMBA, CPUID_EBX, 2, 0x80000020, 0 }, { X86_FEATURE_BMEC, CPUID_EBX, 3, 0x80000020, 0 }, + { X86_FEATURE_ABMC, CPUID_EBX, 5, 0x80000020, 0 }, { X86_FEATURE_TSA_SQ_NO, CPUID_ECX, 1, 0x80000021, 0 }, { X86_FEATURE_TSA_L1_NO, CPUID_ECX, 2, 0x80000021, 0 }, { X86_FEATURE_AMD_WORKLOAD_CLASS, CPUID_EAX, 22, 0x80000021, 0 },  index 3c39cfacb25183..0d0ef54fc4de1f 100644  --- a/  +++ b/ diff --git a/fs/resctrl/ctrlmondata.c b/fs/resctrl/ctrlmondata.cindex 3c39cfacb25183..0d0ef54fc4de1f 100644--- a/ fs/resctrl/ctrlmondata.c +++ b/ fs/resctrl/ctrlmondata.c @@ -473,12 +473,12 @@ ssize_t rdtgroup_mba_mbps_event_write(struct kernfs_open_file *of, rdt_last_cmd_clear(); if (!strcmp(buf, "mbm_local_bytes")) { - if (resctrl_arch_is_mbm_local_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) rdtgrp->mba_mbps_event = QOS_L3_MBM_LOCAL_EVENT_ID; else ret = -EINVAL; } else if (!strcmp(buf, "mbm_total_bytes")) { - if (resctrl_arch_is_mbm_total_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) rdtgrp->mba_mbps_event = QOS_L3_MBM_TOTAL_EVENT_ID; else ret = -EINVAL; @@ -563,10 +563,15 @@ void mon_event_read(struct rmid_read *rr, struct rdt_resource *r, rr->r = r; rr->d = d; rr->first = first; - rr->arch_mon_ctx = resctrl_arch_mon_ctx_alloc(r, evtid); - if (IS_ERR(rr->arch_mon_ctx)) { - rr->err = -EINVAL; - return; + if (resctrl_arch_mbm_cntr_assign_enabled(r) && + resctrl_is_mbm_event(evtid)) { + rr->is_mbm_cntr = true; + } else { + rr->arch_mon_ctx = resctrl_arch_mon_ctx_alloc(r, evtid); + if (IS_ERR(rr->arch_mon_ctx)) { + rr->err = -EINVAL; + return; + } } cpu = cpumask_any_housekeeping(cpumask, RESCTRL_PICK_ANY_CPU); @@ -582,7 +587,8 @@ void mon_event_read(struct rmid_read *rr, struct rdt_resource *r, else smp_call_on_cpu(cpu, smp_mon_event_count, rr, false); - resctrl_arch_mon_ctx_free(r, evtid, rr->arch_mon_ctx); + if (rr->arch_mon_ctx) + resctrl_arch_mon_ctx_free(r, evtid, rr->arch_mon_ctx); } int rdtgroup_mondata_show(struct seq_file *m, void *arg) @@ -653,10 +659,16 @@ int rdtgroup_mondata_show(struct seq_file *m, void *arg) checkresult: + /* + * -ENOENT is a special case, set only when "mbm_event" counter assignment + * mode is enabled and no counter has been assigned. + */ if (rr.err == -EIO) seq_puts(m, "Error  "); else if (rr.err == -EINVAL) seq_puts(m, "Unavailable  "); + else if (rr.err == -ENOENT) + seq_puts(m, "Unassigned  "); else seq_printf(m, "%llu  ", rr.val);  index 9a8cf6f11151d9..cf1fd82dc5a99e 100644  --- a/  +++ b/ diff --git a/fs/resctrl/internal.h b/fs/resctrl/internal.hindex 9a8cf6f11151d9..cf1fd82dc5a99e 100644--- a/ fs/resctrl/internal.h +++ b/ fs/resctrl/internal.h @@ -52,19 +52,31 @@ static inline struct rdt_fs_context *rdt_fc2context(struct fs_context *fc) } /** - * struct mon_evt - Entry in the event list of a resource + * struct mon_evt - Properties of a monitor event * @evtid: event id + * @rid: resource id for this event * @name: name of the event + * @evt_cfg: Event configuration value that represents the + * memory transactions (e.g., READS_TO_LOCAL_MEM, + * READS_TO_REMOTE_MEM) being tracked by @evtid. + * Only valid if @evtid is an MBM event. * @configurable: true if the event is configurable - * @list: entry in &rdt_resource->evt_list + * @enabled: true if the event is enabled */ struct mon_evt { enum resctrl_event_id evtid; + enum resctrl_res_level rid; char *name; + u32 evt_cfg; bool configurable; - struct list_head list; + bool enabled; }; +extern struct mon_evt mon_event_all[QOS_NUM_EVENTS]; + +#define for_each_mon_event(mevt) for (mevt = &mon_event_all[QOS_FIRST_EVENT]; \ + mevt < &mon_event_all[QOS_NUM_EVENTS]; mevt++) + /** * struct mon_data - Monitoring details for each event file. * @list: Member of the global @mon_data_kn_priv_list list. @@ -99,6 +111,8 @@ struct mon_data { * @evtid: Which monitor event to read. * @first: Initialize MBM counter when true. * @ci: Cacheinfo for L3. Only set when @d is NULL. Used when summing domains. + * @is_mbm_cntr: true if "mbm_event" counter assignment mode is enabled and it + * is an MBM event. * @err: Error encountered when reading counter. * @val: Returned value of event counter. If @rgrp is a parent resource group, * @val includes the sum of event counts from its child resource groups. @@ -113,6 +127,7 @@ struct rmid_read { enum resctrl_event_id evtid; bool first; struct cacheinfo *ci; + bool is_mbm_cntr; int err; u64 val; void *arch_mon_ctx; @@ -226,6 +241,8 @@ struct rdtgroup { #define RFTYPE_DEBUG BIT(10) +#define RFTYPE_ASSIGN_CONFIG BIT(11) + #define RFTYPE_CTRL_INFO (RFTYPE_INFO | RFTYPE_CTRL) #define RFTYPE_MON_INFO (RFTYPE_INFO | RFTYPE_MON) @@ -375,6 +392,41 @@ bool closid_allocated(unsigned int closid); int resctrl_find_cleanest_closid(void); +void *rdt_kn_parent_priv(struct kernfs_node *kn); + +int resctrl_mbm_assign_mode_show(struct kernfs_open_file *of, struct seq_file *s, void *v); + +ssize_t resctrl_mbm_assign_mode_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off); + +void resctrl_bmec_files_show(struct rdt_resource *r, struct kernfs_node *l3_mon_kn, + bool show); + +int resctrl_num_mbm_cntrs_show(struct kernfs_open_file *of, struct seq_file *s, void *v); + +int resctrl_available_mbm_cntrs_show(struct kernfs_open_file *of, struct seq_file *s, + void *v); + +void rdtgroup_assign_cntrs(struct rdtgroup *rdtgrp); + +void rdtgroup_unassign_cntrs(struct rdtgroup *rdtgrp); + +int event_filter_show(struct kernfs_open_file *of, struct seq_file *seq, void *v); + +ssize_t event_filter_write(struct kernfs_open_file *of, char *buf, size_t nbytes, + loff_t off); + +int resctrl_mbm_assign_on_mkdir_show(struct kernfs_open_file *of, + struct seq_file *s, void *v); + +ssize_t resctrl_mbm_assign_on_mkdir_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off); + +int mbm_L3_assignments_show(struct kernfs_open_file *of, struct seq_file *s, void *v); + +ssize_t mbm_L3_assignments_write(struct kernfs_open_file *of, char *buf, size_t nbytes, + loff_t off); + #ifdef CONFIG_RESCTRL_FS_PSEUDO_LOCK int rdtgroup_locksetup_enter(struct rdtgroup *rdtgrp);  index 7326c28a7908f3..4076336fbba6db 100644  --- a/  +++ b/ diff --git a/fs/resctrl/monitor.c b/fs/resctrl/monitor.cindex 7326c28a7908f3..4076336fbba6db 100644--- a/ fs/resctrl/monitor.c +++ b/ fs/resctrl/monitor.c @@ -336,7 +336,7 @@ void free_rmid(u32 closid, u32 rmid) entry = __rmid_entry(idx); - if (resctrl_arch_is_llc_occupancy_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) add_rmid_to_limbo(entry); else list_add_tail(&entry->list, &rmid_free_lru); @@ -346,27 +346,97 @@ static struct mbm_state *get_mbm_state(struct rdt_mon_domain *d, u32 closid, u32 rmid, enum resctrl_event_id evtid) { u32 idx = resctrl_arch_rmid_idx_encode(closid, rmid); + struct mbm_state *state; - switch (evtid) { - case QOS_L3_MBM_TOTAL_EVENT_ID: - return &d->mbm_total[idx]; - case QOS_L3_MBM_LOCAL_EVENT_ID: - return &d->mbm_local[idx]; - default: + if (!resctrl_is_mbm_event(evtid)) return NULL; + + state = d->mbm_states[MBM_STATE_IDX(evtid)]; + + return state ? &state[idx] : NULL; +} + +/* + * mbm_cntr_get() - Return the counter ID for the matching @evtid and @rdtgrp. + * + * Return: + * Valid counter ID on success, or -ENOENT on failure. + */ +static int mbm_cntr_get(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, enum resctrl_event_id evtid) +{ + int cntr_id; + + if (!r->mon.mbm_cntr_assignable) + return -ENOENT; + + if (!resctrl_is_mbm_event(evtid)) + return -ENOENT; + + for (cntr_id = 0; cntr_id < r->mon.num_mbm_cntrs; cntr_id++) { + if (d->cntr_cfg[cntr_id].rdtgrp == rdtgrp && + d->cntr_cfg[cntr_id].evtid == evtid) + return cntr_id; + } + + return -ENOENT; +} + +/* + * mbm_cntr_alloc() - Initialize and return a new counter ID in the domain @d. + * Caller must ensure that the specified event is not assigned already. + * + * Return: + * Valid counter ID on success, or -ENOSPC on failure. + */ +static int mbm_cntr_alloc(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, enum resctrl_event_id evtid) +{ + int cntr_id; + + for (cntr_id = 0; cntr_id < r->mon.num_mbm_cntrs; cntr_id++) { + if (!d->cntr_cfg[cntr_id].rdtgrp) { + d->cntr_cfg[cntr_id].rdtgrp = rdtgrp; + d->cntr_cfg[cntr_id].evtid = evtid; + return cntr_id; + } } + + return -ENOSPC; } -static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) +/* + * mbm_cntr_free() - Clear the counter ID configuration details in the domain @d. + */ +static void mbm_cntr_free(struct rdt_mon_domain *d, int cntr_id) +{ + memset(&d->cntr_cfg[cntr_id], 0, sizeof(*d->cntr_cfg)); +} + +static int __mon_event_count(struct rdtgroup *rdtgrp, struct rmid_read *rr) { int cpu = smp_processor_id(); + u32 closid = rdtgrp->closid; + u32 rmid = rdtgrp->mon.rmid; struct rdt_mon_domain *d; + int cntr_id = -ENOENT; struct mbm_state *m; int err, ret; u64 tval = 0; + if (rr->is_mbm_cntr) { + cntr_id = mbm_cntr_get(rr->r, rr->d, rdtgrp, rr->evtid); + if (cntr_id < 0) { + rr->err = -ENOENT; + return -EINVAL; + } + } + if (rr->first) { - resctrl_arch_reset_rmid(rr->r, rr->d, closid, rmid, rr->evtid); + if (rr->is_mbm_cntr) + resctrl_arch_reset_cntr(rr->r, rr->d, closid, rmid, cntr_id, rr->evtid); + else + resctrl_arch_reset_rmid(rr->r, rr->d, closid, rmid, rr->evtid); m = get_mbm_state(rr->d, closid, rmid, rr->evtid); if (m) memset(m, 0, sizeof(struct mbm_state)); @@ -377,8 +447,12 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) /* Reading a single domain, must be on a CPU in that domain. */ if (!cpumask_test_cpu(cpu, &rr->d->hdr.cpu_mask)) return -EINVAL; - rr->err = resctrl_arch_rmid_read(rr->r, rr->d, closid, rmid, - rr->evtid, &tval, rr->arch_mon_ctx); + if (rr->is_mbm_cntr) + rr->err = resctrl_arch_cntr_read(rr->r, rr->d, closid, rmid, cntr_id, + rr->evtid, &tval); + else + rr->err = resctrl_arch_rmid_read(rr->r, rr->d, closid, rmid, + rr->evtid, &tval, rr->arch_mon_ctx); if (rr->err) return rr->err; @@ -402,8 +476,12 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) list_for_each_entry(d, &rr->r->mon_domains, hdr.list) { if (d->ci_id != rr->ci->id) continue; - err = resctrl_arch_rmid_read(rr->r, d, closid, rmid, - rr->evtid, &tval, rr->arch_mon_ctx); + if (rr->is_mbm_cntr) + err = resctrl_arch_cntr_read(rr->r, d, closid, rmid, cntr_id, + rr->evtid, &tval); + else + err = resctrl_arch_rmid_read(rr->r, d, closid, rmid, + rr->evtid, &tval, rr->arch_mon_ctx); if (!err) { rr->val += tval; ret = 0; @@ -419,8 +497,8 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) /* * mbm_bw_count() - Update bw count from values previously read by * __mon_event_count(). - * @closid: The closid used to identify the cached mbm_state. - * @rmid: The rmid used to identify the cached mbm_state. + * @rdtgrp: resctrl group associated with the CLOSID and RMID to identify + * the cached mbm_state. * @rr: The struct rmid_read populated by __mon_event_count(). * * Supporting function to calculate the memory bandwidth @@ -428,9 +506,11 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) * __mon_event_count() is compared with the chunks value from the previous * invocation. This must be called once per second to maintain values in MBps. */ -static void mbm_bw_count(u32 closid, u32 rmid, struct rmid_read *rr) +static void mbm_bw_count(struct rdtgroup *rdtgrp, struct rmid_read *rr) { u64 cur_bw, bytes, cur_bytes; + u32 closid = rdtgrp->closid; + u32 rmid = rdtgrp->mon.rmid; struct mbm_state *m; m = get_mbm_state(rr->d, closid, rmid, rr->evtid); @@ -459,7 +539,7 @@ void mon_event_count(void *info) rdtgrp = rr->rgrp; - ret = __mon_event_count(rdtgrp->closid, rdtgrp->mon.rmid, rr); + ret = __mon_event_count(rdtgrp, rr); /* * For Ctrl groups read data from child monitor groups and @@ -470,8 +550,7 @@ void mon_event_count(void *info) if (rdtgrp->type == RDTCTRL_GROUP) { list_for_each_entry(entry, head, mon.crdtgrp_list) { - if (__mon_event_count(entry->closid, entry->mon.rmid, - rr) == 0) + if (__mon_event_count(entry, rr) == 0) ret = 0; } } @@ -602,44 +681,49 @@ static void update_mba_bw(struct rdtgroup *rgrp, struct rdt_mon_domain *dom_mbm) } static void mbm_update_one_event(struct rdt_resource *r, struct rdt_mon_domain *d, - u32 closid, u32 rmid, enum resctrl_event_id evtid) + struct rdtgroup *rdtgrp, enum resctrl_event_id evtid) { struct rmid_read rr = {0}; rr.r = r; rr.d = d; rr.evtid = evtid; - rr.arch_mon_ctx = resctrl_arch_mon_ctx_alloc(rr.r, rr.evtid); - if (IS_ERR(rr.arch_mon_ctx)) { - pr_warn_ratelimited("Failed to allocate monitor context: %ld", - PTR_ERR(rr.arch_mon_ctx)); - return; + if (resctrl_arch_mbm_cntr_assign_enabled(r)) { + rr.is_mbm_cntr = true; + } else { + rr.arch_mon_ctx = resctrl_arch_mon_ctx_alloc(rr.r, rr.evtid); + if (IS_ERR(rr.arch_mon_ctx)) { + pr_warn_ratelimited("Failed to allocate monitor context: %ld", + PTR_ERR(rr.arch_mon_ctx)); + return; + } } - __mon_event_count(closid, rmid, &rr); + __mon_event_count(rdtgrp, &rr); /* * If the software controller is enabled, compute the * bandwidth for this event id. */ if (is_mba_sc(NULL)) - mbm_bw_count(closid, rmid, &rr); + mbm_bw_count(rdtgrp, &rr); - resctrl_arch_mon_ctx_free(rr.r, rr.evtid, rr.arch_mon_ctx); + if (rr.arch_mon_ctx) + resctrl_arch_mon_ctx_free(rr.r, rr.evtid, rr.arch_mon_ctx); } static void mbm_update(struct rdt_resource *r, struct rdt_mon_domain *d, - u32 closid, u32 rmid) + struct rdtgroup *rdtgrp) { /* * This is protected from concurrent reads from user as both * the user and overflow handler hold the global mutex. */ - if (resctrl_arch_is_mbm_total_enabled()) - mbm_update_one_event(r, d, closid, rmid, QOS_L3_MBM_TOTAL_EVENT_ID); + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + mbm_update_one_event(r, d, rdtgrp, QOS_L3_MBM_TOTAL_EVENT_ID); - if (resctrl_arch_is_mbm_local_enabled()) - mbm_update_one_event(r, d, closid, rmid, QOS_L3_MBM_LOCAL_EVENT_ID); + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + mbm_update_one_event(r, d, rdtgrp, QOS_L3_MBM_LOCAL_EVENT_ID); } /* @@ -712,11 +796,11 @@ void mbm_handle_overflow(struct work_struct *work) d = container_of(work, struct rdt_mon_domain, mbm_over.work); list_for_each_entry(prgrp, &rdt_all_groups, rdtgroup_list) { - mbm_update(r, d, prgrp->closid, prgrp->mon.rmid); + mbm_update(r, d, prgrp); head = &prgrp->mon.crdtgrp_list; list_for_each_entry(crgrp, head, mon.crdtgrp_list) - mbm_update(r, d, crgrp->closid, crgrp->mon.rmid); + mbm_update(r, d, crgrp); if (is_mba_sc(NULL)) update_mba_bw(prgrp, d); @@ -842,38 +926,819 @@ out_unlock: mutex_unlock(&rdtgroup_mutex); } -static struct mon_evt llc_occupancy_event = { - .name = "llc_occupancy", - .evtid = QOS_L3_OCCUP_EVENT_ID, +/* + * All available events. Architecture code marks the ones that + * are supported by a system using resctrl_enable_mon_event() + * to set .enabled. + */ +struct mon_evt mon_event_all[QOS_NUM_EVENTS] = { + [QOS_L3_OCCUP_EVENT_ID] = { + .name = "llc_occupancy", + .evtid = QOS_L3_OCCUP_EVENT_ID, + .rid = RDT_RESOURCE_L3, + }, + [QOS_L3_MBM_TOTAL_EVENT_ID] = { + .name = "mbm_total_bytes", + .evtid = QOS_L3_MBM_TOTAL_EVENT_ID, + .rid = RDT_RESOURCE_L3, + }, + [QOS_L3_MBM_LOCAL_EVENT_ID] = { + .name = "mbm_local_bytes", + .evtid = QOS_L3_MBM_LOCAL_EVENT_ID, + .rid = RDT_RESOURCE_L3, + }, }; -static struct mon_evt mbm_total_event = { - .name = "mbm_total_bytes", - .evtid = QOS_L3_MBM_TOTAL_EVENT_ID, +void resctrl_enable_mon_event(enum resctrl_event_id eventid) +{ + if (WARN_ON_ONCE(eventid < QOS_FIRST_EVENT || eventid >= QOS_NUM_EVENTS)) + return; + if (mon_event_all[eventid].enabled) { + pr_warn("Duplicate enable for event %d  ", eventid); + return; + } + + mon_event_all[eventid].enabled = true; +} + +bool resctrl_is_mon_event_enabled(enum resctrl_event_id eventid) +{ + return eventid >= QOS_FIRST_EVENT && eventid < QOS_NUM_EVENTS && + mon_event_all[eventid].enabled; +} + +u32 resctrl_get_mon_evt_cfg(enum resctrl_event_id evtid) +{ + return mon_event_all[evtid].evt_cfg; +} + +/** + * struct mbm_transaction - Memory transaction an MBM event can be configured with. + * @name: Name of memory transaction (read, write ...). + * @val: The bit (eg. READS_TO_LOCAL_MEM or READS_TO_REMOTE_MEM) used to + * represent the memory transaction within an event's configuration. + */ +struct mbm_transaction { + char name[32]; + u32 val; }; -static struct mon_evt mbm_local_event = { - .name = "mbm_local_bytes", - .evtid = QOS_L3_MBM_LOCAL_EVENT_ID, +/* Decoded values for each type of memory transaction. */ +static struct mbm_transaction mbm_transactions[NUM_MBM_TRANSACTIONS] = { + {"local_reads", READS_TO_LOCAL_MEM}, + {"remote_reads", READS_TO_REMOTE_MEM}, + {"local_non_temporal_writes", NON_TEMP_WRITE_TO_LOCAL_MEM}, + {"remote_non_temporal_writes", NON_TEMP_WRITE_TO_REMOTE_MEM}, + {"local_reads_slow_memory", READS_TO_LOCAL_S_MEM}, + {"remote_reads_slow_memory", READS_TO_REMOTE_S_MEM}, + {"dirty_victim_writes_all", DIRTY_VICTIMS_TO_ALL_MEM}, }; +int event_filter_show(struct kernfs_open_file *of, struct seq_file *seq, void *v) +{ + struct mon_evt *mevt = rdt_kn_parent_priv(of->kn); + struct rdt_resource *r; + bool sep = false; + int ret = 0, i; + + mutex_lock(&rdtgroup_mutex); + rdt_last_cmd_clear(); + + r = resctrl_arch_get_resource(mevt->rid); + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts("mbm_event counter assignment mode is not enabled  "); + ret = -EINVAL; + goto out_unlock; + } + + for (i = 0; i < NUM_MBM_TRANSACTIONS; i++) { + if (mevt->evt_cfg & mbm_transactions[i].val) { + if (sep) + seq_putc(seq, ','); + seq_printf(seq, "%s", mbm_transactions[i].name); + sep = true; + } + } + seq_putc(seq, '  '); + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + + return ret; +} + +int resctrl_mbm_assign_on_mkdir_show(struct kernfs_open_file *of, struct seq_file *s, + void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + int ret = 0; + + mutex_lock(&rdtgroup_mutex); + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts("mbm_event counter assignment mode is not enabled  "); + ret = -EINVAL; + goto out_unlock; + } + + seq_printf(s, "%u  ", r->mon.mbm_assign_on_mkdir); + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + + return ret; +} + +ssize_t resctrl_mbm_assign_on_mkdir_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + bool value; + int ret; + + ret = kstrtobool(buf, &value); + if (ret) + return ret; + + mutex_lock(&rdtgroup_mutex); + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts("mbm_event counter assignment mode is not enabled  "); + ret = -EINVAL; + goto out_unlock; + } + + r->mon.mbm_assign_on_mkdir = value; + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + + return ret ?: nbytes; +} + +/* + * mbm_cntr_free_all() - Clear all the counter ID configuration details in the + * domain @d. Called when mbm_assign_mode is changed. + */ +static void mbm_cntr_free_all(struct rdt_resource *r, struct rdt_mon_domain *d) +{ + memset(d->cntr_cfg, 0, sizeof(*d->cntr_cfg) * r->mon.num_mbm_cntrs); +} + +/* + * resctrl_reset_rmid_all() - Reset all non-architecture states for all the + * supported RMIDs. + */ +static void resctrl_reset_rmid_all(struct rdt_resource *r, struct rdt_mon_domain *d) +{ + u32 idx_limit = resctrl_arch_system_num_rmid_idx(); + enum resctrl_event_id evt; + int idx; + + for_each_mbm_event_id(evt) { + if (!resctrl_is_mon_event_enabled(evt)) + continue; + idx = MBM_STATE_IDX(evt); + memset(d->mbm_states[idx], 0, sizeof(*d->mbm_states[0]) * idx_limit); + } +} + +/* + * rdtgroup_assign_cntr() - Assign/unassign the counter ID for the event, RMID + * pair in the domain. + * + * Assign the counter if @assign is true else unassign the counter. Reset the + * associated non-architectural state. + */ +static void rdtgroup_assign_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + enum resctrl_event_id evtid, u32 rmid, u32 closid, + u32 cntr_id, bool assign) +{ + struct mbm_state *m; + + resctrl_arch_config_cntr(r, d, evtid, rmid, closid, cntr_id, assign); + + m = get_mbm_state(d, closid, rmid, evtid); + if (m) + memset(m, 0, sizeof(*m)); +} + +/* + * rdtgroup_alloc_assign_cntr() - Allocate a counter ID and assign it to the event + * pointed to by @mevt and the resctrl group @rdtgrp within the domain @d. + * + * Return: + * 0 on success, < 0 on failure. + */ +static int rdtgroup_alloc_assign_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, struct mon_evt *mevt) +{ + int cntr_id; + + /* No action required if the counter is assigned already. */ + cntr_id = mbm_cntr_get(r, d, rdtgrp, mevt->evtid); + if (cntr_id >= 0) + return 0; + + cntr_id = mbm_cntr_alloc(r, d, rdtgrp, mevt->evtid); + if (cntr_id < 0) { + rdt_last_cmd_printf("Failed to allocate counter for %s in domain %d  ", + mevt->name, d->hdr.id); + return cntr_id; + } + + rdtgroup_assign_cntr(r, d, mevt->evtid, rdtgrp->mon.rmid, rdtgrp->closid, cntr_id, true); + + return 0; +} + /* - * Initialize the event list for the resource. + * rdtgroup_assign_cntr_event() - Assign a hardware counter for the event in + * @mevt to the resctrl group @rdtgrp. Assign counters to all domains if @d is + * NULL; otherwise, assign the counter to the specified domain @d. + * + * If all counters in a domain are already in use, rdtgroup_alloc_assign_cntr() + * will fail. The assignment process will abort at the first failure encountered + * during domain traversal, which may result in the event being only partially + * assigned. * - * Note that MBM events are also part of RDT_RESOURCE_L3 resource - * because as per the SDM the total and local memory bandwidth - * are enumerated as part of L3 monitoring. + * Return: + * 0 on success, < 0 on failure. + */ +static int rdtgroup_assign_cntr_event(struct rdt_mon_domain *d, struct rdtgroup *rdtgrp, + struct mon_evt *mevt) +{ + struct rdt_resource *r = resctrl_arch_get_resource(mevt->rid); + int ret = 0; + + if (!d) { + list_for_each_entry(d, &r->mon_domains, hdr.list) { + ret = rdtgroup_alloc_assign_cntr(r, d, rdtgrp, mevt); + if (ret) + return ret; + } + } else { + ret = rdtgroup_alloc_assign_cntr(r, d, rdtgrp, mevt); + } + + return ret; +} + +/* + * rdtgroup_assign_cntrs() - Assign counters to MBM events. Called when + * a new group is created. + * + * Each group can accommodate two counters per domain: one for the total + * event and one for the local event. Assignments may fail due to the limited + * number of counters. However, it is not necessary to fail the group creation + * and thus no failure is returned. Users have the option to modify the + * counter assignments after the group has been created. + */ +void rdtgroup_assign_cntrs(struct rdtgroup *rdtgrp) +{ + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); + + if (!r->mon_capable || !resctrl_arch_mbm_cntr_assign_enabled(r) || + !r->mon.mbm_assign_on_mkdir) + return; + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + rdtgroup_assign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID]); + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + rdtgroup_assign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID]); +} + +/* + * rdtgroup_free_unassign_cntr() - Unassign and reset the counter ID configuration + * for the event pointed to by @mevt within the domain @d and resctrl group @rdtgrp. + */ +static void rdtgroup_free_unassign_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, struct mon_evt *mevt) +{ + int cntr_id; + + cntr_id = mbm_cntr_get(r, d, rdtgrp, mevt->evtid); + + /* If there is no cntr_id assigned, nothing to do */ + if (cntr_id < 0) + return; + + rdtgroup_assign_cntr(r, d, mevt->evtid, rdtgrp->mon.rmid, rdtgrp->closid, cntr_id, false); + + mbm_cntr_free(d, cntr_id); +} + +/* + * rdtgroup_unassign_cntr_event() - Unassign a hardware counter associated with + * the event structure @mevt from the domain @d and the group @rdtgrp. Unassign + * the counters from all the domains if @d is NULL else unassign from @d. + */ +static void rdtgroup_unassign_cntr_event(struct rdt_mon_domain *d, struct rdtgroup *rdtgrp, + struct mon_evt *mevt) +{ + struct rdt_resource *r = resctrl_arch_get_resource(mevt->rid); + + if (!d) { + list_for_each_entry(d, &r->mon_domains, hdr.list) + rdtgroup_free_unassign_cntr(r, d, rdtgrp, mevt); + } else { + rdtgroup_free_unassign_cntr(r, d, rdtgrp, mevt); + } +} + +/* + * rdtgroup_unassign_cntrs() - Unassign the counters associated with MBM events. + * Called when a group is deleted. */ -static void l3_mon_evt_init(struct rdt_resource *r) +void rdtgroup_unassign_cntrs(struct rdtgroup *rdtgrp) { - INIT_LIST_HEAD(&r->evt_list); + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); - if (resctrl_arch_is_llc_occupancy_enabled()) - list_add_tail(&llc_occupancy_event.list, &r->evt_list); - if (resctrl_arch_is_mbm_total_enabled()) - list_add_tail(&mbm_total_event.list, &r->evt_list); - if (resctrl_arch_is_mbm_local_enabled()) - list_add_tail(&mbm_local_event.list, &r->evt_list); + if (!r->mon_capable || !resctrl_arch_mbm_cntr_assign_enabled(r)) + return; + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + rdtgroup_unassign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID]); + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + rdtgroup_unassign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID]); +} + +static int resctrl_parse_mem_transactions(char *tok, u32 *val) +{ + u32 temp_val = 0; + char *evt_str; + bool found; + int i; + +next_config: + if (!tok || tok[0] == '\0') { + *val = temp_val; + return 0; + } + + /* Start processing the strings for each memory transaction type */ + evt_str = strim(strsep(&tok, ",")); + found = false; + for (i = 0; i < NUM_MBM_TRANSACTIONS; i++) { + if (!strcmp(mbm_transactions[i].name, evt_str)) { + temp_val |= mbm_transactions[i].val; + found = true; + break; + } + } + + if (!found) { + rdt_last_cmd_printf("Invalid memory transaction type %s  ", evt_str); + return -EINVAL; + } + + goto next_config; +} + +/* + * rdtgroup_update_cntr_event - Update the counter assignments for the event + * in a group. + * @r: Resource to which update needs to be done. + * @rdtgrp: Resctrl group. + * @evtid: MBM monitor event. + */ +static void rdtgroup_update_cntr_event(struct rdt_resource *r, struct rdtgroup *rdtgrp, + enum resctrl_event_id evtid) +{ + struct rdt_mon_domain *d; + int cntr_id; + + list_for_each_entry(d, &r->mon_domains, hdr.list) { + cntr_id = mbm_cntr_get(r, d, rdtgrp, evtid); + if (cntr_id >= 0) + rdtgroup_assign_cntr(r, d, evtid, rdtgrp->mon.rmid, + rdtgrp->closid, cntr_id, true); + } +} + +/* + * resctrl_update_cntr_allrdtgrp - Update the counter assignments for the event + * for all the groups. + * @mevt MBM Monitor event. + */ +static void resctrl_update_cntr_allrdtgrp(struct mon_evt *mevt) +{ + struct rdt_resource *r = resctrl_arch_get_resource(mevt->rid); + struct rdtgroup *prgrp, *crgrp; + + /* + * Find all the groups where the event is assigned and update the + * configuration of existing assignments. + */ + list_for_each_entry(prgrp, &rdt_all_groups, rdtgroup_list) { + rdtgroup_update_cntr_event(r, prgrp, mevt->evtid); + + list_for_each_entry(crgrp, &prgrp->mon.crdtgrp_list, mon.crdtgrp_list) + rdtgroup_update_cntr_event(r, crgrp, mevt->evtid); + } +} + +ssize_t event_filter_write(struct kernfs_open_file *of, char *buf, size_t nbytes, + loff_t off) +{ + struct mon_evt *mevt = rdt_kn_parent_priv(of->kn); + struct rdt_resource *r; + u32 evt_cfg = 0; + int ret = 0; + + /* Valid input requires a trailing newline */ + if (nbytes == 0 || buf[nbytes - 1] != '  ') + return -EINVAL; + + buf[nbytes - 1] = '\0'; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + rdt_last_cmd_clear(); + + r = resctrl_arch_get_resource(mevt->rid); + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts("mbm_event counter assignment mode is not enabled  "); + ret = -EINVAL; + goto out_unlock; + } + + ret = resctrl_parse_mem_transactions(buf, &evt_cfg); + if (!ret && mevt->evt_cfg != evt_cfg) { + mevt->evt_cfg = evt_cfg; + resctrl_update_cntr_allrdtgrp(mevt); + } + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + + return ret ?: nbytes; +} + +int resctrl_mbm_assign_mode_show(struct kernfs_open_file *of, + struct seq_file *s, void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + bool enabled; + + mutex_lock(&rdtgroup_mutex); + enabled = resctrl_arch_mbm_cntr_assign_enabled(r); + + if (r->mon.mbm_cntr_assignable) { + if (enabled) + seq_puts(s, "[mbm_event]  "); + else + seq_puts(s, "[default]  "); + + if (!IS_ENABLED(CONFIG_RESCTRL_ASSIGN_FIXED)) { + if (enabled) + seq_puts(s, "default  "); + else + seq_puts(s, "mbm_event  "); + } + } else { + seq_puts(s, "[default]  "); + } + + mutex_unlock(&rdtgroup_mutex); + + return 0; +} + +ssize_t resctrl_mbm_assign_mode_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + struct rdt_mon_domain *d; + int ret = 0; + bool enable; + + /* Valid input requires a trailing newline */ + if (nbytes == 0 || buf[nbytes - 1] != '  ') + return -EINVAL; + + buf[nbytes - 1] = '\0'; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + rdt_last_cmd_clear(); + + if (!strcmp(buf, "default")) { + enable = 0; + } else if (!strcmp(buf, "mbm_event")) { + if (r->mon.mbm_cntr_assignable) { + enable = 1; + } else { + ret = -EINVAL; + rdt_last_cmd_puts("mbm_event mode is not supported  "); + goto out_unlock; + } + } else { + ret = -EINVAL; + rdt_last_cmd_puts("Unsupported assign mode  "); + goto out_unlock; + } + + if (enable != resctrl_arch_mbm_cntr_assign_enabled(r)) { + ret = resctrl_arch_mbm_cntr_assign_set(r, enable); + if (ret) + goto out_unlock; + + /* Update the visibility of BMEC related files */ + resctrl_bmec_files_show(r, NULL, !enable); + + /* + * Initialize the default memory transaction values for + * total and local events. + */ + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask; + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask & + (READS_TO_LOCAL_MEM | + READS_TO_LOCAL_S_MEM | + NON_TEMP_WRITE_TO_LOCAL_MEM); + /* Enable auto assignment when switching to "mbm_event" mode */ + if (enable) + r->mon.mbm_assign_on_mkdir = true; + /* + * Reset all the non-achitectural RMID state and assignable counters. + */ + list_for_each_entry(d, &r->mon_domains, hdr.list) { + mbm_cntr_free_all(r, d); + resctrl_reset_rmid_all(r, d); + } + } + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + + return ret ?: nbytes; +} + +int resctrl_num_mbm_cntrs_show(struct kernfs_open_file *of, + struct seq_file *s, void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + struct rdt_mon_domain *dom; + bool sep = false; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + list_for_each_entry(dom, &r->mon_domains, hdr.list) { + if (sep) + seq_putc(s, ';'); + + seq_printf(s, "%d=%d", dom->hdr.id, r->mon.num_mbm_cntrs); + sep = true; + } + seq_putc(s, '  '); + + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + return 0; +} + +int resctrl_available_mbm_cntrs_show(struct kernfs_open_file *of, + struct seq_file *s, void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + struct rdt_mon_domain *dom; + bool sep = false; + u32 cntrs, i; + int ret = 0; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts("mbm_event counter assignment mode is not enabled  "); + ret = -EINVAL; + goto out_unlock; + } + + list_for_each_entry(dom, &r->mon_domains, hdr.list) { + if (sep) + seq_putc(s, ';'); + + cntrs = 0; + for (i = 0; i < r->mon.num_mbm_cntrs; i++) { + if (!dom->cntr_cfg[i].rdtgrp) + cntrs++; + } + + seq_printf(s, "%d=%u", dom->hdr.id, cntrs); + sep = true; + } + seq_putc(s, '  '); + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + + return ret; +} + +int mbm_L3_assignments_show(struct kernfs_open_file *of, struct seq_file *s, void *v) +{ + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); + struct rdt_mon_domain *d; + struct rdtgroup *rdtgrp; + struct mon_evt *mevt; + int ret = 0; + bool sep; + + rdtgrp = rdtgroup_kn_lock_live(of->kn); + if (!rdtgrp) { + ret = -ENOENT; + goto out_unlock; + } + + rdt_last_cmd_clear(); + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts("mbm_event counter assignment mode is not enabled  "); + ret = -EINVAL; + goto out_unlock; + } + + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled || !resctrl_is_mbm_event(mevt->evtid)) + continue; + + sep = false; + seq_printf(s, "%s:", mevt->name); + list_for_each_entry(d, &r->mon_domains, hdr.list) { + if (sep) + seq_putc(s, ';'); + + if (mbm_cntr_get(r, d, rdtgrp, mevt->evtid) < 0) + seq_printf(s, "%d=_", d->hdr.id); + else + seq_printf(s, "%d=e", d->hdr.id); + + sep = true; + } + seq_putc(s, '  '); + } + +out_unlock: + rdtgroup_kn_unlock(of->kn); + + return ret; +} + +/* + * mbm_get_mon_event_by_name() - Return the mon_evt entry for the matching + * event name. + */ +static struct mon_evt *mbm_get_mon_event_by_name(struct rdt_resource *r, char *name) +{ + struct mon_evt *mevt; + + for_each_mon_event(mevt) { + if (mevt->rid == r->rid && mevt->enabled && + resctrl_is_mbm_event(mevt->evtid) && + !strcmp(mevt->name, name)) + return mevt; + } + + return NULL; +} + +static int rdtgroup_modify_assign_state(char *assign, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, struct mon_evt *mevt) +{ + int ret = 0; + + if (!assign || strlen(assign) != 1) + return -EINVAL; + + switch (*assign) { + case 'e': + ret = rdtgroup_assign_cntr_event(d, rdtgrp, mevt); + break; + case '_': + rdtgroup_unassign_cntr_event(d, rdtgrp, mevt); + break; + default: + ret = -EINVAL; + break; + } + + return ret; +} + +static int resctrl_parse_mbm_assignment(struct rdt_resource *r, struct rdtgroup *rdtgrp, + char *event, char *tok) +{ + struct rdt_mon_domain *d; + unsigned long dom_id = 0; + char *dom_str, *id_str; + struct mon_evt *mevt; + int ret; + + mevt = mbm_get_mon_event_by_name(r, event); + if (!mevt) { + rdt_last_cmd_printf("Invalid event %s  ", event); + return -ENOENT; + } + +next: + if (!tok || tok[0] == '\0') + return 0; + + /* Start processing the strings for each domain */ + dom_str = strim(strsep(&tok, ";")); + + id_str = strsep(&dom_str, "="); + + /* Check for domain id '*' which means all domains */ + if (id_str && *id_str == '*') { + ret = rdtgroup_modify_assign_state(dom_str, NULL, rdtgrp, mevt); + if (ret) + rdt_last_cmd_printf("Assign operation '%s:*=%s' failed  ", + event, dom_str); + return ret; + } else if (!id_str || kstrtoul(id_str, 10, &dom_id)) { + rdt_last_cmd_puts("Missing domain id  "); + return -EINVAL; + } + + /* Verify if the dom_id is valid */ + list_for_each_entry(d, &r->mon_domains, hdr.list) { + if (d->hdr.id == dom_id) { + ret = rdtgroup_modify_assign_state(dom_str, d, rdtgrp, mevt); + if (ret) { + rdt_last_cmd_printf("Assign operation '%s:%ld=%s' failed  ", + event, dom_id, dom_str); + return ret; + } + goto next; + } + } + + rdt_last_cmd_printf("Invalid domain id %ld  ", dom_id); + return -EINVAL; +} + +ssize_t mbm_L3_assignments_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off) +{ + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); + struct rdtgroup *rdtgrp; + char *token, *event; + int ret = 0; + + /* Valid input requires a trailing newline */ + if (nbytes == 0 || buf[nbytes - 1] != '  ') + return -EINVAL; + + buf[nbytes - 1] = '\0'; + + rdtgrp = rdtgroup_kn_lock_live(of->kn); + if (!rdtgrp) { + rdtgroup_kn_unlock(of->kn); + return -ENOENT; + } + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts("mbm_event mode is not enabled  "); + rdtgroup_kn_unlock(of->kn); + return -EINVAL; + } + + while ((token = strsep(&buf, "  ")) != NULL) { + /* + * The write command follows the following format: + * "<Event>:<Domain ID>=<Assignment state>" + * Extract the event name first. + */ + event = strsep(&token, ":"); + + ret = resctrl_parse_mbm_assignment(r, rdtgrp, event, token); + if (ret) + break; + } + + rdtgroup_kn_unlock(of->kn); + + return ret ?: nbytes; } /** @@ -900,24 +1765,43 @@ int resctrl_mon_resource_init(void) if (ret) return ret; - l3_mon_evt_init(r); - if (resctrl_arch_is_evt_configurable(QOS_L3_MBM_TOTAL_EVENT_ID)) { - mbm_total_event.configurable = true; + mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID].configurable = true; resctrl_file_fflags_init("mbm_total_bytes_config", RFTYPE_MON_INFO | RFTYPE_RES_CACHE); } if (resctrl_arch_is_evt_configurable(QOS_L3_MBM_LOCAL_EVENT_ID)) { - mbm_local_event.configurable = true; + mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID].configurable = true; resctrl_file_fflags_init("mbm_local_bytes_config", RFTYPE_MON_INFO | RFTYPE_RES_CACHE); } - if (resctrl_arch_is_mbm_local_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) mba_mbps_default_event = QOS_L3_MBM_LOCAL_EVENT_ID; - else if (resctrl_arch_is_mbm_total_enabled()) + else if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) mba_mbps_default_event = QOS_L3_MBM_TOTAL_EVENT_ID; + if (r->mon.mbm_cntr_assignable) { + if (!resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + resctrl_enable_mon_event(QOS_L3_MBM_TOTAL_EVENT_ID); + if (!resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + resctrl_enable_mon_event(QOS_L3_MBM_LOCAL_EVENT_ID); + mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask; + mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask & + (READS_TO_LOCAL_MEM | + READS_TO_LOCAL_S_MEM | + NON_TEMP_WRITE_TO_LOCAL_MEM); + r->mon.mbm_assign_on_mkdir = true; + resctrl_file_fflags_init("num_mbm_cntrs", + RFTYPE_MON_INFO | RFTYPE_RES_CACHE); + resctrl_file_fflags_init("available_mbm_cntrs", + RFTYPE_MON_INFO | RFTYPE_RES_CACHE); + resctrl_file_fflags_init("event_filter", RFTYPE_ASSIGN_CONFIG); + resctrl_file_fflags_init("mbm_assign_on_mkdir", RFTYPE_MON_INFO | + RFTYPE_RES_CACHE); + resctrl_file_fflags_init("mbm_L3_assignments", RFTYPE_MON_BASE); + } + return 0; }  index 77d08229d85502..0320360cd7a6eb 100644  --- a/  +++ b/ diff --git a/fs/resctrl/rdtgroup.c b/fs/resctrl/rdtgroup.cindex 77d08229d85502..0320360cd7a6eb 100644--- a/ fs/resctrl/rdtgroup.c +++ b/ fs/resctrl/rdtgroup.c @@ -123,14 +123,8 @@ void rdt_staged_configs_clear(void) static bool resctrl_is_mbm_enabled(void) { - return (resctrl_arch_is_mbm_total_enabled() || - resctrl_arch_is_mbm_local_enabled()); -} - -static bool resctrl_is_mbm_event(int e) -{ - return (e >= QOS_L3_MBM_TOTAL_EVENT_ID && - e <= QOS_L3_MBM_LOCAL_EVENT_ID); + return (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID) || + resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)); } /* @@ -196,7 +190,7 @@ static int closid_alloc(void) lockdep_assert_held(&rdtgroup_mutex); if (IS_ENABLED(CONFIG_RESCTRL_RMID_DEPENDS_ON_CLOSID) && - resctrl_arch_is_llc_occupancy_enabled()) { + resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) { cleanest_closid = resctrl_find_cleanest_closid(); if (cleanest_closid < 0) return cleanest_closid; @@ -981,7 +975,7 @@ static int rdt_last_cmd_status_show(struct kernfs_open_file *of, return 0; } -static void *rdt_kn_parent_priv(struct kernfs_node *kn) +void *rdt_kn_parent_priv(struct kernfs_node *kn) { /* * The parent pointer is only valid within RCU section since it can be @@ -1141,7 +1135,7 @@ static int rdt_num_rmids_show(struct kernfs_open_file *of, { struct rdt_resource *r = rdt_kn_parent_priv(of->kn); - seq_printf(seq, "%d  ", r->num_rmid); + seq_printf(seq, "%d  ", r->mon.num_rmid); return 0; } @@ -1152,9 +1146,12 @@ static int rdt_mon_features_show(struct kernfs_open_file *of, struct rdt_resource *r = rdt_kn_parent_priv(of->kn); struct mon_evt *mevt; - list_for_each_entry(mevt, &r->evt_list, list) { + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled) + continue; seq_printf(seq, "%s  ", mevt->name); - if (mevt->configurable) + if (mevt->configurable && + !resctrl_arch_mbm_cntr_assign_enabled(r)) seq_printf(seq, "%s_config  ", mevt->name); } @@ -1735,9 +1732,9 @@ next: } /* Value from user cannot be more than the supported set of events */ - if ((val & r->mbm_cfg_mask) != val) { + if ((val & r->mon.mbm_cfg_mask) != val) { rdt_last_cmd_printf("Invalid event configuration: max valid mask is 0x%02x  ", - r->mbm_cfg_mask); + r->mon.mbm_cfg_mask); return -EINVAL; } @@ -1803,6 +1800,44 @@ static ssize_t mbm_local_bytes_config_write(struct kernfs_open_file *of, return ret ?: nbytes; } +/* + * resctrl_bmec_files_show() — Controls the visibility of BMEC-related resctrl + * files. When @show is true, the files are displayed; when false, the files + * are hidden. + * Don't treat kernfs_find_and_get failure as an error, since this function may + * be called regardless of whether BMEC is supported or the event is enabled. + */ +void resctrl_bmec_files_show(struct rdt_resource *r, struct kernfs_node *l3_mon_kn, + bool show) +{ + struct kernfs_node *kn_config, *mon_kn = NULL; + char name[32]; + + if (!l3_mon_kn) { + sprintf(name, "%s_MON", r->name); + mon_kn = kernfs_find_and_get(kn_info, name); + if (!mon_kn) + return; + l3_mon_kn = mon_kn; + } + + kn_config = kernfs_find_and_get(l3_mon_kn, "mbm_total_bytes_config"); + if (kn_config) { + kernfs_show(kn_config, show); + kernfs_put(kn_config); + } + + kn_config = kernfs_find_and_get(l3_mon_kn, "mbm_local_bytes_config"); + if (kn_config) { + kernfs_show(kn_config, show); + kernfs_put(kn_config); + } + + /* Release the reference only if it was acquired */ + if (mon_kn) + kernfs_put(mon_kn); +} + /* rdtgroup information files for one cache resource. */ static struct rftype res_common_files[] = { { @@ -1813,6 +1848,13 @@ static struct rftype res_common_files[] = { .fflags = RFTYPE_TOP_INFO, }, { + .name = "mbm_assign_on_mkdir", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_mbm_assign_on_mkdir_show, + .write = resctrl_mbm_assign_on_mkdir_write, + }, + { .name = "num_closids", .mode = 0444, .kf_ops = &rdtgroup_kf_single_ops, @@ -1827,6 +1869,12 @@ static struct rftype res_common_files[] = { .fflags = RFTYPE_MON_INFO, }, { + .name = "available_mbm_cntrs", + .mode = 0444, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_available_mbm_cntrs_show, + }, + { .name = "num_rmids", .mode = 0444, .kf_ops = &rdtgroup_kf_single_ops, @@ -1841,6 +1889,12 @@ static struct rftype res_common_files[] = { .fflags = RFTYPE_CTRL_INFO | RFTYPE_RES_CACHE, }, { + .name = "num_mbm_cntrs", + .mode = 0444, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_num_mbm_cntrs_show, + }, + { .name = "min_cbm_bits", .mode = 0444, .kf_ops = &rdtgroup_kf_single_ops, @@ -1916,6 +1970,28 @@ static struct rftype res_common_files[] = { .write = mbm_local_bytes_config_write, }, { + .name = "event_filter", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = event_filter_show, + .write = event_filter_write, + }, + { + .name = "mbm_L3_assignments", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = mbm_L3_assignments_show, + .write = mbm_L3_assignments_write, + }, + { + .name = "mbm_assign_mode", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_mbm_assign_mode_show, + .write = resctrl_mbm_assign_mode_write, + .fflags = RFTYPE_MON_INFO | RFTYPE_RES_CACHE, + }, + { .name = "cpus", .mode = 0644, .kf_ops = &rdtgroup_kf_single_ops, @@ -2168,10 +2244,48 @@ int rdtgroup_kn_mode_restore(struct rdtgroup *r, const char *name, return ret; } +static int resctrl_mkdir_event_configs(struct rdt_resource *r, struct kernfs_node *l3_mon_kn) +{ + struct kernfs_node *kn_subdir, *kn_subdir2; + struct mon_evt *mevt; + int ret; + + kn_subdir = kernfs_create_dir(l3_mon_kn, "event_configs", l3_mon_kn->mode, NULL); + if (IS_ERR(kn_subdir)) + return PTR_ERR(kn_subdir); + + ret = rdtgroup_kn_set_ugid(kn_subdir); + if (ret) + return ret; + + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled || !resctrl_is_mbm_event(mevt->evtid)) + continue; + + kn_subdir2 = kernfs_create_dir(kn_subdir, mevt->name, kn_subdir->mode, mevt); + if (IS_ERR(kn_subdir2)) { + ret = PTR_ERR(kn_subdir2); + goto out; + } + + ret = rdtgroup_kn_set_ugid(kn_subdir2); + if (ret) + goto out; + + ret = rdtgroup_add_files(kn_subdir2, RFTYPE_ASSIGN_CONFIG); + if (ret) + break; + } + +out: + return ret; +} + static int rdtgroup_mkdir_info_resdir(void *priv, char *name, unsigned long fflags) { struct kernfs_node *kn_subdir; + struct rdt_resource *r; int ret; kn_subdir = kernfs_create_dir(kn_info, name, @@ -2184,8 +2298,25 @@ static int rdtgroup_mkdir_info_resdir(void *priv, char *name, return ret; ret = rdtgroup_add_files(kn_subdir, fflags); - if (!ret) - kernfs_activate(kn_subdir); + if (ret) + return ret; + + if ((fflags & RFTYPE_MON_INFO) == RFTYPE_MON_INFO) { + r = priv; + if (r->mon.mbm_cntr_assignable) { + ret = resctrl_mkdir_event_configs(r, kn_subdir); + if (ret) + return ret; + /* + * Hide BMEC related files if mbm_event mode + * is enabled. + */ + if (resctrl_arch_mbm_cntr_assign_enabled(r)) + resctrl_bmec_files_show(r, kn_subdir, false); + } + } + + kernfs_activate(kn_subdir); return ret; } @@ -2608,10 +2739,8 @@ static int rdt_get_tree(struct fs_context *fc) goto out_root; ret = schemata_list_create(); - if (ret) { - schemata_list_destroy(); - goto out_ctx; - } + if (ret) + goto out_schemata_free; ret = closid_init(); if (ret) @@ -2637,6 +2766,8 @@ static int rdt_get_tree(struct fs_context *fc) if (ret < 0) goto out_info; + rdtgroup_assign_cntrs(&rdtgroup_default); + ret = mkdir_mondata_all(rdtgroup_default.kn, &rdtgroup_default, &kn_mondata); if (ret < 0) @@ -2675,15 +2806,16 @@ out_mondata: if (resctrl_arch_mon_capable()) kernfs_remove(kn_mondata); out_mongrp: - if (resctrl_arch_mon_capable()) + if (resctrl_arch_mon_capable()) { + rdtgroup_unassign_cntrs(&rdtgroup_default); kernfs_remove(kn_mongrp); + } out_info: kernfs_remove(kn_info); out_closid_exit: closid_exit(); out_schemata_free: schemata_list_destroy(); -out_ctx: rdt_disable_ctx(); out_root: rdtgroup_destroy_root(); @@ -2822,6 +2954,7 @@ static void free_all_child_rdtgrp(struct rdtgroup *rdtgrp) head = &rdtgrp->mon.crdtgrp_list; list_for_each_entry_safe(sentry, stmp, head, mon.crdtgrp_list) { + rdtgroup_unassign_cntrs(sentry); free_rmid(sentry->closid, sentry->mon.rmid); list_del(&sentry->mon.crdtgrp_list); @@ -2862,6 +2995,8 @@ static void rmdir_all_sub(void) cpumask_or(&rdtgroup_default.cpu_mask, &rdtgroup_default.cpu_mask, &rdtgrp->cpu_mask); + rdtgroup_unassign_cntrs(rdtgrp); + free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); kernfs_remove(rdtgrp->kn); @@ -2946,6 +3081,7 @@ static void resctrl_fs_teardown(void) return; rmdir_all_sub(); + rdtgroup_unassign_cntrs(&rdtgroup_default); mon_put_kn_priv(); rdt_pseudo_lock_release(); rdtgroup_default.mode = RDT_MODE_SHAREABLE; @@ -3057,10 +3193,9 @@ static int mon_add_all_files(struct kernfs_node *kn, struct rdt_mon_domain *d, struct mon_evt *mevt; int ret, domid; - if (WARN_ON(list_empty(&r->evt_list))) - return -EPERM; - - list_for_each_entry(mevt, &r->evt_list, list) { + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled) + continue; domid = do_sum ? d->ci_id : d->hdr.id; priv = mon_get_kn_priv(r->rid, domid, mevt, do_sum); if (WARN_ON_ONCE(!priv)) @@ -3427,9 +3562,12 @@ static int mkdir_rdt_prepare_rmid_alloc(struct rdtgroup *rdtgrp) } rdtgrp->mon.rmid = ret; + rdtgroup_assign_cntrs(rdtgrp); + ret = mkdir_mondata_all(rdtgrp->kn, rdtgrp, &rdtgrp->mon.mon_data_kn); if (ret) { rdt_last_cmd_puts("kernfs subdir error  "); + rdtgroup_unassign_cntrs(rdtgrp); free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); return ret; } @@ -3439,8 +3577,10 @@ static int mkdir_rdt_prepare_rmid_alloc(struct rdtgroup *rdtgrp) static void mkdir_rdt_prepare_rmid_free(struct rdtgroup *rgrp) { - if (resctrl_arch_mon_capable()) + if (resctrl_arch_mon_capable()) { + rdtgroup_unassign_cntrs(rgrp); free_rmid(rgrp->closid, rgrp->mon.rmid); + } } /* @@ -3716,6 +3856,9 @@ static int rdtgroup_rmdir_mon(struct rdtgroup *rdtgrp, cpumask_var_t tmpmask) update_closid_rmid(tmpmask, NULL); rdtgrp->flags = RDT_DELETED; + + rdtgroup_unassign_cntrs(rdtgrp); + free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); /* @@ -3763,6 +3906,8 @@ static int rdtgroup_rmdir_ctrl(struct rdtgroup *rdtgrp, cpumask_var_t tmpmask) cpumask_or(tmpmask, tmpmask, &rdtgrp->cpu_mask); update_closid_rmid(tmpmask, NULL); + rdtgroup_unassign_cntrs(rdtgrp); + free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); closid_free(rdtgrp->closid); @@ -4022,9 +4167,14 @@ static void rdtgroup_setup_default(void) static void domain_destroy_mon_state(struct rdt_mon_domain *d) { + int idx; + + kfree(d->cntr_cfg); bitmap_free(d->rmid_busy_llc); - kfree(d->mbm_total); - kfree(d->mbm_local); + for_each_mbm_idx(idx) { + kfree(d->mbm_states[idx]); + d->mbm_states[idx] = NULL; + } } void resctrl_offline_ctrl_domain(struct rdt_resource *r, struct rdt_ctrl_domain *d) @@ -4050,7 +4200,7 @@ void resctrl_offline_mon_domain(struct rdt_resource *r, struct rdt_mon_domain *d if (resctrl_is_mbm_enabled()) cancel_delayed_work(&d->mbm_over); - if (resctrl_arch_is_llc_occupancy_enabled() && has_busy_rmid(d)) { + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID) && has_busy_rmid(d)) { /* * When a package is going down, forcefully * decrement rmid->ebusy. There is no way to know @@ -4084,32 +4234,41 @@ void resctrl_offline_mon_domain(struct rdt_resource *r, struct rdt_mon_domain *d static int domain_setup_mon_state(struct rdt_resource *r, struct rdt_mon_domain *d) { u32 idx_limit = resctrl_arch_system_num_rmid_idx(); - size_t tsize; + size_t tsize = sizeof(*d->mbm_states[0]); + enum resctrl_event_id eventid; + int idx; - if (resctrl_arch_is_llc_occupancy_enabled()) { + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) { d->rmid_busy_llc = bitmap_zalloc(idx_limit, GFP_KERNEL); if (!d->rmid_busy_llc) return -ENOMEM; } - if (resctrl_arch_is_mbm_total_enabled()) { - tsize = sizeof(*d->mbm_total); - d->mbm_total = kcalloc(idx_limit, tsize, GFP_KERNEL); - if (!d->mbm_total) { - bitmap_free(d->rmid_busy_llc); - return -ENOMEM; - } + + for_each_mbm_event_id(eventid) { + if (!resctrl_is_mon_event_enabled(eventid)) + continue; + idx = MBM_STATE_IDX(eventid); + d->mbm_states[idx] = kcalloc(idx_limit, tsize, GFP_KERNEL); + if (!d->mbm_states[idx]) + goto cleanup; } - if (resctrl_arch_is_mbm_local_enabled()) { - tsize = sizeof(*d->mbm_local); - d->mbm_local = kcalloc(idx_limit, tsize, GFP_KERNEL); - if (!d->mbm_local) { - bitmap_free(d->rmid_busy_llc); - kfree(d->mbm_total); - return -ENOMEM; - } + + if (resctrl_is_mbm_enabled() && r->mon.mbm_cntr_assignable) { + tsize = sizeof(*d->cntr_cfg); + d->cntr_cfg = kcalloc(r->mon.num_mbm_cntrs, tsize, GFP_KERNEL); + if (!d->cntr_cfg) + goto cleanup; } return 0; +cleanup: + bitmap_free(d->rmid_busy_llc); + for_each_mbm_idx(idx) { + kfree(d->mbm_states[idx]); + d->mbm_states[idx] = NULL; + } + + return -ENOMEM; } int resctrl_online_ctrl_domain(struct rdt_resource *r, struct rdt_ctrl_domain *d) @@ -4144,7 +4303,7 @@ int resctrl_online_mon_domain(struct rdt_resource *r, struct rdt_mon_domain *d) RESCTRL_PICK_ANY_CPU); } - if (resctrl_arch_is_llc_occupancy_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) INIT_DELAYED_WORK(&d->cqm_limbo, cqm_handle_limbo); /* @@ -4219,7 +4378,7 @@ void resctrl_offline_cpu(unsigned int cpu) cancel_delayed_work(&d->mbm_over); mbm_setup_overflow_handler(d, 0, cpu); } - if (resctrl_arch_is_llc_occupancy_enabled() && + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID) && cpu == d->cqm_work_cpu && has_busy_rmid(d)) { cancel_delayed_work(&d->cqm_limbo); cqm_setup_limbo_handler(d, 0, cpu);  index 6fb4894b8cfd1f..a7d92718b653f5 100644  --- a/  +++ b/ diff --git a/include/linux/resctrl.h b/include/linux/resctrl.hindex 6fb4894b8cfd1f..a7d92718b653f5 100644--- a/ include/linux/resctrl.h +++ b/ include/linux/resctrl.h @@ -157,27 +157,42 @@ struct rdt_ctrl_domain { }; /** + * struct mbm_cntr_cfg - Assignable counter configuration. + * @evtid: MBM event to which the counter is assigned. Only valid + * if @rdtgroup is not NULL. + * @rdtgrp: resctrl group assigned to the counter. NULL if the + * counter is free. + */ +struct mbm_cntr_cfg { + enum resctrl_event_id evtid; + struct rdtgroup *rdtgrp; +}; + +/** * struct rdt_mon_domain - group of CPUs sharing a resctrl monitor resource * @hdr: common header for different domain types * @ci_id: cache info id for this domain * @rmid_busy_llc: bitmap of which limbo RMIDs are above threshold - * @mbm_total: saved state for MBM total bandwidth - * @mbm_local: saved state for MBM local bandwidth + * @mbm_states: Per-event pointer to the MBM event's saved state. + * An MBM event's state is an array of struct mbm_state + * indexed by RMID on x86 or combined CLOSID, RMID on Arm. * @mbm_over: worker to periodically read MBM h/w counters * @cqm_limbo: worker to periodically read CQM h/w counters * @mbm_work_cpu: worker CPU for MBM h/w counters * @cqm_work_cpu: worker CPU for CQM h/w counters + * @cntr_cfg: array of assignable counters' configuration (indexed + * by counter ID) */ struct rdt_mon_domain { struct rdt_domain_hdr hdr; unsigned int ci_id; unsigned long *rmid_busy_llc; - struct mbm_state *mbm_total; - struct mbm_state *mbm_local; + struct mbm_state *mbm_states[QOS_NUM_L3_MBM_EVENTS]; struct delayed_work mbm_over; struct delayed_work cqm_limbo; int mbm_work_cpu; int cqm_work_cpu; + struct mbm_cntr_cfg *cntr_cfg; }; /** @@ -256,39 +271,52 @@ enum resctrl_schema_fmt { }; /** + * struct resctrl_mon - Monitoring related data of a resctrl resource. + * @num_rmid: Number of RMIDs available. + * @mbm_cfg_mask: Memory transactions that can be tracked when bandwidth + * monitoring events can be configured. + * @num_mbm_cntrs: Number of assignable counters. + * @mbm_cntr_assignable:Is system capable of supporting counter assignment? + * @mbm_assign_on_mkdir:True if counters should automatically be assigned to MBM + * events of monitor groups created via mkdir. + */ +struct resctrl_mon { + int num_rmid; + unsigned int mbm_cfg_mask; + int num_mbm_cntrs; + bool mbm_cntr_assignable; + bool mbm_assign_on_mkdir; +}; + +/** * struct rdt_resource - attributes of a resctrl resource * @rid: The index of the resource * @alloc_capable: Is allocation available on this machine * @mon_capable: Is monitor feature available on this machine - * @num_rmid: Number of RMIDs available * @ctrl_scope: Scope of this resource for control functions * @mon_scope: Scope of this resource for monitor functions * @cache: Cache allocation related data * @membw: If the component has bandwidth controls, their properties. + * @mon: Monitoring related data. * @ctrl_domains: RCU list of all control domains for this resource * @mon_domains: RCU list of all monitor domains for this resource * @name: Name to use in "schemata" file. * @schema_fmt: Which format string and parser is used for this schema. - * @evt_list: List of monitoring events - * @mbm_cfg_mask: Bandwidth sources that can be tracked when bandwidth - * monitoring events can be configured. * @cdp_capable: Is the CDP feature available on this resource */ struct rdt_resource { int rid; bool alloc_capable; bool mon_capable; - int num_rmid; enum resctrl_scope ctrl_scope; enum resctrl_scope mon_scope; struct resctrl_cache cache; struct resctrl_membw membw; + struct resctrl_mon mon; struct list_head ctrl_domains; struct list_head mon_domains; char *name; enum resctrl_schema_fmt schema_fmt; - struct list_head evt_list; - unsigned int mbm_cfg_mask; bool cdp_capable; }; @@ -372,8 +400,29 @@ u32 resctrl_arch_get_num_closid(struct rdt_resource *r); u32 resctrl_arch_system_num_rmid_idx(void); int resctrl_arch_update_domains(struct rdt_resource *r, u32 closid); +void resctrl_enable_mon_event(enum resctrl_event_id eventid); + +bool resctrl_is_mon_event_enabled(enum resctrl_event_id eventid); + bool resctrl_arch_is_evt_configurable(enum resctrl_event_id evt); +static inline bool resctrl_is_mbm_event(enum resctrl_event_id eventid) +{ + return (eventid >= QOS_L3_MBM_TOTAL_EVENT_ID && + eventid <= QOS_L3_MBM_LOCAL_EVENT_ID); +} + +u32 resctrl_get_mon_evt_cfg(enum resctrl_event_id eventid); + +/* Iterate over all memory bandwidth events */ +#define for_each_mbm_event_id(eventid) \ + for (eventid = QOS_L3_MBM_TOTAL_EVENT_ID; \ + eventid <= QOS_L3_MBM_LOCAL_EVENT_ID; eventid++) + +/* Iterate over memory bandwidth arrays in domain structures */ +#define for_each_mbm_idx(idx) \ + for (idx = 0; idx < QOS_NUM_L3_MBM_EVENTS; idx++) + /** * resctrl_arch_mon_event_config_write() - Write the config for an event. * @config_info: struct resctrl_mon_config_info describing the resource, domain @@ -416,6 +465,26 @@ static inline u32 resctrl_get_config_index(u32 closid, bool resctrl_arch_get_cdp_enabled(enum resctrl_res_level l); int resctrl_arch_set_cdp_enabled(enum resctrl_res_level l, bool enable); +/** + * resctrl_arch_mbm_cntr_assign_enabled() - Check if MBM counter assignment + * mode is enabled. + * @r: Pointer to the resource structure. + * + * Return: + * true if the assignment mode is enabled, false otherwise. + */ +bool resctrl_arch_mbm_cntr_assign_enabled(struct rdt_resource *r); + +/** + * resctrl_arch_mbm_cntr_assign_set() - Configure the MBM counter assignment mode. + * @r: Pointer to the resource structure. + * @enable: Set to true to enable, false to disable the assignment mode. + * + * Return: + * 0 on success, < 0 on error. + */ +int resctrl_arch_mbm_cntr_assign_set(struct rdt_resource *r, bool enable); + /* * Update the ctrl_val and apply this config right now. * Must be called on one of the domain's CPUs. @@ -528,6 +597,63 @@ void resctrl_arch_reset_rmid_all(struct rdt_resource *r, struct rdt_mon_domain * */ void resctrl_arch_reset_all_ctrls(struct rdt_resource *r); +/** + * resctrl_arch_config_cntr() - Configure the counter with its new RMID + * and event details. + * @r: Resource structure. + * @d: The domain in which counter with ID @cntr_id should be configured. + * @evtid: Monitoring event type (e.g., QOS_L3_MBM_TOTAL_EVENT_ID + * or QOS_L3_MBM_LOCAL_EVENT_ID). + * @rmid: RMID. + * @closid: CLOSID. + * @cntr_id: Counter ID to configure. + * @assign: True to assign the counter or update an existing assignment, + * false to unassign the counter. + * + * This can be called from any CPU. + */ +void resctrl_arch_config_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + enum resctrl_event_id evtid, u32 rmid, u32 closid, + u32 cntr_id, bool assign); + +/** + * resctrl_arch_cntr_read() - Read the event data corresponding to the counter ID + * assigned to the RMID, event pair for this resource + * and domain. + * @r: Resource that the counter should be read from. + * @d: Domain that the counter should be read from. + * @closid: CLOSID that matches the RMID. + * @rmid: The RMID to which @cntr_id is assigned. + * @cntr_id: The counter to read. + * @eventid: The MBM event to which @cntr_id is assigned. + * @val: Result of the counter read in bytes. + * + * Called on a CPU that belongs to domain @d when "mbm_event" mode is enabled. + * Called from a non-migrateable process context via smp_call_on_cpu() unless all + * CPUs are nohz_full, in which case it is called via IPI (smp_call_function_any()). + * + * Return: + * 0 on success, or -EIO, -EINVAL etc on error. + */ +int resctrl_arch_cntr_read(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 closid, u32 rmid, int cntr_id, + enum resctrl_event_id eventid, u64 *val); + +/** + * resctrl_arch_reset_cntr() - Reset any private state associated with counter ID. + * @r: The domain's resource. + * @d: The counter ID's domain. + * @closid: CLOSID that matches the RMID. + * @rmid: The RMID to which @cntr_id is assigned. + * @cntr_id: The counter to reset. + * @eventid: The MBM event to which @cntr_id is assigned. + * + * This can be called from any CPU. + */ +void resctrl_arch_reset_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 closid, u32 rmid, int cntr_id, + enum resctrl_event_id eventid); + extern unsigned int resctrl_rmid_realloc_threshold; extern unsigned int resctrl_rmid_realloc_limit;  index a25fb9c4070d3c..acfe07860b346c 100644  --- a/  +++ b/ diff --git a/include/linux/resctrl_types.h b/include/linux/resctrl_types.hindex a25fb9c4070d3c..acfe07860b346c 100644--- a/ include/linux/resctrl_types.h +++ b/ include/linux/resctrl_types.h @@ -34,11 +34,18 @@ /* Max event bits supported */ #define MAX_EVT_CONFIG_BITS GENMASK(6, 0) -/* - * Event IDs, the values match those used to program IA32_QM_EVTSEL before - * reading IA32_QM_CTR on RDT systems. - */ +/* Number of memory transactions that an MBM event can be configured with */ +#define NUM_MBM_TRANSACTIONS 7 + +/* Event IDs */ enum resctrl_event_id { + /* Must match value of first event below */ + QOS_FIRST_EVENT = 0x01, + + /* + * These values match those used to program IA32_QM_EVTSEL before + * reading IA32_QM_CTR on RDT systems. + */ QOS_L3_OCCUP_EVENT_ID = 0x01, QOS_L3_MBM_TOTAL_EVENT_ID = 0x02, QOS_L3_MBM_LOCAL_EVENT_ID = 0x03, @@ -47,4 +54,7 @@ enum resctrl_event_id { QOS_NUM_EVENTS, }; +#define QOS_NUM_L3_MBM_EVENTS (QOS_L3_MBM_LOCAL_EVENT_ID - QOS_L3_MBM_TOTAL_EVENT_ID + 1) +#define MBM_STATE_IDX(evt) ((evt) - QOS_L3_MBM_TOTAL_EVENT_ID) + #endif /* __LINUX_RESCTRL_TYPES_H */
    株式会社バルテック（本社：東京都新宿区）のグループ会社、株式会社バルテックフィールドサービス（本社：東京都新宿区）が運営する中古パソコンの販売サイト「PCバル」（https://www.smaphodock24.jp/used/）では、2025年10月14日に控えたWindows10サポート終了を踏まえ、パソコンの乗り換えが必要なユーザー様に向け開催中の『Windows11乗り換え応援フェア』、好評のフェア限定商品に第３弾として、税込19,800円の富士通LIFEBOOK Aシリーズを15台追加!!  限定15台・税込19,800円 富士通LIFEBOOK Aシリーズはこちら  １． 全台システム要件適合・1,000台以上のWindows11搭載PC  コスパ重視の第8世代からハイスペックの第12・第13世代まで幅広いラインナップのWindows11搭載中古パソコンをご用意!  もちろんパソコン修理店が母体のPCバルならでは、独自の検査基準・項目に基づき状態をチェック後入念に整備しているので、安心してお使いいただけます!  Windows11搭載中古ノートパソコン  Windows11搭載中古デスクトップパソコン  2． 乗り換えフェア限定・特別価格Windows11搭載中古パソコン  さらに! 期間中はPCバルが特選した中古パソコンをフェア限定商品としてサプライズ価格で続々とご提供! PCバルは価格でも皆様のWindows11乗り換えを応援します!!  Window11乗り換え応援フェア限定商品はこちら  新たに登場したフェア限定商品第3弾・ワンプライス19,800円でお届けする人気の富士通Aシリーズを限定15台!!  新着・税込19,800円 富士通LIFEBOOK Aシリーズ 15.6インチはこちら  ☆第8世代Core i5＋8GBメモリで快適動作、実用性の高さが魅力の15.6インチPC  大好評であっという間に売れたワンプライス18,150円のマウス製ノートPC・まだ少々在庫がありますので、こちらも要チェックで!  残り僅か・税込18,150円 MOUSE MPro-NB391H-SSD 13.3インチ/MPro-NB510H 15.6インチ  ☆第8世代Core i5＋Mem8GB(1台だけ16GBモデルあり)＋SSD 240GB~1TB  他にも多彩なフェア限定商品をご用意していますのでお見逃しなく! !  税込22,222円 Lenovo ThinkPad X390 LTE 13.3 Intel Core i5-8265U 8GB  ☆コスパ最重視でWin11搭載PCを選ぶなら! 第8世代CPUで軽作業なら楽々♪  税込54,321円 HP ELITE DRAGONFLY G2 Intel Core i5-1135G7 13.3 8GB  ☆第11世代CPU搭載、スタイリッシュなブルーが印象的な人気機種  税込67,890円 DELL Inspiron 5415 14 AMD Ryzen 7-5700U 8GB  ☆高いマルチコア性能でクリエイティブワークの強い味方・RYZEN 7搭載！  第8世代X1カーボンや第10世代LIFEBOOK Uシリーズなど他にも人気機種をサプライズ価格でご用意しておりますが、いずれも数に限りがありますので、ぜひお早めに!  3． 選べる2つの特典で乗り換え応援!  期間中にフェア限定商品をご成約の方には、MS Officeと高い互換性なのにリーズナブルな価格で人気のキングソフト製定番オフィスソフト『WPS Office 2 Standard Edition』をもれなくプレゼント!  さらに、PCバル各店とWEBSHOPでそれぞれ特典をご用意!  【PCバル各店店頭でのご購入】  PCバル各店店頭でフェア限定商品をご購入のお客様には、今お使いのパソコンからデータのお引越し(データ移行)を、通常の50%OFFでご提供!  大事なデータがあるからパソコンを換えるのは抵抗が…という心配はご無用です。  ご希望のお客様は店頭ご購入時に店頭でお申し付けください。  【PCバルWEBSHOPでのご購入】  PCバルWEBSHOP でフェア限定商品をご購入のお客様には、WPS Office 2に加え、ウイルス＆フィッシング対策・システムメンテナンスを1つでこなす『セキュリティPro』(キングソフト製)をプレゼント!  ■「PCバル」3つの安心  （https://www.smaphodock24.jp/used/）  １．専門店ならではのこだわり  取扱商品は仕入れ後にパソコン整備士の資格を持ったスタッフが、独自の検査基準・項目に基づき状態をチェック後入念に整備。長く使える・故障の少ない状態でお届けできるようメンテナンスした上で販売しています。安定性と体感速度に影響するコンポーネンツはSSD＋RAMメモリ8GB以上を標準構成※とし、プロが手掛けたリフレッシュPCとして高度化・高速化するパソコンの使用環境に対応しお客様満足度の向上を目指しています。  ※一部標準構成外の商品もございます。  ２．お客様に寄り添った情報掲載・商品説明  写真と説明だけで選ぶネットの商品でも安心してお選びいただけるよう、スペック情報だけでなく「動作には問題ないものの、細かなキズや使用感がある部分など…」といった状態も丁寧にご案内しています。  店頭展示品についても、スタッフが実物をご案内しながら、納得いただけるようわかりやすくご説明しています。  ３．安心保証&充実サポート  購入時から最大6ヶ月間の保証※が中古PCに付いてくる！パソコン修理専門店を10年以上全国に展開するPCバルならではの修理技術が可能にする手厚いサポートです。保証期間内中の修理ではお客様の費用負担はゼロ(適用条件あり)！ 保証期間終了後に故障が発生した場合でも、症状状態ご予算に応じ当社の技術スタッフが最善のご提案を致します。  ※中古PCの保証適用条件はWEB保証書へのアクセスまたは(紙)保証書でご確認ください。  ※商品により保証期間が異なります。詳しくは各商品ページをご確認ください。  ◆会社概要  □株式会社バルテック  事業内容：ICT機器及びソフトウェアの開発・製造・管理  設立： 1993年3月23日  所在地：〒163-1103 東京都新宿区西新宿6-22-1 新宿スクエアタワー3階  URL：https://www.webjapan.co.jp/  □株式会社バルテックフィールドサービス  事業内容：ICT機器及びソフトウェアの施工、保守、修理  パソコン修理サービス店のフランチャイズ展開  URL：https://www.smaphodock24.jp/
    If you happen to be on the hunt for a new laptop, whether that’s because you’re a student in need of something to complete assignments, a small business owner looking to handle your business needs, or just some guy looking to watch YouTube and draw pictures, come check out the Dell Inspiron 15. This laptop has a touchscreen and is bundled with some bonus accessories. The Amazon listing has the full price set at $2,200, but the limited time deal indicates its been marked down by 64% to just $800. Some quick napkin math will tell you that’s a $1,400 discount.  You might be thinking that’s absolutely ridiculous. How can this laptop be on sale for that much off? Well, you’re right to be suspicious. When we look at this bundle’s price history, we can see it has only existed on Amazon for about a month. After first being listed, it immediately dropped in price and it’s mostly been at that $800 amount since.  See at Amazon  Lots of sellers on Amazon will artificially inflate the list price so that when they mark it down, the sale looks enormous. Even if we go to Dell’s website, we’ll find versions of this model laptop going for about the same as you find it here. All that said, this is a pretty good value.  What you’re getting is a 15.6-inch touchscreen laptop that’s powered by the AMD Ryzen 7 7730U. With that we also have an integrated graphics card, 32GB of memory, and a full 1TB of internal storage on its SSD. This laptop is designed to be able to take on school, work, entertainment, and any other sort of everyday task an average user might encounter — and it’s got the specs to support that.  The screen’s touch controls allow you to operate the laptop as if it’s a tablet, choosing to use pinch, zoom, and swipe gestures like you would on a mobile device. It has a resolution of 1080p and uses an anti-glare coating to help minimize reflections, making for more comfortable viewing in bright settings.  Bonus Gifts Included  Along with the laptop, you also get a number of free accessories. This Dell Inspiron 15 comes with a stylus pen to be used on the touchscreen, a cleaning clothe, a laptop sleeve for traveling, a USB flash drive with 128GB on it, as well as some port covers and webcam covers. Plus, the laptop comes pre-installed with Windows 11 Pro.  Right now, you can get the Dell Inspiron 15 and all these goodies for just $800.  See at Amazon
    IREN Limited (NASDAQ:IREN) is one of the best performing ASX stocks in 2025. On September 22, the company said it had doubled its GPU fleet to 23,000 units after acquiring 12,400 more GPUs for about $674 million. The expanded fleet now includes a mix of NVIDIA H100s & H200s (1,900), NVIDIA B200s & B300s (19,100), NVIDIA GB300s (1,200), and AMD MI350Xs (1,100).  IREN (IREN) Doubles GPU Fleet to 23,000, Raises Revenue Target  IREN raised its annualized run-rate revenue (ARR) target for its AI Cloud segment to more than $500 million by the end of Q1 2026. The company previously targeted 10,900 GPUs by year-end, but strong market demand led to a larger fleet and a higher ARR goal. It now plans to support up to 60,000 GPUs, especially at its British Columbia sites.  The management expects that the GPU investments will bolster long-term revenue and improve operational efficiency. It is particularly banking on the Blackwell architecture, which offers improvements in AI performance and energy efficiency. Deliveries and deployment will occur at the Prince George campus and other facilities in British Columbia.  IREN Limited (NASDAQ:IREN) is a sustainable Bitcoin mining and AI infrastructure company. It develops and operates large-scale data centers powered by renewable energy, with major facilities in Texas and British Columbia. Its main products are mined bitcoin and high-performance AI cloud services.  While we acknowledge the potential of IREN as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.  READ NEXT: Conservative Stock Portfolio: 11 Best Stocks to Buy Now and 10 Best Performing Penny Stocks to Buy Now.  Disclosure: None. This article is originally published at Insider Monkey.

    ### Intel ###
    China's Zhaoxin breaks into healthcare: 6,000+ hospital PCs run x86 chips against Intel, AMD  Shanghai Zhaoxin Semiconductor has scored a breakthrough in China's healthcare sector. On September 23, the x86 chipmaker announced that over 6,000 of its processor-powered desktops won a major hospital procurement bid, an important step for Chinese x86 CPUs in mission-critical medical deployments.  China's healthcare system is in the midst of rapid digital transformation, with ambitious goals to modernize core hospital information systems by 2025. The transition requires computing platforms that are both powerful and easy to deploy, critical traits in an industry long burdened by fragmented IT ecosystems.  China's healthcare IT fragmentation  Fragmentation remains one of healthcare IT's biggest challenges. Core systems such as hospital information systems (HIS), laboratory information systems (LIS), and picture archiving and communication systems (PACS) still depend on foreign databases like Oracle and SQL Server, which command over 80% market share. Domestic databases account for less than 15%, and migrating decades of records is complicated by format incompatibility and strict real-time demands.  At one leading provincial hospital, 40% of legacy HIS systems still run on outdated VB6 architecture, with upgrades costing up to CNY800,000 (approx. US$112,500) per system. Provinces are now piloting phased adaptation, rushing "emergency fixes" for critical platforms like PACS, while allowing a three-year transition for non-core systems such as office software. The dual-track approach underscores the clash between policy mandates and technical realities.  Smaller hospitals face even sharper challenges: nearly 30% of their systems are too old to run domestic operating systems or new applications, leaving them stuck between costly legacy reuse and risky data migration.  Zhaoxin's processor ecosystem strategy  Zhaoxin is tackling these pain points with processors that combine compatibility and performance. The firm has independently developed six generations of high-performance CPUs, including the KaiXian desktop and KaiSheng server lines, with products spanning AI PCs, desktops, notebooks, all-in-ones, servers, and embedded platforms.  The chips support both domestic operating systems: UnionTech Software UOS, NeoKylin, Zhongkefangde Software, and Microsoft Windows. They are compatible with mainstream applications, cloud platforms, databases, development tools, and AI models, while keeping software migration costs low.  For healthcare, Zhaoxin has introduced "seamless migration" and "one-stop support" solutions. It has also set up medical application innovation centers with partners, offering hospitals end-to-end guidance from chips to operating systems and applications.  Today, Zhaoxin works with nearly 4,000 partners across systems integration, software, and hardware. Together with domestic OS vendors, it has completed more than 200,000 software-hardware adaptation projects, building a full-stack ecosystem from processors to databases and applications.  From 2022 to 2024, Zhaoxin recorded revenues of CNY340 million, CNY555 million, and CNY889 million, respectively, with a compound annual growth rate of 61.71%.  Rivaling Intel and AMD in hospitals  Beating out Intel and AMD in a high-profile bid highlights Zhaoxin's progress in performance, compatibility, and cost efficiency. Its processors are built to handle demanding healthcare workloads — from electronic medical records to telemedicine platforms — while maintaining stable operations.  With integrated security, Zhaoxin CPUs protect patient data across its lifecycle: collection, transmission, storage, and use. This meets China's strict compliance standards, as hospitals lean on secure, high-performance platforms for data-heavy applications.  As digitalization accelerates, medical data will expand from text records and lab reports to imaging archives and real-time vital signs. Zhaoxin's processors can manage these workloads, minimizing downtime and enabling use cases such as AI diagnostics and cross-regional data sharing.  China's x86 chips gain traction  The hospital bid underscores the rising role of Chinese x86 chips in public welfare sectors. By offering strong performance and ecosystem compatibility, Zhaoxin is gaining ground in healthcare digitalization, an arena once dominated by foreign technology.  If sustained, these gains could speed the localization of hospital IT infrastructure, supporting China's drive for tech independence while laying the groundwork for smarter, more secure healthcare systems.  Article edited by Jack Wu
    Qualcomm’s scintillating new Snapdragon X2 Elite chips have prompted a ton of conversations in the past few days. Can they make it? What do you like about them? And so on.  While I can’t say whether or not the Snapdragon X2 Elite and Elite Extreme will eventually succeed, I can offer you an inside look at what people are talking about–at least what I’ve heard and overheard–at Qualcomm’s Snapdragon Summit in Hawaii. If you want to catch up on all the news, the Snapdragon X2 and X2 Elite offer more cores at up to 5GHz speeds, includes optional embedded memory, and preserves the performance on battery from the first generation.  The good: eye-watering performance  If you want a general-purpose productivity laptop, the first-generation Snapdragon X Elite was nearly perfect. The new X2 Elite Extreme looks to be even better, with (controlled) benchmarks that simply blow away Intel’s Core Ultra (Lunar Lake) and AMD’s Ryzen AI 300 chips, from CPU to GPU to the AI-enabling NPU. Qualcomm is really doing almost everything consumers are asking of it in this space.  The CPU benchmarks look particularly juicy. Compared against rival chips in today’s laptops, the Snapdragon X2 Elite absolutely smokes all comers in the Cinebench benchmark beloved by reviewers, in both single- and multi-core tests.  Mark Hachman / Foundry  And the Snapdragon X2 Elite’s NPU offers a whopping 80 TOPs, leaving the competition in the dust. Whether consumers are asking for more TOPS from an NPU, though, is a question mark.  Roughly doubling the TOPS from the first version looks great on paper, and certainly bigger numbers are better. But there’s a lot being bet on whether consumer applications will be able to take advantage of its prowess, including this concept of agentic AI everyone is talking about. No one is still quite sure whether that will happen.  UL’s Procyon Computer Vision benchmark tests AI inference performance and can tap into NPUs, unlike some other AI benchmarks. Mark Hachman / Foundry  It depends on how you see it: Is local AI still a selling point? Either way, the Snapdragon X2 Elite appears loaded with hardware capable of blasting through most of the tasks you throw at it, AI or not.  The bad: Lukewarm PC vendor support, games, and lack of battery life talk  I couldn’t help but notice that only Asus and HP endorsed the Snapdragon X2 architecture, and via video to boot — not in person at the Snapdragon Summit. The odd “agentic AI” Humain Horizon Pro laptop (which won’t use the X2, but the X1) was there, but not Qualcomm’s established customers. And where was longtime Qualcomm backer, Lenovo?  Sure, new partners could always be announced. But I had questions.  Another question: 3D graphics performance. Yes, supposedly the Snapdragon X2 Elite about doubles the performance of the first-gen X Elite platform, which played (some) games at roughly 30 frames per second at 1080p Low performance. Doubling that is, what, 60 fps at the same resolution and image quality? What about all the games that simply refuse to run well on the first-gen Snapdragon chips?  On the more enthusiast end of things, “there’s nothing preventing” the Snapdragon X2 from connecting to a discrete GPU like Nvidia’s GeForce RTX, according to Qualcomm’s senior vice president Kedar Kondap…but it doesn’t appear like it has, or will. This is a tough one: Gaming is often seen as a high-profile design win, and proof that a chip like the X2 Elite should be seen as a sexy, high-margin gaming CPU. But doing so would immediately cut into a key Snapdragon benefit: long battery life.  Gaming on a phone, weirdly, seems more viable with a Qualcomm Snapdragon processor than on a PC. Qualcomm  And that was weird, too: Qualcomm really downplayed the battey life of a Snapdragon X2 laptop, referring it to “multi-day” on a couple of occasions. I’m not sure if that was because the competitive landscape had erased that advantage, or what. But it simply was not a big focus.  Again, Qualcomm does have a cross to bear in its Arm legacy, and how that affects application compatibility. This only really affects some weird, dusty old business utilities, the occasional printer, and games. But games are the one area where it can make inroads, though Snapdragon simply can’t offer the “it just works” assurance of its X86 rivals anytime soon.  The ugly: A grab bag  Naturally, any new launch offers opportunities for criticism.  Not only did people take issue with the Microsoft-esque naming scheme — the X2 Elite Extreme, really?! — critics made the very valid point that this was Qualcomm’s first major architecture launch in years. Reviewers got hands-on tests of the X1 Elite two long years ago, in October 2023, ahead of the Snapdragon’s launch alongside Copilot+ PCs in May 2024. Qualcomm followed it up with the cut-down X1 Plus and X in the interim.  As one attendee pointed out, “You can’t play on that timetable and expect to win against Intel and AMD,” which launch a new or updated mobile chip architecture on an annual cadence.  Intel has been talking about Panther Lake for months…and has already shown more demo systems than Qualcomm has for the X2 Elite. Adam Patrick Murray / Foundry  Qualcomm’s X1 Elite also signaled to Intel and AMD that those rivals needed to have their own chips in order. But tying Snapdragon X to Copilot+ and Microsoft’s beleaguered Recall didn’t do much for Qualcomm, if anything. Qualcomm was the flag-bearer for Windows on Arm, and its (now largely undeserved) reputational concerns about app compatibility. Then Intel’s Lunar Lake came along, and offered a very competitive — and maybe even better — chip without any of that baggage.  One laptop maker told me that they had bought into the original X1 Elite in part as a bargaining chip with Intel. People had a lot of questions about what that meant for Intel’s upcoming “Panther Lake” chip, which should be unveiled this fall.  In my personal opinion, one of the best things Qualcomm ever did was to simply offer a compelling third option to Intel and AMD. That means we all benefited from an competitive market for PC processors that only continues to heat up.  Disclosure: Qualcomm held its press briefings in Hawaii, and would not pre-brief reporters in other locations or over video meetings. They paid for my room, boarding, and travel expenses, but did not ask for or exert any editorial control over this story or other PCWorld content.
    The Error Detection And Correction "EDAC" subsystem continues seeing a lot of new hardware support and code churn across AMD, Intel, and Arm hardware platforms for the Linux kernel. With Linux 6.18 there are several notable additions.A new EDAC driver for Linux 6.18 is "a72_edac" as EDAC support for the Arm Cortex-A72 . While the Arm Cortex-A72 cores have been out for years, with Linux 6.18 there is finally this EDAC driver for being able to report L1 and L2 cache errors with the mainline kernel.Another new EDAC driver for Linux 6.18 is for the AMD Versal NET DDR memory controller for these AMD-Xilinx Versal SoCs.Also on the AMD side, and as noted in the earlier article about the many AMD CPU features in Linux 6.18 , there are a number of new AMD CPU models added to the AMD64 EDAC driver. As explained there the new CPU support appears to include both next-gen AMD EPYC Zen 6 processors with up to 16 memory channels as well as some unreleased Family 26 models limited to 8 memory channels -- perhaps next-gen AMD EPYC 8004 parts?  On the Intel side, there is support for two more Alder Lake S SoCs added to the ie31200_edac driver. Those Alder Lake S parts added are the Intel Core i7-12700K and Core i5-12600K processors that were mistakenly left out of the driver previously for those prior-generation CPUs.The Intel EDAC driver code has also become more flexible for better handling the addition of new generations of CPUs with more memory controllers.More details on all of the EDAC feature changes for Linux 6.18 via this pull request
    Wall Street benchmarks witnessed a slippery start on Tuesday, with investor sentiment taking a hit on US Vice President JD Vance's indication of a government shutdown.  An hour into trade, the Dow Jones Industrial Average saw a decline of 0.18%, the S&P 500 was also down 0.14% while Nasdaq fell 0.10%.  The uncertainty comes as the S&P 500 is headed for its best September in 15 years, fuelled by looser policy and optimism over artificial intelligence as per news agency Bloomberg.  “The main focus will be the US labor market, which should either confirm or challenge expectations of two more rate cuts in 2025,” said Susana Cruz, a strategist at Panmure Liberum told Bloomberg. “If the shutdown delays the release, that could spark some anxiety.”  Six of the 11 sectoral indices was trading in green. Energy sector led the decline, while the healthcare sector led the advancing sectors.  Nvidia Corp., Palantir Technologies, and Alibaba ADR were amongst the gainers for the day. On the other hand, Tilray Inc., Intel Corp., and Tesla were in the red.  Spot gold rose 0.34% to $3,847.03 an ounce after paring record highs. After surging more than 10% this month on optimism over US interest rate cuts and haven demand, traders speculated that Chinese investors pared exposure ahead of the Golden Week holiday, as per Bloomberg.  Crude oil prices slipped, with the West Texas trading 1.77% lower at $62.33 per barrel.  The Bloomberg Dollar Index fell 0.16%, with the British Pound rising 0.15% at $1.3449 and the Japanese yen down to 147.82 per dollar. Bitcoin, the largest traded cryptocurrency saw a decline of 0.95% to $113,233.9700.  As the US market opened, the Dow Jones Industrial Average fell 12 points or 0.03%, the S&P 500 was also down 0.12% while Nasdaq fell 0.22% or nearly 50 points.
    LIVE  Stock Market News Today: Dow Set to Open Down Amid Government Shutdown Risk  The S&P 500 and the Nasdaq are also falling in premarket trading. Treasury yields are down and Bitcoin prices are up.  Last Updated:  Sep. 30, 2025 at 4:00 AM ET  Key Events  Latest Updates  Stock futures were…  This story appeared on barrons.com , 2025-09-30 07:24:23.
    Jon Hicks/Stone/Getty Images  Follow ZDNET: Add us as a preferred source on Google.  ZDNET's key takeaways  Linux 6.17 features significant CPU improvements.  It addresses the eternal Spectre and Meltdown security holes.  The next release, 6.18, will be a long-term support kernel.  Linus Torvalds is the first to admit that there have been more exciting Linux kernel releases. He announced the release of the 6.17 Linux kernel by writing, "It's not exciting, which is all good. I think the biggest patch in there is some locking fixes for some Bluetooth races that could cause use-after-free situations. Whee -- that's about as exciting as it gets."  Also: 5 of my favorite Linux distros ready to use out of the box - no setup required  With that said, 6.17 does come with some notable performance boosts, expanded hardware support, and a medley of improvements aimed at server, desktop, and embedded systems.  The most important of these improvements is for the AMD Ryzen chip. By delivering improved hardware feedback scheduling for Ryzen chips via the new Hardware Feedback Interface (HFI) driver, hybrid-core laptops and desktops will be more intelligent in handling workload distribution with SmartMux support. The feature works by auto-switching between integrated and discrete graphics based on your workload. So, depending on what you're doing, it can either save power or boost your performance as needed.  Also: Is this Arch distro the 'ultimate' Linux? That depends on your GPU  Meanwhile, Intel-powered computers are gaining better graphics support. That's especially true for the forthcoming Xe3 (Panther Lake) systems. You'll see these chips in Core Ultra Series 3 laptops by the holidays. Early tests indicated that Linux desktop gamers can expect significant speed improvements in some of their favorite games. Linux 6.17 also comes with Error Detection and Correction (EDAC) support for Intel's Bartlett Lake processors. EDAC is the mechanism used to spot, report, and correct memory errors.  Not every processor will see improvements with 6.17. Some proposed RISC-V patches ticked off Torvalds because they were both late and poorly written. He described them as: "Garbage. And by 'garbage,' I really mean it. This is stuff that nobody should ever send me, never mind late in a merge window." Better luck next release, folks.  This release also revamps CPU vulnerability management by unifying kernel command-line mitigation options for ancient security holes, such as Spectre and Meltdown. Despite their age, these security problems persist. The new kernel makes it easier for server administrators to streamline performance tweaks and security controls.  On the storage front, Btrfs gains experimental large-folio support for efficient memory access. In the same release, the most popular Linux file system, Ext4, introduces buffered I/O control. Two new system calls, file_getattr() and file_setattr(), are included for advanced inode file system attribute management.  Also: I install these 11 apps on every new Linux system, and you should, too - here's why  For networking, the enhancements include new gateway routing for the Management Component Transport Protocol (MCTP), expansion of the multipath TCP feature, and added support for the DualPI2 congestion control protocol.  Linux 6.17 is not a long-term support (LTS) release. Users who require extended support can stick to 6.12 or wait for the anticipated 6.18 LTS milestone.  Also: How much RAM does your Linux PC really need in 2025? I did the math so you don't have to  Distributions such as the forthcoming Ubuntu 25.10, currently in beta, have already adopted 6.17 in their latest builds. You can expect to see cutting-edge, rolling distributions, such as Arch Linux, openSUSE Tumbleweed, and Fedora Rawhide, release the 6.17 kernel in the next few days and weeks.  As usual, the release opens the merge window for kernel 6.18, with dozens of pull requests queued up for review by Torvalds and the core maintainers. Since it will be an LTS release, I expect to see significant improvements in this anticipated end-of-the-year release.
    Intel’s original 64bit extensions for x86  Introduction  In the late 1900s, Intel was fully invested in Itanium (IA-64) being their future 64bit architecture.  At that time (allegedly around 1997-1998), some Intel engineers – who were more cautious than their management – built a 64bit extension for their x86 processors as a backstop. It never shipped:  Intel’s Pentium 4 had our own internal version of x86–64. But you could not use it: we were forced to “fuse it off”, meaning that even though the functionality was in there, it could not be exercised by a user.  This was a marketing decision by Intel — they believed, probably rightly, that bringing out a new 64-bit feature in the x86 would be perceived as betting against their own native-64-bit Itanium, and might well severely damage Itanium’s chances.  – Bob Colwell  AMD announced AMD64, their own 64bit extension to x86, in 1999 (and shipped it in 2003), condemning both Itanium and Intel’s own x86 extension to obscurity.  Intel implemented AMD’s design in Project Yamhill and shipped its first processors with AMD64 in 2004.  How did Intel’s design look like?  While AMD’s 64bit extension design that repurposed inc/dec instructions as the REX prefix is well-documented, there is very little known about Intel’s own 64bit extension design.  Here is what can be reconstructed from Intel’s patent applications from 2000 and 2003:  An instruction having [a] format […] — where the mode field is 01B , the R/M field is 100B , the index field is 100B — has addressing mode information that is currently unsupported in the IA-32 architecture regardless of the value of the scale field.  An instruction of [that] format […] thereby includes heretofore unused bit fields (e.g., the two bits of scale field, bits of displacement, etc.), that can support an expanded logical register set for existing instructions formats and legacy operands.  Material from the Bristol Community College also mentions this specific combination of bits:  Note that this addressing mode does not allow the use of the ESP register as an index register.  Presumably, Intel left this particular mode undefined to provide the ability to extend the addressing modes in a future version of the CPU.  Differences from AMD64  AMD’s REX prefix introduced 1 bit R to extend the 3-bit register to 4 bits, allowing access to 16 registers.  The prefix also added 1 bit W to extend operand size, 1 bit X to extend SIB byte’s index and 1 bit B to extend SIB byte’s base.  Intel’s approach would have added 2 additional bits to the existing 3-bit register encoding, and introduced a second, additional 5-bit register encoding.  It appears this encoding would have provided a future expansion possibility to 32 registers, even if the implementation may have been limited to 16 registers at first.  It is unclear what the equivalent of (or the alternative to) AMD64’s W , X and B bits would have been under Intel’s design.  Conclusion  Sadly, there is no definitive information on how close the patents were to what was shipped (fused-off) in Intel processors of that specific time period.
    Dave Bautista & Jack Champion in 'Trap House' Action Thriller Trailer  "If we don't get 'em, the cartel will, right? And they don't forget..." Aura Entertainment has unveiled the official trailer for Trap House, an action thriller from filmmaker Michael Dowse (of Fubar, Goon, What If, Stuber, 8-Bit Christmas). This is set for a full nationwide release in November just before the Thanksgiving holiday. Dave Bautista leading this story about rogue teens getting into big trouble! Trap House is centered on a team of elite DEA agents whose rebellious teenage children use their parents' own tactics—surveillance, infiltration, non-lethal weapons, and special intel—to rob a ruthless drug cartel. Along with Dave Bautista, the movie also stars Jack Champion, Sophia Lillis, Tony Dalton, Whitney Peak, Kate Del Castillo, Zaire Adams, and Bobby Cannavale. The tagline within the trailer: "This isn't a raid. It's a reckoning." This is a totally nuts plot - the kids want to get revenge because the death benefits for a DEA agent are bad, so they decide to go rob the cartels all on their own? Yeah um that seems dangerous, remarkably dangerous.  Here's the main official trailer (+ poster) for Michael Dowse's film Trap House, direct from YouTube:  In El Paso, Texas, an undercover DEA agent (Dave Bautista) and his partner embark on a game of cat and mouse with their own teenage children, who are using their parents' tactics – surveillance, infiltration, and non-lethal weapons – to rob a dangerous drug cartel. Trap House is directed by acclaimed Canadian filmmaker Michael Dowse, director of the movies Fubar & Fubar: Balls to the Wall , It's All Gone Pete Tong, Take Me Home Tonight, Goon, What If, Stuber, Coffee & Kareem, 8-Bit Christmas, plus the TV series "Me" and "The Sticky" most recently. The screenplay is written by Gary Scott Thompson and Tom O'Connor; from a story by Gary Scott Thompson. It's produced by Dave Bautista, Rebecca Feuer, Sarah Gabriel, Marc Goldberg, Todd Lundbohm, Jonathan Meisner, Christian Mercuri, and Michael Pruss. Aura Entertainment will debut Dowse's Trap House movie in US theaters starting November 14th, 2025 this fall. Look good?
    We came across a bullish thesis on Intel Corporation on Long-term Investing’s Substack by Sanjiv. In this article, we will summarize the bulls’ thesis on INTC. Intel Corporation's share was trading at $31.22 as of September 24th. INTC’s trailing and forward P/E were 88.08 and 47.39 respectively according to Yahoo Finance.  Intel (INTC) Stock: Morgan Stanley Reiterates Equal Weight, Cautious on Turnaround  Photo by Slejven Djurakovic on Unsplash  Intel Corporation (INTC) has been navigating a turbulent period following setbacks in 2020, with the company working to regain its footing in advanced chip manufacturing. As of mid-2024, Intel had returned to leading-edge production through substantial investments, under a dual strategy of partially outsourcing manufacturing while trying to make Intel Foundry Services (IFS) profitable—a goal management does not expect to achieve until 2030.  Despite these efforts, the company’s competitive position remains challenging, particularly versus TSMC and Samsung, the dominant players in 3nm–5nm semiconductor manufacturing, and the market initially remained skeptical, with INTC shares declining sharply after disappointing Q2 results in August 2024.  Momentum shifted dramatically in 2025 following a series of strategic developments. Pat Gelsinger’s departure as CEO in March and the appointment of Lip-Bu Tan coincided with the U.S. government acquiring a 10% equity stake in Intel through undisbursed CHIPS Act grants and the Secured Enclave program, effectively designating Intel as a national champion for domestic chip production. This move was followed by major strategic investments from SoftBank and Nvidia, with Nvidia taking a $5 billion stake at $23.26 per share, signaling collaboration on AI-focused chips integrating Intel CPUs with Nvidia GPUs and expanding AI computing infrastructure.  These developments have propelled INTC shares sharply higher, with year-to-date gains of over 36% leading up to the Nvidia investment. While the market momentum is undeniable, Intel’s future performance will be influenced by government involvement in strategic decision-making and its ability to execute on these collaborations. The investment case now balances the potential upside from increased AI-related orders and strategic positioning against the complexity and uncertainty of government influence, making valuation challenging but the stock an intriguing prospect for investors watching U.S.-based semiconductor growth.  Previously we covered a bullish thesis on Intel Corporation (INTC) by DeepValue Capital in April 2025, which highlighted AI inference, domestic chip manufacturing, leadership under Lip-Bu Tan, and cost-cutting initiatives. The company's stock price has appreciated approximately by 59% since our coverage. This is because the thesis played out amid renewed investor confidence. Sanjiv shares a similar perspective but emphasizes government stakes and strategic partnerships with Nvidia and SoftBank as key catalysts.
    A rift appears to be forming in the desktop PC market, with full-size desktops on one side and mini PCs on the other side. Of course, there is small, but dedicated community that has sprung up around SFF PCs, but those are often limited, with many calling for flex PSUs and other compromises. The Wee Beastie, a new project on Kickstarter , is a small form-factor PC that hopes to cut back on the compromises, claiming to offer a powerful gaming and LLM-oriented system with an upgradeable dGPU in just 4.75 L volume—this is just 0.25 L more than the Framework Desktop PC , which uses an AMD Ryzen AI+ 395 Max with an iGPU. That said, even the pre-release Kickstarter marketing leaves some questions.The Wee Beastie Super Mini Fishtank, as it is called, is a mini PC with up to an Intel Core Ultra 7 255H CPU and NVIDIA GeForce RTX 4070 12 GB GPU. It will also be available with up to 128 GB of DDR5 RAM and a 16 TB SSD, and it boasts Wi-Fi 7 and room for up to 13 case fans. It will also contain an internal PSU capable of 400 W, which technically falls well below the 550 W we recommend for a desktop RTX 4070. Although the GPU shown on the Kickstarter page has the " AD104-251-A1" associated with the desktop variants of the RTX 4070 , the PSU output suggests that there will be some power throttling or down-tuning at play, so RTX 4070 Mobile performance might be what's to be expected here. Often, the most challenging part of projects like these, as was the case with the custom expansion modules on the Framework Laptop 16 until recently, is supporting the MXM standard for future hardware revisions. Although MXM modules are technically an open standard, like ATX, it is not commonly used due to limited demand and size constraints. Currently, the Kickstarter has completed funding, having reached $53,763 of its $2,570 goal, and the SFF PC looks to be going into production as soon as 2026.
    Hance is working on low energy-consuming, on-device processing that's already attracted the likes of Intel.  This story appeared on techcrunch.com , 2025-09-30 16:22:28.
    Other Windows 11 bug fixes  In addition to new features, here are some noteworthy bug fixes:  In File Explorer, accented backgrounds are removed in the “Open with” list, overlapping icons and text is fixed when using increased text scaling, and cloud files launch faster now.  An issue when starting Hyper-V virtual machines with TPM on Arm64 devices has been fixed.  An issue where some characters didn’t display correctly when Chinese IME was being used.  An issue where you couldn’t connect to shared files and folders when using the SMB v1 protocol over NetBT was fixed.  There is still an issue where DRM content can fail to play in Blu-ray/DVD apps (but not in streaming apps like Netflix).
    https://sputnikglobe.com/20250930/ukraine-preparing-new-high-profile-provocation--russian-intel-1122889214.html  Zelensky Preparing New High-Profile Provocation - Russian Foreign Intel  Zelensky Preparing New High-Profile Provocation - Russian Foreign Intel  Sputnik International  Russian Foreign Intelligence Service reports that the Kiev regime, after organizing provocations with UAVs in the airspace of Poland and Romania, is not abandoning its attempts to draw European NATO countries into armed confrontation with Moscow.  2025-09-30T08:45+0000  2025-09-30T08:45+0000  2025-09-30T09:22+0000  world  ukraine  russian foreign intelligence service  russia  volodymyr zelensky  kiev  poland  nato  https://cdn1.img.sputnikglobe.com/img/07e9/04/14/1121899180_0:160:3072:1888_1920x0_80_0_0_d7a560df4d542add4f92166fe5b4d4bb.jpg  "Kiev is preparing a new high-profile provocation. The Press Bureau of the Russian Foreign Intelligence Service reports that, according to information received by the Russian Foreign Intelligence Service, the Kiev regime, following its organized drone provocations in the airspace of Poland and Romania, is continuing its attempts to draw European NATO countries into an armed confrontation with Moscow. Another provocation is being developed," the SVR said in a statement.The new provocation includes a sabotage and reconnaissance group deployed to Polish territory, allegedly consisting of servicepeople from Russian and Belarusian special forces, the SVR also said, adding that the plan will be implemented by militants from the "Freedom of Russia Legion*" and the Belarusian "Kalinouski Regiment" fighting on the side of the Ukrainian armed forces.The provocation scenario was developed by the Main Intelligence Directorate of the Ukrainian Ministry of Defense jointly with Polish intelligence services, the SVR said.Kiev plans that after the "neutralization" of the sabotage and reconnaissance group by Polish security forces, its members will expose Russia and Belarus for attempting to destabilize the situation in Poland, the SVR said.*recognized as a terrorist organization, banned in Russia  https://sputnikglobe.com/20250804/russian-intel-warns-of-uk-plan-to-stage-tanker-incident-1122550775.html  ukraine  russia  kiev  poland  Sputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60  2025  Sputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60  News  en_EN  Sputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60  1920 1080 true  1920 1440 true  1920 1920 true  Sputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60  Sputnik International  high-profile provocation, russian foreign intelligence service, organizing provocations
    Austin, Sept. 30, 2025 (GLOBE NEWSWIRE) -- The Computer Vision Systems Market Size was valued at USD 19.29 billion in 2024 and is expected to reach USD 75.52 billion by 2032 and grow at a CAGR of 18.63% over the forecast period 2025-2032.  Increasing use of computer vision due to the need for automation in the logistics, manufacturing, quality control, and medical diagnostics industries. Real-time processing made possible by developments in 3D vision, high-resolution imagery, and synchronized sensors to increase accuracy in areas like gesture tracking, facial identification, object detection, and automated optical inspection are some of the noteworthy results. Organizations may implement scalable and low-latency computer vision solutions thanks to the expanding trend of edge computing and cloud-based deployment models, which greatly boosts industry growth. Over 1,200 warehouses and logistics centers currently use real-time item detection, which enhances automated sorting and inventory tracking, according to the report.      Download PDF Sample of Computer Vision Systems Market @ https://www.snsinsider.com/sample-request/8447  Key Players:  NVIDIA  Intel  AMD  Qualcomm  Ambarella  Teledyne Technologies  Omron Corporation  Keyence Corporation  Microsoft  Amazon Web Services (AWS)  Google Cloud  IBM  OpenCV.ai  Roboflow  Matrox Imaging  Allied Vision Technologies  Mobileye (Intel)  Tesla  Aptiv  World Labs  Computer Vision Systems Market Report Scope:  Report Attributes Details Market Size in 2024 USD 19.29 Billion Market Size by 2032 USD 75.52 Billion CAGR CAGR of 18.63% From 2025 to 2032 Base Year 2024 Forecast Period 2025-2032 Historical Data 2021-2023 Report Scope & Coverage Market Size, Segments Analysis, Competitive Landscape, Regional Analysis, DROC & SWOT Analysis, Forecast Outlook Key Segments • By Component (Hardware, Software, Services)  • By Deployment Mode (Cloud-based, On-premises, Edge computing devices)  • By Application (Facial recognition, Image classification, Object detection, Object tracking, Optical Character Recognition (OCR), Image Segmentation, Automated optical inspection, 3D vision and depth sensing, Gesture recognition, Others)  • By Industry Vertical (Manufacturing, Healthcare, Retail, Automotive, Security and surveillance, Agriculture, Smart cities, Consumer electronics, Energy and utilities, Others) Customization Scope Available upon request Pricing Available upon request  If You Need Any Customization on Computer Vision Systems Market Report, Inquire Now @ https://www.snsinsider.com/enquiry/8447  Segmentation Analysis:  By Component, in 2024, Hardware Segment Led the Market with a Share 58.40%, while Services are the Fastest-growing Segment with a CAGR of 20.38%  Hardware component segment occupies a majority share in the Computer Vision Systems Market, largely owing to the large-scale deployment of high-resolution cameras, sensors and GPUs across various industrial verticals. The Services segment is experiencing the highest growth, supported by the growing need for software integration, training and support with AI models, maintenance, consulting, and assistance with cloud-based deploy.  By Deployment Mode, in 2024, On-premises Dominated the Market with a Share of 65.10%, while Edge Computing Devices Fastest-growing Segment with a CAGR 19.96%  On-premises deployment is leading the Computer Vision Systems Market, as many organizations like to process their sensitive data locally in order to guarantee security and have control over their critical operations, especially in industries, such as healthcare, manufacturing, and automotive Edge computing devices are having the highest growth rate due to the demand for data processing at real time, low latency applications, and AI based decision making at-edge level.  By Application, in 2024, Facial Recognition Led the Market with a Share 25.07%, while Object Detection the Fastest-growing Segment with a CAGR 20.24%  Facial Recognition application segment dominated the Computer Vision Systems Market globally, in which computer vision technology is extensively adopted by the government, retail, and corporate sectors for security, surveillance, access control, and identity verification. Object Detection is growing fastest due to increasing need for real-time tracking, anomaly detection, and process optimization from autonomous vehicles, robotics, industrial automation, smart logistics, and others.  By Industry Vertical, in 2024, Manufacturing Dominated the Market with a Share of 32.03%, while Healthcare is the Fastest-growing Segment with a CAGR of 20.91%  Manufacturing tops the industry vertical in the Computer Vision Systems Market, as computer vision is increasingly used for factory deployment for quality inspection, defect detection, assembly verification, and automation globally. Healthcare is experiencing the quickest growth, which is attributed to the rise in uptake of diagnostic imaging, surgical assistance, patient monitoring, and medical image analysis powered by AI.  In 2024, North America Led the Market in 2024; Asia Pacific is Projected to be the Fastest Growing Region in the Market During 2025-2032  The computer vision systems market is propelled by the North America region as the market share 32.50%, owned by the early adopters of AI, machine learning, and advanced imaging technologies for various industries. Asia Pacific is a key and fast-growing market for Computer Vision System with a CAGR 19.74%, due to the rapid industrialization and urbanization along with the adoption of the latest technologies.  Recent Developments:  In May 2024 , Ambarella launched the CV75S AI SoC family built on 5nm technology, enabling power-efficient multi-modal vision-language models and AI inference for cameras and robotics.  , Ambarella launched the CV75S AI SoC family built on 5nm technology, enabling power-efficient multi-modal vision-language models and AI inference for cameras and robotics. In April 2024, Intel announced the Gaudi 3 AI accelerator at Intel Vision 2024, enhancing inference throughput and efficiency for large AI models in data centers and edge devices.  Buy Full Research Report on Computer Vision Systems Market 2025-2032 @ https://www.snsinsider.com/checkout/8447  Exclusive Sections of the Report (The USPs):  Algorithm & Model Performance Metrics – helps you assess the efficiency and maturity of computer vision systems through accuracy and precision rates, real-time processing latency, and the frequency of model updates or optimizations.  – helps you assess the efficiency and maturity of computer vision systems through accuracy and precision rates, real-time processing latency, and the frequency of model updates or optimizations. Human-Machine Interaction Metrics – helps you understand the impact of CV adoption on workforce efficiency by tracking reductions in manual errors, improvements in operator productivity, and user engagement across retail, AR/VR, and industrial applications.  – helps you understand the impact of CV adoption on workforce efficiency by tracking reductions in manual errors, improvements in operator productivity, and user engagement across retail, AR/VR, and industrial applications. Security & Fraud Detection Metrics – helps you evaluate the reliability of CV systems in high-risk environments by analyzing false positive/negative rates, anomaly detection accuracy, and threat response time in surveillance and security applications.  – helps you evaluate the reliability of CV systems in high-risk environments by analyzing false positive/negative rates, anomaly detection accuracy, and threat response time in surveillance and security applications. Product Lifecycle & Reliability Index – helps you measure the operational resilience of CV hardware by monitoring metrics like mean time between failures (MTBF), lifecycle duration of sensors and cameras, and maintenance cost savings achieved through automation.  – helps you measure the operational resilience of CV hardware by monitoring metrics like mean time between failures (MTBF), lifecycle duration of sensors and cameras, and maintenance cost savings achieved through automation. Real-Time Processing Efficiency – helps you benchmark system responsiveness by analyzing average milliseconds per frame in real-time CV applications, enabling performance comparisons across industrial and edge deployments.  – helps you benchmark system responsiveness by analyzing average milliseconds per frame in real-time CV applications, enabling performance comparisons across industrial and edge deployments. Operational Cost Optimization – helps you quantify ROI and cost-effectiveness by assessing reductions in maintenance expenses and productivity gains from automation-driven CV integration.  About Us:  SNS Insider is one of the leading market research and consulting agencies that dominates the market research industry globally. Our company's aim is to give clients the knowledge they require in order to function in changing circumstances. In order to give you current, accurate market data, consumer insights, and opinions so that you can make decisions with confidence, we employ a variety of techniques, including surveys, video talks, and focus groups around the world.
    OpenAI's long-rumored $10 billion partnership with Broadcom is already showing cracks. The company is widely understood to be developing a custom chip designed specifically for OpenAI's inference workloads, but according to individuals familiar with the matter, the project has "hit snags": OpenAI wanted more power, sooner, than Broadcom could deliver, and an internal push to roll the chip out in Q2 2026 has already slipped to Q3 at the earliest, according to a report from The Information.  The project, which has been kept deliberately quiet, is set to have manufacturing run through TSMC. Once live, the chip could handle inference jobs across OpenAI’s growing fleet of data centers, cutting its exposure to GPU bottlenecks and potentially lowering costs.  However, even as OpenAI lays the groundwork for its own silicon, it’s doubling down with Nvidia. A recent infrastructure agreement between the two companies, potentially worth more than $100 billion, would see Nvidia supply GPUs for the next wave of OpenAI-hosted AI clusters. Nvidia’s CEO Jensen Huang recently said that OpenAI “is likely going to be the next multi-trillion-dollar hyperscaler company,” with OpenAI remaining a cornerstone customer for Nvidia’s highest-end systems.  This, then, highlights the same paradoxical situation we’ve seen time and time again with AI. Amazon, Google, Microsoft, Meta, and now OpenAI are all building their own chips to reduce their reliance on Nvidia, while simultaneously relying on Nvidia more than ever.  A hedge with no clear endgame  Broadcom executives first confirmed what is believed to be the OpenAI deal late last year, saying that a large AI customer had booked billions in long-term orders. Reports quickly tied the deal to OpenAI, which has been growing a small, specialized in-house silicon team since at least mid-2023. The chip is understood to be designed for internal inference tasks and is not intended for commercial release. Broadcom handles the physical design, with TSMC expected to fabricate the chips.  This deal made OpenAI the latest entrant in a long line of hyperscalers trying to build their own chips. Amazon has its Trainium and Inferentia platforms. Google is now on its fifth-generation TPU. Microsoft is working on its Maia accelerators. Each was billed as a shift away from GPU dependency. Each still runs major workloads on Nvidia silicon.  OpenAI doesn’t shy away from this fact. Its GPT-4 model was trained on Nvidia H100s, and its hosting partners — including CoreWeave and Microsoft — continue to deploy Nvidia hardware at scale. The new custom chip effort might eventually take over some inference jobs, but there’s no evidence it will replace H100 or Blackwell-class GPUs for training. And even if the silicon performs well, it won’t come bundled with Nvidia’s competitive software stack.  There’s no matching CUDA  This is the piece challengers still can’t match. Nvidia’s CUDA platform remains the default target for nearly every AI framework in use today. From PyTorch and TensorFlow to popular model compilers and quantization toolkits, most of the AI software stack is optimized for Nvidia’s architecture. Migrating off it means rewriting core libraries, retraining engineers, and adapting models to new hardware, which, ultimately, is a cost few companies are willing to absorb.  OpenAI, like others, is unlikely to abandon CUDA without a compelling reason. Broadcom doesn’t offer its own software ecosystem, which means OpenAI’s team would need to build its own toolchain or adopt one of the open standards still struggling to reach parity. In the meantime, the easiest, fastest way to build and run large-scale models is still with Nvidia’s chips and software.  Jensen Huang knows this. Holding an iron grip over the industry, he’s reportedly given a heads-up by the likes of Amazon and Google before they announce a new chip that might compete with Nvidia’s. All this is done on the down low and, according to reports, has become something of an unwritten rule. It’s not required, but it happens, and it shows the degree to which Nvidia still commands power among its customers, even those building chips to hedge against Nvidia.  It’s not difficult to understand why this is the case. Nvidia is pouring billions into partnerships, infrastructure, and component sourcing. It recently agreed to buy up to $6.3 billion in unused GPU capacity from CoreWeave, invested nearly $1 billion to license Enfabrica’s networking tech, and paid Intel $5 billion as part of a joint development pact. It even agreed to support OpenAI’s next generation of GPU data centers despite OpenAI’s clear intent to use its own chips at some point.  Supply chain headwinds  Even if the OpenAI chip meets its performance goals, it faces supply chain headwinds. CoWoS packaging is still bottlenecked at TSMC, with Nvidia and AMD making up much of the near-term capacity. Advanced HBM memory is also under pressure, with SK hynix and Samsung prioritizing existing customers. So, while Broadcam can bring design expertise, it has no control over the back-end. Nor does OpenAI.  There’s also the question of scale. Nvidia’s Blackwell platform uses multi-chip modules, enormous memory bandwidth, and proprietary NVLink switching, a monolithic combination that Broadcom can’t offer. If OpenAI’s chip is simpler, it may be cheaper or more efficient per watt, but it also won’t be competitive on peak performance, which limits its value in training future large models.  All of these point toward a long-term hybrid model, where OpenAI uses both Nvidia and its own custom hardware depending on workload. Which, again, is what all the other hyperscalers are already doing.  The Broadcam partnership does make some sense for OpenAI from a strategic standpoint. If it ships on time (which looks unlikely) and performs well, it could reduce cost per token and give the company a touch more control over its infrastructure. But early signs aren't encouraging, and, in any case, it won’t be a silver bullet that replaces Nvidia's hardware for training cutting-edge models.  Follow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.
    Qualcomm shares may have more growth potential than the market is currently pricing in —but some big hurdles lie ahead.  This story appeared on marketwatch.com , 2025-09-30 20:58:00.
    SAN FRANCISCO, Sept. 30, 2025 (GLOBE NEWSWIRE) -- On September 10, 2025, investors in Synopsys, Inc. (NASDAQ: SNPS) saw the price of their shares crater over $216 (-36%) after the company reported its Q3 2025 financial results and revealed significant problems with a major foundry customer.  The development has prompted national shareholders rights firm Hagens Berman to open an investigation into whether Synopsys may have misled investors about its customer risks and growth prospects.  The firm urges investors in Synopsys who suffered significant losses to submit your losses now. The firm also encourages persons with knowledge who may be able to assist in the investigation to contact its attorneys.  Visit: www.hbsslaw.com/investor-fraud/snps  Contact the Firm Now: SNPS@hbsslaw.com  844-916-0895  Synopsys, Inc. (SNPS) Investigation:  In the past Synopsys has assured investors that, while its largest customer (Intel) had reduced its R&D spend, “it does not impact generally the EDA software[]” and downplayed risks based on its “committed, non-cancellable” agreements with Intel involving a mix of EDA software, IP, and hardware.  The company’s assurances may have come into question on September 9, 2025, when Synopsys reported its Q3 2025 financial results and shockingly guided for Q4 2025 GAAP EPS of negative $0.27 to negative $0.16.  During the earnings call, management revealed the company’s underperformance in its IP business and said it was significantly due to “challenges at a major foundry customer” that is “also having a sizeable impact on the year[.]”  This news drove the price of Synopsys shares down 36% the next day, its worst-ever single-day percentage decline since going public in 1992.  “We’re investigating whether Synopsys may have misled investors about risks posed by its high concentration with a single customer,” said Reed Kathrein, the Hagens Berman partner leading the investigation.  If you invested in Synopsys and have substantial losses, or have knowledge that may assist the firm’s investigation, submit your losses now »  If you’d like more information and answers to frequently asked questions about the Synopsys investigation, read more »  Whistleblowers: Persons with non-public information regarding Synopsys should consider their options to help in the investigation or take advantage of the SEC Whistleblower program. Under the new program, whistleblowers who provide original information may receive rewards totaling up to 30 percent of any successful recovery made by the SEC. For more information, call Reed Kathrein at 844-916-0895 or email SNPS@hbsslaw.com.  About Hagens Berman  Hagens Berman is a global plaintiffs’ rights complex litigation firm focusing on corporate accountability. The firm is home to a robust practice and represents investors as well as whistleblowers, workers, consumers and others in cases achieving real results for those harmed by corporate negligence and other wrongdoings. Hagens Berman’s team has secured more than $2.9 billion in this area of law. More about the firm and its successes can be found at hbsslaw.com. Follow the firm for updates and news at @ClassActionLaw.
    NVIDIA, Apple, Intel, Microsoft, Palantir Technologies, Oracle, and Meta Platforms are the seven Technology stocks to watch today, according to MarketBeat’s stock screener tool. Technology stocks are shares of companies whose core businesses involve developing, manufacturing or distributing technology products and services—ranging from software, hardware and semiconductors to internet platforms and IT consulting. Investors are often drawn to these stocks for their high growth potential driven by rapid innovation, though they can also exhibit above-average volatility and sector-specific risks such as regulatory shifts or technological disruption. These companies had the highest dollar trading volume of any Technology stocks within the last several days.  Get alerts:  NVIDIA (NVDA)  NVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.  Apple (AAPL)  Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal computers; iPad, a line of multi-purpose tablets; and wearables, home, and accessories comprising AirPods, Apple TV, Apple Watch, Beats products, and HomePod.  Read Our Latest Research Report on AAPL  Intel (INTC)  Intel Corporation designs, develops, manufactures, markets, and sells computing and related products and services worldwide. It operates through Client Computing Group, Data Center and AI, Network and Edge, Mobileye, and Intel Foundry Services segments. The company's products portfolio comprises central processing units and chipsets, system-on-chips (SoCs), and multichip packages; mobile and desktop processors; hardware products comprising graphics processing units (GPUs), domain-specific accelerators, and field programmable gate arrays (FPGAs); and memory and storage, connectivity and networking, and other semiconductor products.  Read Our Latest Research Report on INTC  Microsoft (MSFT)  Microsoft Corporation develops and supports software, services, devices and solutions worldwide. The Productivity and Business Processes segment offers office, exchange, SharePoint, Microsoft Teams, office 365 Security and Compliance, Microsoft viva, and Microsoft 365 copilot; and office consumer services, such as Microsoft 365 consumer subscriptions, Office licensed on-premises, and other office services.  Read Our Latest Research Report on MSFT  Palantir Technologies (PLTR)  Palantir Technologies, Inc. engages in the business of building and deploying software platforms that serve as the central operating systems for its customers. It operates under the Commercial and Government segments. The Commercial segment focuses on customers working in non-government industries. The Government segment is involved in providing services to customers that are the United States government and non-United States government agencies.  Read Our Latest Research Report on PLTR  Oracle (ORCL)  Oracle Corporation offers products and services that address enterprise information technology environments worldwide. Its Oracle cloud software as a service offering include various cloud software applications, including Oracle Fusion cloud enterprise resource planning (ERP), Oracle Fusion cloud enterprise performance management, Oracle Fusion cloud supply chain and manufacturing management, Oracle Fusion cloud human capital management, Oracle Cerner healthcare, Oracle Advertising, and NetSuite applications suite, as well as Oracle Fusion Sales, Service, and Marketing.  Read Our Latest Research Report on ORCL  Meta Platforms (META)  Meta Platforms, Inc. engages in the development of products that enable people to connect and share with friends and family through mobile devices, personal computers, virtual reality headsets, and wearables worldwide. It operates in two segments, Family of Apps and Reality Labs. The Family of Apps segment offers Facebook, which enables people to share, discuss, discover, and connect with interests; Instagram, a community for sharing photos, videos, and private messages, as well as feed, stories, reels, video, live, and shops; Messenger, a messaging application for people to connect with friends, family, communities, and businesses across platforms and devices through text, audio, and video calls; and WhatsApp, a messaging application that is used by people and businesses to communicate and transact privately.  Read Our Latest Research Report on META  Featured Articles



    2.  **Historical Context (`historic_summary`):**
        
    ### amd_7day.md
    As an analyst specializing in the semiconductor industry, here is a summary of the risks and opportunities for AMD over the last 7 days, based on the provided knowledge triplets:

    ### Risks for AMD:

    *   **Regulatory & Geopolitical Headwinds**: The company faces potential margin pressure from MI308 export controls, which could impact sales to key markets like China, and broader political developments tying export licenses to payments.
        *   AMD -(faces/margin pressure from MI308 export)-> controls
        *   Trump -(ties/export licenses to payments)-> AMD
    *   **Inventory & Financial Performance Concerns**: AMD recently took a significant inventory charge, and its last reported EPS missed analyst estimates. This suggests potential oversupply or slower demand in certain areas. The stock also experienced a slight decline and insider selling, coupled with a high beta indicating higher volatility.
        *   AMD -(takes/$800 million inventory)-> charge
        *   AMD -(misses/EPS estimate by $0.06)-> estimate
        *   AMD -(declines/stock price 1.1%)-> price
        *   AMD -(experiences/insider)-> selling
        *   AMD -(has/1.92)-> beta
    *   **Competitive Pressures & Valuation**: AMD operates in a highly competitive environment, with players like Snapdragon directly vying for market share. Trading near all-time highs and a high trailing P/E ratio (though forward P/E is more favorable) could expose the stock to corrections.
        *   Snapdragon -(competes/None)-> AMD
        *   AMD -(trades/near all-time)-> highs
        *   AMD -(has/trailing P/E 95.68 and forward P/E 26.88)-> P/E
    *   **Mixed Analyst Sentiment**: While many analysts are positive, one firm issued a cautious rating, indicating some level of market skepticism regarding AMD's near-term prospects or valuation.
        *   AMD -(receives/cautious rating from Wedbush)-> rating

    ### Opportunities for AMD:

    *   **Strong Financial Growth & Positive Outlook**: AMD reported robust Q2 2025 revenue of $7.7 billion with 32% growth, driven by significant increases in gaming (73%) and data center (14%) segments. The company also anticipates strong future EPS and has a positive average price target from analysts.
        *   AMD -(reports/Q2 2025 revenue of $7.7 billion with 32% growth)-> revenue
        *   AMD -(reports/Q2 2025 gaming revenue of $1.1 billion with 73% growth)-> revenue
        *   AMD -(reports/Q2 2025 data center revenue of $3.2 billion with 14% growth)-> revenue
        *   AMD -(expects/current year $3.87)-> EPS
        *   AMD -(has/average price $180.88)-> target
    *   **AI Leadership & Ecosystem Expansion**: AMD is heavily invested in AI, evidenced by new Ryzen AI 300 series chips, extended ROCm software support across various GPUs and APUs, and significant partnerships with industry giants like OpenAI, Cohere, and Meta for Llama solutions. A multibillion-dollar AI chip deal and supplying thousands of GPUs for AI infrastructure underscore strong demand.
        *   AMD -(provides/AI 300)-> Ryzen
        *   AMD -(releases/public preview of ROCm 6.4.4)-> ROCm
        *   AMD -(brings/official framework support to Radeon RX 9000/7000 GPUs and Ryzen AI 300/MAX APUs)-> support
        *   AMD -(partners/None)-> OpenAI
        *   AMD -(strikes/multibillion-dollar AI chip)-> deal
        *   AMD -(partners/for Llama solutions)-> Meta
    *   **Robust Product Portfolio & Market Penetration**: AMD continues to roll out new high-performance processors, including Ryzen 9000WX series (Zen 5), powerful Threadripper offerings (up to 96 Zen 5 cores), and upcoming Strix Point/Halo APUs. The company is gaining EPYC market share, strengthening its data center positioning, and securing design wins in handhelds (e.g., Ally), ExpertBooks, and gaming consoles (Xboxes).
        *   AMD -(has/9000WX series (Zen 5))-> Ryzen
        *   AMD -(offers/9995WX (96 Zen 5 cores))-> Threadripper
        *   AMD -(gains/EPYC market)-> share
        *   AMD -(strengthens/data center)-> positioning
        *   Xboxes -(uses/AMD CPU)-> Ryzen
        *   Ally -(has/Z2 AI Extreme)-> Ryzen
        *   AMD -(produces/Halo APU)-> Strix
    *   **Technological Advancement & Software Support**: AMD is showing a surge in power and efficiency, supporting advanced memory technologies like MRDIMM for future EPYC platforms, and filing related patents. Enhanced software support from Linux (SmartMux) and Microsoft (super resolution for Copilot+ PCs) further strengthens its platform appeal.
        *   AMD -(surges/in power and efficiency)-> ahead
        *   AMD -(supports/None)-> MRDIMM
        *   AMD -(files/HB-DIMM)-> patent
        *   Microsoft -(rolls out/super resolution to Copilot+ PCs)-> AMD
    *   **Diversified Business & Market Perception**: With diversified revenue streams across Data Center, Client, Gaming, and Embedded segments, AMD demonstrates resilience. The perception of becoming a "stable alternative" to competitors and benefiting from "vacuum" left by Intel indicates a favorable market position.
        *   AMD -(has/diversified revenue)-> streams
        *   AMD -(operates/Data Center, Client, Gaming, Embedded)-> segments
        *   AMD -(becomes/stable)-> alternative
        *   AMD -(benefits/from vacuum)-> Intel

    ### Outlook:

    AMD presents a compelling narrative of a rapidly expanding semiconductor powerhouse, significantly capitalizing on the burgeoning AI market through strategic partnerships, advanced product launches, and a strengthened software ecosystem (ROCm). Robust revenue growth, particularly in data center and gaming, and positive analyst consensus indicate strong momentum. However, the company is not without challenges, facing margin pressures from export controls, a recent EPS miss, and high stock volatility with insider selling. While trading near all-time highs could imply overvaluation risks, AMD's aggressive product roadmap and diversified business segments position it well for continued growth, provided it effectively navigates geopolitical complexities and competitive landscapes.

    ### intel_7day.md
    Risks for Intel:
    - `Apple -(end/support for Intel-based Macs after macOS 26)-> Intel` → Apple is phasing out support for Intel-based Macs, indicating a continued decline in Intel's presence within Apple's ecosystem and highlighting the long-term impact of losing a major customer.
    - `Innovation -(lack/in Intel chip manufacturing processes)-> Intel` → Intel faces a critical challenge with a perceived lack of innovation in its core chip manufacturing processes, which is vital for competitiveness against rivals like TSMC.
    - `Intel -(falls/behind NVIDIA)-> rivals` → Intel is falling behind key rivals, particularly Nvidia, which is concerning given Nvidia's dominance in high-growth areas like AI.
    - `Intel -(needs/for foundry business)-> customers` → A significant challenge for Intel's ambitious foundry business is securing sufficient customers to make it a viable and profitable venture.
    - `Intel -(admits/with Arrow Lake)-> error` → Intel has acknowledged an error with its upcoming Arrow Lake processors, which could imply potential design flaws, delays, or performance issues affecting future product launches.
    - `Intel -(struggle/maintaining Itanium contracts with HPE)-> Contracts` → Intel is struggling to maintain legacy contracts, such as Itanium agreements with HPE, indicating an erosion of older revenue streams.

    Opportunities for Intel:
    - `Intel -(receives/from NVIDIA, $55 billion)-> investment` → Intel has received a substantial investment from Nvidia (noting a reported $5 billion figure elsewhere, but the triplet specifies $55 billion), signifying a significant capital infusion and a vote of confidence from a leading industry player.
    - `Intel -(receive/$8.9 billion from US government subsidies)-> Government` → Intel is benefiting from considerable financial support ($8.9 billion in subsidies) from the US government, crucial for its domestic manufacturing expansion and competitiveness.
    - `Government -(purchase/10% stake in Intel)-> Intel` → The US government has taken a 10% stake in Intel, demonstrating strong strategic backing and further capital injection.
    - `Intel -(plans/Panther Lake Q1 next year 18A process)-> Chips` → Intel has a clear roadmap for new chips like Panther Lake in Q1 next year, utilizing its advanced 18A process, signaling progress in its manufacturing technology and future product pipeline.
    - `Apple -(consider/becoming customer for Intel advanced packaging technology)-> Intel` → Apple is considering becoming a customer for Intel's advanced packaging technology, presenting a massive opportunity for Intel Foundry Services to secure a major client.
    - `TSMC -(strengthen/production at Intel US plants through joint venture)-> Intel` → Potential for a joint venture with TSMC to strengthen production at Intel's US plants offers a strategic partnership that could enhance Intel's foundry capabilities and market position.
    - `Intel -(discuss/investment, cooperation with Apple)-> Apple` → Intel is engaged in discussions with Apple regarding investment and cooperation, indicating potential for new strategic partnerships and capital.
    - `Intel -(invests/local)-> AI` → Intel is strategically investing in local AI capabilities, positioning itself in a critical growth market.
    - `Yoga -(power/with Core Ultra 9 285H CPU)-> Intel` → New high-end laptops like the Yoga are adopting Intel's Core Ultra 9 285H CPU, indicating strong design wins and competitive products in the premium segment.
    - `Intel -(receives/for $2 billion from Softbank)-> proposal` → Intel has a $2 billion investment proposal from SoftBank, offering another significant source of capital.
    - `Intel -(repair/its business)-> Business` → Intel is actively working to repair its business, suggesting a strategic focus on turnaround and improvement, supported by `Intel -(get/board support for CEO)-> support` for its leadership.

    Outlook:
    Intel faces a challenging landscape, marked by competitive pressures from Nvidia, a perceived lack of innovation in manufacturing, and the ongoing impact of losing Apple's Mac business. A key concern is the need to attract customers for its nascent foundry business. However, the company is also presented with substantial opportunities. Significant investments from Nvidia, SoftBank, and the US government (totaling billions in subsidies and equity) provide critical capital. Furthermore, potential collaborations with Apple for advanced packaging and TSMC for US plant production could be game-changers for its foundry aspirations. Intel's pipeline of new products like Panther Lake on the 18A process, coupled with strong design wins in high-end laptops and strategic investments in AI, suggest a determined effort towards a comeback. The next few quarters will be crucial in demonstrating whether these opportunities can successfully offset the identified risks.

    ### nvidia_7day.md
    Here's a summary of risks and opportunities for Nvidia over the last 7 days:

    Risks for Nvidia:
    - Huang -(sells/75,000 shares)-> Nvidia → Significant insider selling by CEO Jensen Huang (and other executives like Kress, Harvey, Jen, and Insiders collectively) could signal a lack of confidence or a move to diversify personal holdings, potentially impacting investor sentiment.
    - China -(restricts/Nvidia AI)-> Chips → Geopolitical tensions and export controls from China pose a direct threat to Nvidia's AI chip sales in a crucial market, limiting revenue potential.
    - Nvidia -(relies/6 customers for 83% revenue)-> customers → High customer concentration means Nvidia's revenue is heavily dependent on a small number of clients, increasing vulnerability to changes in their demand or strategic shifts.
    - Nvidia -(proposes/50W power increase)-> 5070Ti → Potential product design choices, like increased power consumption and a proposed price bump for the 5070Ti, could face consumer resistance or competitive pressure.
    - BNP -(upgrades/rating to hold)-> Nvidia → While an upgrade, a "hold" rating from an analyst firm like BNP is less bullish than "buy" ratings, indicating some caution or limited upside potential compared to other analyst outlooks.

    Opportunities for Nvidia:
    - Nvidia -(sees/55.6% revenue increase)-> Quarter → Strong financial performance, evidenced by significant revenue and EPS growth, high return on equity (101.74%), and robust net margins (52.41%), highlights the company's profitability and operational efficiency.
    - KeyCorp -(reiterates/overweight rating)-> Nvidia → Overwhelmingly positive analyst sentiment, with numerous "Strong Buy" and "Buy" ratings and boosted price objectives (e.g., KeyCorp, Stifel, Wolfe, Davidson, NewStreet, Summit), suggests strong market confidence and potential for stock appreciation.
    - Premier -(increases/stake by 27.6%)-> Nvidia → Increased holdings by institutional investors (e.g., Bouvel, Meriwether, Hilltop, Premier, Mallini, Kaufman, Wedmont) signal strong institutional confidence and demand for Nvidia shares.
    - Nvidia -(announces/$100 billion investment)-> OpenAI → Deep strategic partnerships and massive investments in AI infrastructure (e.g., with OpenAI for Stargate, data center build-out, and GPU leasing) position Nvidia at the heart of the burgeoning AI market and reinforce its dominance.
    - Nvidia -(purchases/4% stake in Intel for $5 billion)-> Intel → A significant strategic investment and partnership with Intel to integrate AI and utilize manufacturing capabilities indicates a collaborative approach to expanding its ecosystem and ensuring supply chain stability.
    - Nvidia -(builds/Rubin architecture)-> chips → Continuous product innovation, including the development of next-generation AI architectures like Rubin (replacing Blackwell) and specialized models like NV-Tesseract for AD, ensures Nvidia remains at the forefront of technological advancement.
    - Nvidia -(resumes/sales to China by July)-> sales → The anticipated resumption of sales to China by July presents a significant opportunity to recover and expand market share in a critical region, despite previous restrictions.
    - Nvidia -(open-sources/Audio2Face 3D animation model)-> model → Open-sourcing key technologies like Audio2Face demonstrates an effort to expand its ecosystem, drive adoption, and foster innovation within its developer community.
    - Nvidia -(leads/in networking and graphics)-> industry → Nvidia maintains a leading position in critical areas like graphics, networking, and the AI supply chain, underpinned by strong cash reserves and accelerating AI hardware adoption, supporting long-term growth.

    Outlook:
    Nvidia is currently navigating a dynamic landscape, characterized by robust growth opportunities in AI and continued innovation, significantly bolstered by strong financial performance, overwhelming analyst and investor confidence, and strategic partnerships, particularly with OpenAI and Intel. The company's relentless focus on next-generation architectures like Rubin and expansion into diverse markets from gaming to enterprise AI positions it for sustained leadership. However, these opportunities are shadowed by notable risks, including substantial insider selling, geopolitical hurdles impacting sales to China, and potential customer concentration challenges. While the overall sentiment remains highly positive, the firm must adeptly manage these risks to fully capitalize on its formidable market position and technological prowess.


    **Candidate Summary (The text to be evaluated):**
    "### Summary Report of Financial News (30/09/2025)\n\n### Summary Paragraph\nToday, September 30, 2025, Nvidia is at the forefront of the financial news, primarily driven by a significant $100 billion partnership with OpenAI to power next-generation AI systems, which led to a notable 4% increase in Nvidia's stock. This deal, along with Nvidia-backed CoreWeave's 12% stock surge after a $14.2 billion AI cloud infrastructure deal with Meta Platforms, underscores Nvidia's deepening dominance in the AI sector. The company's strategic alliances, including a crucial High-Bandwidth Memory (HBM) supply link with Micron (whose shares rose 5% on HBM production news for Nvidia) and a 4% stake acquisition in Intel, are reinforcing its market leadership. Analysts like Citi are further bolstering confidence with raised price targets, fueled by projected massive sales for Nvidia's next-generation Blackwell AI chips. While the market sees intense competition from AMD (with its own OpenAI deal and new Dense Geometry Format for GPUs) and Intel (partnering with Nvidia but also vying in x86), and long-term risks from partners potentially developing in-house chips, Nvidia's robust innovation, expanding ecosystem (e.g., UiPath collaboration), and the overall surge in Big Tech's AI spending are painting a highly positive financial picture.\n\n### Key Insight\nHistorically, Nvidia has consistently demonstrated robust growth and innovation in AI, strategically building partnerships that solidified its position. Today's $100 billion OpenAI partnership and CoreWeave's market success are direct outcomes of this sustained strategy, translating into significant stock gains and reinforcing Nvidia's pivotal role in the AI infrastructure. Looking ahead, while Nvidia is poised for continued leadership with its advanced chip architectures and strong demand, the emergence of fierce competition from AMD and Intel, coupled with the potential for key partners like OpenAI to develop their own silicon, suggests that maintaining market share and mitigating disintermediation risks will be critical for sustained, long-term financial outperformance.\n\n### Key Implications\n*   **Key Relationships (from graph_retriever):**\n    *   (NVIDIA) --[forges $100B partnership with]--> (OpenAI)\n    *   (Nvidia) --[backs]--> (CoreWeave)\n    *   (Nvidia) --[has a link in business with]--> (Micron)\n    *   (Nvidia) --[purchases 4% stake in]--> (Intel)\n    *   (Citi) --[gives price target hike to]--> (Nvidia)\n    *   (UiPath) --[announces collaboration with]--> (Nvidia)\n\n*   **Risks and Opportunities:**\n    *   **Opportunity:** Massive future revenue generation from the OpenAI partnership and projected $200 billion sales from Blackwell AI chips.\n    *   **Opportunity:** Enhanced market position as a leading AI infrastructure provider, further validated by successful strategic investments like CoreWeave's Meta deal.\n    *   **Risk:** Intensified competition from AMD (with its Dense Geometry Format and competing OpenAI deal) and Intel (with new x86 competition and joint efforts).\n    *   **Risk:** Potential for partner disintermediation, as OpenAI is reportedly exploring building its own chips, which could impact Nvidia's long-term revenue from a key customer.\n    *   **Risk:** Historical concerns regarding insider selling by CEO Jensen Huang and geopolitical hurdles (e.g., China restrictions) remain underlying challenges.\n    *   **Opportunity:** Strong rebound in the DRAM module market driven by AI demand, ensuring a stable supply of critical components like HBM for Nvidia.\n\n*   **Notable Market and Competitor Events (from enhanced_search_agent):**\n    *   AMD secured a multi-billion-dollar deal with OpenAI, challenging Nvidia's dominance in high-performance AI chips.\n    *   CoreWeave's stock surged 12% after a $14.2 billion AI cloud infrastructure deal with Meta Platforms, validating Nvidia's investment strategy.\n    *   Citi has issued varied price targets for Nvidia, with significant raises due to optimism for Blackwell sales (up to $200 billion next year) and sovereign AI demand.\n    *   AMD introduced the Dense Geometry Format (DGF) to enhance GPU competitiveness, directly competing with NVIDIA's RTX Mega Geometry.\n    *   Intel and AMD are in intense x86 processor competition, with a notable joint effort by Intel and Nvidia to develop 'Intel x86 RTX SOCs' to counter AMD APUs.\n    *   Qualcomm is aggressively pursuing an AI strategy focused on edge AI, posing a broad competitive challenge in the AI chip market.\n    *   Big Tech's AI spending and borrowing are forecasted to be even higher next year, indicating a favorable macro environment for AI hardware providers."

    **Task:**
    Evaluate the **Candidate Summary** based on its analytical quality and usefulness for an investor. Your evaluation must focus on **analytical quality and reasoning**, not on strict adherence to the provided context.

    For each metric, provide a numeric score from 0.0 (very poor) to 1.0 (excellent) and brief reasoning.

    **Evaluation Metrics:**

    1.  **Clarity & Conciseness:**
        - Assesses if the summary is clear, concise, well-structured, and easy to understand.
        - Score 1.0 = Very clear and concise. Score 0.0 = Confusing or verbose.

    2.  **Saliency & Information Prioritization:**
        - Rates how well the summary selects and prioritizes the *most consequential* facts and signals for an investor, filtering out noise.
        - Score 1.0 = Highlights the most critical, market-moving info. Score 0.0 = Focuses on trivial details.

    3.  **Factual Consistency (with References):**
        - Judges if the facts *that are drawn from* the `base` and `historic_summary` are accurate and not misrepresented.
        - *This metric does not penalize new, external information.*
        - Score 1.0 = All facts from references are accurate. Score 0.0 = Misrepresents facts from references.

    4.  **Contextual Integration & Trend Analysis:**
        - Judges how well the summary synthesizes information from both the base (current) and historic_summary (past) contexts, along with any external data, to identify meaningful trends or causal links.
        - Score 1.0 = Clearly identifies a multi-point trend linking past and present. Score 0.0 = Just lists facts or ignores historical context.

    5.  **Analytical Depth & Insightfulness:**
        - Judges if the summary moves beyond merely *reporting* facts (from `base` or `historic`) to **analyze the 'So what?' (implications, market impact) and potentially the 'Why?' (underlying drivers) in a non-obvious way.** Does it offer a unique perspective or forward-looking thought?
        - *Generic statements or simple restatements of news indicate low depth.*
        - Score 1.0 = Provides deep, specific, actionable insights. Score 0.0 = Surface-level reporting or generic, obvious implications.

    6.  **Comprehensiveness & Context Coverage:**
        - Assesses if the summary provides a *sufficiently complete picture* for an investor by covering **both key current events (`base`) AND relevant historical perspectives (`historic_summary`)**. Does it feel like crucial past context necessary to understand the present situation is missing?
        - *Focuses on whether the *combination* of information feels complete.*
        - Score 1.0 = Provides a well-rounded picture integrating current and historical views. Score 0.0 = Feels critically incomplete due to missing important context.

    **FINAL JSON OUTPUT FORMAT (exact structure required)**

    {
    "clarity_and_conciseness": {
        "score": <float_0.0_to_1.0>,
        "reasoning": "<1-2 sentence justification>"
    },
    "saliency_and_information_prioritization": {
        "score": <float_0.0_to_1.0>,
        "reasoning": "<1-2 sentence justification>"
    },
    "factual_consistency_with_references": {
        "score": <float_0.0_to_1.0>,
        "reasoning": "<1-2 sentence justification>"
    },
    "contextual_integration_and_trend_analysis": {
        "score": <float_0.0_to_1.0>,
        "reasoning": "<1-2 sentence justification>"
    },
    "analytical_depth_and_insightfulness": {
        "score": <float_0.0_to_1.0>,
        "reasoning": "<1-2 sentence justification>"
    },
    "comprehensiveness_and_context_coverage": {
        "score": <float_0.0_to_1.0>,
        "reasoning": "<1-2 sentence justification>"
    }
    }

