
CRITICAL: Your entire response MUST be a single, valid JSON object and nothing else. Your response must begin with '{' and end with '}'.

You are an expert evaluator, acting as an LLM-as-a-Judge. 

**Input to Judge:**

this base of news articles:
### Nvidia ###
TheGeekn°72 That's literally just Sapphire's 9070XT NITRO+ design.  IDK about ripoff (because there's only so many ways to hide a power cable) but definitely feels like a copycat move for sure.    Someone *else* finally innovated in GPU design without making it expensive like their proprietary Zero Cables Project (or whatever they called it) parts so of course they had to copy that one to catch on the bandwagon instead of coming up with their own shit.  Actually it's not quite a rip off....I mean it's obviously inspired by it, but sapphire's design the connector points to the back of the card and it's a long PCB so you have a bend under the backplate, this points towards the MB tray so a lot less of a bend radius likely and if it lines up with a cable grommit (which it won't because short PCB, it'll still be covered by the MB) it's no bend at all anywhere near the connector so.... it looks like a much better design
We recently published 10 Stocks Investors Are Gobbling Up. UiPath Inc. (NYSE:PATH) is one of the top performers on Monday.  UiPath extended its rally to a second day on Monday, jumping 12.56 percent to close at $14.52 apiece, mimicking the surge in artificial intelligence stocks on growing investor optimism and a flurry of developments in the industry.  Monday also saw its share price at a 10-month high, just 71 cents shy of its 52-week price of $15.93.  UiPath(PATH) Jumps 12.56% as AI Frenzy Sparks Rosy Prospects  Pixabay / Public Domain  Investor optimism was further supported by UiPath Inc.’s (NYSE:PATH) announcement last week that it partnered with technology giant Nvidia Corp. to support enterprise customers in fortifying their existing automated workflows with AI capabilities in high-trust scenarios, such as fraud detection or care management in healthcare.  A key aspect in the partnership was the introduction of an integration service connector that would connect UiPath Inc. (NYSE:PATH) and Nvidia’s NIM and Nemotron, enabling enterprises to seamlessly and rapidly integrate generative AI features into their applications.  Additionally, UiPath Inc. (NYSE:PATH) said it was exploring opportunities across agentic automation in areas including advancing agentic orchestration and developing differentiated agents, among others.  “Sensitive processes like fraud detection or healthcare workflows demand AI that is both powerful and trustworthy. By integrating NVIDIA NIM models directly into the UiPath Platform, customers can deploy and orchestrate their own hosted models with enterprise-grade governance. That means they can bring AI into their most critical processes with the control, transparency, and confidence they need to deliver real business impact,” said UiPath Inc. (NYSE:PATH) Chief Product Officer Graham Sheldon.  While we acknowledge the potential of PATH as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.  READ NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.
This article first appeared on GuruFocus.  Oct 7 - Iris Energy (NASDAQ:IREN) climbed about 10% in early U.S. trading on Tuesday after the company secured fresh multi-year cloud service agreements with artificial intelligence firms to deploy Nvidia (NASDAQ:NVDA) Blackwell GPUs, according to a Tuesday press release.  The deals extend Iris Energy's reach in the fast-growing AI infrastructure market, where demand for high-performance chips continues to accelerate. The company recently expanded its AI Cloud capacity and said it remains on course to reach more than $500 million in annualized run-rate revenue from 23,000 GPUs that are either operational or on order by the end of the first quarter of 2026.  Iris Energy added that customer contracts now cover roughly 11,000 of those GPUs, representing around $225 million in annual recurring revenue expected to be active by late 2025.  The latest partnerships reinforce Iris Energy's ongoing shift from digital mining toward AI-focused data services, aligning with broader industry trends as more enterprises invest in GPU-powered cloud infrastructure.
This article first appeared on GuruFocus.  AMD (AMD, Financials) is doing great. The chipmaker's stock is going up for the second day in a row following a lot of positive analyst calls that say the company's AI strategy is starting to pay off in a big manner.  This week, a number of Wall Street firms boosted their price forecasts, which shows that demand for AMD's new data center and AI chips is growing.  Analysts claim that cloud providers and business clients are now paying a lot of attention to the company's new processors, such the Instinct MI300 series. These clients want something else than Nvidia's main line of products.  The increase is also part of a bigger recovery in the semiconductor industry, where investors are feeling good about artificial intelligence, data centers, and enterprise computers. Traders are keeping a careful eye on AMD stock to see how far this momentum may go, as it is already outperforming many other chip stocks.  Later this month, executives are anticipated to talk more about production capacity and long-term AI goals at industry meetings. These updates could help establish whether AMD's present momentum is just the beginning.
Benzinga and Yahoo Finance LLC may earn commission or revenue on some items through the links below.  On Monday, Cathie Wood-led Ark Invest made significant trades, notably increasing its stake in DoorDash Inc. (NASDAQ:DASH), Alibaba Group Holding Ltd. (NYSE:BABA) , while reducing its position in Brera Holdings PLC (NASDAQ:BREA) and Rocket Lab Corp. (NASDAQ:RKLB).  The DoorDash Trade  Ark Invest made a substantial purchase of DoorDash shares across the ARK Autonomous Technology & Robotics ETF  (BATS:ARKQ) and ARK Space Exploration & Innovation ETF (BATS:ARKX). On Monday, DoorDash’s stock closed at $281.74, marking a 3.88% increase. Ark’s purchase of 25,581 shares translates to an investment of approximately $7.2 million.  This surge followed the announcement of a new multi-year partnership with Criteo S.A., aimed at enhancing advertising opportunities across DoorDash's platform. The collaboration is set to expand media placements and integrate advertising technologies, capitalizing on the rapid growth of retail media.  Trending: If there was a new fund backed by Jeff Bezos offering a 7-9% target yield with monthly dividends would you invest in it?  The Alibaba Trade  Ark Invest bought 4,449 shares of Alibaba through its ARK Innovation ETF (BATS:ARKK), valued at around $832,000 based on Monday’s closing price of $187.22.  Alibaba’s stock has been on an upward trajectory, driven by its aggressive push into cloud computing and artificial intelligence. This momentum has positioned Alibaba as a top-performing Chinese tech stock, with a year-to-date gain of over 120%. The company’s focus on AI has been a significant factor in its recent performance.  Notably, Ark snapped up $2.74 million worth of Alibaba shares last Thursday, continuing its steady buying streak in the Jack Ma-founded company. The firm had already added $5.5 million worth of shares on Wednesday and $4.1 million the day before.  The Brera Holdings Trade  Ark Invest trimmed its stake in Brera Holdings, unloading 54,400 shares from its ARKK ETF. The stock ended the session at $21.91, down 11.94%, with the sale valued at roughly $1.2 million.    Brera Holdings recently made headlines with its Solana (CRYPTO: SOL) Treasury Strategy, which initially led to a 225% surge in its stock. However, the stock has since seen a pullback, reflecting market volatility and investor sentiment.  Ark has been selling Brea stock lately, with $1.1 million worth of shares sold last Thursday. Last month, Ark had picked up 6,500,001 shares worth $162 million.
Save my User ID and Password  Some subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.  Note: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.
Hedge fund billionaire Paul Tudor Jones, founder and CIO of Tudor Investment Corporation, has raised alarms about the state of financial markets in 2025, drawing pointed comparisons to the explosive tech-driven boom of 1999, while clarifying that today’s environment could be “so much more potentially explosive.” The reason why has to do with what the market veteran knows about how bull markets always play out.  Speaking to Andrew Ross Sorkin of the New York Times’ DealBook on CNBC’s Squawk Box ahead of the upcoming Robin Hood Foundation investor conference, Jones described today’s investment climate as uncannily similar to the one that preceded the 2000 dotcom bust.  “It feels exactly like 1999,” he said, implying that the market was acting like the famous Prince song with the lyrics, “Party like it’s 1999.” He urged investors to position themselves like it’s October 1999, when the Nasdaq doubled in a matter of months before collapsing, a pattern Jones sees as increasingly plausible today. The difference is that this could be even worse than the dotcom bust, he said.  Jones told Sorkin his concerns had to do with investor behavior in every bull market, specifically at the end, when the cliff is nearing and nobody is sure where it is.  The stampede  Jones underscored that in every bull market, the “greatest price appreciation is always the 12 months preceding the top,” like what happened after October 1999. For investors, he said, the challenge is timing: “If you don’t play it, you’re missing out on the juice. If you do play it, you…have to have really happy feet because there will be a really, really bad end to it,” he said, seeming to refer to the American football phrase for when a quarterback is antsy and tiptoeing around the pocket, rather than standing their ground.  “If anything, now is so much more potentially explosive than 1999,” Jones argued, citing the backdrop of the Federal Reserve cutting interest rates. He noted the Fed is set up for several rate cuts, with monetary policy taking the economy to a real interest rate of zero, meaning incentives to invest and spend given such a low cost of capital. In terms of fiscal policy, the Congress had a budget surplus in 1999 and today it has a 6% budget deficit. “That fiscal/monetary combination is a brew that we haven’t seen since, I guess, the postwar period, early ’50s, something like that,” he said. “And that was crazy times, right? Coming out of the war.”  Still, Jones insisted he wasn’t calling a bubble or predicting a crash.
A top Wall Street analyst has sounded an alarm over the U.S. equity bull market, warning that its remarkable run is built on a precariously narrow foundation: a surge in spending on, and optimistic assumptions about, infrastructure for artificial intelligence (AI). This spending has fueled a boom in the shares of most of the so-called Magnificent 7 and a few dozen related businesses, which have now come to account for roughly 75% of the S&P 500’s returns since the rally of the last few years began.  The commentary on September 29 by Morgan Stanley Wealth Management’s chief investment officer, Lisa Shalett, frames the current market boom as a “one-note narrative” almost entirely dependent on massive capital expenditures in generative AI, raising questions about its durability as economic and competitive risks start to mount. Shalett’s critique came squarely in the middle of some people in the AI field — and many financial commentators around Wall Street —fretting at market exuberance and beginning to talk openly about a bubble.  In an interview with Fortune, Shalett said she was “very concerned” about this theme in markets, saying her office had broadened from a belief that the market would only bid up seven or 10 stocks to roughly 40. “At the end of the day … this is not going to be pretty” if and when the generative AI capital expenditure story falters, she said.  Shalett said she’s worried about a “Cisco moment” like when the dotcom bubble burst in 2000, referring to the company that was briefly the most valuable company in the world before an 80% stock plunge. When asked how close we are to such a moment, Shalett said probably not in the next nine months, but very possibly in the next 24. When you look at the actual spending and the amount of capital coming into the space, “we’re a lot closer to the seventh inning than the first or second inning,” she said.  ‘Starting to do what all ultimate bad actors do’  Shalett’s comments centered on several recent multibillion-dollar deals to scale up data-center infrastructure. As notable substacker and former Atlantic writer Derek Thompson recently noted in a post titled “This is how the AI bubble will pop,” so much money is being spent to support AI’s energy-consumption needs that it’s the equivalent of a new Apollo space mission every 10 months. (Tech companies are spending roughly $400 billion this year alone on data-center infrastructure, while the Apollo program allocated about $300 billion in today’s dollars to get to the moon from the 1960s to the ’70s.)  What’s more than a little concerning to Shalett is that one company alone, Nvidia—the most valuable company in the history of the world, with an over $4.5 trillion market cap—is at the center of a significant number of these deals. In September alone, Nvidia invested $100 billion in OpenAI in a massive deal, just days after pledging $5 billion to Intel (the Intel agreement was tied to chips, not data-center infrastructure, per se).  Fortune‘s Jeremy Kahn reported in late September on significant concerns about “circular” financing, or Nvidia’s cash essentially being recycled throughout the AI industry. Shalett sees this as a major concern and a major sign that the business cycle is headed toward some kind of endgame. “The guy at the epicenter, Nvidia, is basically starting to do what all ultimate bad actors do in the final inning, which is extending financing, they’re buying their investors.”  Shalett expanded on her concerns by saying that companies around Nvidia “are starting to become interwoven.” She noted that OpenAI is partially owned by Microsoft, but now Nvidia has also made an investment in the startup, while Oracle and AMD each have their own purchasing agreements with OpenAI. But OpenAI also has a data-center deal with tech giant Oracle, with the “bad news,” Shalett notes, that this deal is “totally debt-financed.” OpenAI also struck a deal in October with chip-maker AMD that allows OpenAI to buy up to 10% of AMD. “Essentially, Nvidia’s main competitor is going to be partially owned by OpenAI, which is partially owned by Nvidia. So, Nvidia can ‘own’ a piece of its largest competitor. It is totally circular and increases systemic risk.”  When reached for comment, a spokesperson for Nvidia said, “We do not require any of the companies we invest in to use Nvidia technology.”  Nvidia CEO Jensen Huang discussed the OpenAI investment in an appearance on the Bg2 podcast with Brad Gerstner and Clark Tang on September 25, calling it an “opportunity to invest” and part of a partnership geared toward helping OpenAI build their own AI infrastructure. When asked about the allegation of circular financing in general and the Cisco precedent in particular, Huang talked about how OpenAI will fund the deal, arguing that it will have to be funded by OpenAI’s future revenues, or “offtake,” which he pointed out are “growing exponentially,” and by its future capital, whether it’s raised by a sale of equity or debt. That will depends on investors’ confidence in OpenAI, he said, and beyond that, it’s “their company, it’s not my business. And of course, we have to stay very close to them to make sure that we build in support of their continued growth.”  Shalett said that she and her team were “starting to watch” for signs of a bubble popping, highlighting the deal announced roughly a week before OpenAI struck its $100 billion data-center deal with Nvidia, when it struck another with Oracle worth $300 billion. Analysts at KeyBanc Capital Markets estimated that Oracle will have to borrow $100 billion of that amount—$25 billion a year for the next four years.  “Every morning the opening screen on my Bloomberg is what’s going on with CDS spreads on Oracle debt,” Shalett said, referring to credit default swaps, the financial instrument that was obscure before the Great Financial Crisis, but infamous for the role it played in a global market meltdown. CDSs essentially serve as insurance to investors in case of insolvency by a market entity. “If people start getting worried about Oracle’s ability to pay,” Shalett said, “that’s gonna be an early indication to us that people are getting nervous.” She added that all the indications to her speak of the end of a cycle and history is littered with cautionary tales from such times.  Oracle did not respond to requests for comment.  90% growth since the last bear market  Since the October 2022 bear market bottom and the launch of ChatGPT, according to Shalett’s calculations, the S&P 500 has soared 90%, but most of these gains have come from a small group of stocks. The so-called “Magnificent Seven”—including high-profile names like Nvidia and Microsoft—plus another 34 AI data-center ecosystem companies, are responsible for, as cited by Shalett and separately by JP Morgan Asset Management’s Michael Cembalest, about three-quarters of overall market returns, 80% of earnings growth, and a staggering 90% of capital spending growth in the index. Comparatively, the other 493 names in the S&P 500 are up just 25%—showing just how concentrated the rally has become.  The so-called “hyperscaler” companies alone are now spending close to $400 billion annually on capex supporting AI infrastructure, Morgan Stanley Wealth Management calculated. The economic influence of AI capex is now immense, contributing an estimated 100 basis points—fully one percentage point—to second-quarter GDP growth, according to Morgan Stanley’s research. This pace outstrips the rate of underlying consumer spending growth by tenfold, underscoring its centrality to both market performance and broader economic data.  “People conflate AI adoption, which is in the first inning, with the capex infrastructure buildout, which has been going full-out since 2022,” Shalett told Fortune. She cited concerns about the prominence of private equity and debt capital coming into play, as that “tends to produce bubbles, because it may be unspoken-for capacity.” In other words, people have money to burn and they’re throwing it at things that may not pay off.  Shalett waved away macro theories about the labor market or the Federal Reserve. “We think that’s missing the forest for the trees because the forest is entirely rooted in this one story” about AI infrastructure. Morgan Stanley’s bull-case mid-2026 price target for the S&P 500 is an eye-popping 7,200, but Shalett highlights that even the most optimistic outlook admits that risk premiums, credit spreads, and market volatility do not seem to fully account for the vulnerabilities lurking beneath the AI-fueled advance.  Shalett’s analysis suggests that AI capex maturity is approaching and some possible slowdowns are already visible. For instance, hyperscalers have already seen free-cash-flow growth turn negative, a sign that investment may have outpaced underlying technology returns. Strategas, an independent research firm, estimates that hyperscaler free cash flow is set to shrink by more than 16% over the next 12 months, putting pressure on lofty valuations and forcing investors to demand more discipline in how these funds are deployed.  Shalett was asked about data centers’ disproportionate impact on GDP throughout 2025, which media blogger Rusty Foster of Today in Tabs described as: “Our economy might just be three AI data centers in a trench coat.” The Morgan Stanley exec said “That’s what makes this cycle so fragile,” adding that at some point, “we’re not gonna be building any data centers for a while.” After that, it’s just a question of whether you crash: “Do you have a mild 1991-92-style recession or does it really become bad?”  A more bullish case  Bank of America Research weighed in on the semiconductors sector in a Friday note, writing that vendor financing in the space, especially Nvidia’s $100 billion commitment to OpenAI, has been “raising eyebrows.” Nevertheless, the team, led by senior analyst Vivek Arya, argued that the deal is structured by performance and competitive need, rather than pure speculative frenzy.  In an interview with Fortune, Arya explained why he wasn’t worried despite the “optics” being pretty obviously bad. “It’s very easy to say, ‘Oh, Nvidia is giving [OpenAI] money and they are buying chips with that money” and so on, but he argued the headlines are misleading about how much money is actually being spent and the $100 billion sticker price on the OpenAI deal “scared everyone.” Noting that the deal has multiple tranches that will play out over several years to come, he said it’s not like Nvidia is “just handing a $100 billion check to OpenAI [and saying] you know, go have fun.”  “Nvidia didn’t fund all of it,” Arya said of the wider generative AI capex boom. Citing public filings, Arya argued that Nvidia’s entire investment in the AI ecosystem is in fact less than $8 billion or so over the last 12 months, not such a large figure after all. And he’s still bullish on Nvidia and OpenAI, he added, because he sees them as the winners of this particular story. “We think they are going to be among the four or five ecosystems that come up. It’s not like Nvidia is going and investing in every one of those ecosystems, right? They’re only investing in one of those five, which is, of course, the most disruptive,” that being OpenAI.  When asked about his own fears of a bubble, Arya actually sounded a calmer but strikingly similar tune to Shalett. “I’m extremely comfortable with what will happen in the next 12 months,” Arya said, “And I have high sense of optimism about what will happen in the next five years. But can there be periods of digestion in between? Yeah.” Explaining that this is the nature of any infrastructure cycle, “it’s not always up and to the right.” In other words, after the next nine months in Shalett’s opinion and the next year in Arya’s, the data-center buildout endgame could be in play. “When these data centers are built,” Arya said, “they are not built for today’s demand. They’re built with some anticipation of demand that will develop in the next, you know, 12 to 18 months. So, are they going to be 100% utilized all the time? No.”  Rising worries about a bubble  Some of the biggest names in tech and Wall Street offered were hedging hard about the possibility of a bubble on Friday. Goldman Sachs CEO David Solomon and Jeff Bezos, both speaking at a tech conference in Turin, Italy, said they were seeing the same patterns as Shalett. Solomon said the massive amounts of spending weren’t fundamentally different from other booms and busts. “There will be a lot of capital that was deployed that didn’t deliver returns,” he said. That’s no different from how investment works. “We just don’t know how that will play out.”  Bezos characterized it as “kind of an industrial bubble,” arguing that the infrastructure would pay off for many years to come.  OpenAI CEO Sam Altman, who got markets jittery in late August when he mentioned the B-word, was asked again to comment on the subject while touring (what else?) a giant new data center in Texas. “Between the 10 years we’ve already been operating and the many decades ahead of us, there will be booms and busts,” Altman said. “People will overinvest and lose money, and underinvest and lose a lot of revenue.”  For his part, Cisco CEO John Chambers, one of the faces of the dotcom bubble, told the Associated Press on October 3 that he sees “a lot of tremendous optimism” about AI that is similar to the “irrational exuberance on a really large scale” that marked the internet age. It indicates a bubble to him, but only “a future bubble for certain companies. Is there going to be train wreck? Yes, for those that aren’t able to translate the technology into a sustainable competitive advantage, how are you going to generate revenue after all the money you poured into it?”  When asked whether the size of this potential bubble represents uncharted waters for the economy, especially considering the one-note nature of the long bull market, Shalett said Wall Streeters are always evaluating risk. But putting on her “American citizen hat,” she warned about the media consolidation that sees Oracle’s founder Larry Ellison also now playing a major role in TikTok (as part of a buying consortium of Trump-friendly billionaires) and Paramount in Hollywood and CBS News in New York (through his son, David Ellison, the media company’s new owner). Shalett said she’s worried about “groupthink” filtering into the functioning of markets. “That is not something that most of us have experienced in our lifetimes,” she said. “You stop factoring in risk premiums into markets, there is no bear case to anything.”
The technical storage or access that is used exclusively for statistical purposes.  The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.
Listen and subscribe to Opening Bid Unfiltered on Apple Podcasts, Amazon Music, Spotify, YouTube, or wherever you find your favorite podcasts.  While Warren Buffett said, “our favorite holding period is forever,” occasional investor skittishness is nothing new. Yet has it gone to extremes?  Despite solid stock market performance this year, “I think that we’re in a period where people are not sure about capitalism,” "Mad Money" host Jim Cramer told Yahoo Finance's Brian Sozzi on a new episode of the Opening Bid Unfiltered podcast (see video above; listen below).  “I do believe we’re still stuck with what happened in 2000 and 2008, which were both horrendous,” he continued. “Although if you held on to the Mercks of the world, you ended up doing fine.”  Cramer has sat in the host chair of "Mad Money" for nearly two decades and is the author of several books, including the recently published "How to Make Money in Any Market." He has studied markets and worked to demystify them for the average investor. He was one of the first to call out Nvidia (NVDA) — “my best pick” — when it was just a gaming company. He also had a hand in coining the acronym FAANG (Facebook, now Meta (META), Apple (AAPL), Amazon (AMZN), Netflix (NFLX), and Google (GOOG), now Alphabet (GOOGL).  Save the date for Yahoo Finance's BIG Invest event!  “FAANG was the greatest creator of wealth in my life other than Nvidia, and I think my job was to find great stocks,” Cramer said. “But I wanted people to understand why I thought they were great.”  For many young investors, crypto and the hot stocks of the moment often crowd out the more traditional names and advice, leaving them susceptible to more volatile investments. “Compounding is so boring,” Cramer said. “People think it’s too hard. They don’t understand what the P/E means. They don’t understand what it means to buy and hold a great stock.”  This shorter-term thinking contrasts with Buffett’s sentiment on the stock market. He once said, “If you aren’t willing to own a stock for 10 years, don’t even think about owning it for 10 minutes.”  Read more: How do millionaires make their money​?  Year to date, markets remain stable. The S&P 500 (^GSPC) is up nearly 15% while the Russell 2000 (^RUT) is up 11.61%, and the Dow Jones Industrial Average (^DJI) is up 9.76%. Top S&P 500 performers during this same time period include Robinhood (HOOD), Seagate Technology (STX), Western Digital (WDC), Newmont (NEM), and Palantir (PLTR).  Impatience and skittishness are only two obstacles, according to Cramer. “The market got a bad rap because it seemed to be the playground of billionaires,” he said. “It got to be the image of the filthy rich, and the billionaires don’t help.”
New York —  OpenAI was an artificial intelligence research lab little known outside of Silicon Valley before ChatGPT debuted in November 2022.  Three years later, OpenAI has become synonymous with the AI boom, making it the envy of its tech peers and thrusting CEO Sam Altman into President Donald Trump’s orbit. ChatGPT writes apps, plans trips and browses the web on users’ behalf. And OpenAI is making inroads into shopping, entertainment, education and government services — laying out plans to become more like a platform than a basic app in its developer conference on Monday.  As its software spills into more areas of online life, OpenAI is shelling out billions to become a leading player in the physical infrastructure for the AI future. With its latest major investment, announced on Monday, OpenAI will invest in 6 gigawatts of data center capacity powered by AMD chips. That deal follows similar agreements with Nvidia and Oracle.  In some ways, OpenAI’s expansion is circular — it needs new applications to bring in the money to fund its massive computing power. And it needs even more computing resources to power those new tools.  OpenAI’s rapid expansion comes against a challenging backdrop. Tech companies are competing fiercely to build the most powerful AI models, but some investors worry the market is in a bubble. What’s more, OpenAI is competing with tech giants such as Meta that already have vast tech ecosystems to help them expand and earn money from their AI tech. And OpenAI, which is not yet profitable, needs to find a way to continue raking in huge amounts of cash to fund its future endeavors.  OpenAI did not respond to a request for comment on this story.  ChatGPT: More than just a chatbot  Google, Amazon and Meta laid the groundwork for the modern web by popularizing search engines, e-commerce and social media. OpenAI could do the same for the AI era by adding new capabilities to ChatGPT, which now has 800 million weekly active users, according to Altman.  OpenAI wants users to get things done online without ever having to leave ChatGPT, which could one day put the app at the core of how people use technology, much like Apple’s iOS or Google’s Android system. Soon ChatGPT will be able to create user playlists directly on Spotify or browse apartment listings on Zillow right from chats, OpenAI announced on Monday.  In late September, OpenAI launched a tool called Instant Checkout that lets users buy certain items directly through ChatGPT.  ChatGPT also now has a study mode, which tailors prompts and responses for students using the tool for schoolwork. And its new Sora 2 app is challenging Meta and TikTok with a scrollable feed of AI-generated short-form videos.  ChatGPT on App Store displayed on a phone screen is seen in this illustration photo taken in Krakow, Poland on September 14, 2025. Jakub Porzycki/NurPhoto/Getty Images  OpenAI could even challenge the most prominent device in consumers’ daily lives: the smartphone. The company is collaborating with former Apple design chief Jony Ive on a new AI hardware product, though details are slim. (OpenAI’s peers like Google and Meta are chasing hardware markets by releasing smart glasses with built-in AI assistants.)  OpenAI’s trajectory mirrors the rise of Google parent Alphabet, which built its business around indexing the web and now has a foothold in everything from consumer tech devices to health research.  Thomas Thiele, an AI expert at management consulting group Arthur D. Little, said he sees similarities between the two companies.  Google “has become this very broad corporation that has an inevitable footprint in everything we see on the internet,” Thiele said. “OpenAI is also aiming for a much bigger footprint.”  Billions on data centers  But scaling up those AI efforts means investing heavily in the sprawling data centers and infrastructure necessary to power them. OpenAI is shelling out billions of dollars to build a massive physical footprint, with plans for AI data centers across the United States and around the world.  “We need as much computing power as we can possibly get,” OpenAI President Greg Brockman told CNBC on Monday.  In January, the company announced a partnership with Oracle and SoftBank to invest up to $500 billion in a company called Stargate to build more AI infrastructure in the United States. The group’s first project, a one-million-square-foot data center, is already under construction in Abilene, Texas, with additional sites planned in Texas, New Mexico and the Midwest. OpenAI agreed in July to pay Oracle another $300 billion over five years to develop additional data center capacity for Stargate.  Last month, OpenAI said it would buy enough Nvidia AI chips to power 10 gigawatts of data center capacity in exchange for a $100 billion investment from the chipmaker. And while analysts expect Nvidia — the undisputed leader in AI chips — to remain OpenAI’s core infrastructure partner, the ChatGPT maker is now also hedging its bets with its AMD deal.  OpenAI has also signed onto partnerships to build out AI infrastructure abroad, including in the United Kingdom and United Arab Emirates.  The Stargate AI data center in Abilene, Texas on September 24, 2025. Stargate is a collaboration between OpenAI, Oracle and SoftBank to build data centers and other infrastructure for AI in the US. Kyle Grillot/Bloomberg/Getty Images  OpenAI’s aggressive expansion could be critical to keep up with rivals like Meta, Microsoft and Google that have spent decades building their digital ecosystems, said Daniel Keum, an associate professor at Columbia Business School. Google, for example, has the advantage of plugging its AI into popular services like Gmail and Google Docs.  “ChatGPT is great right now, but it’s not ChatGPT versus Copilot. It’s ChatGPT versus the Microsoft bundle,” said Keum. So for OpenAI, working with chipmakers to maintain the most advanced large language models could give it a leg up, he said.  But to carry out its ambitious infrastructure plans, OpenAI needs to continue bringing in a whole lot of cash.  The company is reportedly valued at $500 billion. But it’s still far from profitable; it posted an operating loss of $7.8 billion in the first half of 2025 and is still ramping up data center spending, according to a report from tech news site The Information.  It’s unclear whether OpenAI’s bid to turn ChatGPT into an all-encompassing platform will put it on the path to profitability. William Lee, a corporate investor at SuRo Capital, sees it as a “chicken-or-the-egg” problem, he said in an interview with CNN. Demand may be hard to gauge ahead of time, but the more OpenAI customizes ChatGPT for tasks like shopping and schoolwork, the more people could use it for those activities.  It’s a strategy that has worked for the tech giants of today — spend aggressively to make your technology essential to millions of users’ lives, figure out how to make money from them later.  OpenAI is clearly betting that it will pay off again.  “AI revenue is growing faster than, I think, almost any product in history,” Brockman told Bloomberg. “At the end of the day, the reason this compute power is so important, is so worthwhile for everyone to build, is because the revenue ultimately will be there.”
ASUS and GoPro announced today a comprehensive partnership that introduces StoryCube, the world’s first Windows application to integrate GoPro Cloud media with native 360° video support and AI-powered workflow optimization. The collaboration launches with exclusive GoPro Premium+ subscription bundles, ASUS Dial integration, and positions the ProArt P16 as the flagship platform for professional 360° content creation.  Designer: ASUS + GoPro  The partnership targets five distinct creator categories: Travel Vloggers & YouTubers, Advanced Photographers & Videographers, Studio Creators, Sports Content Curators, and Adventurous Content Curators, establishing what ASUS calls “a shared space where adventure inspires storytelling: and storytelling elevates every adventure.”  StoryCube: AI-Driven Content Management System  StoryCube functions as an ASUS-exclusive, intelligent digital asset management application that becomes the world’s first Windows software supporting both GoPro Cloud media and 360° video formats. The application allows creators to preview native .360 files whether stored locally or online, with seamless integration for GoPro MAX and MAX2 360° footage reframing.  The AI model receives specific training on GoPro and action camera imagery to recognize common scenes and activities including biking, surfing, snowboarding, and wave activities. Scene categorization incorporates both automatic face recognition and GPS location data from GoPro cameras, enabling creators to locate source material through multiple organizational methods.  Advanced AI Album Features  StoryCube’s AI Album provides automatic categorization based on “GoPro popular activities” with scene recognition trained specifically on action camera scenarios. The system supports text and image-based searching, allowing creators to find related assets by typing single words or uploading reference photos to locate similar content.  Technical limitations include specific 360° file handling: native .360 files cannot be recognized for AI Album categorization, while 360° videos in .mov and .mp4 formats support full AI categorization. Similarly, .360 files cannot utilize Map and Timeline viewing features, though .mov and .mp4 360° videos with GPS and timestamp information support these organizational tools.  Comprehensive Workflow Integration  The StoryCube workflow encompasses five primary stages: GoPro Cloud access through direct login, AI-powered categorization and management, Map & Timeline viewing by location and time, basic editing capabilities including cropping, trimming, speed adjustment, and contrast/exposure/saturation/brightness controls, and seamless file transfer to professional editing software through drag-and-drop functionality.  Integration with Adobe Premiere Pro and CapCut includes direct drag-and-drop support from StoryCube, with ASUS providing Adobe and CapCut free bundles for ProArt customers. The application connects to ASUS Dial & Control Panel, offering convenient shortcuts for enhanced creative control during editing workflows.  GoPro Premium+ Subscription Strategy and Redemption Process  The partnership includes structured subscription benefits with specific monetary valuations: ProArt laptops provide six-month complimentary GoPro Premium+ subscriptions valued at $49.99, while ZenBook and Vivobook models offer three-month Premium+ access valued at $29.99.  GoPro Premium+ subscriptions unlock unlimited cloud storage for GoPro footage, 500GB storage for non-GoPro files, guaranteed camera replacement, automatic highlight video generation, synced editing across mobile and desktop platforms, and exclusive savings on GoPro products.  MyASUS App Integration  The subscription redemption process operates through the MyASUS application with a three-step workflow: users launch MyASUS and sign in to access the GoPro offer in the coupon area, navigate from MyASUS to the GoPro event page for subscription and 15% camera discount offers, and select either the free subscription ($0) or GoPro products at 15% discount in the shopping cart.  The subscription offer operates from October 7, 2025, through December 31, 2027, with availability in selected territories and complete terms available through both ASUS and GoPro official channels.  ProArt P16: Flagship Hardware for 8K and 360° Processing  The ProArt P16 showcases hardware capabilities specifically designed for GoPro’s MAX2 360° camera True 8K footage processing. All configurations feature AMD Ryzen AI 9 HX 370 processor with 2.0GHz base frequency (up to 5.1GHz boost), 36MB cache, 12 cores, 24 threads, and XDNA NPU delivering up to 50 TOPS AI performance.  Four-Configuration Lineup Structure  The ProArt P16 (H7606) launches with four distinct configurations spanning consumer and professional requirements:  Consumer Configurations (Windows 11 Home):  H7606WP-P16.3KR95070: RTX 5070, 32GB LPDDR5X, 2TB NVMe SSD, 16″ 120Hz 2880×1800 OLED – $2,399.99  H7606WP-P16.R95070: RTX 5070, 32GB LPDDR5X, 2TB NVMe SSD, 16″ 60Hz 3840×2400 OLED – $2,499.99  Professional Configurations (Windows 11 Pro):  H7606WP-PB99T: RTX 5070, 64GB LPDDR5X, enhanced memory for professional workflows  H7606WX-XH99T: RTX 5090, 64GB LPDDR5X, flagship performance (Q4 2025 availability)  ASUS Lumina Pro OLED Display Technology  The ASUS Lumina Pro OLED touchscreen addresses specific 360° video editing requirements with up to 1600 nits HDR peak brightness (700 nits SDR), 120Hz refresh rate with Variable Refresh Rate (VRR) technology, and anti-reflective coating reducing glare by 65%. Color accuracy specifications include 100% DCI-P3 color gamut coverage with PANTONE validation for professional color workflows.  Professional Video Editing Capabilities  The RTX 5090 configuration delivers lightning-fast rendering at extreme resolutions with real-time smooth previews up to 16K and AI-powered tools for seamless stitching, reframing, and intelligent upscaling. Professional video editing support includes 10-bit 4:2:2 color format, dual AV1 encoders, and AI-accelerated enhancements including real-time stitching, frame interpolation, and video stabilization.  These specifications enable fluid multi-track 4K/8K playbook, faster exports, and enhanced stability for complex high-resolution projects involving 360° video editing workflows.  Comprehensive Hardware Specifications and Connectivity  All ProArt P16 configurations include identical connectivity specifications: USB 4.0 Gen 3 Type-C with 40Gbps data speeds and display/power delivery support, USB 3.2 Gen 2 Type-C with 10Gbps speeds, dual USB 3.2 Gen 2 Type-A ports at 10Gbps, HDMI 2.1 FRL output, 3.5mm combo audio jack, DC-in power, and SD Express 7.0 card reader.  Wireless connectivity features Wi-Fi 7 (802.11be) triple band 2×2 configuration with Bluetooth 5.4 support. Audio includes Smart Amp Technology with built-in speakers and array microphone systems. Power delivery utilizes 90WHrs 4S1P 4-cell Li-ion batteries with 200W AC adapters providing 20V DC at 10A output.  Physical specifications maintain consistency across configurations: 4.08 lbs weight, 13.97″ x 9.72″ x 0.59″ to 0.68″ dimensions, aluminum construction, and Nano Black color finish. All models include FHD cameras with IR functionality for Windows Hello authentication.  Enhanced Creative Tools Integration  The ProArt P16 integrates multiple ASUS-exclusive AI tools beyond StoryCube, including MuseTree for additional creative workflow optimization. The system operates as a Copilot+ PC with NVIDIA RTX AI acceleration, empowering GoPro creators to work with enhanced efficiency and intuitive control.  StoryCube’s integration with ASUS Dial & Control Panel provides hardware-level shortcuts for video editing workflows, allowing creators to access trimming, cropping, speed adjustment, and color correction tools through physical controls rather than software-only interfaces.  Target Creator Ecosystem and Market Positioning  The collaboration specifically addresses creator workflow bottlenecks in five key areas: content capture through GoPro cameras, seamless file transfer and organization via StoryCube, professional editing through Adobe Premiere Pro and CapCut integration, advanced editing control through ASUS Dial hardware, and comprehensive sharing workflows optimized for 360° content.  ASUS positions this partnership as targeting “Experiencer Curators” who focus on bridging experience and storytelling through professional editing techniques, creative tool usage, powerful device showcases, real-life captures, outdoor challenges and experiences, and strong user-generated content presence.  Availability and Purchase Details  The ProArt P16 (H7606) launches today through multiple channels: ASUS Store online, Best Buy in-store and online availability. Consumer configurations with RTX 5070 GPU are immediately available, while the flagship H7606WX-XH99T model featuring RTX 5090 GPU is scheduled for Q4 2025 release.  Best Buy provides dedicated product pages for both 3K 120Hz and 4K 60Hz OLED configurations, with pricing starting at $2,399.99 for entry RTX 5070 models. The RTX 5090 flagship configuration pricing remains unannounced pending Q4 2025 availability.  Strategic Partnership Vision  ASUS indicates this collaboration represents the beginning of broader creative technology initiatives, with additional products, technologies, and partnerships planned for storytellers. The strategic timing aligns with GoPro’s MAX2 360° camera release and growing market demand for professional immersive content creation tools.  The partnership’s taglines emphasize the experiential focus: “Be A Hero” and “Where Your Story Begins” for GoPro, combined with ProArt’s creator-centric “Be the Hero of Your Story” messaging, establishing a cohesive brand narrative around adventure-driven storytelling.  The ASUS ProArt x GoPro collaboration launches today, October 7, 2025, with StoryCube availability, GoPro Premium+ subscription activation, and ProArt P16 purchase options through established retail channels. The partnership extends through December 31, 2027, for subscription benefits and represents ASUS’s strategic positioning as the definitive Windows platform for professional GoPro workflows.
Emphasising the rapid evolution of Generative AI into Agentic AI models that are now autonomously addressing complex challenges in the financial sector, Vishal Dhupar, Managing Director of US-based Nvidia, remarked on Tuesday that Mumbai is poised to be recognised not just as the financial capital, but as the ‘financial capital with intelligence’.  Generative AI has moved on to agentic models which can solve many problems autonomously. For instance, a lady in a small town in Maharashtra wants to procure a product. She doesn’t know how to fill up forms, but she knows the image and uploads it. Agentic AI takes over; understands the UPI transaction she is making; her GST filing; her tone and intent; does the market research and comes back and says here is a product and I can offer as a bank against EMIs. It also speaks to the person in Marathi explaining what it is really. She accepts the product. That is truly, the power of generative AI, agentic AI workflows and that is where the universe is going and making a colossal difference — not only to new start ups, but to established banks,” Dhupar said while participating in a fire-side chat on the first day of the Global Fintech Fest 2025 (GFF) here.  “Mobiles brought banks to your pocket, Generative AI is bringing advisors with it,” he said, adding that AI is providing a combination of wealth, bank and insurance advisors that are looking to provide help in “your own language.” Pointing out that Agentic AI has been helping stall “frauds” and “rings of fraudsters” operating in the finance space, Dhupar said that with help of a single command, Agentic AI is able to understand the transactions taking place, verify external sites, identify the origins of the “menace” and stop the transaction beforehand. “It is preventive,” he said.  Talking about how AI will help the finance world in India, Dhupar said, “In 2028, India is going to be talking about population scale applications....I also believe that in 2028, we will be calling Mumbai, the financial capital with intelligence rather than just the finance capital.”  The Nvidia official said AI in future will be like electricity where it will be “both invisible and visible.”  “In the back end it is going to be invisible. All risks, compliances, credit worthiness will embed generative AI and many of them will be working autonomously and giving feedback. On the foreground, it will be visible to each one of us. It is going to be an advisor on different topics including finance. It will help their growth, Dhupar added.  Published on October 7, 2025
Save my User ID and Password  Some subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.  Note: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.
Listen to this post: Log in to listen  OpenAI’s flood of announcements are getting hard to keep up with. A selection — not exhaustive! — from just the last month:  The last two announcements just dropped yesterday, and actually bring clarity and coherence to the entire list. In short, OpenAI is making a play to be the Windows of AI.  For nearly two decades smartphones, and in particular iOS, have been the touchstones in terms of discussing platforms. It’s important to note, however, that while Apple’s strategy of integrating hardware and software was immensely profitable, it entailed leaving the door open for a competing platform to emerge. The challenge of being a hardware company is that by virtue of needing to actually create devices you can’t serve everyone; Apple in particular didn’t have the capacity or desire to go downmarket, which created the opportunity for Android to not only establish a competing platform but to actually significantly exceed iOS in market share.  That means that if we want a historical analogy for total platform dominance — which increasingly appears to be OpenAI’s goal — we have to go back further to the PC era and Windows.  Platform Establishment  Before there was Windows there was DOS; before DOS, however, there was a fast-talking deal-making entrepreneur named Bill Gates. From The Truth About Windows Versus the Mac:  In the late 1970s and very early 1980s, a new breed of personal computers were appearing on the scene, including the Commodore, MITS Altair, Apple II, and more. Some employees were bringing them into the workplace, which major corporations found unacceptable, so IT departments asked IBM for something similar. After all, “No one ever got fired for buying IBM.” IBM spun up a separate team in Florida to put together something they could sell IT departments. Pressed for time, the Florida team put together a minicomputer using mostly off-the shelf components; IBM’s RISC processors and the OS they had under development were technically superior, but Intel had a CISC processor for sale immediately, and a new company called Microsoft said their OS — DOS, which they acquired from another company — could be ready in six months. For the sake of expediency, IBM decided to go with Intel and Microsoft. The rest, as they say, is history. The demand from corporations for IBM PCs was overwhelming, and DOS — and applications written for it — became entrenched. By the time the Mac appeared in 1984, the die had long since been cast. Ultimately, it would take Microsoft a decade to approach the Mac’s ease-of-use, but Windows’ DOS underpinnings and associated application library meant the Microsoft position was secure regardless.  There is nothing like IBM and its dominant position in enterprise today; rather, the route to becoming a platform is to first be a massively popular product. Acquiring developers and users is not a chicken-and-egg problem: it is clear that you must get users first, which attracts developers, enhancing your platform in a virtuous cycle; to put it another way, first a product must Aggregate users and then it gets developers for free.  ChatGPT is exactly that sort of product, and at yesterday’s DevDay 2025 keynote CEO Sam Altman and team demonstrated exactly that sort of pull; from The Verge:  OpenAI is introducing a way to work with apps right inside ChatGPT. The idea is that, from within a conversation with the chatbot, you can essentially tag in apps to help you complete a task while ChatGPT offers context and advice. The company showed off a few different ways this can work. In a live demo, an OpenAI employee launched ChatGPT and then asked Canva to create a poster of a name for a dog-walking business; after a bit of waiting, Canva came back with a few different examples, and the presenter followed up by asking for a generated pitch deck based on the poster. The employee also asked Zillow via ChatGPT to show homes for sale in Pittsburgh, and it created an interactive Zillow map — which the employee then asked follow-up questions about. Apps available inside ChatGPT starting today will include Booking.com, Canva, Coursera, Expedia, Figma, Spotify, and Zillow. In the “weeks ahead,” OpenAI will add more apps, such as DoorDash, OpenTable, Target, and Uber. OpenAI recently started allowing ChatGPT users to make purchases on Etsy through the chatbot, part of its overall push to integrate it with the rest of the web.  It’s fair to wonder if these app experiences will measure up to these company’s self-built apps or websites, just as there are questions about just how well the company’s Instant Checkout will convert; what is notable, however, is that I disagree that this represents a “push to integrate…with the rest of the web”.  This is the opposite: this is a push to make ChatGPT the operating system of the future. Apps won’t be on your phone or in a browser; they’ll be in ChatGPT, and if they aren’t, they simply will not exist for ChatGPT users. That, by extension, means the burden of making these integrations work — and those conversions performant — will be on third party developers, not OpenAI. This is the power that comes from owning users, and OpenAI is flexing that power in a major way.  Second Sourcing  There is a second aspect to the IBM PC strategy, and that is the role of AMD. From a 2024 Update:  While IBM chose Intel to provide the PC’s processor, they were wary of being reliant on a single supplier (it’s notable that IBM didn’t demand the same of the operating system, which was probably a combination of not fully appreciating operating systems as a point of integration and lock-in for 3rd-party software, which barely existed at that point, and a recognition that software is just bits and not a physical good that has to be manufactured). To that end IBM demanded that Intel license its processor to another chip firm, and AMD was the obvious choice: the firm was founded by Jerry Sanders, a Fairchild Semiconductor alum who had worked with Intel’s founders, and specialized in manufacturing licensed chips.  The relationship between Intel and AMD ended up being incredibly fraught and largely documented by endless lawsuits (you can read a brief history in that Update); the key point to understand, however, is that (1) IBM wanted to have dual suppliers to avoid being captive to an essential component provider and (2) IBM had the power to make that happen because they had the customers who were going to provide Intel so much volume.  The true beneficiary of IBM’s foresight, of course, was Microsoft, which controlled the operating system; IBM’s mandate is why it is appropriate that “Windows” comes first in the “Wintel” characterization of the PC era. Intel reaped tremendous profits from its position in the PC value chain, but more value accrued to Microsoft than anyone else.  This question of who will capture the most profit from the AI value chain remains an open one. There’s no question that the early winner is Nvidia: the company has become the most valuable in the world by virtue of its combination of best-in-class GPUs, superior networking, and CUDA software layer that locks people into Nvidia’s own platform. And, as long as power is the limiting factor, Nvidia is well-placed to maintain its position.  What Nvidia is not shy about is capturing its share of value, and that is a powerful incentive for other companies in the value chain to look for alternatives. Google is the furthest along in this regard thanks to its decade-old investment in TPUs, while Amazon is seeking to mimic their strategy with Trainium; Microsoft and Meta are both working to design and build their own chips, and Apple is upscaling Apple Silicon for use in the data center.  Once again, however, the most obvious and most immediately available alternative to Nvidia is AMD, and I think the parallels between yesterday’s announcement of an OpenAI-AMD deal and IBM’s strong-arming of Intel are very clear; from the Wall Street Journal:  OpenAI and chip-designer Advanced Micro Devices announced a multibillion-dollar partnership to collaborate on AI data centers that will run on AMD processors, one of the most direct challenges yet to industry leader Nvidia. Under the terms of the deal, OpenAI committed to purchasing 6 gigawatts worth of AMD’s chips, starting with the MI450 chip next year. The ChatGPT maker will buy the chips either directly or through its cloud computing partners. AMD chief Lisa Su said in an interview Sunday that the deal would result in tens of billions of dollars in new revenue for the chip company over the next half-decade. The two companies didn’t disclose the plan’s expected overall cost, but AMD said it costs tens of billions of dollars per gigawatt of computing capacity. OpenAI will receive warrants for up to 160 million AMD shares, roughly 10% of the chip company, at 1 cent per share, awarded in phases, if OpenAI hits certain milestones for deployment. AMD’s stock price also has to increase for the warrants to be exercised.  If OpenAI is the software layer that matters to the ecosystem, then Nvidia’s long-term pricing power will be diminished; the company, like Intel, may still take the lion’s share of chip profits through sheer performance and low-level lock-in, but I believe the most important reason OpenAI is making this deal is to lock in its own dominant position in the stack. It is pretty notable that this announcement comes only weeks after Nvidia’s investment in OpenAI; that, though, is another affirmation that the company who has the users has the ultimate power.  There is one other part of the stack to keep an eye on: TSMC. Both Nvidia and AMD make their chips with the Taiwanese giant, and while TSMC is famously reticent to take price, they are positioned to do so in the long run. Altman surely knows this as well, which means that I wouldn’t be surprised if there is an Intel announcement sooner rather than later; maybe there is fire to that recent smoke about AMD talking with Intel?  The AI Linchpin  When I started writing Stratechery, Windows was a platform in decline, superceded by mobile and, surprisingly enough, increasingly challenged by its all-but-vanquished ancient foe, the Mac. To that end, one of my first pieces about Microsoft was about then-CEO Steve Ballmer’s misguided attempt to focus on devices instead of services. I wrote a few years later in Microsoft’s Monopoly Hangover:  The truth is that both [IBM and Microsoft] were victims of their own monopolistic success: Windows, like the System/360 before it, was a platform that enabled Microsoft to make money in all directions. Both companies made money on the device itself and by selling many of the most important apps (and in the case of Microsoft, back-room services) that ran on it. There was no need to distinguish between a vertical strategy, in which apps and services served to differentiate the device, or a horizontal one, in which the device served to provide access to apps and services. When you are a monopoly, the answer to strategic choices can always be “Yes.”  Microsoft at that point in time no longer had that luxury: the company needed to make a choice — the days of doing everything were over — and that choice should be services (which is exactly what Satya Nadella did).  Ever since the emergence of ChatGPT made OpenAI The Accidental Consumer Tech Company I have been making similar arguments about OpenAI: they need to focus on the consumer opportunity and leave the enterprise API market to Microsoft. Not only would focus help the company capture the consumer opportunity, there was the opportunity cost of GPUs used for the API that couldn’t be used to deliver consumers a better experience across every tier.  I now have much more appreciation for OpenAI’s insistence on doing it all, for two reasons. First, this is a company in pure growth mode, not in decline. Tradeoffs are in the long run inevitable, but why make them before you need to? It would have been a mistake for Microsoft to restrict Windows to only the enterprise in the 1980s, even if the company had to low-key retreat from the consumer market over the last fifteen years; there was a lot of money to make before that retreat needed to happen! OpenAI, meanwhile, is the hottest brand in AI, so why not make a play to own it all, from consumer touchpoint to API to everything in-between?  Second, we’ve obviously crossed the line into bubble territory, which always was inevitable. The question now is whether or not this is a productive bubble: what durable infrastructure will be built by eventually bankrupt companies that we benefit from for years to come?  GPUs are not that durable infrastructure; data centers are more long-lasting, but not worth the financial pain of a bubble burst. The real payoff would be a massive build-out in power generation, which would be a benefit for the next half a century. Another potential payoff would be the renewed viability of Intel, and as I noted above, OpenAI may be uniquely positioned and motivated to make that happen.  More broadly, this play to be the Windows of AI effectively positions OpenAI as the linchpin of the entire AI buildout. Just look at what the mere announcement of partnerships with OpenAI has done for the stocks of Oracle and AMD. OpenAI is creating the conditions such that it is the primary manifestation of the AI bubble, which ensures the company is the primary beneficiary of all of the speculative capital flooding into the space. Were the company more focused, as I have previously advised, they may not have the leverage to get enough funding to meet those more modest (but still incredible) goals; now it’s hard to see them not getting whatever money they want, at least until the bubble bursts.  What’s amazing about this overview is that I only scratched the surface of what OpenAI announced both yesterday and over the last month — and I haven’t even mentioned Sora (although I covered that topic yesterday). What the company is seeking to achieve is incredibly audacious, but also logical, and something we’ve seen before:  And, interestingly enough, there is an Apple to OpenAI’s Microsoft: it’s Google, with their fully integrated stack, from chips to data centers to models to end user distribution channels. Instead of taking on a menagerie of competitors, however, Google is facing an increasingly unified ecosystem, organized, whether they wish to be or not, around OpenAI. Such is the power of aggregating demand and the phenomenon that is ChatGPT.
This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.  When Sriram Krishnan, a senior White House policy advisor on artificial intelligence, appeared onstage at an event in Washington last month, he listed the Trump administration's priorities for advancing the AI revolution.  At the top of the list? More construction.  "Let's make sure we build our infrastructure," Krishnan said. "'Build, baby, build' is what we tell people."  That rallying cry is echoing across Silicon Valley. Executives at Meta say they expect to spend $600 billion on AI infrastructure, including massive data centers, through 2028. OpenAI and Oracle have announced plans to put $500 billion into a data center project dubbed Stargate, while Amazon plans to spend more than $30 billion on capital expenditures, or capex, in each of the next two quarters.  The problem: The business case for AI remains untested, and it's unclear whether the revenue from AI products will justify the ever-growing spending. If it does, it could push the economy onto a higher growth curve and transform entire industries. If it doesn't, the fallout could reshape the economy — from stock market crashes to communities left with vast, vacant data centers.  Earlier this year, Business Insider published an investigation into the data center industry, creating the most comprehensive map to date of where data centers are in the US. The investigation found 1,240 data centers in America already built or approved for construction at the end of 2024, an almost fourfold increase since 2010. The data didn't include any projects that received permits this year.  This year, four of the five biggest energy users from our tally, Amazon, Meta, Microsoft, and Google, could spend an estimated $320 billion on capex, primarily for AI infrastructure, according to an analysis of financial statements by Business Insider. That's more than the GDP of Finland and just shy of the total revenue ExxonMobil earned in 2024.  The scale of the investment is sparking concerns about a bubble and the potential for a pop that could bring the stock market crashing down from record heights.  So far, the concerns haven't spooked investors. The tech-heavy Nasdaq is up 19% this year, with Nvidia, the world's largest company by market capitalization, Google, and Microsoft all up more than 25%. Oracle has seen its stock rise 75% this year.  The money spent this year on AI infrastructure and software has contributed more to GDP growth than consumer spending, according to Renaissance Macro Research's reading of Bureau of Economic Analysis data.  It's a construction boom unlike any in living memory, transforming landscapes, drawing on scarce water resources, and taxing America's already strained electricity grid. The sheer ambition has drawn comparisons to the Apollo space program, the interstate highway system of the mid-1900s, and the fiber-optic bust around the turn of this century that left miles of "dark fiber."  Sarah Friar, OpenAI's finance chief, recently underscored the size of the industry's goals, when she spoke on the sidelines of a Goldman Sachs conference in September. AI spending, she said, wasn't like the 19th-century railroad system — it was like the early days of it.  "A lot of people have compared the AI era to things like the railway build-out, because it is a very capital-intensive build-out," Friar told Yahoo Finance. "I think we are just beginning. We've maybe laid some track from New York to Baltimore, but we're ultimately going to blanket the US, and ultimately blanket the world."  If the bet pays off, the returns could make the money sunk into data centers seem small. The data-center boom would become the foundation of the next tech cycle, letting Amazon, Microsoft, Google, and others rent out intelligence the way they rent cloud storage now. AI agents and custom models could form the basis of steady, high-margin subscription products.  Related stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know  If it doesn't pay off? Look no further than the railroads. Overinvestment in rail lines, including the Transcontinental Railroad, sparked not one but two banking crises in the latter half of the 1800s. The industry struggled with overspending, eventually leaving investors and the banks that had backed them with heavy losses.  Despite the investment, the business case for AI is still untested.  The AI infrastructure boom is built on a fundamental assumption about how machines learn best. The approach involves feeding massive amounts of data into large language models, which then look for patterns, or signals, buried in the noise. To improve, the theory goes, the models must ingest and analyze increasing amounts of data, which requires more and more computing power.  That need for scale has shaped the competitive landscape. If better models depend on more computing power, the obvious next step is to secure as much of it as possible. And that means more data centers — large warehouses filled with graphics processing units, or GPUs, that handle the complex computations required.  In a recent blog post, OpenAI CEO Sam Altman imagined what might be possible if AI systems had virtually unlimited computing power. AI could cure cancer or give every student on Earth a personalized tutor. "If we are limited by compute," he wrote, "we'll have to choose which one to prioritize; no one wants to make that choice, so let's go build."  Gary Marcus, a New York University professor emeritus of psychology and neural science and a vocal critic of Silicon Valley's approach to developing AI, has argued against the strategy that building bigger is better. Marcus has repeatedly argued that the fundamental theory driving Big Tech companies to build computing capacity, the scaling laws, is wrong.  "The meaning of the word scaling has been greatly devalued," Marcus wrote. "'Scaling' used to mean 'I can predict pretty much exactly how well a given LLM will do, by knowing the size of its database and the amount of compute being used to train it, and those increases will be exponential." Not anymore, he wrote.  OpenAI's August launch of GPT-5, its latest model, underscored Marcus' skepticism, as many perceived it as an incremental step and a challenge to the idea that adding more computing power makes better models. The leading language models still make simple mistakes, or hallucinations, that hurt their reliability. The problem persists even as companies have poured exponentially more computing power into training them, according to Bain & Company.  Big-spending corporations have yet to show meaningful results aided by AI, several studies have concluded. Researchers at the Massachusetts Institute of Technology published a report this summer suggesting 95% of early corporate AI initiatives had yet to deliver a return. Tech stocks briefly slumped on the report, among other reasons.  Researchers at BetterUp Labs and the Stanford Social Media Lab coined the term "workslop" to describe the substandard AI-assisted product that more and more employees are producing. Because the models still lack accuracy and nuance, the task of fact-checking and cleaning the output falls to colleagues. Writing in the Harvard Business Review, the researchers said 40% of the 1,150 workers they surveyed reported having received "workslop" from colleagues over the past month.  With its utility still in question, it's not clear when or if the revenue to come from AI products will justify its spending. Bain estimates that by 2030, annual capex spending will be $500 billion to meet the industry's computing needs. To justify that, companies would need to generate $2 trillion in annual revenue, Bain said. That's about $800 billion more than companies can save by using AI to make sales, marketing, customer support, and R&D more efficient. In other words, the consulting firm concluded, the industry will come up short unless it can find new products or services to sell.  In September, Friar, OpenAI's CFO, said the company will triple revenue this year to about $13 billion. That same month, the company agreed to pay Oracle an average of $60 billion a year for data center capacity — nearly five times more than it expects to bring in.  Related stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know  McKinsey & Company acknowledged, in an April report about capex spending, the difficult position the industry is in: Spend too little and risk missing out on a technology that may be one of the most transformative in history. Spend too much and risk wasting tens or hundreds of billions of dollars.  "The stakes are high," McKinsey wrote in the report. "Overinvesting in data center infrastructure risks stranding assets, while underinvesting means falling behind."  Meta CEO Mark Zuckerberg put it more bluntly when he admitted how much money he was prepared to waste to win the AI arms race. "If we end up misspending a couple of hundred billion dollars, I think that that is going to be very unfortunate," Zuckerberg told a podcast interviewer. At the same time, he underscored the risk of losing out if productive AI usage gains traction.  "I actually think the risk is higher on the other side," he said.  A quarter of a century ago, a similar pattern emerged when firms rushed to lay the backbone of the emerging internet. Companies like WorldCom and Global Crossing spent tens of billions of dollars in the five years through 2001 laying fiber optic cables and installing other networking capabilities, only to crash the following year when the dot-com bust led lenders who had financed the construction to demand their money.  Shareholders in the companies leading the fiber-optic build-out lost $2 trillion in value, while 500,000 workers lost their jobs, according to analysis conducted by the Brookings Institution. While the fiber optic cable was eventually put to use, largely by the streaming video revolution pioneered by Netflix, many of the companies that laid it weren't around to see it.  Like fiber optic cables and the railroads of an earlier era, data center construction and the purchase of GPUs are being financed by Wall Street.  Some of the money is coming through familiar channels. Oracle recently sold $18 billion worth of bonds to finance its data center expansion plans, while data center upstart CoreWeave, which went public in March, has tapped the public debt and equity markets to the tune of $25 billion since last year to fund its own expansion.  Increasingly, companies are also turning to less traditional lenders. Meta recently raised $29 billion for its latest data center project from firms including the Pacific Investment Management Company and Blue Owl Capital. The deal allowed Meta to raise billions without having to report the full amount on its balance sheet.  When Meta CFO Susan Li was asked about the company's plans for non-traditional financing methods at a recent conference, she said the company had built its own data centers for most of its history. Now, she said, as "the ambition of our infrastructure capacity unfolds ahead of us, it kind of dwarfs what we've built before, and we need to be sort of more expansive in the way that we are thinking about this."  Other data center developers are using the securitized bond markets to keep the boom going. Once a project is built and leased, they're turning the leasing revenue into bonds and selling to investors eager to be part of the AI boom. That frees up more money to put into future projects and fuels the spending, even if demand for mature data center projects starts to wane, said Paul Kedrosky, a financial blogger and advisor to hedge funds who recently wrote about the development.  "Developers build data centers, lease access to hyperscalers, and then package the rental income into bonds. Proceeds are recycled into the next round of construction," Kedrosky wrote on his website. "In short: the structured-credit world, not the real estate equity one, now finances the data-center boom."  Increasingly, Silicon Valley itself is helping to finance the boom. In September, Nvidia agreed to invest $100 billion into OpenAI to help with its data center build-out, with the expectation that OpenAI would turn around and use the money to purchase Nvidia's GPUs for its data centers. Microsoft invested in OpenAI early, and OpenAI used the money to rent out Microsoft's computing capacity. On Monday, chipmaker AMD announced that OpenAI has agreed to buy GPUs to power as many as 6 gigawatts of computing capacity in return for a warrant that would give OpenAI a 10% stake in the chipmaker if it hits certain milestones.  "This partnership is a major step in building the compute capacity needed to realize AI's full potential," Altman said in the statement announcing the deal.  The circular flow of money is yet another element of the AI infrastructure bet that underscores its scale, as well as its risks. If the hype around AI proves fleeting — if more computing power doesn't equate to better models, or the industry can't find more ways to make more money — the interlocking investments could magnify the fallout.  Even proponents of AI say the math is daunting.  "We are bullish on this in a big way," said David Crawford, the chairman of Bain's technology practice. "The point we were trying to make is that it's expensive."
NVIDIA Corporation (NASDAQ:NVDA) is one of the AI Stocks Investors Are Watching Closely. On October 3, Bank of America reiterated the stock as “Buy” stating that the stock remains a top idea.  “We continue to prefer NVDA as our top AI pick, levered to the most critical compute (accelerator) and networking (scale-up links/switches, scale-out switches, NICs, DPUs), components of the $1.2tn potential data center capex.”  NVIDIA Corporation (NASDAQ:NVDA) specializes in AI-driven solutions, offering platforms for data centers, self-driving cars, robotics, and cloud services.  While we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.  READ NEXT: 10 Buzzing AI Stocks on Wall Street and 10 AI Stocks Shaping Wall Street’s Next Big Rally  Disclosure: None.

### AMD ###
US stocks slipped from their latest record-setting run on Tuesday, as Wall Street weighed worries over the government shutdown against hopes for artificial intelligence.  The Dow Jones Industrial Average (^DJI) fell 0.2%. The S&P 500 (^GSPC) dropped around 0.4%, while the tech-heavy Nasdaq Composite (^IXIC) decreased roughly 0.7% after fresh record high closes on Wall Street.  Gold (GC=F) futures topped $4,000 per ounce for the first time ever, as investors continue to flock to the safe-haven asset.  The pullback in stocks comes after the S&P and Nasdaq both scored their seventh win in a row on Monday, boosted by news of a multibillion-dollar deal between AMD (AMD) and OpenAI (OPAI.PVT) that sent the chip company's stock rocketing higher.  But the AI trade lost some steam Tuesday, led by a decline in Oracle (ORCL) stock after a report said the profit margin in its cloud computing business was likely lower than many Wall Street forecasts. Shares of Oracle fell as much as 7% throughout the day but closed 2% lower.  Tesla (TSLA) shares also lost steam, dropping 4%, after the EV maker unveiled a cheaper Model Y priced under $40,000 on Tuesday in a launch initially teased in a series of cryptic social media posts.  Earnings results will take on even greater prominence than usual for markets during the US government shutdown. The longer the federal stoppage drags on, the more clouded the picture of the economy will become for investors as key data releases dry up, making it hard to divine the path of interest rates.  It has already delayed the September jobs report that was due Friday. Next week's releases on consumer and producer inflation, crucial to the Federal Reserve's decision making, could also be postponed.  Meanwhile, the Washington gridlock on a funding bill continues. President Trump signaled he would negotiate with Democrats over the healthcare subsidies they want to extend but only after the government is reopened. He also amped up threats toward federal workers.  LIVE COVERAGE IS OVER  23 updates
This repo aims to prove that something is wrong with APFS on macOS, but is also a good stress test in general when changing machine tooling that wants to oberve fs events (such as security tooling / EDR / virus scanners / etc).  The Test  Steps:  Setup Gather Results Report / PR with your Results ❤️  Setup  have node @ >= 22.11 have pnpm @ >= 10.2  (if you have proto (with auto-install) or volta installed, these versions will be selected for you)  git clone https://github.com/NullVoxPopuli/disk-perf-git-and-pnpm.git cd disk-perf-git-and-pnpm pnpm install # Fill the cache so we don't hit the network during testing  Gather Results  Since you've installed all the dependencies already, we can start with the clean test:  time ( git clean -Xfd ; git clean -fd )  Windows Powershell:  ( Measure-Command { git clean - Xfd; git clean - fd }).ToString()  And then once that finishes, we can run the install test:  time ( pnpm install )  Windows Powershell:  ( Measure-Command { pnpm install }).ToString()  If using zsh your time will be total . 0.01s user 0.00s system 94% cpu 0.007 total # . ^ this number and round to the tenths decimal place  if using bash your time will be real . real 2.02s # this number user 0.00s sys 0.01s and round to the tenths decimal place  How to find your disk info MacOS Apple Menu "About this Mac" (a window appears) "More Info..." (a window appears) scroll down and click "System Report..." (a window appears) in the left nav of this third window, click "NVMExpress"  PR your Results back to this Repo  and interact with the results here  Date CPU RAM (GB) Clean (s) Install (s) OS FileSystem Disk Notable Software Changes 2025-02-07 AMD Ryzen 5 7640U 12 Core 92 6.8 5.9 Ubuntu 24.04.1 Ext4 WD Black SN850 500GB 2025-02-24 AMD Ryzen 5 7640U throttle to ~550Mhz 92 56 44 Ubuntu 24.10 Ext4 WD Black SN850 500GB 2025-02-07 AMD Ryzen 9 7900X 12/24 Core 64 6.0 4.3 Ubuntu 24.04.1 Ext4 Samsung SSD 980 Pro 2TB 2025-02-07 AMD Ryzen 9 7900X 12/24 Core 64 3.3 4.0 Ubuntu 24.04.1 tmpfs (ramdisk) G.Skill F5-6000J3040G32G 2025-02-09 Apple M1 Pro 16 42.2 44.0 macOS 15.3 APFS (Encrypted) APPLE SSD AP0512R 500GB 2025-02-08 Apple M1 Max 64 31.5 44.2 macOS 14.7.3 APFS (Encrypted) APPLE SSD AP1024R 1TB 2025-02-08 Apple M4 16 29.6 31.4 macOS 15.2 APFS (Encrypted) APPLE SSD AP1024Z 1TB 2025-02-09 AMD Ryzen 7 7800X3D 8 Core 32 17.1 16.1 Ubuntu 22.04.3 Ext4 Corsair MP600 PRO LPX 2025-02-09 AMD Ryzen 7 7800X3D 8 Core 32 65.5 42.3 Windows 10 Pro 22H2 NTFS Corsair MP600 PRO LPX 2025-02-09 AMD Ryzen 5 7800X3D 8 Core 64 69.5 73.3 Windows 11 Pro 23H2 NTFS WD Black SN850x 2TB 2025-02-09 AMD Ryzen 5 7800X3D 8 Core 64 23.7 19.0 W11 Pro 23H2 / WSL2 / Ubuntu 24.04 Ext4 WD Black SN850x 2TB 2025-02-10 Intel i5-1145G7 8 Core 32 1.9 15.3 Debian Trixie Ext4 BC711 NVMe SK hynix 512GB 2025-02-12 Apple M1 Max 32 71.4 87.7 macOS 14.6.1 APFS (Encrypted) APPLE SSD AP2048R 2TB 2025-02-12 Apple M4 Pro (14 Cores) 48 30.1 65.1 macOS 15.3 APFS (Encrypted) APPLE SSD AP2048Z 2TB 2025-02-13 Apple M1 Ultra 64 45.2 137.5 macOS 15.3 APFS APPLE SSD AP1024R 1TB 2025-02-14 Apple M2 Max (6 vCPU) 16 3.2 12 Ubuntu 24.04 Ext4 APPLE SSD AP1024Z Parallels VM 2025-02-14 Apple M2 Max (6 vCPU) 16 2.8 11.9 Ubuntu 24.04 Ext4 LVM2 Encrypted APPLE SSD AP1024Z Parallels VM 2025-02-14 Apple M2 Max (6 vCPU) 16 1.6 10.7 Ubuntu 24.04 tmpfs (ramdisk) Hynix LPDDR5 / Virtual RAM Parallels VM 2025-02-15 Apple M1 Pro 32 44.5 50.2 macOS 15.3 APFS (Encrypted) APPLE SSD AP0512R 500GB 2025-02-19 Apple M1 16 37.8 33.3 macOS 15.3.1 APFS (Encypted) APPLE SSD AP0512Q 500GB 2025-02-19 Apple M1 Pro 16 59.4 69.1 macOS 14.7.3 APFS (Encrypted) APPLE SSD AP1024R 1TB 2025-02-21 Apple M3 16 36.23 30.3 macOS 15.3 APFS APPLE SSD AP0256Z 256GB 2025-02-20 Apple M4 Max (16 Cores) 128 36.7 64.5 macOS 15.2 APFS (Encrypted) APPLE SSD AP2048Z 2TB 2025-02-20 Apple M3 24 46.6 44.6 macOS ?? APFS APPLE SSD AP1024Z 1TB 2025-02-21 Intel Core i7 14700K (20 Cores) 64 3.1 13.8 W10 22H2 / WSL2 / Ubuntu 24.04 Ext4 WD Black 2TB SN850 2025-02-22 Apple M3 Pro 18 37.7 40 macOS 15.3 APFS APPLE SSD AP1024Z 1TB 2025-02-24 Apple M2 Pro 32 34.6 32.0 macOS 13.6 APFS APPLE SSD AP0512Z 2025-02-25 Apple M3 16 34.213 27.851 macOS 15.3.1 APFS APPLE SSD AP1024Z 2025-02-25 Apple M3 Pro (12 Core, 6p6e) 36 47.8 52.6 macOS 14.7.4 APFS APPLE SSD AP0512Z 500GB 2025-02-25 Apple M3 Pro (12 Core, 6p6e) 36 32 53.3 macOS 14.7.4 APFS APPLE SSD AP0512Z 500GB Spotlight disabled 2025-02-25 Apple M3 Pro (12 Core, 6p6e) 36 26.3 19.9 macOS 14.7.4 APFS APPLE SSD AP0512Z 500GB Spotlight disabled, csrutil disable 2025-02-26 Apple M2 Max (12 Core, 8p4e) 32 41.4 39.8 macOS 15.3.1 APFS (Encrypted) APPLE SSD AP1024Z 1TB Spotlight disabled, Kandji, SentinelOne 2025-02-26 Apple M4 Pro (14 Cores) (6 core vCPU) 6 2.5 16.9 Ubuntu 24.10 Ext4 Unencrypted APPLE SSD AP2048Z 2TB UTM VM 2025-02-28 Apple M2 Max (6 vCPU) 16 11.9 15.7 Ubuntu 24.04.2 Ext4 LVM2 Encrypted APPLE SSD AP1024Z Parallels VM, SentinelOne 2025-02-28 Apple M2 Max (6 vCPU) 16 9.1 13.3 Ubuntu 24.04.2 tmpfs (ramdisk) Hynix LPDDR5 / Virtual RAM Parallels VM, SentinelOne 2025-04-26 Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz 32 103.98 116.62 macOS 15.4.1 APFS (Encrypted) Apple SSD AP1024N 2025-04-27 Apple M4 Pro (14 Core, 10p4e) 48 64.48 145.40 macOS 15.3.2 APFS (Encrypted) Apple SSD AP1024Z 2025-04-27 Apple M4 Pro (14 Core, 10p4e) 48 3.209 17.302 Ubuntu 24.04.2 btrfs Apple SSD AP1024Z Ubuntu machine running in OrbStack 2025-10-06 Apple M2 Max (12 Core, 8p4e) 32 46.730 54.603 macOS 15.5 APFS (Encrypted) Apple SSD AP1024Z 1TB Kandji, Code42, SentinelOne, tested in excluded directory 2025-15-07 Apple M3 Air (8 Core, 4p4e) 16 34.104 29.293 macOS 15.7 APFS (Encrypted) Apple SSD AP0512Z 500GB Kandji, SentinelOne, tested in excluded directory  What to do for now?  If you're using macOS, and your file system performance is unbearable, there are some options:
As the eye-watering AI investment deals keep coming, skeptics are starting to ask: Where is the money?  Monday’s deal between AMD and OpenAI shows both the markets’ AI enthusiasm and the financial experiments being launched to pay for it all. Some are warning that AI spending is unsustainable and circular, as companies prop up money-losing customers. “OpenAI is in no position to make any of these commitments,” one analyst told the Financial Times.  OpenAI has $12 billion in annualized revenue and $8 billion in annualized losses, The Information reported in July. Making good on the $1 trillion it has committed to AI compute will require some combination of near-constant private fundraising, an embrace of debt, and nifty financial footwork that uses public stockholders’ AI mania to cover the tab. (“Chips are being paid by the [AMD] shareholders lmfao,” one engineer and tech investor wrote.)  “We look at everything — equity, debt… [we are] trying to find creative ways of financing all of this,” OpenAI president Greg Brockman told Bloomberg Monday
The technical storage or access that is used exclusively for statistical purposes.  The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.
We recently published 10 Stocks Investors Are Gobbling Up. IREN Ltd. (NASDAQ:IREN) is one of the top performers on Monday.  IREN Ltd. soared to a new all-time high on Monday, as investor funds poured into artificial intelligence stocks following aggressive dealmaking activities in the industry.  In intra-day trading, IREN Ltd. (NASDAQ:IREN) hit a new record high of $58.28 before trimming gains to finish the day just up by 14.45 percent at $57.75 apiece, supported by OpenAI’s newly clinched supply deal with Advanced Micro Devices Inc. (AMD).  IREN (IREN) Touches Fresh Peak on AI Deals  spacedrone808/Shutterstock.com  In a statement, AMD said it entered into a definitive agreement with OpenAI to supply the latter with 6 gigawatts of Instinct GPUs to enable an ambitious AI buildout and advance the entire ecosystem. The first GW is expected to be deployed in the second half of 2026.  As a pioneer in the AI industry, OpenAI’s ongoing expansion program bolstered optimism for companies riding the wave, including IREN Ltd. (NASDAQ:IREN), a Bitcoin miner slowly transitioning to AI servicing through expanding its cloud business to support demand growth in high-performance computing (HPC) services.  Amid the developments, IREN Ltd. (NASDAQ:IREN) earned an “overweight” rating and a $75 price target from investment firm Bernstein—a 275 percent increase from its previous target of $20.  The upgrade was based on IREN Ltd.’s (NASDAQ:IREN) differentiated approach among Bitcoin miners, underscoring the development of its own AI infrastructure, while competitors pursue capital-light co-location deals with AI cloud companies.  While we acknowledge the potential of IREN as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.  READ NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.
This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.  When Sriram Krishnan, a senior White House policy advisor on artificial intelligence, appeared onstage at an event in Washington last month, he listed the Trump administration's priorities for advancing the AI revolution.  At the top of the list? More construction.  "Let's make sure we build our infrastructure," Krishnan said. "'Build, baby, build' is what we tell people."  That rallying cry is echoing across Silicon Valley. Executives at Meta say they expect to spend $600 billion on AI infrastructure, including massive data centers, through 2028. OpenAI and Oracle have announced plans to put $500 billion into a data center project dubbed Stargate, while Amazon plans to spend more than $30 billion on capital expenditures, or capex, in each of the next two quarters.  The problem: The business case for AI remains untested, and it's unclear whether the revenue from AI products will justify the ever-growing spending. If it does, it could push the economy onto a higher growth curve and transform entire industries. If it doesn't, the fallout could reshape the economy — from stock market crashes to communities left with vast, vacant data centers.  Earlier this year, Business Insider published an investigation into the data center industry, creating the most comprehensive map to date of where data centers are in the US. The investigation found 1,240 data centers in America already built or approved for construction at the end of 2024, an almost fourfold increase since 2010. The data didn't include any projects that received permits this year.  This year, four of the five biggest energy users from our tally, Amazon, Meta, Microsoft, and Google, could spend an estimated $320 billion on capex, primarily for AI infrastructure, according to an analysis of financial statements by Business Insider. That's more than the GDP of Finland and just shy of the total revenue ExxonMobil earned in 2024.  The scale of the investment is sparking concerns about a bubble and the potential for a pop that could bring the stock market crashing down from record heights.  So far, the concerns haven't spooked investors. The tech-heavy Nasdaq is up 19% this year, with Nvidia, the world's largest company by market capitalization, Google, and Microsoft all up more than 25%. Oracle has seen its stock rise 75% this year.  The money spent this year on AI infrastructure and software has contributed more to GDP growth than consumer spending, according to Renaissance Macro Research's reading of Bureau of Economic Analysis data.  It's a construction boom unlike any in living memory, transforming landscapes, drawing on scarce water resources, and taxing America's already strained electricity grid. The sheer ambition has drawn comparisons to the Apollo space program, the interstate highway system of the mid-1900s, and the fiber-optic bust around the turn of this century that left miles of "dark fiber."  Sarah Friar, OpenAI's finance chief, recently underscored the size of the industry's goals, when she spoke on the sidelines of a Goldman Sachs conference in September. AI spending, she said, wasn't like the 19th-century railroad system — it was like the early days of it.  "A lot of people have compared the AI era to things like the railway build-out, because it is a very capital-intensive build-out," Friar told Yahoo Finance. "I think we are just beginning. We've maybe laid some track from New York to Baltimore, but we're ultimately going to blanket the US, and ultimately blanket the world."  If the bet pays off, the returns could make the money sunk into data centers seem small. The data-center boom would become the foundation of the next tech cycle, letting Amazon, Microsoft, Google, and others rent out intelligence the way they rent cloud storage now. AI agents and custom models could form the basis of steady, high-margin subscription products.  Related stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know  If it doesn't pay off? Look no further than the railroads. Overinvestment in rail lines, including the Transcontinental Railroad, sparked not one but two banking crises in the latter half of the 1800s. The industry struggled with overspending, eventually leaving investors and the banks that had backed them with heavy losses.  Despite the investment, the business case for AI is still untested.  The AI infrastructure boom is built on a fundamental assumption about how machines learn best. The approach involves feeding massive amounts of data into large language models, which then look for patterns, or signals, buried in the noise. To improve, the theory goes, the models must ingest and analyze increasing amounts of data, which requires more and more computing power.  That need for scale has shaped the competitive landscape. If better models depend on more computing power, the obvious next step is to secure as much of it as possible. And that means more data centers — large warehouses filled with graphics processing units, or GPUs, that handle the complex computations required.  In a recent blog post, OpenAI CEO Sam Altman imagined what might be possible if AI systems had virtually unlimited computing power. AI could cure cancer or give every student on Earth a personalized tutor. "If we are limited by compute," he wrote, "we'll have to choose which one to prioritize; no one wants to make that choice, so let's go build."  Gary Marcus, a New York University professor emeritus of psychology and neural science and a vocal critic of Silicon Valley's approach to developing AI, has argued against the strategy that building bigger is better. Marcus has repeatedly argued that the fundamental theory driving Big Tech companies to build computing capacity, the scaling laws, is wrong.  "The meaning of the word scaling has been greatly devalued," Marcus wrote. "'Scaling' used to mean 'I can predict pretty much exactly how well a given LLM will do, by knowing the size of its database and the amount of compute being used to train it, and those increases will be exponential." Not anymore, he wrote.  OpenAI's August launch of GPT-5, its latest model, underscored Marcus' skepticism, as many perceived it as an incremental step and a challenge to the idea that adding more computing power makes better models. The leading language models still make simple mistakes, or hallucinations, that hurt their reliability. The problem persists even as companies have poured exponentially more computing power into training them, according to Bain & Company.  Big-spending corporations have yet to show meaningful results aided by AI, several studies have concluded. Researchers at the Massachusetts Institute of Technology published a report this summer suggesting 95% of early corporate AI initiatives had yet to deliver a return. Tech stocks briefly slumped on the report, among other reasons.  Researchers at BetterUp Labs and the Stanford Social Media Lab coined the term "workslop" to describe the substandard AI-assisted product that more and more employees are producing. Because the models still lack accuracy and nuance, the task of fact-checking and cleaning the output falls to colleagues. Writing in the Harvard Business Review, the researchers said 40% of the 1,150 workers they surveyed reported having received "workslop" from colleagues over the past month.  With its utility still in question, it's not clear when or if the revenue to come from AI products will justify its spending. Bain estimates that by 2030, annual capex spending will be $500 billion to meet the industry's computing needs. To justify that, companies would need to generate $2 trillion in annual revenue, Bain said. That's about $800 billion more than companies can save by using AI to make sales, marketing, customer support, and R&D more efficient. In other words, the consulting firm concluded, the industry will come up short unless it can find new products or services to sell.  In September, Friar, OpenAI's CFO, said the company will triple revenue this year to about $13 billion. That same month, the company agreed to pay Oracle an average of $60 billion a year for data center capacity — nearly five times more than it expects to bring in.  Related stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know  McKinsey & Company acknowledged, in an April report about capex spending, the difficult position the industry is in: Spend too little and risk missing out on a technology that may be one of the most transformative in history. Spend too much and risk wasting tens or hundreds of billions of dollars.  "The stakes are high," McKinsey wrote in the report. "Overinvesting in data center infrastructure risks stranding assets, while underinvesting means falling behind."  Meta CEO Mark Zuckerberg put it more bluntly when he admitted how much money he was prepared to waste to win the AI arms race. "If we end up misspending a couple of hundred billion dollars, I think that that is going to be very unfortunate," Zuckerberg told a podcast interviewer. At the same time, he underscored the risk of losing out if productive AI usage gains traction.  "I actually think the risk is higher on the other side," he said.  A quarter of a century ago, a similar pattern emerged when firms rushed to lay the backbone of the emerging internet. Companies like WorldCom and Global Crossing spent tens of billions of dollars in the five years through 2001 laying fiber optic cables and installing other networking capabilities, only to crash the following year when the dot-com bust led lenders who had financed the construction to demand their money.  Shareholders in the companies leading the fiber-optic build-out lost $2 trillion in value, while 500,000 workers lost their jobs, according to analysis conducted by the Brookings Institution. While the fiber optic cable was eventually put to use, largely by the streaming video revolution pioneered by Netflix, many of the companies that laid it weren't around to see it.  Like fiber optic cables and the railroads of an earlier era, data center construction and the purchase of GPUs are being financed by Wall Street.  Some of the money is coming through familiar channels. Oracle recently sold $18 billion worth of bonds to finance its data center expansion plans, while data center upstart CoreWeave, which went public in March, has tapped the public debt and equity markets to the tune of $25 billion since last year to fund its own expansion.  Increasingly, companies are also turning to less traditional lenders. Meta recently raised $29 billion for its latest data center project from firms including the Pacific Investment Management Company and Blue Owl Capital. The deal allowed Meta to raise billions without having to report the full amount on its balance sheet.  When Meta CFO Susan Li was asked about the company's plans for non-traditional financing methods at a recent conference, she said the company had built its own data centers for most of its history. Now, she said, as "the ambition of our infrastructure capacity unfolds ahead of us, it kind of dwarfs what we've built before, and we need to be sort of more expansive in the way that we are thinking about this."  Other data center developers are using the securitized bond markets to keep the boom going. Once a project is built and leased, they're turning the leasing revenue into bonds and selling to investors eager to be part of the AI boom. That frees up more money to put into future projects and fuels the spending, even if demand for mature data center projects starts to wane, said Paul Kedrosky, a financial blogger and advisor to hedge funds who recently wrote about the development.  "Developers build data centers, lease access to hyperscalers, and then package the rental income into bonds. Proceeds are recycled into the next round of construction," Kedrosky wrote on his website. "In short: the structured-credit world, not the real estate equity one, now finances the data-center boom."  Increasingly, Silicon Valley itself is helping to finance the boom. In September, Nvidia agreed to invest $100 billion into OpenAI to help with its data center build-out, with the expectation that OpenAI would turn around and use the money to purchase Nvidia's GPUs for its data centers. Microsoft invested in OpenAI early, and OpenAI used the money to rent out Microsoft's computing capacity. On Monday, chipmaker AMD announced that OpenAI has agreed to buy GPUs to power as many as 6 gigawatts of computing capacity in return for a warrant that would give OpenAI a 10% stake in the chipmaker if it hits certain milestones.  "This partnership is a major step in building the compute capacity needed to realize AI's full potential," Altman said in the statement announcing the deal.  The circular flow of money is yet another element of the AI infrastructure bet that underscores its scale, as well as its risks. If the hype around AI proves fleeting — if more computing power doesn't equate to better models, or the industry can't find more ways to make more money — the interlocking investments could magnify the fallout.  Even proponents of AI say the math is daunting.  "We are bullish on this in a big way," said David Crawford, the chairman of Bain's technology practice. "The point we were trying to make is that it's expensive."
Up to 40% lower latency than previous AMD Solarflare Ethernet Adapters generations  Enhanced Performance: 200% improved system performance and higher ingestion of market data compared to the AMD Solarflare X2 Series  Backward compatibility for seamless integration with existing networking infrastructure  Up to 12% lower latency compared to competition when leveraging AMD Solarflare X4 Ethernet Adapters with AMD EPYC 4005 Series CPUs  Offers improved ultra-low latency  Helps handle a high volume of small data packets quickly and reliably, even during peak trading activity.  Reduces CPU workload by efficiently moving data, allowing more processing power for analyzing and executing complex trading strategies.  Enables consistent, predictable response times and optimum performance on standard servers, avoiding common network slowdowns.  For over 15 years, AMD Solarflare solutions have set the standard for ultra-low latency networking, empowering industries like capital markets to gain a true competitive edge. When complex trading algorithms shape global investments, every nanosecond matters—which is why speed and reliable execution are mission critical. Leading financial institutions trust AMD Solarflare for best-in-class performance, with 9 out of the top 10 global stock exchanges relying on these solutions to power their trading platforms and keep markets running smoothly.The AMD Solarflare X4 Ethernet Adapters represents a significant advancement in ultra-low latency Ethernet networking. As trading systems and high-performance applications continue to push the boundaries of speed and efficiency, the AMD Solarflare X4 Ethernet Adapters sets new benchmarks with industry-leading latency and throughput:With these capabilities, the AMD Solarflare X4 Ethernet Adapters are designed to address the critical needs of industries where every nanosecond counts—offering the reliability, openness and consistency required to maintain a competitive edge in high-frequency trading, financial services, and other latency-sensitive environments.With AMD Solarflare solutions, capital markets firms can leverage AMD enterprise-class software and support within a single, unified vendor relationship. This streamlines workload acceleration, troubleshooting, and compliance activities—simplifying operations and supporting the legal and regulatory reporting requirements critical to financial environments.AMD Solarflare Onload Software:This makes the solution ideal for trading environments where speed and reliability are essential.The AMD Solarflare X4 Ethernet Adapters deliver sub-microsecond latency with flexible form factors to meet diverse capital market needs. It combines industry-leading performance, forward-looking feature enhancements, and backward compatibility to drive faster, more reliable trading infrastructure.Experience the definitive networking solution trusted by the world's top financial institutions.Begin powering your trading solutions with AMD Solarflare X4 Ethernet Adapters and AMD EYPC processors today.
Listen to this post: Log in to listen  OpenAI’s flood of announcements are getting hard to keep up with. A selection — not exhaustive! — from just the last month:  The last two announcements just dropped yesterday, and actually bring clarity and coherence to the entire list. In short, OpenAI is making a play to be the Windows of AI.  For nearly two decades smartphones, and in particular iOS, have been the touchstones in terms of discussing platforms. It’s important to note, however, that while Apple’s strategy of integrating hardware and software was immensely profitable, it entailed leaving the door open for a competing platform to emerge. The challenge of being a hardware company is that by virtue of needing to actually create devices you can’t serve everyone; Apple in particular didn’t have the capacity or desire to go downmarket, which created the opportunity for Android to not only establish a competing platform but to actually significantly exceed iOS in market share.  That means that if we want a historical analogy for total platform dominance — which increasingly appears to be OpenAI’s goal — we have to go back further to the PC era and Windows.  Platform Establishment  Before there was Windows there was DOS; before DOS, however, there was a fast-talking deal-making entrepreneur named Bill Gates. From The Truth About Windows Versus the Mac:  In the late 1970s and very early 1980s, a new breed of personal computers were appearing on the scene, including the Commodore, MITS Altair, Apple II, and more. Some employees were bringing them into the workplace, which major corporations found unacceptable, so IT departments asked IBM for something similar. After all, “No one ever got fired for buying IBM.” IBM spun up a separate team in Florida to put together something they could sell IT departments. Pressed for time, the Florida team put together a minicomputer using mostly off-the shelf components; IBM’s RISC processors and the OS they had under development were technically superior, but Intel had a CISC processor for sale immediately, and a new company called Microsoft said their OS — DOS, which they acquired from another company — could be ready in six months. For the sake of expediency, IBM decided to go with Intel and Microsoft. The rest, as they say, is history. The demand from corporations for IBM PCs was overwhelming, and DOS — and applications written for it — became entrenched. By the time the Mac appeared in 1984, the die had long since been cast. Ultimately, it would take Microsoft a decade to approach the Mac’s ease-of-use, but Windows’ DOS underpinnings and associated application library meant the Microsoft position was secure regardless.  There is nothing like IBM and its dominant position in enterprise today; rather, the route to becoming a platform is to first be a massively popular product. Acquiring developers and users is not a chicken-and-egg problem: it is clear that you must get users first, which attracts developers, enhancing your platform in a virtuous cycle; to put it another way, first a product must Aggregate users and then it gets developers for free.  ChatGPT is exactly that sort of product, and at yesterday’s DevDay 2025 keynote CEO Sam Altman and team demonstrated exactly that sort of pull; from The Verge:  OpenAI is introducing a way to work with apps right inside ChatGPT. The idea is that, from within a conversation with the chatbot, you can essentially tag in apps to help you complete a task while ChatGPT offers context and advice. The company showed off a few different ways this can work. In a live demo, an OpenAI employee launched ChatGPT and then asked Canva to create a poster of a name for a dog-walking business; after a bit of waiting, Canva came back with a few different examples, and the presenter followed up by asking for a generated pitch deck based on the poster. The employee also asked Zillow via ChatGPT to show homes for sale in Pittsburgh, and it created an interactive Zillow map — which the employee then asked follow-up questions about. Apps available inside ChatGPT starting today will include Booking.com, Canva, Coursera, Expedia, Figma, Spotify, and Zillow. In the “weeks ahead,” OpenAI will add more apps, such as DoorDash, OpenTable, Target, and Uber. OpenAI recently started allowing ChatGPT users to make purchases on Etsy through the chatbot, part of its overall push to integrate it with the rest of the web.  It’s fair to wonder if these app experiences will measure up to these company’s self-built apps or websites, just as there are questions about just how well the company’s Instant Checkout will convert; what is notable, however, is that I disagree that this represents a “push to integrate…with the rest of the web”.  This is the opposite: this is a push to make ChatGPT the operating system of the future. Apps won’t be on your phone or in a browser; they’ll be in ChatGPT, and if they aren’t, they simply will not exist for ChatGPT users. That, by extension, means the burden of making these integrations work — and those conversions performant — will be on third party developers, not OpenAI. This is the power that comes from owning users, and OpenAI is flexing that power in a major way.  Second Sourcing  There is a second aspect to the IBM PC strategy, and that is the role of AMD. From a 2024 Update:  While IBM chose Intel to provide the PC’s processor, they were wary of being reliant on a single supplier (it’s notable that IBM didn’t demand the same of the operating system, which was probably a combination of not fully appreciating operating systems as a point of integration and lock-in for 3rd-party software, which barely existed at that point, and a recognition that software is just bits and not a physical good that has to be manufactured). To that end IBM demanded that Intel license its processor to another chip firm, and AMD was the obvious choice: the firm was founded by Jerry Sanders, a Fairchild Semiconductor alum who had worked with Intel’s founders, and specialized in manufacturing licensed chips.  The relationship between Intel and AMD ended up being incredibly fraught and largely documented by endless lawsuits (you can read a brief history in that Update); the key point to understand, however, is that (1) IBM wanted to have dual suppliers to avoid being captive to an essential component provider and (2) IBM had the power to make that happen because they had the customers who were going to provide Intel so much volume.  The true beneficiary of IBM’s foresight, of course, was Microsoft, which controlled the operating system; IBM’s mandate is why it is appropriate that “Windows” comes first in the “Wintel” characterization of the PC era. Intel reaped tremendous profits from its position in the PC value chain, but more value accrued to Microsoft than anyone else.  This question of who will capture the most profit from the AI value chain remains an open one. There’s no question that the early winner is Nvidia: the company has become the most valuable in the world by virtue of its combination of best-in-class GPUs, superior networking, and CUDA software layer that locks people into Nvidia’s own platform. And, as long as power is the limiting factor, Nvidia is well-placed to maintain its position.  What Nvidia is not shy about is capturing its share of value, and that is a powerful incentive for other companies in the value chain to look for alternatives. Google is the furthest along in this regard thanks to its decade-old investment in TPUs, while Amazon is seeking to mimic their strategy with Trainium; Microsoft and Meta are both working to design and build their own chips, and Apple is upscaling Apple Silicon for use in the data center.  Once again, however, the most obvious and most immediately available alternative to Nvidia is AMD, and I think the parallels between yesterday’s announcement of an OpenAI-AMD deal and IBM’s strong-arming of Intel are very clear; from the Wall Street Journal:  OpenAI and chip-designer Advanced Micro Devices announced a multibillion-dollar partnership to collaborate on AI data centers that will run on AMD processors, one of the most direct challenges yet to industry leader Nvidia. Under the terms of the deal, OpenAI committed to purchasing 6 gigawatts worth of AMD’s chips, starting with the MI450 chip next year. The ChatGPT maker will buy the chips either directly or through its cloud computing partners. AMD chief Lisa Su said in an interview Sunday that the deal would result in tens of billions of dollars in new revenue for the chip company over the next half-decade. The two companies didn’t disclose the plan’s expected overall cost, but AMD said it costs tens of billions of dollars per gigawatt of computing capacity. OpenAI will receive warrants for up to 160 million AMD shares, roughly 10% of the chip company, at 1 cent per share, awarded in phases, if OpenAI hits certain milestones for deployment. AMD’s stock price also has to increase for the warrants to be exercised.  If OpenAI is the software layer that matters to the ecosystem, then Nvidia’s long-term pricing power will be diminished; the company, like Intel, may still take the lion’s share of chip profits through sheer performance and low-level lock-in, but I believe the most important reason OpenAI is making this deal is to lock in its own dominant position in the stack. It is pretty notable that this announcement comes only weeks after Nvidia’s investment in OpenAI; that, though, is another affirmation that the company who has the users has the ultimate power.  There is one other part of the stack to keep an eye on: TSMC. Both Nvidia and AMD make their chips with the Taiwanese giant, and while TSMC is famously reticent to take price, they are positioned to do so in the long run. Altman surely knows this as well, which means that I wouldn’t be surprised if there is an Intel announcement sooner rather than later; maybe there is fire to that recent smoke about AMD talking with Intel?  The AI Linchpin  When I started writing Stratechery, Windows was a platform in decline, superceded by mobile and, surprisingly enough, increasingly challenged by its all-but-vanquished ancient foe, the Mac. To that end, one of my first pieces about Microsoft was about then-CEO Steve Ballmer’s misguided attempt to focus on devices instead of services. I wrote a few years later in Microsoft’s Monopoly Hangover:  The truth is that both [IBM and Microsoft] were victims of their own monopolistic success: Windows, like the System/360 before it, was a platform that enabled Microsoft to make money in all directions. Both companies made money on the device itself and by selling many of the most important apps (and in the case of Microsoft, back-room services) that ran on it. There was no need to distinguish between a vertical strategy, in which apps and services served to differentiate the device, or a horizontal one, in which the device served to provide access to apps and services. When you are a monopoly, the answer to strategic choices can always be “Yes.”  Microsoft at that point in time no longer had that luxury: the company needed to make a choice — the days of doing everything were over — and that choice should be services (which is exactly what Satya Nadella did).  Ever since the emergence of ChatGPT made OpenAI The Accidental Consumer Tech Company I have been making similar arguments about OpenAI: they need to focus on the consumer opportunity and leave the enterprise API market to Microsoft. Not only would focus help the company capture the consumer opportunity, there was the opportunity cost of GPUs used for the API that couldn’t be used to deliver consumers a better experience across every tier.  I now have much more appreciation for OpenAI’s insistence on doing it all, for two reasons. First, this is a company in pure growth mode, not in decline. Tradeoffs are in the long run inevitable, but why make them before you need to? It would have been a mistake for Microsoft to restrict Windows to only the enterprise in the 1980s, even if the company had to low-key retreat from the consumer market over the last fifteen years; there was a lot of money to make before that retreat needed to happen! OpenAI, meanwhile, is the hottest brand in AI, so why not make a play to own it all, from consumer touchpoint to API to everything in-between?  Second, we’ve obviously crossed the line into bubble territory, which always was inevitable. The question now is whether or not this is a productive bubble: what durable infrastructure will be built by eventually bankrupt companies that we benefit from for years to come?  GPUs are not that durable infrastructure; data centers are more long-lasting, but not worth the financial pain of a bubble burst. The real payoff would be a massive build-out in power generation, which would be a benefit for the next half a century. Another potential payoff would be the renewed viability of Intel, and as I noted above, OpenAI may be uniquely positioned and motivated to make that happen.  More broadly, this play to be the Windows of AI effectively positions OpenAI as the linchpin of the entire AI buildout. Just look at what the mere announcement of partnerships with OpenAI has done for the stocks of Oracle and AMD. OpenAI is creating the conditions such that it is the primary manifestation of the AI bubble, which ensures the company is the primary beneficiary of all of the speculative capital flooding into the space. Were the company more focused, as I have previously advised, they may not have the leverage to get enough funding to meet those more modest (but still incredible) goals; now it’s hard to see them not getting whatever money they want, at least until the bubble bursts.  What’s amazing about this overview is that I only scratched the surface of what OpenAI announced both yesterday and over the last month — and I haven’t even mentioned Sora (although I covered that topic yesterday). What the company is seeking to achieve is incredibly audacious, but also logical, and something we’ve seen before:  And, interestingly enough, there is an Apple to OpenAI’s Microsoft: it’s Google, with their fully integrated stack, from chips to data centers to models to end user distribution channels. Instead of taking on a menagerie of competitors, however, Google is facing an increasingly unified ecosystem, organized, whether they wish to be or not, around OpenAI. Such is the power of aggregating demand and the phenomenon that is ChatGPT.
US stocks slipped from their latest record-setting run on Tuesday, as Wall Street weighed worries over the government shutdown against hopes for artificial intelligence.  The Dow Jones Industrial Average (^DJI) fell 0.2%. The S&P 500 (^GSPC) dropped around 0.4%, while the tech-heavy Nasdaq Composite (^IXIC) decreased roughly 0.7% after fresh record high closes on Wall Street.  Gold (GC=F) futures topped $4,000 per ounce for the first time ever, as investors continue to flock to the safe-haven asset.  The pullback in stocks comes after the S&P and Nasdaq both scored their seventh win in a row on Monday, boosted by news of a multibillion-dollar deal between AMD (AMD) and OpenAI (OPAI.PVT) that sent the chip company's stock rocketing higher.  But the AI trade lost some steam Tuesday, led by a decline in Oracle (ORCL) stock after a report said the profit margin in its cloud computing business was likely lower than many Wall Street forecasts. Shares of Oracle fell as much as 7% throughout the day but closed 2% lower.  Tesla (TSLA) shares also lost steam, dropping 4%, after the EV maker unveiled a cheaper Model Y priced under $40,000 on Tuesday in a launch initially teased in a series of cryptic social media posts.  Earnings results will take on even greater prominence than usual for markets during the US government shutdown. The longer the federal stoppage drags on, the more clouded the picture of the economy will become for investors as key data releases dry up, making it hard to divine the path of interest rates.  It has already delayed the September jobs report that was due Friday. Next week's releases on consumer and producer inflation, crucial to the Federal Reserve's decision making, could also be postponed.  Meanwhile, the Washington gridlock on a funding bill continues. President Trump signaled he would negotiate with Democrats over the healthcare subsidies they want to extend but only after the government is reopened. He also amped up threats toward federal workers.  LIVE COVERAGE IS OVER  23 updates
Save my User ID and Password  Some subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.  Note: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.
Analysts believe the OpenAI deal positions AMD as a strong AI competitor, validating product quality and brightening future prospects.  The deal is forecasted to accelerate AMD's growth and boost its valuation, with some analysts predicting a target toward $1 trillion and higher data…  This story appeared on seekingalpha.com , 2025-10-07 15:44:16.935000.
Summer-like temperatures stick around for one more day across the Northeast; another tropical disturbance brews in the Atlantic
Key Takeaways An EV leader saw its stock drop on Tuesday, Oct. 7, 2025, after announcing lower-cost models, while a chipmaker added to its gains in the wake of a massive AI deal.  Tesla shares slid after the company rolled out cheaper models that analysts said weren't as cheap as they had hoped.  Shares of Advanced Micro Devices added to yesterday's gains on a big partnership with OpenAI.  Shares of the world's most valuable electric vehicle maker slumped on Tuesday, Oct. 7, 2025, after revealing lower-cost models, while a chipmaker added to its gains in the wake of a massive AI deal.    The major U.S. equities indexes finished lower as tech stocks came under pressure. The S&P 500 dropped 0.4% and the Nasdaq declined 0.7% Tuesday, after retreating from intraday records. The Dow slipped 0.2%. To read more reporting from Investopedia on the day's market moves, click here.  Advanced Micro Devices (AMD) was a bright spot in a down day for the broader semiconductor industry, as shares climbed 3.8%, adding to yesterday's 24% jump on the chipmaker's partnership with ChatGPT owner OpenAI.  Other semiconductor and AI-related stocks, including chip manufacturing equipment makers Lam Research (LRCX) and Applied Materials (AMAT), dropped along with shares of Oracle (ORCL) following a report that its cloud-computing margins could be smaller than expected. Shares of hard disk drive maker Seagate Technology (STX), which have soared in recent months on anticipation of AI-driven demand for data storage, dropped 7.3% to lead losses on the S&P 500.  Tesla (TSLA) shares dropped nearly 5% after the company announced lower-priced versions of its Model 3 and Y vehicles, with the 3 starting at around $35,000 and the Y near $38,000. Some analysts suggested the cheaper models weren't as cheap as they had hoped.    Shares of Ford Motor (F), another automaker, tumbled about 6% following reports that a fire at an aluminum plant in Oswego, N.Y., would disrupt operations over the coming months.    Adtech darling AppLovin (APP) surged 7.6% to log the S&P 500's top daily performance, clawing back some of Monday's losses on reports of a probe by the Securities and Exchange Commission into AppLovin's data collection practices. While acknowledging the investigation could drive short-term volatility, analysts at Oppenheimer reiterated an "outperform" rating on AppLovin's stock Tuesday, suggesting their positive long-term outlook remains intact.  Shares of PayPal (PYPL) gained close to 5% after the financial technology firm announced the launch of its Ads Manager service for small businesses. Small businesses will be able to opt into PayPal's Ads Manager with no upfront costs or minimum commitments, and the fintech will automatically serve relevant ads on the companies' platforms, PayPal said.

### Intel ###
An all round great PC is now even more affordable than before.  Amazon's Prime Big Deal Days sale is well underway, and for the next two days I'm on the hunt for the best Windows 11 PC deals that you should be paying attention to, especially if you're on a Windows 10 EOL PC and need something to upgrade to. Right now, I've found an incredible deal on a new Windows 11 Copilot+ PC that brings it down to $499 — a 40% discount over its usual price of $829.  This is the Acer Aspire 14 AI, a Copilot+ PC powered by an Intel Core Ultra 5 CPU, paired with an Intel Arc GPU, 16GB RAM, and 512GB SSD storage. It's an all round excellent package, capable of productivity workflows, media consumption, and even some creative tasks and light gaming.  Deal Save 40% ($330) Acer Aspire 14 AI: was $829 now $499 at Amazon This AI PC laptop features an Intel Core Ultra 5 226V CPU with an Intel Arc 130V GPU, 16GB LPDDR5X RAM, and 512GB SSD. It also offers a 14-inch IPS display and an overall metal chassis that feels premium to hold.  When we reviewed the Acer Aspire 14 AI, we found that it's an excellent affordable option for people who are looking to dive into the AI PC space, but don't want to break the bank. It's powered by an Intel Core Ultra 5 226V, along with 16GB RAM and 512GB SSD storage.  This combination of specs makes it a great PC for productivity workflows, such as browsing the web, email, Microsoft Office, Slack and Teams. It's also capable at editing photos and light video work, and can even play games on low to medium settings, and possibly higher depending how old they are.  From a hardware perspective, the Acer Aspire 14 AI has a 14-inch 1080p display with an aspect ratio of 16:10, which means it's slightly taller than normal and makes writing in Word or browsing the web just a little bit nicer. It has a full-size keyboard and large trackpad too, which are great to use.  For ports, it has two USB4 Type-C ports, two USB-A 3.2 Gen 1 ports, a single HDMI 2.1 port, and one headphone jack, which is plenty of I/O for most tasks. It also has Wi-Fi 6E and Bluetooth 5.3 for wirelessly connected peripherals and internet.  FAQ  What’s special about a Copilot+ PC under $500? Copilot+ PCs have, so far, mostly been found priced at the higher side of the spectrum. Usually, you'll find Copilot+ PCs on sale for $600 or more, so when a big sale like Amazon Prime Day comes around, it's a great opportunity to grab one at a sub $500 price point.  How does this relate to Windows 10’s end of life? With Windows 10 support ending in October 2025, casual users who want the latest AI abilities without breaking the bank can see this Copilot+ PC as a future‑proof replacement. It ensures ongoing security updates, compatibility with new apps and AI features, and access to exclusive Copilot+ features like Recall.  Is this deal limited to Prime Day? Yes. The sub‑$500 price is tied to Amazon Prime Day promotions and will only be available for the next two days. Once the sale ends, prices are expected to return to standard retail levels.  Follow Windows Central on Google News to keep our latest news, insights, and features at the top of your feeds!
OpenAI has banned ChatGPT accounts believed to be linked to Chinese government entities attempting to use AI models to surveil individuals and social media accounts.  In its most recent threat report [PDF] published today, the GenAI giant said that these users usually asked ChatGPT to help design tools for large-scale monitoring and analysis - but stopped short of asking the model to perform the surveillance activities.  "What we saw and banned in those cases was typically threat actors asking ChatGPT to help put together plans or documentation for AI-powered tools, but not then to implement them," Ben Nimmo, principal investigator on OpenAI's Intelligence and Investigations team, told reporters.  One now-banned user, suspected to be using a VPN to access the AI service from China, asked ChatGPT to design promotional materials and project plans for a social media listening tool, described as a "probe," that could scan X, Facebook, Instagram, Reddit, TikTok, and YouTube for what the user described as extremist speech, and ethnic, religious, and political content.  This user claimed a government client wanted this scanning tool, but stopped short of using the model to monitor social media. OpenAI said it's unable to verify if the Chinese government ended up using any such tool.  In two other cases, the company banned one user who asked ChatGPT to identify funding sources for an X account that criticized the Chinese government and another one who asked ChatGPT to identify petition organizers in Mongolia.  In both, we're told, OpenAI's models only provided publicly available information - not identities, funding sources, or other sensitive details.  "Cases like these are limited snapshots, but they do give us important insights into how authoritarian regimes might abuse future AI capabilities," Nimmo said. "They point to something about the direction of travel, even if they also suggest that maybe the destination is somewhere away."  Since the company started producing threat reports in February 2024, OpenAI said it has banned more than 40 networks that violated its usage policies.  Also since that time, the threat groups and individuals attempting to use AI for evil have been employing the models to improve their existing tradecraft, not to develop entirely new cyberattacks or workflows. That still seems to be the case, according to OpenAI execs.  More recently, however, some of the disrupted accounts appear to be using multiple AI models to achieve their nefarious goals.  "One China-linked cluster that we investigated, for example, used ChatGPT to draft phishing lures and then explored another model, DeepSeek, to automate mass targeting," said Michael Flossman, who leads OpenAI's threat intelligence team.  Similarly, a set of suspected and now-banned Russian accounts used ChatGPT to generate video prompts for an influence operation dubbed Stop News, but then attempted to use other companies' AI tools to produce the videos that were later posted on YouTube and TikTok.  OpenAI could not independently confirm which other models this group used.  "We're seeing adversaries routinely use multiple AI tools hopping between models for small gains in speed or automation," Flossman said.  In another example of attempted model abuse originating from Russia, the company banned accounts asking ChatGPT to develop and refine malware, including a remote-access trojan, credential stealers, and features to help malware evade detection. The company wrote:  Specifically, they used ChatGPT to generate and iterate on working code and deployment guidance for in‑memory execution and shellcode loaders; UAC / SmartScreen / Mark‑of‑the‑Web bypasses; browser credential / cookie extraction and app‑bound decryption scaffolds; LevelDB wallet parsing and clipboard‑hijack / clipboard‑replacement tooling with exfiltration; and remote‑access (RAT) components including video and input emulation. In line with their safeguards, our models refused requests that were clearly malicious and lacked any legitimate application.  These accounts appear to be linked with Russian-speaking criminal groups, as the threat intel team saw them posting about their activities in a Telegram channel connected to a specific criminal gang. OpenAI execs declined to attribute the malware-making endeavors to a particular cybercrime crew, but said they have "medium to high confidence on who is behind it." ®
The Life of a Showgirl is finally here and—surprise, surprise—half the songs on the album are dedicated to Taylor Swift’s fiancé, Travis Kelce. And while she has seemingly been with her guy on the Chiefs foreeeeever (even though it’s only been a little over two years, believe it or not!), he’s definitely not the first lover to get a song or so penned in his honor.  Before moving on with Travis, Taylor dated Joe Alwyn for a full six years before breaking up...and while there aren’t nearly as many songs about Joe on Showgirl as they were on The Tortured Poets Department, there are still a few subtle nods to her ex. (“Elizabeth Taylor,” anyone?)  Still wondering, “Why did Taylor and Joe break up?” Between scoops from multiple sources and insiders—and clues from Taylor herself—Swifties have a pretty decent idea of what happened between Joe and Tay...and we’re laying it all out in a timeline.  March 20, 2023  Taylor is spotted getting visibly emotional while performing “Champagne Problems” on the Eras Tour, which, in retrospect, fans think might have had something to do with the fact that she was mid-breakup with Joe at this point. (We just didn’t know it yet!!)  March 31, 2023  Taylor switches up her set list, swapping out “Invisible String” (a song widely believed to be about Joe) for “The 1,” a breakup song. I mean, the signs were there!  April 8, 2023  Everyone’s minding their damn business when Entertainment Tonight pops up and announces that Taylor and Joe have broken up. Their headline? A harrowing “Taylor Swift and Joe Alwyn Break Up After Six Years of Dating (Exclusive).”  The intel? That Taylor and Joe broke up “a few weeks ago” (so...sometime in late March 2023) and it was “not dramatic.” ET’s source also says “the relationship had just run its course. It’s why [Joe] hasn’t been spotted at any shows.”  April 10, 2023  After several days of me, you, and everyone we know spiraling, People speaks to someone who says “differences in their personalities” caused Taylor and Joe’s breakup.  “They had plenty in common and fell in love in a safe bubble while she was retreating from the world during Reputation," the source said. "Then the pandemic hit, and they were locked down together and able to continue growing their relationship in this insulated way. But he didn’t really ‘know’ her yet outside of that bubble.”  They continued, “Joe has struggled with Taylor’s level of fame and the attention from the public. The differences in their personalities have also become harder to ignore after years together. They’ve grown apart.”  April 11, 2023  The Daily Mail comes through with a source who says, “It’s been hard for Joe trying to make it in Hollywood and not quite becoming leading man material while dating one of the most famous women in the world over the last six years. It was easier during the pandemic when it was just the two of them, but once things returned to normal, Taylor Swift the superstar emerged, and their differences were even more apparent.”  Meanwhile, Entertainment Tonight speaks to an insider who says, “Taylor and Joe are in totally different places in their lives right now. It was more of Taylor’s decision to break up, but both of them realized that they weren’t completely right for one another. They had been together for such a long time and were spending so much time together, but their personalities were just too different. Joe is more introverted, shy, and quiet.”  April 13, 2023  Taylor performs in Tampa and fans are convinced she’s out here making references to her breakup:  April 19, 2023  A buncha Taylor’s friends unfollow Joe all at once:  May 18, 2023  Amid Taylor’s new relationship with Matty Healy, a source tells the Daily Mail, “Joe feels slighted and is distraught after seeing her budding relationship with Matt but is doing his best to keep busy and focus on himself.”  Oh, and “Joe was aware that Taylor and Matt were making music together and collaborating” and “she told him that they had become friends and he trusted her.”  May 24, 2023  Taylor reveals her vault track “You’re Losing Me,” and everyone speculates that it’s about Joe thanks to lyrics like, “I can't find a pulse / My heart won’t start anymore for you / ’Cause you’re losin’ me.”  September 5, 2023  Joe posts to Instagram for the first time following their breakup, and fans are convinced it’s full of REFERENCES:  November 29, 2023  Jack Antonoff reveals that “You're Losing Me” (which reminder, Taylor dropped in May 2023) was written alllll the way back in December 2021. Which is eye opening, to say the least.  November 30, 2023  Taylor’s publicist, Tree Paine, shuts down speculation that Taylor and Joe had previously gotten married:  February 4, 2024  Taylor reveals her new album is called The Tortured Poets Department, which fans immediately assume is a reference to Joe’s group chat with Paul Mescal and Andrew Scott called “The Tortured Man Club.”  I mean....  February 5, 2024  Taylor drops the tracklist for Tortured Poets, which includes the song “So Long, London,” so naturally everyone spirals:  Meanwhile, a source tells the Daily Mail, “Joe has not said one word about Taylor or their breakup and has been completely respectful of her. It’s undeniable that the name of her upcoming album is in reference to Joe’s WhatsApp group chat. Taylor knocked him for the name of this when they were together. She didn’t want people to think that it had anything to do with her, so when he spoke out about it, she was, of course, bothered.”  They continued, “Joe has no reason to believe yet that she is going to dis him or their relationship. She writes about her past using code and points of reference. It may just be that she is reflecting on their time together and he is hoping it is nothing more.”  And they concluded with: “If it is a dis album, that is shady. He helped her with song writing on her past album so it will really come as a shock to him if she talks about their breakup, as it is something he has not spoken of at all. Regardless of what she does, he will still not respond because he has removed himself from her narrative and is very glad he did.”  Oh, and about the album’s release date? Reminder that April 19 was the day a buncha Taylor’s friends unfollowed Joe:  And April 19 is also considered the date the American Revolution began, which !!  February 16, 2024  Taylor reveals a bonus song on Tortured Poets is called “The Bolter” and everyone immediately thinks it’s a reference to that time Joe quite literally bolted to a car with Taylor.  April 18, 2024  Tortured Poets drops and turns out it is...actually more about Matty Healy? But there is one VERY Joe-coded song called “So Long, London,” which is about the devastating end of their relationship:  I mean, these lyrics!  I saw in my mind ferry lights through the mist  I kept calm and carried the weight of the rift  Pulled him in tighter each time he was drifting away  My spine split from carrying us up the hill  Wet through my clothes, weary bones caught the chill  I stopped trying to make him laugh, stopped trying to drill the safe  June 15, 2024  Joe breaks his silence in a Sunday Times profile. When asked if he’s heard Taylor’s album, he simply says, “I would hope that anyone and everyone can empathize and understand the difficulties that come with the end of a long, loving, fully committed relationship of over six-and-a-half years. That is a hard thing to navigate. What is unusual and abnormal in this situation is that, one week later, it’s suddenly in the public domain and the outside world is able to weigh in.”  He also says the relationship was “never something to commodify, and I see no reason to change that now. Look, this is also a little over a year ago now, and I feel fortunate to be in a really great place in my life—professionally and personally. I feel really good.”  And, baby, that’s show business for you!
The Trump administration is not pleased about a Biden-era, private-sector-led nonprofit that vets AI tools for use in healthcare settings.  The Coalition for Health AI (CHAI) came under criticism from top officials at the Department of Health and Human Services last week, Politico reports.  With laboratories at Duke, Stanford, and Mayo Clinic, CHAI works with the private tech and healthcare sectors to develop guidelines and best practices for AI implementation. The founding partners of the coalition include hospitals like Mass General Brigham, healthcare companies like CVS and UnitedHealth, and big tech giants Microsoft, Amazon, and Google.  “CHAI is this public-private partnership where you have private sector innovators informing public sector officials, and the public sector is able to make better informed policies coming out of there,” CHAI CEO Brian Anderson told Gizmodo.  The non-profit currently has roughly 15 use-case working groups, each led by researchers from the likes of Amazon, Intel, Oracle, Microsoft, and more. The Coalition is also planning to launch a nationwide registry of model cards—kind of like nutritional labels that provide high-level information on AI models—to better inform health systems that are looking to procure AI models.  Trump admin officials are now claiming that the organization’s real aim is to stifle health tech startups and AI development.  “Biden’s Department of Health and Human Services gave CHAI and its Big Tech backers the power to regulate and stifle health-tech startups. This took regulatory capture to a whole new level — one of regulatory outsourcing,” deputy HHS secretary Jim O’Neill and FDA commissioner Marty Makary said in a guest article published by conservative newspaper Washington Examiner last week.  CHAI CEO Brian Anderson argues against that characterization.  “CHAI has nothing to do with government regulation. The government decides on policy and regulation, and CHAI, we will adapt to that,” Anderson said. “[But] in a public-private partnership, we want ideally to inform our regulators and our policymakers so they make informed regulations.”  CHAI has no actual regulatory power, but O’Neill told Politico last week that he has heard from industry officials who have raised concerns that startups that want to work in the space feel as if they need to be a member of the organization. O’Neill believes CHAI holds the potential to become a “cartel” that suppresses innovation in health AI.  “No one should really feel compelled to submit their work for the analysis of their competitors or people that are entangled with their competitors,” O’Neill told Politico.  “It’s like a self-licking ice cream cone, a virtual and unethical syndicate. We’re hitting reset. Under Secretary Robert F. Kennedy Jr., HHS will not allow CHAI—nor any other nonprofit group, think tank, or company—to operate as an implicitly government-backed regulator or policymaker,” O’Neill and Makary wrote in the Washington Examiner. That claim might seem rich considering the Trump administration has largely been following the Project 2025 playbook that was devised by the Heritage Foundation, a conservative think tank.  CHAI’s aims were also questioned along similar lines by Republican Congressmen at previous Senate hearings.  In a hearing from May 2024, Republican Rep. Mariannette Miller-Meeks said that CHAI and other similar organizations, referred to as assurance labs, don’t “pass the smell test” and show “clear signs of attempt at regulatory capture.”  Regulatory capture happens when a regulatory agency created to advance public interest becomes a shell for special interest groups that dominate the very industry that the agency is supposed to regulate. During the hearing, Dr. Jeff Shuren, who led the FDA’s Center for Devices and Radiological Health at the time but has since left his post, responded to the representatives’ concerns by saying that if CHAI produces “anything in terms of deliverables that is useful, we may take it into consideration. But they don’t work for us, we don’t work for them.”  Fears of CHAI attempting regulatory capture were also raised in an opinion piece by an executive at venture capital firm Andreessen Horowitz.  “Big corporations have a strong incentive to seize the market under the guise of safety,” general partner at Andreessen Horowitz’s Bio+Health team Julie Yoo wrote in the op-ed, claiming that additional layers of review of startups’ intellectual property were “slowing down real innovation.”  The founders of Andreessen Horowitz endorsed Trump in the 2024 election and have backed a $100 million effort to influence AI policy with an outside group called “Leading the Future.”  CHAI is not mandatory, but despite that, there are 3,000 organizations that are members of the coalition, a mix of tech and healthcare companies, and hospitals. Anderson says that 700 of these members are startups, the most active and fastest growing stakeholder community in CHAI.  He argues that startups join CHAI not out of pressure but as a way to advance their business and understand their customers.  “The reason why the startups want to be part of this is because they want to build a product that they can sell to as many health systems and life science companies,” Anderson said. “It is Business 101 for any technology company to know your customers, and that’s essentially what we’re creating.”  That logic also goes for big tech companies that provide cloud services to these health AI startups, according to him. Microsoft’s Azure, Amazon’s AWS, and the Google Cloud Platform are all go-to picks for AI startups and are all founding partners.  He insists that startups’ interests won’t be crushed under the big tech companies that are also a part of the Coalition, saying that each company only gets one seat in working groups, and the startups outnumber big tech companies.  But the founding partners, which include Amazon, Google, and Microsoft, also have a guaranteed seat on an advisory board that reports to the board of directors to shape governance decisions.  All for transparency  O’Neill told Politico that the Trump administration supports AI transparency efforts so that buyers can make better-informed decisions. That’s one point that, in principle, he and Anderson see eye to eye on.  Because AI is rather new, “it’s really important to have a level of transparency into how these models actually perform, and to be able to monitor them once they’re deployed,” Anderson said.  “The ultimate liable party when a model is used is not the vendor, it’s the doctor, it’s the health system. So you have health systems rightly saying ‘Well, before I use this model, I need to know what kind of data sets were used to train it, what was the training methodology?” Anderson said.  But Anderson believes it makes sense that tech companies don’t want to reveal their intellectual property. CHAI tries to strike a balance through working groups that bring together researchers and executives from both sectors to come to a consensus on what the minimum amount of disclosure is that can satisfy these transparency requirements.  This includes high-level descriptions of datasets and methodology that is used to train AI models, rather than showing row for row the exact datasets used.  “The model card does not require the startup community, or the tech companies in general, to reveal their IP,” Anderson said. “This was the vendors wanting to build trust with customers, and the customers wanting to be able to trust these tools.”  Assurance resource providers certified by CHAI, BeeKeeperAI, and Citadel AI, with more incoming, also offer a voluntary test that health systems can ask developers to go through before making a final purchasing decision. It’s tests like these that critics are against, but CHAI claims that it’s important for responsible and transparent health AI deployment, and that it actually accelerates AI adoption in healthcare by streamlining the vetting and deployment process.  Government relations  Despite being private sector-led, CHAI does work in some capacity with government officials.  Two former Biden administration officials, HHS assistant secretary for technology policy Mickey Tripathi and director of the FDA’s Digital Health Center of Excellence Troy Tazbaz, were for a limited time non-voting members of the board while still serving in government positions, but later resigned citing conflicts of interest.  The Biden administration also had multiple federal liaisons working in the Coalition’s working groups, and the Coalition’s relationship with the government continues under the Trump administration. At least so far.  Anderson said they have had multiple technical leads from HHS agencies like the Centers for Medicare & Medicaid Services, and recently announced a collaboration with the National Institute of Standards and Technology, which has been directed to focus entirely on advancing AI under Trump.  CHAI also has regular meetings with Republican Senators Mike Crapo, Mike Rounds, Todd Young, and Ted Cruz to talk about AI in health, according to Anderson. Politico reported that CHAI hired Sen. Crapo’s former health care aide, Susan Zook, earlier this year to lobby officials.  He is worried that this change of heart by the HHS might jeopardize these connections. CMS has not yet responded to a request for comment from Gizmodo on its plans going forward regarding CHAI.  Healthcare is one of AI’s most celebrated and scrutinized use cases. AI companies, like OpenAI, are making huge plays for the healthcare sector. Meanwhile, healthcare AI startup OpenEvidence has (allegedly) found its way onto the screens of a quarter of doctors nationwide.  The government is bullish on it, too. In July, the White House hosted a “Make Health Tech Great Again” event where Trump announced a private sector initiative that will use conversational AI assistants for patient care and share the private medical records of Americans across apps and programs from 60 companies.  But there is no clear verdict on just how well AI performs in medical settings. A Stanford study from last year showed that ChatGPT performed very well in medical diagnoses, even better than some physicians did, but some doctors are not convinced that the early tests are reassuring.  Healthcare is a closely scrutinized AI use case because even one mistake can be fatal, and our current AI systems are very far from perfect, with frequent hallucinations and baked-in biases.  It’s led concerned experts to call for more transparency and regulation. The United States made its first major regulatory step towards achieving that transparency earlier this week when California Governor Gavin Newsom signed into law the Transparency in Frontier Artificial Intelligence Act, a first-of-its-kind bill that could be a catalyst for more legislation nationwide.  There is currently limited federal oversight when it comes to the deployment of health AI, though it’s looking as if the Trump administration could be ready to take over the reins.  The FDA published a request for information last week, seeking to gather feedback from the medical sector on health AI deployment and evaluation. Whether that direct feedback will be taken as seriously as the desires of deep-pocketed outside interest groups remains to be seen.
Dublin, Oct. 07, 2025 (GLOBE NEWSWIRE) -- The "The Global Market for Glass Substrates for Semiconductors 2026-2036" report has been added to ResearchAndMarkets.com's offering.    The Global Glass Substrate for Semiconductors Market 2026-2036 report provides critical insights for semiconductor manufacturers, substrate suppliers, equipment providers, and technology investors navigating this revolutionary transition.  The report delivers comprehensive coverage across seven critical application segments: carrier and support glass, blank drilled core panels, finished IC substrates for single-die usage, finished interposers for multi-die packages, glass integrated passive devices (IPD), RF-MEMS applications, and photonic integration tiles. Each segment analysis includes detailed market forecasts, technology requirements, competitive positioning, and growth drivers specific to AI accelerators, data center infrastructure, 5G/6G communications, automotive electronics, and consumer devices.  The glass substrate for semiconductors market represents one of the most significant material shifts in the packaging industry in decades, driven by the escalating demands of AI, high-performance computing (HPC), and advanced networking applications. This emerging market is transitioning glass from a background consumable to the core substrate material enabling next-generation chip architectures. The market is experiencing unexpected acceleration, with commercialization timelines moving ahead of initial projections.  Recent industry events have highlighted the competitive intensity, particularly following speculation about potential partnerships between major players. SKC's stock price surged 44.4% in early 2025 after comments suggesting advanced negotiations with leading AI chip manufacturers, signaling investor confidence in near-term commercialization prospects. The momentum reflects growing recognition that glass substrates can deliver up to 40% speed improvements while reducing power consumption by half compared to conventional organic substrates.  The surge in AI accelerators and HPC devices has created unprecedented demands for bandwidth density and power delivery that traditional organic substrates simply cannot support. Modern training accelerators require thousands of high-speed I/O bumps and power-delivery networks handling hundreds of amps with minimal noise. Glass substrates address these challenges through superior dimensional stability, ultra-low warpage, and the ability to support sub-2-micron interconnects with exceptional signal integrity. Glass substrates excel in heat and warpage resistance while enabling higher chip stacking densities on single substrates. The smoother surface allows ultra-fine circuit patterns, making them ideal for applications spanning carrier glass, IC substrates, interposers for multi-die packages, RF-MEMS applications, and photonic integration. Major semiconductor companies including Intel, AMD, and Broadcom have announced adoption plans for their next-generation chips.  Glass substrates offer compelling advantages over existing materials. Their coefficient of thermal expansion (CTE) matches silicon (3-7 ppm/C), dramatically reducing thermomechanical stress in advanced packages. The dielectric constant is significantly lower than silicon (2.8 vs. 12), enabling superior high-frequency performance with orders of magnitude lower transmission losses. Manufacturing infrastructure is rapidly developing. Through-glass via (TGV) formation represents the core enabling technology, with multiple approaches including laser-induced deep etching (LIDE), direct laser drilling, and photosensitive glass processing. Leading equipment suppliers like LPKF, Canon, and Yield Engineering Systems are developing production-ready tools.  The glass substrate market emergence coincides with the industry's shift toward advanced packaging methodologies including chiplets, 2.5D/3D-IC integration, and heterogeneous system architectures. While organic substrates will continue serving mainstream applications, the accelerating timeline for glass commercialization suggests the high-performance segment transition may occur faster than initially anticipated. Success depends on continued yield improvements, cost reduction through scale, and ecosystem maturation. With AI/HPC growth driving performance requirements beyond organic substrate capabilities, glass substrates represent the critical enabler for continued semiconductor advancement, with commercial deployment potentially beginning as early as 2025-2026.  Report contents include:  Glass materials overview and semiconductor applications analysis  Market opportunities and value chain transformation from organic to glass substrates  Global market forecasts with unit shipment and revenue projections 2025-2036  Key advantages, adoption challenges, and future market trends  Advanced processing technologies and sustainable manufacturing initiatives  Investment priority areas and representative player activity assessment  Technology Fundamentals & Manufacturing  Glass materials properties: borosilicate, quartz, and specialty compositions  Manufacturing processes: glass melting, forming, and panel-level processing  Through Glass Via (TGV) formation technologies and metallization processes  Design considerations: thermal management, stress analysis, electrical optimization  Build-up layer fabrication and advanced manufacturing process development  Advanced Packaging & IC Substrates Analysis  Evolution from 1D to 4D advanced packaging architectures  Intel's roadmap, heterogeneous integration, and system-level packaging solutions  Glass IC substrate evolution and organic-to-glass core transition analysis  Comprehensive TGV technology coverage: formation, processing, metallization  Material property comparisons and performance benchmarking  Traditional substrate limitations and glass core substrate technologies  Industry implementation case studies and innovation analysis  Photonic Integration Applications  Photonic integrated circuits and co-packaged optics architecture  Glass waveguide technologies and ion exchange formation processes  EIC/PIC integration and optical coupling solutions  Manufacturing processes and laser separation technology  3D integration capabilities and fabrication process optimization  Corning's high-density platform and advancement analysis  High-Frequency Applications Market  Low-loss material requirements for 5G/6G semiconductor packaging  Material benchmarking: LTCC vs glass performance characteristics  RF applications enabled by glass substrate technology  Commercial product analysis and supplier ecosystem  Filter substrates, IPD implementations, and antenna-in-package solutions  6G technology enablement and glass interposer applications  Technology Benchmarking & Competitive Analysis  Glass vs organic substrates: performance, cost, manufacturing comparison  Glass vs silicon interposers: technical metrics and economic analysis  Hybrid substrate solutions and multi-material integration strategies  Future technology roadmaps and performance projection modeling  Innovation trends and process technology evolution analysis  End-User Market Analysis  AI and high-performance computing market requirements and growth drivers  Data center infrastructure scaling and performance efficiency demands  Telecommunications 5G/6G evolution and RF component specifications  Automotive electronics: ADAS, EV, autonomous driving applications  Consumer electronics: mobile, wearable, gaming system integration  Market Challenges & Strategic Opportunities  Technical challenges: manufacturing maturity, yield optimization, standardization  Economic barriers: cost competitiveness, investment requirements, adoption timelines  Strategic opportunities: performance differentiation and new application development  Technology convergence benefits and market expansion potential  Future Outlook & Market Scenarios  Technology evolution projections and material development roadmaps  Advanced manufacturing process development and integration advances  Performance enhancement projections and capability scaling  Market development scenarios: optimistic, conservative, disruptive impact analysis  Comprehensive Company Profiles (35 Featured)  Absolics  BOE  Corning  Intel  JNTC Co., Ltd.  KCC  LG Innotek  LPKF  Nippon Electric Glass (NEG)  Plan Optik AG  Samsung Electro-Mechanics (Semco)  Toppan  The report includes:  PDF report. Print edition also available.  Comprehensive Excel spreadsheet of all data.  Mid-year Update  Key Topics Covered:      1 EXECUTIVE SUMMARY  1.1 Glass Materials Overview  1.2 Applications of Glass in Semiconductors  1.3 Glass for Advanced Packaging  1.4 Glass Used in Various Semiconductor Applications  1.5 Opportunities with Glass Packaging  1.6 Advantages of Glass Substrates  1.7 Challenges in Adopting Glass Substrates  1.8 Future Market Trends  1.9 Value Chain of Glass Substrate  1.10 Future Outlook  1.11 Material Innovations  1.12 Global Market Forecasts 2025-2036  2 GLASS SUBSTRATES TECHNOLOGY FUNDAMENTALS  2.1 Glass Materials Properties  2.2 Manufacturing Processes  2.3 Design and Process Considerations  3 GLASS IN ADVANCED PACKAGING AND IC SUBSTRATES  3.1 Advanced Packaging Evolution  3.2 Packaging Architecture and Integration  3.3 Glass IC Substrates Evolution  3.4 Through Glass Via Technology  3.5 TGV Metallization and Processing  3.6 Material Properties and Performance  3.7 Traditional Substrate Limitations  3.8 Glass Core Substrate Technologies  3.9 Glass Substrate Manufacturing  3.10 Advanced Manufacturing Processes  3.11 Industry Implementation and Innovation  4 GLASS IN PHOTONICS  4.1 Photonic Integration  4.2 Co-Packaged Optics  4.3 Glass Waveguide Technologies  4.4 Manufacturing and Integration Processes  5 GLASS IN HIGH-FREQUENCY APPLICATIONS  5.1 High-Frequency Material Requirements  5.2 Material Benchmarking and Performance  5.3 Glass Suppliers and Products  5.4 RF Applications and Implementations  6 TECHNOLOGY BENCHMARKING AND COMPARISON  6.1 Glass vs Organic Substrates  6.2 Glass vs Silicon Interposers  6.3 Hybrid Substrates  6.4 Future Technology Roadmaps  7 END-USER MARKET ANALYSIS  7.1 AI and High-Performance Computing  7.2 Data Centers and Cloud Computing  7.3 Telecommunications and 5G/6G  7.4 Automotive Electronics  7.5 Consumer Electronics  8 CHALLENGES AND OPPORTUNITIES  8.1 Technical Challenges  8.2 Economic and Market Challenges  8.3 Strategic Opportunities  9 FUTURE OUTLOOK  9.1 Technology Evolution Projections  9.2 Market Development Scenarios  10 COMPANY PROFILES (35 company profiles)  11 APPENDICES  11.1 Technical Glossary and Definitions  11.2 Technology Evolution Timeline  11.3 Market Research Methodology Details  12 REFERENCES  For more information about this report visit https://www.researchandmarkets.com/r/t2lo4f  About ResearchAndMarkets.com  ResearchAndMarkets.com is the world's leading source for international market research reports and market data. We provide you with the latest data on international and regional markets, key industries, the top companies, new products and the latest trends.
Apple Intelligence is Apple’s take on AI, powering many handy features, including Writing Tools, Genmoji, Image Playground, Live Translation, Transcription, and more. It’s available on select devices, software versions, regions, and languages. So, if you’re unable to set it up, go through this Apple Intelligence compatibility guide to ensure you have a supported device and have fulfilled the other conditions.  Supported devices  Apple Intelligence works on the following devices.  iPhone:  iPhone 17 Pro Max  iPhone 17 Pro  iPhone Air  iPhone 17  iPhone 16 Pro Max  iPhone 16 Pro  iPhone 16 Plus  iPhone 16  iPhone 16e  iPhone 15 Pro Max  iPhone 15 Pro  iPad:  iPads with Apple silicon chip and iPad mini with A17 Pro chip support Apple Intelligence.  iPad mini (A17 Pr0)  iPad Air (M1 and later)  iPad Pro (M1 and later)  Mac:  Mac notebooks and desktops with an Apple silicon chip support Apple Intelligence. None of the Intel Macs are supported.  MacBook Air (M1 and later)  MacBook Pro (M1 and later)  iMac (M1 and later)  Mac mini (M1 and later)  Mac Studio (M1 Max and later)  Mac Pro (M2 Ultra)  Apple Watch:  Apple Intelligence is available on the following Apple Watch models only when connected to an Apple Intelligence-enabled iPhone.  Apple Watch Series 6 and later  All Apple Watch Ultra models  Apple Watch SE 2 and later  Apple Vision Pro  There is only one model of Apple Vision Pro, and it supports Apple Intelligence.  Software requirements  Apple Intelligence is available on supported devices running the following versions of Apple’s operating systems:  iOS 18.1 or later  iPadOS 18.1 or later  macOS Sequoia 15.1 or later  watchOS 11 or later  visionOS 2.4 or later  However, for most features and to get the best experience, make sure your devices are updated to iOS 26, iPadOS 26, macOS Tahoe 26, watchOS 26, and visionOS 26.  Three other requirements  Your device language (Settings > General > Language & Region) and Siri Language (Settings > Siri > Language) must be one of the supported languages (list below).  Your device language and the Siri language must be set to the same language. For instance, both must be English (US).  language. For instance, both must be English (US). Apple Intelligence downloads and stores a ton of files to your device’s local storage. These files are needed for both online and offline Apple Intelligence tools. Therefore, you must have at least 7 GB of free space on your device just for Apple Intelligence to activate. Note that since Apple Intelligence on Apple Watch is simply an extension of iPhone, this free storage requirement doesn’t apply to Apple Watch.  Supported Languages  Your OS 26 device and Siri language must be set to one of the following languages for Apple Intelligence to work. Note that Apple Intelligence should work in most countries, even if the following languages are not the primarily spoken there.  English (Australia, Canada, India, Ireland, New Zealand, Singapore, South Africa, the United Kingdom, and the United States)  Chinese (Simplified) (not available in China mainland)  French  German  Italian  Japanese  Korean  Portuguese (Brazil) (not on Apple Vision Pro)  Spanish  Support for these languages and locales is expected to arrive soon:  Chinese (Traditional)  Danish  Dutch  Norwegian  Swedish  Portuguese (Portugal)  Vietnamese  Turkish  What happens if you change your device or Siri language?  If you change both the device and Siri language to a supported language:  Apple Intelligence is unavailable for a while until the new language files are downloaded. Keep your device connected to Wi-Fi and power for the essential Apple Intelligence files to download.  If you change just one (device or Siri) language:  Apple Intelligence won’t work unless both the device language and Siri language are the same.  If you change either or both the device and Siri languages to an unsupported language:  Apple Intelligence won’t work.  Supported regions  Apple Intelligence is available in most countries and regions, including the European Union (EU), provided:  Your iPhone, iPad, or Mac is updated to iOS 26, iPadOS 26, and macOS Tahoe 26.  Both your device and Siri languages are set to one of the above supported languages.  Your device was not purchased from China mainland. And you (with a supported device) are not in China, and your Apple Account country is not set to China mainland. Note: Once Apple Intelligence is available in China, devices purchased there and Apple Accounts with their region set to China mainland will be able to use Apple’s AI features.  Does Apple Intelligence work if you travel to a new country?  Once you’ve set up Apple Intelligence successfully, it will keep working even if you travel to most other countries and regions around the world, provided you haven’t changed the device and Siri language.  Language requirement for specific Apple Intelligence features  From Writing Tools to Image Playground and Live Translation to Clean Up, more than 30 individual features are powered by Apple Intelligence.  Most of these features work with all supported languages and regions (list above). But of course, there are exceptions, and you can see them all at Apple’s feature availability page.  Also, check out: How to turn off all Apple Intelligence features on iPhone
is a senior editor and author of Notepad , who has been covering all things Microsoft, PC, and tech for over 20 years.  Posts from this author will be added to your daily email digest and your homepage feed.  It’s been a while since Apple last mocked Windows security, but the iPhone maker has just released an ad that hits Windows hard. The eight-minute commercial pokes fun at the CrowdStrike Blue Screen of Death (BSOD) issue that took down millions of Windows machines last year.  Apple’s ad follows The Underdogs, a fictional company that’s about to attend a trade show, before a PC outage causes chaos and a Blue Screen of Death shuts down machines at the convention. If it wasn’t clear Apple was mocking the infamous CrowdStrike incident, an IT expert appears in the middle of the ad and starts discussing kernel-level functionality, the core part of an operating system that has unrestricted access to system memory and hardware.  CrowdStrike’s Falcon protection software operates at the Kernel level, and a buggy update last year created BSOD issues that took down banks, airlines, TV broadcasters, and much more.  “The endpoint security API handles kernel-level functionality by default, it doesn’t grant kernel-level access,” says Sam, Apple’s security expert character. “The deepest parts of an operating system are being protected from modification by third-party software or malware, which is obviously what happened to those PCs. It’s a PC problem, your Macs are secure.”  Apple’s solution in its commercial? Switch to Mac, of course. The ad shows how The Underdogs were able to keep working on Macs and make sales, while the rest of the convention switched to Mac Minis.  Apple has a long history of mocking Windows security. The original “Get a Mac” TV campaign started nearly 20 years ago, and included a 30-second spot of the “I’m a PC” guy sneezing after catching a virus. Apple’s “I’m a Mac” guy, actor Justin Long, even returned a few years ago and defected to Intel to praise PCs, before also appearing in Qualcomm’s skit blasting macOS notifications and nag screens.
This repo aims to prove that something is wrong with APFS on macOS, but is also a good stress test in general when changing machine tooling that wants to oberve fs events (such as security tooling / EDR / virus scanners / etc).  The Test  Steps:  Setup Gather Results Report / PR with your Results ❤️  Setup  have node @ >= 22.11 have pnpm @ >= 10.2  (if you have proto (with auto-install) or volta installed, these versions will be selected for you)  git clone https://github.com/NullVoxPopuli/disk-perf-git-and-pnpm.git cd disk-perf-git-and-pnpm pnpm install # Fill the cache so we don't hit the network during testing  Gather Results  Since you've installed all the dependencies already, we can start with the clean test:  time ( git clean -Xfd ; git clean -fd )  Windows Powershell:  ( Measure-Command { git clean - Xfd; git clean - fd }).ToString()  And then once that finishes, we can run the install test:  time ( pnpm install )  Windows Powershell:  ( Measure-Command { pnpm install }).ToString()  If using zsh your time will be total . 0.01s user 0.00s system 94% cpu 0.007 total # . ^ this number and round to the tenths decimal place  if using bash your time will be real . real 2.02s # this number user 0.00s sys 0.01s and round to the tenths decimal place  How to find your disk info MacOS Apple Menu "About this Mac" (a window appears) "More Info..." (a window appears) scroll down and click "System Report..." (a window appears) in the left nav of this third window, click "NVMExpress"  PR your Results back to this Repo  and interact with the results here  Date CPU RAM (GB) Clean (s) Install (s) OS FileSystem Disk Notable Software Changes 2025-02-07 AMD Ryzen 5 7640U 12 Core 92 6.8 5.9 Ubuntu 24.04.1 Ext4 WD Black SN850 500GB 2025-02-24 AMD Ryzen 5 7640U throttle to ~550Mhz 92 56 44 Ubuntu 24.10 Ext4 WD Black SN850 500GB 2025-02-07 AMD Ryzen 9 7900X 12/24 Core 64 6.0 4.3 Ubuntu 24.04.1 Ext4 Samsung SSD 980 Pro 2TB 2025-02-07 AMD Ryzen 9 7900X 12/24 Core 64 3.3 4.0 Ubuntu 24.04.1 tmpfs (ramdisk) G.Skill F5-6000J3040G32G 2025-02-09 Apple M1 Pro 16 42.2 44.0 macOS 15.3 APFS (Encrypted) APPLE SSD AP0512R 500GB 2025-02-08 Apple M1 Max 64 31.5 44.2 macOS 14.7.3 APFS (Encrypted) APPLE SSD AP1024R 1TB 2025-02-08 Apple M4 16 29.6 31.4 macOS 15.2 APFS (Encrypted) APPLE SSD AP1024Z 1TB 2025-02-09 AMD Ryzen 7 7800X3D 8 Core 32 17.1 16.1 Ubuntu 22.04.3 Ext4 Corsair MP600 PRO LPX 2025-02-09 AMD Ryzen 7 7800X3D 8 Core 32 65.5 42.3 Windows 10 Pro 22H2 NTFS Corsair MP600 PRO LPX 2025-02-09 AMD Ryzen 5 7800X3D 8 Core 64 69.5 73.3 Windows 11 Pro 23H2 NTFS WD Black SN850x 2TB 2025-02-09 AMD Ryzen 5 7800X3D 8 Core 64 23.7 19.0 W11 Pro 23H2 / WSL2 / Ubuntu 24.04 Ext4 WD Black SN850x 2TB 2025-02-10 Intel i5-1145G7 8 Core 32 1.9 15.3 Debian Trixie Ext4 BC711 NVMe SK hynix 512GB 2025-02-12 Apple M1 Max 32 71.4 87.7 macOS 14.6.1 APFS (Encrypted) APPLE SSD AP2048R 2TB 2025-02-12 Apple M4 Pro (14 Cores) 48 30.1 65.1 macOS 15.3 APFS (Encrypted) APPLE SSD AP2048Z 2TB 2025-02-13 Apple M1 Ultra 64 45.2 137.5 macOS 15.3 APFS APPLE SSD AP1024R 1TB 2025-02-14 Apple M2 Max (6 vCPU) 16 3.2 12 Ubuntu 24.04 Ext4 APPLE SSD AP1024Z Parallels VM 2025-02-14 Apple M2 Max (6 vCPU) 16 2.8 11.9 Ubuntu 24.04 Ext4 LVM2 Encrypted APPLE SSD AP1024Z Parallels VM 2025-02-14 Apple M2 Max (6 vCPU) 16 1.6 10.7 Ubuntu 24.04 tmpfs (ramdisk) Hynix LPDDR5 / Virtual RAM Parallels VM 2025-02-15 Apple M1 Pro 32 44.5 50.2 macOS 15.3 APFS (Encrypted) APPLE SSD AP0512R 500GB 2025-02-19 Apple M1 16 37.8 33.3 macOS 15.3.1 APFS (Encypted) APPLE SSD AP0512Q 500GB 2025-02-19 Apple M1 Pro 16 59.4 69.1 macOS 14.7.3 APFS (Encrypted) APPLE SSD AP1024R 1TB 2025-02-21 Apple M3 16 36.23 30.3 macOS 15.3 APFS APPLE SSD AP0256Z 256GB 2025-02-20 Apple M4 Max (16 Cores) 128 36.7 64.5 macOS 15.2 APFS (Encrypted) APPLE SSD AP2048Z 2TB 2025-02-20 Apple M3 24 46.6 44.6 macOS ?? APFS APPLE SSD AP1024Z 1TB 2025-02-21 Intel Core i7 14700K (20 Cores) 64 3.1 13.8 W10 22H2 / WSL2 / Ubuntu 24.04 Ext4 WD Black 2TB SN850 2025-02-22 Apple M3 Pro 18 37.7 40 macOS 15.3 APFS APPLE SSD AP1024Z 1TB 2025-02-24 Apple M2 Pro 32 34.6 32.0 macOS 13.6 APFS APPLE SSD AP0512Z 2025-02-25 Apple M3 16 34.213 27.851 macOS 15.3.1 APFS APPLE SSD AP1024Z 2025-02-25 Apple M3 Pro (12 Core, 6p6e) 36 47.8 52.6 macOS 14.7.4 APFS APPLE SSD AP0512Z 500GB 2025-02-25 Apple M3 Pro (12 Core, 6p6e) 36 32 53.3 macOS 14.7.4 APFS APPLE SSD AP0512Z 500GB Spotlight disabled 2025-02-25 Apple M3 Pro (12 Core, 6p6e) 36 26.3 19.9 macOS 14.7.4 APFS APPLE SSD AP0512Z 500GB Spotlight disabled, csrutil disable 2025-02-26 Apple M2 Max (12 Core, 8p4e) 32 41.4 39.8 macOS 15.3.1 APFS (Encrypted) APPLE SSD AP1024Z 1TB Spotlight disabled, Kandji, SentinelOne 2025-02-26 Apple M4 Pro (14 Cores) (6 core vCPU) 6 2.5 16.9 Ubuntu 24.10 Ext4 Unencrypted APPLE SSD AP2048Z 2TB UTM VM 2025-02-28 Apple M2 Max (6 vCPU) 16 11.9 15.7 Ubuntu 24.04.2 Ext4 LVM2 Encrypted APPLE SSD AP1024Z Parallels VM, SentinelOne 2025-02-28 Apple M2 Max (6 vCPU) 16 9.1 13.3 Ubuntu 24.04.2 tmpfs (ramdisk) Hynix LPDDR5 / Virtual RAM Parallels VM, SentinelOne 2025-04-26 Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz 32 103.98 116.62 macOS 15.4.1 APFS (Encrypted) Apple SSD AP1024N 2025-04-27 Apple M4 Pro (14 Core, 10p4e) 48 64.48 145.40 macOS 15.3.2 APFS (Encrypted) Apple SSD AP1024Z 2025-04-27 Apple M4 Pro (14 Core, 10p4e) 48 3.209 17.302 Ubuntu 24.04.2 btrfs Apple SSD AP1024Z Ubuntu machine running in OrbStack 2025-10-06 Apple M2 Max (12 Core, 8p4e) 32 46.730 54.603 macOS 15.5 APFS (Encrypted) Apple SSD AP1024Z 1TB Kandji, Code42, SentinelOne, tested in excluded directory 2025-15-07 Apple M3 Air (8 Core, 4p4e) 16 34.104 29.293 macOS 15.7 APFS (Encrypted) Apple SSD AP0512Z 500GB Kandji, SentinelOne, tested in excluded directory  What to do for now?  If you're using macOS, and your file system performance is unbearable, there are some options:
This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.  Nvidia CEO Jensen Huang told staff that the company will continue to sponsor H-1B visas and cover all associated costs following President Donald Trump's executive order last month that imposed a $100,000 fee on each new application.  Huang reiterated his earlier support for the changes and shared personal reflections on immigration in the internal message, which Business Insider viewed.  "As one of many immigrants at Nvidia, I know that the opportunities we've found in America have profoundly shaped our lives," he wrote. "And the miracle of Nvidia — built by all of you, and by brilliant colleagues around the world — would not be possible without immigration."  Nvidia declined to comment.  In his message to staff, Huang said "legal immigration remains essential to ensuring the US continues to lead in technology and ideas," and that the Trump administration's "recent changes reaffirm this."  Huang previously said on CNBC that he was "glad" to see Trump's executive order. In a subsequent interview on the "BG2 Pod" podcast, he expressed some critiques, saying the changes were a "great start," but that the $100,000 price tag "probably sets the bar a little too high."  Huang also acknowledged another critique in his podcast interview: that the $100,000 fees could have a more significant impact on cash-strapped startups than well-funded tech companies, which can more easily afford them.  Related stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know  The Trump administration said it imposed the rules to encourage more domestic hiring and prevent what it called "abuses" of the H-1B visa system. Critics argue that it could have the opposite effect, leading to increased hiring abroad.  Nvidia is one of the world's most successful companies, with a market capitalization of $4.5 trillion. It's also one of the top sponsors of H-1B visas in the tech industry, with roughly 1,500 approvals in 2025.  You can read Huang's memo in full below.  Hi everyone, Immigration is at the heart of the American dream — an enduring symbol of opportunity that reminds us that anyone, regardless of where they come from, can achieve success and build a better life through hard work, talent, and determination. As one of many immigrants at NVIDIA, I know that the opportunities we've found in America have profoundly shaped our lives. And the miracle of NVIDIA — built by all of you, and by brilliant colleagues around the world — would not be possible without immigration. H-1 B visas provide a vital pathway for exceptional talent to contribute to America's growth and innovation. Legal immigration remains essential to ensuring the U.S. continues to lead in technology and ideas. The administration's recent changes reaffirm this — helping America attract and retain the most exceptional talent. At NVIDIA, we built our company with extraordinary people from around the world, and we will continue to sponsor H-1B applicants and cover all associated fees. If you have any questions about H-1B visas, please reach out to NVIDIA-Immigration. Best regards, Jensen  Have a tip? Contact this reporter via email at gweiss@businessinsider.com or Signal at @geoffweiss.25. Use a personal email address and a nonwork device; here's our guide to sharing information securely.
The extensive collaboration features and global adoption of Microsoft Teams make it a high-value target for both cybercriminals and state-sponsored actors. Threat actors abuse its core capabilities – messaging (chat), calls and meetings, and video-based screen-sharing – at different points along the attack chain. This raises the stakes for defenders to proactively monitor, detect, and respond.  While under Microsoft’s Secure Future Initiative (SFI), default security has been strengthened by design, defenders still need to make the most out of customer-facing security capabilities. Therefore, this blog recommends countermeasures and controls across identity, endpoints, data apps, and network layers to help harden enterprise Teams environments. To frame these defenses, we first examine relevant stages of the attack chain. This guidance complements, but doesn’t repeat, the guidance built into the Microsoft Security Development Lifecycle (SDL) as outlined in the Teams Security Guide; we will instead focus on guidance for disrupting adversarial objectives based on the relatively recently observed attempts to exploit Teams infrastructure and capabilities.  Attack chain  Figure 1. Attack techniques that abuse Teams along the attack chain  Reconnaissance  Every Teams user account is backed by a Microsoft Entra ID identity. Each team member is an Entra ID object, and a team is a collection of channel objects. Teams may be configured for the cloud or a hybrid environment and supports multi-tenant organizations (MTO) and cross-tenant communication and collaboration. There are anonymous participants, guests, and external access users. From an API perspective, Teams is an object type that can be queried and stored in a local database for reconnaissance by enumerating directory objects, and mapping relationships and privileges. For example, federation tenant configuration indicates whether the tenant allows external communication and can be inferred from the API response queries reflecting the effective tenant federation policy.  While not unique to Teams, there are open-source frameworks that can specifically be leveraged to enumerate less secure users, groups, and tenants in Teams (mostly by repurposing the Microsoft Graph API or gathering DNS), including ROADtools, TeamFiltration, TeamsEnum, and MSFT-Recon-RS. These tools facilitate enumerating teams, members of teams and channels, tenant IDs and enabled domains, as well as permissiveness for communicating with external organizations and other properties, like presence. Presence indicates a user’s current availability and status outside the organization if Privacy mode is not enabled, which could then be exploited if the admin has not disabled external meetings and chat with people and organizations outside the organization (or at least limited it to specified external domains).  Many open-source tools are modular Python packages including reusable libraries and classes that can be directly imported or extended to support custom classes, meaning they are also interoperable with other custom open-source reconnaissance and discovery frameworks designed to identify potential misconfigurations.  Resource development  Microsoft continuously enhances protections against fraudulent Microsoft Entra ID Workforce tenants and the abuse of free tenants and trial subscriptions. As these defenses grow stronger, threat actors are forced to invest significantly more resources in their attempts to impersonate trusted users, demonstrating the effectiveness of our layered security approach. . This includes threat actors trying to compromise weakly configured legitimate tenants, or even actually purchasing legitimate ones if they have confidence they could ultimately profit. It should come as no surprise that if they can build a persona for social engineering, they will take advantage of the same resources as legitimate organizations, including custom domains and branding, especially if it can lend credibility to impersonating internal help desk, admin, or IT support, which could then be used as a convincing pretext to compromise targets through chat messaging and phone calls. Sophisticated threat actors try to use the very same resources used by trustworthy organizations, such as acquiring multiple tenants for staging development or running separate operations across regions, and using everyday Teams features like scheduling private meetings through chat, and audio, video and screen-sharing capabilities for productivity.  Initial access  Tech support scams remain a generally popular pretext for delivery of malicious remote monitoring and management (RMM) tools and information-stealing malware, leading to credential theft, extortion, and ransomware. There are always new variants to bypass security awareness defenses, such as the rise in email bombing to create a sense of stress and urgency to restore normalcy. In 2024, for instance, Storm-1811 impersonated tech support, claiming to be addressing junk email issues that it had initiated. They used RMM tools to deliver the ReedBed malware loader of ransomware payloads and remote command execution. Meanwhile, Midnight Blizard has successfully impersonated security and technical support teams to get targets to verify their identities under the pretext of protecting their accounts by entering authentication codes that complete the authentication flow for breaking into the accounts.  Similarly in May, Sophos identified a 3AM ransomware (believed to be a rebranding of BlackSuit) affiliate adopting techniques from Storm-1811, including flooding employees with unwanted emails followed by voice and video calls on Teams impersonating help desk personnel, claiming they needed remote access to stop the flood of junk emails. The threat actor reportedly spoofed the IT organization’s phone number.  With threat actors leveraging deepfakes, perceived authority helps make this kind of social engineering even more effective. Threat actors seeking to spoof automated workflow notifications and interactions can naturally extend to spoofing legitimate bots and agents as they gain more traction, as threat actors are turning to language models to facilitate their objectives.  Prevalent threat actors associated with ransomware campaigns, including the access broker tracked as Storm-1674 have used sophisticated red teaming tools, like TeamsPhisher, to distribute DarkGate malware and other malicious payloads over Teams. In December 2024, for example, Trend Micro reported an incident in which a threat actor impersonated a client during a Teams call to persuade a target to install AnyDesk. Remote access was reportedly then used also to deploy DarkGate. Threat actors may also just use Teams to gain initial access through drive-by-compromise activity to direct users to malicious websites.  Widely available admin tools, including AADInternals, could be leveraged to deliver malicious links and payloads directly into Teams. Teams branding (like any communications brand asset) makes for effective bait, and has been used by adversary-in-the-middle (AiTM) actors like Storm-00485. Threat actors could place malicious advertisements in search results for a spoofed app like Teams to misdirect users to a download site hosting credential-stealing malware. In July 2025, for instance, Malwarebytes reported observing a malvertising campaign delivering credential-stealing malware through a fake Microsoft Teams for Mac installer.  Whether it is a core app that is part of Teams, an app created by Microsoft, a partner app validated by Microsoft, or a custom app created by your own organization—no matter how secure an app—they could still be spoofed to gain a foothold in a network. And similar to leveraging a trusted brand like Teams, threat actors will also continue to try and take advantage of trusted relationships as well to gain Teams access, whether leveraging an account with access or abusing delegated administrator relationships to reach a target environment.  Persistence  Threat actors employ a variety of persistence techniques to maintain access to target systems—even after defenders attempt to regain control. These methods include abusing shortcuts in the Startup folder to execute malicious tools, or exploiting accessibility features like Sticky Keys (as seen in this ransomware case study). Threat actors could try to create guest users in target tenants or add their own credentials to a Teams account to maintain access.  Part of the reason device code phishing has been used to access target accounts is that it could enable persistent access for as long as the tokens remain valid. In February, Microsoft reported that Storm-2372 had been capturing authentication tokens by exploiting device code authentication flows, partially by masquerading as Microsoft Teams meeting invitations and initiating Teams chats to build rapport, so that when the targets were prompted to authenticate, they would use Storm-2372-generated device codes, enabling Storm-2372 to steal the authenticated sessions from the valid access tokens.  Teams phishing lures themselves can sometimes be a disguised attempt to help threat actors maintain persistence. For example, in July 2025, the financially motivated Storm-0324 most likely relied on TeamsPhisher to send Teams phishing lures to deliver a custom malware JSSloader for the ransomware operator Sangria Tempest to use as an access vector to maintain a foothold.  Execution  Apart from admin accounts, which are an attractive target because they come with elevated privileges, threat actors try and trick everyday Teams users into clicking links or opening files that lead to malicious code execution, just like through email.  Privilege escalation  If threat actors successfully compromise accounts or register actor-controlled devices, they often times try to change permission groups to escalate privileges. If a threat actor successfully compromises a Teams admin role, this could lead to abuse of the permissions to use the admin tools that belong to that role.  Credential access  With a valid refresh token, actors can impersonate users through Teams APIs. There is no shortage of administrator tools that can be maliciously repurposed, such as AADInternals, to intercept access to tokens with custom phishing flows. Tools like TeamFiltration could be leveraged just like for any other Microsoft 365 service for targeting Teams. If credentials are compromised through password spraying, threat actors use tools like this to request OAuth tokens for Teams and other services. Threat actors continue to try and bypass multifactor authentication (MFA) by repeatedly generating authentication prompts until someone accepts by mistake, and try to compromise MFA by adding alternate phone numbers or intercepting SMS-based codes.  For instance, the financially motivated threat actor Octo Tempest uses aggressive social engineering, including over Teams, to take control of MFA for privileged accounts. They consistently socially engineer help desk personnel, targeting federated identity providers using tools like AADInternals to federate existing domains, or spoof legitimate domains by adding and then federating new domains to forge tokens.  Discovery  To refine targeting, threat actors analyze Teams configuration data from API responses, enumerate Teams apps if they obtain unauthorized access, and search for valuable files and directories by leveraging toolkits for contextualizing potential attack paths. For instance, Void Blizzard has used AzureHound to enumerate a compromised organization’s Microsoft Entra ID configuration and gather details on users, roles, groups, applications, and devices. In a small number of compromises, the threat actor accessed Teams conversations and messages through the web client. AADInternals can also be used to discover Teams group structures and permissions.  The state-sponsored actor Peach Sandstorm has delivered malicious ZIP files through Teams, then used AD Explorer to take snapshots of on-premises Active Directory database and related files.  Lateral movement  A threat actor that manages to obtain Teams admin access (whether directly or indirectly by purchasing an admin account through a rogue online marketplace) could potentially leverage external communication settings and enable trust relationships between organizations to move laterally. In late 2024, in a campaign dubbed VEILdrive by Hunters’ Team AXON, the financially motivated cybercriminal threat actors Sangria Tempest and Storm-1674 used previously compromised accounts to impersonate IT personnel and convince a user in another organization through Teams to accept a chat request and grant access through a remote connection.  Collection  Threat actors often target Teams to try and collect information from it that could help them to accomplish their objectives, such as to discover collaboration channels or high-privileged accounts. They could try to mine Teams for any information perceived as useful in furtherance of their objectives, including pivoting from a compromised account to data accessible to that user from OneDrive or SharePoint. AADInternals can be used to collect sensitive chat data and user profiles. Post-compromise, GraphRunner can leverage the Microsoft Graph API to search all chats and channels and export Teams conversations.  Command and control  Threat actors attempt to deliver malware through file attachments in Teams chats or channels. A cracked version of Brute Ratel C4 (BRc4) includes features to establish C2 channels with platforms like Microsoft Teams by using their communications protocols to send and receive commands and data.  Post-compromise, threat actors can use red teaming tool ConvoC2 to send commands through Microsoft Teams messages using the Adaptive Card framework to embed data in hidden span tags and then exfiltrate using webhooks. But threat actors can also use legitimate remote access tools to try and establish interactive C2 through Teams.  Exfiltration  Threat actors may use Teams messages or shared links to direct data exfiltration to cloud storage under their control. Tools like TeamFiltration include an exfiltration module that rely on a valid access token to then extract recent contacts and download chats and files through OneDrive or SharePoint.  Impact  Threat actors try to use Teams messages to support financial theft through extortion, social engineering, or technical means.  Octo Tempest has used communication apps, including Teams to send taunting and threatening messages to organizations, defenders, and incident response teams as part of extortion and ransomware payment pressure tactics. After gaining control of MFA through social engineering password resets, they sign in to Teams to identify sensitive information supporting their financially motivated operations.  Mitigation and protection guidance  Strengthen identity protection  Enable sign-in and user risk policies in Microsoft Entra ID Protection. Enforce access controls based on sign-in risk. Users must be registered for Microsoft Entra multifactor authentication before sign-in risk policies can be triggered.  Configure just-in-time access to privileged roles. Use Microsoft Entra Privileged Identity Management (PIM) (preview) to provide as-needed and just-in-time access to Microsoft 365 roles to reduce standing privileges and limit exposure.  Harden endpoint security  Secure Teams clients and apps  Implementing some of these recommendations will require Teams Administrator permissions.  Protect sensitive data  Raise awareness  Configure detection and response  Microsoft Defender detections  Microsoft Defender XDR customers can refer to the list of applicable detections below. Microsoft Defender XDR coordinates detection, prevention, investigation, and response across endpoints, identities, email, apps to provide integrated protection against attacks like the threat discussed in this blog.  Customers with provisioned access can also use Microsoft Security Copilot in Microsoft Defender to investigate and respond to incidents, hunt for threats, and protect their organization with relevant threat intelligence.  Microsoft Defender XDR  The following alerts might indicate threat activity associated with this threat.  Malicious sign in from a risky IP address  Malicious sign in from an unusual user agent  Account compromised following a password-spray attack  Compromised user account identified in Password Spray activity  Successful authentication after password spray attack  Password Spray detected via suspicious Teams client (TeamFiltration)  Microsoft Entra ID Protection  Any type of sign-in and user risk detection might also indicate threat activity associated with this threat. An example is listed below. These alerts, however, can be triggered by unrelated threat activity.  Impossible travel  Anomalous Microsoft Teams login from web client  Microsoft Defender for Endpoint  The following alerts might indicate threat activity associated with this threat.  Suspicious module loaded using Microsoft Teams  The following alerts might also indicate threat activity associated with this threat. These alerts, however, can be triggered by unrelated threat activity and are not monitored in the status cards provided with this report.  Suspicious usage of remote management software  Microsoft Defender for Office 365  The following alerts might indicate threat activity associated with this threat.  Malicious link shared in Teams chat  User clicked a malicious link in Teams chat  When Microsoft Defender for Cloud Apps is enabled, the following alert might indicate threat activity associated with this threat.  Potentially Malicious IT Support Teams impersonation post mail bombing  The following alerts might also indicate threat activity associated with this threat. These alerts, however, can be triggered by unrelated threat activity and are not monitored in the status cards provided with this report.  A potentially malicious URL click was detected  Possible AiTM phishing attempt  Microsoft Defender for Identity  The following Microsoft Defender for Identity alerts can indicate associated threat activity:  Account enumeration reconnaissance  Suspicious additions to sensitive groups  Account Enumeration reconnaissance (LDAP)  Microsoft Defender for Cloud Apps  The following alerts might indicate threat activity associated with this threat.  Consent granted to application with Microsoft Teams permissions  Risky user installed a suspicious application in Microsoft Teams  Compromised account signed in to Microsoft Teams  Microsoft Teams chat initiated by a suspicious external user  Suspicious Teams access via Graph API  The following alerts might also indicate threat activity associated with this threat. These alerts, however, can be triggered by unrelated threat activity and are not monitored in the status cards provided with this report.  Possible mail exfiltration by app  Microsoft Security Copilot  Microsoft Security Copilot customers can use the Copilot in Defender embedded experience to check the impact of this report and get insights based on their environment’s highest exposure level in Threat analytics, Intel profiles, Intel Explorer and Intel projects pages of the Defender portal.  You can also use Copilot in Defender to speed up analysis of suspicious scripts and command lines by inspecting them below the incident graph on an incident page and in the timeline on the Device entity page without using external tools.  Threat intelligence reports  Microsoft customers can use the following reports in Microsoft products to get the most up-to-date information about the threat actor, malicious activity, and techniques discussed in this blog. These reports provide the intelligence, protection information, and recommended actions to prevent, mitigate, or respond to associated threats found in customer environments.  Microsoft Defender XDR threat analytics  Microsoft Security Copilot customers can also use the Microsoft Security Copilot integration in Microsoft Defender Threat Intelligence, either in the Security Copilot standalone portal or in the embedded experience in the Microsoft Defender portal to get more information about this threat actor.  Hunting queries  Microsoft Defender XDR  Advanced hunting allows you to view and query all the data sources available within the unified Microsoft Defender portal, which include Microsoft Defender XDR and various Microsoft security services.  After onboarding to the Microsoft Sentinel data lake, auxiliary log tables are no longer available in Microsoft Defender advanced hunting. Instead, you can access them through data lake exploration Kusto Query Language (KQL) queries in the Defender portal. For more information, see KQL queries in the Microsoft Sentinel data lake.  You can design and tweak custom detection rules using the advanced hunting queries and set them to run at regular intervals, generating alerts and taking response actions whenever there are matches. You can also link the generated alert to this report so that it appears in the Related incidents tab in threat analytics. Custom detection rule can automatically take actions on devices, files, users, or emails that are returned by the query. To make sure you’re creating detections that trigger true alerts, take time to review your existing custom detections by following the steps in Manage existing custom detection rules.  Detect potential data exfiltration from Teams  Detect mail bombing that sometimes precedes technical support scams on Microsoft Teams  Detect malicious Teams content from MessageEvents  Detect communication with external help desk/support representatives  Expand detection of communication with external help desk/support representatives by searching for linked process executions  Surface Teams threat activity using Microsoft Security Copilot  Microsoft Security Copilot in Microsoft Defender comes with a query assistant capability in advanced hunting. You can also run the following prompt in Microsoft Security Copilot pane in the Advanced hunting page or by reopening Copilot from the top of the query editor:  Microsoft Sentinel  Possible Teams phishing activity  This query specifically monitors Microsoft Teams for one-on-one chats involving impersonated users (e.g., 'Help Desk', 'Microsoft Security').  Files uploaded to Teams and access summary  This query identifies files uploaded to Microsoft Teams chat files and their access history, specifically mentioning operations from SharePoint. It allows tracking of potential file collection activity through Teams-related storage.  References  Learn more  For the latest security research from the Microsoft Threat Intelligence community, check out ff  To get notified about new publications and to join discussions on social media, follow us on LinkedIn, X (formerly Twitter), and Bluesky.  To hear stories and insights from the Microsoft Threat Intelligence community about the ever-evolving threat landscape, listen to the Microsoft Threat Intelligence podcast.
Shalett’s comments centered on several recent multibillion-dollar deals to scale up data-center infrastructure. As notable substacker and former Atlantic writer Derek Thompson recently noted in a post titled “ This is how the AI bubble will pop ,” so much money is being spent to support AI’s energy-consumption needs that it’s the equivalent of a new Apollo space mission every 10 months. (Tech companies are spending roughly $400 billion this year alone on data-center infrastructure, while the Apollo program allocated about $300 billion in today’s dollars to get to the moon from the 1960s to the ’70s.)  Shalett said she’s worried about a “Cisco moment” like when the dotcom bubble burst in 2000, referring to the company that was briefly the most valuable company in the world before an 80% stock plunge . When asked how close we are to such a moment, Shalett said probably not in the next nine months, but very possibly in the next 24. When you look at the actual spending and the amount of capital coming into the space, “we’re a lot closer to the seventh inning than the first or second inning,” she said.  In an interview with Fortune, Shalett said she was “very concerned” about this theme in markets, saying her office had broadened from a belief that the market would only bid up seven or 10 stocks to roughly 40. “At the end of the day … this is not going to be pretty” if and when the generative AI capital expenditure story falters, she said.  The commentary on September 29 by Morgan Stanley Wealth Management’s chief investment officer, Lisa Shalett , frames the current market boom as a “one-note narrative” almost entirely dependent on massive capital expenditures in generative AI, raising questions about its durability as economic and competitive risks start to mount. Shalett’s critique came squarely in the middle of some people in the AI field — and many financial commentators around Wall Street —fretting at market exuberance and beginning to talk openly about a bubble .  A top Wall Street analyst has sounded an alarm over the U.S. equity bull market, warning that its remarkable run is built on a precariously narrow foundation: a surge in spending on, and optimistic assumptions about, infrastructure for artificial intelligence (AI). This spending has fueled a boom in the shares of most of the so-called Magnificent 7 and a few dozen related businesses, which have now come to account for roughly 75% of the S&P 500’s returns since the rally of the last few years began.  Story Continues  What’s more than a little concerning to Shalett is that one company alone, Nvidia—the most valuable company in the history of the world, with an over $4.5 trillion market cap—is at the center of a significant number of these deals. In September alone, Nvidia invested $100 billion in OpenAI in a massive deal, just days after pledging $5 billion to Intel (the Intel agreement was tied to chips, not data-center infrastructure, per se).  Fortune‘s Jeremy Kahn reported in late September on significant concerns about “circular” financing, or Nvidia’s cash essentially being recycled throughout the AI industry. Shalett sees this as a major concern and a major sign that the business cycle is headed toward some kind of endgame. “The guy at the epicenter, Nvidia, is basically starting to do what all ultimate bad actors do in the final inning, which is extending financing, they’re buying their investors.”  Shalett expanded on her concerns by saying that companies around Nvidia “are starting to become interwoven.” She noted that OpenAI is partially owned by Microsoft, but now Nvidia has also made an investment in the startup, while Oracle and AMD each have their own purchasing agreements with OpenAI. But OpenAI also has a data-center deal with tech giant Oracle, with the “bad news,” Shalett notes, that this deal is “totally debt-financed.” OpenAI also struck a deal in October with chip-maker AMD that allows OpenAI to buy up to 10% of AMD. “Essentially, Nvidia’s main competitor is going to be partially owned by OpenAI, which is partially owned by Nvidia. So, Nvidia can ‘own’ a piece of its largest competitor. It is totally circular and increases systemic risk.”  When reached for comment, a spokesperson for Nvidia said, “We do not require any of the companies we invest in to use Nvidia technology.”  Nvidia CEO Jensen Huang discussed the OpenAI investment in an appearance on the Bg2 podcast with Brad Gerstner and Clark Tang on September 25, calling it an “opportunity to invest” and part of a partnership geared toward helping OpenAI build their own AI infrastructure. When asked about the allegation of circular financing in general and the Cisco precedent in particular, Huang talked about how OpenAI will fund the deal, arguing that it will have to be funded by OpenAI’s future revenues, or “offtake,” which he pointed out are “growing exponentially,” and by its future capital, whether it’s raised by a sale of equity or debt. That will depends on investors’ confidence in OpenAI, he said, and beyond that, it’s “their company, it’s not my business. And of course, we have to stay very close to them to make sure that we build in support of their continued growth.”  Shalett said that she and her team were “starting to watch” for signs of a bubble popping, highlighting the deal announced roughly a week before OpenAI struck its $100 billion data-center deal with Nvidia, when it struck another with Oracle worth $300 billion. Analysts at KeyBanc Capital Markets estimated that Oracle will have to borrow $100 billion of that amount—$25 billion a year for the next four years.  “Every morning the opening screen on my Bloomberg is what’s going on with CDS spreads on Oracle debt,” Shalett said, referring to credit default swaps, the financial instrument that was obscure before the Great Financial Crisis, but infamous for the role it played in a global market meltdown. CDSs essentially serve as insurance to investors in case of insolvency by a market entity. “If people start getting worried about Oracle’s ability to pay,” Shalett said, “that’s gonna be an early indication to us that people are getting nervous.” She added that all the indications to her speak of the end of a cycle and history is littered with cautionary tales from such times.  Oracle did not respond to requests for comment.  90% growth since the last bear market  Since the October 2022 bear market bottom and the launch of ChatGPT, according to Shalett’s calculations, the S&P 500 has soared 90%, but most of these gains have come from a small group of stocks. The so-called “Magnificent Seven”—including high-profile names like Nvidia and Microsoft—plus another 34 AI data-center ecosystem companies, are responsible for, as cited by Shalett and separately by JP Morgan Asset Management’s Michael Cembalest, about three-quarters of overall market returns, 80% of earnings growth, and a staggering 90% of capital spending growth in the index. Comparatively, the other 493 names in the S&P 500 are up just 25%—showing just how concentrated the rally has become.  The so-called “hyperscaler” companies alone are now spending close to $400 billion annually on capex supporting AI infrastructure, Morgan Stanley Wealth Management calculated. The economic influence of AI capex is now immense, contributing an estimated 100 basis points—fully one percentage point—to second-quarter GDP growth, according to Morgan Stanley’s research. This pace outstrips the rate of underlying consumer spending growth by tenfold, underscoring its centrality to both market performance and broader economic data.  “People conflate AI adoption, which is in the first inning, with the capex infrastructure buildout, which has been going full-out since 2022,” Shalett told Fortune. She cited concerns about the prominence of private equity and debt capital coming into play, as that “tends to produce bubbles, because it may be unspoken-for capacity.” In other words, people have money to burn and they’re throwing it at things that may not pay off.  Shalett waved away macro theories about the labor market or the Federal Reserve. “We think that’s missing the forest for the trees because the forest is entirely rooted in this one story” about AI infrastructure. Morgan Stanley’s bull-case mid-2026 price target for the S&P 500 is an eye-popping 7,200, but Shalett highlights that even the most optimistic outlook admits that risk premiums, credit spreads, and market volatility do not seem to fully account for the vulnerabilities lurking beneath the AI-fueled advance.  Shalett’s analysis suggests that AI capex maturity is approaching and some possible slowdowns are already visible. For instance, hyperscalers have already seen free-cash-flow growth turn negative, a sign that investment may have outpaced underlying technology returns. Strategas, an independent research firm, estimates that hyperscaler free cash flow is set to shrink by more than 16% over the next 12 months, putting pressure on lofty valuations and forcing investors to demand more discipline in how these funds are deployed.  Shalett was asked about data centers’ disproportionate impact on GDP throughout 2025, which media blogger Rusty Foster of Today in Tabs described as: “Our economy might just be three AI data centers in a trench coat.” The Morgan Stanley exec said “That’s what makes this cycle so fragile,” adding that at some point, “we’re not gonna be building any data centers for a while.” After that, it’s just a question of whether you crash: “Do you have a mild 1991-92-style recession or does it really become bad?”  A more bullish case  Bank of America Research weighed in on the semiconductors sector in a Friday note, writing that vendor financing in the space, especially Nvidia’s $100 billion commitment to OpenAI, has been “raising eyebrows.” Nevertheless, the team, led by senior analyst Vivek Arya, argued that the deal is structured by performance and competitive need, rather than pure speculative frenzy.  In an interview with Fortune, Arya explained why he wasn’t worried despite the “optics” being pretty obviously bad. “It’s very easy to say, ‘Oh, Nvidia is giving [OpenAI] money and they are buying chips with that money” and so on, but he argued the headlines are misleading about how much money is actually being spent and the $100 billion sticker price on the OpenAI deal “scared everyone.” Noting that the deal has multiple tranches that will play out over several years to come, he said it’s not like Nvidia is “just handing a $100 billion check to OpenAI [and saying] you know, go have fun.”  “Nvidia didn’t fund all of it,” Arya said of the wider generative AI capex boom. Citing public filings, Arya argued that Nvidia’s entire investment in the AI ecosystem is in fact less than $8 billion or so over the last 12 months, not such a large figure after all. And he’s still bullish on Nvidia and OpenAI, he added, because he sees them as the winners of this particular story. “We think they are going to be among the four or five ecosystems that come up. It’s not like Nvidia is going and investing in every one of those ecosystems, right? They’re only investing in one of those five, which is, of course, the most disruptive,” that being OpenAI.  When asked about his own fears of a bubble, Arya actually sounded a calmer but strikingly similar tune to Shalett. “I’m extremely comfortable with what will happen in the next 12 months,” Arya said, “And I have high sense of optimism about what will happen in the next five years. But can there be periods of digestion in between? Yeah.” Explaining that this is the nature of any infrastructure cycle, “it’s not always up and to the right.” In other words, after the next nine months in Shalett’s opinion and the next year in Arya’s, the data-center buildout endgame could be in play. “When these data centers are built,” Arya said, “they are not built for today’s demand. They’re built with some anticipation of demand that will develop in the next, you know, 12 to 18 months. So, are they going to be 100% utilized all the time? No.”  Rising worries about a bubble  Some of the biggest names in tech and Wall Street offered were hedging hard about the possibility of a bubble on Friday. Goldman Sachs CEO David Solomon and Jeff Bezos, both speaking at a tech conference in Turin, Italy, said they were seeing the same patterns as Shalett. Solomon said the massive amounts of spending weren’t fundamentally different from other booms and busts. “There will be a lot of capital that was deployed that didn’t deliver returns,” he said. That’s no different from how investment works. “We just don’t know how that will play out.”  Bezos characterized it as “kind of an industrial bubble,” arguing that the infrastructure would pay off for many years to come.  OpenAI CEO Sam Altman, who got markets jittery in late August when he mentioned the B-word, was asked again to comment on the subject while touring (what else?) a giant new data center in Texas. “Between the 10 years we’ve already been operating and the many decades ahead of us, there will be booms and busts,” Altman said. “People will overinvest and lose money, and underinvest and lose a lot of revenue.”  For his part, Cisco CEO John Chambers, one of the faces of the dotcom bubble, told the Associated Press on October 3 that he sees “a lot of tremendous optimism” about AI that is similar to the “irrational exuberance on a really large scale” that marked the internet age. It indicates a bubble to him, but only “a future bubble for certain companies. Is there going to be train wreck? Yes, for those that aren’t able to translate the technology into a sustainable competitive advantage, how are you going to generate revenue after all the money you poured into it?”  When asked whether the size of this potential bubble represents uncharted waters for the economy, especially considering the one-note nature of the long bull market, Shalett said Wall Streeters are always evaluating risk. But putting on her “American citizen hat,” she warned about the media consolidation that sees Oracle’s founder Larry Ellison also now playing a major role in TikTok (as part of a buying consortium of Trump-friendly billionaires) and Paramount in Hollywood and CBS News in New York (through his son, David Ellison, the media company’s new owner). Shalett said she’s worried about “groupthink” filtering into the functioning of markets. “That is not something that most of us have experienced in our lifetimes,” she said. “You stop factoring in risk premiums into markets, there is no bear case to anything.”  This story was originally featured on Fortune.com
The NucBox K7 Plus is another mini PC configuration that is entering an already crowded segment. Compared to the base version, this model comes with an Intel Core i7-13620H, which features 10 cores and Intel UHD Graphics. A dedicated graphics card is not included and not supported. If users need more GPU performance, the NucBox K7 Plus is probably not a good choice, and not just for that reason. The mini PC also lacks OCuLink or Thunderbolt 5 for connecting an external graphics card.  The manufacturer is selling the barebone version without RAM or an SSD for $339 at its official online store. For $599, buyers can opt for the NucBox K7 Plus with 32GB RAM and a 1TB SSD. That is not the maxed-out configuration, as the two DDR5 slots can accommodate up to 96GB of 4,800MHz memory. The compact desktop computer also offers two M.2 2280 SSD slots, but only the primary slot seems to offer faster transfer speeds.
Access to this page requires authorization. You can try changing directories .  Access to this page requires authorization. You can try signing in or changing directories .  Develop AI applications for Copilot+ PCs  Copilot+ PCs are a new class of Windows 11 hardware powered by a high-performance Neural Processing Unit (NPU) — a specialized computer chip for AI-intensive processes like real-time translations and image generation—that can perform more than 40 trillion operations per second (TOPS). Copilot+ PCs provide all–day battery life and access to the most advanced AI features and models.  Learn more:  The following Copilot+ PC Developer Guidance covers:  Device Prerequisites  What is the Arm-based Snapdragon Elite X+ chip?  Unique AI features supported by Copilot+ PCs with an NPU processor  How to access the NPU on a Copilot+ PC  How to use ONNX Runtime to programmatically access the NPU on a Copilot+ PC  How to measure performance of AI models running locally on the device NPU  Prerequisites  This guidance is specific to Copilot+ PCs.  Many of the new Windows AI features require an NPU with the ability to run at 40+ TOPS, including but not limited to:  Microsoft Surface Laptop Copilot+ PC  Microsoft Surface Pro Copilot + PC  HP OmniBook X 14  Dell Latitude 7455, XPS 13, and Inspiron 14  Acer Swift 14 AI  Lenovo Yoga Slim 7x and ThinkPad T14s  Samsung Galaxy Book4 Edge  ASUS Vivobook S 15 and ProArt PZ13  Copilot+ PCs with new AMD and Intel silicon, including AMD Ryzen AI 300 series and Intel Core Ultra 200V series.  Surface Copilot+ PCs for Business:  What is the Arm-based Snapdragon Elite X chip?  The new Snapdragon X Elite Arm-based chip built by Qualcomm emphasizes AI integration through its industry-leading Neural Processing Unit (NPU). This NPU is able to process large amounts of data in parallel, performing trillions of operations per second, using energy on AI tasks more efficiently than a CPU or GPU resulting in longer device battery life. The NPU works in alignment with the CPU and GPU. Windows 11 assigns processing tasks to the most appropriate place in order to deliver fast and efficient performance. The NPU enables on-device AI intelligent experiences with Enterprise-grade security for enhanced protection from chip to cloud.  Learn more about the Qualcomm Snapdragon X Elite.  Learn more about using and developing for Windows on Arm.  Unique AI features supported by Copilot+ PCs with an NPU  Copilot+ PCs offer unique AI experiences that ship with modern versions of Windows 11. These AI features, designed to run on the device NPU, ship in the latest releases of Windows and will be available via APIs in the Windows AI Foundry. Learn more about Windows Runtime Copilot APIs that are supported by models optimized to run (inference) on the NPU. These APIs will ship in an upcoming release of the Windows App SDK.  How to access the NPU on a Copilot+ PC  The Neural Processing Unit (NPU) is a new hardware resource. Like other hardware resources on a PC, the NPU needs software to be specifically programmed to take advantage of the benefits it offers. NPUs are designed specifically to execute the deep learning math operations that make up AI models.  The Windows 11 Copilot+ AI features mentioned above have been specifically designed to take advantage of the NPU. Users will get improved battery life and faster inference execution time for AI models that target the NPU. Windows 11 support for NPUs will include Arm-based Qualcomm devices, as well as Intel and AMD devices (coming soon).  For devices with NPUs, the Task Manager can now be used to view NPU resource usage.  The recommended way to inference (run AI tasks) on the device NPU is to use Windows ML.  How to programmatically access the NPU on a Copilot+ PC for AI acceleration  The recommended way to programmatically access the NPU (Neural Processing Unit) and GPU for AI acceleration has shifted from DirectML to Windows ML (WinML). This transition reflects a broader effort to simplify and optimize the developer experience for AI workloads on Windows devices. You can find updated guidance here: Learn how Windows Machine Learning (ML) helps your Windows apps run AI models locally..  Built-in EP discovery : Previously, developers were required to know which Execution Providers (EPs) were compatible with their hardware and bundle those EPs with their applications. This often led to larger application sizes and increased complexity in managing dependencies. With Windows ML, the process is now automated and streamlined. Windows ML automatically detects the available hardware on the device and downloads the appropriate EPs as needed. This means that developers no longer need to bundle specific EPs with their applications, resulting in smaller application sizes and reduced complexity.  Integrated EP delivery : The required EPs, such as Qualcomm’s QNNExecutionProvider or Intel’s OpenVINO EP, are now bundled with Windows or delivered via Windows Update, eliminating the need for manual downloads.  ORT under the hood : Windows ML still uses ONNX Runtime as its inference engine, but abstracts away the complexity of EP management. ONNX Runtime is an open source inference and training engine for AI models using the ONNX format and enabling developers to build AI applications that can run efficiently across a wide range of devices.  Collaboration with hardware vendors: Microsoft works directly with hardware vendors, such as Qualcomm and Intel, to ensure EP compatibility with early driver versions and new silicon (for example, Snapdragon X Elite, Intel Core Ultra, etc.).  When you deploy an AI model using Windows ML on a Copilot+ PC:  Windows ML queries the system for available hardware accelerators.  It selects the most performant EP (for example, QNN for Qualcomm NPUs, OpenVINO for Intel NPUs).  The EP is loaded automatically, and inference begins.  If the preferred EP fails or is unavailable, Windows ML gracefully falls back to another (for example, using the GPU or CPU).  This means developers can focus on building AI experiences without worrying about low-level hardware integration  Supported model formats  AI models are often trained and available in larger data formats, such as FP32. Many NPU devices, however, only support integer math in lower bit format, such as INT8, for increased performance and power efficiency. Therefore, AI models need to be converted (or "quantized") to run on the NPU. There are many models available that have already been converted into a ready-to-use format. You can also bring your own model (BYOM) to convert or optimize.  Qualcomm AI Hub (Compute) : Qualcomm provides AI models that have already been validated for use on Copilot+ PCs with Snapdragon X Elite with the available models specifically optimized to run efficiently on this NPU. Learn more: Accelerate model deployment with Qualcomm AI Hub | Microsoft Build 2024.  : Qualcomm provides AI models that have already been validated for use on Copilot+ PCs with Snapdragon X Elite with the available models specifically optimized to run efficiently on this NPU. Learn more: Accelerate model deployment with Qualcomm AI Hub | Microsoft Build 2024. ONNX Model Zoo: This open source repository offers a curated collection of pre-trained, state-of-the-art models in the ONNX format. These models are recommended for use with NPUs across all Copilot+ PCs, including Intel and AMD devices (coming soon).  For those who want to bring your own model, we recommend using the hardware-aware model optimization tool, Olive. Olive can help with model compression, optimization, and compilation to work with ONNX Runtime as an NPU performance optimization solution. Learn more: AI made easier: How the ONNX Runtime and Olive toolchain will help you Q&A | Build 2023.  How to measure performance of AI models running locally on the device NPU  To measure the performance of AI feature integration in your app and the associated AI model runtimes:  Record a trace : Recording device activity over a period of time is known as system tracing. System tracing produces a "trace" file that can be used to generate a report and help you identify how to be improve your app's performance. Learn more: Capture a system trace to analyze memory usage.  View NPU usage : Examine which processes are using the NPU and the callstacks submitting work.  View work and callstacks on the CPU : Examine the results of the pre-work feeding AI models and post-work processing AI models.  Load and Runtime : Examine the length of time to load an AI model and create an ONNX Runtime session.  Runtime parameters : Examine ONNX Runtime configuration and Execution Provider (EP) parameters that affect model runtime performance and optimization.  Individual inference times : Track per-inference times and sub-details from the NPU.  Profiler : Profile AI model operations to see how long each operator took to contribute to the total inference time.  NPU-specific: Examine NPU sub-details such as sub-HW metrics, memory bandwidth, and more.  To perform these measurements, we recommend the following diagnostic and tracing tools:  Note WPR UI (the user interface available to support the command-line based WPR included in Windows), WPA, and GPUView are all part of Windows Performance Toolkit (WPT), version May 2024+. To use the WPT, you will need to: Download the Windows ADK Toolkit.  For a quickstart on viewing ONNX Runtime events with the Windows Performance Analyzer (WPA), follow these steps:  Download ort.wprp and etw_provider.wprp. Open your command line and enter: wpr -start ort.wprp -start etw_provider.wprp -start NeuralProcessing -start CPU echo Repro the issue allowing ONNX to run wpr -stop onnx_NPU.etl -compress Combine the Windows Performance Recorder (WPR) profiles with other Built-in Recording Profiles such as CPU, Disk, etc. Download Windows Performance Analyzer (WPA) from the Microsoft Store. Open the onnx_NPU.etl file in WPA. Double-Click to open these graphs: "Neural Processing -> NPU Utilization  Generic Events for ONNX events  Additional performance measurement tools to consider using with the Microsoft Windows tools listed above, include:  Qualcomm Snapdragon Profiler (qprof): A GUI and system-wide performance profiling tool designed to visualize system performance, as well as identify optimization and application scaling improvement opportunities across Qualcomm SoC CPUs, GPUs, DSPs and other IP blocks. The Snapdragon Profiler allows viewing NPU sub-details, such as sub-HW metrics, memory bandwidth and more.  Additional Resources
Cesar Cadenas/ZDNET  Follow ZDNET: Add us as a preferred source on Google.  When we reviewed the Dell 14 Plus earlier this year, we praised its fantastic value, reliability, and solid build. Now, Dell has marked down the laptop's already low price to $649, staying competitive to the online retailer's Big Prime Deal Days event.  Also: Best Amazon Prime Day deals 2025: Our 90+ favorite sales this October  If you're looking for a high-performing 14-inch laptop with the latest hardware, Dell's 14 Plus is a great choice for students, professionals, or creatives. The best thing about this laptop is its versatility; with an Intel Core Ultra 7 or 9 processor, 16GB or 32GB of RAM, and a good selection of ports, this is a laptop that's suited to a variety of modern workloads.  Let's take a closer look at what we liked about it, and highlight what might not be for you.  As we mentioned, Dell's Plus new lineup includes laptops that are versatile and high-performing relative to cost, with some of the best consumer-facing hardware of the year. The Dell 14 Plus was released earlier in 2025 and is the successor to other similarly-priced laptops in Dell's midrange lineup like the Inspiron 14 Plus.  The laptop comes with one USB-A port, two USB-Cs (one of which is a Thunderbolt 4), an HDMI 2.1 port, and an audio jack. It also supports Wi-Fi 7, giving it top-tier connectivity, something you'll appreciate if you're a remote or hybrid worker.  Review: This Dell laptop is my top pick for both work and travel - especially at this price    The 64WHr battery performed about as expected in our testing, running for about 11 hours and 40 minutes under Best Power Efficiency before draining completely. In practical terms, this is a laptop that will likely last a full workday on one charge under normal load, but will see much better longevity in battery saver mode.  The Dell 14 Plus with Intel Core Ultra 7 256V processor, 16GB of RAM, and a 1TB SSD is the starting configuration for $649, but there are two additional models with 32GB of RAM and an Intel Core Ultra 9 288V processor -- one of the most high-performing on the market right now.  So let's consider the traits that might not be for everyone. First off, the display on the Dell 14 Plus is a 2.5K non-touchscreen IPS, maxing out at 300 nits of brightness. It's not a bad display, but it won't look as vibrant as some of the other flashy OLED screens out there. If you're just going to hook up your laptop to an external monitor anyway, this won't be of much concern.  Also: Best Amazon Prime Day laptop deals 2025: My 30 favorites sales live now  Secondly, the Dell 14 Plus is certainly portable, but compared to some of the razor-thin laptops on the market right now, its 3.4-pound weight places it on the chunkier end. Just keep in mind that it's a trade-off, and the Dell 14 Plus is going to have more powerful hardware (and run faster) than competing ultralight laptops.  Looking for the next best product? Get expert reviews and editor favorites with ZDNET Recommends.  How I rated this deal  We praised the Dell 14 Plus' bang-for-buck when it first released, so when we saw the sale price of $649, we jumped on board. This is a great price for a laptop in general, not to mention one with the latest hardware in 2025 from a solid, jack-of-all-trades lineup that we awarded our Editor's Choice to.  When will this deal expire? Deals are subject to sell out or expire anytime, though ZDNET remains committed to finding, sharing, and updating the best product deals for you to score the best savings. Our team of experts regularly checks in on the deals we share to ensure they are still live and obtainable. We're sorry if you've missed out on this deal, but don't fret -- we're constantly finding new chances to save and sharing them with you at ZDNET.com. Show more  How do we rate deals at ZDNET? We aim to deliver the most accurate advice to help you shop smarter. ZDNET offers 33 years of experience, 30 hands-on product reviewers, and 10,000 square feet of lab space to ensure we bring you the best of tech. In 2025, we refined our approach to deals, developing a measurable system for sharing savings with readers like you. Our editor's deal rating badges are affixed to most of our deal content, making it easy to interpret our expertise to help you make the best purchase decision. At the core of this approach is a percentage-off-based system to classify savings offered on top-tech products, combined with a sliding-scale system based on our team members' expertise and several factors like frequency, brand or product recognition, and more. The result? Hand-crafted deals chosen specifically for ZDNET readers like you, fully backed by our experts. Also: How we rate deals at ZDNET in 2025 Show more
The Trump administration is planning to become a shareholder in yet another company, continuing a trend that finds the Republican president embracing a socialist economic model, nationalizing otherwise independent businesses despite his party’s longstanding opposition to federal interference with “free enterprise.”  The White House recently announced plans to take a 10% stake in Canadian mining company Trilogy Metals. Forbes reported that the deal — and the surge in stock price that followed — produced a windfall for billionaire Trump donor John Paulson, who has a considerable stake in the company. The deal is a prime example of the kind of crony capitalism that such government investment can invite.  As stock news website Benzinga noted, the Trilogy Metals announcement brings the total number of companies in which the Trump administration has taken stake to five: Intel, mining company MP Materials, mining company Lithium Americas, and a “golden share” of U.S. Steel that grants the government veto power over many of the company’s decisions.  Under Barack Obama’s administration, the mere act of offering loans or other incentives to certain businesses frequently garnered outcry and anti-socialist condemnations from conservatives who said they were angry about the government unfairly choosing “winners and losers.” Now, one could argue Trump’s taking a page out of Fidel Castro’s book as his administration seeks to grow its portfolio of businesses under partial government influence. And indeed, many people —including some members of the president’s own party — have noted that the ownership stake his administration has taken is a “paradigm shift towards socialism,” in the words of conservative commentator Erick Erickson.  Americans would do well to keep this blatant socialism in mind the next time they hear conservatives trying to scare voters with stories of socialists intent on destroying the U.S. with things like government-funded grocery stores or free bus rides for local residents.
Save my User ID and Password  Some subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.  Note: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.
This article first appeared on GuruFocus.  Investors are rediscovering the power of political capital. Lithium Americas (NYSE:LAC) has surged 188% in just two weeks after the U.S. government, under President Donald Trump's directive, struck a deal to take a 5% equity stake in both the company and its Thacker Pass lithium project in Nevada. The agreement also includes a $435 million Department of Energy loan, with $182 million in debt servicing deferred for five years. The stock now trades over 40% above the average analyst price targetreflecting how Washington's renewed focus on securing domestic lithium supply has reignited speculative enthusiasm across the battery metals sector.  Scotiabank analyst Ben Isaacson was quick to temper the excitement, downgrading the stock to sector underperform and warning that the magic touch from Trump's involvement could prove dilutive to shareholders. Morningstar and Cormark Securities echoed the caution, arguing that valuations have run too far ahead of fundamentals. Jefferies analysts estimate that if future loan drawdowns carry similar concessions, equity dilution could reach 40% over the coming years. Still, the market's reaction suggests investors are betting on the administration's momentum rather than the mathbelieving the government's strategic backing could continue to drive upside, even as analysts urge patience.  Lithium Americas joins a growing list of companies boosted by Trump's direct intervention in critical U.S. industries. MP Materials (NYSE:MP) has surged more than 390% this year following a $400 million Defense Department investment, while Intel has gained over 50% since news surfaced of a near-10% federal stake. JPMorgan analysts note that more partnerships could emerge, with EVgo and Plug Power seen as potential candidates for similar Energy Department loan revisions. For now, the market seems to be pricing not just in the value of lithiumbut the value of proximity to the White House.
The hearing follows a tumultuous summer for the Department of Justice.  President Donald Trump's tightening grip over the Justice Department to target his political opponents and lawmakers' increasing calls for the release of more files from federal investigations into deceased sex offender Jeffrey Epstein took center stage at a contentious Senate hearing Tuesday for Attorney General Pam Bondi.  The hearing before the Senate Judiciary Committee is the first time since July that Bondi has faced questions from lawmakers and follows a tumultuous summer for the department that included deployments of federal law enforcement to Democratic-run cities, a growing number of investigations announced into Trump's political foes and the controversial indictment of former FBI Director James Comey.  Attorney General Pam Bondi arrives to testify before the Senate Judiciary Committee on Capitol Hill, October 7, 2025 in Washington. Win McNamee/Getty Images  Democratic, Republican leaders differ on hearing focus  Senate Judiciary Chairman Chuck Grassley kicked off the hearing with extensive remarks seeking to highlight instances of what Republicans have labeled "weaponization" of the Justice Department under the Biden Administration, citing selective disclosures by FBI Director Kash Patel of the investigation into President Trump's attempt to overturn his 2020 election loss.  "These are indefensible acts," Grassley said. "This was a political fishing expedition to get Trump at all costs."  Specifically, Grassley singled out a timely disclosure by the FBI on Monday that showed former Special Counsel Jack Smith's investigators at one point sought limited phone toll records of several Republican senators around the time of the Jan. 6 attack on the U.S. Capitol.  As part of his investigation, Smith extensively investigated Trump and his allies' pressure campaign on lawmakers to block the certification of former President Joe Biden's election win -- including calls that were made to senators after the Capitol was breached by the pro-Trump mob.  There's no indication that Republican senators were a target of Smith's investigation, and the toll records sought by investigators would not include any information about the content of conversations they may have had.  "We're pointing this all out because we can't have this repeated in the United States," Grassley said. "We want to end it right now, whether we have Republican or Democrat administrations."  Chairman of the Senate Judiciary Committee Senator Chuck Grassley and Ranking Member Senator Dick Durbin speak with each other, as they attend an oversight hearing of Attorney General Pam Bondi, Capitol Hill in Washington, Oct. 7, 2025. Kent Nishimura/Reuters  Grassley made no mention of recent directives from Trump to have the Justice Department act "now" to carry out prosecutions of his political foes, or other instances of alleged politicization during Bondi's tenure that have led to scores of departures of longtime career officials who have sounded alarm about the department being used as a tool to enact political retribution.  Ranking Democratic member Dick Durbin said in his opening statement assailed the Trump administration for the conduct in Chicago, a city in which Durbin represents.  "As President Trump turns the full force of the federal government on Chicago and other American cities, the assault on the city I am proud to represent is just one example of how President Trump and Attorney General Bondi shut down justice at the Department of Justice, even before the president's party controlling the white House, Senate and House of Representatives shut down the government," Durbin said.  "The attorney general has systematically weaponized our nation's leading law enforcement agency to protect President Trump and his allies and attack his opponents. And sadly, the American people. You have purged hundreds of senior career officials since you first appeared before us," he added.  Durbin listed various controversies for critics of Bondi's Justice Department, the closed investigation into Border Czar Tom Homan, the Eric Adams case being dropped, the hiring of a Jan. 6 defendant who attacked MPD officers, the handling of the Jeffrey Epstein files, and the case against James Comey.  "What has taken place since Jan. 20, 2025, would make even President Nixon recoil. This is your legacy," Durbin said.  Senators grill Bondi on closed Homan investigation  Sen. Mazie Hirono, D-Hawaii, also pressed Bondi on Tuesday over whether Bondi personally approved closing the investigation into Homan.  "Miss Bondi, did you approve closing the Homan investigation? Bribery investigation?" Hirono said.  "Senator Hirono, as I stated earlier, the Department of Justice and the FBI conducted a thorough review, and they found no credible evidence of any wrongdoing," Bondi responded.  Hirono then pressed Bondi over the department's removal of dozens of prosecutors who worked on investigations involving President Trump and the Jan. 6 attack on the Capitol.  Bondi shot back, "I'm not going to discuss personnel matters with you."  Hirono concluded her questioning by accusing Bondi of deliberately politicizing the department, turning it from the Department of Justice into the "Department of revenge and corruption."  In another heated exchanges at the hearing, Bondi reacted with outrage as she accused Sen. Peter Welch, D-Vt., of suggesting she was lying as she evaded questions about the investigation into Homan.  "First of all, is there a tape that has audio and video of the transfer the $50,000?" Welch asked.  "You would have to talk to Director Patel about that," Bondi replied.  "No, I'm talking to you," Welch said.  "I don't know the answer --" Bondi said before Welch interjected, "You do know the answer."  "Don't call me a liar!" Bondi shot back. "I didn't call you a liar," Welch responded.  Bondi pushes back against Democrats  Bondi pushed back against her critics and Democrats during the hearing. In her opening statement, she framed her tenure as the "end" of weaponization of law enforcement, while reinforcing her extensive efforts to enact President Trump's agenda.  "We will work to earn that back every single day. We are returning to our core mission of fighting real crime. While there is more work to do, I believe in eight short months we have made tremendous progress towards those ends," she said.  Attorney General Pam Bondi takes notes as she testifies during a Senate Judiciary Committee hearing on oversight of the Department of Justice, Capitol Hill in Washington, October 7, 2025. Brendan Smialowski/AFP via Getty Images  She also railed against judges who have ruled against the administration in the months since Trump took office, while highlighting the Justice Department's string of victories at the Supreme Court.  "My attorneys have done incredible work advancing President Trump's agenda and protecting the Executive Branch from judicial overreach," she said.  Bondi continued to hit back at Durbin, who questioned her about the federal deployment to Illinois.  The attorney general taunted the senator about Chicago's crime rate. Bondi said that Patel and Deputy Attorney General Todd Blanche were on their way to the city.  Attorney General Pam Bondi testifies before the Senate Judiciary Committee, Capitol Hill, October 7, 2025 in Washington. Jonathan Ernst/Reuters  "Chairman, as you shut down the government, you voted to shut down the government and you're sitting here as law enforcement officers aren't being paid. They're out there working to protect you. I wish you love Chicago as much as you hate President Trump," she said.  Durbin was taken aback by Bondi's responses.  "Madam attorney general, it's my job to grill you. Investigation of your agency is part of my responsibility. And this - this committee, you mean. I'd like the experience, but others have weathered the storm and answered questions in a respectful manner," he said.  Bondi in the hot seat over Epstein files  Bondi faced heavy scrutiny over conflicting statements out of the administration on the Epstein files, after the Justice Department and FBI said in a July letter that no further releases were warranted and that there was no evidence suggesting others participated or enabled Epstein's abuse of minor girls.  Democrats have accused the administration of seeking to cover up any mentions of Trump or high-profile appointees who had past associations with Epstein, which the administration has denied.  Trump and Epstein, who died by suicide in 2019 while awaiting trial on charges of trafficking young girls and women, were friends in the 1990s but the president said the relationship soured after Epstein poached some employees from Trump's Florida club after he explicitly warned him not to do so.  When asked on Fox News about the alleged Epstein client list, the attorney general told Fox News in February, "It's sitting on my desk right now to review."  She refused to elaborate about those past comments or the growing calls for the Epstein files while testifying.  Attorney General Pam Bondi testifies before the Senate Judiciary Committee, Capitol Hill, October 7, 2025 in Washington. Kent Nishimura/Reuters  Bondi responded to individual Democrats who sought more details by surfacing donations they allegedly may have received from Reid Hoffman -- an entrepreneur and founder of LinkedIn who is known to have past associations with Epstein.  She again surfaced Hoffman's alleged donations in an exchange with Sen. Sheldon Whitehouse, in which she again refused to answer his direct questions about the Epstein files.  Political targeting questioned  Trump has recently ordered the department to ramp up investigations into so-called "radical left" organizations that he and other senior White House officials have alleged, without providing evidence, as helping to fund perpetrators who have attacked federal law enforcement officials dispatched around the country.  Just days after Trump's comments, a senior official in the Justice Department ordered several U.S. Attorney's offices around the country to prepare to open sweeping criminal investigations in to the Open Society Foundations founded by billionaire George Soros, naming criminal statutes ranging from robbery, material support for terrorism and racketeering, ABC News previously confirmed.  In a statement, the Open Society Foundations called the accusations "politically motivated attacks on civil society, meant to silence speech the administration disagrees with and undermine the First Amendment right to free speech."  Bondi sought to brush off pointed questions from Democrats by repeatedly deflecting to crimes committed by undocumented immigrants in their states and districts that were among the briefing materials she brought with her to the hearings.  Attorney General Pam Bondi attends a oversight hearing of Senate Judiciary Committee on Capitol Hill in Washington, October 7, 2025. Jonathan Ernst/Reuters  She has also dismissed any characterization of the Justice Department appearing to work in lockstep with the White House as "politicization" of law enforcement. Bondi and other senior DOJ officials have instead argued that the two federal cases brought against Trump by a special counsel under the Biden Administration represented a far more egregious example of weaponization, echoing grievances leveled at the department by Trump.  DOJ under scrutiny amid growing controversies  As ABC News first reported, the move to seek Comey's indictment came over the objections of career prosecutors and followed Trump's removal of his appointee to lead the U.S. Attorney's Office for the Eastern District of Virginia, Erik Siebert, who expressed reservations about pursuing charges against Comey and New York Attorney General Letitia James, sources told ABC News.  Trump eventually installed a White House aide and former personal attorney Lindsey Halligan to lead the office and move forward with the case against Comey, and a grand jury narrowly voted to indict him on two counts of making false statements to Congress and obstructing a congressional investigation -- while declining to indict on a third false statements charge. Comey has denied wrongdoing and is set to appear Thursday in federal court for his arraignment.  Attorney General Pam Bondi listens as President Donald Trump signs a presidential memorandum on the death penalty in the District of Columbia in the Oval Office at the White House, Sept. 25, 2025, in Washington. Alex Brandon/AP  While sources told ABC News that leadership at the DOJ expressed reservations about pursuing the case, Bondi and FBI Director Kash Patel went on to publicly cheer news of Comey's indictment in news interviews and social media posts.  The next week, the administration moved to fire a top national security prosecutor in the office, Michael Ben'Ary, over a misleading social media post that falsely suggested he was among the prosecutors who resisted charging Comey.  Ben'Ary was leading a major case against one of the alleged plotters of the Abbey Gate bombing during the U.S. withdrawal from Afghanistan. In a scathing departure letter, Ben'Ary set his sights squarely on the Justice Department's leadership and labeled his removal as just one in a series of recent moves taken to root out career officials for political reasons at the expense of the nation's security.  Attorney General Pam Bondi testifies before the Senate Judiciary Committee, Capitol Hill, October 7, 2025 in Washington. Brendan Smialowski/AFP via Getty Images  "This example highlights the most troubling aspect of the current operations of the Department of Justice: the leadership is more concerned with punishing the President's perceived enemies than they are with protecting our national security," Ben'Ary wrote. "Justice for Americans killed and injured by our enemies should not be contingent on what someone in the Department of Justice sees in their social media feed that day."  The DOJ declined to comment when asked about Ben'Ary's letter.  Sen. Richard Blumenthal pressed Bondi repeatedly on Tuesday over instances of pressure on the department by Trump and what conversations she may have had with him in the days leading up to the indictment of Comey.  "I'd like to know from you what conversations you had with President Trump about the indictment of James Comey," Blumenthal said.  "Senator, I am not going to discuss any conversations I have or have not had with the President of the United States. You're an attorney, you have a law degree, and you know that I'm not going to do that," Bondi said on Tuesday.  Those actions have caused unprecedented turmoil at the Eastern District, which oversees some of the nation's most sensitive national security, terrorism and espionage investigations.  Current and former officials say that turmoil has reverberated further across the Justice Department's workforce around the country, with attorneys concerned they'll face professional repercussions if they resist taking part in politicized investigations or prosecutions.  On Monday, nearly 300 DOJ employees who left the department since Trump's inauguration released a letter on the eve of Bondi's hearing describing her leadership as "appalling" in its treatment of the career workforce and the elimination of longstanding norms of independence from the White House.  "We call on Congress to exercise its oversight responsibilities far more vigorously," the former employees said. "Members in both chambers and on both sides of the aisle must provide a meaningful check on the abuses we're witnessing. And we call on all Americans -- whose safety, prosperity, and rights depend on a strong DOJ -- to speak out against its destruction."  The DOJ declined to comment on the letter.



this summary from the following news articles:
"### Summary Report of Financial News (07/10/2025)\n\n### Summary Paragraph\nToday's financial landscape is dominated by the intensifying competition and rapid expansion within the AI semiconductor industry. Nvidia, despite launching new products like the MSI GeForce RTX 5070 Ti series and maintaining significant market dominance in AI GPUs with robust financials, is facing increased pressure. This is largely due to AMD securing a multi-billion dollar AI chip supply deal with OpenAI, directly challenging Nvidia's prior near-monopoly and boosting AMD's stock. This move by OpenAI, which also has an enabling relationship with Microsoft and substantial past investments from Nvidia, highlights a strategic diversification of its AI infrastructure suppliers. The broader market is characterized by massive, multi-hundred-billion-dollar investments in AI infrastructure by tech giants like Amazon, Meta, Microsoft, and Google, yet analysts express growing concerns about an \"AI bubble\" and a potential \"Cisco moment\" similar to the dot-com crash. Amidst this, Intel remains a relevant player, with its price target raised by UBS Group and ongoing speculation about potential strategic collaborations.\n\n### Key Insight\nHistorically, Nvidia maintained a near-monopolistic grip on the AI GPU market, notably through a massive $100 billion partnership with OpenAI, which simultaneously presented a risk due to high customer concentration and raised early AI bubble concerns. Today, this dynamic is fundamentally shifting as AMD has successfully forged a multi-billion dollar AI chip supply agreement with OpenAI, signaling OpenAI's strategic diversification and directly intensifying competition for Nvidia. This, coupled with Nvidia's continued innovation and strategic investments, underscores a rapidly evolving and highly competitive AI landscape. The future will likely compel Nvidia to accelerate diversification and R&D to maintain market share, while the entire sector faces the critical challenge of demonstrating long-term profitability from immense AI infrastructure investments to avert a potential \"Cisco moment.\" The actionable insight is that the AI hardware market is rapidly decentralizing, forcing major players to strategically adapt to a more competitive and potentially volatile growth trajectory.\n\n### Key Implications\n*   **Key Relationships (from `graph_retriever` and `Analysis_Worker_Agent`):\n**    *   (Nvidia) --[invests ($100 billion, 2025-10-02)]--> (OpenAI)\n    *   (Nvidia) --[provides (10 gigawatts compute capacity access, 2025-10-02)]--> (OpenAI)\n    *   (Nvidia) --[supplies (AI hardware, 2025-09-30)]--> (OpenAI)\n    *   (OpenAI) --[depends (for GPUs, 2025-10-06)]--> (Nvidia)\n    *   (Microsoft) --[enables (None, 2025-09-30)]--> (Nvidia)\n    *   (Nvidia) --[invests ($5 billion, 2025-09-30)]--> (Google)\n    *   (AMD) --[secures (AI chip-supply deal, tens of billions)]--> (OpenAI)\n\n*   **Risks and Opportunities (derived from `Analysis_Worker_Agent`):\n**    *   **Risk:** Intensified competition from AMD's significant AI chip deal with OpenAI threatens to erode Nvidia's market share and future revenue predictability from key customers.\n    *   **Risk:** Persistent and growing concerns among analysts regarding an \"AI bubble\" suggest potential market overvaluation and risk of a significant correction in AI-related stocks.\n    *   **Risk:** Nvidia faces the challenge of high customer concentration, despite major clients like OpenAI diversifying their supplier base.\n    *   **Opportunity:** Nvidia's continuous innovation (e.g., Blackwell chips, H200), robust CUDA ecosystem, and diverse product portfolio position it for sustained growth within the expanding AI applications market.\n    *   **Opportunity:** AMD's strategic alliance with OpenAI significantly validates its AI chip capabilities, boosting its market presence and investor confidence.\n\n*   **Notable Market and Competitor Events (from `enhanced_search_agent`):\n**    *   Nvidia CEO Jensen Huang remains confident in sustained investment in AI infrastructure, even during a potential recession, indicating a strong long-term market belief.\n    *   OpenAI is actively diversifying its AI hardware suppliers, evidenced by significant deals with both Nvidia and AMD, without altering existing partnerships like Microsoft.\n    *   Major tech companies (Amazon, Meta, Microsoft, and Google) are collectively committing hundreds of billions of dollars ($320 billion) to AI infrastructure, highlighting a massive industry-wide bet, though questions persist about the immediate return on these investments.\n    *   Intel is maintaining its strategic position in the chip market, with a raised price target from UBS Group and potential for collaborations in the evolving competitive landscape."

**Instructions:**
For each criterion, provide a score from 0.0 (very poor) to 1.0 (excellent) and a brief justification. 

- Clarity – Is the response clearly written and easy to understand?
- Relevance – Does the response stay on topic and directly address the input or question?
- Depth of Analysis – Does the response demonstrate thoughtful reasoning, insight, or understanding beyond surface-level information?
- Actionable Output – Does the response provide useful, applicable, or implementable information or recommendations?

**Final JSON Output Format** 
After completing your evaluation, structure your entire response into the following nested JSON format. Provide a score and a brief reasoning for each metric as determined in the steps above.

{
  "clarity": {
    "score": <float_from_0.0_to_1.0>,
    "reasoning": "<brief justification for clarity>"
  },
  "relevance": {
    "score": <float_from_0.0_to_1.0>,
    "reasoning": "<brief justification for relevance>"
  },
  "depth_of_analysis": {
    "score": <float_from_0.0_to_1.0>,
    "reasoning": "<brief justification for depth of analysis>"
  },
  "actionable_output": {
    "score": <float_from_0.0_to_1.0>,
    "reasoning": "<brief justification for actionable output>"
  }
}
