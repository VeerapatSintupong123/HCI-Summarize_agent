{
  "Nvidia": [
    {
      "headline": "Nvidia is the world's most valuable company. Why does CEO Jensen Huang barely make the list of the 10 wealthiest people?",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nThe list of the world's wealthiest people mostly comprises the biggest shareholders of the largest companies on the planet. So why does the cofounder and CEO of the world's most valuable company rank just 10th?\n\nAs of Monday's close, Nvidia's Jensen Huang had a net worth of $147 billion, per the Bloomberg Billionaires Index.\n\nThat puts him just behind Warren Buffett, who has a $148 billion fortune, even though Buffett's Berkshire Hathaway is worth about a quarter as much as Nvidia, and Buffett has gifted more than half of his Berkshire stock to foundations since 2006.\n\nBernard Arnault ranks eighth with a $164 billion fortune, despite LVMH being worth under $300 billion, or less than a 10th of Nvidia.\n\nElon Musk, the world's wealthiest person, has an estimated net worth of $383 billion and could extend his lead if his proposed $1 trillion pay package is approved. That's striking as the two companies that make up the lion's share of Musk's wealth, Tesla and SpaceX, are together valued around $1.6 trillion — less than 40% of Nvidia's market value.\n\nDilution of shares\n\nThere's one reason Huang, who cofounded Nvidia in 1993 and has been the chipmaker's CEO ever since, isn't richer: dilution.\n\nAhead of Nvidia's IPO in 1999, Huang owned 12.8% of the company. That stake would be worth over $500 billion today.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nWhile it's typical for founders to sell shares and see their ownership diluted when their companies go public, Huang has seen a far more significant and prolonged decline in his stake. It fell to 9.9% in 1999, 7.1% in 2003, 4.4% in 2010, then stabilized between 3.5% and 4% from 2020 through this summer, filings show.\n\nFor comparison, Buffett owns about 14% of Berkshire, Arnault owns roughly half of LVMH, and Musk owns around 13% of Tesla and 42% of SpaceX.\n\nHuang's percentage ownership has dropped by more than two-thirds primarily because Nvidia has issued vast amounts of shares to provide equity for its employees. The company reported a hefty $14 billion of unearned stock-based compensation as of July 27, much of which it expected to recognize in around two years' time.\n\nNvidia has offset some of the dilution through stock buybacks, but its outstanding shares have surged from a split-adjusted 1.7 billion when it went public, to north of 23 billion now — a roughly 14-fold increase.\n\nMany companies, especially in the tech space, award employees with stock or stock options to incentivize them to increase the value of the company and its stock, while discouraging them from decamping to rivals. It's a way to attract and retain talent without spending cash.\n\nHuang's stake has also shrunk because he's sold shares, including a prearranged trading plan to dispose of up to 6 million shares this year, worth about $1 billion at Nvidia's current stock price.\n\nThe rich list changes as companies' market caps fluctuate, but Huang's smaller stake means he's unlikely to top it anytime soon.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/nvidia-stock-jensen-huang-wealth-musk-buffett-ai-tech-compensation-2025-9",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Europe's answer to OpenAI just got a $1.5 billion boost from chip giant ASML",
      "content": "lighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nHave an account? Log in .\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nFrench AI startup Mistral has secured a massive investment from Dutch chip company ASML.\n\nMistral, which is seen as Europe's answer to OpenAI, received a 1.3 billion euros, or $1.5 billion, investment from ASML as part of a wider $2 billion funding round, the companies said Tuesday.\n\nASML, which has a market capitalization of $308 billion, has taken a roughly 11% stake in Mistral, making it the startup's largest shareholder. The Dutch company sells specialized machinery essential for chip manufacturing,\n\nThe funding roughly doubles Mistral's post-money valuation to nearly $13.8 billion, cementing its place as Europe's most valuable AI startup.\n\nMistral's funding is dwarfed by that of OpenAI, which has raised close to $60 billion in total.\n\nMistral has developed large language models that are open weights, meaning anyone can see or use information determining how the model works after it's been trained — but not the full source code.\n\nASML's president and CEO, Christophe Fouquet, said the company would use Mistral's AI technology in its own supply chains and for R&D.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nArthur Mensch, the cofounder and CEO of Mistral, said it would help ASML \"solve current and future engineering challenges through AI.\"\n\nOther investors in the Series C round included DST Global, Andreessen Horowitz, and Nvidia, which have all previously invested in Mistral.\n\nUnlike Nvidia, which makes a large number of investments in startups, ASML is more selective. The Dutch company has invested in venture funds like the DeepTechXL fund, but its last public direct investment in a startup was Smart Photonics in 2023.\n\nIt's also the latest example of a synergy between Mistral and one of its investors from the semiconductor world.\n\nIn June, Nvidia announced a partnership with Mistral to provide Nvidia chips for the startup's homegrown AI infrastructure platform.\n\nCEO Jensen Huang took to the stage with Mensch to talk up \"AI sovereignty,\" the idea of a country using its own AI infrastructure, such as hardware and data, within its own borders.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/mistral-funding-asml-chips-ai-europe-2025-9",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nebius Shares Surge on $17.4 Billion AI Infrastructure Deal With Microsoft",
      "content": "This article first appeared on GuruFocus.\n\nNvidia (NVDA)-backed Nebius Group (NASDAQ:NBIS) said Monday it reached a $17.4 billion agreement to provide Microsoft (NASDAQ:MSFT) with GPU infrastructure capacity, sending its shares up more than 47% in after-hours trading.\n\nThe five-year contract, which could increase to $19.4 billion if Microsoft opts for additional services, underscores rising demand for high-performance computing to support artificial intelligence development.\n\nNebius, which provides Nvidia-based GPUs and AI cloud services, will supply Microsoft from a new data center in Vineland, New Jersey, beginning later this year. The company said the partnership will accelerate growth of its AI cloud business into 2026 and beyond.\n\nMicrosoft has also been expanding partnerships with other GPU providers, including CoreWeave, one of Nebius' rivals.\n\nAmsterdam-based Nebius was formed out of a restructuring of Russian technology firm Yandex.\n\nInvestors will watch for updates on the rollout of the Vineland data center and the pace of AI cloud adoption in the coming quarters.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nebius-shares-surge-17-4-145136091.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "US Tech Companies Enabled the Surveillance and Detention of Hundreds of Thousands in China",
      "content": "An Associated Press investigation based on tens of thousands of leaked documents revealed Tuesday that American technology companies designed and built core components of China's surveillance apparatus over the past 25 years, selling billions of dollars in equipment to Chinese police and government agencies despite warnings about human rights abuses.IBM partnered with Chinese defense contractor Huadi in 2009 to develop predictive policing systems for the \"Golden Shield\" project, AP reports, citing classified government blueprints. The technology enabled mass detentions in Xinjiang, where administrators assigned 100-point risk scores to Uyghurs with deductions for growing beards or being aged 15-55. Dell promoted a laptop with \"all-race recognition\" capabilities on its WeChat account in 2019. Thermo Fisher Scientific marketed DNA kits as \"designed\" for ethnic minorities including Uyghurs and Tibetans until August 2024.Oracle, Microsoft, HP, Cisco, Intel, NVIDIA, and VMware sold geographic mapping software, facial recognition systems, and cloud infrastructure to Chinese police through the 2010s. The surveillance network tracks \"key persons\" whose movements are restricted and monitored, with one estimate suggesting 55,000 to 110,000 people were placed under residential surveillance in the past decade. China now has more surveillance cameras than the rest of the world combined.",
      "source": "Slashdot.org",
      "url": "https://news.slashdot.org/story/25/09/09/1124247/us-tech-companies-enabled-the-surveillance-and-detention-of-hundreds-of-thousands-in-china",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Hardware vs. IP: How to trade the gaming industry",
      "content": "00:00 Speaker A\n\nI want to shift gears to a discussion of hardware versus intellectual property. And just thinking about over the next 12 months, if you had to pick one bucket, and one of those could be chips and hardware with maybe Nvidia, Microsoft, Sony consoles, and then you have content and IP on the other, with Take two and Roblox and we'll get to the game, we'll get to, um, Grand Theft in a second. Where do you see that heading over the next year?\n\n00:32 Speaker B\n\nI mean, the hardware side's hard to play. Um, Nvidia obviously is a phenomenal company, but you know, a very small percentage, I think less than 5% of their revenue comes from gaming. So it might be 10, but it's really small. I think it's four or five billion a quarter out of 45 billion. So, you know, they're they're great, um, but they're not going to really grow that very much. They used to be more like 50% gaming for PC graphic processors. Um now it's all AI. So I love Nvidia, uh, but it's really not a gaming play. Nintendo is the pure play. Sony is not quite pure play because of studios and other things. But Nintendo is a pure play, uh hardware manufacturer that also happens to have a lot of great software. Um, and and you can participate there. The stock's at an all-time high. So, you know, it's fine. I think that there're probably some upside there. But I much, much prefer to play in the software side. Uh intellectual property is inexpensive to reproduce again and again and again, very high margin. So you want to play the guys that have the content or the guys that have the technology and that would include Unity and AppLovin.\n\n02:08 Speaker A\n\nAll right, let's stick with content and IP, talk about Grand Theft Auto 6. Uh, it's been a dozen years since five came out and I'm wondering what the expectations are and then the pricing point especially. I believe you've said it could reach triple digits.\n\n02:30 Speaker B\n\nYeah, I'm I'm pretty confident it will be $100. Um and you know, it's funny because I'm basing my guess on what the CEO Strauss Zelnick has said, which is that they're going to charge what they believe that the game is worth and consumers will feel that they got a value for what they're paying. No no no point in making that comment if you're going to charge 60 or 70 bucks. So just the idea that he's addressed price tells me it's going to start at 100, and I don't think gamers are going to even flinch. Um, this game is going to be probably twice as big as the last one. Uh as you pointed out, 12 years in development, it'll come out, uh just shy of the 13th anniversary of the last release. They have 1,200 people working on it, which means they're spending way north of 100 million per year on development cost. So they've got a billion, billion five invested in the game. Why not charge 100 bucks? And and the truth is, gamers are an entitled bunch of whiny little babies, but but the truth, you know, they they can wait a year if they don't want to pay 100 bucks. They can buy it at 70 next year. And I think Take two will charge 100. I think they will sell 30 or 40 or 50 million units at 100 bucks and that incremental $30 is virtually all profit. So if they can make an extra two or three billion dollars, why not?",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/hardware-vs-ip-trade-gaming-183000002.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AI expert says it’s ‘not a question’ that AI will take over all jobs—but people will have 80 hours a week of free time",
      "content": "While many CEOs are pausing hiring while they wait and see what jobs AI could replace, one AI expert warns that nearly all roles are at risk. Professor of computer science Dr. Roman Yampolskiy predicts that 99% of work will be placed by AI and humanoid robots in the next five years, and there will be no “plan B” in retraining for a new job. On the plus side, however, he predicts that humans will have 60 to 80 hours freed up per week, thanks to not having to work.\n\nIt’s only been three years since OpenAI released ChatGPT into the world, and companies are already shaving down their workforces to make way for AI automation. This has left many employees clinging to their jobs for dear life—but according to Dr. Roman Yampolskiy, a professor of computer science and leading voice in AI safety, no worker is safe.\n\nDespite cab drivers and even teachers like himself saying they’re irreplaceable, he said it’s inevitable that the technology will take over.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\n“That is not even a question if it’s possible,” Yampolskiy recently said on The Diary of a CEO podcast when discussing jobs being automated by AI. “It’s like, how soon before you [are] fired?”\n\nThe computer science professor has joined the cohort of tech leaders—including Anthropic CEO Dario Amodei and Silicon Valley investor Vinod Khosla—raising the alarm bells that AI will trigger a jobs armageddon.\n\nBut while Amodei thinks that AI could swipe half of white-collar roles in the next five years, spiking unemployment up to 20%, Yampolskiy said that joblessness could reach as high as 99% in that same time frame. And contrary to popular belief, he thinks that workers won’t simply funnel into new roles that haven’t been disrupted or invented by AI yet.\n\n“Before we always said, ‘This job is going to be automated, retrain to do this other job,’” the AI expert said. “But if I’m telling you that all jobs will be automated, then there is no plan B. You cannot retrain.”\n\nThere will be record levels of unemployment—but he says humans will have 60 hours of freed time\n\nThe engineering professor is steadfast that nearly all jobs will be taken over by AI—even most of the ones that have a special human touch, like teachers and car drivers.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAnd the career paths that once guaranteed six-figure salaries are also on the way out; he pointed out the very popular computer science track, which he currently teaches at the University of Louisville, and has since been upended by AI.\n\n“Look at computer science. Two years ago, we told people ‘Learn to code—you are an artist, you cannot make money. Learn to code.’ Then we realized, ‘Oh, AI kind of knows how to code and [is] getting better. Become a prompt engineer. You can engineer prompts for AI. It’s going to be a great job. Get a four-year degree in it,’” Yampolskiy said on the podcast. “But then we’re like, ‘AI is way better at designing prompts for other AIs than any human.’ So that’s gone.”\n\nAs more jobs get replaced by AI, and roles that are created from this change also get automated, it’s an endless domino effect of unemployment. Yampolskiy warned joblessness will hit an all-time high in the next five years as all human work, including manual labor, is replaced by humanoid robots and AI agents.\n\n“We’re looking at a world where we have levels of unemployment we [have] never seen before,” he revealed. “[I’m] not talking about 10% unemployment, which is scary, but 99%. All you have left is jobs where, for whatever reason, you prefer another human would do it for you. But anything else can be fully automated.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nWhile that sounds like a dark reality for most workers, Yampolskiy doesn’t seem phased by the inevitable. In fact, he sees an upside in this huge workforce shift—just like other tech leaders, he says massive jobs automation will lead to shorter workweeks.\n\nHe echoes the likes of former Microsoft CEO Bill Gates—who said that we’ll clock in just two days a week in the next ten years—and Nvidia chief executive Jensen Huang who predicts a four-day workweek. But Yampolskiy optimistically believes work will be scrapped entirely, leaving humans with the question of how they’ll spend their free time.\n\n“I don’t think there is a, ‘This occupation needs to learn to do this instead.’ I think it’s more like, ‘We as a humanity, then we all lose our jobs. What do we do? What do we do financially? Who’s paying for us? And what do we do in terms of meaning? What do I do with my extra 60, 80 hours a week?’”\n\nYampolskiy isn’t positive where that money is going to come from, but other tech leaders, like Elon Musk, suggest that the technology will create the need for a “universal high income”—where people have access to all the money they need to survive without having a job. Though he isn’t explicit on how much each person would need every year.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\n“There will be no shortage of goods and services. It will be an age of abundance,” Musk told former U.K. Prime Minister Rishi Sunak in 2023. “We won’t have universal basic income. We’ll have universal high income…In some sense, it’ll be somewhat of a leveler, an equalizer.”\n\nThis story was originally featured on Fortune.com",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/ai-expert-says-not-ai-145521588.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia Announces Rubin CPX GPU To Speed Long-Context AI",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/karlfreund/2025/09/09/nvidia-announces-rubin-cpx-gpu-to-speed-long-context-ai/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "NVIDIA (NVDA) Remains a Franchise Pick as Jefferies Reiterates Buy",
      "content": "NVIDIA Corporation (NASDAQ:NVDA) is one of the Buzzing AI Stocks on Wall Street. One of the biggest analyst calls on Friday, September 5, was for Nvidia Corporation. Jefferies reiterated the stock as “Buy,” stating that the stock remains on the franchise picks list.\n\n“The rapid proliferation of AI demand continues with leaders from across the industry offering commentary indicating significant compute supply shortages. Given NVDA’s position as the dominant supplier of AI accelerators within AI data centers, we remain bullish on shares.”\n\nNVIDIA Corporation (NASDAQ:NVDA) specializes in AI-driven solutions, offering platforms for data centers, self-driving cars, robotics, and cloud services.\n\nWhile we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 10 AI Stocks to Watch Out For in 2025 and 10 AI Stocks Gaining Attention on Wall Street.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-nvda-remains-franchise-pick-190205857.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Analyst Slashes Nvidia Price Target By 5%, Citing Intensifying AI Chip Rivalry From Broadcom And Google",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/cc2ab47e4c4f73c3",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Analyst surprisingly cuts Nvidia stock target amid a growing threat",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/investing/analyst-surprisingly-cuts-nvidia-stock-target-amid-a-growing-threat",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "UAE Lab Releases Open-Source Model to Rival China’s DeepSeek",
      "content": "The United Arab Emirates wants to compete with the U.S. and China in AI, and a new open source model may be its strongest contender yet.\n\nAn Emirati AI lab called the Institute of Foundation Models released K2 Think on Tuesday, a model that researchers say rivals OpenAI’s ChatGPT and China’s DeepSeek in standard benchmark tests.\n\n“With just 32 billion parameters, it outperforms flagship reasoning models that are 20x larger,” the lab wrote in a press release on Tuesday. DeepSeek’s R1 has 671 billion parameters, though only 37 billion are active. Meta’s latest Llama 4 models range from 17 billion to 288 billion active parameters. OpenAI doesn’t share parameter information.\n\nResearchers also claim that K2 Think leads “all open-source models in math performance” across several benchmarks. The model is intended to be more focused on math, coding, and scientific research than most other AI chatbots.\n\nThe Emirati lab’s selling point for the model is similar to DeepSeek’s strategy that disrupted the AI market earlier this year: optimized efficiency that will have better or the same computing power at a lower cost.\n\n“By proving that smaller, more resourceful models can rival the largest reasoning systems, this milestone marks the beginning of the next wave of AI innovation,” Peng Xiao, council member of Abu Dhabi’s AI and Advanced Technology Council, said in the press release.\n\nXiao is also the CEO of G42, an Emirati AI development company that co-launched the K2 Think model. The company last made headlines for inking a multibillion-dollar data center deal with the Trump administration earlier this year, which has since been mired in national security concerns.\n\nThe lab is also aiming to be transparent in everything, “open-sourcing not just models but entire development processes” that provide “researchers with complete materials including training code, datasets, and model checkpoints,” IFM said in a press release from May.\n\nThe long-term plan is to incorporate K2 Think into a full LLM in the coming months, WIRED reported.\n\nBooming Emirati investment in AI\n\nThe Emiratis are serious about AI. The country counted 672 new AI companies between June 2023 and June 2024, making it the fastest-growing AI cluster in the Middle East and North Africa region.\n\nThe lab behind K2 Think was established by the Mohamed bin Zayed University of Artificial Intelligence, which has its headquarters in Abu Dhabi and two research hubs in Silicon Valley and Paris. It was founded a couple of years ago as part of the Emirati government’s AI overhaul strategy, called Artificial Intelligence 2031. The university’s president is Chinese-born American researcher Dr. Eric Xing.\n\nThe Emirati AI overhaul has also benefited American companies. Abu Dhabi state AI fund MGX, chaired by the UAE’s national security adviser, is a founding partner of Trump’s Project Stargate, and the fund has previously invested in OpenAI.\n\nTrump also announced in May that Abu Dhabi and Washington were partnering to create the largest AI data center cluster outside of the U.S., built and operated by G42 —the company that co-launched K2 Think on Tuesday— and with the help of Nvidia, OpenAI, Cisco, Oracle, and Japanese firm Softbank.\n\nBut that deal has faced U.S. regulator scrutiny over security concerns, particularly regarding the UAE’s relationship with China. Chinese tech and AI firms like Huawei and Alibaba have been expanding their influence in the UAE and the Middle East at large.\n\nG42 specifically had several Chinese investments, which the company reportedly got rid of after pressure from the Biden administration over a $1.5 billion strategic investment by Microsoft.\n\nAI is the new oil in the Middle East\n\nThe Emirates’ growing bet on AI is driven by a desire to diversify investments and reduce its economic dependence on fossil fuels like oil and gas.\n\nThe trend is seen in the rest of the Arab world as well, particularly in the oil-rich Gulf states. Saudi Arabia created a $100 billion AI investment fund last year as part of an effort to diversify its oil-reliant economy by 2030.\n\nSaudi Arabian DataVolt is moving forward with plans to invest $20 billion in AI data centers and energy infrastructure in the United States.\n\nElsewhere in the Gulf, Qatar Investment Authority was a significant investor in American AI company Anthropic in a $13 billion funding round last week.\n\nMore countries seek to challenge U.S. and Chinese dominance in AI\n\nA growing list of countries is seeking to join the battle for global AI dominance that’s currently dominated by American and Chinese companies.\n\nIn the rest of Asia, Singapore is a rising power, with AI-friendly regulatory oversight that has spurred the launch of AI innovation hubs from tech giants like Microsoft.\n\nIn Europe, the French are making major AI plays. The French AI startup Mistral just secured a $1.5 billion investment by Dutch semiconductor maker ASML on Tuesday. Mistral is considered a major competitor to OpenAI in Europe.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/uae-lab-releases-open-source-model-to-rival-chinas-deepseek-2000656197",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Forget the September slump: Why this market continues to rally",
      "content": "0:05 spk_0\n\nWelcome to Stocks and Translation, Yahoo Finance's video podcast that cuts through the market mayhem, the noisy numbers, and the hyperbole to give you the information you need to make the right trade for your portfolio. I'm Jared Blickery, your host, and with me is Yahoo Finance's Allie Cannell, who's here to keep the discussion simple, accessible, and also lively. Today we're gonna be talking about theCooling labor market. If the Fed is once again too slow to cut rates and how to square that with a stock market that keeps hitting record highs. Our phrase of the day is the September effect. History says we're in the worst month of the year right now, and the weakness tends to come in the back half of the month. So how much do investors really need to care about history rhyming?And this episode is brought to you by the number 9.7. That's how many percentage points of pure profit you would have missed out on, had you panic sold after Liberation Day and missed the single best day of the year, how to make an investing plan that keeps you cool and calm when the headlines, they get scary.And today we're welcoming back Phil Rosen, co-founder of the Opening Bell Daily. He recently left Business Insider to build his independent data-driven markets outlet along with Anthony Pomliano, and he's also a published author, twice over, penning a collection of New York centric vignettes in lifeween moments, as well as a travel novel, everywhere but Home. So Phil, it is great to see you here.And uh we're gonna get to our phrase of the day, September effect in a minute. Just tell us how you're seeing the markets right now overall.\n\n1:35 spk_1\n\nSo, uh, first of all, thank you both for having me. It's great to be back. Um, the market right now, we have a lot of positive momentum and I think that is the, the twist in history right now. So typically we're going into September, very weak and very jittery and investors across the board are expecting this pull back, but I do think.This year, uh, you know, famous last words this time is different. However, uh, the rate cut on September 17th, which is pretty much guaranteed at this point, I think that is going to see markets finish higher in September, which is very unusual because I think in the last 10 years September's finished down 2% on average, and if you go back to 1950, it's down like 0.8% or something like that. Yeah,\n\n2:18 spk_0\n\nand so that's perfect. Let's get into our phrase of the day that would be the September effect.And this is the historical tendency for stocks to post returns that are weaker in September than the other months, and it's important to note that this is just a pattern based on history, which may or may not pan out, but I'm wondering how you think about seasonality in general, seasonality just being, you know,The same types of things, patterns that we see in the market happen year after year. How much do they play into your analysis?\n\n2:46 spk_1\n\nSo I think a lot of this, especially in September, is a self-fulfilling prophecy, right? Investors are expecting this September effect to take hold, but again,I don't know if it applies as much this year because this has also been one of the wildest, most eventful years in market history, and you know we all know this as reporters we're writing about it every day, but we have, uh, the Federal Reserve has been pushing back and forth with the White House. We have these tariffs and we have this now widely expected rate cut in a week. So all this, I think anything is uh up for grabs right now, but I, I don't think seasonality will have as much of a play.As history suggests, you\n\n3:28 spk_2\n\ncan even look at go away. That that trend did not work\n\n3:32 spk_0\n\nout. Yeah, well, I, and I've done, I've done some studies on this go away. It's more like hedge and may and go away. It's evolved over the years, but we've seen different patterns from like 1940s to 1980s versus 1980s to now.Um, you've said some interesting things here, and you mentioned the fact that this is a wild year, Phil, and I was looking at seasonality coming into the, uh, the Trump presidency, and you can do seasonality. You can slice it, uh, and dice it several different ways. And one of the ways is to look at what year of the presidential cycle we're in. This is the first year. This is Donald, even though it's his 2nd term, it's his first year of this term.And I got to tell you what happened around liberation Day completely destroyed the seasonality chart, and then the market kind of came back and it seemed like at the end of August, we were right on track again according to some models. But in general, just talk to us about, especially maybe as, as in terms of how you cover these markets, what you've seen and how this has surprised you this year, some of the wildcards.\n\n4:29 spk_1\n\nSo I, I think right now the S&P 500.Actually having a better than average year generally, but also a better than average post-election year. So all this is going against the, let's say the tariff doomers in the start of the year. Everyone thought tariffs would destroy the market. They thought the Fed independence battle that would also destroy the market, but pretty much investors have not even paid attention to this, uh, let's say when you zoom out. So I, I think, um.A lot of the bearishness has been sort of eked out of the market right now, and almost every single firm has turned bullish for the year, and uh this.The narrative of betting against the Bears, I think that is the story of the year because the Bears have been the loudest, certainly in the first half of the year, but all the Bulls have been the ones that ended up right.\n\n5:18 spk_2\n\nBut it is interesting to me as a reporter like you were saying, covering this day in and day out, there are a lot of bulls out there, but there also are more cautious voices even when we talk about rate cuts, Eddie Denny from your Denny Research, he's a fan of the show, friend of the show, and he said that maybe the Fed shouldn't be cutting right now, and that could actually maybe lead to a market melt up and there could be a lot of money running in here at a time when you haveInflation that's still hot. There's also this debate about whether or not we're not too heavy, too concentrated in the market. So it does feel like at the same time there are a lot of unknowns and there is this tension among strategists about what comes next.\n\n6:01 spk_1\n\nSo I think your Danny is definitely not alone in that view, right? And I read his research all the time. He's super smart. I will say our team at opening Bill Daily, we've pretty much been calling for a rate cut.It's about March. Um, so we do think the Fed has been slow to respond in policy, and I think the, the jobs report really confirmedthat.\n\n6:22 spk_0\n\nYeah, that was that was dismal in a lot of ways. And then we know, we learned retroactively that one of the months, a few months ago, I think it was June turned negative and that's always had it, had it been negative in June, we probably would have had a rate cut already. And so that kind of brings to the forefront the issue is Jerome Powell and the Fed a little bit too late? What do you think about that?\n\n6:42 spk_1\n\nI do think they are too late, but I don't think it's necessarily Jerome Powell's fault. I think it's a structural deficiency of the Fed because it's a backward looking institution, right? But markets move so rapidly the economy can change faster than we think, but the Fed is pretty much working with uh a backward looking.Mandate, right? And then also the data can be hit or miss on whether you believe it or not. Maybe not believe is not the right word, but it's always revised, right? So the Fed's working with a pretty difficult circumstance. So I, I, I don't know if it's necessarily Jerome Powell. I think if anyone was in theThat job, they would probably be late this year.\n\n7:20 spk_0\n\nYeah, I don't, I don't envy anybody in that slot. You just brought up the data and I'm wondering what you've, you've thought about all the controversy surrounding the BLS, um, and a lot of this comes from the fact that since the pandemic, peoplehaven't been responding to these government surveys and so there's, you can't, you can't rely on the data as much. The margin of error is greater. And so I think it's no surprise that we have June being revised negative. There's a, there's a huge uh leeway that you got to give this data. So what do you think about the issue that, um, you know, Trump has raised the question of integrity. Do you think that's an issue?\n\n7:56 spk_1\n\nSo I, I don't know if replacing the head of the BLS is going to change the integrity of the data. I think the data was pretty, um, let's say, uh, it was gonna be revised no matter who is in charge, right? So I don't know if Trump putting his own person in there is gonna improve or worsen the data because I, I think it's, again, these are very old, you know.Methods that they're using to track all this data and I for one, I try to look at alternative sources of data, try to accrue a bunch of different sources when I make my analysis on the market and I would never just rely on let's say the BLS to determine what I think is gonna happen next in the market.\n\n8:36 spk_2\n\nSo what are those sources of data for you.really inform your viewpoints when it\n\n8:40 spk_0\n\ncomes to what do you look at every morning? Yeah.\n\n8:42 spk_1\n\nSo I, I think anecdotally, um, I talked to a lot of people, so I talked to a lot of strategists, as you both do. I talked to a lot of economists, and I talked to people in hiring manager, manager positions, right? Are they hiring? Are they not hiring? Um, you know, I actually met this engineer the other day and um.He told me that, so he's been at this firm for about a decade, this is a big tech company, and he used to do 2 interviews a week. This was about a year and a half ago, and now he does about an interview per quarter, and to me that was like a very uh red flag, let's say on the labor market.\n\n9:17 spk_0\n\nI want to talk about some of the market stuff that we're seeing. concentration has been a big issue, you know, do we, is too much of the market's gain due to just a few companies and arguably it's been that case over the last few years. And the other thing is we're in the 3rd year of this bull market now.And that's typically, you don't see the gains that you saw in the first two years. I would say 23 and 24, we had gains of 20+% and the S&P 500, now we're looking, I think we're on track for 9 or 10, which is not bad, uh, for especially for a third year, but how do you see the concentration issue evolving?\n\n9:50 spk_1\n\nSo I, I do think that's a very um relevant issue to talk about, right? It's super concentrated we're at dotcom levels and that's certainly not a comparison you want to hear in any context. You never want to be compared to the dotcom bubble, um, but I, I think the difference today is that the companies that are at the top of this concentration, the mag 7, right, we've never seen companies this profitable with this large balance sheets.And that to me that does give some cushion to that concentration argument right that the earnings have justified it maybe, yes, I, I think earnings have definitely justified it and I don't know if that's gonna last for much longer, but up to this point, I don't think it's um let's say something we should be overly concerned about. And again, I, I think I've seen um.S&P 493 earnings are slowly gonna catch up in the coming quarters while Mag 7 slows down, so that is something I think worth monitoring as well. Yeah,\n\n10:43 spk_2\n\nand Torsten Stock from Apollo, our parent company, he did publish uh quite a bit of research about how concentrated we are in this market, and that's because of those hyper scalers and the data demand and how much CapEx they're spending.Given that we just finished wrapped up this latest earnings season, were there any little signs that maybe that demand is starting to weaken just just a little bit? I know Nvidia missed on data center revenue. Was that concerning to you at all?\n\n11:10 spk_1\n\nSo I'm not sure if I have much to say on the side of that, but I do know we've never seen this S&P 50.earnings calls mention AI, right? So that's, you know, on one hand, you can say, oh, there's a top signal, who knows? Um, and then we also have um data center spend is, that's, that's going to keep increasing for probably several more quarters. Um, so all these things, it's like the\n\n11:34 spk_2\n\nmining.\n\n11:39 spk_1\n\nYou could argue very convincingly that there is a lot of froth in the market right now with AI, with crypto, with some of these meme stocks, but also you could take the other side and say earnings have been phenomenal and they're projected to be phenomenal again in the 4th quarter. That's why\n\n11:56 spk_2\n\nI think this market's been a little confusing because you can argue both sides of that equation, and we talk about retail traders, unprofitable tech that that's been leading the meme stocks like you mentioned.They're sort of bleeding this market higher and dragging the institutions along with it. So that's been something that I, yeah,\n\n12:12 spk_0\n\nI see that too, Ali. Hold that thought though, because guess what, we got to take a short break. Coming up, we're going to break down the number that captures market regret and a runway battle between David and Goliath, but with stocks, of course.This episode is brought to you by the number 9.7% points. That's how much profit you would have missed out on had you sold at the Lowe's after that scary post-liberation Day sell off and missed the April 9th rally. So one day, nearly 10%, and Phil, I'm saying this because it kind of opens up a discussion in a market psychology and about staying invested, all these things that we like to talk about. How do you, how do you think about this phenomenon and how do you keep, how do you tune out the noise?That's all in the media.\n\n13:05 spk_1\n\nThat's a very difficult and timeless question. Um, I, I think if you are someone with a 30 year investing horizon, you can pretty much ignore the news, right? And I say that as someone who's in the news, um, and\n\n13:17 spk_0\n\nwho probably has a 30 year investment horizon.\n\n13:19 spk_1\n\nYes, yes, exactly. So, um, for myself, um.I do think that the day to day fluctuations of the market, maybe the tariff scares or the Fed independence scares, all this stuff, it's intense in the moment, but if you're looking decades in advance, odds are your portfolio will be just fine if you just leave it as is and and stick to your plans, stick to your dollar cost averaging all those things.\n\n13:42 spk_2\n\nYeah, and when we talk about the record highs that we've been seeing and Jared was just mentioning some of the returns that we've had over the past few years, and then you try and match that with the state of the US economy and post-COVID we did see a struggle with inflation really rampant. A lot of everyday Americans were underwater, yet we had these double digit gains in the stock market.So how, how do you really square that when it comes to assessing the status of the economy while also what we're seeing with stocks at record highs?\n\n14:16 spk_1\n\nThat's a great question. So we've seen this phrase a tale of two economies, right? I think you pretty much have your asset allocators and then those that aren't in the market, and there's really been a clear winner and loser story here. And um if youYou know, the short of it, if you've been in the market, you've done very well, and if not, your dollar has lost purchasing power dramatically over the last 5 years. I think since 2020 we've probably lost 25% to 28% of our 1 dollar's purchasing power. So that is very significant. And if you were in the market, then you've been able to keep up or beat that, um.Let's say loss in purchasing power, but if not, you really can't buy as much as you could. Um, so these are, uh, these are structural issues thatReally points to the importance of investing, I think, um, but it also points to the uh probably the widening inequality gapas well.\n\n15:09 spk_2\n\nMaybe the types of companies you invest in too, because those that are more exposed to that lower income consumer, they have been reporting a little bit more of astruggle.\n\n15:18 spk_0\n\nYou've brought up a great point. I want to launch off that because you, you sent us a chart a few hours ago. Dollar General and Dollar Tree, two companies that are known to do well when the consumer is feeling a little bit off andTheir pockets are a little bit pinched. They are outperforming most of the other retail companies, especially the big box retailers this year. Not only that, they're outperforming Nvidia. So talk to us about that phenomenon. What do you think ofthat?\n\n15:42 spk_1\n\nSo when I saw those numbers and I sort of put the stocks on a line chart.I was very shocked and uh because Nvidia is the story of the year, right? Everyone loves this stock, earnings are the Super Bowl, all this, but Dollar Tree and Dollar General are beating it by I think by double digit digits still. Um, and the CEO of Dollar Tree at the last earnings call said.The majority of their new customers in the last quarter were six figure households. So that, that's, I read that and it was a baffling stat because you wouldn't assume that a six figure, uh, you know, high income household is going to a dollar store. Um, and I will say I love dollar stores likewise, I, I love a dollar store, um.But that points to this sort of flights of value, right? So everyday consumers regardless of income bracket are looking to stretch their dollars more and that goes to the loss of purchasing power, it goes to inflation, it goes to high interest rates. So all these things, um, it is pointing to a constrained consumer, I think.\n\n16:40 spk_2\n\nYeah, and, and when you talk about the dollar, I mean, I think year to date we've lost about 10% compared to other types of currencies, and it's interesting to look at that and then look at gold, which is now at record highs right around, let's talk about gold bucks. I mean, where is that mostly foreign investors piling into gold? Is it the expectation of rate cuts? What, what do you think has been driving kind of that side of the market?\n\n17:03 spk_1\n\nThat's a great question. Um, I, I think part of it is a lot of governments and central banks are buying gold, right? China, Russia, yeah. So I think that's, uh, you know, I don't know what percent they're driving, but that's probably a huge chunk of it. And then you have, um, Bitcoin as well has seen a similar, very strong year. Um, so you have central bank and government buying, I think you have retail catching on to this gold trade.And then you also have the general narrative, I think of you want to hedge against dollar debasement and gold and Bitcoin are are the best ways to play that, according to most people.\n\n17:36 spk_0\n\nWhat do you think of all these Bitcoin treasury companies, not just Bitcoin. Now we're seeing Ethereum treasury companies, people piling into the micro strategy, which almost got just got in, uh, added to the S&P 5.didn't quite make it. But uh Solana too, what do you think of all this, all this phenomenon?\n\n17:52 spk_1\n\nFirst of all, I think with the micro strategy not getting added, there were definitely some politics at play there. Um, I don't know the details, but it was so eligible, right, but it didn't get picked. Um and as far as the the broader Bitcoin treasury trend, um, this, you could say from a very high level.Is a bet that the dollar will continue to lose its value and Bitcoin will continue to appreciate over time so why wouldn't want, why wouldn't you want your balance sheet to be denominated in the asset that's gonna appreciate rather than get debased? So I think very simply and from a very high level that's what we're looking at and again you might be.Able to point out some froth in the market because there's been a lot of these popping up and I, I think we're seeing other crypto assets being put on balance sheets as well so that also suggests uh OK, are we getting overextended here but uh right now uh.I think the the train is still gonna keep going.\n\n18:50 spk_0\n\nAll right, we got to get to our runway battle today because on who are better. We are crowning a market leader and we are pitting the mega cap giants against their small cap cousins. On the left catwalk struts the mega cap moat, armor plated balance sheets, thick margins, and a wardrobe of buybacks. When the lights flicker, these names don't flinch. They just tighten their costs and keep the cash flows of coming. On the right runway, we've got thisAll caps scramble, cyclical energy turnaround stories and tags that still say discount. When the economy accelerates and money gets cheaper, these names rip. But rate cuts are a double-edged sword because if the Fed is too late, small caps, they get torn to shreds, while large caps, well, they suffer too, but typically a bit less. So Phil, you don't need to pick a religion here. We just want to know which closet you're wearing and why, who wears it better over the next year, Mega cap moat or theSmall cap scramble.\n\n19:43 spk_1\n\nThat'sa, that's a hell of an intro. Um, I, I would say from this point to year end, if we get, let's say 2 to 3 rate cuts, I think small caps will do very well. They're very interest rate sensitive and I think, um, large caps, you could also argue are getting a bit overextended despite the earnings that have been sogood.\n\n20:01 spk_2\n\nWhat if we only get one this\n\n20:03 spk_0\n\nyear or 10. That's not a good sign.\n\n20:08 spk_1\n\nUm.One cut, I would probably lean more towards mega caps, but I don't think we'll only get one cut. I think we'll probably get 3 by by December, I think so.\n\n20:17 spk_2\n\nYeah. And what do you think we'll drive that the continued deterioration of the labor market, or do you think the inflation side of the picture if that comes in hot this week, could that maybe give the Fed some pause?\n\n20:27 spk_1\n\nI think even if inflation comes in hot, the Fed has pretty much conceded that they're gonna let inflation run hot so I think they're gonna look at the labor market and they're also of course the the political pressure whether you say they're buckling or not, it's definitely a factor. So I, I think they're gonna let inflation.Rise, even if, you know, whether it rise or not, they're not going to be worried about that right now.\n\n20:47 spk_0\n\nPhil, at the beginning of the show, I mentioned you are an accomplished author, and I have read your book Life Between Moments. I love it. Tell us about your journey into writing fiction and how that's kind of uh maybe jive with your job here at Morning Bell.\n\n21:02 spk_1\n\nThat's that's deep in the archives there. Um, I think writing fiction has helped me, uh, just be a better writer in general, right? It helps me use differentUm, literary tools in my financial reporting, and I think it makes me, uh, understand the psychology of things a bit better. And yeah, that book really, uh, I wrote it when I was at Business Insider, and, uh, I would go home after work and spend maybe 30 to an hour on it a day, finished it in a year, and then published it and uh it has nothing to do with markets, nothing to do with Wall Street, um, but it was a great passion.of mine at the time and I'm honored you even know about it. Hey,\n\n21:38 spk_0\n\nIencourage everybody to read it, download it, get the Kindle some great stories in there. All right, so what did we learn today? We talked about the September and that's the seasonality play. It's just a tendency. It doesn't mean you have to get all scared because September tends to close down, but we do have some other orange or yellow flash.Warning signs and some of those have to do with the fact that the Fed might be a little bit behind the eight ball. We got a deteriorating labor market. But what's most important is that investors keep their, uh, keep their head on their accounts and not necessarily responding to the news on a day by day basis, uh, because the, the market itself, the S&P 500, yes, it's concentrated, but we've seenThis concentrated persists for long periods of time over history. So that's gonna do it for today. We got to wind down things here at Stocks and Translation, but be sure to check out all our other episodes of our video podcast on the Yahoo Finance site and mobile app. We are also on all your favorite podcast platforms, so be sure to like, leave a comment, and subscribe wherever you get your podcast. We'll see you next time on Stocks in Translation.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/forget-september-slump-why-market-100001329.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Cadence Built An Nvidia DGX SuperPOD Digital Twin With Incredible Scale And Accuracy",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/marcochiappetta/2025/09/09/cadence-built-an-nvidia-dgx-superpod-digital-twin-with-incredible-scale-and-accuracy/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Will Broadcom Chips End AMD Stock's AI Dreams?",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/09/will-broadcom-chips-end-amd-stocks-ai-dreams/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The XFX Radeon RX 7900 XT Graphics Card Drops to $630: This Is the Least Expensive 4K-Capable GPU",
      "content": "If you've just upgraded to a new 4K gaming monitor and now you're looking for a reasonably priced GPU that can comfortably run games off it, then check out this deal. Amazon is offering the XFX AMD Radeon RX 7900 XT 20GB graphics card for just $630.63. This is the lowest price I've ever seen for an RX 7900 XT GPU, and that's saying something because nearly all video cards nowadays are higher than their original launch price. The RX 7900 XT is a generation old, but it's still an excellent 4K GPU that approaches the performance of the GeForce RTX 5070 Ti and Radeon 9070 XT.\n\nThe Radeon RX 7900 XT was released back in 2022, but its still a relevant card today, able to play pretty much any game at 4K with consistent framerates of 60fps and beyond. Compared to current generation cards, it's roughly 5%-10% behind the Nvidia GeForce RTX 5070 Ti and and the AMD Radeon 9070 XT in 4K rasterized (non ray-traced) performance. It's also 10%-20% less expensive, making it a very attractive alternative for those of you who are on a budget. The RX 7900 XT also comes equipped with 20GB VRAM, which is more than the 5070 T iand 9070 XT, which come with 16GB. The extra VRAM allows it to scale well in high-resolution gaming and it's also a good card for AI use.\n\nIf You Need Ray Tracing, Stick with NVIDIA\n\nAMD Radeon cards are outstanding alternatives to the NVIDIA GeForce cards. For gamers who want to maximize their performance for their dollar, AMD GPUs are the way to go. However, if you're set on playing 4K games with ray tracing enabled, then you'll want to stick with NVIDIA. That's because the GeForce cards perform better than their Radeon counterparts when it comes to ray tracing. Ray tracing is a form of rendering that allows for more realstic lighting effects. It makes light sources and shadows look better, but at the steep cost of GPU resources.\n\nWhy Should You Trust IGN's Deals Team? IGN's deals team has a combined 30+ years of experience finding the best discounts in gaming, tech, and just about every other category. We don't try to trick our readers into buying things they don't need at prices that aren't worth buying something at. Our ultimate goal is to surface the best possible deals from brands we trust and our editorial team has personal experience with. You can check out our deals standards here for more information on our process, or keep up with the latest deals we find on IGN's Deals account on Twitter.\n\nEric Song is the IGN commerce manager in charge of finding the best gaming and tech deals every day. When Eric isn't hunting for deals for other people at work, he's hunting for deals for himself during his free time.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/xfx-radeon-rx-7900-xt-graphics-card-deal-best-4k-gpu-under-650",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia's CFO says there's still 'a little geopolitical situation that we need to work through' before shipping its AI GPUs to China, but it's 'a $2 billion to $5 billion potential opportunity'",
      "content": "Nvidia's executive vice president and chief financial officer, Collette Kress, spoke yesterday at the Goldman Sachs Communicopea event about a variety of topics, including a discussion of its recent financial results and the ongoing situation regarding its dealings with China. When asked for an update on demand for its H20 AI GPU in the country, and what needs to happen before it's potentially shipped in the second-to-last quarter of this year, Kress said:\n\n\"Yes, we did receive a license approval and have received licenses for several of our key customers in China. And we do want that opportunity to complete that and actually ship the H20 architecture to them.\n\n\"Right now, there is still… a little geopolitical situation that we need to work through between the two governments,\" Kress continued. \"Our customers in China do want to make sure that [the] China government is also very well received in terms of receiving the H20 to them. But we do believe there is a strong possibility that this will occur.\n\n\n\n\"And so it could add additional revenue. It's still hard to determine how much within the quarter. We talked about it being about a $2 billion to $5 billion potential opportunity if we can get through that geopolitical statement.\"\n\nWe reported last week that tech firms in China, including TikTok owner ByteDance, were reportedly waiting on their GPUs to arrive after placing orders back in July, when Nvidia was first said to be in the process of obtaining the appropriate licenses, with assurances from the US government they would be granted. Since then, Chinese data center operators have been given orders to obtain at least 50% of their chips from domestic manufacturers, while it's also been claimed that Nvidia has suspended production of the H20 chip after security concerns were raised by Chinese officials.\n\n(Image credit: Nvida)\n\nSo, by the looks of things, while licenses have indeed been granted to Nvidia to sell its H20 GPUs to China, there are still some serious headwinds to work through before the powerful AI hardware actually arrives on Chinese shores. It certainly seems like Nvidia is confident everything will get straightened out eventually, but this \"little geopolitical situation\" seems to be gumming up the works significantly.\n\n\n\nStill, with an estimated $2 to $5 billion of additional revenue on the line, I'd imagine Nvidia is working hard behind the scenes with both governments to come to a resolution. Us gamers may no longer be the biggest revenue driver for the company, but part of me wonders if the geopolitical intricacies of selling AI hardware to China amid confusing tariffs, export restrictions, and perceived political brinksmanship between the US and Chinese governments has ended up being more of a headache than Nvidia first imagined.\n\n\n\nWe humble consumer GPU enthusiasts are usually mostly interested in gaming performance and pricing, which I'd say makes us easier customers to deal with. Still, swimming in deep waters attracts big fish, and it seems like Nvidia might still have some paddling to do before reeling in its multi-billion-dollar prize.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/software/ai/nvidias-cfo-says-theres-still-a-little-geopolitical-situation-that-we-need-to-work-through-before-shipping-its-ai-gpus-to-china-but-its-a-usd2-billion-to-usd5-billion-potential-opportunity/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia-Backed Nebius Stock Soars 50% on AI Infrastructure Deal With Microsoft",
      "content": "Key Takeaways Nebius Group inked a deal with Microsoft worth up to $19.4 billion to provide artificial intelligence infrastructure for the software giant's new data center in New Jersey.\n\nMicrosoft agreed to pay Nebius $17.4 billion over five years, and could add another $2 billion for additional services or capacity.\n\nNebius said this was the first of what it expects to be similar contracts with big AI labs and tech firms.\n\nShares of Nebius Group (NBIS) soared 50% in early trading Tuesday after the artificial intelligence infrastructure company struck a deal with Microsoft (MSFT) that could be valued as much as $19.4 billion.\n\nMicrosoft agreed to pay the Nvidia-backed (NVDA) firm, which completed its split from Russian internet giant Yandex last year, $17.4 billion over five years to provide artificial intelligence infrastructure for a new data center in New Jersey.\n\nMicrosoft “may also acquire additional services and/or capacity” for another $2 billion under the agreement.\n\nFounder and CEO Arkady Volozh said this was the first of what Nebius expects will be “significant long-term committed contracts with leading AI labs and big tech companies.”\n\nWith Tuesday's surge, Nebius shares have more than tripled in value since the start of the year. Microsoft shares were up less than 1% in recent trading and have added close to 20% year-to-date.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/nvidia-backed-nebius-stock-soars-50-percent-on-ai-infrastructure-deal-with-microsoft-11806153",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD's FSR 4 upscaling tech gives even more PC games a free image quality upgrade – but you still need a modern GPU",
      "content": "AMD's FSR 4 is now available in most FSR 3.1 and DX12 supported games\n\nThe new Adrenalin Software driver allows users to override FSR 3.1 with FSR 4\n\nIt only works in games that have a signed FSR 3.1 DLL\n\nWhile AMD fans await an eventual FSR 4 backport to older non-RDNA 4 graphics cards alongside updates to the upscaling technology that's exclusive to some of the best GPUs on the market, Team Red has at least made life easier for developers and gamers.\n\nAs reported by VideoCardz, AMD's latest driver 25.9.1 adds further FSR 4 support for most FSR 3.1 and DX12-supported games, which AMD says is now 'over 85 games'. RDNA 4 GPU owners simply need to enable FSR 4 on the AMD Adrenalin Software and toggle on FSR 3.1 in a supported game, allowing the driver to override FSR 3.1 with FSR 4.\n\nIt's worth noting that this is only possible in games that have a signed FSR 3.1 DLL, which means the override won't work via third-party integration. While FSR 4 still hasn't been backported to RDNA 3 and older GPUs, FSR 4's driver override should make things much easier if a backport does happen soon.\n\nTeam Red's recent FSR 4 open-source slip-up revealed that it was (and potentially still is) working on an FSR 4 backport to RDNA 3. And with the FSR 'Redstone' presentation set to reveal frame generation and image quality improvements, it may not be far-fetched to suggest that AMD may have another surprise announcement in store.\n\nAMD's fierce rival, Nvidia, has DLSS 4 available for all RTX GPUs; not only does it have the advantage of being widely available to more PC gamers, but the image quality is superior to FSR 4's, and there's nothing better than AMD's Redstone shortening the gap to Team Green's offering, while also allowing all (or at least most) Radeon GPU users to benefit from sharper images in games.\n\nAnalysis: FSR 4 on RDNA 3 and older GPUs should be AMD's number one priority\n\n(Image credit: AMD)\n\nWithout a doubt, Nvidia is still leading the GPU market. That's unsurprising, especially since the RTX 5000 series GPUs are gradually plummeting back to their launch prices – and Team Green is rumored to be launching Super series GPUs this fall.\n\nWith this in mind, it's time for AMD to at least provide its latest upscaling tech to RDNA 3 GPUs before Nvidia bridges the gap further.\n\nGet daily insight, inspiration and deals in your inbox Sign up for breaking news, reviews, opinion, top tech deals, and more. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAgain, Nvidia already has DLSS 4 available on all RTX GPUs, except for Multi Frame Generation (exclusive to RTX 5000 series) and Frame Generation (starting from RTX 4000 series). DLSS 4 has shown how vital it is for upscaling tech to have sharper super-resolution image quality, and it shines bright even in DLSS performance, which benefits PC gamers with low-end hardware.\n\nTeam Red's FSR 4 has a similar effect with better image quality across its upscaling modes, and while it certainly doesn't match up to DLSS 4, it beats both FSR 3 and DLSS 3. As a handheld PC gamer, FSR 4 would do wonders at providing better performance via aggressive upscaling, without too much of a heavy sacrifice on image quality, like FSR 3 has.\n\nIt's the ideal time for AMD to get this going, as it would add to the firepower it needs to fully compete with its GPU rival.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/computing/gpu/amds-fsr-4-upscaling-tech-gives-even-more-pc-games-a-free-image-quality-upgrade-but-you-still-need-a-modern-gpu",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Jim Cramer Discusses Whether Broadcom Inc. (AVGO)’s $10 Billion Mystery Customer Is OpenAI",
      "content": "We recently published 10 Stocks Jim Cramer Discussed As He Dismissed A Recession. Broadcom Inc. (NASDAQ:AVGO) is one of the stocks Jim Cramer recently discussed.\n\nJoao Virissimo/Shutterstock.com\n\nBroadcom Inc. (NASDAQ:AVGO) stunned the stock market and the AI sector when it revealed that it had landed a $10 billion deal for custom AI chips. The announcement, paired with a strong earnings report, sent the stock 13.7% higher. Cramer discussed the potential of OpenAI moving away from NVIDIA to Broadcom:\n\n“[On stock higher on reports that the $10 billion mystery customer is OpenAI] Yeah look I, I don’t want to be contrarian about too many things. . .but I would say the reason I even knew about OpenAI was that Jensen Huang, CEO NVIDIA, told me that really that they were the first company to really understand what Jensen had. And their partnership dates back the longest of any one of these hyperscalers. So I know I read this stuff and it says okay well this is a threat, an existential threat to NVIDIA and NVIDIA stock is down and then I read Ben Reitzes, who’s been the most right about this, particularly with Hock, with the CEO of Broadcom, he says no time to debate about, there’s so much business, there is a huge amount of business.\n\nWhile we acknowledge the potential of AVGO as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/jim-cramer-discusses-whether-broadcom-133530898.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AT&T Stock Rebounds After EchoStar and SpaceX Deal. Why the Shares Can Jump 10%",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/0c3af72450f4b369",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Quantum Pact: NVIDIA, Honeywell Raise Stakes for IonQ, Rigetti, D-Wave",
      "content": "NVIDIA’s NVDA latest move into quantum computing through a landmark investment in Honeywell HON-backed Quantinuum has jolted the sector, instantly lifting its profile among investors. Following the Sept. 4 announcement, the Defiance Quantum ETF (QTUM) rallied 2.3% as of yesterday.\n\nZacks Investment Research\n\n\n\nImage Source: Zacks Investment Research\n\nFor public pure-plays like IonQ IONQ, Rigetti Computing RGTI and D-Wave Quantum QBTS, this development brings both opportunity and pressure. On the one hand, it sparks renewed investor attention and potential capital flows into the space. On the other hand, it raises the bar for technological execution and commercial traction. Let’s delve deeper.\n\nNVIDIA, Honeywell Pact: Funding Surge Accelerates Fault-Tolerant Quantum Push\n\nOn Sept. 4, 2025, Honeywell announced that its quantum computing arm, Quantinuum, completed an approximately $600 million equity capital raise at a $10 billion pre-money valuation. Key new investors include Quanta Computer, NVentures (NVIDIA’s venture capital arm) and QED Investors, alongside follow-on investments from existing backers such as JPMorgan Chase, Mitsui, Amgen, Cambridge Quantum Holdings, Serendipity Capital and Honeywell itself.\n\nThe new funding will help Quantinuum speed up its work in quantum computing, including the launch of its next-generation system, Helios, expected later this year. The company is also working toward building universal, fault-tolerant quantum systems. In addition, Quantinuum has strengthened its role as a founding partner in NVIDIA’s Accelerated Quantum Research Center and is expanding global partnerships in places such as New Mexico, Qatar and Singapore.\n\nNVIDIA's $600 Million Bet Sparks Momentum or Pressure for Pure Plays?\n\nStock Comparison Since NVDA-HON Deal\n\nZacks Investment Research\n\n\n\nImage Source: Zacks Investment Research\n\nIonQ: It recently announced a major strategic milestone through the acquisition of U.K. quantum startup Oxford Ionics in a deal valued at approximately $1.075 billion. This move bolsters IonQ’s trapped-ion technology roadmap by integrating chip-scale ion-trap expertise. NVIDIA’s backing of Quantinuum, also a trapped-ion player, intensifies the race, raising competitive pressure. For IonQ, this could attract more investor attention but also forces the company to deliver commercial results at a pace that keeps it in step with this well-funded rival.\n\nIONQ, a Zacks Rank #3 (Hold) stock, dipped 2.6% since the April 4 announcement. However, full-year 2025 earnings are projected to grow 37.8% on 115.1% revenue growth over 2024.\n\nIonQ, Inc. Price and Consensus\n\nIonQ, Inc. Price and Consensus\n\nIonQ, Inc. price-consensus-chart | IonQ, Inc. Quote",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/quantum-pact-nvidia-honeywell-raise-190000357.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Brighten winter with indoor blooms by forcing spring bulbs to flower early",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/4a856886acc3819e",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Eightco Chair Dan Ives Calls Sam Altman's World Project The 'Intersection Of AI And Crypto,' Compares It To Nvidia, Palantir",
      "content": "Benzinga and Yahoo Finance LLC may earn commission or revenue on some items through the links below.\n\nWall Street tech analyst Dan Ives expressed on Monday his excitement and vision for his new role as chairman of Eightco Holdings Inc. (NASDAQ:OCTO), a firm that has adopted World (WLD) as its primary reserve asset.\n\n‘Intersection’ Of AI And Crypto\n\nDuring an interview with CNBC, Ives, a senior research analyst at Wedbush Securities, said he was “excited” to take over the role, given his “passion” for AI and the potential of the decentralized identity verification project.\n\n“When you think about these Orb devices, the iris scanning, in my opinion, is going to be the de facto standard when we think about separating from bots, identifying humans. And ultimately, this is really more of an infrastructure play. It’s really the intersection of AI and crypto,” Ives said.\n\n\n\n\n\nTrending: Your Last Chance to Invest in Pacaso Before Their Global Expansion — Offer Ends Sept 18\n\nIves Compares World To Nvidia, Palantir\n\nHe argued that despite the trillions being poured into large language models and data centers, the future of AI will be determined by authentication and identification.\n\nIves compared the current state of the project to where Nvidia Corp. (NASDAQ:NVDA) and Palantir Technologies Inc. (NASDAQ:PLTR) were in 2022, suggesting a similar trajectory of growth and influence.\n\nEightCo raised $250 million through a private placement to adopt WLD as its primary treasury reserve asset.\n\nTom Lee-led Bitmine Immersion Technologies Inc. (AMEX:BMNR) also disclosed a $20 million investment into the company as the first \"Moonshot\" initiative in its Ethereum (CRYPTO: ETH) ecosystem expansion plan.\n\nSee Also: If there was a new fund backed by Jeff Bezos offering a 7-9% target yield with monthly dividends would you invest in it?\n\nWorld’s Privacy Concerns\n\nWorld, formerly Worldcoin, co-founded by OpenAI CEO Sam Altman, is an identity verification project that captures people’s irises to confirm their humanness and build a digital ID, allowing them to receive free WLD tokens. However, it has courted controversy over personal data privacy concerns and is currently outlawed in Hong Kong, Kenya, and Spain. The project debuted in the U.S. earlier this year.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/eightco-chair-dan-ives-calls-180012236.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "This Blender tool can transform 3D models into pencil sketches",
      "content": "We're big fans of Blender. The free, open-source program has a place in our guides to the best 3D modelling software and the best animation software. And it turns out that it can be given another interesting use: creating sketches that look like they were drawn by hand.\n\nOne of the great things about Blender is the huge range of third-party plugins constantly emerging. CGMatter has already made a whole bunch of addons, and one of his latest is the hand-drawn sketch emulator Pencil Pro (also see our roundup of Blender tutorials).\n\nPencil Pro Tutorial - YouTube Watch On\n\nPencil Pro is a Blender addon that can be used to imitate the look of hand-drawn sketches. It works on any kind of mesh, and it's more detailed than converters that rely on materials because it actually simulates how someone would draw.\n\nIt deals with the placement, direction and pressure of strokes and decides if cross-hatching and shading would work for every frame on the fly. No UVs are needed and it can work with any lighting.\n\nAs creator CGMatter notes, believable drawings come from a combination of shading and general pencil strokes, and Pencil Pro accounts for both. It uses screen coordinates rather than grunge on a 3D mesh, so you never run out of shading detail, and it looks at edge flow to approximate how pencil strokes usually follow the curvature of an object.\n\nIn the video below, CGMatter puts the tool to use to create the content to make a flipbook in Blender.\n\nAnimating a Flipbook for an Animation?? // Blender Tutorial - YouTube Watch On\n\nYou can get the Pencil Pro plugin from Superhive for $15. It also comes bundled in the Genie pack.\n\nGet the Creative Bloq Newsletter Daily design news, reviews, how-tos and more, as picked by the editors. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFor more Blender news, see OK Go's animated video and Blender's Nvidia DLSS upscaling. You might also like a Blender plugin that delivers instant '90s video game graphics.",
      "source": "Creative Bloq",
      "url": "https://www.creativebloq.com/3d/this-blender-tool-can-transform-3d-models-into-pencil-sketches",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nebius-Microsoft $17.4B Deal Lifts AI Mining Stocks in Pre-Market Trading",
      "content": "Nebius Group (NBIS) shares soared 47% in pre-market trading after the company said it signed an agreement to supply Microsoft (MSFT) with graphic processing units (GPUs) in a deal Reuters valued at $17.4 billion over five years.\n\nThe contract is worth more than the Amsterdam-based company's entire market capitalization, currently $15.29 billion. According to Reuters, Microsoft may increase the contract value to $19.4 billion by acquiring additional services capacity.\n\nSTORY CONTINUES BELOW Don't miss another story. Subscribe to the Crypto Daybook Americas Newsletter today . See all newsletters Sign me up By signing up, you will receive emails about CoinDesk products and you agree to our terms of use and privacy policy .\n\nShares of other companies involved in artificial intelligence (AI) computing, also advanced. Cipher Mining (CIFR) and IREN (IREN) both climbed 9% on speculation of further AI infrastructure partnerships, echoing similar moves seen earlier this year with CoreWeave (CRWV) and TerraWulf (WULF).\n\nNebius provides Nvidia-powered GPUs, cloud services and AI developer tools built on its proprietary hardware and software.\n\n",
      "source": "CoinDesk",
      "url": "https://www.coindesk.com/markets/2025/09/09/nebius-microsoft-usd17-4b-deal-lifts-ai-mining-stocks-in-pre-market-trading",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The UAE Showcases Its Abilities In AI Reasoning With K2 Think Model",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/patrickmoorhead/2025/09/09/the-uae-showcases-its-abilities-in-ai-reasoning-with-k2-think-model/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia debuts Rubin CPX GPU for massive AI applications",
      "content": "Nvidia (NVDA) on Tuesday unveiled its new Rubin CPX GPU at the AI Infra Summit in Santa Clara, Calif.\n\nAccording to Nvidia, Rubin CPX is “purpose-built to handle million-token coding and generative video applications.”\n\nTokens are a unit of data in AI and can represent everything from words to pieces of video and audio. Every time you use a service like ChatGPT, Claude, Gemini, or Grok they break down your questions and requests into tokens to serve up an answer.\n\nThe Rubin CPX will work with the company’s Vera CPU and Rubin GPU as part of Nvidia’s Vera Rubin NVL 144 CPX platform. NVL 144 means that the system has 144 GPUs.\n\n“The Vera Rubin platform will mark another leap in the frontier of AI computing—introducing both the next-generation Rubin GPU and a new category of processors called CPX,” Nvidia CEO Jensen Huang said in a statement.\n\n“Just as RTX revolutionized graphics and physical AI, Rubin CPX is the first CUDA GPU purpose-built for massive-context AI, where models reason across millions of tokens of knowledge at once.”\n\nAccording to Nvidia, the Vera Rubin NVL 144 CPX will offer 7.5x more AI performance than the company’s Grace Blackwell based BG300 NVL 72 system. That, the company says, will also help customers monetize their AI platforms with Nvidia estimating they could see $5 billion in token revenue for every $100 million invested.\n\nAn image of Nvidia's Vera Rubin chip. (Image: Nvidia) · Nvidia\n\nThe Rubin CPX will be available at the end of 2026.\n\nShares of Nvidia are up 25% year-to-date and 63% over the last 12 months. The company reported better than anticipated earnings per share and revenue in Q2, but missed slightly on Data Center segment revenue.\n\nNvidia’s largest customers are cloud service providers, which make up roughly 50% of the company’s sales.\n\nThe chip giant is also working its way through resuming shipments of its H20 GPU to customers in China. President Trump initially banned the sale of the processor in April, but reversed course in July. He later announced that the US government would take a 15% cut of chip sales to the region.\n\nDuring a conversation with Yahoo Finance following the company’s earnings call, Huang said production of Nvidia’s next-generation Blackwell chips is “ramping at full speed, and demand is extraordinary.”\n\nTrump, however, is also considering a 100% tariff on semiconductors, though he said that companies that build in the US will be exempt from the duty. While Nvidia doesn’t build chips on its own, it contracts with companies like TSMC (TSM), which is building new plants in the US.\n\nSign up for Yahoo Finance's Week in Tech newsletter. · yahoofinance\n\nEmail Daniel Howley at dhowley@yahoofinance.com. Follow him on X/Twitter at @DanielHowley.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-debuts-rubin-cpx-gpu-for-massive-ai-applications-150047032.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "CoreWeave Stock Rises on News of Nvidia-Backed Firm's VC Fund for AI Investments",
      "content": "Key Takeaways CoreWeave has launched a venture initiative designed to support founders of new artificial intelligence efforts.\n\nThe artificial intelligence cloud computing firm's CoreWeave Ventures will offer direct investment capital and other assistance designed to bring new ideas to market faster.\n\nCoreWeave shares hit the market just five months ago, and shares have more than doubled since then.\n\nCoreWeave (CRWV) shares gained 4% in morning trading after the artificial intelligence (AI) cloud computing platform announced plans to support new AI efforts.\n\nThe Nvidia-backed company said it was starting CoreWeave Ventures to provide “investment resources, technical expertise, and compute” to help AI founders bring new ideas to the market more quickly.\n\nThe assistance will range “from direct capital investment and compute-for-equity transactions to technical collaboration and go-to-market opportunities.”\n\nCo-founder and Chief Development Officer Brannin McBee explained CoreWeave Ventures is designed “to give other audacious, like-minded founders the support they need to drive technical advancements and bring to market the next class of innovation.”\n\nThe company noted that CoreWeave Ventures \"is already working with a diverse group of innovators, from foundational model developers building novel large language models to pioneers in vertical AI applications and infrastructure.\"\n\nShares of CoreWeave, which only began publicly trading in March, are up about 150% since then.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/coreweave-stock-rises-on-news-of-nvidia-backed-firms-vc-fund-for-ai-investments-11806230",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel reshuffle puts engineering and 'a new custom silicon business' in the spotlight but also ends a 30-year career at Intel for Product CEO Michelle Johnston Holthaus",
      "content": "Things are, once again, all shake-up at Intel. After a new CEO, tons of layoffs, an increased focus on the Foundry side of the business, and other changes, Intel is sticking on-brand and making even more changes, this time to executive leadership. And while the biggest news for many might be that Intel Products CEO Michelle Johnston Holthaus is leaving, what's particularly interesting is the company is starting a new group that will focus on a new custom silicon business.\n\nIn addition to these two things, Intel also announced that Jim Johnson will lead the Client Computing Group (CCG), Kevork Kechichian from Arm will join to lead Intel's Data Center Group (DCG), and Intel Foundry CTOO Naga Chandrasekaran will also cover Foundry Services.\n\nThe custom silicon business that's perhaps of most interest is to be headed up by senior VP and Fellow Srini Iyengar. Iyengar joined Intel earlier in the year after being a Fellow at Cadence Design Systems, which is of note because Intel CEO Lip-Bu Tan was previously CEO of Cadence until 2021.\n\nThe new group will apparently be looking towards serving external customers: \"Intel is also establishing a new Central Engineering Group led by Srinivasan (Srini) Iyengar, a senior vice president and Fellow. In his expanded role, Iyengar will lead horizontal engineering functions and build a new custom silicon business to serve a broad range of external customers.\"\n\nIf it pans it, this could certainly be a good move for Intel. Hearing the words \"custom silicon\" for \"external customers\" in 2025 triggers obvious thoughts of AI, as well as chasing down TSMC's foundry dollar. Data centres are increasingly gobbling up AI workloads and thus far Nvidia has been the company to reap the bulk of the rewards from that.\n\nIntel CEO Lip-Bu Tan conducting a keynote address. (Image credit: Intel)\n\nFrom his very first earnings call, Tan made it clear that Intel is going to look to cement itself in the AI market, although there's been no definite word over what exactly that means. Now, there's some reason to suppose that will mean custom AI silicon for data centers. Intel Foundry could certainly do with something of the sort to stake a bold new claim to after the past few years and especially months of troubled waters. But it really needs customers onboard.\n\nNo doubt extra incentive to push into Intel Foundry comes from the recent 10% buy-in from the US government, which is under the stipulation that Intel must own at least 51% of its Foundry for five years. In other words, there can be no back-up plan to scarper and sell.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAs far as we're concerned as PC gamers, it could be good news, too. Emphasis on \"could\" there, but a push into AI accelerators, for instance, would presumably give Intel a lot of R&D as well as actual GPU silicon to trickle down into its gaming division. Just like Nvidia with Blackwell and the RTX 50-series. Though I suppose that analogy should show us such a development might not necessarily spell any improvements for GPU prices. At any rate, changes are afoot.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/graphics-cards/intel-reshuffle-puts-engineering-and-a-new-custom-silicon-business-in-the-spotlight-but-also-ends-a-30-year-career-at-intel-for-product-ceo-michelle-johnston-holthaus/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "New Intel executive reshuffle sees products chief Holthaus leave after 30 years",
      "content": "Intel’s Michelle Johnston Holthaus leaves the company after 30+ years\n\nFurther leadership roles appointed, including a new hire\n\nCEO Lip-Bu Tan wants to flatten company leadership\n\nSenior Intel exec Michelle Johnston Holthaus will be departing the company after more than three decades, including a short stint as interim co-CEO with David Zinsner after ex-CEO Pat Gelsinger’s departure.\n\nHolthaus’ most recent role as Chief Exec of Products comes to a close after 10 months, and the company will not be rehiring for this role.\n\nAcknowledging Holthaus’ transformational impacts, new CEO Lip-Bu Tan noted: “She has made a lasting impact on our company and inspired so many of us with her leadership.”\n\nIntel announces major leadership shakeups\n\nThe company also announced the appointment of Kevork Kechichian as EVP & GM of Data Center Group, bringing more than 30 years’ chip industry experience from Arm, NXP Semiconductor, Qualcomm and more.\n\nJim Johnson becomes SVP & GM of Client Computing Group after around four decades at Intel, Srinivasan Iyengar becomes the head of a new Central Engineering Group, and Naga Chandrasekaran steps up at EVP & CTO of Intel Foundry to oversee development, manufacturing and go-to-market.\n\nThe changes come amid Intel’s ongoing efforts to flatten its hierarchical structure, resulting in more leaders reporting directly to Tan. By streamlining operations, cutting jobs and rebuilding its engineering culture, Tan hopes Intel can reposition itself to succeed going forward.\n\nThe news comes a couple of weeks after Intel reached an agreement with President Trump, whereby the US Government would invest $8.9 billion in Intel to help strengthen its position and bolster domestic American manufacturing.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nA move that has drawn its fair share of public scrutiny, including remarks made by Intel itself about the potential implications of having such political backing.\n\nIntel shares are up 21% this year to date, but the company’s market cap ($113.87 billion) falls far behind that of Nvidia ($4.097 trillion), now ranked as the world’s most valuable company.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/new-intel-executive-reshuffle-sees-products-chief-holthaus-leave-after-30-years",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Samsung to double GDDR7 output following Nvidia B40 order",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250908PD233/nvidia-samsung-production-market-accelerator.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "(PR) NVIDIA Blackwell Ultra Sets the Bar in New MLPerf Inference Benchmark",
      "content": "Inference performance is critical, as it directly influences the economics of an AI factory. The higher the throughput of AI factory infrastructure, the more tokens it can produce at a high speed - increasing revenue, driving down total cost of ownership (TCO) and enhancing the system's overall productivity. Less than half a year since its debut at NVIDIA GTC, the NVIDIA GB300 NVL72 rack-scale system - powered by the NVIDIA Blackwell Ultra architecture - set records on the new reasoning inference benchmark in MLPerf Inference v5.1, delivering up to 1.4x more DeepSeek-R1 inference throughput compared with NVIDIA Blackwell-based GB200 NVL72 systems.Blackwell Ultra builds on the success of the Blackwell architecture, with the Blackwell Ultra architecture featuring 1.5x more NVFP4 AI compute and 2x more attention-layer acceleration than Blackwell, as well as up to 288 GB of HBM3e memory per GPU. The NVIDIA platform also set performance records on all new data center benchmarks added to the MLPerf Inference v5.1 suite - including DeepSeek-R1, Llama 3.1 405B Interactive, Llama 3.1 8B and Whisper - while continuing to hold per-GPU records on every MLPerf data center benchmark.Full-stack co-design plays an important role in delivering these latest benchmark results. Blackwell and Blackwell Ultra incorporate hardware acceleration for the NVFP4 data format - an NVIDIA-designed 4-bit floating point format that provides better accuracy compared with other FP4 formats, as well as comparable accuracy to higher-precision formats.NVIDIA TensorRT Model Optimizer software quantized DeepSeek-R1, Llama 3.1 405B, Llama 2 70B and Llama 3.1 8B to NVFP4. In concert with the open-source NVIDIA TensorRT-LLM library, this optimization enabled Blackwell and Blackwell Ultra to deliver higher performance while meeting strict accuracy requirements in submissions.Large language model inference consists of two workloads with distinct execution characteristics: 1) context for processing user input to produce the first output token and 2) generation to produce all subsequent output tokens.A technique called disaggregated serving splits context and generation tasks so each part can be optimized independently for best overall throughput. This technique was key to record-setting performance on the Llama 3.1 405B Interactive benchmark, helping to deliver a nearly 50% increase in performance per GPU with GB200 NVL72 systems compared with each Blackwell GPU in an NVIDIA DGX B200 server running the benchmark with traditional serving.NVIDIA also made its first submissions this round using the NVIDIA Dynamo inference framework.NVIDIA partners - including cloud service providers and server makers - submitted great results using the NVIDIA Blackwell and/or Hopper platform. These partners include Azure, Broadcom, Cisco, CoreWeave, Dell Technologies, Giga Computing, HPE, Lambda, Lenovo, Nebius, Oracle, Quanta Cloud Technology, Supermicro and the University of Florida.The market-leading inference performance on the NVIDIA AI platform is available from major cloud providers and server makers. This translates to lower TCO and enhanced return on investment for organizations deploying sophisticated AI applications.Learn more about these full-stack technologies by reading the NVIDIA Technical Blog on MLPerf Inference v5.1. Plus, visit the NVIDIA DGX Cloud Performance Explorer to learn more about NVIDIA performance, model TCO and generate custom reports.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340827/nvidia-blackwell-ultra-sets-the-bar-in-new-mlperf-inference-benchmark",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Was Jim Cramer Right About NVIDIA (NVDA)?",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_2d0cb57e-7f83-446e-b643-b14fc4304262",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "S&P 500’s Big Risk This 9/11",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/09/sp-500s-big-risk-this-911/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Watch The PC Gamer Streamer Showdown live today on Twitch",
      "content": "Are you ready?\n\nThe PC Gamer Streamer Showdown kicks off today, a three-day triathalon of gaming competition between eight talented streamers. Watch live on twitch.tv/pcgamer beginning at 12 noon ET / 9 AM PT / 5 PM BST or on the streams of any of our eight competitors.\n\nWins in these three games aren't the only thing that our streamers are fighting for, they're also vying for \"Cool Points\" that add to their overall tournament performance, earned by completing special challenges within matches like registering a perfect round in Street Fighter 6 or finding the Bugle of Friendship in Peak. For more details read here.\n\nHere's a breakdown of the match schedule for September 9, 10, and 12.\n\nThe weeklong schedule of competition. (Image credit: PC Gamer)\n\nThe lineup of competitors is a talented set of variety streamers:\n\nBarefootTasha twitch.tv/barefoottasha\n\nKingGothalion twitch.tv/kinggothalion\n\nAplFisher twitch.tv/aplfisher\n\nRIPMika twitch.tv/ripmika\n\nAsh IV twitch.tv/ashiv_\n\nElainaExe twitch.tv/elainaexe\n\nDish twitch.tv/dish\n\nunCAGEDgamez twitch.tv/uncagedgamez\n\nOur brave contestants. (Image credit: Future)\n\nThe PC Gamer Streamer Showdown is powered by OMEN. Watch all week long for a chance to win an OMEN Max 16 laptop, valued at more than $3000! On the final day of the tournament, a viewer of the winning streamer will be randomly selected to win.\n\nLaptop specs and features include:\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n(Image credit: OMEN)",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/games/pc-gamer-streamer-showdown/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Eightco Chair Dan Ives Calls Sam Altman's World Project The 'Intersection Of AI And Crypto,' Compares It To Nvidia, Palantir",
      "content": "Wall Street tech analyst Dan Ives expressed on Monday his excitement and vision for his new role as chairman of Eightco Holdings Inc. (NASDAQ:OCTO), a firm that has adopted World (WLD) as its primary reserve asset.\n\n‘Intersection’ Of AI And Crypto\n\nDuring an interview with CNBC, Ives, a senior research analyst at Wedbush Securities, said he was “excited” to take over the role, given his “passion” for AI and the potential of the decentralized identity verification project.\n\n“When you think about these Orb devices, the iris scanning, in my opinion, is going to be the de facto standard when we think about separating from bots, identifying humans. And ultimately, this is really more of an infrastructure play. It’s really the intersection of AI and crypto,” Ives said.\n\nSee Also: Warren Paul Anderson: Token Buy-And-Burn Mechanisms Could Damp Volatility Spillovers Into Bitcoin, Ethereum – Benzinga\n\nIves Compares World To Nvidia, Palantir\n\nHe argued that despite the trillions being poured into large language models and data centers, the future of AI will be determined by authentication and identification.\n\nIves compared the current state of the project to where Nvidia Corp. (NASDAQ:NVDA) and Palantir Technologies Inc. (NASDAQ:PLTR) were in 2022, suggesting a similar trajectory of growth and influence.\n\nEightCo raised $250 million through a private placement to adopt WLD as its primary treasury reserve asset.\n\nTom Lee-led Bitmine Immersion Technologies Inc. (AMEX:BMNR) also disclosed a $20 million investment into the company as the first \"Moonshot\" initiative in its Ethereum (CRYPTO: ETH) ecosystem expansion plan.\n\nWorld’s Privacy Concerns\n\nWorld, formerly Worldcoin, co-founded by OpenAI CEO Sam Altman, is an identity verification project that captures people’s irises to confirm their humanness and build a digital ID, allowing them to receive free WLD tokens. However, it has courted controversy over personal data privacy concerns and is currently outlawed in Hong Kong, Kenya, and Spain. The project debuted in the U.S. earlier this year.\n\nTo address the privacy concerns, World implemented a personal custody feature that ensures users' data remains on their devices and not with World or any third party.\n\nPrice Action: At the time of writing, WLD was exchanging hands at $1.68, up 45% in the last 24 hours, according to data from Benzinga Pro. Shares of Eightco fell 5.94% in after-hours trading after exploding 3008.97% to $45.08 during the regular trading session.\n\nAs of this writing, the stock demonstrated a moderately high Momentum score. Visit Benzinga Edge Stock Rankings to compare it with how BitMine, the world’s biggest ETH treasury company.\n\n\n\nLoading... Loading...\n\nRead Next:\n\nPhoto Courtesy: CryptoFX on Shutterstock.com\n\nDisclaimer: This content was partially produced with the help of Benzinga Neuro and was reviewed and published by Benzinga editors.",
      "source": "Benzinga",
      "url": "https://www.benzinga.com/crypto/cryptocurrency/25/09/47562367/eightco-chair-dan-ives-calls-sam-altmans-world-project-the-intersection-of-ai-and-crypto-compares-it-to-nvidia-palantir",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "CoreWeave Shares Gain 4.5% After Launch of VC Arm Targeting AI Startups",
      "content": "Shares of CoreWeave (CRWV) rose as much as 9% on Monday morning after the company announced it’s launching a venture capital arm focused on early-stage artificial intelligence startups.\n\nThe stock was higher by 4.5% as midday U.S. hours approached..\n\nSTORY CONTINUES BELOW Don't miss another story. Subscribe to the Crypto Daybook Americas Newsletter today . See all newsletters Sign me up By signing up, you will receive emails about CoinDesk products and you agree to our terms of use and privacy policy .\n\nThe new fund, called CoreWeave Ventures, will focus on investing in startups building tools, infrastructure or applications for AI. The company didn’t disclose how much capital would be committed but framed the effort as an extension of its broader mission to support high-performance computing for machine learning and generative AI.\n\n“Our aim with CoreWeave Ventures is to give other audacious, like-minded founders the support they need to drive technical advancements and bring to market the next class of innovation,” said Brannin McBee, co-founder and chief development officer at CoreWeave.\n\nCoreWeave specializes in cloud computing optimized for AI workloads, offering access to Nvidia GPUs and fast storage to clients ranging from large enterprises to research labs. It went public earlier this year at $40 per share and surged to a high of $187 in June before pulling back.\n\nThe launch of CoreWeave Ventures comes during a busy period for cloud infrastructure firms focused on AI. On Monday, Nebius, another player in the “neocloud” space, signed a five-year, $19.4 billion agreement with Microsoft to supply computing power. That announcement sent several AI and data center stocks higher, adding momentum to the sector.\n\nCoreWeave is also in the process of acquiring bitcoin miner Core Scientific (CORZ) in a $9 billion all-stock deal. The merger, announced in July, is still subject to shareholder and regulatory approvals.\n\nFor AI startups, the arrival of another specialized investor could offer an alternative to generalist VC firms or hyperscaler-linked capital. And for CoreWeave, it’s a chance to bet on the ecosystem it helps power — and maybe get early access to the next breakthrough.\n\n\n\n\n\n",
      "source": "CoinDesk",
      "url": "https://www.coindesk.com/markets/2025/09/09/coreweave-shares-rise-after-launch-of-vc-arm-targeting-ai-startups",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Synopsys reports quarterly revenue below estimates, shares fall",
      "content": "(Reuters) -Chip design software provider Synopsys (SNPS) missed Wall Street estimates for third-quarter revenue on Tuesday, hurt by weakness in its Design IP business, sending shares down 20% in premarket trading on Wednesday.\n\nThe segment includes Synopsys' interface, security and embedded processor intellectual property, along with IP implementation services.\n\nThe underperformance in the segment was caused by deals that did not materialize, largely due to new export restrictions disrupting design starts in China and challenges at a major foundry customer, CEO Sassine Ghazi said on a post-earnings call.\n\nIn early July, the United States lifted restrictions on exports to China for chip design software developers, which had been imposed in late May.\n\nSynopsys had made significant investments in building out IP for the foundry customer, with expectations for returns in the second half of 2025, Ghazi said on the call. However, the customer pulled out due to market and client-related reasons.\n\nSynopsys, which counts companies such as Nvidia, Intel and Qualcomm among its partners, provides software and hardware used to design advanced processors.\n\nSunnyvale, California-based Synopsys completed its $35 billion cash-and-stock acquisition of engineering design firm Ansys in July, after receiving conditional approval from China's market regulator. The deal, announced early last year, faced intense antitrust scrutiny in markets including Britain.\n\nThe company reported revenue of $1.74 billion for the third quarter ended July 31, missing analysts' estimates of $1.77 billion, according to data compiled by LSEG.\n\nOn an adjusted basis, Synopsys reported a profit of $3.39 per share, also below estimates of $3.74 per share.\n\nSynopsys projected current-quarter revenue between $2.23 billion and $2.26 billion, while analysts expect $2.09 billion.\n\nRival Cadence Design Systems raised its annual sales and profit forecast in July.\n\n(Reporting by Juby Babu in Mexico City; Editing by Mohammed Safi Shamsi)",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/synopsys-reports-quarterly-revenue-below-233110633.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia-backed AI stock pulls off jaw-dropping deal",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/technology/this-nvidia-backed-ai-stock-just-pulled-off-a-jaw-dropping-play-",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "NVIDIA Unveils \"Rubin CPX\" GPU: Single-Die, 30 PetaFLOPS, and 128 GB of GDDR7 Memory",
      "content": "During the AI Infra Summit, NVIDIA announced the \"Rubin CPX\" GPU, a specialized accelerator derived from the upcoming \"Rubin\" family, specifically made for massive-context AI models. The chip delivers 30 PetaFLOPS of NVFP4 compute performance on a monolithic die, accompanied by 128 GB of GDDR7 memory. The monolithic die configuration represents a departure from the dual-GPU packages characteristic of NVIDIA's current Blackwell and Blackwell Ultra architectures, as well as the design path that the rest of the Rubin family will follow. The Rubin CPX addresses computational bottlenecks in extended-context scenarios where AI models process millions of tokens simultaneously. This capability proves critical for applications including comprehensive software codebase analysis and hour-long video content processing, which can require up to one million tokens.The processor integrates four NVENC and four NVDEC video encoders directly on-chip, enabling streamlined multimedia workflows without external processing dependencies. Performance metrics suggest that the Rubin CPX is delivering three times the attention processing speed of NVIDIA's current best GB300 Blackwell Ultra accelerator systems. The architecture employs a cost-optimized single-die approach, rather than multi-chip modules, which potentially reduces manufacturing complexity while maintaining computational density. Memory bandwidth specifications remain undisclosed, though a 512-bit interface could yield approximately 1.8 TB/s throughput when using 30 Gbps GDDR7 memory chips. NVIDIA plans integration of Rubin CPX processors within the Vera Rubin NVL144 CPX platform, which combines traditional Rubin GPUs with the specialized CPX variants. This hybrid configuration targets 8 ExaFLOPS of aggregate compute performance, with 1.7 PB/s of memory bandwidth, across a complete rack deployment. The \"Kyber\" rack will include ConnectX-9 network adapters capable of 1600G networking, Spectrum6 doing 102.4T switching, as well as co-packaged optics. NVIDIA plans this to arrive in late 2026, after the regular Rubin GPU launch in early 2026.NVIDIA pushes Rubin CPX as a one-off in the Rubin family to address the complexity of inferencing a test-time scaling AI system. As models evolve beyond simple text generation toward sophisticated reasoning systems, inference operations increasingly split between computationally intensive context processing and memory-bandwidth-dependent token generation phases. The CPX design optimizes for these dual requirements through its dedicated architecture, handling context prefill operations that can span enterprise chatbot sessions with 256,000 tokens or comprehensive code analysis exceeding 100,000 lines. This specialization becomes critical as AI systems transition from basic language models to multistep reasoning agents that maintain persistent memory across extended interactions. Hence, all of that needs to be enabled by hardware, and NVIDIA wants to make it a seamless experience for developers.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340818/nvidia-unveils-rubin-cpx-gpu-single-die-30-petaflops-and-128-gb-of-gddr7-memory",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia unveils AI chips for video, software generation",
      "content": "Nvidia said on Tuesday it would launch a new artificial intelligence chip by the end of next year, designed to handle complex functions such as creating videos and software.\n\nThe chips, dubbed \"Rubin CPX\", will be built on Nvidia's next-generation Rubin architecture — the successor to its latest \"Blackwell\" technology that marked the company's foray into providing larger processing systems.\n\nAs AI systems grow more sophisticated, tackling data-heavy tasks such as \"vibe coding\" or AI-assisted code generation and video generation, the industry's processing needs are intensifying.\n\nAI models can take up to 1 million tokens to process an hour of video content — a challenging feat for traditional GPUs, the company said. Tokens refer to the units of data processed by an AI model.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nTo remedy this, Nvidia will integrate various steps of the drawn-out processing sequence such as video decoding, encoding, and inference — when AI models produce an output — together into its new chip.\n\nInvesting $100 million in these new systems could help generate $5 billion in token revenue, the company said, as Wall Street increasingly focuses on the return from pouring hundreds of billions of dollars into AI hardware.\n\nThe race to develop the most sophisticated AI systems has made Nvidia the world's most valuable company, commanding a dominant share of the AI chip market with its pricey, top-of-the-line processors.",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/business/nvidia-unveils-ai-chips-video-software-generation-5340646",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Takeaways from AP's investigation into how US tech companies enabled China's digital police state",
      "content": "BEIJING (AP) — Across China, tens of thousands of people tagged as troublemakers are trapped in a digital cage, barred from leaving their province and sometimes even their homes by the world’s largest digital surveillance apparatus. Most of this technology came from companies in a country that has long claimed to support freedoms worldwide: the United States.\n\nOver the past quarter century, American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warnings from the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nMost of the companies that responded said they fully complied with all laws, sanctions and U.S. export controls governing business in China, past and present. Here are key findings:\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAmerica brought ‘predicative policing’ to China\n\nU.S. companies introduced systems that mine a vast array of information — texts, calls, payments, flights, video, DNA swabs, mail deliveries, the internet, even water and power use — to unearth individuals deemed suspicious and predict their movements. But this technology also allows Chinese police to threaten friends and family and preemptively detain people for crimes they have not even committed. The AP found a Chinese defense contractor, Huadi, worked with IBM in 2009 to design the main policing system for Beijing to censor the internet and crack down on alleged terrorists, the Falun Gong religious sect, and even villagers deemed troublesome. IBM referred to any possible relationship it may have had with Chinese government agencies as “old, stale interactions”: “ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.” Huadi did not respond.\n\nUS tech enabled the Xinjiang crackdown\n\nAmerican surveillance technologies allowed a brutal mass detention campaign in the far west region of Xinjiang — targeting, tracking and grading virtually the entire native Uyghur population to forcibly assimilate and subdue them. IBM agents in China sold its i2 software to the Xinjiang police, China’s Ministry of State Security, and many other Chinese police units throughout the 2010s, leaked emails show. One agent, Landasoft, subsequently copied and deployed it as the basis for a predictive policing platform that tagged hundreds of thousands of people as potential terrorists. IBM said it has no record of its i2 software ever being sold to the Public Security Bureau in Xinjiang, was not aware of any interaction between Landasoft and that bureau and cut ties with Landasoft in 2014. Landasoft did not respond.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome tech companies even specifically addressed race in their marketing. Dell and a Chinese surveillance firm promoted a “military-grade” AI-powered laptop with “all-race recognition” on its official WeChat account in 2019. And until contacted by AP in August, biotech giant Thermo Fisher Scientific’s website marketed DNA kits to the Chinese police as “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans.” The Xinjiang government said that it uses surveillance technologies to prevent terrorism, and that Western countries also use such technology, calling the U.S. “a true surveillance state.”\n\nCompanies pitched tech to control citizens\n\nThough the companies often claim they aren’t responsible for how their products are used, some directly pitched their tech as tools for Chinese police to control citizens, marketing materials from IBM, Dell, Cisco, and Seagate show. Their sales pitches — made both publicly and privately — cited Communist Party catchphrases on crushing protest, including “stability maintenance,” “key persons,” and “abnormal gatherings,” and named programs that stifle dissent, such as “Internet Police,” “Sharp Eyes” and the “Golden Shield.” IBM, Dell, Cisco and Seagate said they adhere to all relevant laws.\n\nAmerican tech laid the foundation for Chinese surveillance\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAmerican technology laid the foundation for China’s surveillance apparatus that Chinese companies have since built on and in some cases replaced. Intel and Nvidia helped China’s three biggest surveillance companies make their camera systems AI-powered. Contracts to maintain existing IBM, Dell, HP, Cisco, Oracle, and Microsoft software and gear remain ubiquitous, often with third parties. And to this day, concerns remain over where technology sold to China will end up, with former U.S. officials and national security experts criticizing a deal struck this summer for Nvidia to sell chips used in artificial intelligence to China, saying the technology would fall into the hands of the Chinese military and intelligence. Nvidia said in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk, but told the AP those relationships no longer continue. Nvidia said it does not make surveillance systems or software, does not work with police in China and has not designed the H20 chips for police surveillance, and the White House and Department of Commerce did not respond to requests for comment.\n\nBig loopholes in sanctions remain\n\nSome U.S. companies ended contracts in China over rights concerns and after sanctions. IBM said it has prohibited sales to Tibet and Xinjiang police since 2015, and suspended business relations with defense contractor Huadi in 2019. Nvidia and Intel also ended partnerships with China’s top two surveillance companies in 2019. However, sanctions experts noted that the laws have significant loopholes and often lag behind new developments. For example, a ban on military and policing gear to China after the 1989 Tiananmen massacre does not take into account newer technologies or general-use products that can be applied in policing. They also noted that the law around export controls is complicated.\n\nA cautionary tale\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nWhat started in China more than a decade ago could be seen as a cautionary tale for other countries at a time when the use of surveillance technology worldwide is rising sharply, including in the United States. Emboldened by the Trump administration, U.S. tech companies are more powerful than ever, and President Donald Trump has rolled back a Biden-era executive order meant to safeguard civil rights from new surveillance technologies. As the capacity and sophistication of such technologies has grown, so has their reach. Surveillance technologies now include AI systems that help track and detain migrants in the U.S. and identify people to kill in the Israel-Hamas war. China, in the meantime, has used what it learned from the U.S. to turn itself into a surveillance superpower, selling technologies to countries like Iran and Russia.\n\n“Because of this technology … we have no freedom at all,” said Yang Caiying, now in exile in Japan, whose family has been trapped in an increasingly tight noose of surveillance for the past 16 years. “At the moment, it’s us Chinese that are suffering the consequences, but sooner or later, Americans and others, too, will lose their freedoms.”\n\n__\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/takeaways-aps-investigation-us-tech-043117960.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "(PR) NVIDIA RTX Remix Update Introduces Advanced Path-Traced Particle System",
      "content": "Many classic PC games remain beloved for their unforgettable stories, characters, and gameplay. But as technology advances, their visuals struggle to keep up, making it harder for the original gamers who played them, or new generations, to appreciate their magic. NVIDIA RTX Remix, a modding platform for RTX AI PCs, was built to change that. By reimagining the graphics of these timeless classics with cutting-edge path tracing, we're allowing longtime fans to relive their favorite adventures in stunning detail, while introducing a new wave of players to the games that defined an era.Today, we've released a new RTX Remix update through NVIDIA app, adding an advanced particle system that enables modders to enhance traditional fire and smoke effects, as well as more fantastical effects, like those in Portal. Check out our official documentation to see the full release notes.In RTX Remix, legacy particles from a classic game could be interpreted as path-traced, enabling them to cast realistic light, enhancing the appearance of many scenes. But ultimately, these particles were still over 20 years old, lacking detail, flair, and fluid animations.Now, modders can create brand new particles in Remix that match the look of those found in modern titles. This opens the door for over 165 RTX Remix compatible games to have advanced particle effects for the first time, and we can't wait to see all the ways modders dazzle gamers with realistic and spectacular effects.RTX Remix particles are GPU-driven, meaning you can add tens of thousands of them without significantly reducing performance. They are path-traced, meaning they cast accurate shadows, and are reflected in the world-a rarity in games. Additionally, they feature a realistic physics simulation, complete with proper collisions with the environment. All of these elements together give modders a chance to make breathtaking VFX. As an example, we've designated the Antlion Guard from Half-Life 2 RTX as a particle emitter. Over 100,000 shadowed particles are performantly rendered, and as the Antlion Guard moves, the physics of each particle is accurately reflected and affected.In the clip below, you can see how the fire in Half-Life 2 RTX can be elevated to look more natural and realistic through the use of advanced particles, with smoke billowing from the tips, and embers sparking and floating through the air:These effects can be tuned dramatically, giving modders many ways to channel their creativity. For example, here are three vastly different interpretations of the high energy pellet from Portal with RTX:And best of all, RTX Remix lets you add particles into your scene instantly while you play - it's instantaneous and a whole lot of fun.Adding RTX Remix particles is fast and easy. Simply open the Alt+X RTX Remix Developer Menu while in-game, navigate to the Games Setup > Categorize Textures tab, and select any game element, be that a fire effect, character, or malfunctioning light-from there, simply select \"particle emitters\" to see particles spawn. On the \"Rendering tab\", adjust the size of the effect, the number of particles spawned, the color, and other fields to achieve the perfect look - it's as easy as that!For more serious modders, we recommend building your particles in the RTX Remix Toolkit, which offers a lot more control. For a complete breakdown of all the new particle options, check out the release notes, and head over to the RTX Remix developer manual.Since its initial release, the RTX Remix modding community has grown to 237 active projects, with over 100 RTX Remix mods released. They span a catalog of beloved games like Half-Life 2, Need for Speed Underground,Portal 2 and Deus Ex, boasting over 2 million downloads.Recently, we asked the community to make new mods and enhance their existing work in our RTX Remix Mod Contest. The mods created were phenomenal, and ultimately we awarded $60,000 in cash prizes to the developers of Painkiller RTX Remix, Vampire The Masquerade: Bloodlines - RTX Remaster, I-Ninja Remixed, and Call of Duty 2 RTX Remix of Carentan. Head to our contest article to learn more, and to download the mods.As a modder plays through a classic game with RTX Remix, textures, models, lighting, effects, and more can all be captured, and reassembled into an editable scene. Through an intuitive interface, the RTX Remix application lets modders drag and drop lights, recreate every object and material to modern standards, copy-paste existing objects into a scene to increase clutter and grass coverage, convert lights to be fully ray-traced, AI enhance textures, and add DLSS 4 to improve image quality and accelerate performance.To make your own RTX mods, download NVIDIA RTX Remix from the Home screen of NVIDIA app. And grab the Half-Life 2 RTX demo or Portal with RTX from Steam for an example of what's possible with the latest RTX Remix upgrades.NVIDIA RTX Remix requires a GeForce RTX GPU to create RTX Remix Mods, while mods and games built using Remix are compatible with any hardware that can run Vulkan ray-traced games.To find RTX Remix mods to download and play, we recommend ModDB and the RTX Remix Showcase Discord server.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340816/nvidia-rtx-remix-update-introduces-advanced-path-traced-particle-system",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 \"Battlemage\" Nears Launch as Intel Prepares Packaging",
      "content": "Intel plans to complete its Arc \"Battlemage\" lineup with the highest-performing B770 SKU. Thanks to @Haze2K1 on X, we found shipping manifests dated June 11, 2025, which list BMG-G31 GPU dies packed in boxes with dimensions matching those used before the Arc B580 launch. Last time with B580, the launch happened 2.5 months after these shipping manifests appeared. The current rumor mill suggests that the card will utilize 32 Xe2 cores with 16 GB of memory on a 256-bit bus, providing it with a clear capacity edge over many 8 GB rivals from AMD and NVIDIA, like the RTX 5060 Ti and RX 9060. The BMG-G31 die is bigger than the BMG-G21 used in the B580, B570, and Arc Pro parts, which explains the larger crates. Extra silicon could enable higher clocks, stronger ray tracing, and a wider memory interface, though thermal management and power draw will matter. Early samples and firmware checks will set the final timing and availability soon.Timing will determine how much impact the Arc B770 can have, because AMD and NVIDIA already control much of the upper mid-range and high-end segments. NVIDIA \"SUPER\" refreshes of the current \"Blackwell\" only raise the pressure on Intel to be both performance competitive and well priced. Battlemage has already shifted pricing expectations in the market before, compelling rivals to rethink memory configurations and price points. Intel has also shown steady improvement in its driver updates and software support, which has narrowed historical gaps in user experience. Rumors pointing to a Q4 2025 debut would put the card into the usual holiday buying window, but to convert gamer's interest into real market share, Intel will need an aggressive pricing strategy and solid supply.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340802/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "China's first open AI computing architecture: Sugon, Lenovo, Moore Threads comes together to challenge Nvidia CUDA",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250909PD213/cuda-nvidia-launch-lenovo-moore-threads.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Detailed findings from AP investigation into how US tech firms enabled China's digital police state",
      "content": "BEIJING (AP) — American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warningsfrom the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nThe AP investigation was based on tens of thousands of leaked emails and databases from a Chinese surveillance company; thousands of pages of confidential corporate and government documents; public Chinese language marketing material; and thousands of procurements, many provided by ChinaFile, a digital magazine published by the non-profit Asia Society. The AP also drew from dozens of open record requests and interviews with more than 100 current and former Chinese and American engineers, executives, experts, officials, administrators, and police officers.\n\nAmerican tech firms were by far the biggest suppliers, but German, Japanese, and Korean firms also had a role. Here are some examples:\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nMILITARY ACCESS: A Chinese military contractor worked with Armonk, New York-based IBM in 2009 to design national intelligence systems, including a counterterrorism system, according to classified Chinese government documents. These systems were used by China’s secret police, the Ministry of State Security, and the Chinese military. IBM referred to any such deals as “old, stale interactions”: “ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.”\n\nANTI-TERROR ANALYSIS: IBM agents in China sold IBM’s i2 policing analysis software to the Xinjiang police, China’s Ministry of State Security, and other Chinese police units throughout the 2010s, leaked emails show. i2 software was subsequently copied and deployed by one former IBM agent, Landasoft, as the basis for a predictive policing platform that tagged hundreds of thousands of people as potential terrorists during a brutal crackdown in China’s far west Xinjiang region. IBM says it ceased relations with Landasoft in 2014, prohibited sales to police in Xinjiang and Tibet since 2015, and has no record of any sales of i2 software to the Public Security Bureau in Xinjiang.\n\nETHNIC REPRESSION: Dell and then-subsidiary VMWare sold cloud software and storage devices to police and entities providing data to police in Tibet and Xinjiang, even as late as 2022 after ethnic repression there was widely known. Dell addressed race in its marketing: In 2019, Dell said on WeChat it had teamed up with surveillance firm Yitu to sell a “military-grade” AI-powered laptop for Chinese police with “all-race recognition.” Dell, based in Round Rock, Texas, told AP it conducts “rigorous due diligence” to ensure compliance with U.S. export controls. Chinese policing systems, including in Xinjiang, also used software from Oracle, based in Austin, Texas, and from Microsoft, based in Seattle, according to procurements and a leaked database obtained by AP.\n\nFINGERPRINT RECOGNITION: Chinese defense contractor Huadi worked with IBM to construct China’s national fingerprint database; IBM said it never sold “fingerprinting-specific” products to the Chinese government and that any possible misuse “for fingerprinting purposes” was done without its knowledge or assistance. HP and VMWare sold technology used for fingerprint comparison by Chinese police. Intel said in 2019 marketing material that it partnered with Hisign, a Chinese fingerprinting company that sold to Xinjiang police, to make their fingerprint readers more effective, and that the new reader was “fully tested in an actual application scenario” with a municipal police bureau. Hisign was still an Intel partner as of last year, according to Chinese media reports. California-based Intel said it has not had any technical engagement with Hisign since 2024, and told AP it would “act swiftly” if it became aware of any “credible misuse.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAI CAMERAS: IBM, Dell, Tokyo-based Hitachi, and VMWare promoted facial recognition for use by Chinese police. Japanese electronics giant Sony said on its official WeChat account that it wired a Chinese prison with “intelligent” cameras, saying it was widely trusted for “surveillance projects.” California chip giant Nvidia and Intel partnered with China’s three biggest surveillance companies to add AI capabilities to camera systems used for video surveillance across China, including in Xinjiang and Tibet, until sanctions were imposed. Relations with other Chinese surveillance companies continued more recently: Nvidia posted on its WeChat social media account in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk. Nvidia told AP those relationships no longer continue.\n\nSURVEILLANCE RESEARCH: Nvidia, IBM, and Hitachi staff collaborated with Chinese police researchers and companies on surveillance technology. Nvidia said in a post dating to 2013 or later that a Chinese police institute used its chips for surveillance technology research. Nvidia said it doesn’t currently work with Chinese police but did not address the past. And in 2021, an IBM and a U.S. Army researcher coauthored an AI video study with a Chinese police researcher working at a sanctioned company, according to a paper unearthed by IPVM, a surveillance research publication. The U.S. Army told AP the Chinese police researcher only worked on the paper after the Army researcher’s work had concluded.\n\nDNA: Chinese police DNA labs bought Dell and Microsoft software and equipment to save genetic data on police databases. In 2021, Hitachi advertised DNA sequencers to Chinese police, and police labs bought pipettes from German biotech firm Eppendorf last year. And until contacted by AP in August, Massachusetts-based biotech firm Thermo Fisher Scientific‘s website stated that its kits are made for China’s national DNA database and “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans,” and featured the work of a Chinese police researcher who discussed using Thermo Fisher kits to identify ethnic Uyghur and Manchu populations at a 2016 conference. Thermo Fisher stopped sales in Xinjiang in 2021 and in Tibet in 2024, but still promotes kits to police elsewhere in China, including at a police trade show earlier this year. In a statement to AP, Thermo Fisher said its kits “are designed to be effective across diverse global populations” but “do not have the capability to distinguish among specific ethnic groups.”\n\nINTERNET POLICE: In 2014, VMWare said internet police in cities across China used its software, and in 2016, Dell said on its WeChat account that its services assisted the Chinese internet police in “cracking down on rumormongers” — essentially promoting censorship. An undated IBM marketing presentation said that internet police in Shanghai and Guangzhou used its i2 software, with metadata suggesting it was from 2018. IBM held a conference in Beijing promoting i2 in 2018, according to its official WeChat account.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nENCRYPTION TECHNOLOGY: Leaked government blueprints show Illinois-based Motorola provided encrypted radio communications technology to the Chinese police for handling “sudden and mass events in Beijing.” Motorola did not respond to requests for comment.\n\nAI DRIVES: Californian hard disk giants Seagate and Western Digital and Tokyo-based Toshiba sell hard drives specialized for AI video systems for use by Chinese police. In 2022, Toshiba wrote about how its surveillance hard drives can help police monitor communities to “identify and control suspicious” or “blacklisted” individuals. “They’re optimized and adapted for security systems,” Toshiba sales director Feng Hao told AP. Last year, Western Digital touted its partnership with Chinese surveillance company Uniview at a policing trade expo, months before Uniview was sanctioned over complicity in rights abuses. And Seagate said on WeChat in 2022 that it sells hard drives “tailor made” for AI video systems in China for use by police to help them ”control key persons,” and promoted their drives to police at a security trade association in China this year.\n\nMAPPING SOFTWARE: Blueprints show that in 2009, IBM, Oracle, and Esri, the creator of ArcGIS based in California, sold hundreds of thousands of dollars’ worth of software to build China’s Police Geographic Information System, and in 2013, HP said it sold “digital fencing” solutions to Chinese police. Such systems alert Chinese police even today when Uyghurs, Tibetans or dissidents stray out of provinces, counties or even villages. The U.S. curbed exports of such mapping software to China in 2020. But the restrictions are narrow in scope, and Esri maintains a research center in Beijing that marketed to police and other Chinese clients. Esri denied involvement.\n\nPOLICE GEAR: Chinese police patrol the streets equipped with foreign technology. Officers stroll the streets of Beijing with Motorola walkie-talkies, for example, while Korean electronics giant Samsung sells microSD cards for police body cameras, advertising them at Chinese police trade shows in 2023 and 2024. And in WeChat posts, Chinese state-owned company Jinghua said it cooperated with German electronics giant Philips on China’s first ”AI-powered 5G” police body camera and advertised Philips-branded recorders and cameras to Chinese police. In a statement, Philips said it had no partnership with Jinghua, did not authorize sales of Philips-branded body cameras in China, and would be contacting Jinghua over the posts.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nIBM, Dell, California network seller Cisco, Seattle-based Amazon Web Services, Seagate, Intel, Thermo Fisher and Western Digital all said they adhere to relevant export controls, laws and regulations where they operate. Eppendorf, Sony, and Hitachi declined to describe their business relationships in China but said they respected human rights.\n\nOracle, Hewlett Packard Enterprise, and California tech conglomerate Broadcom, which acquired VMWare in 2023, did not comment on the record. HP, Motorola, Samsung, Toshiba, Huadi, and Landasoft did not respond. Microsoft said it did not knowingly provide software for updates to China’s main policing system.\n\nThe Xinjiang government said in a statement that it uses surveillance technologies to “prevent and combat terrorist and criminal activity” and does not target any particular ethnicity. The statement said Western countries also use such technology, calling the U.S. “a true surveillance state.” Other government agencies did not respond to a request for comment.\n\n__\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/detailed-findings-ap-investigation-us-043012321.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "SailPoint CEO: AI agents promise big gains — and big risks",
      "content": "AI agents are here — and they could be a blessing and a curse.\n\n\"It's the classic double-edged sword of technology,\" SailPoint (SAIL) CEO Mark McClain told Yahoo Finance's Executive Editor Brian Sozzi at Goldman Sachs' Communacopia + Technology Conference.\n\n\"People are rapidly wanting to deploy agents as a way to enhance the productivity, effectiveness, efficiency ... on their business. But they're increasingly cognizant of the risk,\" he said.\n\nThe risk comes down to visibility and control. While AI-driven agents can automate workflows and even generate subagents, they raise questions about accountability.\n\n\"You have to always ensure that there's some person in the organization that's taking responsibility for that [agent],\" McClain said.\n\nMcClain's comments come as SailPoint, an identity security developer, works to position itself at the center of the AI wave. It specializes in securing machine identities and managing access for companies like Home Depot (HD).\n\nThe company recently raised its full-year outlook despite short-term stock pressure tied to its third quarter guidance. SailPoint stock was down over 8% during Tuesday afternoon trading. Year to date, shares have fallen 7%.\n\nMcClain noted that SailPoint is working in tandem with firms like CrowdStrike (CRWD), calling the company \"complementary to us,\" as it focuses on device-level security.\n\nHowever, McClain downplayed the idea that automation will replace entire workforces. \"I think they're going to leverage this technology to make their people better and more effective, far more than they're going to just replace people,\" he said.\n\nSailPoint began trading on Feb. 13 on the Nasdaq. The company priced its initial public offering (IPO) at the top end of its targeted range of $21 to $23, raising $1.38 billion in proceeds.\n\nThe stock closed its first day of trading at $22 per share and hit a closing high of $25.70 on Feb. 16. It was the first big test of the tech IPO market in 2025. Since then, several other buzzy IPOs came to market, including Nvidia (NVDA) chip consumer CoreWeave (CRWV), trading platform eToro (ETOR), and software play Figma (FIG).\n\n\"We see an opportunity with SAIL to own a best-of-breed vendor at a discount as Identity continues to move up the priority stack. We have seen significant share shift across the Identity landscape in the wake of an 'identity crisis' legacy vendors face as they have not efficiently invested in their platforms to address Identity related risk that is poised to accelerate,\" JPMorgan analyst Brian Essex wrote in a note.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/sailpoint-ceo-ai-agents-promise-big-gains--and-big-risks-162015066.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia Unveils Rubin CPX: A New AI Chip System for Video and Software Creation",
      "content": null,
      "source": "Patently Apple",
      "url": "https://www.patentlyapple.com/2025/09/nvidia-unveils-rubin-cpx-a-new-ai-chip-system-for-video-and-software-creation.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "ASML Invests Billions In Nvidia-Backed Mistral AI To Power Next Era Of Semiconductors",
      "content": "ASML Holding (NASDAQ:ASML) and France-based Mistral AI announced a strategic partnership on Tuesday that combines semiconductor manufacturing expertise with frontier artificial intelligence capabilities to accelerate innovation across the semiconductor and AI value chain.\n\nASML said it will apply Mistral’s AI models throughout its product portfolio and R&D operations to deliver faster time-to-market and higher-performance holistic lithography systems for its customers.\n\nTo cement the collaboration, ASML is investing 1.3 billion euros as the lead investor in Mistral AI’s Series C funding round, acquiring an 11% stake on a fully diluted basis.\n\nAlso Read: ASML Explores India As Geopolitical Risks Threaten China Business\n\nASML CEO Christophe Fouquet said the agreement moves beyond a traditional vendor-client relationship, creating opportunities for joint research and AI-enabled product innovation.\n\nMistral AI CEO Arthur Mensch said the partnership blends ASML’s industrial leadership with Mistral’s frontier AI expertise. ASML will gain a seat on Mistral AI’s Strategic Committee as part of the deal, with CFO Roger Dassen appointed to represent the company.\n\nASML stock has climbed 15% so far in 2025, outpacing the Nasdaq 100 Index’s gain of just over 13%. The performance reflects sustained demand for its extreme ultraviolet lithography machines, the cornerstone of advanced semiconductor production and a critical enabler of the current AI-driven chip boom.\n\nRecent reports indicate that ASML is becoming Mistral AI’s largest shareholder after leading its $2 billion Series C funding round.\n\nMistral, often called Europe’s AI champion and backed by Nvidia (NASDAQ:NVDA), competes with U.S. leaders like OpenAI and Alphabet’s (NASDAQ:GOOGL) (NASDAQ:GOOG) Google. ASML’s investment could reduce Europe’s reliance on American and Chinese AI models while boosting its use of AI in chipmaking.\n\nPrice Action: ASML stock is trading higher by 0.04% to 796.60 premarket at last check Tuesday.\n\nRead Next:\n\nImage via Shutterstock\n\nUNLOCKED: 5 NEW TRADES EVERY WEEK. Click now to get top trade ideas daily, plus unlimited access to cutting-edge tools and strategies to gain an edge in the markets.\n\nGet the latest stock analysis from Benzinga?\n\nThis article ASML Invests Billions In Nvidia-Backed Mistral AI To Power Next Era Of Semiconductors originally appeared on Benzinga.com\n\n© 2025 Benzinga.com. Benzinga does not provide investment advice. All rights reserved.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/asml-invests-billions-nvidia-backed-095358773.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia-backed Reflection AI eyes $5.5 billion valuation as AI runs hot, FT reports",
      "content": "Nvidia-backed Reflection AI is raising around $1 billion in a financing that will value the startup at up to $5.5 billion, the Financial Times reported on Tuesday, citing people familiar with the matter.\n\nThe round could value Reflection between $4.5 billion and $5.5 billion, including the new investment, FT added.\n\nThe announcement could potentially mark a nearly 10-fold valuation jump merely six months after the company's previous external fundraising, where it was valued at $545 million, according to PitchBook data.\n\nStartups leveraging artificial intelligence continue to attract investor capital, with the nascent technology even sparking a multi-billion-dollar race for infrastructure build across Big Tech companies.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nNvidia's venture capital arm would invest at least $250 million, the report added. Lightspeed Venture Partners, Sequoia and Yuri Milner's DST Global are also participating in the round.\n\nFounded in 2024 by former Google-backed DeepMind researchers Misha Laskin and Ioannis Antonoglou, Reflection develops tools that automate coding, a highly valuable use case of AI.\n\nThe latest financing also comes amid the bidding war across Silicon Valley sparked by AI talent like Laskin and Antonoglou, with Meta offering salaries and signing bonuses that liken those of professional athletes.",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/business/nvidia-backed-reflection-ai-eyes-55-billion-valuation-ai-runs-hot-ft-reports-5340786",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "NVIDIA Rubin CPX GPU Is Designed For Super AI Tasks Including Million-Token Coding & GenAI, Up To 128 GB GDDR7 Memory, 30 PFLOPs of FP4",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/nvidia-rubin-cpx-gpu-128-gb-gddr7-30-exaflops-ai-compute/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "MicroStrategy’s $71B treasury tops Apple, Tesla as stock slides 26%",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/crypto/investing/microstrategys-71b-treasury-tops-apple-tesla-as-stock-slides-26",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia previews Rubin CPX graphics card for disaggregated inference",
      "content": null,
      "source": "SiliconANGLE News",
      "url": "https://siliconangle.com/2025/09/09/nvidia-previews-rubin-cpx-graphics-card-disaggregated-inference/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Stacy Rasgon’s Prediction About Broadcom (AVGO) Was Right",
      "content": "We recently published Top 10 Analyst Calls on Trending Stocks You Shouldn’t Miss. Broadcom Inc. (NASDAQ:AVGO) is one of the major analyst calls.\n\nStacy Rasgon, Bernstein senior U.S. semiconductor analyst, said in a CNBC program in May that AI demand is “off the charts” and CapEx is not slowing as it was feared. Rasgon liked Broadcom Inc (NASDAQ:AVGO) amid the company’s AI and software exposure:\n\n“Look, I’ve liked the AI names. I felt that whereas for a lot of these other end markets people were really worried about what’s going to happen in the second half and whether demand is real or not, AI demand is real. I also think the AI hardware, if tariffs are implemented, is somewhat insulated because most of the AI servers come into the U.S. through Mexico — they’re USMCA-compliant and tariff-free. So I actually like AI. I like Broadcom Inc (NASDAQ:AVGO)— it has an AI story, and they’ve also got 40% of their revenue from software, which is safe. Their non-AI semis were already at a cyclical low.”\n\nAVGO is up 80% over the past six months. For the fiscal fourth quarter, AVGO expects $6.2 billion in AI revenue, up 66% from a year earlier. The company said it secured $10 billion in AI infrastructure orders from a new customer. Many analysts believe this customer is OpenAI. Some media reports said the two companies co-designed a chip that will be launched next year.\n\nBaron Technology Fund stated the following regarding Broadcom Inc. (NASDAQ:AVGO) in its Q1 2025 investor letter:",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/stacy-rasgon-prediction-broadcom-avgo-212944839.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "YMMV: HP OMEN MAX: 16\" QHD+ 240Hz IPS, Ryzen AI 9 HX 375, RTX 5080, 32GB DDR5, 1TB SSD $1999.99",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired Dr.W posted Item 1 of 2 Item 1 of 2 expired Dr.W posted YMMV: HP OMEN MAX: 16\" QHD+ 240Hz IPS, Ryzen AI 9 HX 375, RTX 5080, 32GB DDR5, 1TB SSD $1999.99 $2,000 $2,400 16% off Micro Center 9 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 5,787 Views Visit Micro Center Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details Available In-store Only at selective stores, YMMV.\n\n\n\nSPECS: AMD Ryzen AI 9 HX 375 (2.0GHz) Processor\n\n32GB DDR5-5600 RAM\n\nNVIDIA GeForce RTX 5080 Graphics Card\n\n1TB PCIe Gen4 NVMe M.2 SSD\n\n16\" WQXGA IPS Anti-Glare Display\n\n2.5Gb LAN, 2x2 WiFi 7 (802.11be), Bluetooth 5.4\n\n5.88 lbs. (2.67 kg)\n\nWindows 11 Home\n\nhttps://www.microcenter .com/produ...-processor Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster Dr.W Follow Give Rep Message 8,032 Deal Posts 11,542 Comments Posts 16,996 Reputation Points 10,806 Votes Submitted Deal Details Community Notes About the Poster Available In-store Only at selective stores, YMMV.\n\n\n\nSPECS: AMD Ryzen AI 9 HX 375 (2.0GHz) Processor\n\n32GB DDR5-5600 RAM\n\nNVIDIA GeForce RTX 5080 Graphics Card\n\n1TB PCIe Gen4 NVMe M.2 SSD\n\n16\" WQXGA IPS Anti-Glare Display\n\n2.5Gb LAN, 2x2 WiFi 7 (802.11be), Bluetooth 5.4\n\n5.88 lbs. (2.67 kg)\n\nWindows 11 Home\n\nhttps://www.microcenter .com/produ...-processor",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18593653-ymmv-hp-omen-max-16-qhd-240hz-ips-ryzen-ai-9-hx-375-rtx-5080-32gb-ddr5-1tb-ssd-1999-99",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Mistral Cements AI Lead In Europe With Cash Infusion",
      "content": null,
      "source": "International Business Times",
      "url": "https://www.ibtimes.com/mistral-cements-ai-lead-europe-cash-infusion-3782885",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "US tech companies enabled the surveillance and detention of hundreds of thousands in China",
      "content": "BEIJING (AP) — The body camera hung from the top of the IV drip, recording the slightest twitch made by Yang Guoliang as he lay bloody and paralyzed in a hospital bed after a police beating with bricks.\n\nBy then, surveillance was nothing new for the Yang family in rural China, snared in an intricate network based on U.S. technology that spies on them and predicts what they’ll do.\n\nTheir train tickets, hotel bookings, purchases, text messages and phone calls are forwarded to the government. Their house is ringed with more than a dozen cameras. They’ve tried to go to Beijing 20 times in the past few years, but masked men show up and grab them, often before they depart. And last year, Yang’s wife and younger daughter were detained and now face trial for disrupting the work of the Chinese state — a crime carrying a sentence of up to a decade in prison.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nYet the Yangs say they are not criminals. They are simply farmers trying to beg Beijing to stop local officials from seizing their 1 1/2 acres of land in China’s eastern Jiangsu province.\n\n“Every move in my own home is monitored,” Yang said, sitting behind black curtains that block him from the glare of police lights trained straight at his house. “Their surveillance makes me feel unsafe all the time, everywhere.”\n\nAcross China, tens of thousands of people tagged as troublemakers like the Yangs are trapped in a digital cage, barred from leaving their province and sometimes even their homes by the world’s largest digital surveillance apparatus. Most of this technology came from companies in a country that has long claimed to support freedoms worldwide: the United States.\n\nOver the past quarter century, American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warningsfrom the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nCritically, American surveillance technologies allowed a brutal mass detention campaign in the far west region of Xinjiang — targeting, tracking and grading virtually the entire native Uyghur population to forcibly assimilate and subdue them.\n\nU.S. companies did this by bringing “predictive policing” to China — technology that sucks in and analyzes data to prevent crime, protests, or terror attacks before they happen. Such systems mine a vast array of information — texts, calls, payments, flights, video, DNA swabs, mail deliveries, the internet, even water and power use — to unearth individuals deemed suspicious and predict their behavior. But they also allow Chinese police to threaten friends and family and preemptively detain people for crimes they have not even committed.\n\nFor example, the AP found a Chinese defense contractor, Huadi, worked with IBM to design the main policing system known as the “Golden Shield” for Beijing to censor the internet and crack down on alleged terrorists, the Falun Gong religious sect, and even villagers deemed troublesome, according to thousands of pages of classified government blueprints taken out of China by a whistleblower, verified by AP and revealed here for the first time. IBM and other companies that responded said they fully complied with all laws, sanctions and U.S. export controls governing business in China, past and present.\n\nAcross China, surveillance systems track blacklisted “key persons,” whose movements are restricted and monitored. In Xinjiang, administrators logged people as high, medium, or low risk, often according to 100-point scores with deductions for factors like growing a beard, being 15 to 55 years old, or just being Uyghur.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome tech companies even specifically addressed race in their marketing. Dell and a Chinese surveillance firm promoted a “military-grade” AI-powered laptop with “all-race recognition” on Dell's official WeChat account in 2019. And until contacted by AP in August, biotech giant Thermo Fisher Scientific’s website marketed DNA kits to the Chinese police as “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans.”\n\nWhile the flood of American technology slowed considerably starting in 2019 after outrage and sanctions over atrocities in Xinjiang, it laid the foundation for China’s surveillance apparatus that Chinese companies have since built on and in some cases replaced. To this day, concerns remain over where technology sold to China will end up.\n\nFor example, 20 former U.S. officials and national security experts wrote a letter in late July criticizing a deal for Nvidia to sell H20 chips used in artificial intelligence to China, with 15% of revenues going to the U.S. government. They said no matter who the chip is sold to, it will fall into the hands of Chinese military and intelligence services.\n\nNvidia said it does not make surveillance systems or software, does not work with police in China and has not designed the H20 for police surveillance. Nvidia posted on its WeChat social media account in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk, but told the AP those relationships no longer continue. The White House and Department of Commerce did not respond to requests for comment.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nThermo Fisher and hard drive maker Seagate promoted their products to Chinese police at conferences and trade shows this year, according to online posts. Officers stroll the streets of Beijing with Motorola walkie talkies. Nvidia and Intel chips remain critical for Chinese policing systems, procurements show. And contracts to maintain existing IBM, Dell, HP, Cisco, Oracle, and Microsoft software and gear remain ubiquitous, often with third parties.\n\nWhat started in China more than a decade ago could be seen as a cautionary tale for other countries at a time when the use of surveillance technology worldwide is rising sharply, including in the United States. Emboldened by the Trump administration, U.S. tech companies are more powerful than ever, and President Donald Trump has rolled back a Biden-era executive order meant to safeguard civil rights from new surveillance technologies.\n\nAs the capacity and sophistication of such technologies has grown, so has their reach. Surveillance technologies now include AI systems that help track and detain migrants in the U.S. and identify people to kill in the Israel-Hamas war. China, in the meantime, has used what it learned from the U.S. to turn itself into a surveillance superpower, selling technologies to countries like Iran and Russia.\n\nThe AP investigation was based on tens of thousands of leaked emails and databases from a Chinese surveillance company; tens of thousands of pages of confidential corporate and government documents; public Chinese language marketing material; and thousands of procurements, many provided by ChinaFile, a digital magazine published by the non-profit Asia Society. The AP also drew from dozens of open record requests and interviews with more than 100 current and former Chinese and American engineers, executives, experts, officials, administrators, and police officers.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nThough the companies often claim they aren’t responsible for how their products are used, some directly pitched their tech as tools for Chinese police to control citizens, marketing material from IBM, Dell, Cisco, and Seagate show. Their sales pitches — made both publicly and privately — cited Communist Party catchphrases on crushing protest, including “stability maintenance,” “key persons,” and “abnormal gatherings,” and named programs that stifle dissent, such as “Internet Police,” “Sharp Eyes” and the “Golden Shield.”\n\nOther companies, like Intel, Nvidia, Oracle, Thermo Fisher, Motorola, Amazon Web Services, Microsoft, Western Digital, creator of mapping software ArcGIS Esri, and what was then Hewlett Packard, or HP, also sold technology or services knowingly to Chinese police or surveillance companies. Four practicing lawyers said sales like those uncovered by AP could potentially go against at least the spirit, if not the letter, of U.S. export laws at the time, which the companies denied.\n\nAmerican technology made up nearly every part of China’s surveillance apparatus, AP found:\n\nMILITARY AND POLICE: In 2009, Chinese defense contractor Huadi worked with IBM to build national intelligence systems, including a counterterrorism system, used by the Chinese military and China’s secret police, the Ministry of State Security. Chinese agents sold IBM’s i2 police surveillance analysis software to the same ministry and to Chinese police, including in Xinjiang, through the 2010s, leaked emails and marketing posts show. IBM said it has no record of its i2 software ever having been sold to the Public Security Bureau in Xinjiang.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSURVEILLANCE: Nvidia and Intel partnered with China’s three biggest surveillance companies to add AI capabilities to camera systems used for video surveillance across China, including Xinjiang and Tibet, until sanctions were imposed. Nvidia said in a post dating to 2013 or later that a Chinese police institute used its chips for surveillance technology research.\n\nETHNIC REPRESSION: IBM, Oracle, HP, and ArcGIS developer Esri sold hundreds of thousands of dollars’ worth of geographic and mapping software to Chinese police that allows officers to detect when blacklisted Uyghurs, Tibetans or dissidents stray out of provinces or villages. As late as 2019, with detentions in Xinjiang well underway, Dell hosted an industry summit in its capital. Dell and then-subsidiary VMWare sold cloud software and storage devices to police and entities providing data to police in Tibet and Xinjiang, even in 2022 after abuses there became widely known.\n\nIDENTIFICATION: Huadi worked with IBM to construct China’s national fingerprint database; IBM told AP it never sold “fingerprinting-specific product or technology” to the Chinese government “in violation of US law.” HP and VMWare sold technology used for fingerprint comparison by Chinese police, while Intel partnered with a Chinese fingerprinting company to make their devices more effective. IBM, Dell, and VMWare also promoted facial recognition to Chinese police. China’s police and police DNA labs bought Dell and Microsoft software and equipment to save genetic data on police databases.\n\nCENSORSHIP AND CONTROL: In 2016, Dell boasted on its WeChat account that its services assisted the Chinese internet police in “cracking down on rumormongers.” Seagate said on WeChat in 2022 that it sells hard drives “tailor made” for AI video systems in China for use by police to help them ”control key persons,” despite facing backlash for selling drives in Xinjiang.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nFor extended findings, click here.\n\n“Everything was built on American tech,” said Valentin Weber, a researcher at the German Council on Foreign Relations who studied the use of U.S. tech by Chinese police. “China’s capability was close to zero.”\n\nIBM, Dell, Cisco, Intel, Thermo Fisher and Amazon Web Services all said they adhere to export control policies. Seagate and Western Digital said they adhere to all relevant laws and regulations where they operate.\n\nOracle, Hewlett Packard Enterprise, and tech conglomerate Broadcom, which acquired VMWare and cloud company Pivotal in 2023, did not comment on the record; HP, Motorola and Huadi did not respond, and Esri denied involvement but did not reply to examples. Microsoft told AP it found no evidence that it “knowingly sold technology to the military or police” as part of updates to the “Golden Shield.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome U.S. companies ended contracts in China over rights concerns and after sanctions. For example, IBM said it has prohibited sales to Tibet and Xinjiang police since 2015, and suspended business relations with defense contractor Huadi in 2019.\n\nHowever, sanctions experts noted that the laws have significant loopholes and often lag behind new developments. For example, a ban on military and policing gear to China after the 1989 Tiananmen massacre does not take into account newer technologies or general-use products that can be applied in policing.\n\nThey also noted that the law around export controls is complicated. Raj Bhala, an expert in international trade law at the University of Kansas, said the issues the AP described fell into “the kind of gray area that we put in exams.”\n\n“It would raise concerns about possible inconsistencies, possible violations,” said Bhala, who emphasized he was speaking generally and not about any specific company. “But I really stress ‘possible.’ We need to know more facts.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nWhile German, Japanese and Korean firms also played a role, American tech firms were by far the biggest suppliers.\n\nThe Xinjiang government said in a statement that it uses surveillance technologies to “prevent and combat terrorist and criminal activity,” that it respects citizens’ privacy and legal rights and that it does not target any particular ethnicity. The statement said Western countries also use such technology, calling the U.S. “a true surveillance state.” Other government agencies did not respond to a request for comment, including China’s police and authorities in the Yangs’ province.\n\nThis technology still powers the police database that controls the Yangs and other ordinary people. An estimate based on Chinese government statistics found at least 55,000 to 110,000 were put under residential surveillance in the past decade, and vast numbers are restricted from travel in Xinjiang and Tibet. China’s cities, roads and villages are now studded with more cameras than the rest of the world combined, analysts say — one for every two people.\n\n“Because of this technology … we have no freedom at all,” said Yang Guoliang’s elder daughter, Yang Caiying, now in exile in Japan. “At the moment, it’s us Chinese that are suffering the consequences, but sooner or later, Americans and others, too, will lose their freedoms.”\n\nSelling surveillance superpowers\n\nBack when China was emerging from the chaotic violence of the Cultural Revolution in 1976, three in four Chinese were farmers, including the Yangs. They lived in a three-room home of tiles and pounded earth nestled among the lush, humid fields of the Yangtze River delta.\n\nAfter Chairman Mao Zedong’s death that year, Beijing’s new leaders opened China to the world, and American tech firms like HP and IBM rushed in. But there were hard limits on how much change the government would accept. In 1989, the Tiananmen pro-democracy protests rattled Beijing, which sent tanks and troops to shoot students.\n\nSoon after, Beijing began planning the “Golden Shield,” aimed at digitizing China’s police force.\n\nIn 2001, the 9/11 al-Qaida attacks turbocharged interest in surveillance technology. One researcher claimed authorities could have foiled the attack by unearthing connections between hijackers through public information in databases.\n\nAmerican companies cashed in, selling the U.S. billions of dollars in surveillance technologies they said could prevent crime and terror attacks.\n\nThey spotted the same sales opportunity in China. Researchers warned surveillance technologies would be “instruments of repression” in the hands of authoritarian states. Yet IBM, Cisco, Oracle, and other American companies clinched orders to supply Beijing’s “Golden Shield.”\n\n“China didn’t have this kind of thing before,” said Wang, a former Chinese police official in Xinjiang who asked to be identified only by last name for fear of retaliation. “These concepts all came from the West.”\n\nSoon, disturbing stories emerged. Chinese police blocked sensitive news, pinpointing dissidents with unnerving precision. They stalked adherents of the Falun Gong sect banned by authorities. Congress demanded explanations from tech companies.\n\nIn 2008, documents leaked to the press showed Cisco saw the “Golden Shield” as a sales opportunity, quoting a Chinese official calling the Falun Gong an “evil cult.” A Cisco presentation reviewed by AP from the same year said its products could identify over 90% of Falun Gong material on the web. Followers sued Cisco, which is now petitioning the U.S. Supreme Court to throw out the lower court ruling that allowed the lawsuit.\n\nAt a human rights conference in February, then-Cisco lawyer Katie Shay said companies had a responsibility to understand how customers might misuse their technology for “surveillance and censorship.”\n\n“A lot of people have suffered at the hands of their government, and I want to acknowledge that pain,” said Shay, who left Cisco in June. “I also will say that Cisco disputes the allegations of Cisco’s involvement.”\n\nCisco told the AP it is committed to human rights, but the court allegations may “open the floodgates for suits against U.S. corporations merely for legal exports of off-the-shelf goods and services.”\n\nAs Cisco was summoned before Congress, IBM partnered with a Chinese defense contractor on Phase Two of China’s “Golden Shield.”\n\nClassified government blueprints obtained by AP show that in 2009, IBM worked with Huadi, the state-owned subsidiary of China’s biggest missile military contractor spun off from China’s Ministry of Defense, to build out predictive policing.\n\n“Consolidate Communist Party rule,” read the Huadi blueprint, which showed the databases would track hundreds of thousands of people online.\n\nIn response to AP’s questions, IBM referred to any possible relationship it may have had with Chinese government agencies as “old, stale interactions”:\n\n“ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.”\n\nBack in 2009, Beijing needed the technology urgently to quash critics bonding online. Among them were the Yangs.\n\nIn April that year, local authorities ordered the Yangs and more than 300 other families in their village off their land. Developers coveted their prime lakefront property for “Western-style” apartments and villas, with fountains, football fields and shopping centers.\n\nThe Yangs had no idea police were installing systems that could target families like theirs. They just knew their land was being seized — in return for just a unit in a five-floor walk-up, too many stairs for their elderly mother to climb.\n\nThe Yangs and other farmers across China filed complaints.\n\n“I discovered the way the government took our land was illegal,” Yang Caiying said. “They cheated us.”\n\nPredict and prevent\n\nIn July 2009, three months after the Yang land was seized, riots erupted on the other side of the country in Xinjiang. Gory images of a Uyghur lynched at a toy factory spread online, angry Uyghurs took to the streets, and hundreds were killed.\n\nOnce again, American firms pitched their technology as the solution.\n\nThe government sent troops and cut Xinjiang’s phone and internet connections. In secret meetings, officials concluded that police had failed to spot the danger signs because they couldn’t identify Uyghurs deemed separatists, terrorists, and religious extremists, three engineers then working for the Xinjiang government told AP.\n\nAt the time, Xinjiang police and data systems were already running on American technology including IBM, Cisco, Oracle, and Microsoft, the engineers said, which AP verified by reviewing government contracts. But the databases were unconnected.\n\nSo Xinjiang launched an ambitious initiative to fuse data from all available sources, including banks, railways, and phone companies, into a central database. Officials demanded complete information on all suspicious individuals and their relatives going back three generations, according to the engineers, who described specific meetings in which they participated. Two asked to remain anonymous, fearing for their family in China; the third, Nureli Abliz, is now in Germany.\n\nSoon, lucrative contracts went up for bidding. Among those seeking to profit was IBM.\n\n“Prevent problems before they happen,” IBM promised Chinese officials. In an August 2009 pamphlet, IBM cited the Xinjiang riots and said its technology could help the government “ensure urban safety and stability.”\n\nIBM executives fanned out across the country to court Chinese officials. In December 2009, they set up a new “IBM Institute for Electronic Governance Innovation” in Beijing. In 2011, IBM acquired i2, a software program designed to prevent “terrorist threats.” IBM touted i2’s ability to analyze Chinese social media and licensed a Shanghai-based firm called Landasoft to sell it to China’s police, corporate records show.\n\nChinese police purchased tens of millions of dollars’ worth of products from companies like IBM, Cisco, Oracle, and Microsoft to upgrade the “Golden Shield” policing systems, a leaked accounting ledger acquired by AP from a whistleblower shows.\n\nIn the confrontation between the Chinese state and its critics, American technology tipped the scales of power.\n\nIn 2011, thieves ransacked the Yangs’ house, hunting for their property deed. They didn’t find it.\n\nTwo years later, bald men with tattoos and gold chains smashed down their door, shattered windows and flipped furniture to bully them out of their home anyway. Yang’s mother dropped to the floor in terror. Doctors diagnosed a heart attack, but the Yangs didn’t have money for a pacemaker.\n\nFurious, the Yangs sued local police. In June 2015, a judge ruled their land had been seized illegally. The Yangs celebrated.\n\nBut just weeks after the ruling, officers identified human rights lawyers through the “Golden Shield” technology, cuffed hundreds of them and pressed them into police vans across China. One lawyer later recalled how police monitored his messages on human rights in WeChat before they grabbed him, shackled him to a chair, and tortured him.\n\nOvernight, China’s budding rights-defense movement was dealt a fatal blow — and with it, the Yangs’ case. The Yangs were called in and curtly told the judgment was being overturned, their lawsuit dismissed without trial.\n\n“We really had too much faith in the law, you know?” Yang Guoliang said, his hands clenched in fists. “It turned out to be worthless.”\n\nTechnologies of terror\n\nIn the meantime, Beijing was transforming Xinjiang into the most heavily surveilled place on earth, sweeping around a million people into camps and prisons.\n\nWhen bombs tore through a train station in Xinjiang’s capital hours after a visit by leader Xi Jinping in 2014, Xi demanded a crackdown.\n\n“He was super angry,” said Abliz, one of the engineers with the Xinjiang government. “They concluded they weren’t surveilling Uyghurs closely enough.”\n\nThe next year, in April 2015, Abliz attended a closed-door exposition in Xinjiang. A booth ran by Landasoft, the former IBM partner, caught his eye.\n\nAfter years as a vendor of IBM’s i2 police surveillance analysis software to Xinjiang police, Landasoft had struck out on its own, touting i2-like software it said could detain extremists before they caused trouble. The similarity was no coincidence: Landasoft’s software was copied from i2, according to leaked emails and records.\n\n“The platform is developed based on i2,” a Landasoft project manager wrote in an email.\n\nIt used a proprietary data visualization system developed by i2. The software powered what was called the Integrated Joint Operations Platform, or IJOP, with the authority to trigger arrests.\n\nAbliz went numb.\n\n“I thought then that this was the end of humanity,” he said.\n\nLandasoft did not respond to repeated requests for comment. IBM said it cut ties with Landasoft in 2014 and was not aware of any interaction between Landasoft and the Public Security Bureau in Xinjiang.\n\nIn the autumn of 2015, months after the Xinjiang expo, Landasoft signed contracts with Xinjiang police, emails show. Workers installed millions of cameras and wired over 7,000 police outposts, often built just hundreds of meters apart. Nearly 100,000 officers were recruited to pound on doors and collect names, addresses, fingerprints and face-scans.\n\nThough Chinese hardware was favored, foreign software was irreplaceable for its performance and compatibility with China’s American-built systems, engineers told AP. That included server and database software from Oracle and Microsoft and cloud software from VMWare, which Dell acquired in 2016.\n\nIn late 2016, the crackdown began. Internal documents, a leaked copy of the Landasoft software and interviews with 16 former Xinjiang police officers, officials and engineers reveal how the system worked.\n\nLandasoft’s software combined data fed into a central police database to compile a dossier on vast swaths of Xinjiang’s population, tagging them with categories like “went on pilgrimage” or “studied abroad.” Administrators then questioned them, computed risk scores and decided who to detain.\n\nHundreds of thousands of people were tagged “untrustworthy”, leaked messages show. Leaked documents show the IJOP flagged 24,412 people as “suspicious” in just one week in 2017, leading to most being detained.\n\n“They thought it better to grab thousands of innocents than let a single criminal slip free,” Abliz said.\n\nThe technology was crude and flawed. Landasoft emails show engineers frantically fixing a software bug to release hundreds of people categorized as high-risk. And surveillance cameras often misidentified people, a former Xinjiang police officer found when he checked their ID cards.\n\nYet officers were told “computers cannot lie” and that the IJOP’s listed targets were “absolutely correct,” Abliz said. The software’s orders were often obeyed fearfully, unquestioningly.\n\n“The tech companies told the government their software is perfect,” Abliz said. “It’s all a myth.”\n\nMinority report\n\nThe all-encompassing surveillance forced total compliance: Officers arrested colleagues, neighbors informed on each other.\n\nIn May 2017, Kalbinur Sidik, a teacher now in the Netherlands, was summoned to her district government office in a yellow brick apartment building in Xinjiang’s capital. A young Uyghur woman, fresh from college, rose and introduced herself as a local official. Sidik, the woman explained, was being appointed as the head of her building, responsible for collecting information on neighbors.\n\n“What’s this data going to be used for?” Sidik asked.\n\nThe woman looked at a computer, with a Landasoft program running and lists of names and tags: “Goes out at night,” “Overseas phone,” “unemployed.” One button stood out: “Push Alert.”\n\nThe woman clicked it, and the screen filled with names. These people, the woman explained, would be detained and interrogated for suspected ties to terrorism. Sidik’s eyes widened.\n\n“I hated her for what she was doing,” Sidik said. “I knew those people would disappear.”\n\nXinjiang officials issued arrest quotas, Sidik and five other former officers and administrators said. Sidik watched with horror as the number of people who attended her compound’s weekly mandatory flag-raising ceremony shrank, from 400 to just over 100, as residents were arrested.\n\nAt the district office, she observed the logos popping up on screens: Oracle, Microsoft, Intel. The AP found evidence of products from all three companies used in Xinjiang’s policing and data systems during the crackdown, along with Esri, Seagate, Western Digital, Nvidia, Thermo Fisher, and VMWare, then owned by Dell, which advertised cooperation with Xinjiang authorities on its website.\n\nSidik asked her neighborhood official where it all came from.\n\n“We’ve spent a lot of money to import foreign technology,” she recalls the official telling her.\n\nAmong those caught in the digital dragnet was Parida Qabylqai, an ethnic Kazakh pharmacist at a military hospital in Xinjiang.\n\nIn February 2018, Qabylqai was flagged by the IJOP for visiting her parents in Kazakhstan. At first, her boss thought it was a mistake.\n\n“You’re a good person, you shouldn’t be listed,” she recalled him saying. Then he checked the IJOP and spotted her name.\n\n“It’s really serious! You’re going to end up in the camps,” he blurted out in shock.\n\nAn officer pressed a confession into her hands.\n\n“What did I do wrong?” Qabylqai asked.\n\n“Just sign!” the officer shouted.\n\nQabylqai was cuffed, hooded, and whisked to a camp, where cameras watched her day and night, even peering at her naked body in the toilet. Guards barking over speakers ordered her not to speak or even to move.\n\n“They did things to us that no human being should ever have to experience,” she said. “But they said my name was listed by the IJOP, so they didn’t need to explain anything.”\n\nEven enforcers of the system weren’t spared.\n\nIn 2018, Liu Yuliang, a civil servant in Xinjiang, was ordered to the home of a young police officer in his village. He and dozens of others stood, silent, as the officer embraced his sobbing, pregnant wife.\n\nThe officer had forced many people into the camps. Then he himself was flagged for detention.\n\nToo fearful to resist, Liu went along with the arrest, just as the young officer had done before him.\n\nLandasoft software alerted police when flagged people did anything labeled suspicious, like going out at night or logging on the internet repeatedly. Liu was sent to knock on doors, questioning residents whose “eyes filled with fear.”\n\nAs police swept Xinjiang, Landasoft purchased software from Pivotal, a cloud company later acquired by Broadcom, emails show. And Landasoft registered accounts on both Amazon Web Services and Microsoft Azure in 2018, seeking to expand cloud offerings to police clients, emails show.\n\nAWS said Landasoft “consumed very limited cloud services for a brief period” and not for software in the Xinjiang crackdown. Microsoft said Landasoft used Azure services through a self-service portal retired in 2021, and that any Landasoft data was deleted.\n\nThe Xinjiang government told the AP: “There is absolutely no such thing as ‘large-scale human rights violations.’”\n\nLiu eventually resigned and returned to his hometown in eastern China, trying to forget what he had seen and done. But he noted with unease the new cameras and checkpoints being installed around his home.\n\nFour days later, state security called and summoned him for questioning. The all-seeing surveillance apparatus had followed him home.\n\n“The Xinjiang model is being copied everywhere, in every city in China,” Liu said.\n\nIn 2024, Liu left China, ignoring an airport officer who warned that wherever he went, he would be watched.\n\n“This technology has no emotions,” Liu said. “But in the hands of a government that doesn’t respect the law, it becomes a tool for evil.”\n\nAutomated autocracy\n\nThe Yangs are still trapped by U.S. technology. IBM, Dell, HP, Cisco, and Seagate servers, switches and drives power police systems targeting them, maintenance contracts dating to this year show. Intel and Nvidia chips process data. Oracle and VMWare software run the database.\n\nBut the harder the Yangs push, the harder the system pushes back.\n\nIn February 2023, they went to the National Public Complaints Administration in Beijing with a letter. Two days later, police grabbed them from their hotel and drove them home.\n\nThe Yangs persisted, trying to plead their case to Beijing. In the following months, they were seized at bus and train stations, beaten at a hospital and abducted by ambulance.\n\nLast July, Yang’s mother tried again. She carried a letter for Chinese leader Xi Jinping:\n\n“They’re using violence and kidnapping to bar me from petitioning and seeking medical treatment ... We beg you, General Secretary, to save us.”\n\nOutside Beijing’s leadership compound, burly men in black tackled Yang’s mother to the ground. She was jailed for over a month, questioned, strip-searched, force-fed medication and deprived of food and water. In October, she and Yang’s sister disappeared.\n\nThe Yangs’ house is now the last left standing. The father lives alone.\n\nHis relatives have cut contact, unnerved by the flock of police that tail him. Thousands of pages of documents stashed in drawers, stuffed in bags, and piled in boxes in a bathtub chronicle every step of their 16-year quest for justice.\n\nIn April, Yang was sent criminal charges showing how much police had spent to stop the family’s “abnormal petitioning.”\n\nThe cost: About $37,000.\n\n__\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/us-tech-companies-enabled-surveillance-040441040.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "NVIDIA Unveils Its Newest ‘Rubin CPX’ AI GPUs, Featuring 128 GB GDDR7 Memory & Targeted Towards High-Value Inference Workloads",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/nvidia-unveils-its-newest-rubin-cpx-ai-gpus/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Just Released: NVIDIA PhysicsNeMo 25.08",
      "content": null,
      "source": "Example.com",
      "url": "http://www.example.com/blog/2025/08/27/physicsnemo-release-25-08/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Wall Street Loves Taiwan Semi. Should You Buy TSM Stock Now?",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/34699828/wall-street-loves-taiwan-semi-should-you-buy-tsm-stock-now",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "How does Tesla get to $8.5 trillion value? Robots, robotaxis and hope",
      "content": "By Abhirup Roy and Akash Sriram\n\nSAN FRANCISCO (Reuters) -How can Tesla (TSLA) become an $8.5 trillion company? That's the market valuation the electric vehicle maker would have to reach to justify CEO Elon Musk's new pay package announced last week.\n\nSelling 100 million humanoid robots in a year could do it; creating a robotaxi network with more than 10 times the revenue of Uber might as well. And of course, investor hope is part of the equation.\n\nMusk on Friday was given a decade to expand Tesla's $1 trillion valuation into a company worth more than the combined current value of Nvidia (NVDA) and Microsoft (MSFT), the two most valuable publicly traded companies in the world. If he succeeds, Musk, already the best-paid CEO in the world, would receive a trillion-dollar pay package.\n\nMusk's new pay package was granted on September 3, but it is subject to shareholder approval in November.\n\nThe board showed how and where it expects Tesla to make its money by structuring Musk's pay package around 12 milestones that are primarily based on products and profit, as well as market capitalization. They target enormous increases in profit as Tesla rolls out its Optimus humanoid robots and a robotaxi fleet that it hopes will be more efficient than human-driven rivals.\n\nA lot depends on how investors value the company. Tesla, for example, is valued as a growth stock, trading at around 75 times its earnings before interest, taxes, depreciation and amortization, or EBITDA, even though its vehicle sales dropped last year and are likely to drop this year.\n\nThe payoff is astounding - and so are the goals. Gene Munster, managing partner at Deepwater Asset Management, broadly estimated that robotaxis and self-driving software could be worth a trillion dollars of market cap each, with cars another half-trillion. \"At the end of the day, the reason why this is going to work or not work really comes down to Optimus,\" he said. \"It's a fairy tale, but it's one that could actually happen.\"\n\nMusk has been betting the company on self-driving software and robotaxis for some time. Tesla currently has a small fleet of robotaxis - estimated to be about three dozen vehicles - in a part of Austin, Texas. An early Musk milestone is to have a million robotaxis in operation.\n\nOne of Tesla's biggest fans, ARK Invest, predicted an even sunnier case well before the Musk pay package was announced. They see Tesla's market capitalization hitting $7 trillion to $10.9 trillion in 2029, with a Tesla robotaxi network bringing in between $603 billion and $951 billion of ride-hail revenue per year. Global ride-hailing leader Uber, by comparison, will have revenue of $52 billion this year, according to LSEG.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/does-tesla-8-5-trillion-100326566.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "China’s AI Chip Ambitions Limited by HBM Memory Supply, Notes Report",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/chinas-ai-chip-ambitions-limited-by-hbm-memory-supply-notes-report/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 “Battlemage” Nears Launch as Intel Prepares Packaging",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "5 Things to Know Before the Stock Market Opens",
      "content": "Stock futures are slightly higher after the tech-heavy Nasdaq hit a new all-time-high; Nebius Group (NBIS) shares are soaring after the company inked an AI infrastructure deal with Microsoft (MSFT); Lachlan Murdoch gains control of the media empire that includes Fox (FOX) and News Corp (NWS); Oracle (ORCL) is expected to report revenue growth when it delivers quarterly earnings after the closing bell; Teck Resources (TECK) and Anglo American announce merger to form copper mining giant; and Apple launches its iPhone 17. Here's what investors need to know today.\n\n1. Stock Futures Tick Higher as Indexes Hover Near Record Highs\n\nStock futures are slightly higher this morning after the tech-heavy Nasdaq Composite hit a new record high on Monday, as stocks rallied amid expectations that the Federal Reserve will cut interest rates soon. The benchmark S&P 500 and the Dow Jones Industrial Average come into today's session just below all-time highs of their own. Bitcoin (BTCUSD), which has been under pressure in recent weeks, is up slightly at $112,500. The yield on the 10-year Treasury note is ticking higher after hitting its lowest level since April yesterday, while gold and oil futures are also edging upwards in early trading. (Read Investopedia's real-time markets coverage here.)\n\n2. Nebius Group Soars on AI Deal with Microsoft\n\nNebius Group (NBIS) shares are up more than 50% in premarket trading after the AI infrastructure company announced a multi-year deal with Microsoft (MSFT). Amsterdam-based Nebius will provide Microsoft with dedicated capacity at its new data center in Vineland, New Jersey starting later this year, the company said. CNBC reported the deal was worth $19.4 billion. AI chipmaker Nvidia (NVDA) owns a stake in Nebius. “The deal will also help us to accelerate the growth of our AI cloud business even further in 2026 and beyond,” said Nebius CEO Arkady Volozh. Microsoft and Nvidia shares inched higher in premarket trading.\n\n3. Lachlan Murdoch Gains Control of Fox, News Corp in New Family Deal\n\nA deal has been reached to end the yearslong fight over control of the media empire founded by Rupert Murdoch that includes Fox News and The Wall Street Journal. Lachlan Murdoch, who is the CEO of Fox (FOX) and chair of News Corp (NWS), will take control of the trust that holds sizable stakes in both of his father’s companies. As part of the deal, Rupert Murdoch’s children Prudence MacLeod, Elisabeth Murdoch and James Murdoch will end their claim to the company. Shares of Fox and News Corp were each down nearly 5% in recent premarket trading.\n\n4. Oracle Expected to Grow Quarterly Revenue Amid New Cloud Deals\n\nInvestors are awaiting quarterly results from Oracle (ORCL), which are scheduled to be released after markets close today. The cloud computing giant is expected to post a 13% year-over-year jump in quarterly revenue to $15 billion, according to analysts tracked by Visible Alpha. Meanwhile, its adjusted earnings per share are expected to increase to $1.48. The report comes after Oracle shares hit an all-time-high earlier this year on the announcement of $30 billion in new cloud deals. The stock, which has gained more than 40% since the start of 2025, was up about 1% in premarket trading.\n\n5. Teck, Anglo American Merge to Form Copper Mining Giant\n\nMining firms Teck Resources (TECK) and Anglo American have agreed to merge to form a new global minerals company that will be one of the world’s largest producers of copper. The new company, to be called Anglo Teck, will have a combined market capitalization of more than $53 billion. “Anglo Teck will hold an industry-leading portfolio of producing operations, including six world-class copper assets, alongside high-quality premium iron ore and zinc businesses,” Teck said in a release. Shares of Canada-based Teck Resources were up about 17% in premarket trading, while U.K.-based Anglo American gained about 8% in London trading.",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/5-things-to-know-before-the-stock-market-opens-september-9-2025-11806131",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Mistral AI raises 1.7 billion euros as ASML becomes its top shareholder",
      "content": "AMSTERDAM : Dutch chip equipment maker ASML has invested 1.3 billion euros ($1.5 billion) to become the biggest investor in French artificial intelligence startup Mistral AI in a significant boost to Europe's AI ambitions.\n\nMistral AI raised a total of 1.7 billion euros ($2 billion) in its latest funding round, it said on Tuesday. ASML's investment made it Mistral's main shareholder with a stake of about 11 per cent.\n\nThe statement confirmed a Reuters report from Sunday.\n\nThe deal is a boost for Europe's AI ambitions, pairing the continent's most credible rival to U.S. giants OpenAI, Meta and Alphabet's Google with one of its largest tech companies.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nThe latest funding round gives Mistral an 11.7 billion-euro valuation, Mistral said in a statement, becoming the most valuable AI company in Europe.\n\nASML will also partner with Mistral to integrate AI models across its semiconductor equipment portfolio and gain a board seat on the French startup's strategic committee through finance chief Roger Dassen.\n\nMistral, founded in 2023 by former researchers from Google DeepMind and Meta, has positioned itself as Europe's AI alternative to the U.S. and is a centerpiece of France's strategy to become a leading AI competitor.\n\nHowever, it is still worth only a fraction of its U.S. peers. OpenAI is eyeing a valuation of around $500 billion in a potential stock sale, a source familiar with the matter told Reuters in August, more than 40 times Mistral's valuation.\n\nThe Dutch company has recently strengthened its French connections by appointing former French Finance Minister Bruno Le Maire as a special adviser to its executive board. It is also led by French CEO Christophe Fouquet, who took the helm in 2024.\n\n\"It helps that ASML is well connected to the industrial and political establishment to pick and choose its partners,\" said ING analyst Jan Frederik Slijkerman.\n\n\"There is an industrial rational to develop products together,\" he added. \"For ASML it is probably easier to develop AI based products through a partnership then to do this in house.\"\n\nBesides ASML, other investors who joined the fundraising are DST Global, Andreessen Horowitz, Bpifrance, General Catalyst, Index Ventures, Lightspeed and Nvidia, Mistral said.\n\nASML's shares were up 1 per cent in early Amsterdam trading, giving it a market value of 268 billion euros.\n\n($1 = 0.8495 euros)",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/business/mistral-ai-raises-17-billion-euros-asml-becomes-its-top-shareholder-5339461",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "NVIDIA Unveils Rubin CPX: A New Class of GPU Designed for Massive-Context Inference",
      "content": "News Summary:\n\nThe NVIDIA Rubin CPX GPU is purpose-built to handle million-token coding and generative video applications.\n\nThe NVIDIA Vera Rubin NVL144 CPX platform packs 8 exaflops of AI performance and 100TB of fast memory in a single rack.\n\nCompanies can monetize at an unprecedented scale, with $5B in token revenue for every $100M invested.\n\nAI innovators like Cursor, Runway and Magic are exploring how Rubin CPX can accelerate their applications.\n\nSANTA CLARA, Calif., Sept. 09, 2025 (GLOBE NEWSWIRE) -- AI Infra Summit -- NVIDIA® today announced NVIDIA Rubin CPX, a new class of GPU purpose-built for massive-context processing. This enables AI systems to handle million-token software coding and generative video with groundbreaking speed and efficiency.\n\nRubin CPX works hand in hand with NVIDIA Vera CPUs and Rubin GPUs inside the new NVIDIA Vera Rubin NVL144 CPX platform. This integrated NVIDIA MGX system packs 8 exaflops of AI compute to provide 7.5x more AI performance than NVIDIA GB300 NVL72 systems, as well as 100TB of fast memory and 1.7 petabytes per second of memory bandwidth in a single rack. A dedicated Rubin CPX compute tray will also be offered for customers looking to reuse existing Vera Rubin 144 systems.\n\n“The Vera Rubin platform will mark another leap in the frontier of AI computing — introducing both the next-generation Rubin GPU and a new category of processors called CPX,” said Jensen Huang, founder and CEO of NVIDIA. “Just as RTX revolutionized graphics and physical AI, Rubin CPX is the first CUDA GPU purpose-built for massive-context AI, where models reason across millions of tokens of knowledge at once.”\n\nNVIDIA Rubin CPX enables the highest performance and token revenue for long-context processing — far beyond what today’s systems were designed to handle. This transforms AI coding assistants from simple code-generation tools into sophisticated systems that can comprehend and optimize large-scale software projects.\n\nTo process video, AI models can take up to 1 million tokens for an hour of content, pushing the limits of traditional GPU compute. Rubin CPX integrates video decoder and encoders, as well as long-context inference processing, in a single chip for unprecedented capabilities in long-format applications such as video search and high-quality generative video.\n\nBuilt on the NVIDIA Rubin architecture, the Rubin CPX GPU uses a cost‑efficient, monolithic die design packed with powerful NVFP4 computing resources and is optimized to deliver extremely high performance and energy efficiency for AI inference tasks.\n\nAdvancements Offered by Rubin CPX\n\nRubin CPX delivers up to 30 petaflops of compute with NVFP4 precision for the highest performance and accuracy. It features 128GB of cost-efficient GDDR7 memory to accelerate the most demanding context-based workloads. In addition, it delivers 3x faster attention capabilities compared with NVIDIA GB300 NVL72 systems — boosting an AI model’s ability to process longer context sequences without a drop in speed.\n\nRubin CPX is offered in multiple configurations, including the Vera Rubin NVL144 CPX, that can be combined with the NVIDIA Quantum‑X800 InfiniBand scale-out compute fabric or the NVIDIA Spectrum-X™ Ethernet networking platform with NVIDIA Spectrum-XGS Ethernet technology and NVIDIA ConnectX®-9 SuperNICs™. Vera Rubin NVL144 CPX enables companies to monetize at an unprecedented scale, with $5 billion in token revenue for every $100 million invested.\n\nIndustry Leaders Look to Rubin CPX\n\nAI innovators are exploring how Rubin CPX can accelerate their applications, ranging from large-scale software development to the analysis of dynamic visual content to better understand moving images.\n\nCursor, an AI-powered software company that offers an advanced code editor, sees the benefits of Rubin CPX to boost developer productivity with intelligent code generation and collaborative tools directly in the coding environment.\n\n“With NVIDIA Rubin CPX, Cursor will be able to deliver lightning-fast code generation and developer insights, transforming software creation,” said Michael Truell, CEO of Cursor. “This will unlock new levels of productivity and empower users to ship ideas once out of reach.”\n\nRunway, an American generative AI company, will use NVIDIA technologies to enable creators to produce cinematic content and sophisticated visual effects with unmatched scale and efficiency.\n\n“Video generation is rapidly advancing toward longer context and more flexible, agent-driven creative workflows,” said Cristóbal Valenzuela, CEO of Runway. “We see Rubin CPX as a major leap in performance, supporting these demanding workloads to build more general, intelligent creative tools. This means creators — from independent artists to major studios — can gain unprecedented speed, realism and control in their work.”\n\nMagic is an AI research and product company developing foundation models to power AI agents that can automate software engineering.\n\n“With a 100-million-token context window, our models can see a codebase, years of interaction history, documentation and libraries in context without fine-tuning,” said Eric Steinberger, CEO of Magic. “This enables users to coach the agent at test time through conversation and access to their environments, bringing us closer to autonomous agentic experiences. Using a GPU like NVIDIA Rubin CPX greatly accelerates our compute workloads.”\n\nSoftware Support\n\nNVIDIA Rubin CPX will be supported by the complete NVIDIA AI stack — from accelerated infrastructure to enterprise‑ready software. The NVIDIA Dynamo platform efficiently scales AI inference, dramatically boosting throughput while cutting response times and model serving costs.\n\nThe processors will be able to run the latest in the NVIDIA Nemotron™ family of multimodal models that provide state-of-the-art reasoning for enterprise-ready AI agents. For production-grade AI, Nemotron models can be delivered with NVIDIA AI Enterprise, a software platform that includes NVIDIA NIM ™ microservices as well as AI frameworks, libraries and tools that enterprises can deploy on NVIDIA-accelerated clouds, data centers and workstations.\n\nBuilt on decades of innovation, the Rubin platform extends NVIDIA’s developer ecosystem — with NVIDIA CUDA‑X ™ libraries, a community of over 6 million developers and nearly 6,000 CUDA applications.\n\nAvailability\n\nNVIDIA Rubin CPX is expected to be available at the end of 2026.\n\nLearn more by watching NVIDIA Vice President of Hyperscale and High-Performance Computing Ian Buck’s keynote at AI Infra Summit on Sept. 9 at 10am PT.\n\nAbout NVIDIA\n\nNVIDIA (NASDAQ: NVDA) is the world leader in accelerated computing.\n\nFor further information, contact:\n\nKristin Uchiyama\n\nNVIDIA Corporation\n\n+1-408-313-0448\n\nkuchiyama@nvidia.com\n\nCertain statements in this press release including, but not limited to, statements as to: Vera Rubin systems continuing to deliver extraordinary performance and efficiency; with Rubin CPX, building a GPU uniquely suited for million-token context processing, cutting the cost of inference and unlocking advanced capabilities for developers and creators everywhere; the benefits, impact, performance, and availability of NVIDIA’s products, services, and technologies; expectations with respect to NVIDIA’s third party arrangements, including with its collaborators and partners; expectations with respect to technology developments; and other statements that are not historical facts are forward-looking statements within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended, which are subject to the “safe harbor” created by those sections based on management’s beliefs and assumptions and on information currently available to management and are subject to risks and uncertainties that could cause results to be materially different than expectations. Important factors that could cause actual results to differ materially include: global economic and political conditions; NVIDIA’s reliance on third parties to manufacture, assemble, package and test NVIDIA’s products; the impact of technological development and competition; development of new products and technologies or enhancements to NVIDIA’s existing product and technologies; market acceptance of NVIDIA’s products or NVIDIA’s partners’ products; design, manufacturing or software defects; changes in consumer preferences or demands; changes in industry standards and interfaces; unexpected loss of performance of NVIDIA’s products or technologies when integrated into systems; and changes in applicable laws and regulations, as well as other factors detailed from time to time in the most recent reports NVIDIA files with the Securities and Exchange Commission, or SEC, including, but not limited to, its annual report on Form 10-K and quarterly reports on Form 10-Q. Copies of reports filed with the SEC are posted on the company’s website and are available from NVIDIA without charge. These forward-looking statements are not guarantees of future performance and speak only as of the date hereof, and, except as required by law, NVIDIA disclaims any obligation to update these forward-looking statements to reflect future events or circumstances.\n\nMany of the products and features described herein remain in various stages and will be offered on a when-and-if-available basis. The statements above are not intended to be, and should not be interpreted as a commitment, promise, or legal obligation, and the development, release, and timing of any features or functionalities described for our products is subject to change and remains at the sole discretion of NVIDIA. NVIDIA will have no liability for failure to deliver or delay in the delivery of any of the products, features or functions set forth herein.\n\n© 2025 NVIDIA Corporation. All rights reserved. NVIDIA, the NVIDIA logo and all other NVIDIA trademarks mentioned herein are trademarks and/or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated. Features, pricing, availability and specifications are subject to change without notice.\n\nA photo accompanying this announcement is available at https://www.globenewswire.com/NewsRoom/AttachmentNg/3266451c-18af-4394-8290-db8d9ae220b4",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/09/3147154/0/en/NVIDIA-Unveils-Rubin-CPX-A-New-Class-of-GPU-Designed-for-Massive-Context-Inference.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia is the world's most valuable company. Why does CEO Jensen Huang barely make the list of the 10 wealthiest people?",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/adc86d3e90150c71",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "A Weak Jobs Report Implies Lower Rates Ahead",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/09/a-weak-jobs-report-implies-lower-rates-ahead/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "ASML invests $1.5B in French AI startup Mistral, forming European tech alliance",
      "content": "LONDON (AP) — ASML, a leading Dutch maker of chipmaking gear, is investing 1.3 billion euros ($1.5 billion) into French artificial intelligence startup Mistral AI, the two said on Tuesday, announcing a partnership between two of Europe's top technology companies.\n\nASML Holding, based in Veldhoven, Netherlands, holds an important role in the global tech industry because it makes equipment used to manufacture semiconductors, including the most advanced microchips used for cutting-edge AI systems.\n\nMistral was founded two years ago in Paris by former researchers at Google DeepMind and Meta Platforms and quickly became a European tech darling.\n\nThe partnership underscores Europe's efforts to reduce exposure to American technology. President Donald Trump's increasingly hostile attitude to European Union tech regulations has fueled debate about whether the continent is too dependent on services provided by U.S. tech companies such as cloud computing and mobile operating systems.\n\nMistral makes the Le Chat chatbot but it has struggled to keep up with American AI companies like ChatGPT-maker OpenAI, and Chinese rivals like DeepSeek.\n\nASML's chipmaking equipment can cost hundreds of millions of dollars but the U.S. government has blocked it from selling its most advanced machines to China.\n\nThe deal gives ASML an 11% stake in Mistral, and values the startup at about 11.7 billion euros. The 1.3 billion euro investment is part of a larger funding round worth 1.7 billion euros, which also involves venture capital firms and chipmaker Nvidia.\n\nMistral CEO Arthur Mensch said in a press release that the alliance combines Mistral's “frontier AI expertise with ASML’s unmatched industrial leadership and most sophisticated engineering capabilities.\"\n\n“Together, we will accelerate technological progress across the global semiconductor and AI value chain,\" Mensch said.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/asml-invests-1-5b-french-143653959.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Deploy Scalable AI Inference with NVIDIA NIM Operator 3.0.0",
      "content": "AI models, inference engine backends, and distributed inference frameworks continue to evolve in architecture, complexity, and scale. With the rapid pace of change, deploying and efficiently managing AI inference pipelines that support these advanced capabilities becomes a critical challenge.\n\nNVIDIA NIM Operator is designed to help you scale intelligently. It enables Kubernetes cluster administrators to operate the software components and services necessary to run NVIDIA NIM inference microservices for the latest LLMs and multimodal AI models, including reasoning, retrieval, vision, speech, biology, and more.\n\nThe latest release of NIM Operator 3.0.0 introduces expanded capabilities to simplify and optimize the deployment of NVIDIA NIM microservices and NVIDIA NeMo microservices across Kubernetes environments. NIM Operator 3.0.0 supports efficient resource utilization and integrates seamlessly with your existing Kubernetes infrastructure, including KServe deployments.\n\nNVIDIA customers and partners have been using the NIM Operator to efficiently manage inference pipelines for a variety of applications and AI agents, including chatbots, agentic RAG, and virtual drug discovery.\n\nNVIDIA has recently collaborated with Red Hat to enable NIM deployment on KServe with the NIM Operator. “Red Hat contributed to the NIM Operator open source GitHub repo to enable NVIDIA NIM deployment on KServe,” said Red Hat Director of Engineering Babak Mozaffari. “This feature allows the NIM Operator to deploy NIM microservices that benefit from KServe lifecycle management and simplifies scalable NIM deployment using NIM service. Native KServe support in the NIM Operator also allows users to benefit from model caching with NIM cache and leverage NeMo capabilities like NeMo Guardrails for building Trusted AI for all your KServe Inference endpoints.”\n\nThis post explains new capabilities in the NIM Operator 3.0.0 release, including:\n\nFigure 1. NIM Operator architecture\n\nFlexible NIM deployment: Multi-LLM compatible and multi-node\n\nNIM Operator 3.0.0 adds support for easy, fast NIM deployment. You can use it with a domain-specific NIM—such as those for biology, speech, or retrieval—or various NIM deployment options, including multi-LLM compatible, or multi-node.\n\nMulti-LLM compatible NIM deployment: Deploy diverse models with custom weights from sources like NVIDIA NGC, Hugging Face, or local storage. Use the NIM cache custom resource definition (CRD) to download weights to PVCs and the NIM service CRD to manage deployment, scaling, and ingress.\n\nDeploy diverse models with custom weights from sources like NVIDIA NGC, Hugging Face, or local storage. Use the NIM cache custom resource definition (CRD) to download weights to PVCs and the NIM service CRD to manage deployment, scaling, and ingress. Multi-node NIM deployment addresses the challenge of deploying massive LLMs that cannot fit on a single GPU or need to run on multiple GPUs and potentially on multiple nodes. NIM Operator supports caching for multi-node NIM deployment using the NIM cache CRD, and deploying them using the NIM service CRD on Kubernetes with LeaderWorkerSets (LWS).\n\nNote that the multi-node NIM deployment without GPUDirect RDMA may result in frequent restarts of LWS leader and worker pods due to model shard loading timeouts. Using fast network connectivity such as IPoIB or ROCE is highly recommended and can be easily configured through the NVIDIA Network Operator.\n\nFigure 2 shows the deployment of large language models (LLMs) from the Hugging Face library on Kubernetes using the NVIDIA NIM Operator as a multi-LLM NIM deployment. It specifically demonstrates deploying the Llama 3 8B Instruct model, including service and pod status verification, followed by a curl command to send a request to the service.\n\nFigure 2. Multi-LLM deployment of the Llama 3 8B Instruct model using NIM Operator\n\nEfficient GPU utilization with DRA\n\nDRA is a built-in Kubernetes feature that simplifies GPU management by replacing traditional device plugins with a more flexible and extensible approach. DRA enables users to define GPU device classes, request GPUs based on those classes, and filter them according to workload and business needs.\n\nNIM Operator 3.0.0 supports DRA under technology preview by configuring ResourceClaim and ResourceClaimTemplate on NIM Pod through both the NIM service CRD and NIM Pipeline CRD. You can either create and attach your own claims or let the NIM Operator create and manage them automatically.\n\nThe NIM Operator DRA supports:\n\nFull GPU and MIG usage\n\nGPU sharing through time slicing by assigning the same claim to multiple NIM services\n\nNote: This feature is currently available as a technology preview, with full support available soon.\n\nFigure 3 demonstrates the deployment of Llama 3 8B Instruct NIM using Kubernetes DRA with NIM Operator. Users can define a resource claim in a NIM service to request specific hardware attributes such as GPU architecture and memory, and interact with the deployed LLM using curl .\n\nFigure 3. Deployment of Llama 3 8B Instruct NIM using Kubernetes DRA with NIM Operator\n\nSeamless deployment on KServe\n\nKServe is a widely adopted open source inference serving platform used by many partners and customers. NIM Operator 3.0.0 supports both raw and serverless deployments on KServe by configuring the InferenceService custom resource to manage deployment, upgrades, and autoscaling of NIM. NIM Operator simplifies the deployment process by automatically configuring all required environment variables and resources in the InferenceService CRDs.\n\nThis integration delivers two additional benefits:\n\nIntelligent caching with NIM cache to reduce initial inference time and autoscaling latency, resulting in faster and more responsive deployments.\n\nNeMo microservices support for evaluation, guardrails, and customization to enhance AI systems for latency, accuracy, cost, and compliance.\n\nFigure 4 shows the deployment of the Llama 3.2 1B Instruct NIM on KServe using NIM Operator. Two distinct deployment methodologies are shown: RawDeployment and Serverless. The Serverless deployment incorporates autoscaling functionality through K8s annotation. Both strategies use a curl command to test the responses of the NIM.\n\nFigure 4. Deployment of the Llama 3.2 1B Instruct NIM on KServe using NIM Operator with both RawDeployment and Serverless methodologies\n\nGet started scaling AI inference with NIM Operator 3.0.0\n\nNVIDIA NIM Operator 3.0.0 makes deploying scalable AI inference easier than ever. Whether you’re working with multi-LLM compatible or multi-node NIM deployment, optimizing GPU usage with DRA, or deploying on KServe, this release enables you to build high-performance, flexible, and scalable AI applications.\n\nBy automating the deployment, scaling, and lifecycle management of both NVIDIA NIM and NVIDIA NeMo microservices, NIM Operator makes it easier for enterprise teams to adopt AI workflows. This effort aligns with making AI workflows easy to deploy with NVIDIA AI Blueprints, enabling quick movement to production. The NIM Operator is part of NVIDIA AI Enterprise, providing enterprise support, API stability, and proactive security patching.\n\nGet started through NGC or from the NVIDIA/k8s-nim-operator open source GitHub repo. For technical questions on installation, usage, or issues, file an issue on the NVIDIA/k8s-nim-operator GitHub repo.",
      "source": "Nvidia.com",
      "url": "https://developer.nvidia.com/blog/deploy-scalable-ai-inference-with-nvidia-nim-operator-3-0-0/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "PsiQuantum valued at $7 billion in latest funding round, teams up with Nvidia",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_27654e15-a66d-47f0-bbab-84bb2e3dec10",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Elon Musk Was Just Unseated as the World’s Richest Person",
      "content": "Oracle Chairman Larry Ellison is having a good morning.\n\nOracle’s stock is up more than 42% on Wednesday, thanks to an earnings call on Tuesday that left investors stunned.\n\nThe company missed earnings and revenue estimates, but the forward looking guidance alone was apparently good enough to get investors to rally around it. A bulk of that reaction had to do with the revenue that AI computing demand was expected to bring to Oracle’s cloud infrastructure service.\n\nThe shares skyrocketed in response. Oracle’s stock is now on pace to have its largest single session surge since the dot-com boom, according to CNBC.\n\nWith the current surge in shares, Ellison has increased his wealth by more than $100 billion, thanks to the roughly 1.16 billion shares he owns. This meteoric rise grabbed him the title of the richest person on Earth from the former title holder, Elon Musk, according to the Bloomberg Billionaires Index.\n\nAs of Tuesday, Ellison’s current total fortune was worth $295 billion, having increased by $100 billion in worth in just the past year. Today’s additional increase has catapulted him to a staggering $389 billion, surpassing Elon Musk’s whopping $384 billion fortune.\n\nMusk was first named the richest man in the world in 2021, and has since been up and down on the list. He has held the title consistently since last year and briefly became the first person to surpass $400 billion net worth in December. Although Ellison has overtaken him on the list, Musk might reverse that yet again soon. Musk is facing the potential of becoming the world’s first trillionaire, that is if the massive and unprecedented proposed pay package plan by the Tesla board gets approved by shareholders.\n\nOracle’s AI success story\n\nLarry Ellison co-founded Oracle in the late 1970s with the CIA as an early customer. Decades down the line, the database software company now specializes in AI-first cloud computing and competes with other giants like Microsoft’s Azure, Alphabet’s Google Cloud, and Amazon’s AWS. It’s the aggressively positive and AI-driven outlook for its cloud infrastructure business that has led to investor delight and the 81-year-old Ellison is benefiting handsomely from it.\n\nAlthough the revenue estimates were down, the company said it was expecting to collect more than half a trillion dollars extra thanks to four multi-billion-dollar contracts it signed in the past quarter. At the company’s earnings call, CEO Safra Catz mentioned OpenAI, Meta, Nvidia, AMD, and Elon Musk’s xAI as some of the company it has “significant cloud contracts with.”\n\nCompany executives shared that they are expecting to finalize even more multi-billion-dollar deals in the near future.\n\nOracle, and Ellison, are hell-bent on AI. The company recently made headlines for an alleged plan to spend more than $1 billion a year to run a new data center in Texas on gas generators rather than wait for approval and infrastructure to pull the electricity from the local grid. Oracle is also one of the partners in the Trump administration’s ambitious AI project Stargate.\n\nCloud computing is the hot name in AI earnings\n\nCloud computing might be one of the clearest early winners of the AI hype. AI companies are scouring for more computing capacity as they try to compete with each other and scale operations, and they are willing to spend a hefty amount of money for it. Enter cloud infrastructure providers, like Oracle and Microsoft, that provide computing power for large AI models. Both the companies showed a meteoric stock increase after their recent earnings report.\n\nIn its latest earnings report in July, Microsoft reported that sales were up 18% from last year and that revenue for its cloud computing platform Azure had surpassed $75 billion this year, up 34% from last. Despite these numbers accompanying Microsoft’s largest ever quarterly capital expenditure forecast, the market went crazy for it. The shares jumped and the tech giant briefly became the second-ever company to hit $4 trillion market valuation.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/elon-musk-was-just-unseated-as-the-worlds-richest-person-2000656741",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Despite cutting the gags, Borderlands 4's PC specs say it still needs 100GB of SSD space",
      "content": "Two days before launch, Borderlands 4 has its PC system requirements. They’re generally on the higher side without teetering over into full-on tech demo lunacy – the RTX 2070 is a minimum-spec graphics card, for instance – though anyone with a smaller SSD will need to make room for the looty FPS sequel’s bumper-size 100GB storage requirement.\n\nI have mixed feelings about this. On the one hand, gargantuan install sizes are kind of obnoxious (even the infamously bloated Call of Duty agrees), and are partly caused by merely visual, high-resolution textures that we increasingly need madly expensive GPUs to even enable. Or at least, to enable without simultaneously committing framerateicide.\n\nOn the other hand, 100 is a very round and satisfying number. Just look at it. Way better than 112 or some garbage. I do wonder if anyone working in Gearbox’s gigabyte dieting department saw it was possible to compress it down to 99GB, potentially avoiding the shock of entering the triple digits, but left it at 100GB just because it’s vaguely nicer. I suspect I’d do the same.\n\nAnyway, here’s the hardware:\n\nBorderlands 4 minimum PC specs\n\nOS: Windows 10 / 11\n\nWindows 10 / 11 CPU: Intel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum)\n\nIntel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum) RAM: 16GB\n\n16GB GPU: Nvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum)\n\nNvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum) Storage: 100GB (SSD required)\n\nBorderlands 4 recommended PC specs\n\nOS: Windows 10 / Windows 11\n\nWindows 10 / Windows 11 CPU: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nIntel Core i7-12700 / AMD Ryzen 7 5800X RAM: 32GB\n\n32GB GPU: Nvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nNvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580 Storage: 100GB (SSD required)\n\nSolid state hungriness aside, it’s a bit strange seeing the Arc B580 in the recommended tier, alongside the RTX 3080 and RX 6800 XT – it’s a good little budget card but not on the same level as those two older, yet bonafide high-end GPUs. Though maybe that means Borderlands 4 performs better-than-recommended on this Nvidia/AMD kit?\n\nAlso, 2K’s post doesn’t mention it specifically, but DLSS 4 Multi Frame Generation is supported as well. This needs a GeForce RTX 50 series card to operate at full pelt, with RTX 40 models making do with DLSS 3-style 2x frame gen.\n\nI’m generally in the 'wait and see how it is' camp on Fourderlands, with its new planet and its many billions of randomly generated firearms, having previously been interested enough to mulch through Borderlands 3 with mates but jointly concluding it wasn’t worth our time. This new one is something of a reset, with its lead writer Taylor Clark claiming it won’t have as many jokes. Which is, at once, likely an improvement and also a weird thing to make a selling point of. B4's out on September 12th.",
      "source": "Rock Paper Shotgun",
      "url": "https://www.rockpapershotgun.com/despite-cutting-the-gags-borderlands-4s-pc-specs-say-it-still-needs-100gb-of-ssd-space",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "I pivoted from software engineering to AI product management. Here are the 3 strategies I used to help me land the job.",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nThis as-told-to essay is based on a conversation with Phani Sai Ram Munipalli, a 28-year-old full-time AI/tech product manager from Santa Clara, California. It's been edited for length and clarity.\n\nI worked for four years as a full-time software engineer — two years at IBM and two years at Walmart Global Tech — after completing my undergraduate program in India in 2017.\n\nIn July 2022, I left software engineering and chose to shift my career path to compete for an AI/tech product management role at Walmart in the US, even though I had little experience in that field.\n\nMy career change wasn't motivated by the idea of potentially making more money — I believe in technology that can change lives.\n\nThis journey began not with a job application but with a realization in 2022\n\nRight as ChatGPT was introduced to the world, I knew a massive shift was coming, and my technical background was my unique entry point into the AI talent wars.\n\nI started my master's program in computer software engineering at San Jose State University in August 2022. During my master's summer, I did a product management internship at Walmart. I graduated from with my degree in May 2024 and joined Walmart as a full-time product manager in July 2024.\n\nI love coding and still do it for my side projects, but I wanted to go beyond just writing code. I wanted to understand what products can be built leveraging AI, who the users are, and how it's helping them.\n\nThis recognition led to a self-assessment and a personal road map to create my own AI-centric playbook around three core strategies.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\n1. I rewired my brain for AI product thinking\n\nMy technical background helped me grasp AI concepts, but I needed to learn how to think like an AI product leader. In 2023, I took on an additional role at my university as an AI research assistant in conversational AI.\n\nTo add to my AI expertise and rewire my brain for AI product thinking, I went all in on a self-education sprint. I listened to podcasts like Lenny's Podcast and the Nvidia AI Podcast, which focus on the complexities of productionizing AI and learning the crucial lesson that AI is never the product itself — solving a user's problem is.\n\nI also completed Google's \"Responsible AI: Applying AI Principles with Google Cloud\" credential in December 2023 and the AI Product Management Bootcamp led by Marily Nika, a former Google AI product manager, in April 2024.\n\nFinally, I put theory into practice by building several web apps — including LinkPlus, VibeCard, and SafeWord AI — using both OpenAI's and Google's Gemini APIs, teaching myself the real-world challenges of prompt engineering and leveraging LLMs.\n\n2. I ditched popular frameworks in interviews\n\nWhen it came time to interview for my summer product management internship at Walmart, I knew that reciting standard product frameworks would be a failing strategy.\n\nI was an underdog among 20+ intern candidates from top schools. I knew I had to prove myself. My differentiator wasn't a textbook answer; it was the portfolio of AI projects I'd built and the platform I'd created.\n\nInstead of trying to impress with pure technical knowledge, I focused on translating it. I used storytelling — especially the \"Hero's Journey\" technique in my presentations — to craft compelling narratives explaining how these AI solutions could solve real, human problems for Walmart's gig drivers.\n\nThis approach — proving I could not only understand AI but also build with it and communicate its value — is what landed me the internship at Walmart. This focus on bridging the gap between complex tech and user needs was so successful that it also secured me a full-time return offer at Walmart for my current position, which I started in July 2024.\n\n3. I built a platform to give first and networked second\n\nI believed an AI-focused product manager should have their own product, so in March 2023, I started a podcast, The Hustle Chapters, and a newsletter, Phani's Product.\n\nMy podcast platform completely flipped the networking dynamic. Instead of asking for 15-minute coffee chats, I invited directors and founders onto my show, offering them value first.\n\nI hosted 21 builders from the AI space, learning directly from them about the myths of building AI. This approach built genuine connections and directly led to a spring internship offer from VComply in 2024.\n\nThen — even after securing my role at Walmart — I took on a subsequent spring internship focused entirely on the complex challenge of productizing an LLM-based application for enterprise users. I experimented with running LLMs on my local machine and then documented the entire setup process in a technical guide for my newsletter.\n\nThis trial-by-fire experience — tackling the nuances of bringing cutting-edge LLMs into a real-world business context — gave me an even deeper level of practical knowledge to bring to my full-time position.\n\nI also regularly published one-pagers and newsletters analyzing how Big Tech companies use AI and data to create superior customer experiences, building a small but engaged audience of tech professionals.\n\nThis three-pronged approach helped me pivot successfully\n\nI've spent a year on my team full-time, solving fascinating problems for gig drivers in Walmart's Last Mile Delivery ecosystem. I work in the realm of AI, LLM, and ML in product management — a complete gearshift from my former full-time roles as a software engineer.\n\nUltimately, my journey is a playbook for forging your own path, proving that the right strategy and mindset about pivoting into AI or another area are more powerful than a traditional background.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/how-pivoted-software-engineering-ai-product-management-2025-9",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Why Nvidia Stock Jumped Today",
      "content": "Prime Minister Sébastien Lecornu’s sudden resignation deepens France’s political instability, spooking markets and complicating President Macron’s government ahead of budget battles.\n\nMarket Summary Markets show cautious optimism as U.S. stock futures edge higher driven by hopes for Federal Reserve rate cuts and AI sector momentum. However, geopolitical tensions and a prolonged U.S. government shutdown sustain volatility. Japan stocks rally on leadership changes, while French political upheaval sparks selloffs in Europe. Bitcoin's record highs reflect growing safe-haven demand amidst uncertainty.\n\nFifth Third Strikes $10.9 Billion Deal to Acquire Comerica Fifth Third to Absorb Comerica in $10.9 Billion Stock Deal Fifth Third Bancorp confirms $10.9 billion acquisition of Comerica, marking a major consolidation in U.S. regional banking. The all-stock deal aims to expand market presence amid banking sector challenges.\n\nFigure of the Day 125,000 - Bitcoin's new record price in USD, signaling heightened crypto market interest amid economic uncertainty.\n\nFrench PM Lecornu Resigns Hours After Cabinet Reveal New French PM Quits After Less Than A Month in Office French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after unveiling his cabinet. This resignation deepens France’s political crisis with markets reacting negatively.\n\nGovernment Shutdown Hits Second Week with No Breakthrough Shutdown Stalemate Promises Prolonged Federal Gridlock The U.S. federal government shutdown extends beyond a week, with lawmakers at an impasse. Threats of mass federal layoffs mount, fueling market uncertainty and increasing economic pressure.\n\nBullish SpaceX Secures $714M Pentagon Contract, Edging Out Blue Origin Elon Musk’s SpaceX wins major defense contracts, reinforcing its dominance in military space launches and solidifying government partnerships. More on benzinga.com\n\nJapan Stocks Rally as Takaichi Takes Ruling Party Helm Nikkei Inches to Record High on Takaichi’s Pro-Stimulus Win Japan’s stock market soars as ultra-conservative Sanae Takaichi wins the ruling party leadership, triggering yen weakness. Investors expect pro-stimulus policies and possible BOJ monetary shifts.\n\nBitcoin Surges Past $125,000 Amid Market Turmoil Crypto Rally Continues with Bitcoin at New All-Time High Bitcoin hits new record highs surpassing $125,000 despite market volatility. Investors flock to cryptocurrencies as safe havens amid geopolitical tensions and U.S. government shutdown uncertainty.\n\nBearish Aston Martin Shares Tank as Tariff Pressures Slash Profit Outlook Luxury carmaker Aston Martin issues profit warning amid rising U.S. tariffs and supply chain woes, triggering a steep stock selloff. More on businessinsider.com\n\nAston Martin Shares Dive on New Profit Warning — Tariff Drag Lingers Aston Martin Slashes Profits Amid US Tariff Turmoil Aston Martin’s shares plunge after issuing fresh profit warnings citing ongoing tariff impacts and supply chain challenges. The luxury carmaker seeks proactive support amid uncertain US trade policies.\n\nSpaceX Lands $714 Million Pentagon Contract, Beating Blue Origin SpaceX outpaces Blue Origin by securing $714 million Pentagon contract for military space missions, bolstering Elon Musk’s dominance in U.S. defense space operations.\n\nRegulatory Impact EU financial regulator ESMA moves to centralize oversight of stock exchanges, crypto firms, and clearing houses, aiming to boost market stability across member states.\n\nQualtrics to Acquire Press Ganey in $6.8 Billion Healthcare Deal Qualtrics plans $6.8 billion acquisition of Press Ganey Forsta to strengthen healthcare technology footprint. The deal includes cash and debt components, signaling strategic expansion.\n\nQuote \"The political instability in France is weighing heavily on markets, signaling uncertain times ahead for investors and policymakers alike.\"\n\n— Senior European Market Strategist\n\nCourt Halts Trump’s National Guard Deployment to Oregon U.S. judges temporarily block Trump administration’s National Guard deployments to Oregon and Portland amid legal battles. States challenge federal troop movements amid rising tensions.\n\n2025 Nobel Prize in Medicine Honors Immunology Trailblazers Immunology Pioneers Share Nobel Prize for Medicine 2025 Nobel Prize in Medicine awarded to pioneers in immunology for breakthroughs in immune system research, advancing understanding of physiological disease mechanisms.\n\nESMA Pushes for Unified EU Oversight of Exchanges and Crypto EU’s financial watchdog plans centralized oversight of stock exchanges, crypto firms, and clearing houses to harmonize regulation across the bloc and enhance capital market stability.\n\nOPEC+ Approves Small Oil Production Hike, Markets React OPEC+ Output Raised Slightly; Price Sentiment Wavers OPEC+ agrees to a modest 137,000 barrel per day oil output increase in November amid concerns of oversupply. Market remains cautious as global economic outlook loosens.\n\nTesla Reports Record Q3 Deliveries Amid Emerging Headwinds Tesla sets record Q3 vehicle deliveries but faces emerging operational challenges. Positive growth outlook is tempered by supply chain concerns and market pressures.\n\nStock Futures Rise on Fed Rate-Cut Hopes and AI Buzz Wall Street Futures Up as Investors Eye AI and Policy Moves Wall Street stock futures edge mostly higher, supported by hopes of Fed rate cuts and rapid AI sector growth despite the shadow of a prolonged U.S. government shutdown.\n\nHong Kong Stocks Slide as U.S. Shutdown Hurts Sentiment Hong Kong stocks dip due to dampened investor sentiment linked to U.S. government shutdown; demand rises for safe-haven assets like gold amid global uncertainties.\n\nAmazon Lets Prime Shoppers Add Last-Minute Items to Delivery Amazon enhances its Prime offering with 'Add to Delivery' feature allowing last-minute additions to shipments, aiming to boost holiday shopping convenience.\n\nChina Unveils Stealth Fighter Jet Development Footage Powerful jet fighter development footage emerges from China, positioning the country as the global leader in stealth combat aircraft alongside the U.S.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/db3bfaea0ef02c73",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "AI Is Coming for YouTube Creators",
      "content": "Editor’s note: This analysis is part of The Atlantic’s investigation into how YouTube videos are taken to train AI tools. You can use the search tool directly here, to see whether videos you’ve created or watched are included in the data sets. This work is part of AI Watchdog, The Atlantic’s ongoing investigation into the generative-AI industry.\n\nWhen Jon Peters uploaded his first video to YouTube in 2010, he had no idea where it would lead. He was a professional woodworker running a small business who decided to film himself making a dining table with some old legs he had found in a barn. It turned out that people liked his candid style, and as he posted more videos, a fan base began to grow. “All of a sudden there’s people who appreciate the work I’m doing,” he told me. “The comments were a motivator.” Fifteen years later, his channel has more than 1 million subscribers. Sometimes he gets photos of people in their shops, following his guidance from a big TV on the wall—most of his viewers, Peters told me, are woodworkers looking to him for instruction.\n\nBut Peters’s channel could soon be obsolete, along with millions of other videos created by people who share their expertise and advice on YouTube. Over the past few months, I’ve discovered more than 15.8 million videos from more than 2 million channels that tech companies have, without permission, downloaded to train AI products. Nearly 1 million of them, by my count, are how-to videos. You can find these videos in at least 13 different data sets distributed by AI developers at tech companies, universities, and research organizations, through websites such as Hugging Face, an online AI-development hub.\n\nIn most cases the videos are anonymized, meaning that titles and creator names are not included. I was able to identify the videos by extracting unique identifiers from the data sets and looking them up on YouTube—similar to the process I followed when I revealed the contents of the Books3, OpenSubtitles, and LibGen data sets. You can search the data sets using the tool below, typing in channel names like “MrBeast” or “James Charles,” for example.\n\n(A note for users: Just because a video appears in these data sets does not mean it was used for training by AI companies, which could choose to omit certain videos when developing their products.)\n\nTo create AI products capable of generating video, developers need huge quantities of videos, and YouTube has become a common source. Although YouTube does offer paying subscribers the ability to download videos and watch them through the company’s app whenever they’d like, this is something different: Video files are being ripped from YouTube en masse and saved in files that are then fed to AI algorithms. This kind of downloading violates the platform’s terms of service, but many tools allow AI developers to download videos in this way. YouTube appears to have done little, if anything, to stop the mass downloading, and the company did not respond to my request for comment.\n\nNot all YouTube videos are copyrighted (and some are uploaded by people who don’t own the copyrights), but many are. Unauthorized copying or distribution of those videos is illegal, but whether AI training constitutes a form of copying or distribution is still a question being debated in many ongoing lawsuits. Tech companies have argued that training is a “fair use” of copyrighted work, and some judges have disagreed in their responses. How the courts ultimately apply the law to this novel technology could have massive consequences for creators’ motivations to post their work on YouTube and similar platforms—if tech companies are able to continue taking creators’ work to build AI products that compete with them, then creators may have little choice but to stop sharing.\n\nGenerative-AI tools are already producing videos that compete with human-made work on YouTube. AI-generated history videos with hundreds of thousands of views and many inaccuracies are drowning out fact-checked, expert-produced content. Popular music-remix videos are frequently created using this technology, and many of them perform better than human-made videos.\n\nThe problem extends far beyond YouTube, however. Most modern chatbots are “multimodal,” meaning they can respond to a question by creating relevant media. Google’s Gemini chatbot, for instance, will produce short clips for paying users. Soon, you may be able to ask ChatGPT or another generative-AI tool about how to build a table from found legs and get a custom how-to video in response. Even if that response isn’t as good as any video Peters would make, it will be immediate, and it will be tailor-made to your specifications. The online-publishing business has already been decimated by text-generation tools; video creators should expect similar challenges from generative-AI tools in the near future.\n\nMany major tech companies have used these data sets to train AI, according to research papers I’ve read and AI developers I’ve spoken with. The group includes Microsoft, Meta, Amazon, Nvidia, Runway, ByteDance, Snap, and Tencent. I reached out to each of these companies to ask about their use of these data sets. Only Meta, Amazon, and Nvidia responded. All three said they “respect” content creators and believe that their use of the work is legal under existing copyright law. Amazon also shared that, where video is concerned, it is currently focused on developing ways to generate “compelling, high-quality advertisements from simple prompts.”\n\nWe can’t be certain whether all these companies will use the videos to create for-profit video-generating tools. Some of the work they’ve done may be simply experimental. But a few of these companies have an obvious interest in pursuing commercial products: Meta, for instance, is developing a suite of tools called Movie Gen that creates videos from text prompts, and Snap offers “AI Video Lenses” that allow users to augment their videos with generative AI. Videos such as the ones in these data sets are the raw material for products like these; much as ChatGPT couldn’t write like Shakespeare without first “reading” Shakespeare, a video generator couldn’t construct a fake newscast without “watching” tons of recorded broadcasts. In fact, a large number of the videos in these data sets are from news and educational channels, such as the BBC (which has at least 33,000 videos in the data sets, across its various brands) and TED (nearly 50,000). Hundreds of thousands of others—if not more—are from individual creators, such as Peters.\n\nAI companies are more interested in some videos than others. A spreadsheet leaked to 404 Media by a former employee at Runway, which builds AI video-generation tools, shows what the company valued about certain channels: “high camera movement,” “beautiful cinematic landscapes,” “high quality scenes from movies,” “super high quality sci-fi short films.” One channel was labeled “THE HOLY GRAIL OF CAR CINEMATICS SO FAR”; another was labeled “only 4 videos but they are really well done.”\n\nDevelopers seek out high-quality videos in a variety of ways. Curators of two of the data sets collected here—HowTo100M and HD-VILA-100M—prioritized videos with high view counts on YouTube, equating popularity with quality. The creators of another data set, HD-VG-130M, noted that “high view count does not guarantee video quality,” and used an AI model to select videos of high “aesthetic quality.” Data-set creators often try to avoid videos that contain overlaid text, such as subtitles and logos, so these identifying features don’t appear in videos generated by their model. So, some advice for YouTubers: Putting a watermark or logo on your videos, even a small one, makes them less desirable for training.\n\nTo prepare the videos for training, developers split the footage into short clips, in many cases cutting wherever there is a scene or camera change. Each clip is then given an English-language description of the visual scene so the model can be trained to correlate words with moving images, and to generate videos from text prompts. AI developers have a few methods of writing these captions. One way is to pay workers to do it. Another is to use separate AI models to generate a description automatically. The latter is more common, because of its lower cost.\n\nAI video tools aren’t yet as mainstream as chatbots or image generators, but they are already in wide use. You may already have seen AI-manipulated video without realizing it. For example, TED has been using AI to dub speakers’ talks in different languages. This includes the video as well as the audio: Speakers’ mouths are lip-synched with the new words so it looks like they’re speaking Japanese, French, or Russian. Nishat Ruiter, TED’s general counsel, told me this is done with the speakers’ knowledge and consent.\n\nThere are also consumer-facing products for tweaking videos with AI. If your face doesn’t look right, for example, you can try a face-enhancer such as Facetune, or ditch your mug entirely with a face-swapper such as Facewow. With Runway’s Aleph, you can change the colors of objects, or turn sunshine into a snowstorm.\n\nThen there are tools that generate new videos based on an image you provide. Google encourages Gemini users to animate their “favorite photos.” The result is a clip that extrapolates eight seconds of movement from an initial image, making a person dance, cook, or swing a golf club. These are often both amazing and creepy. “Talking head generation”—for employee-orientation videos, for example—is also advancing. Vidnoz AI promises to generate “Realistic AI Spokespersons of Any Style.” A company called Arcads will generate a complete advertisement, with actors and voiceover. ByteDance, the company that operates TikTok, offers a similar product called Symphony Creative Studio. Other applications of AI video generation include virtual try-on of clothes, generating custom video games, and animating cartoon characters and people.\n\nSome companies are both working with AI and simultaneously fighting to defend their content from being pilfered by AI companies. This reflects the Wild West mentality in AI right now—companies exploiting legal gray areas to see how they can profit. As I investigated these data sets, I learned about an incident involving TED—again, one of the most-pilfered organizations in the data sets captured here, and one that is attempting to employ AI to advance its own business. In June, the Cannes Lions international advertising festival gave one of its Grand Prix awards to an ad that included deepfaked footage from a TED talk by DeAndrea Salvador, currently a state senator in North Carolina. The ad agency, DM9, “used AI cloning to change her talk and repurposed it for a commercial ad campaign,” Ruiter told me on a video call recently. When the manipulation was discovered, the Cannes Lions festival withdrew the award. Last month, Salvador sued DM9 along with its clients—Whirlpool and Consul—for misappropriation of her likeness, among other things. DM9 apologized for the incident and cited “a series of failures in the production and sending” of the ad. A spokesperson from Whirlpool told me the company was unaware the senator’s remarks had been altered.\n\nOthers in the film industry have filed lawsuits against AI companies for training with their content. In June, Disney and Universal sued Midjourney, the maker of an image-generating tool that can produce images containing recognizable characters (Warner Brothers joined the lawsuit last week). The lawsuit called Midjourney a “bottomless pit of plagiarism.” The following month, two adult-film companies sued Meta for downloading (and distributing through BitTorrent) more than 2,000 of their videos. Neither Midjourney nor Meta has responded to the allegations, and neither responded to my request for comment. One YouTuber filed their own lawsuit: In August of last year, David Millette sued Nvidia for unjust enrichment and unfair competition with regard to the training of its Cosmos AI, but the case was voluntarily dismissed months later.\n\nThe Disney characters and the deepfaked Salvador ad are just two instances of how these tools can be damaging. The floodgates may soon be opening further. Thanks to the enormous amount of investment in the technology, generated videos are beginning to appear everywhere. One company, DeepBrain AI, pays “creators” to post AI-generated videos made with its tools on YouTube. It currently offers $500 for a video that gets 10,000 views, a relatively low threshold. Companies that run social-media platforms, such as Google and Meta, also pay users for content, through ad-revenue sharing, and many directly encourage the posting of AI-generated content. Not surprisingly, a coterie of gurus has arrived to teach the secrets of making money with AI-generated content.\n\nGoogle and Meta have also trained AI tools on large quantities of videos from their own platforms: Google has taken at least 70 million clips from YouTube, and Meta has taken more than 65 million clips from Instagram. If these companies succeed in flooding their platforms with synthetic videos, human creators could be left with the unenviable task of competing with machines that churn out endless content based on their original work. And social media will become even less social than it is.\n\nI asked Peters if he knew his videos had been taken from YouTube to train AI. He said he didn’t, but he wasn’t surprised. “I think everything’s gonna get stolen,” he told me. But he didn’t know what to do about it. “Do I quit, or do I just keep making videos and hope people want to connect with a person?”",
      "source": "The Atlantic",
      "url": "https://www.theatlantic.com/technology/archive/2025/09/youtube-ai-training-data-sets/684116/",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Elon Musk Loses World's Richest Person Title To Larry Ellison",
      "content": "Elon Musk can no longer stake his claim as the richest person on Earth ... the distinction now belongs to Larry Ellison.\n\nThe Tesla honcho lost his title during early morning trading Wednesday, when Larry's net worth surged on the strength of his company, Oracle, which saw its stock price jump dramatically.\n\nLarry's fortune skyrocketed $101 billion to a whopping $393 billion ... thanks to a strong earnings report Tuesday evening from Oracle.\n\nElon's net worth, according to Bloomberg, is a paltry $385 billion ... meaning Musk is now looking up when it comes to the billionaire's index. Oh, the horror.\n\nLarry's accumulating tons of wealth thanks to artificial intelligence ... the rapid rise in Oracle stock is being primarily fueled by Oracle reporting huge demand for cloud services and four multibillion-dollar contracts with big AI companies like OpenAI and Nvidia.\n\nOracle stock is up 40% Wednesday ... and it's a huge windfall for Larry, who is the largest individual shareholder.\n\nBloomberg says Larry's $101 billion gain is the biggest one-day increase on record.\n\nDon't shed a tear for Elon ... he's largely held on to the title as world's richest person since 2021, mainly due to his Tesla and SpaceX stock.",
      "source": "TMZ",
      "url": "https://www.tmz.com/2025/09/10/elon-musk-no-longer-worlds-richest-person/",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Hands-on: Nvidia GeForce Now’s Blackwell upgrade looks great, but you’ll need the right games",
      "content": "As promised, Nvidia is launching its Blackwell upgrade today for GeForce Now, bringing RTX 5080-based machines to the cloud service alongside a whole slew of other upgrades.\n\nWith the move to Blackwell architecture, GeForce Now subscribers on the $20/month Ultimate plan will now have support for DLSS 4 directly in the cloud. It’s capable of streaming at 5K 120 FPS — though there are very few true 5K displays available on the market at the moment — alongside 360 FPS support when running at 1080p. I was able to take a test run prior to today’s launch, and so far, what I’m seeing looks (and feels) very promising.\n\nThat said, how you benefit from an upgrade to Blackwell might primarily depend on the games you play; as someone who primarily focuses on single-player RPGs — with a pretty deep backlog of older titles to boot — the upgrade isn’t quite as impressive as it might be, say, if your Steam library has doubled in size this calendar year alone. That’s not to say RTX 5080 machines can’t bring refreshed visuals or improved performance to older titles, but it won’t be quite as impactful as if you’re playing fresh AAA releases like Doom: The Dark Ages or Assassin’s Creed Shadows.\n\nSomething that will affect titles, though, are the upgrades to visual performance coming to GeForce Now as part of this launch. A new “Cinematic Quality” setting is designed to optimize for visuals over all else, and assuming you have the network connection to handle it, it does deliver a noticeably improved experience over legacy quality settings. The specs sheet here is fairly impressive: 10-bit HDR with 4:4:4 chrome sampling, new AV1 encoders for improved network adaptation, and refreshed sharpness filters to help improve HUDs and on-screen text.\n\nAdvertisement - scroll for more content\n\nGenerally, I’d say it’s a pretty big improvement, especially with a strong-enough connection. That said, on a big-enough display, anyone looking for imperfections can probably still find them. Text does look plenty legible, especially in games like The Witcher 3, where the HUD is fairly busy with plenty of information, and colors appear as rich and vibrant as if I was playing on, say, a PS5. But sitting close enough to a 32-inch 4K monitor, it’s still apparent that you’re watching a stream of a game, rather than the native gaming experience itself. That encoding sheen, for lack of a better phrase, is surprisingly downplayed, but it’ll likely even better with the right display — say, a television across your living room, or a Steam Deck in your hands.\n\nReally, the biggest problem still affecting GeForce Now is its library support, and in this case, I’m not just talking about whether or not your entire Steam library syncs with your account. While that remains frustrating — a solid 50 percent of my own backlog can’t be played with the service — the upgrade to RTX 5080 hardware is starting off slow. In fact, at launch (and, as a result, during my testing period), only 20 games actually support RTX 5080 machines, with more to come during the service’s usual GFN Thursday updates.\n\nThat’s not necessarily a dealbreaker — GeForce Now has certainly collected plenty of fans running on that last-gen hardware, and at least in terms of the games I play, I’m not sure I would’ve immediately noticed the difference in performance if I wasn’t specifically looking for 5080-supported titles. In these early days, though, it would be nice for Nvidia to specifically denote games that run on Blackwell. For now, here’s the list:\n\nApex Legends\n\nAssassin’s Creed Shadows\n\nBaldur’s Gate 3\n\nBlack Myth: Wukong\n\nBorderlands 4 (at launch)\n\nClair Obscur: Expedition 33\n\nCounter-Strike 2\n\nCronos: The New Dawn\n\nCyberpunk 2077\n\nDiablo 4\n\nDoom: The Dark Ages\n\nDune: Awakening\n\nDying Light: The Beast\n\nThe Elder Scrolls IV: Oblivion Remastered\n\nGrounded 2\n\nHell Is Us\n\nIndiana Jones and the Great Circle\n\nMafia: The Old Country\n\nMicrosoft Flight Simulator 2024\n\nOverwatch 2\n\nTitan Quest II\n\nWarframe\n\nThe Witcher 3\n\nOverall, I’m pretty impressed with just how good GeForce Now has gotten over the last couple of years. Cloud gaming has had plenty of ups and downs over the last half-decade, but when it comes to Nvidia’s service, it’s really the latency that continues to impress me. The improvements Blackwell is bringing to the table should continue to keep GeForce Now at the top of the list when it comes to the overall experience, but they’ll need to keep delivering upgraded games at a relatively quick pace to do it.",
      "source": "9to5google.com",
      "url": "http://9to5google.com/2025/09/10/hands-on-nvidia-geforce-now-blackwell-upgrade/",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Why Is Nvidia Stock (NVDA) Soaring Today?",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_3611cebf-629a-48f9-b1db-1e48ee04e959",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Nvidia’s latest RTX Remix update brings path-traced particles to classic games — major overhaul promises 'tens of thousands' of particles without significant performance reduction",
      "content": "Nvidia’s modding platform for retrofitting classic games with ray tracing has just had a huge overhaul. On September 9, Nvidia announced major updates to RTX Remix, including an “advanced path-traced particle system” that adds real-time particle effects like fire and smoke with full lighting and animation controls, without touching the original game engine.\n\nThe new particle system was introduced in a standalone update to RTX Remix available through the Nvidia app. Fundamentally, the GPU particle simulation behaves like a native part of the ray-traced world, with particles casting and receiving shadows, reflecting in surfaces, and responding to both physics and the camera.\n\nWith the update, Nvidia is giving modders the kind of visual effects tools that are usually reserved for modern game engines. The company claims that “tens of thousands” of path-traced particles can be rendered “without significantly reducing performance.”\n\nThat’s a bold claim that’s likely to draw scrutiny. In previous RTX Remix projects like Portal RTX , particle-heavy scenes have pushed high-end GPUs to their limits , even with DLSS enabled. While Nvidia explicitly recommends RTX 30-series cards as the baseline for an acceptable experience, some players with 3090-class GPUs reported dips well below 60 fps in particle-heavy scenes.\n\nNVIDIA RTX Remix | Half-Life 2 RTX Fire Particles - YouTube Watch On\n\nThe updates also introduce a more streamlined authoring workflow. Modders can now tag textures in-game as particle emitters via the Alt+X developer menu and tweak properties like size and color directly within the Remix UI. The more advanced Remix Toolkit adds scripting support for lighting behaviors and collision physics powered by PhysX in the backend, according to Nvidia’s documentation .\n\nNvidia says that over 165 games are compatible with RTX Remix, provided they use DX8 or DX9 with fixed-function pipeline. That still leaves plenty of room for quirks like potential crashes and rendering issues in some titles, but there’s no denying that RTX Remix is becoming a more powerful and practical tool by the month for modders committed to rebuilding classic games.\n\nSince its release, the RTX Remix community has breathed new life into classic games like Half-Life 2, Need for Speed Underground, and Deux Ex, with more than 2 million downloads to date.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/video-games/nvidia-rtx-remix-update-brings-path-traced-particles",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Nvidia GeForce Now RTX 5080 (Blackwell) Review: RTX 5080 in a MacBook",
      "content": "It goes further with 4:4:4 color sampling as opposed to the 4:2:0 sampling GeForce Now typically uses, and Nvidia includes a couple of AI-driven filters for your in-game HUD and menus that help them look extra sharp, a common weak point when streaming games from the cloud. I booted up Cyberpunk 2077 to try out this mode on a MacBook Air, immediately cranking the graphics as high as they can go. It was locked at 60 fps. Despite a much lower frame rate than what I saw in Silksong, my latency still hovered between 35 and 40 milliseconds. The feel was spot-on; the quality, however, wasn't perfect.\n\nIt's almost as if Nvidia is pushing too much data through the pipeline. You can tell the extra visual quality is there, but on a high-resolution display sitting close to your face, the finer details are lost in what feels like a faint layer of frosted glass. If you're a couple of feet away (or even better, sitting on a couch with GeForce Now on your TV), you won't be able to tell. Up close and personal, the seams become more obvious.\n\nOutside of Cinematic quality, the RTX 5080 comes with Nvidia's DLSS Multi-Frame Generation (MFG). It can generate up to three frames for every rendered frame, and I found it particularly useful in games that are a little more demanding but still competitive, like Marvel Rivals.\n\nMFG introduces additional latency, which I assumed would be a death sentence in the context of GeForce Now. I was wrong. You can pick up on minuscule latency differences with MFG using it natively, but in the cloud, the network latency has a way of obfuscating that lag.\n\nDoubling the Library\n\nGeForce Now via Jacob Roach\n\nNvidia consistently adds new games to the GeForce Now library. It's so consistent that Nvidia established GFN Thursday, where it announces new games coming to the service every week, usually with at least half a dozen new titles. They've added up quickly, with GeForce Now supporting over 2,300 games. The Blackwell update doubles the library size to over 4,500 titles with Nvidia's new install-to-play (I2P) feature.",
      "source": "Wired",
      "url": "https://www.wired.com/review/nvidia-geforce-now-rtx-5080-blackwell/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Nvidia-baked Cusp AI Raises $100m In Series A Funding",
      "content": "As European companies seek listings in the US, others are changing the way our industries work. Cusp AI is a platform that acts like a search engine for novel materials, enabling customers to specify the exact properties they need and generating new, synthesisable candidates up to 10x faster than traditional discovery methods. They've recently secured $100 million in Series A funding round - with backers including Nvidia and Singapore's sovereign wealth fund. The startup has also locked in partnerships with Hyundai and Meta. Bloomberg's Tom Mackenzie spoke exclusively to Cusp AI co-founder and CEO, Chad Edwards.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/nvidia-baked-cusp-ai-raises-084416380.html",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Klarna’s $17 billion IPO has just turned 40 staffers into overnight millionaires—while Nvidia, Canva, and Palantir workers are seeing similar gains",
      "content": "Klarna made its New York Stock Exchange debut this week, sending its market cap soaring to $15 billion—propelling around 40 staffers to millionaire status overnight, with its executive team gaining the most from the IPO. It’s not the first time Klarna’s success has created ultrarich employees—at least 115 of its workers have hit seven-figure net worths since 2021. And staffers at other tech companies, including Nvidia, Canva, and Palantir, who invested early have also made it into the exclusive wealth club.\n\nMany might think that only savvy investors, pioneering founders, and rising CEOs become millionaires overnight—but employees are reaping seven-figure net worths from the successes of their companies, too. Three dozen lucky Klarna staffers just joined the ultrarich club thanks to its recent stock windfall.\n\nKlarna made its New York stock market trading debut this week, with shares skyrocketing after the fintech company and its backers raised $1.37 billion in an initial public offering (IPO). The business’s shares shot up as much as 43% on Wednesday, opening at $52 a share and closing at around $45.82 each, well above the IPO price of $40 ahead of the listing. This shot up Klarna’s market cap to a whopping $17 billion—and it’s estimated that the stock surge catapulted more than 40 current and former Klarna staffers up into the millionaires’ club, thanks to its employee stock perks.\n\nOf course, the fintech company’s cofounders, Sebastian Siemiatkowski and Victor Jacobsson, had the most to gain from the debut. Despite leaving the company in 2012, Jacobsson still held on to 31.4 million shares valued at $1.1 billion at the time of the IPO—and will reportedly sell 2.5% of them.\n\nMeanwhile, CEO Siemiatkowski owns 25.6 million shares with a value of $920 million. And dozens of other staffers benefited as well; there are 37 former and current Klarna employees who now hold shares worth more than $1 million, according to an analysis from startup publication Sifted.\n\nKlarna declined Fortune’s request for comment.\n\nKlarna executives had the most to gain among the new staffed millionaires\n\nAside from the cofounders, many of the Swedish fintech company’s executive team had the most to gain thanks to their enviable stock portfolios.\n\nFor example, Klarna’s chief product and design officer, David Fock, owns more than 600,000 shares worth a total of $21.6 million—and at the IPO, he plans to sell almost 40% of his stock, according to Sifted reporting.\n\nMeanwhile Niclas Neglén, the company’s chief financial officer, holds around 280,000 shares worth $10 million and plans to sell 8%. And chief marketing officer David Sandström, who owns about 290,000 shares valued at $10.4 million, seeks to offload 30%.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/klarna-17-billion-ipo-just-153530675.html",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "NVIDIA, AI & Quantum Leaders Drive Health Tech: 2 Stocks to Buy",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_d4b18937-bf7c-4942-bdd2-a019913f45ed",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "La-Proteina",
      "content": "La-Proteina: Atomistic Protein Generation via Partially Latent Flow Matching\n\nAbstract. Recently, many generative models for de novo protein structure design have emerged. Yet, only few tackle the difficult task of directly generating fully atomistic structures jointly with the underlying amino acid sequence. This is challenging, for instance, because the model must reason over side chains that change in length during generation. We introduce La-Proteina for atomistic protein design based on a novel partially latent protein representation: coarse backbone structure is modeled explicitly, while sequence and atomistic details are captured via per-residue latent variables of fixed dimensionality, thereby effectively side-stepping challenges of explicit side-chain representations. Flow matching in this partially latent space then models the joint distribution over sequences and full-atom structures. La-Proteina achieves state-of-the-art performance on multiple generation benchmarks, including all-atom co-designability, diversity, and structural validity, as confirmed through detailed structural analyses and evaluations. Notably, La-Proteina also surpasses previous models in atomistic motif scaffolding performance, unlocking critical atomistic structure-conditioned protein design tasks. Moreover, La-Proteina is able to generate co-designable proteins of up to 800 residues, a regime where most baselines collapse and fail to produce valid samples, demonstrating La-Proteina's scalability and robustness.\n\nFind the Model Card++ for La-Proteina here.\n\nSetup\n\nFor environment setup mamba or micromamba is recommended, but alternatively conda can also be used as a drop-in replacement (substitute mamba with conda ).\n\nmamba env create -f environment.yaml mamba activate laproteina_env pip install torch==2.7.0 --index-url https://download.pytorch.org/whl/cu118 pip install graphein==1.7.7 --no-deps pip install torch_geometric torch_scatter torch_sparse torch_cluster -f https://data.pyg.org/whl/torch-2.7.0+cu118.html\n\nPlease download all model checkpoints into the ./checkpoints_laproteina directory, as indicated in the Checkpoints section, which is necessary to sample our models.\n\nIf you are only interested in sampling our models, please go to Sampling our models.\n\nTo train models and use our minimal dataloaders, create a file .env in the root directory of the repo with the single line\n\nDATA_PATH=/directory/where/you/want/dataset\n\nIn the paper we train our models on subsets of the AFDB. We provide lists of IDs for each dataset in laproteina_afdb_ids.zip.\n\nDataloaders\n\nWe provide minimal dataloader implementations that allow training on different subsets of the PDB. Here we describe how to use these minimal dataloaders. Note that all our models are trained on subsets of the AFDB, not on the PDB, as described in the paper. We provide the indices of the AFDB used for the datasets described in the paper here.\n\nPDB dataloader\n\nTo use the PDB dataloader, you can for example use the pdb_train_ucond.yaml file, which we provide as part of our configs/dataset/pdb directory, in the following way:\n\nimport os import hydra import lightning as L L.seed_everything(43) version_base = hydra.__version__ config_path = </path/to/datasets_configs> hydra.initialize_config_dir(config_dir=f\"{config_path}/pdb\", version_base=version_base) cfg = hydra.compose( config_name=\"pdb_train\", return_hydra_config=True, ) pdb_datamodule = hydra.utils.instantiate(cfg.datamodule) pdb_datamodule.prepare_data() pdb_datamodule.setup(\"fit\") pdb_train_dataloader = pdb_datamodule.train_dataloader()\n\nWith this, the dataloader selects all PDB chains according to the selection criteria specified in the yaml file, downloads, processes and splits the data and generates ready-to-use dataloaders and datamodules. For simple demonstration we subsample the dataset in pdb_train_ucond.yaml via the fraction attribute; for the full dataset change this value to 1.\n\nModel training\n\nVAE training\n\nRun the command python proteinfoundation/partial_autoencoder/train.py . Certain parameters, such as KL weight use for the loss, how often to save checkpoints, wandb logging, etc, can be controlled from configs/training_ae.yaml .\n\nUnconditional training\n\nRun the command python proteinfoundation/train.py . This will start training according to the configuration specified in configs/training_local_latents.yaml , specifying the autoencoder checkpoint, and the neural network config (for unconditional models use - nn: local_latents_score_nn_160M ), learning rate, among other parameters.\n\nMotif-scaffolding partially latent flow matching training\n\nTraining indexed all-atom vs. indexed tip-atom scaffolding models. For indexed all-atom scaffolding, set the dataset, line 11 of configs/training_local_latents.yaml , to - dataset: pdb/pdb_train_motif_aa , and the neural network, line 12 of configs/training_local_latents.yaml , to - nn: local_latents_score_nn_160M_motif_idx_aa . For indexed tip-atom scaffolding, set them to - dataset: pdb/pdb_train_motif_tip and - nn: local_latents_score_nn_160M_motif_idx_tip .\n\nTraining unindexed all-atom vs. unindexed tip-atom scaffolding models. Set the architecture, line 12 of configs/training_local_latents.yaml , to - nn: local_latents_score_nn_160M_motif_uidx (all-atom and tip-atom use the same neural network in the unindexed case). For unindexed all-atom scaffolding, set the dataset, line 11 of configs/training_local_latents.yaml , to - dataset: pdb/pdb_train_motif_aa . For indexed tip-atom scaffolding, set them to - dataset: pdb/pdb_train_motif_tip and - nn: local_latents_score_nn_160M_motif_idx_tip .\n\nOnce the config is modified accordingly, run python proteinfoundation/train.py .\n\nTraining/Sampling with compiled models\n\nSince our transformer-based architecture is amenable to hardware optimizations, we leverage the torch compilation framework to speed up training and inference. This feature is by default disabled in this repository, but can be enabled easily:\n\nFor sampling, just outcomment the torch.compile line in the forward method in proteinfoundation/nn/local_latents_transformer.py and proteinfoundation/nn/local_latents_transformer_unindexed.py .\n\nline in the forward method in and . For training, in addition you need to enable the PaddingTransform with the appropriate max_size argument to make all batches the same length across the sequence dimension. By default, we only pad the batches to the longest sequence in the batch for efficiency reasons, but to leverage compilation this size should be constant.\n\nSampling\n\nCheckpoints\n\nLa-Proteina consists of two models, the autoencoder and the latent diffusion. All checkpoints should be downloaded and placed in the directory ./checkpoints_laproteina in the codebase's root directory. The code loads checkpoints from this directory automatically. All checkpoints can be found here. We also provide individual links below.\n\nWe provide weights for the following latent diffusion models (for autoencoders see next paragraph):\n\n(LD1) Unconditional generation, no triangular update layers, generation up to 500 residues: LD1_ucond_notri_512.ckpt.\n\n(LD2) Unconditional generation, triangular multiplicative update layers, generation up to 500: LD2_ucond_tri_512.ckpt.\n\n(LD3) Unconditional generation, no triangular update layers, generation between 300 and 800 residues: LD3_ucond_notri_800.ckpt.\n\n(LD4) Indexed atomistic motif scaffolding, all atom: LD4_motif_idx_aa.ckpt.\n\n(LD5) Indexed atomistic motif scaffolding, tip atom: LD5_motif_idx_tip.ckpt.\n\n(LD6) Unindexed atomistic motif scaffolding, all atom: LD6_motif_uidx_aa.ckpt.\n\n(LD7) Unindexed atomistic motif scaffolding, tip atom: LD7_motif_uidx_tip.ckpt.\n\nEach La-Proteina model requires an autoencoder in addition to the latent diffusion model. We provide three different autoencoder checkpoints since each one is trained for proteins of different lengths: up to 256 residues for atomistic motif scaffolding, up to 512 residues for unconditional generation up to 500 residues, and up to 896 residues for unconditional generation of longer chains:\n\n(AE1) Autoencoder for unconditional generation up to 500 residues, which should be used with models (LD1, LD2): AE1_ucond_512.ckpt.\n\n(AE2) Autoencoder for unconditional generation between 300 and 800 residues, which should be used with model (LD3): AE2_ucond_800.ckpt.\n\n(AE3) Autoencoder for atomistic motif scaffolding, which should be used with model (LD4, LD5, LD6, LD7): AE3_motif.ckpt.\n\nSampling different configurations\n\nWe provide config files and commands to sample our different models. All models can be sampled by running\n\npython proteinfoundation/generate.py --config_name <config_name>\n\nfor the corresponding config file.\n\nUnconditional generation:\n\nUnconditional samples from the LD1 model: Run python proteinfoundation/generate.py --config_name inference_ucond_notri . This will use noise scales of 0.1 for the alpha carbon atoms and 0.1 for the latent variables, and will produce 100 samples for each of the lengths in [100, 200, 300, 400, 500]. These values can be changed in the config file configs/generation/uncod_codes.yaml .\n\nUnconditional samples from the LD2 model: Run python proteinfoundation/generate.py --config_name inference_ucond_tri . This will use noise scales of 0.1 for the alpha carbon atoms and 0.1 for the latent variables, and will produce 100 samples for each of the lengths in [100, 200, 300, 400, 500]. These values can be changed in the config file configs/generation/uncod_codes.yaml .\n\nUnconditional samples from the LD3 model: Run python proteinfoundation/generate.py --config_name inference_ucond_notri_long . This will use noise scales of 0.15 for the alpha carbon atoms and 0.05 for the latent variables, and will produce 100 samples for each of the lengths in [300, 400, 500, 600, 700, 800]. These values can be changed in the config file configs/generation/uncod_codes_800.yaml .\n\nConditional generation: We provide models for atomistic motif scaffolding for four different setups: indexed all-atom, indexed tip-atom, unindexed all-atom, unindexed tip-atom. Please check the paper for precise descriptions of each setup. The lists of atomistic motif scaffolding tasks can be found in configs/generation/motif_dict.yaml , where you'll also find the specification (contig string) for each task. Tasks ending with the \"_TIP\" suffix should be used for tip-atom scaffolding models (indexed and unindexed), and tasks without the \"_TIP\" suffix in their names should be used for the all-atom scaffolding models. Note that the following four tasks (indexed all-atom, indexed tip-atom, unindexed all-atom, unindexed tip-atom) require some small changes in the codebase, as indicated below for each specific case. These changes involve how to map motif residues to sequence indices (different in indexed vs. unindexed) or how the exact features used as input to the model are built.\n\nConditional samples from the LD4 model, indexed and all-atom atomistic motif scaffolding: Run python proteinfoundation/generate.py --config_name inference_motif_idx_aa . This will use a temperature of 0.1 for the alpha carbon atoms and 0.1 for the latent variables. The motif task can be specified in the config file configs/inference_motif_idx_aa.yaml , and the number of samples produced in the configs/generation/motif.yaml file. This model should be used for all-atom tasks, that is, the ones that do not contain the \"_TIP\" suffix in their name. For this model you need to use lines 1851 and 1852 in proteinfoundation/nn/feature_factory.py , and lines 228 to 230 in ./proteinfoundation/evaluate.py .\n\nConditional samples from the LD5 model, indexed and tip-atom atomistic motif scaffolding: Run python proteinfoundation/generate.py --config_name inference_motif_idx_tip . This will use a temperature of 0.1 for the alpha carbon atoms and 0.1 for the latent variables. The motif task can be specified in the config file configs/inference_motif_idx_tip.yaml , and the number of samples produced in the configs/generation/motif.yaml file. This model should be used for tip-atom tasks, that is, the ones that contain the \"_TIP\" suffix in their name. For this model you need to use lines 1847 and 1848 in proteinfoundation/nn/feature_factory.py , and lines 228 to 230 in ./proteinfoundation/evaluate.py .\n\nConditional samples from the LD6 model, unindexed and all-atom atomistic motif scaffolding: Run python proteinfoundation/generate.py --config_name inference_motif_uidx_aa . This will use a temperature of 0.1 for the alpha carbon atoms and 0.1 for the latent variables. The motif task can be specified in the config file configs/inference_motif_uidx_aa.yaml , and the number of samples produced in the configs/generation/motif.yaml file. This model should be used for all-atom tasks, that is, the ones that do not contain the \"_TIP\" suffix in their name. For this model you need to use lines 1851 and 1852 in proteinfoundation/nn/feature_factory.py , and lines 233 to 240 in ./proteinfoundation/evaluate.py .\n\nConditional samples from the LD7 model, unindexed and tip-atom atomistic motif scaffolding: Run python proteinfoundation/generate.py --config_name inference_motif_uidx_tip . This will use a temperature of 0.1 for the alpha carbon atoms and 0.1 for the latent variables. The motif task can be specified in the config file configs/inference_motif_uidx_tip.yaml , and the number of samples produced in the configs/generation/motif.yaml file. This model should be used for all-atom tasks, that is, the ones that contain the \"_TIP\" suffix in their name. For this model you need to use lines 1847 and 1848 in proteinfoundation/nn/feature_factory.py , and lines 233 to 240 in ./proteinfoundation/evaluate.py .\n\nEvaluation\n\nOur evaluation pipeline requires ProteinMPNN to compute (co-)designability. Running bash script_utils/download_pmpnn_weights.sh in the codebase root directory will download the required weights to the correct location. Note that these weights only needed for the evaluation pipeline, not for sampling our models.\n\nWe provide code to compute (co-)designability of the samples produced by our models in proteinfoundation/evaluate.py . For the motif scaffolding tasks it also computes motif RMSD values and motif sequence recovery. Run python proteinfoundation/evaluate.py --config_name <config_name> . Please see this bash script example which can be used to sample some one of our models and evaluate the resulting samples.\n\nExplanation of config file parameters\n\nThis section briefly explains the multiple parameters in the inference config files. All inference config files are based on configs/experiment_config/inference_base_release.yaml . Then, the config files for the corresponding experiments (e.g. inference_ucond_notri.yaml simply overrides some parameters in the base config). Some of the parameters in these config files are:\n\nckpt_name determines the checkpoint for the latent diffusion model. Only requires the checkpoint name, not full path.\n\ndetermines the checkpoint for the latent diffusion model. Only requires the checkpoint name, not full path. autoencoder_ckpt_path determines the checkpoint for the autoencoder. Requires full path to checkpoint.\n\ndetermines the checkpoint for the autoencoder. Requires full path to checkpoint. self_cond specifies whether to use self-conditioning during sampling. All our evaluations are done with self-conditioning, as we observe that yields better performance.\n\nspecifies whether to use self-conditioning during sampling. All our evaluations are done with self-conditioning, as we observe that yields better performance. sc_scale_noise controls the noise scale (for alpha carbon atoms and latent variables, can be set separately).\n\nLicense\n\nSource code is released under the Apache 2.0 license. Please see the LICENSE. Model Weights are released under NVIDIA Open Model License Agreement. All other materials are released under the Creative Commons Attribution 4.0 International License, CC-BY 4.0.\n\nCitation\n\nCite our paper using the following bibtex item:",
      "source": "Github.com",
      "url": "https://github.com/NVIDIA-Digital-Bio/la-proteina",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Streaming Can’t Replace Your PC, but Nvidia’s Updated GeForce Now Comes Close",
      "content": "The best compliment I could ever lay at the feet of any game streaming service is that I can forget I was even using it. Nvidia’s GeForce Now service, which lets players run their own game library through the cloud, is better than ever with its most recent update. As a bonus, Nvidia’s $20-per-month “Ultimate” subscription doesn’t cost any more than it did previously, unlike TV streaming’s constant price gouging. Just know that when I say the service has improved, I mean the service is better at everything it was already great for.\n\nIs streaming the future of gaming? No, especially not for multiplayer. But when PC and console prices are more expensive than ever, GeForce Now could fill in the gaps when hardware starts to falter.\n\nGeForce Now RTX 5080 Update The performance uplift may not be significant for some games, but GeForce Now makes PC gaming far more accessible. 4 Pros Better performance across multiple games\n\nMore resolution options\n\nLittle latency\n\nBetter graphics in \"cinematic\" mode\n\n90Hz support on Steam Deck Cons Visuals can't be be native PC quality\n\nPoor for multiplayer\n\nMulti-frame gen is pointless over streaming\n\nNvidia let me try out its update to GeForce Now early, before it started rolling out to users on Wednesday. It upgrades some games to use a better GPU, dampens server latency, and makes games look better. As much as that sounds like a good deal, let’s remember who is making use of cloud gaming in the first place. Gamers running systems that can’t play today’s AAA games, whether they’re not powerful enough or incompatible altogether, can instead stream the game to their system for the cost of two large artisan coffees each month. That hasn’t changed with the update, but now PC players with a Steam backlog may be able to play far more games using Nvidia’s new Install-to-Play feature.\n\nDon’t expect miracles from RTX 5080\n\nNvidia’s latest update to GeForce Now allows some games to run on systems with the GeForce RTX 5080 GPU, rather than the last-gen RTX 4080. Not all games support this at launch, though titles that can get performance uplift with the new GPU, including older titles like Cyberpunk 2077 and new games such as Borderlands 4, benefit from extra frame rates and more graphics options. You may find you can push some titles with ray tracing settings that you weren’t able to before. I could get Cyberpunk 2077 running with path tracing enabled for ultra-realistic lighting effects and still have more than enough frame rates that I wasn’t completely relying on digital tricks or so-called “fake frames.”\n\nNvidia claims it pushed latency down as much as possible below 30ms to make games feel more seamless. That would be enough to receive my paternalistic nod of approval, but Nvidia also touts the RTX 5080’s multi-frame gen capabilities as a big reason why users should jump on the streaming bandwagon. This is an RTX 50-series Blackwell-exclusive software feature that inserts multiple generated—aka “fake”—frames in between each rendered frame, artificially increasing frame rates for more responsive gameplay. It’s the kind of feature that sounds great on paper, but in practice is more constrained. Users need to achieve more than 50 fps normally to make multi-frame gen work without introducing odd graphical glitches. Frame generation also introduces more latency, though Nvidia said it was able to tamp down on sluggishness with some help from its updated SuperPOD servers.\n\nI tried games with and without frame gen, and in most cases, I still think gamers can go without. In Indiana Jones and the Great Circle, I pushed it up to beyond 250 fps with 4x frame gen, and the experience didn’t feel any better than without any frame gen running at around 90 fps. The added latency runs counter to smooth frame rates. Plus, 90 fps is more than playable for single-player titles.\n\nIf you can afford a 360Hz monitor, which is now supported by GeForce Now, you can probably afford a non-streaming gaming device. And if you’re using a high-refresh-rate display, you’re likely playing multiplayer games. I could jump into Overwatch 2 or Counter-Strike 2 through streaming and about as well as usual (re: awful), but pushing the refresh rate to 360Hz also pares down the resolution to 1080p. Streaming is not the arena for competitive multiplayer. I doubt it ever could be.\n\nGeForce Now can’t replace PC gaming… yet\n\nI wasn’t as interested in running these games on my usual gaming PC. If you can play these games natively, then there’s no reason you should be spending an extra $20 on top of however much you blow on the next Steam sale. Instead, I wanted to see what happens when using devices like a 14-inch MacBook Pro with M4 chip, a Steam Deck, and even an Nvidia Shield set-top box, which—like a spunky grandfather—is still kicking despite its age.\n\nNvidia claims it reduced latency enough to enjoy games online or offline, but the real reason you get GeForce Now is to play your games without spending money on new hardware. Streaming is notorious for introducing odd visuals into high-fidelity 3D games. To remedy this, Nvidia introduced a new “Cinematic” quality mode that enhances colors and sharpens certain objects, like trees. This means a game like Assassin’s Creed: Shadows appears sharper than it did in previous versions of GeForce Now. The extra visual quality was enough to entice me to put a few more hours into a game I had already harangued back at launch.\n\nI took screenshots of both Baldur’s Gate III and Cyberpunk 2077 running natively and streaming on my 14-inch MacBook Pro. There are obvious quality differences between the two, plus Nvidia’s base HDR settings result in an overall darker image than natively. It’s a fully playable experience, but I still noticed a loss in detail on some terrain in Baldur’s Gate III and fuzz,y far-distant objects in Cyberpunk 2077.\n\nOf course, I was getting better frame rates through GeForce Now than playing each game on a MacBook Pro with M4 chip. For single player games, the latency never became a problem on my home Wi-Fi. Packet loss, where data goes missing moving between your device and the server, is also kept manageable. I do not have the best home Wi-Fi, but in tests, my internet bandwidth usually sits at 75Mbps with a 26ms latency. That’s more than enough for me to stream at 4K and even the new 5K resolution at 120 fps. Other people may not be so lucky to have the 54Mbps minimum required to achieve the highest resolution possible on GeForce Now.\n\nGood reminder of what games you own\n\nNvidia updated its existing Steam Deck app to play games with support for up to 90Hz refresh rate. Of all the devices I’ve tested with Nvidia’s streaming service, handhelds and other mobile devices are where GeForce Now shines. You can push the resolution in games beyond the Steam Deck’s 800p display, which will help reduce artifacts that pop up from streaming. I can settle down and play from lying down on my bed. Nvidia also released a version of the app for the Lenovo Legion Go S with SteamOS to support 120Hz gaming. That 8.8-inch display and 1200p resolution combine well with an RTX 5080 GPU to offer strong performance across titles. If the SteamOS handhelds are the most console-like devices you can take with you, then GeForce Now makes it so much easier to enjoy games without having to worry nearly as much about frame rate dips or battery life.\n\nYou still won’t find titles like Elden Ring available to stream on GeForce Now. However, Nvidia effectively opened up servers for users to download a whole host of new titles. These games remain on the servers until you log off, though you can rent out that space for an extra $3 a month if you want your games to remain.\n\nCurrently, Install-to-Play is mostly filled with the kind of older games or indie titles that don’t normally require much graphical power, which in turn means they don’t have enormous file sizes that take hours to download on Nvidia’s remote PCs. Going through the staggering 4,700 titles, you may think there are more games than it’s possible to try. Still, out of the 441 games in my Steam Library, only 15 of them were available through Install-to-Play. That ignores the titles that are fully streaming-ready on the service, which would push the actual number to 359 across my Steam, Epic, and Xbox libraries. Nvidia said it plans to add more games to the service as more developers opt in.\n\nDownloading games on these cloud-based PCs didn’t take much hassle. I could already play games like Mark of the Ninja perfectly well on my Steam Deck, but having access to it on my phone, should I want it, is a treat. I only hope Nvidia doesn’t use this feature to eventually dump games that are less played from its official servers, but at least we know we’ll still be able to download them, should that ever happen.\n\nGeForce Now is becoming more and more a go-to for me and my personal gaming habits. I enjoy using my Steam Deck at home for playing through Clair Obscur: Expedition 33 and then taking the device on the road to run through compatible games like Warhammer 40K: Rogue Trader. I’m at a point in my gaming life where my consoles and PCs are like chains that keep me tied to a desk or across a TV. I know the good times can’t last forever, and I’m waiting for the hammer blow of increased subscription costs or the inevitable enshittification that comes to all streaming services.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/streaming-cant-replace-your-pc-but-nvidias-updated-geforce-now-comes-close-2000657060",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Inside nuclear startup Terra Innovatum's plan to cash in on the SPAC comeback",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nBlank-check mergers are back on the cards — at least for nuclear startups.\n\nTerra Innovatum, a company developing micro-modular nuclear reactors, is one of the contenders. It's pursuing a SPAC by merging with GSR III Acquisition Corp, with the aim of raising around $230 million at a $475 million pre-money valuation.\n\nIts chief business development officer, Giordano Morichi, told Business Insider that the company is opting for a SPAC because the startup sees it as a smoother alternative to an IPO.\n\nMorichi said the startup didn't want to go through a funding round because it \"wanted a more regulated fundraising environment.\"\n\nMorichi, who joined the company last year to restrategize its business, has witnessed growing investor appetite for SPACs. He said the transaction's profits would help Terra propel the commercialization of its small-scale nuclear reactor technology.\n\nThe team has earmarked around $70 million to build its first unit, a cubic reactor that aims to deliver one megawatt of electricity through its standard fuel rods. The startup anticipates generating this through the listing, which is set for early autumn.\n\nThe SPAC process is much faster than that of a traditional IPO, and one that suits a pre-revenue company, said Alex Gadotti, a capital markets advisor at Park Avenue Capital, which is advising Terra Innovatum on the deal. \"It gives much, much more certainty on the proceeds, and the stock gives more control in the process than a normal IPO,\" he added.\n\nTerra Innovatum isn't alone in forgoing an IPO. Nuclear upstarts Terrestrial Energy and Eagle Energy Metals are also planning to merge with special purpose acquisition companies.\n\nTapping into the SPAC comeback\n\nThis year has been something of a turnaround for SPACs, which had their moment in the sun in 2020 before they were marred by challenges and disappointing exits. High-profile listings from 2021, such as BuzzFeed and Grab, plummeted the following year, dipping over 50% in value year on year. Investors became wary.\n\nThis year, there's been a steady uptick in SPAC activity. In the US, SPACs raised a total of $11 billion in the first half of 2025, compared with the $2 billion raised in the same period in 2024, per Bloomberg data. Notable listings include Sam Altman-backed nuclear company Oklo's merger with AltC Acquisition Corp, and the upcoming listing of firearms company GrabAGun, which counts Donald Trump Jr. as a board member, merging with Colombier Acquisition Corp. II.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nSome investors have pointed out the parallels between the electric vehicle SPAC boom of 2021 and the trajectory of nuclear startups today.\n\nEV heavyweight Fisker went public via a SPAC in 2020 and later went bankrupt, while ChargePoint has faced financial challenges since its 2021 SPAC.\n\nMorichi said that the EV juggernauts that fell from grace post-SPAC had their lofty, multibillion-dollar valuations to blame, but Terra Innovatum's $475 million pre-money valuation is much more \"reasonable\" for investors. The company intends to raise around $230 million, but this is subject to change as it has yet to disclose its pipeline.\n\nAI has catalyzed a frenzy for nuclear energy\n\nTerra Innovatum is building small-scale nuclear reactors, a technology that's been gaining investor traction as AI juggernauts scramble to power their energy-intensive data centers.\n\nCompanies spearheading the AI boom, from Google and Microsoft to Nvidia and OpenAI, have increasingly considered nuclear energy a viable source to meet AI's sky-high energy demands. Amazon took a stake in SMR developer X-Energy last year, while Google struck a nuclear energy deal with Kairos Power. This has given nuclear energy startups a boost as they find a purple patch to scale.\n\nTerra's thesis is that energy generation is bottlenecked by energy distribution, and developing micro reactors can tackle both issues.\n\n\"Having a reactor that can be next to a factory or hospital can be one of the biggest upsides,\" said Morichi. \"To do so, the reactor needs to be extremely safe. It needs to be small enough so it can't physically explode.\"\n\nOften, hydrogen explosions are the key cause of concern in nuclear reactors; the startup uses helium gas as an alternative to hydrogen to minimize this risk.\n\nHe added that Terra's micro modular reactors \"can't explode\" because they don't contain water, giving them a higher safety profile.\n\nMorichi acknowledges that other SMR companies may yield a higher energy output. But the company's selling point has been its scalability. The reactor's off-grid capability and modular design make it an attractive option for data center companies, he said.\n\nThe company is in talks to partner with data center providers, but declined to provide specifics as that information is not yet public.\n\nUnlike many clean energy companies dealing with the financial fallout from Donald Trump's \"Big Beautiful Bill,\" the team has actually been emboldened by federal policy that's \"propelling the wind in our sails,\" Morichi told Business Insider. The Nuclear Regulatory Commission announced it would be cutting fees for the process of licensing and reviewing nuclear projects, which Morichi said would help bring the reactors to market much quicker.\n\nIt's also avoided any major bruising from the administration's tariffs that have otherwise hampered supply chains globally. \"We have a seamless model for the supply chain. We have secured part of the supply chain in Italy and in the US, and we have different types of partners that will help on those fronts,\" he added.\n\nWhile the listing will be on the Nasdaq, the team ultimately has international ambitions. Energy resilience is not a national issue affecting only the US, but a global problem, Morichi said.\n\n\"Because we really want to deploy these reactors globally, it's important that we work with local entities and industries, not only to propel their own economic state value, but to help us enter the market,\" he said.\n\nCorrection: September 11, 2025 — An earlier version of this story misstated who Alex Gadotti works for.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/terra-innovatum-nuclear-spac-boom-2025-9",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "An Interview with Dan Kim About Intel, Nvidia, and the U.S. Government",
      "content": "Subscribe to Stratechery Plus for full access. Already subscribed? Log in $15 / month or $150 / year\n\nWith Stratechery Plus you get access to the subscriber-only Stratechery Update and Stratechery Interviews, and the Sharp Tech, Sharp China, Dithering, Greatest of All Talk, and Asianometry podcasts.\n\nStratechery Update\n\nSubstantial analysis of the news of the day delivered via three weekly emails or podcasts. Stratechery Interviews\n\nInterviews with leading public CEOs, private company founders, and discussions with fellow analysts. Dithering\n\nA twice-weekly podcast from John Gruber and myself: 15 minutes an episode, not a minute less, not a minute more. Sharp Tech\n\nAndrew Sharp and myself discuss how technology works and the ways it impacts our lives. Sharp China\n\nA weekly podcast from Andrew Sharp and Sinocism’s Bill Bishop about understanding China and how China impacts the world. Greatest Of All Talk\n\nA twice-weekly podcast from Andrew Sharp and Ben Golliver about the NBA, life, and national parks. Asianometry\n\nAudio and transcripts of the Asianometry YouTube channel, the best source for learning about how tech works.\n\nStratechery Updates are also available via SMS, RSS, or on this site. Please see the Stratechery Update Schedule for more details about delivery times and planned days-off. Please note that all subscriptions auto-renew monthly/annually (but can be cancelled at any time). If you are interested in ordering and managing multiple subscriptions for your team or company, please fill in the form here.\n\nFrequently-Asked Questions\n\nHow do I subscribe to the Stratechery Podcast? Once you are subscribed, please visit your Delivery Preferences where you will find easy-to-follow instructions for adding Stratechery Podcasts to your favorite podcast player.\n\nCan I read Stratechery via RSS? Yes! Create a Stratechery Passport account, go to Delivery Preferences, and add your personalized RSS feed. Free accounts will have access to Weekly Articles, while subscribers will have access to the Daily Update as well.\n\nCan I share a Stratechery Update subscription with a friend? No, the Stratechery Update and Stratechery Podcast are intended for one subscriber only. Sharing emails, using shared inboxes, or sharing RSS feeds is a violation of Stratechery’s Terms of Service, and your account may be suspended or your RSS feed reset. Of course occasional forwarding of the Stratechery Update to interested friends or colleagues is totally fine.\n\nCan I buy a subscription for my team? Yes! You can purchase a team subscription here.\n\nCan I switch to an annual plan? Yes! Just go to your account page, choose the ‘Subscriptions’ tab, and click the Annual upgrade button. You will be charged immediately, with a prorated discount applied for the remainder of your current monthly plan.\n\nDo you offer a student discount? Stratechery is purposely kept at a low price — thousands of dollars less than other analyst reports or newsletters — to ensure it is accessible to everyone, including students.\n\nCan you create a custom invoice that meets my government/company requirements? I am happy to create an invoice to your specification for annual subscribers; however, it is simply not viable for me to offer this service to monthly subscribers. Therefore, if you need a custom invoice please subscribe or switch to an annual subscription and contact Stratechery. June 1, 2021 Update: We are hoping to add native support for custom invoices to Passport; you can subscribe to Passport Updates to be notified when it is available.",
      "source": "Stratechery.com",
      "url": "https://stratechery.com/2025/an-interview-with-dan-kim-about-intel-nvidia-and-the-u-s-government/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Google TPUs Vs Nvidia GPUs",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/11/google-tpus-vs-nvidia-gpus/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Nvidia has launched a GPU with 128GB of GDDR7 RAM but yeah, there's no way it will sell one to us to run games",
      "content": "Nvidia announces Rubin CPX GPU with 128GB memory built for enterprise AI workloads\n\nVera Rubin NVL144 CPX rack delivers 8 exaFLOPs compute and 100TB fast memory\n\nShipments planned for late 2026 with Rubin Ultra and Feynman already on roadmap\n\nNvidia has announced a brand new GPU built on the Rubin architecture and designed for long-context AI workloads.\n\nRubin CPX, as it’s known, includes 128GB of GDDR7 memory, making it the company’s first GPU at that capacity.\n\nThere were rumors of a 128GB RTX gaming card, but this is 100% not that. This GPU is a compute engine aimed at inference in areas such as software development, research, and high-definition video generation. It will not be running Metal Gear Solid Delta: Snake Eater any time soon.\n\nVera Rubin NVL144 CPX rack\n\nThe GPU delivers up to 30 petaFLOPs of NVFP4 compute and integrates hardware attention acceleration that Nvidia says is three times faster than the GB300 NVL72.\n\nIt also incorporates four NVENC and four NVDEC units to accelerate video workflows.\n\nAs part of Nvidia’s broader push toward disaggregated inference, Rubin CPX is designed to handle the compute-heavy context phase, while other Rubin GPUs and Vera CPUs address generation tasks.\n\nBy concentrating Rubin CPX on context processing tasks, Nvidia aims to improve throughput while lowering high-value inference deployment costs.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nNvidia’s Dynamo software will manage things behind the scenes, handing low-latency cache transfers and routing across components.\n\nThe company’s largest deployment model is the Vera Rubin NVL144 CPX rack. Each unit integrates 144 Rubin CPX GPUs, 144 Rubin GPUs, and 36 Vera CPUs.\n\nTogether they deliver 8 exaFLOPs of NVFP4 compute, 100TB of high-speed memory, and 1.7PB/s of memory bandwidth.\n\nQuantum-X800 InfiniBand or Spectrum-X Ethernet with ConnectX-9 SuperNICs provide the connectivity.\n\nShipments of Rubin CPX and the NVL144 CPX racks are currently penciled in for late 2026, following the recent tape-out at TSMC.\n\nNvidia’s roadmap includes Rubin Ultra, now expected in 2027, and Feynman, slated for 2028.\n\nThose designs will extend the Rubin architecture with higher density modules, HBM4E memory, and faster networking.\n\nVia Videocardz\n\n(Image credit: Nvidia)",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/nvidia-has-launched-a-gpu-with-128gb-of-gddr7-ram-but-yeah-theres-no-way-it-will-sell-one-to-us-to-run-games",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Top Stock Reports for NVIDIA, Meta Platforms & Alibaba",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_35ba17c2-11fe-49ca-a1c5-2beafda45349",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "China’s souring on Nvidia. Here’s why",
      "content": "Beijing is souring on Nvidia.\n\nChina, which used to be one of Nvidia’s largest markets, seems largely conflicted about reaccepting Nvidia’s lower-tech H20 chips that Trump administration finally allowed to resume sales of in July. The Chinese tech industry might be excited about the Nvidia chip flow resuming, but the government is allegedly not.\n\nChinese authorities have discouraged local tech companies from purchasing Nvidia chips citing national security concerns, and even questioned industry titans like Tencent over their purchases of Nvidia chips, according to Reuters.\n\nIn response, tech giants like Alibaba and Baidu have begun using their own chips to train smaller AI models, the Information reported on Thursday, but they will reportedly continue to use some Nvidia chips.\n\n“The competition has undeniably arrived,” an Nvidia spokesperson told Gizmodo. “Customers will choose the best technology stack for running the world’s most popular commercial applications and open-source models. We’ll continue to work to earn the trust and support of mainstream developers everywhere.”\n\nChinese development is ramping up. China chip stocks have experienced a major boom so big that the Beijing-based company Cambricon had to warn investors recently. Tech giants like Huawei and Alibaba are leading the push, but smaller companies are also making strides.\n\nShanghai-based tech company MetaX told the Wall Street Journal last month that it’s preparing to start mass production of a new chip that has bigger memory than Nvidia’s H20.\n\nStill, largely no chip offering so far has been considered completely up to par with Nvidia’s best offerings. Reuters reported last week that top Chinese tech firms like Alibaba and ByteDance are still very keen to get their hands on Nvidia chips. That’s despite the fact that the Nvidia chips that are being sold to China are downgraded versions of existing models, developed to abide by U.S. exports restrictions.\n\nThe chips saga\n\nSome experts in Washington think any supply of American tech to China has sizable national security risks attached to it. They also claim the chips can assist China in outpacing American AI innovation.\n\nThe Biden administration was first to enforce export restrictions on Nvidia chips sold to China, in an effort to curb the entry of high-tech chips into China off of those fears.\n\nBeijing landed a particularly big blow to domestic AI confidence earlier this year with Deepseek’s R1, an AI model that rivaled the best of American companies offerings using lower cost chips, inadvertently showing Americans that Chinese innovation did not require the top Nvidia chips.\n\nThat fueled the blanket ban decision which turned out to be less effective than expected when a Financial Times report found that Nvidia’s highest tech chips were being smuggled into China in the absence of the lower tech H20s.\n\nThe decision was also a big hit to Nvidia: executives shared in a May earnings call that they had to revise revenue expectations down for the quarter by about $8 billion due to the restrictions.\n\nAfter an intense lobbying effort by Nvidia CEO Jensen Huang, Trump reversed his decision in July, allowing H20 chips sales to China. In exchange, Trump demanded that Nvidia, and fellow American chipmaker AMD, both give the U.S. government a 15% cut of all of their chips revenue in China.\n\nJust when Nvidia thought all was finally well, Beijing started raising concerns about the new Nvidia chips coming into China having kill switches and backdoors, urging Chinese companies to not use them. Nvidia has denied the claim.\n\nThe remaining political uncertainty has continued to cast a shadow on Nvidia’s performance in China. The company conceded in its latest earnings call that they were facing disappointing numbers from the region still and were yet to begin H20 shipments.\n\nWhy did Beijing change its mind?\n\nChina has a long relationship with Nvidia. The downturn in that relationship began after the first export restrictions went into effect, ramped up after an antitrust probe in December and has developed a life of its own under Trump’s trade war.\n\nChinese officials have voiced security concerns related to the latest round of chips set to enter the country, but this attitude change has less to do with Nvidia itself and more about China’s own chip industry.\n\nChinese AI industry is currently dependent on American chipmakers like Nvidia, and that gives Americans an edge. In the absence of Nvidia chips, China will have to develop their own high-tech chips that can rival and even surpass the quality of Nvidia chips. If that happens, the United States can be at jeopardy to lose its hold on the global chips demand, and China is the runner-up.\n\nThe country is making a big bet on AI, announcing an $8.2 billion AI-investment fund earlier this year, in an effort to spur innovation and reach independence.\n\n“It’s unfortunate to see that we in Asia, including China, are emulating the U.S. when it comes to developing algorithms and large models,” Wei Shaojun, an adviser to senior Chinese government officials and a professor at top Beijing university Tsinghua University told a forum in Singapore on Thursday. He warned that staying on this path of dependence could be “lethal” for the region, according to Bloomberg.\n\nAlong with the chips push, the country has increasingly emphasized global cooperation in AI, and center to that initiative is Beijing’s desire to cement itself at the center of the global AI trade.\n\nIt seems China is coming to terms with the fact that aspiration won’t be achievable as long as the industry is dependent on the U.S. for chips, especially when Washington has demonstrated that its trade policy decisions are volatile.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/chinas-souring-on-nvidia-heres-why-2000657632",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Chinese scientists claim to have built the first \"brain-like\" AI model — said to be up to 100 times faster than ChatGPT",
      "content": "In the mid-20th Century, we had the Space Race kick off, and in the mid-2020s, we're very much in the middle of the AI race. Nobody is sitting still, with parties all around the globe pushing for the next big advancements.\n\nChinese scientists are now making a big claim to have made one of their own. As reported by The Independent, SpikingBrain1.0 is a new large language model (LLM) out of China, which ordinarily might not be so exciting. But this isn't supposed to be any normal LLM. SpikingBrain1.0 is reported to be as much as 100x faster than current models such as those behind ChatGPT and Copilot.\n\nAll down to the way the model operates, which is something completely new. It's being touted as the first \"brain-like\" LLM, but what does that actually mean? First, a little background on how the current crop of LLMs work.\n\nThe current crop of LLMs work very differently to what's claimed of SpikingBrain1.0 (Image credit: Windows Central)\n\nBear with me on this one, hopefully I can make it make sense and as simply as possible. Essentially, the current crop of LLMs look at all of the words in a sentence at once. They're looking for patterns, relationships between words, whatever their position in the sentence.\n\nIt uses a method known as Attention. Take a sentence such as this:\n\n\"The Baseball player swung the bat and hit a home run.\"\n\nYou, as a human, read that sentence and instantly know what it means, because your brain immediately associates \"Baseball\" with the words that come after it. But to an LLM, the word \"bat\" on its own could be both a baseball bat or the animal. Without examining the rest of the sentence, it wouldn't be able to make that differentiation.\n\nAttention in an LLM will look at the whole sentence and then map out relationships between the words to understand it. It will identify the other terms, such as \"swung\" and \"baseball player,\" to identify the correct definition and make better predictions.\n\nThis connects with the training data for the LLM, where it will have learned that \"baseball\" and \"bat\" often go together.\n\nThe new model has been developed to rely not on NVIDIA hardware, running on homegrown chips from MetaX. (Image credit: Getty Images | WANG ZHAO)\n\nExamining whole sentences at once takes resources, though. And the larger the input, the more resources needed to understand it. This, in part, is why current LLMs generally need massive amounts of computing power. Every word is compared to every other word, and it consumes a lot of resources.\n\nSpikingBrain1.0 claims to mimic the human brain's approach, focusing only on nearby words, similar to how we would approach a sentence's context. A brain fires the nerve cells it needs to; it doesn't run at full power all of the time.\n\nThe net result is a more efficient process, with its creators claiming between 25x and 100x performance gains over current LLMs. Compared to something such as ChatGPT, this model is supposed to selectively respond to inputs, reducing its resource requirements to operate.\n\nAs written in the research paper:\n\n\"This enables continual pre-training with less than 2 percent of the data while achieving performance comparable to mainstream open-source models.”\n\nPerhaps equally interesting, at least for China, is that the model has been built not to rely on GPU compute from NVIDIA hardware. It has been tested on a locally produced chip from a Chinese company, MetaX.\n\nCould SpikingBrain1.0 lead to a path where we need less of these to power AI? (Image credit: Windows Central | Ben Wilson)\n\nThere is, of course, much to be considered, but on paper at least, SpikingBrain1.0 could be a logical next evolution of LLMs. Much has been made of the impact AI will have on the environment, with vast energy requirements and equally vast requirements to cool these massive data centers.\n\nIt's bad enough running LLMs in Ollama at home with an RTX 5090. My office gets hot, and with a graphics card that can draw close to 600W, it's hardly efficient. Scale that thought up to a data center full of GPUs.\n\nThis is an interesting development if it all pans out to be accurate. It could be the next leap forward, but only if the balance of accuracy and efficiency is there. Exciting times for sure, though.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/artificial-intelligence/chinese-scientists-claim-to-have-built-the-first-brain-like-ai-model",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Borderlands 4 Dev Gearbox Asks PC Gamers to Keep Playing for at Least 15 Minutes After They Tweak Settings to See How Performance Has Changed, as Negative Steam Reviews Pile Up",
      "content": "Borderlands 4 has launched on Steam to big concurrent player numbers, but the release was marred by complaints about PC performance that have resulted in a ‘mixed’ user review rating on Valve’s platform.\n\nBorderlands 4 peaked at 207,479 concurrent player numbers on Steam yesterday, September 11, which was significantly higher than any previous Borderlands before it. However, the game launched to ‘mostly negative’ Steam reviews over performance issues and crashing, before recovering overnight to ‘mixed.’\n\nThe complaints revolve around poor performance even on high powered PCs, with some affected by crashing that makes the game difficult to even start.\n\n“Terrible optimization. Another Unreal Engine 5 casualty. Not worth buying in its current state unless you have a NASA PC,” said one person in a negative review.\n\n“Terrible, terrible performance. Worst I've ever seen. Turned it down to Low graphics presets and couldn't hit 60 FPS, even with FSR upscaling on my RX 6900 XT,” said another.\n\nIn response, Gearbox posted a Borderlands 4 Nvidia Optimization guide on Steam, advising players how to optimize their graphics settings for “better performance and framerates” on PC with the Nvidia app.\n\n“As PC gamers begin their Vault-hunting journeys in Borderlands 4, we've seen early feedback from the community surrounding graphics settings and how to achieve optimal performance,” Gearbox said, before outlining the “expected results” for the Borderlands 4 PC specs:\n\nMinimum PC specs - 1080p @ 30FPS with Low Preset settings\n\nRecommended PC specs - 1440p @ 60FPS with Medium Preset settings\n\nGearbox then issued a piece of advice to PC gamers that to me reads like an effort to prevent players from making knee-jerk reactions to the game's performance as soon as they’ve changed their settings: “Please note that any time you change any of your graphics settings, your shaders will need to recompile. Please keep playing for at least 15 minutes to see how your PC's performance has changed.”\n\nGearbox went on to show the “Optimal Settings” charts provided by Nvidia with suggestions for which graphics settings may work best for your combination of GPU and desired display resolution. Meanwhile, it recommended using the Nvidia app to download and install Nvidia’s newest Game Ready Driver (581.29) and “optimize for your system.” If all else fails, “please contact 2K Support for direct assistance.”\n\nBorderlands 4 Review Screenshots View 159 Images\n\nGearbox and publisher 2K Games will be keen to address the performance complaints early, given the impact negative reviews on Steam can have on a video game’s success. Ahead of launch, Gearbox development chief Randy Pitchford had said the Borderlands 4 Day 1 patch “does a lot,” amid concern about the performance of the looter shooter. Pitchford had responded to concern about Borderlands 4’s pre-release performance on PC from some users on X / Twitter.\n\nDespite the Day 1 patch, playing Borderlands 4 on older hardware won't miraculously unlock \"buttery smooth performance,\" Pitchford added. It should be expected that Borderlands 4 is “unplayable” if you’re trying to use a PC below min-spec, he said, and, generally, playing new AAA games on older hardware won't achieve impressive results.\n\nHere’s Pitchford's comment in full:\n\nThe Day 1 patch does a lot! That said, the expectation for using a below min-spec machine should be that the game is unplayable. That the game runs at all on your system is a miracle. That you can get 55 - 60 fps out of heavy combat is actually incredible given how the engine and what's going on under the hood. Your specification doesn't indicate if you're on SDD or HDD, but that could also explain some of the hitching. It's a big, bold, new, seamless world and I'm sorry to say that older hardware may not provide buttery smooth performance for the latest gen AAA games, as has always been the case since the dawn of PC gaming.\n\nAs a reminder, here are Borderlands 4’s PC specs:\n\nBorderlands 4 System Requirements:\n\nMinimum:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-9700 / AMD Ryzen 7 2700X\n\nMemory: 16 GB RAM\n\nGraphics: NVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. Requires 8 CPU Cores for processor. Requires 8 GB VRAM for graphics. SSD storage required\n\nRecommended:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nMemory: 32 GB RAM\n\nGraphics: NVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. SSD storage required\n\nIf you are delving into Borderlands 4 don't go without our updated hourly SHiFT codes list. We've also got a huge interactive map ready to go and a badass Borderlands 4 planner tool courtesy of our buds at Maxroll. Plus check out our expert players' choices for which character to choose (no one agreed).\n\nWesley is Director, News at IGN. Find him on Twitter at @wyp100. You can reach Wesley at wesley_yinpoole@ign.com or confidentially at wyp100@proton.me.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/borderlands-4-dev-gearbox-asks-pc-gamers-to-keep-playing-for-at-least-15-minutes-after-they-tweak-settings-to-see-how-performance-has-changed-as-negative-steam-reviews-pile-up",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "I tried the new recommended settings for Borderlands 4 and oh no, they don’t actually fix its stuttering",
      "content": "It’s been a rough first day at the office for Borderlands 4, which has launched amid spyware denials and widespread user reports of dodgy PC performance. That being crashing, stuttering, the usual Unreal Engine 5 trouble at the mill. Framerate-related grumbling in particular has prompted a Steam post from Gearbox, presenting a setting-by-setting guide to optimisation on GeForce graphics cards that their pals at Nvidia put together.\n\nFirst off, oi, that’s my job. Second, I say \"prompted\", but the sheer number of GPUs it covers – separately for 1080p, 1440p, and 4K resolutions – has produced settings tables so rich in cells that it’s far more likely a sweating intern has spent the entire past week cranking these out. No disrespect, obviously. Solidarity to benchmarkers. But, are these guides reliable?\n\nLet’s start by taking a my god, look at the size of it.\n\nImage credit: 2K\n\nMaybe the text version further down the post is more easily readable?\n\nImage credit: 2K\n\nAh. JPG it is then, where we can see that even at 1080p, Borderlands 4 thinks you should run it with both DLSS upscaling and frame generation. I booted up the RPS Test Rig with an 8GB RTX 4060 Ti, one of the included cards, and settled down in one of the more demanding open world areas for a spot of corroboration.\n\nAnd yes, DLSS – or the GPU-supported upscaler of your choosing – is clearly intended as standard procedure. With frame gen disabled and Nvidia’s suggested settings in place, I was averaging 99fps, but switching off Quality-level DLSS and running at native 1080p saw that stoop to 62fps.\n\nFrame gen itself, meanwhile, is just weird. It did get my average framerate up to 148fps (visually, anyway – only 90 to 95 of those were 'real' frames) but motion didn’t appear any smoother. In fact, it gained a harsher, grittier quality that didn’t look dissimilar to a lower framerate. I’ve seen this happen with less advanced upscalers like the original FSR 3.0, but never with the new and improved DLSS 4.\n\nOtherwise, Gearbox/Nvidia’s settings guide for the RTX 4060 Ti is decent, if a little excessive. I’m not sure it needs such deep cuts to volumetric clouds and the main shadow quality options, both of which produced negligible differences between their highest and lowest settings in my testing. Foliage density, volumetric fog, and directional shadows all have slightly bigger framerate impacts, but I only lost 3-5fps apiece by toggling them to Very High. Which, by the by, is worth trying for foliage, given how bare the game looks without its veggies.\n\nImage credit: 2K\n\nStill, the guide does correctly identify these as leveraging some level of performance tax, and I’d have to agree with it keeping lighting quality on Low. This is one of the heaviest settings of the bunch, with my RTX 4060 Ti falling from 99fps to 74fps after changing this single setting up to Very High, with surprisingly little gain in terms of visual niceness. Frame gen remains a no-no, but fair dos, you would be getting a more fined-tuned Borderlands 4 with these than any of the presets.\n\nUnfortunately, a good showing for Gearbox’s big Excel project ultimately doesn’t truly address its performance problems. I haven’t had any crashes yet but stuttering is, indeed, a common occurrence, especially during big fights where multiple baddies are onscreen and some manner of elemental particle effect tornado is blowing through them. Which, this being a Borderlands game, is most fights. Although higher framerates can help mask the effect, it doesn’t seem that you can completely stutter-proof your PC, even with pre-tailored settings recommendations.\n\nPerhaps unsurprisingly, then, it doesn’t pay to try skirting under the system requirements. I had a cheeky go on my RTX 4050 laptop, the 8GB system RAM and 6GB VRAM of which come under the official minimums, and even DLSS wasn’t enough to stay above 30fps in the open world. With, naturally, plenty of big stutters along the way.\n\nWhether you’re playing Borderlands 4 or not, we’re all uncomfortably familiar with the problem at this point. It’s one that’s frayed the edges of games, unusual Unreal Engine 5 ones, from recent releases Wuchang: Fallen Feathers and Dune: Awakening back to the likes of Remnant II and beyond. We also know by now, as Gearbox and 2K should, that it’s not something that can be fixed on our end by changing a few settings.",
      "source": "Rock Paper Shotgun",
      "url": "https://www.rockpapershotgun.com/i-tried-the-new-recommended-settings-for-borderlands-4-and-oh-no-they-dont-actually-fix-its-stuttering",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Companies' RTO plans often include turning to the data. It doesn't always work out that well.",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nHappy Friday! Ever wondered what Elon Musk's xAI stands for? (Of course you have.) According to a recent Tesla filing, the startup's full name is \"eXploratory Artificial Intelligence.\" There's just one problem: Neither Musk nor xAI appears to have publicly said that's the case.\n\nIn today's big story, companies' push to get employees back to the office includes looking at the data. It's working better for some (Microsoft) more than others (AT&T).\n\nWhat's on deck:\n\nMarkets: Forget \"Equities in Dallas,\" Wall Street is investing big in its Texas offices.\n\nTech: Microsoft wants to show it can do AI all by itself.\n\nBusiness: Flip wanted to take on TikTok. Instead, it flopped.\n\nBut first, Bueller? Bueller? Bueller?\n\nIf this was forwarded to you, sign up here.\n\nThe big story\n\nSwiping in\n\nPau Barrena/AFP via Getty Images\n\nAT&T = Attendance taking & trouble.\n\nThat's the pickle the telecom giant is in when it comes to enforcing its RTO policy. A system meant to track the hours workers actually spend in the office is causing more headaches than it's worth, reports BI's Dominick Reuter.\n\nAT&T chief marketing and growth officer Kellyn Kenny told employees last month she understands inaccuracies in the attendance tracking tool are \"driving people to the brink of frustration.\"\n\nIn case you aren't dialed in to what's going on at AT&T, here's a refresher. AT&T required people to return to the office five days a week at the beginning of the year. The rollout didn't go smoothly, with everything from parking spots to desks filling up quickly. Things seemed to come to a head last month when CEO John Stankey sent a memo telling workers to get on board with RTO or get out of the way.\n\nAT&T's attendance tracker was meant to suss out people abusing the system by swiping into the office only for a few hours, known as \"coffee-badging.\" To catch those \"freeloaders,\" as Kenny described them, the company set up benchmarks around the number of hours and days workers were to badge in.\n\nBut the data wasn't always perfect. Routine things — attending doctors' appointments, taking lunch — complicated matters.\n\nIn some cases, AT&T's attendance tracker backfired. If the company wanted eight hours a day, workers wondered, why bother putting in more time than that?\n\nMicrosoft CEO Satya Nadella speaking at a conference in San Francisco. Carlos Barria/REUTERS\n\nMeanwhile, another corner of the business world is touting its RTO data.\n\nMicrosoft executives told employees at an all-employee town hall that internal data shows workers spending more time in the office are \"thriving,\" writes BI's Ashley Stewart.\n\nThe data comes after Microsoft announced its RTO plans.\n\nMicrosoft HR chief Amy Coleman said people who spend at least three days in the office, which is Microsoft's new RTO mandate, are energized, empowered, and find meaning in their work.\n\nHowever, CEO Satya Nadella acknowledged the importance of maintaining some flexibility with work, according to internal comments at the town hall reviewed by Ashley.\n\n\"There's tons of empowerment here for people to go organize this in such a way that it works for the folks,\" Nadella said.\n\n3 things in markets\n\nInside a Trader Joe's store in Miami Beach, Florida. Jeff Greenberg/Getty Images\n\n1. Inflation came in as hot as expected. CPI data showed inflation in August ticked up to 2.9%, up from 2.7% in June and July. The new numbers have had little effect on the Fed's likelihood of cutting rates next week, which traders and economists still expect to happen.\n\n2. Nvidia has finally won over one of Wall Street's biggest skeptics. DA Davidson changed its rating on the chip giant's stock from \"neutral\" to \"buy,\" raising its price target from $195 to $210 a share. The firm cited rapid development and AI adoption among companies for its flipped perspective.\n\n3. Everything's bigger in Texas — even the banks. Big financial players like Goldman Sachs, JPMorgan, and the New York Stock Exchange are setting up shop in the Lone Star State, which promises business-friendly taxes. See what they're up to out west.\n\n3 things in tech\n\nGetty Images\n\n1. US data center construction breaks new ground. Thanks to ever-rising demand from AI, spending on data center construction hit $40 billion annually in June, up 28% from the year before. That's a new record, and it shows no signs of slowing: Big Tech's spree could total more than $1 trillion by 2028.\n\n2. Oh great, now there's AI \"psychosis risk\" to worry about. Wall Street is beginning to evaluate AI chatbots and models based on \"psychosis risk,\" or the tendency of the bot to exacerbate user mental health problems. A recent study showed stark differences between the models that mitigate risk and those that amplify it, leaving analysts concerned.\n\n3. It looks like Microsoft might be trying to forge its own AI path. The company is planning \"significant investments\" in its own AI chip cluster, Microsoft AI CEO Mustafa Suleyman said in an all-employee town hall meeting. Microsoft appears to be drifting apart from OpenAI, with Suleyman saying it should be \"self-sufficient\" in the sector.\n\n3 things in business\n\nFlip; Tyler Le/BI\n\n1. A TikTok challenger's mysterious demise. Video app Flip looked primed to take over TikTok's dominance in mid-January amid mounting regulatory pressure. Seven months later, the $1 billion company was dead. Former employees, investors, creators, and more told BI how it flew and then flopped.\n\n2. David Ellison means business. Paramount's reported bid for Warner Bros. Discovery shows the Paramount CEO is serious about taking on Netflix and Disney for Hollywood's crown. It doesn't hurt that he has the financial backing of his father, Larry Ellison, who briefly became the richest man in the world this week.\n\n3. America's oldest workers are taking pay cuts. As part of BI's \"80 over 80\" series, dozens of older workers told us they earn less than $20 an hour. Many held white-collar or high-paying blue-collar jobs before, but took on low-paying jobs as they got older to make ends meet.\n\nIn other news\n\nWhat's happening today\n\nCongressional Budget Office releases its \"Current View of the Economy from 2025 to 2028,\" including short-term projections for major economic indicators.\n\nNew iPhones are available to pre-order.\n\nDan DeFrancesco, deputy editor and anchor, in New York. Hallam Bullock, senior editor, in London. Akin Oyedele, deputy editor, in New York. Grace Lett, editor, in New York. Amanda Yen, associate editor, in New York.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/att-rto-stankey-memo-remote-work-rto-microsoft-2025-9",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "How AMD, Nvidia, Broadcom Can Ride Oracle’s $455B Cloud Surge",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/12/how-amd-nvidia-broadcom-can-ride-oracles-455b-cloud-surge/",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Jim Cramer Discusses NVIDIA Corporation (NVDA) & AI Spending",
      "content": "We recently published 13 Latest Stocks on Jim Cramer’s Radar. NVIDIA Corporation (NASDAQ:NVDA) is one of the stocks Jim Cramer recently discussed.\n\nNVIDIA Corporation (NASDAQ:NVDA) continues to be a stock that’s favorably present on Jim Cramer’s radar even though the shares have experienced some turbulence lately. The CNBC TV host firmly holds the opinion that the firm and its CEO, Jensen Huang, are heralding a new industrial revolution. This time, Cramer discussed the spending estimates that he was hearing related to NVIDIA Corporation (NASDAQ:NVDA):\n\nPhoto by Christian Wiediger on Unsplash\n\n“A lot of people, when I used to put out the three trillion number, that Jensen Huang put out, people would say well listen, you’re constrained by how much these companies can spend. But now the number’s seven trillion. I’m hearing seven trillion, that’s going to be spent. . .but that’s unbelievable!\n\nWhile we acknowledge the potential of NVDA as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/jim-cramer-discusses-nvidia-corporation-194654028.html",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Nvidia and Kioxia target 100 million IOPS SSD in 2027 — AI server drives aim to deliver 33 times more performance",
      "content": "Kioxia is working with Nvidia to build a solid-state drive that would deliver 100 million random IOPS already in 2027, the company said at a news conference earlier this month, Nikkei reports. Nvidia reportedly plans to use a couple of such SSDs — totalling a whopping 200 million IOPS — attached directly to its GPUs to boost AI performance.\n\n\"We will proceed with development in accordance with the proposals and requests from Nvidia,\" said Koichi Fukuda, chief technology officer of Kioxia's SSD division.\n\n100 million IOPS SSD\n\nKioxia's drives with 100 million random read speeds are projected to use a PCIe 7.0 interface to connect to GPUs in a peer-to-peer mode and will be exclusively designed for use in AI servers that need to access and process vast amounts of data quickly.\n\nToday's high-end solid-state drives can deliver around 3 million 4K random IOPS, but to meet the performance needs of modern and upcoming GPUs — which are optimized for burst memory access — they need to get substantially faster and change the way they interact with NAND media.\n\nEarlier this year, Silicon Motion's CEO Wallace Kou told Tom's Hardware that Nvidia was interested in building SSDs that offer as many as 100 million random IOPS, 33 times more than existing drives can deliver. Around the same time, Kioxia disclosed plans to build XL-Flash-based 'AI SSDs' with over 10 million 512K random read IOPS in the second half of 2026.\n\nAI workloads rely on frequent, small, random reads to retrieve embeddings, model parameters, or database entries. In such cases, 512-byte blocks better represent actual usage patterns than 4KB blocks and provide lower latency. While drives that operate 512B blocks may not deliver the same raw bandwidth as typical SSDs with 4K blocks, it is easier to scale out sequential read/write speeds with multiple drives than to lower the latencies of conventional SSDs.\n\nIt remains to be seen whether Kioxia's AI SSD with a 10 million 512K IOPS random performance will materialize in 2026 if Kioxia plans to build drives with a 100 million IOPS random performance in 2027.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nUsing XL-Flash?\n\nWhat is interesting is how exactly Kioxia plans to build its 100 million IOPS drive. Its proposed AI SSD is based on XL-Flash, which is SLC NAND memory with high endurance, very low latency, and fairly high performance. Kioxia's XL-Flash devices feature 16 planes (up significantly from 3 to 6 planes on modern 3D NAND devices for client PCs), which points to higher sequential and random performance. As Kioxia does not publish specifications of XL-Flash, it is impossible to judge the per-device performance of this memory type.\n\nMeanwhile, considering that an Innogrit Tacoma-based 400GB XL-Flash SSD with 32 NAND dies (with seven allocated for overprovisioning) and a PCIe 5.0 x4 interface delivers 3.5 million random read IOPS and 0.5 million random write IOPS, we can estimate that each die contributes up to 109,375 random read IOPS and 15,625 random write IOPS—though this calculation comes with some caveats.\n\nAssuming perfect linear scaling across loads of NAND devices, a 100 million 512B IOPS SSD would require 915 of such dies (presuming the same levels of over provisioning). Now that Kioxia knows how to pack 32 NAND ICs into a single package, it can certainly build a drive based on 915 XL-Flash ICs (in 28 packages). Such a drive would require a special controller with at least a PCIe 5.0 x16 host interface (though PCIe 7.0 x4 would be more preferable). The problem is, there is no perfect linear scaling. Real-world performance of NAND devices in SSDs is limited by channel bandwidth, multi‑plane constraints, command pipelining/overheads, queue depth, firmware, and loads of other factors. Hence, the best case scenario for a 100 million 512B IOPS SSD featuring XL-Flash devices is a multi-controller module with dozens of controllers and a switch. Such a solution may well make sense in all-flash arrays, but Kioxia is explicitly talking about an SSD.\n\nWelcome, HBF?\n\nSince using traditional 3D NAND memory for a 100 million IOPS SSD with 512B blocks is not exactly feasible, whereas using a brand-new type of media on a commercial data center-grade product is highly unlikely, Kioxia might instead look to emerging technologies that use NAND memory in an unconventional way.\n\nOne of such technologies is probably high bandwidth flash (HBF) that packs up to 16 NAND devices and a logic die (a controller?) into a single stack and interconnects them using TSVs and microbumps. While HBF layers still use proven NAND memory cells, they are organized in multiple arrays to achieve a very high level of parallelism and therefore performance. We do not know whether Kioxia plans to use HBF for the project or stick to something similar. However, it is safe to assume that the knowledge it will gain from its experimentation with HBF to build ultra-high-performance SSDs is something the company intends to leverage.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/nvidia-and-kioxia-target-100-million-iops-ssd-in-2027-33-times-more-than-existing-drives-for-exclusive-use-in-ai-servers",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Super Micro Computer Stock (SMCI) Surges with Nvidia Shipments Underway",
      "content": "Prime Minister Sébastien Lecornu’s sudden resignation deepens France’s political instability, spooking markets and complicating President Macron’s government ahead of budget battles.\n\nMarket Summary Markets show cautious optimism as U.S. stock futures edge higher driven by hopes for Federal Reserve rate cuts and AI sector momentum. However, geopolitical tensions and a prolonged U.S. government shutdown sustain volatility. Japan stocks rally on leadership changes, while French political upheaval sparks selloffs in Europe. Bitcoin's record highs reflect growing safe-haven demand amidst uncertainty.\n\nFifth Third Strikes $10.9 Billion Deal to Acquire Comerica Fifth Third to Absorb Comerica in $10.9 Billion Stock Deal Fifth Third Bancorp confirms $10.9 billion acquisition of Comerica, marking a major consolidation in U.S. regional banking. The all-stock deal aims to expand market presence amid banking sector challenges.\n\nFigure of the Day 125,000 - Bitcoin's new record price in USD, signaling heightened crypto market interest amid economic uncertainty.\n\nFrench PM Lecornu Resigns Hours After Cabinet Reveal New French PM Quits After Less Than A Month in Office French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after unveiling his cabinet. This resignation deepens France’s political crisis with markets reacting negatively.\n\nGovernment Shutdown Hits Second Week with No Breakthrough Shutdown Stalemate Promises Prolonged Federal Gridlock The U.S. federal government shutdown extends beyond a week, with lawmakers at an impasse. Threats of mass federal layoffs mount, fueling market uncertainty and increasing economic pressure.\n\nBullish SpaceX Secures $714M Pentagon Contract, Edging Out Blue Origin Elon Musk’s SpaceX wins major defense contracts, reinforcing its dominance in military space launches and solidifying government partnerships. More on benzinga.com\n\nJapan Stocks Rally as Takaichi Takes Ruling Party Helm Nikkei Inches to Record High on Takaichi’s Pro-Stimulus Win Japan’s stock market soars as ultra-conservative Sanae Takaichi wins the ruling party leadership, triggering yen weakness. Investors expect pro-stimulus policies and possible BOJ monetary shifts.\n\nBitcoin Surges Past $125,000 Amid Market Turmoil Crypto Rally Continues with Bitcoin at New All-Time High Bitcoin hits new record highs surpassing $125,000 despite market volatility. Investors flock to cryptocurrencies as safe havens amid geopolitical tensions and U.S. government shutdown uncertainty.\n\nBearish Aston Martin Shares Tank as Tariff Pressures Slash Profit Outlook Luxury carmaker Aston Martin issues profit warning amid rising U.S. tariffs and supply chain woes, triggering a steep stock selloff. More on businessinsider.com\n\nAston Martin Shares Dive on New Profit Warning — Tariff Drag Lingers Aston Martin Slashes Profits Amid US Tariff Turmoil Aston Martin’s shares plunge after issuing fresh profit warnings citing ongoing tariff impacts and supply chain challenges. The luxury carmaker seeks proactive support amid uncertain US trade policies.\n\nSpaceX Lands $714 Million Pentagon Contract, Beating Blue Origin SpaceX outpaces Blue Origin by securing $714 million Pentagon contract for military space missions, bolstering Elon Musk’s dominance in U.S. defense space operations.\n\nRegulatory Impact EU financial regulator ESMA moves to centralize oversight of stock exchanges, crypto firms, and clearing houses, aiming to boost market stability across member states.\n\nQualtrics to Acquire Press Ganey in $6.8 Billion Healthcare Deal Qualtrics plans $6.8 billion acquisition of Press Ganey Forsta to strengthen healthcare technology footprint. The deal includes cash and debt components, signaling strategic expansion.\n\nQuote \"The political instability in France is weighing heavily on markets, signaling uncertain times ahead for investors and policymakers alike.\"\n\n— Senior European Market Strategist\n\nCourt Halts Trump’s National Guard Deployment to Oregon U.S. judges temporarily block Trump administration’s National Guard deployments to Oregon and Portland amid legal battles. States challenge federal troop movements amid rising tensions.\n\n2025 Nobel Prize in Medicine Honors Immunology Trailblazers Immunology Pioneers Share Nobel Prize for Medicine 2025 Nobel Prize in Medicine awarded to pioneers in immunology for breakthroughs in immune system research, advancing understanding of physiological disease mechanisms.\n\nESMA Pushes for Unified EU Oversight of Exchanges and Crypto EU’s financial watchdog plans centralized oversight of stock exchanges, crypto firms, and clearing houses to harmonize regulation across the bloc and enhance capital market stability.\n\nOPEC+ Approves Small Oil Production Hike, Markets React OPEC+ Output Raised Slightly; Price Sentiment Wavers OPEC+ agrees to a modest 137,000 barrel per day oil output increase in November amid concerns of oversupply. Market remains cautious as global economic outlook loosens.\n\nTesla Reports Record Q3 Deliveries Amid Emerging Headwinds Tesla sets record Q3 vehicle deliveries but faces emerging operational challenges. Positive growth outlook is tempered by supply chain concerns and market pressures.\n\nStock Futures Rise on Fed Rate-Cut Hopes and AI Buzz Wall Street Futures Up as Investors Eye AI and Policy Moves Wall Street stock futures edge mostly higher, supported by hopes of Fed rate cuts and rapid AI sector growth despite the shadow of a prolonged U.S. government shutdown.\n\nHong Kong Stocks Slide as U.S. Shutdown Hurts Sentiment Hong Kong stocks dip due to dampened investor sentiment linked to U.S. government shutdown; demand rises for safe-haven assets like gold amid global uncertainties.\n\nAmazon Lets Prime Shoppers Add Last-Minute Items to Delivery Amazon enhances its Prime offering with 'Add to Delivery' feature allowing last-minute additions to shipments, aiming to boost holiday shopping convenience.\n\nChina Unveils Stealth Fighter Jet Development Footage Powerful jet fighter development footage emerges from China, positioning the country as the global leader in stealth combat aircraft alongside the U.S.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/eb7e18f3de0e9bc9",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "AI drone swarms revolutionize wildfire detection and air quality monitoring",
      "content": "University of Minnesota researchers have developed AI-powered drone swarms to track wildfire smoke in 3D, offering a better way to predict air pollution. (CREDIT: Shutterstock)\n\nFrom the outside, wildfire smoke may look like a drifting gray cloud. But for scientists, these plumes are dynamic, complex, and potentially dangerous. They can stretch for hundreds of miles, impacting air quality, visibility, and public health. Until now, capturing accurate data on how these smoke particles move and behave has been one of the most difficult tasks in atmospheric science.\n\nResearchers at the University of Minnesota Twin Cities have developed a groundbreaking way to observe and analyze wildfire smoke: a swarm of AI-powered aerial robots that can detect, track, and build 3D models of smoke plumes.\n\nUnlike traditional drones, these small flying machines work as a team. They recognize smoke, fly directly into it, and take high-resolution images from multiple angles. Their mission is to help us better understand how smoke travels—an understanding that could reshape how we predict air pollution and respond to environmental hazards.\n\nThis new study, published in the peer-reviewed journal Science of the Total Environment, opens doors to more accurate fire behavior models and better air quality predictions, not just for wildfires, but also for prescribed burns, volcanic eruptions, sandstorms, and other particle-driven events.\n\nA graphical abstract of the study. (CREDIT: Science of The Total Environment)\n\nBetween 2012 and 2021, about 50,000 prescribed burns were carried out in the United States—intentional fires set under controlled conditions to improve forest health and reduce wildfire risk. But even controlled burns carry risk. According to a 2024 report by the Associated Press, 43 of these burns spiraled out of control and became wildfires.\n\nThese numbers, while small in percentage, matter deeply. That’s because smoke particles, especially the small ones, can stay in the air for days and travel far from their source. “A key step is understanding the composition of smoke particles and how they disperse,” explained Jiarong Hong, professor of mechanical engineering at the University of Minnesota and senior author of the study. “Smaller particles can travel farther and stay suspended longer, impacting regions far from the original fire.”\n\nUnderstanding how these plumes evolve over time is essential for early hazard detection, public health responses, and emergency planning. Yet, traditional tools for studying smoke—like satellites, remote sensing, and Lidar—fall short. These tools lack the detail and flexibility needed to capture fast-changing flows of smoke, especially in rough terrain or remote regions.\n\nRelated Stories\n\nThat’s where the new drone swarm steps in. These AI-enabled robots are designed to adapt to the smoke’s size and shape. They gather rich data in real time—something existing technologies can’t do affordably or efficiently.\n\nThe Science Behind the Swarm\n\nThe team’s drone system includes one manager drone and four worker drones. These drones aren’t just fancy flying cameras—they’re mini laboratories in the sky.\n\nEach drone carries a 12-megapixel camera mounted on a three-axis gimbal for capturing smoke in motion. They are powered by long-lasting 6000 mAh batteries and guided by advanced flight controllers and NVIDIA Jetson processors. These processors allow the drones to recognize smoke in real time, adjust their paths, and capture the best angles for imaging.\n\nWhen launched, the drones work together to fly around a smoke plume, snapping high-resolution images from multiple directions. These images are then grouped by time intervals and fed into a computer model using something called a Neural Radiance Field (NeRF). This advanced AI model helps turn 2D images into a realistic, detailed 3D reconstruction of the smoke plume.\n\nIllustration of the drone swarm system that uses multi-view imaging for 3D smoke plume characterization. (CREDIT: Science of The Total Environment)\n\nThis step is key. With the 3D model, researchers can analyze the shape, direction, and flow of the smoke over time. It gives them crucial data like volume, angle of movement, and dispersion speed—all critical for improving fire and smoke simulation tools.\n\nOther cutting-edge AI techniques were considered, including Dynamic NeRF (D-NeRF) and RoDynRF, which are good at modeling motion. But these systems struggle with featureless subjects like smoke and require long training times. The drone swarm approach avoids those problems by directly capturing the data in the field.\n\n“This approach allows for high-resolution data collection across large areas—at a lower cost than satellite-based tools,” said Nikil Nrishnakumar, the study’s first author and a graduate researcher at the Minnesota Robotics Institute.\n\nFrom Research to Real-World Impact\n\nThe drone swarm has already been tested in field deployments and has shown promising results. With this system, the team can generate multiple 3D reconstructions over time, creating a time-lapse view of how a smoke plume changes in real-time. It’s like watching the plume evolve in 3D—a powerful tool for scientists and emergency responders.\n\nDrone hardware configuration showing the quadcopter with camera mounted on a 3-axis gimbal and GPS with RTK (left), and the NVIDIA Jetson Orin Nano (right). (CREDIT: Science of The Total Environment)\n\nBut the benefits of this technology reach far beyond wildfire science.\n\n“Early identification is key,” Hong emphasized. “The sooner you can see the fire, the faster you can respond.”\n\nThe drones could be used in other dangerous scenarios as well, including volcanic eruptions, dust storms, and even urban pollution events. Because the system is modular and cost-effective, it can be scaled up or down based on the size of the area being studied. This flexibility makes it a strong candidate for use by government agencies, environmental researchers, and emergency crews.\n\nThe next steps for the team involve making the system more autonomous and scalable. They’re now integrating fixed-wing drones with Vertical Takeoff and Landing (VTOL) capability. These new drones can fly longer distances—over an hour at a time—and don’t need a runway to take off. That opens the door to monitoring vast forests and hard-to-reach locations.\n\nIn addition, the team plans to explore Digital Inline Holography to improve particle characterization. This method could provide even deeper insights into what types of particles are present in a smoke plume and how they interact with the environment.\n\n“We’re not just building tools,” Nrishnakumar said. “We’re laying the groundwork for smarter, faster, and safer responses to environmental hazards.”\n\nFlowcharts detailing the steps involved in (a) stabilizing the manager drone, (b) collecting data with the worker drone swarm, and (c) processing captured data for 3D plume reconstruction and characterization. (CREDIT: Science of The Total Environment)\n\nA New Era of Smoke Science\n\nMany modern simulation tools like FIRETEC and QUIC-Fire already exist to model how fires spread and how smoke particles behave. These systems use complex inputs—everything from fuel type and moisture to wind speed and topography. But even the best models have one major limitation: they need real-world data to validate their predictions.\n\nThat’s why the drone swarm matters so much. It provides the missing piece—real, time-sensitive, high-resolution data that can make these simulations more accurate and useful.\n\nUntil now, simulation models have struggled to work in areas without detailed 3D maps of vegetation and terrain. They also haven’t been able to compare their predictions with real-world smoke movement, especially in complex or fast-changing environments. The drone swarm changes that by creating accurate 3D ground truth models that can be used for comparison and refinement.\n\nAs the climate warms and wildfire risks rise, these tools may become vital to protecting both ecosystems and human health. With more than 40% of the U.S. population living in areas prone to wildfire smoke, this research couldn’t come at a better time.\n\nThis project was supported by the National Science Foundation’s Major Research Instrumentation program and conducted with the help of the St. Anthony Falls Laboratory. Along with Hong and Nrishnakumar, the research team included Shashank Sharma and Srijan Kumar Pal, also from the Minnesota Robotics Institute.\n\nNote: The article above provided above by The Brighter Side of News.",
      "source": "Thebrighterside.news",
      "url": "https://www.thebrighterside.news/post/ai-drone-swarms-revolutionize-wildfire-detection-and-air-quality-monitoring/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Intel Loses Another Prominent Linux Engineer - Now Going To NVIDIA",
      "content": "In the past few months at Intel between layoffs / corporate reorganizations and some deciding to pursue job opportunities elsewhere, there have been unfortunate impacts to their Linux engineering resources. Intel over the summer lost some prominent Linux engineering talent and in turn has even led to upstream Linux drivers being orphaned along with other driver maintainers departing and various other staffing changes . Unfortunate for Intel, another notable Linux name has left the company.Colin Ian King announced today that it was his last day at Intel. Colin King had just been employed by Intel for nearly four years but is well known prior to then. Prior to joining Intel, Colin was a kernel engineer at Canonical where he worked on Ubuntu Linux for over 13 years. Colin King was well known for his Ubuntu Linux work and has contributed more than four thousand patches to the upstream Linux kernel over the years. At Intel, Colin continued his kernel contributions with performance optimizations and more.If his name doesn't ring a bell, perhaps you know it from Stress-NG with Colin being the lead developer of those kernel micro-benchmarks. Colin has made incredible contributions to the upstream Linux kernel community over the past many years.Colin announced his departure from Intel today on LinkedIn:\n\nIn there he also announced he will now apparently be working for NVIDIA. For the benefit of the upstream Linux kernel community, hopefully he will be continuing to focus on upstream Linux kernel activity at NVIDIA... Especially given their increasing open-source GPU driver activity as well as growing kernel activity elsewhere from their networking products to other data center offerings and also needing to ensure the Linux kernel is performing effectively for showcasing the power of their products for AI and more.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Colin-King-Leaving-Intel",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Supermicro (SMCI): Evaluating Valuation Following Launch of Blackwell Ultra AI Data Center Solutions",
      "content": "Super Micro Computer (SMCI) has just started shipping its highly anticipated NVIDIA Blackwell Ultra solutions worldwide, a move that is capturing plenty of investor attention. These new systems represent more than incremental upgrades. They promise to deliver rapid deployment and enhanced performance for some of the most demanding AI data center projects. With pre-validated racks, plug-and-play installation, and cutting-edge cooling innovations, Super Micro is making a bold play to lead the next wave of AI infrastructure.\n\nThis launch arrives at a pivotal moment for Super Micro. After a stretch of volatility, the stock jumped 4% on the news of these volume shipments, signaling a renewed sense of optimism in the company’s growth story. Over the past year, SMCI shares have wavered with a small year-over-year dip, but momentum has started building again in 2025, helped along by AI-driven product expansions and major partnerships. While there has been a near 50% year-to-date gain, recent months have seen some pullback, reminding investors that expectations remain high but not assured.\n\nAfter a big announcement and a sharp move, the big question remains. Is Super Micro ready for another leg up, or is the market already factoring in all that future growth?\n\nMost Popular Narrative: 39.6% Undervalued\n\nAccording to the most popular narrative, Super Micro Computer is considered significantly undervalued. The argument hinges on robust projected growth and strong positioning in the AI infrastructure market.\n\nPartnerships with NVDA, AMD, xAI and Intel position them as one of the most attractive providers of GPU data center infrastructure. They are also profiting from growth in other related industries such as Cloud, 5G and Storage. Using the SWS Fair Value tool and management guidance of $23bn for 2025 and $40bn for 2026, I decided to use a revenue growth rate of 50% to reach an estimated revenue of $50bn for 2028, which I consider conservative.\n\nCurious about what drives this bold undervaluation call? The key lies in aggressive growth assumptions and a premium multiple historically reserved for industry giants. Want to see how these strategic forecasts transform into a game-changing price target and why this narrative is gaining traction? The most intriguing projections are just one click away.\n\nResult: Fair Value of $74.53 (UNDERVALUED)\n\nHave a read of the narrative in full and understand what's behind the forecasts.\n\nHowever, risks remain, including potential regulatory hurdles and execution missteps. Either of these factors could challenge even the most optimistic projections for Super Micro.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/supermicro-smci-evaluating-valuation-following-125543430.html",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Stocks Reach Highs On Oracle And Fed Expectations",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/bill_stone/2025/09/13/stocks-reach-highs-on-oracle-and-fed-expectations/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "AI Will Not Make You Rich",
      "content": null,
      "source": "Joincolossus.com",
      "url": "https://joincolossus.com/article/ai-will-not-make-you-rich/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "U.S. Stock Market Nears Records Ahead of Fed Meeting; Nvidia, Meta, Tesla Eye Technical Breakouts",
      "content": null,
      "source": "International Business Times",
      "url": "https://www.ibtimes.com/us-stock-market-nears-records-ahead-fed-meeting-nvidia-meta-tesla-eye-technical-breakouts-3783273",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Randy Pitchford Addresses Borderlands 4 Console FOV Slider Complaints: 'There's Some Dreams I Have Where an FOV Setting Might Affect Fairness'",
      "content": "Randy Pitchford has responded to complaints about the console version of Borderlands 4 lacking a field of view (FOV) slider, suggesting fairness may have something to do with it.\n\nPlayStation 5 and Xbox Series X and S players of Borderlands 4 were shocked to discover not only a lack of a FOV slider in-game, but no motion blur toggle, either. The PC version of Borderlands 4 has settings for both — in the case of FOV you can increase the value in degrees up to 110 for both first-person play and vehicle use, and for motion blur you can change the amount and the quality.\n\nThe lack of a FOV slider is the biggest issue right now with Borderlands 4 on console, if anecdotal evidence across the internet is anything to go by, with some complaining that not being able to tweak the FOV value is causing them motion sickness.\n\n“Man, I've tried to play it twice today,” said redditor xInsaneAbilityx. “Both times I get that ‘car-sick’ feel after about 15 minutes and have to stop.” “Yeah I’m pretty sensitive to motion sickness and a narrow FOV in first-person makes me really dizzy. Combining that with motion blur just churns my stomach,” added Dallywack3r. “This game feels almost zoomed in, it‘s really not pleasant to play,” said christophlieber.\n\nThere are also suggestions the console version of Borderlands 4 lacks a FOV slider in order to maintain certain performance levels. By increasing the FOV, you’re putting the hardware under more strain and potentially impacting things like framerate.\n\nBut social media posts from Gearbox development chief Randy Pitchford suggest one of the considerations is fairness.\n\nBorderlands 4 Review Screenshots View 159 Images\n\n“Quickie for console friends: FOV settings,” Pitchford began. “There's some dreams I have where an FOV setting might affect fairness. I can't really talk about it yet, but I see this is important to you so we're looking at it.”\n\nPitchford included a vote in his social media post, which, after nearly 25,000 votes, reveals just how important a FOV slider is to his followers. At the time of this article’s publication, the option “FOV slider or GTFO!” had 72% of the vote.\n\nThe outspoken Gearbox boss went on to say players “have no idea what the team and I were planning and how FOV slider might affect fairness with such a thing.”\n\nHe added: “That said, I've always want to commit to and prioritize what Borderlands should be versus try to turn it into something it should. My hope is for my/our ambitions to be additive, not subtractive.”\n\nQuickie for console friends: FOV settings: There's some dreams I have where an FOV setting might affect fairness. I can't really talk about it yet, but I see this is important to you so we're looking at it. Vote here: — Randy Pitchford (@DuvalMagic) September 12, 2025\n\nSo, what is Pitchford actually saying here? The “fairness” quote has caused some confusion. Could it relate to an upcoming PvP mode? If so, why would the PC version have it? Right now, Borderlands 4 is a PvE co-op game, so the line about “fairness” has raised more than a few eyebrows.\n\nSome are wondering if Pitchford is talking about fairness in terms of the performance of the game giving some players an advantage. The higher the FOV, the more the player can see, versus the lower the FOV the more stable the frames are. Perhaps both give some level of advantage?\n\n“What does ‘fairness’ even mean?’ asked redditor buddachickentml. “Basically being impartial to all players without favoritism. Fairness to all,” suggested Wolf-O7. “Funny enough it's completely backwards though. Because console players aren't being treated fairly compared to their counterpart on PC. (Especially since this sort of sounds like a PVP mode the way he makes it seem).” Then, from Airaen: “Yeah, how is it fair that PC players can change the FoV and console players can't?” “Fairness in a PvE game? Will you ban ultrawide monitors?” said on social media user.\n\nBorderlands 4 supports crossplay between all platforms at launch, so Pitchford’s comments are doubly confusing.\n\nAs for motion blur, in another social media post Pitchford told console players \"we aren't down with motion blur and do not support it.\" He continued: “If you're seeing what seems to be motion blur, maybe check your television settings for whatever automatic BS it might be doing to your image? It's not us.”\n\nBut again, that comment is confusing given there are motion blur settings in Borderlands 4 on PC.\n\nRandy Pitchford has addressed Borderlands 4 console complaints. Photo by Jon Kopaloff/Getty Images for Lionsgate.\n\nWhatever Pitchford means here, Borderlands 4 has got off to a big start on Steam. It’s approaching a peak concurrent player count of 300,000 on Valve’s platform, where it is one of the most-played games. No other Borderlands game has come close to that in terms of concurrent player numbers on Steam.\n\nPitchford declared it impossible to break the Borderlands 4 servers this weekend through sheer weight of player numbers alone — and he’s so confident he’s publicly promised that Borderlands 4 won’t join the long list of big AAA games whose online systems fail at launch.\n\nWhile Borderlands 4 is off to a big start in terms of player numbers, it’s not entirely plain sailing for Gearbox. The release was marred by complaints about PC performance that have resulted in a ‘mixed’ user review rating on Valve’s platform. The complaints revolve around poor performance even on high powered PCs, with some affected by crashing that makes the game difficult to even start.\n\nIn response, Gearbox posted a Borderlands 4 Nvidia Optimization guide on Steam , advising players how to optimize their graphics settings for “better performance and framerates” on PC with the Nvidia app.\n\nGearbox then issued a piece of advice to PC gamers that to me reads like an effort to prevent players from making knee-jerk reactions to the game's performance as soon as they’ve changed their settings : “Please note that any time you change any of your graphics settings, your shaders will need to recompile. Please keep playing for at least 15 minutes to see how your PC's performance has changed.”\n\nIf you are delving into Borderlands 4 don't go without updated hourly SHiFT codes list . We've also got a huge interactive map ready to go and a badass Borderlands 4 planner tool courtesy of our buds at Maxroll. Plus check out our expert players' choices for which character to choose (no one agreed).\n\nWesley is Director, News at IGN. Find him on Twitter at @wyp100. You can reach Wesley at wesley_yinpoole@ign.com or confidentially at wyp100@proton.me.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/randy-pitchford-addresses-borderlands-4-console-fov-slider-complaints-theres-some-dreams-i-have-where-an-fov-setting-might-affect-fairness",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "AMD's RDNA4 GPU Architecture at Hot Chips 2025",
      "content": "RDNA4 is AMD’s latest graphics-focused architecture, and fills out their RX 9000 line of discrete GPUs. AMD noted that creating a good gaming GPU requires understanding both current workloads, as well as taking into account what workloads might look like five years in the future. Thus AMD has been trying to improve efficiency across rasterization, compute, and raytracing. Machine learning has gained importance including in games, so AMD’s new GPU architecture caters to ML workloads as well.\n\nFrom AMD’s perspective, RDNA4 represents a large efficiency leap in raytracing and machine learning, while also improving on the rasterization front. Improved compression helps keep the graphics architecture fed. Outside of the GPU’s core graphics acceleration responsibility, RDNA4 brings improved media and display capabilities to round out the package.\n\nMedia Engine\n\nThe Media Engine provides hardware accelerated video encode and decode for a wide range of codecs. High end RDNA4 parts like the RX 9070XT have two media engines. RDNA4’s media engines feature faster decoding speed, helping save power during video playback by racing to idle. For video encoding, AMD targeted better quality in H.264, H.265, and AV1, especially in low latency encoding.\n\nLow latency encoder modes are mostly beneficial for streaming, where delays caused by the media engine ultimately translate to a delayed stream. Reducing latency can make quality optimizations more challenging. Video codecs strive to encode differences between frames to economize storage. Buffering up more frames gives the encoder more opportunities to look for similar content across frames, and lets it allocate more bitrate budget for difficult sequences. But buffering up frames introduces latency. Another challenge is some popular streaming platforms mainly use H.264, an older codec that’s less efficient than AV1. Newer codecs are being tested, so the situation may start to change as the next few decades fly by. But for now, H.264 remains important due to its wide support.\n\nTesting with an old gameplay clip from Elder Scrolls Online shows a clear advantage for RDNA4’s media engine when testing with the latency-constrained VBR mode and encoder tuned for low latency encoding (-usage lowlatency -rc vbr_latency). Netflix’s VMAF video quality metric gives higher scores for RDNA4 throughout the bitrate range. Closer inspection generally agrees with the VMAF metric.\n\nRDNA4 does a better job preserving high contrast outlines. Differences are especially visible around text, which RDNA4 handles better than its predecessor while using a lower bitrate. Neither result looks great with such a close look, with blurred text on both examples and fine detail crushed in video encoding artifacts. But it’s worth remembering that the latency-constrained VBR mode uses a VBV buffer of up to three frames, while higher latency modes can use VBV buffer sizes covering multiple seconds of video. Encoding speed has improved slightly as well, jumping from ~190 to ~200 FPS from RDNA3.5 to RDNA4.\n\nDisplay Engine\n\nThe display engine fetches on-screen frame data from memory, composites it into a final image, and drives it to the display outputs. It’s a basic task that most people take for granted, but the display engine is also a good place to perform various image enhancements. A traditional example is using a lookup table to apply color correction. Enhancements at the display engine are invisible to user software, and are typically carried out in hardware with minimal power cost. On RDNA4, AMD added a “Radeon Image Sharpening” filter, letting the display engine sharpen the final image. Using dedicated hardware at the display engine instead of the GPU’s programmable shaders means that the sharpening filter won’t impact performance and can be carried out with better power efficiency. And, AMD doesn’t need to rely on game developers to implement the effect. Sharpening can even apply to the desktop, though I’m not sure why anyone would want that.\n\nPower consumption is another important optimization area for display engines. Traditionally that’s been more of a concern for mobile products, where maximizing battery life under low load is a top priority. But RDNA4 has taken aim at multi-monitor idle power with its newer display engine. AMD’s presentation stated that they took advantage of variable refresh rates on FreeSync displays. They didn’t go into more detail, but it’s easy to imagine what AMD might be doing. High resolution and high refresh rate displays translate to high pixel rates. That in turn drives higher memory bandwidth demands. Dynamically lowering refresh rates could let RDNA4’s memory subsystem enter a low power state while still meeting refresh deadlines.\n\nPower and GDDR6 data rates for various refresh rate combinations. AMD’s monitoring software (and others) read out extremely low memory clocks when the memory bus is able to idle, so those readings aren’t listed.\n\nI have a RX 9070 hooked up to a Viotek GN24CW 1080P display via HDMI, and a MSI MAG271QX 1440P capable of refresh rates up to 360 Hz. The latter is connected via DisplayPort. The RX 9070 manages to keep memory at idle clocks even at high refresh rate settings. Moving the mouse causes the card to ramp up memory clocks and consume more power, hinting that RDNA4 is lowering refresh rates when screen contents don’t change. Additionally, RDNA4 gets an intermediate GDDR6 power state that lets it handle the 1080P 60 Hz + 1440P 240 Hz combination without going to maximum memory clocks. On RDNA2, it’s more of an all or nothing situation. The older card is more prone to ramping up memory clocks to handle high pixel rates, and power consumption remains high even when screen contents don’t change.\n\nCompute Changes\n\nRDNA4’s Workgroup Processor retains the same high level layout as prior RDNA generations. However, it gets major improvements targeted towards raytracing, like improved raytracing units and wider BVH nodes, a dynamic register allocation mode, and a scheduler that no longer suffers false memory dependencies between waves. I covered those in previous articles. Besides those improvements, AMD’s presentation went over a couple other details worth discussing.\n\nScalar Floating Point Instructions\n\nAMD has a long history of using a scalar unit to offload operations that are constant across a wave. Scalar offload saves power by avoiding redundant computation, and frees up the vector unit to increase performance in compute-bound sequences. RDNA4’s scalar unit gains a few floating point instructions, expanding scalar offload opportunities. This capability debuted on RDNA3.5, but RDNA4 brings it to discrete GPUs.\n\nWhile not discussed in AMD’s presentation, scalar offload can bring additional performance benefits because scalar instructions sometimes have lower latency than their vector counterparts. Most basic vector instructions on RDNA4 have 5 cycle latency. FP32 adds and multiples on the scalar unit have 4 cycle latency. The biggest latency benefits still come from offloading integer operations though.\n\nSplit Barriers\n\nGPUs use barriers to synchronize threads and enforce memory ordering. For example, a s_barrier instruction on older AMD GPUs would cause a thread to wait until all of its peers in the workgroup also reached the s_barrier instruction. Barriers degrade performance because any thread that happened to reach the barrier faster would have to stall until its peers catch up.\n\nRDNA4 splits the barrier into separate “signal” and “wait” actions. Instead of s_barrier, RDNA4 has s_barrier_signal and s_barrier_wait. A thread can “signal” the barrier once it produces data that other threads might need. It can then do independent work, and only wait on the barrier once it needs to use data produced by other threads. The s_barrier_wait will then stall the thread until all other threads in the workgroup have signalled the barrier.\n\nMemory Subsystem\n\nThe largest RDNA4 variants have a 8 MB L2 cache, representing a substantial L2 capacity increase compared to prior RDNA generations. RDNA3 and RDNA2 maxed out at 6 MB and 4 MB L2 capacities, respectively. AMD found that difficult workloads like raytracing benefit from the larger L2. Raytracing involves pointer chasing during BVH traversal, and it’s not surprising that it’s more sensitive to accesses getting serviced from the slower Infinity Cache as opposed to L2. In the initial scene in 3DMark’s DXR feature test, run in Explorer Mode, RDNA4 dramatically cuts down the amount of data that has to be fetched from beyond L2.\n\nRDNA2 still does a good job of keeping data in L2 in absolute terms. But it’s worth noting that hitting Infinity Cache on both platforms adds more than 50 ns of extra latency over a L2 hit. That’s well north of 100 cycles because both RDNA2 and RDNA4 run above 2 GHz. While AMD’s graphics strategy has shifted towards making the faster caches bigger, it still contrasts with Nvidia’s strategy of putting way more eggs in the L2 basket. Blackwell’s L2 cache serves the functions of both AMD’s L2 and Infinity Cache, and has latency between those two cache levels. Nvidia also has a flexible L1/shared memory allocation scheme that can give them more low latency caching capacity in front of L2, depending on a workload’s requested local storage (shared memory) capacity.\n\nA mid-level L1 cache was a familiar fixture on prior RDNA generations. It’s conspicuously missing from RDNA4, as well as AMD’s presentation. One possibility is that L1 cache hitrate wasn’t high enough to justify the complexity of an extra cache level. Perhaps AMD felt its area and transistor budget was better allocated towards increasing L2 capacity. To support this theory, L1 hitrate on RDNA1 was often below 50%. At the same time, the RDNA series always enjoyed a high bandwidth and low latency L2. Putting more pressure on L2 in exchange for reducing L2 misses may have been an enticing tradeoff. Another possibility is that AMD ran into validation issues with the L1 cache and decided to skip it for this generation. There’s no way to verify either possibility of course, but I think the former reasons make more sense.\n\nBeyond tweaking the cache hierarchy, RDNA4 brings improvements to transparent compression. AMD emphasized that they’re using compression throughout the SoC, including at points like the display engine and media engine. Compressed data can be stored in caches, and decompressed before being written back to memory. Compression cuts down on data transfer, which reduces bandwidth requirements and improves power efficiency.\n\nTransparent compression is not a new feature. It has a long history of being one tool in the GPU toolbox for reducing memory bandwidth usage, and it would be difficult to find any modern GPU without compression features of some sort. Even compression in other blocks like the display engine have precedent. Intel’s display engines for example use Framebuffer Compression (FBC), which can write a compressed copy of frame data and keep fetching the compressed copy to reduce data transfer power usage as long as the data doesn’t change. Prior RDNA generations had compression features too, and AMD’sdocumentation summarizes some compression targets. While AMD didn’t talk about compression efficiency, I tried to take similar frame captures using RGP on both RDNA1 and RDNA4 to see if there’s a large difference in memory access per frame. It didn’t quite work out the way I expected, but I’ll put them here anyway and discuss why evaluating compression efficacy is challenging.\n\nThe first challenge is that both architectures satisfy most memory requests from L0 or L1. AMD slides on RDNA1 suggest the L0 and L1 only hold decompressed data, at least for delta color compression. Compression does apply to L2. For RDNA4, AMD’s slides indicate it applies to the Infinity Cache too. However, focusing on data transfer to and from the L2 wouldn’t work due the large cache hierarchy differences between those RDNA generations.\n\nDCC, or delta color compression, is not the only form of compression. But this slide shows one example of compression/decompression happening in front of L2\n\nAnother issue is, it’s easy to imagine a compression scheme that doesn’t change the number of cache requests involved. For example, data might be compressed to only take up part of a cacheline. A request only causes a subset of the cacheline to be read out, which a decompressor module expands to the full 128B. Older RDNA1 slides are ambiguous about this, indicating that DCC operates on 256B granularity (two cachelines) without providing further details.\n\nIn any case, compression may be a contributing factor in RDNA4 being able to achieve better performance while using a smaller Infinity Cache than prior generations, despite only having a 256-bit GDDR6 DRAM setup.\n\nSoC Features\n\nAMD went over RAS, or reliability, availability, and serviceability features in RDNA4. Modern chips use parity and ECC to detect errors and correct them, and evidently RDNA4 does the same. Unrecoverable errors are handled with driver intervention, by “re-initializing the relevant portion of the SoC, thus preventing the platform from shutting down”. There’s two ways to interpret that statement. One is that the GPU can be re-initialized to recover from hardware errors, obviously affecting any software relying on GPU acceleration. Another is that some parts of the GPU can be re-initialized while the GPU continues handling work. I think the former is more likely, though I can imagine the latter being possible in limited forms too. For example, an unrecoverable error reading from GDDR6 can hypothetically be fixed if that data is backed by a duplicate in system memory. The driver could transfer known-good data from the host to replace the corrupted copy. But errors with modified data would be difficult to recover from, because there might not be an up-to-date copy elsewhere in the system.\n\nOn the security front, microprocessors get private buses to “critical blocks” and protected register access mechanisms. Security here targets HDCP and other DRM features, which I don’t find particularly amusing. But terminology shown on the slide is interesting, because MP0 and MP1 are also covered in AMD’s CPU-side documentation. On the CPU side, MP0 (microprocessor 0) handles some Secure Encrypted Virtualization (SEV) features. It’s sometimes called the Platform Security Processor (PSP) too. MP1 on CPUs is called the System Management Unit (SMU), which covers power control functions. Curiously AMD’s slide labels MP1 and the SMU separately on RDNA4. MP0/MP1 could have completely different functions on GPUs of course. But the common terminology raises the possibility that there’s a lot of shared work between CPU and GPU SoC design. RAS is also a very traditional CPU feature, though GPUs have picked up RAS features over time as GPU compute picked up steam.\n\nInfinity Fabric\n\nOne of the most obvious examples of shared effort between the CPU and GPU sides is Infinity Fabric making its way to graphics designs. This started years ago with Vega, though back then using Infinity Fabric was more of an implementation detail. But years later, Infinity Fabric components provided an elegant way to implement a large last level cache, or multi-socket coherent systems with gigantic iGPUs (like MI300A).\n\nSlide from Hot Chips 29, covering Infinity Fabric used in AMD’s older Vega GPU\n\nThe Infinity Fabric memory-side subsystem on RDNA4 consists of 16 CS (Coherent Station) blocks, each paired with a Unified Memory Controller (UMC). Coherent Stations receive requests coming off the graphics L2 and other clients. They ensure coherent memory access by either getting data from a UMC, or by sending a probe if another block has a more up-to-date copy of the requested cacheline. The CS is a logical place to implement a memory side cache, and each CS instance has 4 MB of cache in RDNA4.\n\nTo save power, Infinity Fabric supports DVFS (dynamic voltage and frequency scaling) to save power, and clocks between 1.5 and 2.5 GHz. Infinity Fabric bandwidth is 1024 bytes per clock, which suggests the Infinity Cache can provide 2.5 TB/s of theoretical bandwidth. That roughly lines up with results from Nemes’s Vulkan-based GPU cache and memory bandwidth microbenchmark.\n\nAMD also went over their ability to disable various SoC components to harvest dies and create different SKUs. Shader Engines, WGPs, and memory controller channels can be disabled. AMD and other manufacturers have used similar harvesting capabilities in the past. I’m not sure what’s new here. Likely, AMD wants to re-emphasize their harvesting options.\n\nFinally, AMD mentioned that they chose a monolithic design for RDNA4 because it made sense for a graphics engine of its size. They looked at performance goals, package assembly and turnaround time, and cost. After evaluating those factors, they decided a monolithic design was the right option. It’s not a surprise. After all, AMD used monolithic designs for lower end RDNA3 products with smaller graphics engines, and only used chiplets for the largest SKUs. Rather, it’s a reminder that there’s no one size fits all solution. Whether a monolithic or chiplet-based design makes more sense depends heavily on design goals.\n\nFinal Words\n\nRDNA4 brings a lot of exciting improvements to the table, while breaking away from any attempt to tackle the top end performance segment. Rather than going for maximum performance, RDNA4 looks optimized to improve efficiency over prior generations. The RX 9070 offers similar performance to the RX 7900XT in rasterization workloads despite having a lower power budget, less memory bandwidth, and a smaller last level cache. Techspot also shows the RX 9070 leading with raytracing workloads, which aligns with AMD's goal of enhancing raytracing performance.\n\nSlide from RDNA4’s Launch Presentation not Hot Chips 2025\n\nAMD achieves this efficiency using compression, better raytracing structures, and a larger L2 cache. As a result, RDNA4 can pack its performance into a relatively small 356.5 mm² die and use a modest 256-bit GDDR6 memory setup. Display and media engine improvements are welcome too. Multi-monitor idle power feels like a neglected area for discrete GPUs, even though I know many people use multiple monitors for productivity. Lowering idle power in those setups is much appreciated. On the media engine side, AMD’s video encoding capabilities have often lagged behind the competition. RDNA4’s progress at least prevents AMD from falling as far behind as they have before.\n\nIf you like the content then consider heading over to the Patreon or PayPal if you want to toss a few bucks to Chips and Cheese. Also consider joining the Discord.",
      "source": "Chipsandcheese.com",
      "url": "https://chipsandcheese.com/p/amds-rdna4-gpu-architecture-at-hot",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "What Does 'Ti' Actually Mean On An Nvidia Graphics Card?",
      "content": "Nvidia is well known around the world for creating video graphics cards, with the company holding an impressive 94% market share in the sector. The company even provides the custom graphics chip for the Nintendo Switch 2 console. From more budget-minded offerings to high-end graphics cards, Nvidia needs a way to highlight the highest-end cards in a line, and does so by using the Ti abbreviation, which stands for Titanium.\n\nOne thing that helps define all modern Nvidia graphics cards is what is known as the CUDA core. A CUDA (Compute Unified Device Architecture) is responsible for processing the data sent to and from the graphics card, with potentially thousands of CUDA cores being used by a given Nvidia GPU. The more CUDA cores a graphics card has, the more powerful it generally is.\n\nOn top of CUDA cores, Nvidia graphics cards rely on dedicated VRAM (Video Random Access Memory) that is designed to process the video data coming from your graphics card. A video card that features more VRAM will allow you to produce and display higher, more complex graphics on screen. Cards in a line with the most CUDA cores and oftentimes with the most built-in VRAM generally earn the coveted Ti branding, marking them as the most powerful in a series.",
      "source": "BGR",
      "url": "https://www.bgr.com/1964309/what-nvidia-gpu-graphics-card-ti-means/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Bring back your old Mac: 5 ways to refresh the OS on elderly Apples",
      "content": "Any day now, a new version of Apple's macOS is due to launch, and it will exclude the bulk of the Intel-powered models the company has ever sold. However, there are multiple ways to breathe new life into Macs that go back as far as 10 or even 15 years.\n\nThe Reg FOSS desk has two older Intel Macs in daily use that can't run any currently-supported version of macOS, though. Recently, we've been exploring our available options, and we've found that there are multiple potential routes to keep an old-time Mac productive.\n\nmacOS 26 \"Tahoe\" is due in a few days, and there are a whole four Intel Macs that will be able to run it: the 2019 MacBook Pro and Mac Pro, and the 2020 MacBook Pro and iMac. Those are the official models, anyway. As we covered back in 2023, the OpenCore Legacy Patcher project offers a free tool that lets you create a custom-modified macOS installer that will let you install newer versions of macOS onto Macs too old to officially support them. We reckon there's a good chance that a future update to OCLP will make more older models able to run macOS 26.\n\n\"Tahoe\" is officially the last-ever macOS for Intel hardware, though. The switch to Arm-based Apple Silicon processors is permanently closing the door on the \"Hackintosh\" world, and the world of Arm devices is so wildly heterogeneous that there's basically zero prospect of running Arm macOS on anything else. That's why there's the special Armbian distro just to make the current Linux available on Arm kit.\n\nBefore we tried to upgrade one of our daily drivers with OCLP, though, we wanted to test drive upgrading to an unsupported macOS. To this end, we recently pulled a retired MacBook out of storage. It's a 2010 13-inch MacBook Pro. The last supported macOS for this model is 10.13 \"High Sierra\", and the newest mainstream web browser for this is Firefox 115, which is the ESR release from 2023. When its successor Firefox 128 appeared, Mozilla said it would keep updating version 115 for as long as possible. As The Register reported last week, that currently means March 2026. To get to the subsequent Firefox ESR, we needed at least macOS 10.15 \"Catalina\".\n\nThis shouldn't work, but it does: macOS 10.15 running happily on a MacBook Pro from two years before Apple's cut-off - Click to enlarge\n\nThat poses a slight snag. The 2010 MBP is the only Core 2 Duo machine we've encountered that refuses memory that's faster than the 1066 MHz DDR3 SDRAM for which it's specified. It wants at least one PC3-8500 SO-DIMM, and it won't start with PC3-10600, let alone even faster. (We blame the Nvidia GeForce 320M GPU for this fussiness.) As a result, our MBP only has 6 GB of RAM. That's a snag.\n\nThe current release of OCLP is version 2.4.1 and the oldest macOS it supports is macOS 11 \"Big Sur\". Officially, this will run in 4 GB, but we suspect it might be rather sluggish. However, OCLP doesn't support Catalina.\n\nEnter the DOS dude\n\nHelp is at hand from Collin Mistr, AKA dosdude1. Among other apps, he offers a tool called macOS Catalina Patcher. It's a just-over-200-MB download, although obviously you will need a copy of macOS Catalina as well. Apple has a helpful downloads page for every version from 10.7 to 15 (oddly, except 10.9 Mavericks, which was the first release the company distributed for free).\n\nCatalina Patcher offers three different ways to install, including an in-place upgrade. - Click to enlarge\n\nThe \"Install macOS Catalina.app\" file is an 8.26 GB download, so we didn't download a fresh copy: we copied it from our iMac onto a Mac-formatted USB key, and then onto the MBP. Then we downloaded Mistr's patcher and ran it. (Unsurprisingly, this is not an authorized app, as it does something Apple doesn't want to support, so don't double-click it; right-click it and pick Open.) It offers the choice of creating an installer USB, installing onto the machine it's running on, or creating an ISO file.\n\nSince this is a sacrificial testbed machine – it was replaced by a Core i7 Dell Latitude running ChromeOS Flex a couple of years ago – we just told it to install in place. It creates a modified installer in the /tmp folder, then launches that. First this converted our HFS+ SSD into the newer APFS format, then started the upgrade. Apple's time estimate was just under half an hour, but it took longer. Once the process finished, our 2010 MacBook Pro was running the 2020 version of macOS, even though it officially only supports models from 2012 onwards. On its own, macOS found an update for Safari, downloaded and installed it, and we were done.\n\nThere are no giveaways that this is an unofficial OS. The About this Mac dialog box still identifies the correct model, its GPU, its RAM slots, everything. On first launch, Firefox 115 automatically updated itself to version 128, and we then manually upgraded that to the latest 142. It runs fine – not blazingly fast, but pretty well for a 15-year-old computer based on a CPU launched in 2007.\n\nOur primary objective was successfully accomplished: to get a current, supported web browser. A few applets automatically updated themselves, such as the Rectangle window-tiling tool. We had to manually download Chrome from Google's Other Platforms page, and version 128 is the latest for this old OS, but it works.\n\nEvery silver lining has a cloud\n\nThere are some drawbacks to the upgrade, though. The machine is a little more sluggish than before. Although 10.15 was the first all-64-bit version of macOS, it has multiple new features to offset the removal of the 32-bit subsystems: the APFS filesystem, built-in Siri, several separate apps in place of iTunes, and so on. Our ancient but perfectly serviceable copy of Microsoft Office 2011 was 32-bit only so it no longer works. We grabbed the latest LibreOffice 25.8, which does work, but it's not exactly snappy. Now we have dark mode. Woohoo.\n\nTo be honest, just as Office 2011 did everything we wanted and a very great deal more besides, so did High Sierra. As The Register said in 2017:\n\nAll High Sierra's most interesting features are at the deep system level. 10.13 has no new apps and (almost) no new user-facing features at all. Apple has even resisted to give a cosmetic makeover to what's already there.\n\nIn this, it reminds us of the classic Mac OS X 10.6 \"Snow Leopard\", of which the same writer said:\n\nWhat greeted me was familiar: Snow Leopard starts like Leopard, down to the pixel. Apple promises that Snow Leopard frees about 7 GB from a comparable Leopard installation… there's some serious shrinkage going on. Safari's public beta on Leopard weighs in at 45 MB, but the Snow Leopard Safari at just 14 MB. The Address Book shrinks from 58 MB to 15 MB. Mail is now 77.5 MB.\n\nThat's the kind of upgrade we like. These days, 10.6 is hailed as one of the best-ever releases. Perhaps we should say liked, because High Sierra was the last time Apple managed a new version that looked and worked the same, but tightened everything up under the hood.\n\nNostalgia for old OS releases‽\n\nPart of the reason for this dramatic shrinkage was that Mac OS X 10.5 \"Leopard\" was the last ever PowerPC version. 10.6 removed all the PowerPC code, leaving only Rosetta, licensed from Transitive – which also sold it as QuickTransit to HP and Novell before IBM acquired it in 2008.\n\nOfficially, Snow Leopard is Intel only. That hasn't stopped the hardcore PowerMac enthusiasts, though, who have managed to custom-compile and put out a pre-release version.\n\nSome Mac fans miss old versions, just as some Windows fans do. We've written about running the translucent glories of Windows 7 in 2025, as we did about running Windows XP in 2023.\n\nAlthough it still looks sleek, Snow Leopard is so long in the tooth now that it's more of a Smilodon. This vulture ran it for years on a homemade Hackintosh, but we don't want to go back that far.\n\nWe recently discovered the website of Jonathan \"Wowfunhappy\" Alland, a discerning vintage-macOS aficionado who runs Mavericks Forever, and on it, he explains in detail why he chose this particular version; for instance, it was the first OS X to support memory compression, so it runs well on low-memory machines, and it was one of the last versions to retain the Aqua appearance. He also has a meticulously curated Mavericks App Library.\n\nNow that we've upgraded our elderly MacBook Pro, we're considering maxing out its memory and seeing how far we can upgrade it, but we might end up going backwards instead. However, on the same trip when we retrieved the MBP, we also collected an even older MacBook: a 2008 white MacBook. Sadly, this machine really is maxed out. As far as we can find out, OS X 10.7 \"Lion\" really is the last version of OS X it can run.\n\nLeopards and Lions … why not revenant Foxes, and shiny shiny Chromium?\n\nBut some of the hints on Mavericks Forever made us wonder if we could make Lion a little more useful. Before COVID-19, we had installed Firefox Legacy on the machine. It's based on Firefox 68, but although it's not maintained anymore, it still works and can open most contemporary websites. The Mavericks page told us about Firefox Dynasty. This is a port of the current Firefox for older versions of Mac OS X, back to version 10.8 \"Mountain Lion\".\n\nUnfortunately, it's on GitHub, and Firefox Legacy can't open GitHub's JavaScript-riddled Releases page. But we did recently discover another browser that can: Chromium Legacy. The latest version is from May 2024, based on Chromium 127, but it unzips and runs fine on \"Lion\", and in turn, it enabled us to download Firefox Dynasty.\n\nAnd this definitely shouldn't work, but here's the current Firefox (and Chromium 124) on OS X 10.7. - Click to enlarge\n\nResult: the latest Firefox 142, complete with vertical tab bar, running happily on the version of OS X El Reg reviewed in 2011. And, for any websites that won't work right in Firefox, we have a fairly recent version of Chromium as well. Suddenly, that makes this ancient OS a much more viable proposition.\n\nOne limitation of Chromium Legacy is that it can't check for updates – if there ever will be any more – and you may have difficulties fetching it from GitHub using a very old Firefox. Never fear: Wowfunhappy's Chromium Legacy Downloader is here, and he also offers the corresponding Firefox Dynasty Downloader PrefPane.\n\nSomewhere, we think we have a spare 4 GB DDR2 SO-DIMM lying around. We will try to max out the MacBook's RAM at a massive 6 GB, give the creaky old thing a small SSD, and take it out on the road for a run. With two modern browsers, we should be able to handle most things, and fifteen or twenty-year-old writing tools are still absolutely perfect. Maybe we can dig out a copy of Word from before the \"fluent interface\" and its wretched Ribbon were dreamed up.\n\nBootnote\n\nAs we've seen, a community of dedicated and determined enthusiasts is getting more recent OSes and modern browsers working on ancient Intel Macs and PowerMacs.\n\nBut it's not limited to getting newer OSes running on older kit. The counterpart is Mac OS 9 Lives, which has versions of the real original macOS that have been tweaked to run on some later PowerPC G4 hardware, released after Apple started amending the machines' firmware to compel users to switch to the fancy new Mac OS X.\n\nFor instance, there's a build of Mac OS 9.2.2 for iBook G4, and another one for the Mac mini G4. Somewhere, we have both of those machines, and once we can find them, we plan to try this out. They are both rather underpowered for Mac OS X, but they represent the fastest hardware ever made for Mac OS 9.\n\nOur G4 mini was a gift from the late DJ Walker Morgan, who some Register readers may remember for his Unix column in Personal Computer World under the pseudonym of David Evnull. (\"D. Evnull\" – /dev/null – geddit?) Ave, atque, vale. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/13/refresh_an_old_mac/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "NVIDIA and OpenAI CEOs accompanying President Trump's UK state visit — major AI projects on the agenda",
      "content": "U.S. President Donald Trump is about to do something none of his predecessors have — make a second full state visit to the UK. Ordinarily, a President in a second term of office visits, meets with the monarch, but doesn't get a second full state visit.\n\nOn this one it seems he'll be accompanied by two of the biggest faces in the ever-growing AI race; OpenAI CEO, Sam Altman, and NVIDIA CEO, Jensen Huang.\n\nThis is according to a report by the Financial Times, which claims that the two are accompanying President Trump to announce a \"large artificial intelligence infrastructure deal.\"\n\nThe deal is said to support a number of data center projects in the UK, another deal towards developing \"sovereign\" AI for another of the United States' allies.\n\nThe report claims that the two CEOs will announce the deal during the Trump state visit, and will see OpenAI supply the technology, and NVIDIA the hardware. The UK will supply all the energy required, which is handy for the two companies involved.\n\nUK energy is some of the most expensive in the world (one reason I'm trying to use my gaming PC with an RTX 5090 a lot less!)\n\nThe exact makeup of the deal is still unknown, and, naturally, neither the U.S. nor UK governments have said anything at this point.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAI has helped push NVIDIA to the lofty height of being the world's most valuable company. (Image credit: Getty Images | Kevin Dietsch)\n\nThe UK government, like many others, has openly announced its plans to invest in AI. As the next frontier for tech, you either get on board or you get left behind. And President Trump has made no secret of his desires to ensure the U.S. is a world leader.\n\nOpenAI isn't the only company that could provide the software side, but it is the most established. While Microsoft may be looking towards a future where it is less reliant on the tech behind ChatGPT for its own AI ambitions, it makes total sense that organizations around the world would be looking to OpenAI.\n\nNVIDIA, meanwhile, continues to be the runaway leader on the hardware front. We've seen recently that AMD is planning to keep pushing forward, and a recent Chinese model has reportedly been built to run specifically without NVIDIA GPUs.\n\nBut for now, everything runs best on NVIDIA, and as long as it can keep churning out enough GPUs to fill these data centers, it will continue to print money.\n\nThe state visit is scheduled to begin on Wednesday, September 17, so I'll be keeping a close eye out for when this AI deal gets announced.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/artificial-intelligence/nvidia-and-openai-ceos-accompanying-president-trumps-uk-state-visit-major-ai-projects-on-the-agenda",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Has Nvidia Lost Sight of the Core Consumer?",
      "content": "As seen in the above, datacenters made up a significantly smaller portion of NVDA's revenue prior to 2021 and the focus was on their core consumer grade gaming segment. However, with the popularization of generative AI tools like DALL-E and Chat-GPT by OpenAI in 2021 which sparked a race among the top tech companies to invest in and create the best generative models as a result we saw a more than 3x surge in AI investment market-wide between 2019 and 2021 which has since come to a plateau following a huge spike in 2021, after many of these companies including Microsoft and Google announced that they would be slowing down on their AI related spending and/or exploring in-house solutions to save on CapEx.\n\nBut today, It's all about AI and enterprise contracts. The headlines out of their most recent CES keynote weren't about consumer-grade GPUs or gaming, they were about new datacenter products and AI reasoning models with names like Nemotron and Llama in focus rather than the standard consumer power focused terms like CUDA and RTX. The everyday consumer will have minimal to no practical use for these AI reasoning models displayed by NVDA yet this was the focus of the showcase and really put things into perspective for me that NVDA seems to be abandoning its core consumer base in favor of satisfying its newly found AI enterprise markets. It was not so long ago that gaming was NVDA's top revenue source as detailed here in their 2021 Annual 10k filing;\n\nIn the past, NVIDIA events were all about Productivity, Games, GPUs, and Raw graphics horsepower aimed at consumer interests like pushing frames per second higher, powering better visuals, improving encoding performance, power efficiency, and exciting the consumer base by which Nvidia's $4 trillion foundation was built upon.\n\nVery little attention was given to the Next-gen consumer focused RTX-50 series graphics cards during the showcase. I found this to be disappointing because this was at an annual event meant to showcase Consumer Electronics, yet Nvidia consumers essentially took a backseat to all of these more Enterprise focused AI products/concepts.\n\nAt the start of 2025, there was a lot of optimistic chatter about what Nvidia's stock might do during this year's Central Electronics Showcase. Thinking back to this timeline it almost seemed as if every headline, every social media post, and the majority of online commentary surrounding Nvidia's CES press conference focused on Nvidia forwarding their growth in AI markets ranging from: AI PCs built for developers to more efficiently run LLMs, AI powered Robotics platforms, and their partnerships with various players within the Autonomous Automobile industry such as Toyota and Tesla.\n\nStory Continues\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Quid & Stanford University: 2025 AI Index\n\nThis AI investment surge has been congruent with the recent trend in NVDA's datacenter segment overtaking their gaming segment by an exponentially wide margin as seen a more recent 10k filing:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nIt is worth noting however that the corporate investments into AI only began to plateau in 2021-present, during this time we saw the top companies in the industry collectively aim to reduce their AI CapEx spend was also in alignment with the start of a sharp continuous decline in US Consumer Sentiment as released by the University of Michigan:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nFurthermore, this decline in consumer sentiment has not only been observed in the US but China as well as China Consumer Sentiment has nose-dived to and even further extent during the same period;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Organization for Economic Co-operation and Development via FRED\n\nThis sudden decline in the consumer sentiment has led to the pulling of investment capital not just in AI as detailed earlier, but also in adjacent industries like EVs;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: IEA\n\nI have referenced the chart above in a previous article, which delves into my concerns revolving around a recent slowdown in TSLA Cash Flows. If TSLA keeps going on the path that it currently is, their Non-adjusted Free Cash Flows will once again turn negative. Given that TSLA is one of NVDA's top B2B customers, I see this as a worrying trend as this has all aligned with the drop in consumer sentiment starting in 2021.\n\nEven as big tech investment into AI pulls back and the consumer sentiment declines, we can still see an exponential growth in the amount of newly funded Generative AI companies popping up on the frontend.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Quid & Stanford University: 2025 AI Index\n\nThese newfound startups could find themselves entering into what was a booming industry, now entering a cooldown period, if that's the case these companies will be unlikely to find success in chasing the Gen-AI trend now as the CapEx liquidity once provided to this industry by big tech players dries up.\n\nConcerningly, when evaluating NVDA's 2025 annual 10k filing it can be seen that 34% of this newfound revenue came from only three of their direct enterprise customers;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nThough Nvidia did not name their customers directly, it can be inferred through Omida Research's Q32023 report of H100 Shipments that NVDA's top customers were Microsoft, Meta, Google, and Amazon with notable business from TSLA, Oracle, Tiktok, and CoreWeave.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nGiven that many of these customers are the same companies that have begun to cut back on external AI CapEx spending, likely in alignment with the fall of the consumer, it is very likely that NVDA sees an exceptionally greater direct hit in not only their profit margins but also their total revenue as these companies seek internal solutions and competition from potentially more balanced companies such as Intel enters the fray.\n\nThe goal of many of these companies are to balance capex spend with their revenues and right now they are focusing on creating the best product for their core consumer base to fall back on, as these companies reduce spending, develop in-house solutions, or find better and most likely cheaper competitors to NVDA, we will see more and more of NVDA's overly focused B2B model dwindle. In times like these it would be great for NVDA to not only have a functioning B2B base but to also maintain its base consumer as a foundation to fall back on in hard times just some of NVDA's most successful corporate customers do, but in the effort to chase a growing AI trend NVDA has lost sight of that foundation and is leaving itself open to a massive pull of liquidity. The time may soon be coming when a company such as NVDA would want to have a strong consumer base to fall back on because as of now when reading into NVDA's QoQ Net Margins, a peak can already be observed, rounding down since the start of 2024 with a declines being experienced the in Q2, 2025.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MicroTrends.net\n\nThe last time we experienced any such decline in margins like this was at the start of 2022 which proceeded a 62% drop from $28.95 a share to $10.81 near the 89-month EMA all within the same year. If things were to go similarly this time around we could experience a similar 60-70% decline to around $50 per share aligning with the 89-month EMA in white.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: TradingView\n\nNVDA currently trades at a 57x multiple with a $3.15 EPS, I'd suspect that NVDA has the capacity to correct down to around a 15-20x multiple If it experienced a severe repricing due to its AI endeavors being priced out by the market and there's even the risk of EPS going down due to falling margins. If EPS drops significantly to $1.15, setting it back a year a 20x multiple of that would align with NVDA trading down to $23 a share in the coming months.\n\nIntel: Back to the consumer\n\nIntel, is taking the opposite approach of Nvidia.\n\nAt CES 2025, Intel rolled out its Core Ultra 200 series processors. These cover everything from thin-and-light laptops to high-performance desktops. Unlike Nvidia's corporate-heavy pitch, Intel's message was simple: more power, less energy, and prices that make sense for consumers.\n\nThe Core Ultra 200HX and H series aims to bring serious improvements to creators and gamers, better multi-thread performance, integrated Arc graphics, and even built-in NPUs for AI acceleration. The 200U series targets mainstream laptops, while the 200S series brings efficient yet power a high 16-20+ core count 125-watt chips to desktops.\n\nIntel is also targeting the mobile and notebook space directly, going up against Qualcomm and ARM and unlike Nvidia, Intel manufacture the majority of its chips in the United States. This puts them ad a great advantage when it comes to managing the ongoing tariffs and is likely to Nvidia heavy reliance on TSMC for production and Samsung for memory chips, which puts Nvidia in the crosshairs of these tariffs in which U.S based and sourced companies such as Intel and Micron could greatly benefit.\n\nAs NVDA has shifted its focus away from the consumer INTC has been aggressive in building its product lineup in the favor of the consumer and it really shows when looking at the chart of the historic video card market share:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: PassMark\n\nThe data here shows that NVDA's consumer video card market share dropped from 61.8% in 2022, to 54.2% in 2025, AMD remained stagnant, and during the same period, Intel's share rose from 16.1% to 21%.\n\nObserving the chart, it would appear that NVDA's market share is on a downwards trajectory with more declines likely as competition, mainly the now pro-consumer focused Intel continues to gain ground within NVDA's lost, yet core industry as Intel's product lineup right now puts the core consumer base first and remains easily accessible. Unlike NVDA, INTC is not talking about abstract AI models with gimmicky names that sound like they were ripped out of some sci-fi film; they're instead talking about battery life, power efficiency, security features, and real improvements that everyday people will notice when they buy their next laptop or desktop.\n\nA familiar trap?\n\nIn many ways, this is reminiscent to when Microsoft fumbled with the new generations of Xbox with the Kinect. Microsoft had a winning product in the Xbox 360 but got distracted by the gimmicks introduced with the Kinect, focusing on getting rid of the traditional controller in favor of motion controls, becoming an all in one media hub, and enforcing always online requirements for Xbox One with Kinect; a practice none of the consumers ever approved of yet Microsoft pushed it for years. It seems likely that Microsoft's obsession with motion controls came from their desire to chase after the success of the Nintendo Wii, which released in 2006, introduced motion controls to the masses, and ended up being the best-selling seventh generation console of that generation by far.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nBut by the time the eighth generation rolled in, the novelty of motion controls had long played it course and that was made very apparent with the fall in the Nintendo Wii's yearly sales as well as to complete failure of the Wii U.\n\nDuring the start of the eighth generation in 2013, we would see Sony, with its PS4 release, focus on games and gamer alike, showcasing pro-consumer features such as game sharing along with the ability to play games without the need of an internet connection; all backed by a strong lineup of game releases to boot. Sony did all of this and even took direct jabs at Microsoft, their competition, who was not then concerned with these pro-consumer moves at the time. Despite these open jabs from Sony, Microsoft would carry on with its anti-consumer practices in favor of the Kinect as it continued to push the all-in-one media hub features which was likely an attempt to compete with the then trending streaming markets, as well as pushing the motion controls which was a dying fad. As a result, a new trend would emerge of yearly PS4 sales consistently being double that of Xbox One sales;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nOne year later the CEO of Microsoft would appoint Phil Spencer as the new head of Xbox who then would undo the anti-consumer practices set in motion by the previous head, Don Mattrick, starting with the unbundling of the kinect and a more consumer friendly approach to gamer by offering backwards compatibility, and reverting back to the brand's roots; Unfortunately it was too late as the previous leadership had already sullied the brand's relationship with its core customer base and many of those that might have considered coming back to Xbox were already comfortably on PlayStation and later on, thanks to a much improved marketing campaign, Nintendo Switch; the result of Xbox's previous years of not focusing on the core consumer and even antagonizing the consumer at times made it very tough to take back market share against Nintendo and Sony, which remained, focused on their core gaming audience throughout.\n\nEven all these years later in the ninth generation of consoles, as Microsoft has spent the last 13 years reversing course on all of these anti-consumer practices, they remain significantly behind Nintendo and Sony generations later as the consumer base has already settled within their perspective ecosystems and winning them back has proven to be very hard for Microsoft to do with PS5 sales now being triple that of Xbox Series X/S.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nNvidia risks falling into the same trap: chasing enterprise AI hype while forgetting about the consumer market that made it a household name in the first place and in time of economic slowdown Nvidia will need to lean back on this core base but by the time they do another competitor would have likely scooped up a significant portion of this core base and just like Microsoft with the Xbox, it could take years before Nvidia can rebuild all of that lost consumer trust.\n\nValuation Overview:\n\nWhen taking in account NVDA's slowdown in profit margins mainly attributed to the slowdown in enterprise revenue paired with their loss in market share to INTC within the consumer base, it makes sense to consider INTC as the alternative investment to NVDA. Despite INTC's recent shaky history of EPS misses, it is worth considering the fact that the stock price trades at a very low price to sales multiple of 1.98x:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nThis low price to sales value contrasts with NVDA's which currently trades at a 25.95x multiple to its sales;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nThis in my opinion is a massive oversight in the market that shows speculative growth being priced into NVDA while ignoring the current actual contraction NVDA is currently facing, as a result, the comparison of these ratios tells us that sales growth is failing to keep up with the high speculative valuations of the current market.\n\nMeanwhile the market has severely undervalued INTC, not taking into consideration the fact that it is currently gaining a significant core market share against NVDA and AMD alike in a trend that seems likely to continue.\n\nLooking into other valuation data we can also see that INTC trades at a 1.01x book value which ultimately confirms that despite INTC's recent growth, the stock market still hasn't priced in any growth at all within the company which means that the stock is currently at its fairest value right now.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nMeanwhile when looking at NVDA's price to book we can see that in spite of recent contractions, the market is still valuing NVDA's stock at a 42.33x multiple to its book value.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nTaking in the totality of the data it would be in my opinion a valuable opportunity to capitalize on the arbitrage between NVDA and INTC's valuation and performance by investing long term into INTC rather it be shares or Long Call LEAPS (1 year or more of theta), while reducing share allocation or even buying some longer dated 300+ DTE OTM puts in NVDA or at least hedging current long positions in NVDA more aggressively with covered calls. As this arbitrage closes, I would anticipate NVDA's market cap valuation to contract while INTC's expands, narrowing the current spread between NVDA's $4.4T and INTC's $100B market cap valuations.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-lost-sight-core-consumer-185126232.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "As of 2025, the Average Social Security Retirement Benefit Check Is $1,976. Could Nvidia Help Boost Your Retirement?",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_a4129eb8-d5bc-494f-a061-a06b3a2b5061",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Are NVIDIA Shares Still Worth the Price After UK Datacenter Investment News?",
      "content": "Thinking about what to do with your NVIDIA shares? You’re not alone. Whether you’ve been riding the wave since the early days or just now looking at that ticker symbol, NVIDIA’s recent moves have certainly put it on everyone’s radar. Just this past week, the stock jumped 6.5%, bouncing back after a minor 1.5% stumble over the past month. For the year-to-date, that’s an impressive climb of 28.6%, while the longer view is almost jaw-dropping: up more than 1,200% over three years and over 1,300% across five years. Those numbers are hard to ignore, especially when the headlines keep NVIDIA front and center in the tech world.\n\nRecent news about NVIDIA partnering with global players on massive datacenter investments underscores the company’s persistent growth narrative. At the same time, the company has faced new challenges, like scaling back some cloud services to focus on core strengths and seeing competition rise from major clients developing their own AI chips. The market is taking it all in stride, recalibrating its expectations and risk appetite in real time.\n\nIf you’re wondering if all that momentum is baked into today’s price or if there’s more room to grow, here’s a good starting point: by our scorecard, NVIDIA clocks a valuation score of 2 out of 6. That means it’s undervalued in only two key checks, something we’ll break down together, step by step. In the next section, I’ll walk you through these valuation methods to put today’s price in context, and stick around for a smarter way to assess true value at the end.\n\nNVIDIA scores just 2/6 on our valuation checks. See what other red flags we found in the full valuation breakdown.\n\nApproach 1: NVIDIA Discounted Cash Flow (DCF) Analysis\n\nA Discounted Cash Flow (DCF) model works by forecasting a company’s future free cash flows and then discounting those back to their present value. This gives investors an estimate of what the business is really worth today, based on its expected ability to generate cash in the future.\n\nFor NVIDIA, the current Free Cash Flow is $72.28 Billion. Analysts forecast this number to grow rapidly over the upcoming years, reaching a projected $249.21 Billion by 2030. Estimates are solid for the next five years; after that, Simply Wall St algorithmically extends the projections further, reflecting optimism around NVIDIA’s continuing innovation and market expansion.\n\nUsing these projections and discounting them to today's dollars, the DCF model calculates an intrinsic value of $143.89 per share. This valuation suggests NVIDIA shares are around 23.6% overvalued compared to the current stock price.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-shares-still-worth-price-122551220.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Beyond the data center: Nvidia’s GB10 and DGX Spark mark a new phase in its AI strategy",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250912PD217/nvidia-soc-market-2025-gpu.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "NVIDIA Pulls GeForce RTX 5090 and RTX 5080 Founders Edition from Its Marketplace",
      "content": "NVIDIA has quietly removed its GeForce RTX 5090 and RTX 5080 Founders Edition graphics cards from its online marketplace. This removal seems to affect all international online stores, including those in the US, Germany, the UK, and France. In the US, NVIDIA now only offers the Founders Edition version of the GeForce RTX 5070, which includes a Borderlands 4 game as a bonus. The Founders Edition versions of the RTX 5090 and RTX 5080 are absent, with AIB-designed versions taking their place. The situation is similar in the UK, while stores in France and Germany only list the RTX 5070 and RTX 5080 Founders Editions, with no RTX 5090 Founders Edition available.One possible reason for this could be that NVIDIA is preparing a mid-cycle refresh with the RTX 50 SUPER series and wants to avoid excess inventory of non-SUPER models. However, this would mainly affect the RTX 5070 and RTX 5080, which are rumored to receive the SUPER upgrade. There is no clear explanation for the absence of the RTX 5090 Founders Edition from all global stores, especially given the high demand and record-breaking gaming revenues . An End-of-Life (EOL) scenario seems unlikely. We can only speculate about NVIDIA's reasons for this removal, but it might be an inventory adjustment, as NVIDIA could have distributed too many of these models to other retailers, leaving none for its own store. We will continue to monitor the marketplace for updates in the coming days.: An NVIDIA spokesperson for Wccftech confirmed that \"GeForce RTX 50 series Founders Editions continue to be in production. They are limited edition products so, from time to time, go out of stock on our website and return when back in stock.\" So there are no long-term reasons for potential buyers to worry about.Below are the screenshots with the available Founders Edition SKUs at the time of writing. The listings are presented in an order of: US, UK, Germany, and France.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340982/nvidia-pulls-geforce-rtx-5090-and-rtx-5080-founders-edition-from-its-marketplace",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Wall Street Turns Bullish on NVIDIA (NVDA) as AI Compute Drives Growth",
      "content": "NVIDIA Corporation (NASDAQ:NVDA) is one of the AI Stocks on Wall Street’s Radar. On September 11, D.A. Davidson upgraded the stock to “Buy” from Neutral and with a price target of $210, up from $195. The firm said that it is getting more bullish on the stock.\n\nAccording to the firm, the growth in AI compute demand is going to drive enough demand that will sustain Nvidia’s growth next year and even beyond.\n\n“We believe the growth in AI compute demand will drive enough demand to sustain NVDA’s growth into next year and likely beyond. While there are still several cross-currents, we believe those are not enough to change that trajectory and are upgrading to BUY from Neutral, raising our price target to $210 from $195.\"\n\n\"Our increasingly optimistic view of the growth in AI compute demand supersedes our list of concerns regarding NVDA. Our perspective that AI will transform work through labor itself, as opposed to the IT tech stack, lends itself to a continued ramp in compute demand even before enterprise customers see a return on investment.”\n\nNVIDIA Corporation (NASDAQ:NVDA) specializes in AI-driven solutions, offering platforms for data centers, self-driving cars, robotics, and cloud services.\n\nWhile we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 10 AI Stocks In The Spotlight For Investors and 10 AI Stocks on Wall Street’s Radar.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/wall-street-turns-bullish-nvidia-001416750.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Beijing Tsinghua professor warns China must cut AI reliance on Nvidia",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250912PD237/nvidia-asia-chairman-tsinghua-university-training.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Refurb Weekend: Silicon Graphics Indigo² Impact 10000",
      "content": "My general vintage computing projects, mostly microcomputers, 6502, PalmOS, 68K/Power Mac and Unix workstations, but that's not all you'll see. While over the decades I've written for publications likeand, these articles are all original and just for you. My promise: No AI-generated article text, ever. All em-dashes are intentional and inserted by hand. Be kind, REWIND and PLAY.Old VCR is advertisement- and donation-funded, and what I get goes to maintaining the hardware here at Floodgap. I don't drink coffee, but the Mr Pibb doesn't buy itself. :-) Thanks for reading.",
      "source": "Blogspot.com",
      "url": "http://oldvcr.blogspot.com/2025/09/refurb-weekend-silicon-graphics-indigo.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Trump is modeling Chinese state capitalism and there's no going back (Long Le/The Hill)",
      "content": "Sister Sites:\n\nTechmeme\n\nTop news and commentary for technology's leaders, from all around the web Top news and commentary for technology's leaders, from all around the web Mediagazer\n\nTop news and commentary for media professionals from all around the web Top news and commentary for media professionals from all around the web WeSmirch\n\nThe top celebrity news from all around the web on a single page The top celebrity news from all around the web on a single page",
      "source": "Memeorandum.com",
      "url": "https://www.memeorandum.com/250914/p45",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "China says Nvidia violated antitrust laws",
      "content": "lighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nRegulators in China said US chip giant Nvidia broke its antitrust laws, following a preliminary investigation.\n\nThe State Administration for Market Regulation, or SAMR, said in a brief Monday statement that Nvidia violated anti-monopoly laws.\n\nThe regulator said it suspected Nvidia of violating commitments made during its 2020 acquisition of Israeli chip designer Mellanox, which Beijing had conditionally approved. SAMR then launched an antitrust probe into the Mellanox deal in December 2024.\n\n\"The State Administration for Market Regulation decided to conduct further investigation into it in accordance with the law,\" the regulator said in its statement.\n\n\"We comply with the law in all respects,\" an Nvidia spokesperson told Business Insider. \"We will continue to cooperate with all relevant government agencies as they evaluate the impact of export controls on competition in the commercial markets.\"\n\nShares in Nvidia fell 2.5% in premarket trading.\n\nNvidia is at the heart of ongoing semiconductor industry tensions between the US and China.\n\nThe US began limiting China's access to high-tech chips in 2022.\n\nIn April, the US government announced a new export license requirement for Nvidia's H20 chip, which had been designed to comply with previous rules. The company said it expected a $5.5 billion hit in first-quarter earnings due to the new restrictions.\n\nNvidia CEO Jensen Huang said in May that China's AI market could be worth $50 billion in a few years' time, and that losing access to it would be a \"tremendous loss\" for his company.\n\nIn July, Nvidia said it was gearing up to sell its H20 chips in China again after receiving export assurances from the US government.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/china-nvidia-violated-antitrust-laws-mellanox-chips-semiconductors-2025-9",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Fueled by AI Hype, Google Becomes Fourth Company to Pass $3 Trillion Market Cap",
      "content": "On Monday, Google’s parent company, Alphabet, became the fourth company to reach a market value of $3 trillion, and every member of this exclusive club has something in common.\n\nAll it took was a rather small 4% rise in shares for the tech giant to hit the coveted stock market benchmark. Rather unsurprisingly, the three previous winners of that title—Nvidia, Microsoft, and Apple—are all titans of the tech industry that have been riding the wave of investor interest in AI, as well.\n\nAlphabet stock had a great start to September after a federal judge concluded earlier this month that the tech giant could keep Chrome despite its monopoly in internet search. The judge’s reasoning for that was that generative AI would eventually pose “a meaningful challenge to Google’s market dominance.”\n\nGoogle is trying to get ahead of that “meaningful challenge” by fusing AI into its search engine and pouring billions into developing its AI offerings, including its own AI chatbot Gemini.\n\nIt seems that investment cashed out for the company. As of Monday morning, Google Gemini is now the number one free app on Apple’s App Store, relegating OpenAI’s ChatGPT to number two status and giving the much-needed push to the company’s stock.\n\nThe AI hype is inextricably and intricately linked to the significant stock market returns that these tech giants, and many others, have experienced this year. The trillion-dollar question: Is there an AI bubble?\n\nAI hype driving major gains\n\nThe best example of AI hype delivering trillions of dollars of financial gain is perhaps Nvidia, the ultimate AI darling of the stock market. Due to its immense market share in AI chips and the meteoric rise it experienced thanks to the technology, the company is largely considered the face of the AI hype.\n\nEarlier this summer, Nvidia made history as the first company to ever hit $4 trillion market valuation.\n\nApple, considered the least AI-savvy of the four companies to breach the $3 trillion benchmark, was the first company to ever be worth $3 trillion but is still yet to hit $4 trillion. Meanwhile, both Nvidia and Microsoft have outperformed Apple and already reached that milestone. Microsoft’s breach of the $4 trillion benchmark was also thanks to AI.\n\nLate July, Microsoft posted an earnings report that showed stellar revenue for its cloud computing platform Azure. The stock move following the report pushed Microsoft briefly above $4 trillion market value.\n\nFellow cloud infrastructure provider Oracle also benefited greatly from an AI-demand-driven stock move. Chairman Larry Ellison became the richest man on Earth last week after Oracle stock skyrocketed more than 42% on news that the company expects to collect half a trillion dollars (and potentially billions of dollars more) in the coming quarter on AI deals alone.\n\nIs there a bubble?\n\nAll this is great news for tech companies and their financial metrics, but is it substantiated? That question has been plaguing investors for some time now.\n\nAccording to some experts (and OpenAI CEO Sam Altman), there is indeed an AI bubble.\n\n“Are we in a phase where investors as a whole are overexcited about AI?” Altman said last month in a dinner with journalists, according to The Verge. “My opinion is yes.”\n\nAn AI report from MIT fueled those worries further just a few weeks ago. The researchers shared that despite the push to scale AI in the corporate world, fewer than one in ten AI pilot programs have actually generated revenue gains.\n\nAI is currently deployed mostly by larger firms in select fields. But even there, AI adoption is now declining, according to the latest U.S. Census Bureau findings.\n\nIf AI is indeed in a bubble, the burst could be catastrophic. So much is riding on the AI wave right now, including the entire U.S. economy.\n\nIn a paper published in July, Fed researchers said that if AI demand does not scale proportionally with investment, it can lead to “disastrous consequences,” and compared it to the railroad over-expansion of the 1800s and the economic depression that followed. Also in July, economist Torsten Slok called the AI bubble of today even worse than the 1999 Dot-com bubble.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/fueled-by-ai-hype-google-becomes-fourth-company-to-pass-3-trillion-market-cap-2000658927",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Nvidia targeted by China: Top Story",
      "content": "00:00 Speaker A\n\nWell, overnight, China has ruled that Nvidia violated anti-monopoly laws after concluding an initial investigation.\n\n00:10 Speaker A\n\nThis is likely to ramp up the pressure on Washington during sensitive trade negotiations that are taking place right now in Madrid.\n\n00:20 Speaker A\n\nNvidia's shares fell over 2% in the pre-market. The company has previously disclosed it's facing scrutiny inside China where regulators demanded it keep supplying local companies in return\n\n00:34 Speaker A\n\nfor regulatory approval of its 2020 acquisition of Mellanox.\n\n00:40 Speaker A\n\nAccording to China's anti-trust law, companies can face fines of between 1 and 10% of their annual sales from the previous year.\n\n00:50 Speaker A\n\nChina generated $17 billion in revenue for Nvidia in the fiscal year ending January 26th, or 13% of total sales based on its last annual report.\n\n01:03 Speaker A\n\nNow, US-China trade talks continue in Madrid today with the sale of Tik Tok high up on the agenda.\n\n01:10 Speaker A\n\nHere's President Trump's take on that. He was speaking before China released its Nvidia statement.\n\n01:23 Donald Trump\n\nI may or may not. They're negotiating Tik Tok right now.\n\n01:28 Donald Trump\n\nWe may let it die or we may, I don't know, it depends. Up to China. It doesn't matter too much.\n\n01:33 Donald Trump\n\nI'd like to uh do it for the kids that like it.\n\n01:37 Donald Trump\n\nI mean, selfishly speaking, I did very well on Tik Tok and I got the youth vote. I got numbers that nobody's ever even come close to in the Republican Party, nobody.\n\n01:48 Donald Trump\n\nIf you look back to Romney and all these people, they got practically no votes. I got a lot.\n\n01:53 Donald Trump\n\nAnd uh some was attributed to Tik Tok, and a lot was attributed to Charlie.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/nvidia-targeted-china-top-story-124435795.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "This Little-Known AI Stock Is Up 70% in 2025 and Analysts Think It Can Rally Further From Here",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/34814263/this-little-known-ai-stock-is-up-70-in-2025-and-analysts-think-it-can-rally-further-from-here",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "The Borderlands 4 PC Performance Fiasco, Explained",
      "content": "Borderlands 4 launched last week to big numbers and mostly positive reviews on Steam. But there’s been a lot of chatter and debate online about the looter shooter’s performance. Some players aren’t happy that Borderlands 4 seemingly requires DLSS and frame generation to run decently, even on the highest-end hardware. Meanwhile, Gearbox co-founder and CEO Randy Pitchford has defended the game’s performance, calling it “pretty damn optimal,” and suggested people need to use the “tools” provided by the studio and accept some trade-offs.\n\nOn PC, many games can utilize real-time upscaling tech, like Nvidia’s DLSS and AMD’s FSR. Nvidia and others have also created tools that allow your GPU to fill in the gaps between real frames rendered by the game with frames generated using deep learning tech. When this kind of tech was first introduced about six years ago or so, players complained that DLSS and other tools made games look blurry, even if it led to some performance boosts. As DLSS and similar tech have improved, the images produced looked have better and better. Today, DLSS 4.0 can produce some truly sharp-looking frames and provide some big performance gains, assuming you have a powerful enough video card.\n\nBut some, myself included, have started to grow concerned that studios are building games around DLSS and other similar tech, and aren’t optimizing them in the way devs did in the past. When DLSS was introduced, it felt like a great tool for gamers who had a slightly older card but still wanted to play a newer game. It would let them squeeze out a bit more performance without shelling out for a pricey upgrade. Now it seems like newer games running on more advanced engines require users to turn on DLSS and frame gen to play. And so enters Borderlands 4, a game that has found itself at the center of this heated debate.\n\nShortly after Borderlands 4 launched, players on PC began to complain that the game didn’t run very well. Gearbox responded with some updates that, at least in my experience with the game on PC, helped a bit. The company also released a guide from Nvidia for how to optimize the game based on your GPU and settings. And while that helped some reach better performance on PC, many others, myself included, were struggling to get the game to run well on powerful hardware. I’m rocking a 5080, and even playing the game at 1080p on medium settings led to tons of FPS drops, even while trying to play at 60FPS. That all changed when I did as Gearbox and Nvidia suggest and turned on DLSS and frame gen. Now, I can run Borderlands 4 at a mostly locked 120 with most settings set to high and medium. It looks nice and plays fine, but many aren’t okay with a game in 2025 being unable to run on high-end hardware without some upscaling assistance.\n\nNot helping matters is the fact that Randy Pitchford posted, as part of a recent and lengthy thread on Twitter, that people should use DLSS because it’s “great” and added: “The game was built to take advantage of it.” That, and a different part of the thread claiming it was acceptable for devs to focus on “default settings” reaching only 30FPS, didn’t go over well with a lot of PC gamers who specifically buy new parts and upgrade their rigs to achieve high framerates at high resolutions. For many, Pitchford’s claim that Borderlands 4 was developed to “take advantage” of DLSS was him confirming that it was built with the assumption that most users would use DLSS. And that, to some, sounds a lot like the game wasn’t properly optimized to run without help from DLSS and frame generation.\n\nWhile I do agree that newer DLSS and frame gen tools are powerful and impressive, it feels weird that Borderlands 4, along with other games like Alan Wake 2, demand that even users with the highest-end hardware lean on upscaling tech to play at decent settings and historically popular framerates like 120. In a recent video, the tech experts over at Digital Foundry weren’t impressed with Borderlands 4 on PC, with one even saying: “[Borderlands 4] does seem to be running worse than usual for an Unreal Engine 5 game. It is below where it seems like it should be given how other games using this engine perform.”\n\nPitchford has promised on Twitter that more updates are coming, including some more improvements to how the game runs on PC. He’s also been spending a lot of time online helping people improve how Borderlands 4 runs and claiming that performance issues are not as widespread as some might make you believe. Personally, I just miss when games could run on a high-end computer packed with powerful hardware without needing four different upscaling tools. And it seems I’m not alone.",
      "source": "Kotaku",
      "url": "https://kotaku.com/borderlands-4-pc-performance-dlss-frame-gen-pitchford-gearbox-steam-2000625765",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "\"NVIDIA violated the anti-monopoly law\" — China's ongoing investigation digs up antitrust violations as trade tensions mount",
      "content": "NVIDIA, the US company supplying most of the world with GPUs built specifically for powering AI, finds itself once again at odds with Chinese authorities.\n\nFollowing a preliminary investigation into the matter, Chinese antimonopoly regulators claim that NVIDIA broke antitrust laws (via Business Insider) in connection with the acquisition of Israeli chip design company Mellanox.\n\nNVIDIA announced it had reached a $6.9 billion deal with Mellanox in March 2019. China, shortly after the announcement, stated it had conditionally approved the deal.\n\nHowever, the antitrust investigation was initiated in December 2024 by China's State Administration for Market Regulation (SAMR). The investigation remains ongoing, say SAMR officials in the press release.\n\n[...] the State Administration for Market Regulation decided to conduct further investigation in accordance with the law.\n\nThe SAMR dropped the antitrust news at the same time that Chinese and US officials are attempting to negotiate trade intricacies in Madrid. Trade tensions have been on the rise for most of 2024 and 2025, with both sides making some bold claims regarding AI GPUs and how they're being used.\n\nA brief history of US, China, and NVIDIA trade tensions\n\nTwo cargo ships, one with a Chinese flag and the other with an American flag. (Image credit: Getty Images | Yaorusheng)\n\nA lot of recent trade tension between the US and China has NVIDIA sitting in the center. The GPU company's H20 AI chip, created specifically for the Chinese market as a less-powerful alternative to US AI chips, is highly sought after by China's AI firms.\n\nHowever, the NVIDIA chip was fully banned from being sold to China in April 2025 by the Trump administration. The cause of the ban centered on concerns that China was using the H20 chips to bolster its military and to develop further domestic AI models that could challenge US firms.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe ban was walked back in July, when NVIDIA CEO Jensen Huang reached a deal with President Trump following a White House visit. Huang's argument? It's better to have all AI models running on US technology.\n\nIt didn't take long for Huang to announce that NVIDIA was ordering 300,000 more H20 AI chips from TSMC in order to meet Chinese demand. And that was on top of the 600,000 to 700,000 H20 chips already stockpiled and awaiting buyers.\n\nAs a final part of the deal with the US government, NVIDIA and AMD agreed to pay a 15% chip tax for the export licenses needed to sell to China. The unprecedented deal remains informally approved. While Chinese AI firms clambered to place orders for the unbanned H20 AI GPUs, state officials began pressuring the firms to avoid the US hardware over fears of tracking devices, spyware, and other hidden back doors.\n\nNVIDIA responded by firmly stating that it wasn't placing any sort of trackers or malware in its AI GPUs.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/nvidia/nvidia-violated-anti-monopoly-laws-chinese-officials",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Tech Volatility to Persist: Columbia Threadneedle's Wade",
      "content": "There are no significant events for this country at this time. Select ‘All’ to see top events in other countries or view all events.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/tech-volatility-persist-columbia-threadneedles-194229741.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "SoundHound AI (SOUN) Stock Trades Up, Here Is Why",
      "content": "What Happened?\n\nShares of voice AI technology company SoundHound AI (NASDAQ:SOUN) jumped 2.1% in the afternoon session after it received continued positive commentary from Wall Street analysts.\n\nThe move follows several bullish actions, including DA Davidson analyst Gil Luria maintaining a \"Strong Buy\" rating and increasing the price target from $15 to $17 on September 10. Additionally, Wedbush's Daniel Ives reiterated a \"Buy\" rating on September 11. This optimistic analyst sentiment is supported by the company's strong performance, with a recent report noting that SoundHound AI's revenue tripled in the second quarter compared to the previous year. The company's voice AI platform has now surpassed 1 billion queries per month, positioning it to capitalize on the growing use of AI in devices, cars, and homes.\n\nAfter the initial pop the shares cooled down to $14.37, up 1.8% from previous close.\n\nIs now the time to buy SoundHound AI? Access our full analysis report here, it’s free.\n\nWhat Is The Market Telling Us\n\nSoundHound AI’s shares are extremely volatile and have had 92 moves greater than 5% over the last year. In that context, today’s move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.\n\nThe previous big move we wrote about was 5 days ago when the stock dropped 4.9% on the news that markets pulled back, reversing early gains, as investor sentiment remained cautious despite a softer-than-expected inflation reading.\n\nStocks rose in the morning session after an unexpected drop in the Producer Price Index (PPI) for August signaled easing inflation and raised expectations for a potential Federal Reserve interest rate cut. The U.S. Bureau of Labor Statistics reported that the PPI, which measures wholesale prices, edged down 0.1% last month, contrary to analyst expectations for a 0.3% rise. This data gives the Federal Reserve more flexibility to consider lowering interest rates to stimulate the economy.\n\nSoundHound AI is down 28.7% since the beginning of the year, and at $14.37 per share, it is trading 40.7% below its 52-week high of $24.23 from December 2024. Investors who bought $1,000 worth of SoundHound AI’s shares at the IPO in April 2022 would now be looking at an investment worth $1,915.\n\nUnless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/soundhound-ai-soun-stock-trades-183609103.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Canonical Make It Easier to Install NVIDIA CUDA on Ubuntu",
      "content": "Installing NVIDIA CUDA on Ubuntu desktops is about to get a whole lot easier, as Canonical today announced plans to package and distribute the latest releases in the Ubuntu repositories.\n\nCurrently, to install CUDA Toolkit and runtime on Ubuntu, users go to the NVIDIA website and download a repo DEB, install it, import a GPG key, pin the APT repo, and then install the relevant packages they need from the repo.\n\nShortly, everything they need will be in once place: the Ubuntu repos.\n\nIn packaging the CUDA toolkit and runtime (which includes proprietary components) and distributing it the Ubuntu archives, the ensure process is is simplified: a single command can installed everything, and users with supported NVIDIA hardware can get on with using it.\n\nThe move is part of an ongoing partnership between Canonical and NVIDIA, aimed at providing ‘turnkey AI solutions for the enterprise’ on Ubuntu — something NVIDIA CUDA is a core component of.\n\nOnce CUDA redistribution is fully integrated into Ubuntu, application developers and system administrators can expect the current multi-step CUDA installation process to become a single command Canonical\n\nCUDA is described as “a parallel computing platform and programming model that lets developers use NVIDIA GPUs for general-purpose processing”.\n\nIn practice, it is used for all kinds of things, from faster video encoding and machine learning training, to robotics, scientific computing and other computationally intensive workloads.\n\nWhich is why CUDA is widely used by developers, researchers, animators, data scientists, and AI/ML engineers. Making it easier to install on Ubuntu through a single command , users and enterprises will find Ubuntu a more attractive platform.\n\nWith CUDA available in the Ubuntu repos, any app or software that targets Ubuntu and makes use of CUDA is better able to detect and integrate with the software.\n\nThat helps position Ubuntu as a practical option to anyone looking for a capable, reliable and ready-to-use development environment (and with LTS support, security and stability reassurances).\n\nUbuntu may not be cool® among chronically-online and self-styled Linux influencers, but the distro remains the world’s most popular desktop Linux operating system. The bulk of the tens of millions of people who use it, use it for what it lets them do.\n\nAnd with CUDA in the repos (presumably the multiverse section), that’s more than before.\n\nYou can find a pinch more detail on the Canonical blog.",
      "source": "Omgubuntu.co.uk",
      "url": "https://www.omgubuntu.co.uk/2025/09/canonical-adds-nvidia-cuda-ubuntu-repos",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "\"Some need to learn how their PCs work\" — Borderlands 4 head fires back as optimal settings for 68 GPUs released",
      "content": "Borderlands 4, the latest looter-shooter in the beloved series from Gearbox Software, launched on September 11, 2025. Less than a week later, it's sitting at a \"Mixed\" review score on Steam with more than 16,500 entries. The prevailing issue forcing the review score down? Dreadful PC optimization.\n\nThe game's developer has now released a couple of lengthy PC optimization guides for both NVIDIA and AMD GPUs (via Videocardz). There are 68 different GPUs listed, with optimal settings for 1080p, 1440p, and 4K resolutions. NVIDIA's cards range from the RTX 2070 to the mighty RTX 5090, while AMD's cards range from the RX 5700 XT to the RX 9070 XT.\n\nUnless you're using an RTX 3060 Ti or newer, you can expect about 30 FPS at 1080p. For 1440p, you'll want at least an RTX 3070 Ti to run the game at 30 FPS. Want to play at 4K? You'll want at least an RTX 3090 Ti to hit 60 FPS.\n\nBorderlands 4's poor PC performance doesn't sit well with gamers\n\nA look at recommended NVIDIA GPU settings for playing Borderlands 4 at 1440p. (Image credit: 2K Games)\n\nMy current GPU, NVIDIA's RTX 5070 Ti, is listed under the 4K section. In order to achieve 60+ FPS, I'll need DLSS 4's Multi Frame Generation cranked up to 4x with texture quality set to Medium (and many other settings dropped to Low).\n\nIf I want to hit 60+ FPS at 1440p, I'll still need DLSS MFG 4x, though textures and other quality can be cranked up a bit. I think perhaps I'll wait a bit longer before trying the game to see if any more performance updates are released.\n\nDespite knowing months ahead of launch that Borderlands 4's PC specs were very demanding — more than 50% of Steam users may need an upgrade to play the game, at least judging by Steam's frequent hardware surveys — players are trashing the game for its brutal performance.\n\nPoor optimization and PC performance were topics of our Borderlands 4 review.\n\nDespite playing the game on an NVIDIA RTX 3080 and AMD Ryzen 9 5900X — older hardware that should nevertheless be relevant today — our reviewer experienced some brutal performance woes that mostly continued after a patch.\n\nTerrible, terrible performance. Worst I've ever seen. Turned it down to Low graphics preset and couldn't hit 60 FPS, even with FSR upscaling on my RX 6900 XT. Steam user \"Etiko\"\n\nRandy Pitchford, CEO of Gearbox Software, hasn't been shy about stating his case for Borderlands 4's performance. The game, which runs on the controversial Unreal Engine 5, is demanding, and Pitchford says gamers need to come to terms with lowering the resolution or in-game settings to achieve stability.\n\n\"Borderlands 4 is a premium game made for premium gamers,\" said Pitchford in an X reply to a gamer struggling to play on older hardware.\n\nThe minimum and recommended specs are published. The most common hardware is a four year old cell phone. Borderlands 4 is a premium game made for premium gamers. Just as Borderlands 4 cannot run on a PlayStation 4, it cannot be expected to run on too-old PC hardware. Unlike on…September 13, 2025\n\nConsidering NVIDIA's RTX 3060 and RTX 4060 GPUs continue to hold the top spots on Steam's GPU survey list, many players are struggling to come to terms with how a AAA game can launch at a $70 price tag and run so poorly.\n\nOn the other side of the hardware fence, console players have bemoaned the lack of an FOV slider and a motion blur toggle. Considering that both of these common settings can directly contribute to motion sickness, it's not a good look for Gearbox.\n\nIf you are indeed one of Borderlands 4's launch adopters, I recommend giving the recommended GPU specs laid out by Gearbox a shot. At this point, any extra frames are appreciated.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/gaming/pc-gaming/borderlands-4-official-amd-nvidia-gpu-settings",
      "timestamp": "2025-09-15"
    }
  ],
  "AMD": [
    {
      "headline": "Intel's crown as the best choice for gamers may be slipping as pros complain about its performance vs. AMD",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/intels-crown-slipping-pros-complain-performance-vs-amd/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Exit, rebuild, repeat — Intel’s new era begins without Holthaus",
      "content": "The Intel logo is displayed during the 2018 CeBIT technology trade fair\n\nIntel has announced major leadership changes as CEO Lip-Bu Tan pushes ahead with efforts to transform the struggling chipmaker. The most notable departure is Michelle Johnston Holthaus, whose career at Intel has spanned more than 30 years.\n\nThe shake-up comes just as Intel admitted its Arrow Lake processors failed to live up to expectations. All eyes are now on the upcoming Nova Lake architecture, which it hopes will restore competitiveness against AMD. This rivalry continues to gain ground with users and across the industry.\n\nHolthaus’s departure after 30 years at Intel\n\nHolthaus joined Intel in 1996, a year before I was even born, which makes me feel old. Anyway, starting as a program manager in the OEM Platform Solutions Division. Holthaus went from there, and she moved steadily through leadership roles in sales, marketing, and product development.\n\nBetween 2013 and 2017, she managed Intel’s partnership with Microsoft, coordinating sales, product roadmaps, and technical support. This role kept Intel’s CPUs and Microsoft’s platforms closely aligned across Windows, Surface, Xbox, and cloud services.\n\nIn late 2024, Holthaus stepped into the spotlight as interim co-CEO alongside CFO David Zinsner following Pat Gelsinger’s departure. She was later appointed CEO of Intel Products but held the position for only 9 months before resigning. Intel said the decision was due to “a material reduction in her duties, responsibilities, salary, and target annual bonus,” which matched the “Good Reason” clause in her contract.\n\nThanks to this clause, Holthaus will receive full severance benefits and remain with Intel in a non-executive advisory role until March 1, 2026.\n\nNew leadership team takes shape\n\nKevork Kechichian has joined Intel from Arm as Executive Vice President and General Manager of the Data Center Group. He brings more than 30 years of semiconductor experience and previously managed Snapdragon SoC teams at Qualcomm.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAnother addition is Jim Johnson, a 40-year Intel veteran, who has been confirmed as Senior Vice President and General Manager of the Client Computing Group. Over his long career, Johnson has worked across Intel’s Technology and Manufacturing Group, Networking and Communications, and global operations.\n\nIntel has also formed a new division in 2025, the Central Engineering Group, which will be led by Srinivasan “Srini” Iyengar. This team will focus on custom silicon design for external customers. Iyengar, who spent over 25 years at Cadence Design Systems, brings deep expertise in silicon engineering and design automation.\n\nLastly, Dr. Naga Chandrasekaran’s responsibilities have been expanded to include Foundry Services, alongside his existing role as Executive Vice President and Chief Technology and Operations Officer of Intel Foundry. Before joining Intel, he spent 16 years at Micron, where he led advanced memory technology development.\n\nTogether, these appointments show Tan’s push to blend long-time Intel leaders with external expertise from companies like Arm, Cadence, and Micron. It may take time before the results are clear, but the changes highlight Intel’s willingness to act boldly as it struggles to compete.\n\nTan’s strategy and vision for Intel’s future\n\nLip-Bu Tan, chief executive officer of Intel Corp (Image credit: Getty Images | Bloomberg)\n\nTan is aiming to cut back on bureaucracy by eliminating redundant management layers and creating a flatter, more focused structure. The goal is to speed up decision-making and bring more direct accountability. A clear example is that Holthaus’s position will not be replaced, with key groups now reporting directly to Lip-Bu Tan.\n\nHe is also pivoting Intel toward custom silicon and foundry services, areas where the company hopes to become a leader. The newly formed Central Engineering Group is central to this effort, with a focus on building chips for external customers instead of just Intel’s own products.\n\nOf course, no turnaround story in 2025 would be complete without AI, and Tan’s plans touch on that too. Still, the real test will be whether this strategy helps Intel compete with rivals like AMD. Rebuilding trust with users and partners will take time, but Nova Lake may give us the first glimpse of what Tan’s reshaped Intel can deliver.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/intel/exit-rebuild-repeat-intels-new-era-begins-without-holthaus",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Why I stopped overclocking my CPU after years of enthusiasm",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/cpu-overclocking-is-mostly-dead/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Will Broadcom Chips End AMD Stock's AI Dreams?",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/09/will-broadcom-chips-end-amd-stocks-ai-dreams/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD's FSR 4 upscaling tech gives even more PC games a free image quality upgrade – but you still need a modern GPU",
      "content": "AMD's FSR 4 is now available in most FSR 3.1 and DX12 supported games\n\nThe new Adrenalin Software driver allows users to override FSR 3.1 with FSR 4\n\nIt only works in games that have a signed FSR 3.1 DLL\n\nWhile AMD fans await an eventual FSR 4 backport to older non-RDNA 4 graphics cards alongside updates to the upscaling technology that's exclusive to some of the best GPUs on the market, Team Red has at least made life easier for developers and gamers.\n\nAs reported by VideoCardz, AMD's latest driver 25.9.1 adds further FSR 4 support for most FSR 3.1 and DX12-supported games, which AMD says is now 'over 85 games'. RDNA 4 GPU owners simply need to enable FSR 4 on the AMD Adrenalin Software and toggle on FSR 3.1 in a supported game, allowing the driver to override FSR 3.1 with FSR 4.\n\nIt's worth noting that this is only possible in games that have a signed FSR 3.1 DLL, which means the override won't work via third-party integration. While FSR 4 still hasn't been backported to RDNA 3 and older GPUs, FSR 4's driver override should make things much easier if a backport does happen soon.\n\nTeam Red's recent FSR 4 open-source slip-up revealed that it was (and potentially still is) working on an FSR 4 backport to RDNA 3. And with the FSR 'Redstone' presentation set to reveal frame generation and image quality improvements, it may not be far-fetched to suggest that AMD may have another surprise announcement in store.\n\nAMD's fierce rival, Nvidia, has DLSS 4 available for all RTX GPUs; not only does it have the advantage of being widely available to more PC gamers, but the image quality is superior to FSR 4's, and there's nothing better than AMD's Redstone shortening the gap to Team Green's offering, while also allowing all (or at least most) Radeon GPU users to benefit from sharper images in games.\n\nAnalysis: FSR 4 on RDNA 3 and older GPUs should be AMD's number one priority\n\n(Image credit: AMD)\n\nWithout a doubt, Nvidia is still leading the GPU market. That's unsurprising, especially since the RTX 5000 series GPUs are gradually plummeting back to their launch prices – and Team Green is rumored to be launching Super series GPUs this fall.\n\nWith this in mind, it's time for AMD to at least provide its latest upscaling tech to RDNA 3 GPUs before Nvidia bridges the gap further.\n\nGet daily insight, inspiration and deals in your inbox Sign up for breaking news, reviews, opinion, top tech deals, and more. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAgain, Nvidia already has DLSS 4 available on all RTX GPUs, except for Multi Frame Generation (exclusive to RTX 5000 series) and Frame Generation (starting from RTX 4000 series). DLSS 4 has shown how vital it is for upscaling tech to have sharper super-resolution image quality, and it shines bright even in DLSS performance, which benefits PC gamers with low-end hardware.\n\nTeam Red's FSR 4 has a similar effect with better image quality across its upscaling modes, and while it certainly doesn't match up to DLSS 4, it beats both FSR 3 and DLSS 3. As a handheld PC gamer, FSR 4 would do wonders at providing better performance via aggressive upscaling, without too much of a heavy sacrifice on image quality, like FSR 3 has.\n\nIt's the ideal time for AMD to get this going, as it would add to the firepower it needs to fully compete with its GPU rival.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/computing/gpu/amds-fsr-4-upscaling-tech-gives-even-more-pc-games-a-free-image-quality-upgrade-but-you-still-need-a-modern-gpu",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Qualcomm Snapdragon X Elite Linux Performance Improving But Short Of AMD Ryzen & Intel Core Ultra",
      "content": "Back in May we provided an initial look at the Qualcomm Snapdragon X Elite laptop performance on Ubuntu Linux with the upstream support for the Qualcomm Snapdragon X1E maturing, more laptops becoming supported, and the Ubuntu X1E \"Concept\" ISOs enhancing the end-user experience. The performance was okay but short of expectations. Months later we are revisiting the Qualcomm Snapdragon X Elite Linux performance on the newest Ubuntu Concept ISOs and newer firmware that is providing a much better experience albeit still not as competitive as the newest AMD Ryzen AI 300 series and Intel Core Ultra laptops under Linux.\n\nSince the May testing, the Qualcomm Snapdragon X Elite Linux testing was experiencing a hiatus... Newer Ubuntu X1E Concept ISOs were failing to properly work on the Acer Swift AI 14 laptop that I had purchased to carry out these Linux tests. Repeatedly the new refreshed media for several months failed to boot properly on the laptop due to Device Tree issues and/or other problems over time. Fortunately, the newest Ubuntu X1E Concept ISOs from late August fixed those problems. So I have been able to carry out clean, working installs of Ubuntu again on this Acer Swift 14 AI laptop powered by an X1 Elite SoC.\n\nThe \"plucky-desktop-arm64+x1e-20250827.iso\" as the newest as of testing now has everything in place so the laptop I have been using for testing works out. Though caveats still apply like you will want to keep around the Microsoft Windows 11 on ARM installation in order to run qcom-firmware-extract for extracting the necessary firmware from the Windows partitions. Most Snapdragon X laptops still do not have any firmware permitted for redistribution in upstream linux-firmware.git and thus the workaround of needing to fetch it from a Windows partition is needed for getting features like GPU acceleration and other functionality working.\n\nKeeping the Windows 11 installation is also important for easily applying system firmware updates to the device itself. While working through these Ubuntu Linux woes on the Acer Swift 14 AI, a system firmware update came down and was applied that ended up being very important for multi-core performance as I'll be showing in this article.\n\nIt's far from a pleasant out-of-the-box experience but at least an easier route than the likes of Apple Silicon on Linux.\n\nFor today's benchmarking is a look at how the Qualcomm Snapdragon X Elite performance has evolved since the tests earlier this year and then followed by a comparison of the Acer Swift 14 AI up against an assortment of other Intel Core and AMD Ryzen laptops tested over the summer, all on Ubuntu 25.04 and tested within the Phoronix lab.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/review/snapdragon-x1e-september",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "What I learned while optimizing my RAM timings for better PC performance",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/improve-your-ram-timings/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The XFX Radeon RX 7900 XT Graphics Card Drops to $630: This Is the Least Expensive 4K-Capable GPU",
      "content": "If you've just upgraded to a new 4K gaming monitor and now you're looking for a reasonably priced GPU that can comfortably run games off it, then check out this deal. Amazon is offering the XFX AMD Radeon RX 7900 XT 20GB graphics card for just $630.63. This is the lowest price I've ever seen for an RX 7900 XT GPU, and that's saying something because nearly all video cards nowadays are higher than their original launch price. The RX 7900 XT is a generation old, but it's still an excellent 4K GPU that approaches the performance of the GeForce RTX 5070 Ti and Radeon 9070 XT.\n\nThe Radeon RX 7900 XT was released back in 2022, but its still a relevant card today, able to play pretty much any game at 4K with consistent framerates of 60fps and beyond. Compared to current generation cards, it's roughly 5%-10% behind the Nvidia GeForce RTX 5070 Ti and and the AMD Radeon 9070 XT in 4K rasterized (non ray-traced) performance. It's also 10%-20% less expensive, making it a very attractive alternative for those of you who are on a budget. The RX 7900 XT also comes equipped with 20GB VRAM, which is more than the 5070 T iand 9070 XT, which come with 16GB. The extra VRAM allows it to scale well in high-resolution gaming and it's also a good card for AI use.\n\nIf You Need Ray Tracing, Stick with NVIDIA\n\nAMD Radeon cards are outstanding alternatives to the NVIDIA GeForce cards. For gamers who want to maximize their performance for their dollar, AMD GPUs are the way to go. However, if you're set on playing 4K games with ray tracing enabled, then you'll want to stick with NVIDIA. That's because the GeForce cards perform better than their Radeon counterparts when it comes to ray tracing. Ray tracing is a form of rendering that allows for more realstic lighting effects. It makes light sources and shadows look better, but at the steep cost of GPU resources.\n\nWhy Should You Trust IGN's Deals Team? IGN's deals team has a combined 30+ years of experience finding the best discounts in gaming, tech, and just about every other category. We don't try to trick our readers into buying things they don't need at prices that aren't worth buying something at. Our ultimate goal is to surface the best possible deals from brands we trust and our editorial team has personal experience with. You can check out our deals standards here for more information on our process, or keep up with the latest deals we find on IGN's Deals account on Twitter.\n\nEric Song is the IGN commerce manager in charge of finding the best gaming and tech deals every day. When Eric isn't hunting for deals for other people at work, he's hunting for deals for himself during his free time.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/xfx-radeon-rx-7900-xt-graphics-card-deal-best-4k-gpu-under-650",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "ACEMAGIC Kron Mini K1 review – Quite a capable mini PC",
      "content": "MetryGrow 48W LED Plant Grow Light review – makes sure your indoor plants get what they need",
      "source": "The Gadgeteer",
      "url": "https://the-gadgeteer.com/2025/09/09/acemagic-kron-mini-k1-review-quite-a-capable-mini-pc/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "This budget-friendly Ryzen mini PC with 16GB RAM is an extra 29% off",
      "content": "Finding the best computer for your office isn’t always easy, and who wants to waste precious hours (or days) researching a bunch of models to find the ones that tick the right boxes at the right budgets? You might just be better off snagging this Bosgame E2 mini PC, which is a great daily driver PC for home offices that balances performance with price.\n\nRight now, the Bosgame E2 is only $169.99 on Amazon (was $239.99), a significant 29% discount that brings it down to almost impulse-buy levels of affordability. Is it going to be a blazing-fast machine that blows you away? Of course not. But similar machines usually cost double, so if you’re hunting for a solid deal, this is one worth jumping on.\n\nThe Bosgame E2 mini PC comes with an AMD Ryzen 5 3550H processor, which may be a few years old but is still perfectly capable of handling modern apps and day-to-day tasks. It also comes with 16GB of RAM and a 512GB SSD, which is adequate for running Windows 11 without slowing to an unbearable crawl. It even has some room for growth, with user-upgradeable memory (up to 32GB) and storage (up to 4TB).\n\nOne of the best things about this mini PC for productivity is that it supports triple 4K@60Hz monitors thanks to its dual HDMI ports plus USB-C video port. You also get three fast USB-A for data, a slower USB-A for peripherals, a 3.5mm audio jack, and a Gigabit Ethernet port. The cherry on top? It comes with a VESA plate so you can mount it to the back of any VESA-compatible monitor so it’s out of sight.\n\nThis is a super bargain for anyone who needs a decent home PC at a bottom-barrel price. Get the Bosgame E2 for just $169.99 while you can because this limited-time deal won’t last forever!\n\nSnag this budget-friendly Ryzen 5 mini PC with 16GB RAM for 29% off",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2902891/this-budget-friendly-ryzen-5-mini-pc-with-16gb-ram-is-an-extra-29-percent-off.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Legion Go 2’s pricing draws backlash, and Lenovo’s response falls flat",
      "content": "The Steam Deck starts at $400. That’s one of its most appealing aspects, even years after it launched. The new Lenovo Legion Go 2 starts at $1,050, and it goes up to $1,350 if you really want to max its specs. Perhaps that’s an unfair comparison, but it’s one that plenty of fans are making anyway… and Lenovo’s response to them isn’t helping.\n\n\n\nIn a recent interview at IFA 2025, PC Watch of Japan (via Windows Central) asked Lenovo executives about the high pricing. It starts at €1,000, “which is close to the price of a laptop,” according to a Google translation.\n\n“The Legion Go 2 is expensive because of the high-performance processor, OLED display, detachable controllers, and ergonomic design that make it so powerful,” replied a representative. “Therefore, the Legion Go 2 targets enthusiast gamers who are willing to invest in their hobbies. They value customizing their own hardware and building their own setups, and they choose such hardware even if it is expensive.”\n\nThe representative offered up the Legion Go S as “a more affordable option.” That’s a handheld that starts at $600 for the SteamOS version and goes up to $830 for the most powerful hardware. “Affordable” is pulling a lot of weight here, in a form factor that’s still fairly limited even compared to a desktop PC at the same price.\n\nDirect sales comparisons are hard to make, considering the paucity of data available. But it seems like the Steam Deck is still outselling its newer competition by a large factor, even given its three-year-old hardware. SteamOS—which is better than Windows 11 for gaming in almost every way—is certainly part of that success.\n\nBut I can’t help but notice that you can get a top-of-the-line Steam Deck OLED for just a little more than Lenovo’s “more affordable option.” It doesn’t help that in the US, consumers will be paying for the current administration’s import taxes on basically everything, too.\n\nLenovo seems to be betting that gamers love the handheld PC form factor so much that they’re willing to pay double or even triple for hardware that’s more powerful and flexible. I’m sure some are, but when I look at those price tags, I just see diminishing returns. A Legion Go 2 with an AMD Z2 Extreme processor and 64GB of shared memory can do more than a base model Steam Deck… But three times more? Nah.\n\nPerhaps a revitalized Windows 11—with a refreshed interface that’s set to debut on the Asus ROG Xbox Ally—could shake up this equation. (Asus is still afraid to put a price on that device and we only have a month until its planned release.) But even if it does, it won’t be until sometime next year that the new UI comes to other devices like the Legion Go 2. Even if I were tempted to buy a handheld PC with a four-figure price tag, I’d want to wait until that option became available.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2903198/legion-go-2s-pricing-draws-backlash-and-lenovos-response-falls-flat.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "XFX says its 'V3' Radeon RX 9060 XT GPUs with Samsung GDDR6 run much cooler and quieter than previous models with SK Hynix memory",
      "content": "Having the most powerful and fastest hardware is often the goal of many PC builders, so we are often left comparing things on pure benchmarking and performance. So when AMD swapped from using SK Hynix to Samsung GDDR6 memory in its new Radeon RX 9060 XT GPUs, gamers were quick to jump to performance comparisons between them.\n\nWhat they found was a drop when moving over to the new Samsung memory, and gamers were quick to condemn the change. Like our reviewer of the RX 9060 XT XFX Swift GPU, many have been pleased by the performance from the budget friendly offering. It seems it might have been a bit too quick, as new comparisons spotted by VideoCardz are showing ways the Samsung GDDR6 may actually be more beneficial, if a little less powerful than the SK Hynix offering.\n\nAMD partner XFX posted comparisons to Bilibili, a Chinese social blog site that often delves into PC gaming hardware critique. They tell the same story of less powerful GDDR6, but with a huge boon to cooling and potentially power consumption.\n\nAccording to these tests the Samsung memory garnered temperatures 10°C lower than its SK Hynix counterpart, allowing for an almost 400 rpm drop in fan speeds. This means the Samsung components are significantly cooler than the previous ones, and as an added bonus they're quieter and less demanding on your fans, too. This is on top of a 20 W lower power draw over the SK Hynix memory.\n\nThis drop may not seem like a big deal, especially for those who like to go all in on power for their rigs. But power isn't the whole story when it comes to building a capable gaming machine, you still have to be able to power and run it, and temperatures can be a huge mitigating factor.\n\nKeeping things cool is an integral part of any good rig, and it's not always easy especially in warmer climates. As an Australian I've run into difficulties keeping rigs cool enough to function over hot summers and have often had to forgo power for lower temperatures. Choosing parts that can help you maintain lower temperatures even if it's at the cost of some beef is often a really smart move in building a gaming PC.\n\nSK Hynix and Samsung are some of the biggest players investing billions in developing memory, not only for GPUs but also AI computing. Both have also been hit with reversals against using US tech in their China-based facilities. With a seemingly even playing field, seeing such a huge difference in these results is a little surprising.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThese results are almost certainly biased, but this could mean the revised 9060's are a better choice for many looking to upgrade. According to XFX the Samsung GDDR6 units can be identified by a \"V3\" moniker and are already available in China. It'll be interesting to see what further testing shows when it comes to the difference between these GPU variants.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/graphics-cards/xfx-says-its-v3-radeon-rx-9060-xt-gpus-with-samsung-gddr6-run-much-cooler-and-quieter-than-previous-models-with-sk-hynix-memory/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Chip, cloud, and AI firms unite to break Nvidia's stranglehold",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250909PD224/amd-nvidia-cloud-ai-launch-openai.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD Claims Arm ISA Doesn’t Offer Efficiency Advantage Over x86",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/amd-claims-arm-isa-doesnt-offer-efficiency-advantage-over-x86/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The UAE Showcases Its Abilities In AI Reasoning With K2 Think Model",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/patrickmoorhead/2025/09/09/the-uae-showcases-its-abilities-in-ai-reasoning-with-k2-think-model/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 \"Battlemage\" Nears Launch as Intel Prepares Packaging",
      "content": "Intel plans to complete its Arc \"Battlemage\" lineup with the highest-performing B770 SKU. Thanks to @Haze2K1 on X, we found shipping manifests dated June 11, 2025, which list BMG-G31 GPU dies packed in boxes with dimensions matching those used before the Arc B580 launch. Last time with B580, the launch happened 2.5 months after these shipping manifests appeared. The current rumor mill suggests that the card will utilize 32 Xe2 cores with 16 GB of memory on a 256-bit bus, providing it with a clear capacity edge over many 8 GB rivals from AMD and NVIDIA, like the RTX 5060 Ti and RX 9060. The BMG-G31 die is bigger than the BMG-G21 used in the B580, B570, and Arc Pro parts, which explains the larger crates. Extra silicon could enable higher clocks, stronger ray tracing, and a wider memory interface, though thermal management and power draw will matter. Early samples and firmware checks will set the final timing and availability soon.Timing will determine how much impact the Arc B770 can have, because AMD and NVIDIA already control much of the upper mid-range and high-end segments. NVIDIA \"SUPER\" refreshes of the current \"Blackwell\" only raise the pressure on Intel to be both performance competitive and well priced. Battlemage has already shifted pricing expectations in the market before, compelling rivals to rethink memory configurations and price points. Intel has also shown steady improvement in its driver updates and software support, which has narrowed historical gaps in user experience. Rumors pointing to a Q4 2025 debut would put the card into the usual holiday buying window, but to convert gamer's interest into real market share, Intel will need an aggressive pricing strategy and solid supply.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340802/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Former MS engineer Dave Plummer admits he accidentally coded Pinball to run 'at like, 5,000 frames per second' on Windows NT",
      "content": "I'm not sure why I played so much Pinball on my Windows machine as a child. Nor am I sure why it was given so many different names, like Space Cadet 3D Pinball, 3D Pinball for Windows, Microsoft 3D Pinball, etc. What I do know, however, is it ran great on my old Windows NT 4.0 beige box, and now I've learned exactly why—the engineer who ported it over accidentally built a surprisingly resource-heavy game engine around it.\n\nEnter Dave Plummer, an ex-Microsoft engineer whose other Windows contributions include Task Manager, native Zip file support, and Media Center, to name just a few (via The Register). Speaking on his YouTube channel, Dave's Attic, Plummer revealed that when he ported the game to Windows NT from Windows 95, he wrote a whole new game engine around the original logic in order to handle the video rendering and sound.\n\n\"My game engine had a bug, in that it would draw frames as fast as it could\" said Plummer. At the time, the game was being coded on a MIPS R4000 processor running at a mighty 200 MHz, which resulted in the game running at 60-90 fps, a speed Plummer judged as \"plenty, for a game like that.\"\n\n\"Fast forward a couple of years later, somebody notices that on multi-core machines, it's using an entire core to play Pinball at all times,\" he laughs. \"It was still drawing as fast as it could, but it was now drawing at like, 5,000 frames per second, because machines were much much faster than they used to be.\"\n\nThe bug was fixed by another ex-Microsoft engineer, Raymond Chen. Speaking on Plummer's other YouTube channel, Dave's Garage, Chen fondly remembers adding a frame rate limiter, thereby reigning the game in to a 100 fps maximum. \"My proudest moment in Windows development,\" Chen says, \"was I fixed Pinball so you could kick off a build and play Pinball at the same time.\"\n\n(Image credit: Microsoft)\n\nPlummer categorises the mistake as the worst Windows bug he ever shipped, and although he laughs about it now, it seems Microsoft culture at the time was particularly adverse to brushing off mistakes: \"If you had a bug that actually made it into the product and required work in a Service Pack, that was never a laughing matter. That was kind of a shameful thing.\"\n\nStill, no real harm done. I'd imagine the rise of multi-core processors required all kinds of fixes to integrate within existing codebases successfully, and it certainly seems like Plummer and his ex-colleagues remember the bug fondly.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAnd it must be said, part of me wants to run that early build on a modern multi-core monster like the AMD Ryzen 9 9950X3D, given that NT seems to play remarkably well with modern hardware. I'd like to imagine that the frame rate would break world records, although I've got a funny feeling I'd get that iconic Windows NT 4.0 error sound instead. Ah, the error messages of my youth. Perhaps it's time to boot Pinball up once more for a game or three.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/software/windows/former-ms-engineer-dave-plummer-admits-he-accidentally-coded-pinball-to-run-at-like-5-000-frames-per-second-on-windows-nt/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Byte Type: Supporting Raw Data Copies in the LLVM IR",
      "content": "GSoC 2025 - Byte Type: Supporting Raw Data Copies in the LLVM IR\n\nBy Pedro Lobo\n\n\n\n#GSoC , #clang , #optimizations , #IR\n\n22 minute read\n\nThis summer I participated in GSoC under the LLVM Compiler Infrastructure. The goal of the project was to add a new byte type to the LLVM IR, capable of representing raw memory values. This new addition enables the native implementation of memory-related intrinsics in the IR, including memcpy , memmove and memcmp , fixes existing unsound transformations and enables new optimizations, all with a minimal performance impact.\n\nBackground\n\nOne of LLVM’s longstanding problems is the absence of a type capable of representing raw memory values. Currently, memory loads of raw bytes are performed through an appropriately sized integer type. However, integers are incapable of representing an arbitrary memory value. Firstly, they do not retain pointer provenance information, rendering them unable to fully specify the value of a pointer. Secondly, loading memory values containing poison bits through an integer type taints the loaded value, as integer values are either poison or have a fully-defined value, with no way to represent individual poison bits.\n\nSource languages such as C and C++ provide proper types to inspect and manipulate raw memory. These include char , signed char and unsigned char . C++17 introduced the std::byte type, which offers similar raw memory access capabilities, but does not support arithmetic operations. Currently, Clang lowers these types to the i8 integer type, which does not accurately model their raw memory access semantics, motivating miscompilations such as the one reported in bug report 37469.\n\nThe absence of a similar type in the LLVM IR hinders the implementation of memory-related intrinsics such as memcpy , memmove and memcmp , and introduces additional friction when loading and converting memory values to other types, leading to implicit conversions that are hard to identify and reason about. The two core problems stemming from the absence of a proper type to access and manipulate raw memory, directly addressed by the byte type and explored throughout the remainder of this section, are summarized as follows:\n\nIntegers do not track provenance, rendering them incapable of representing a pointer. Loads through integer types spread poison values, which taints the load result if the loaded values contain at least one poison bit (as occurs with padded values).\n\nPointer Provenance\n\nAccording to the LLVM Language Reference, pointers track provenance, which is the ability to perform memory accesses through the pointer, in the sense of the pointer aliasing rules. The main goal of tracking pointer provenance is to simplify alias analysis, yielding more precise results, which enables high-level optimizations.\n\nIntegers, unlike pointers, do not capture provenance information, being solely characterized by their numerical value. Therefore, loading a pointer through an integer type discards the pointer’s provenance. This is problematic as such loads can cause pointer escapes that go unnoticed by alias analysis. Once alias analysis is compromised, simple optimizations that rely on the absence of aliasing become invalid, compromising the correctness of the whole compilation process.\n\nCurrently, Alive2 defines the result of loading a pointer value through an integer type as poison . This implies that loads through integer types fail to accurately recreate the original memory value, hindering pointer copies via integer types. In the following example, storing a pointer to memory and loading it through the i64 type yields poison , invalidating the transformation.\n\ndefine ptr @src( ptr %ptr, ptr %v) { store ptr %v, ptr %ptr %l = load ptr , ptr %ptr ret ptr %l } define ptr @tgt( ptr %ptr, ptr %v) { store ptr %v, ptr %ptr %l = load i64 , ptr %ptr ; poison %c = inttoptr i64 %l to ptr ; poison ret ptr %c ; poison }\n\nUndefined Behavior\n\nLLVM’s poison value is used to represent unspecified values, such as padding bits. Loading such memory values through an integer type propagates poison values, as integer types are either poison or have a fully-defined value, not providing enough granularity to represent individual poison bits. This hinders the copy of padded values.\n\nMoreover, this lack of granularity can lead to subtle issues that are often overlooked. The LLVM Language Reference defines the bitcast instruction as a no-op cast because no bits change with this conversion. Nonetheless, while scalar types are either poison or have a fully-defined value, vector types in LLVM track poison values on a per-lane basis. This introduces potential pitfalls when casting vector types to non-vector types, as the cast operation can inadvertently taint non- poison lanes. In the following example, considering the first lane of %v to be poison , the result of casting the vector to an i64 value is poison , regardless of the value of the second lane.\n\ndefine i64 @ub( ptr %ptr) { %v = load < 2 x i32 >, ptr %ptr ; <i32 poison, i32 42> %c = bitcast < 2 x i32 > %v to i64 ; i64 poison ret i64 %c }\n\nAlthough covered by the Language Reference (\"the [bitcast] conversion is done as if the value had been stored to memory and read back as [the destination type]\"), this duality in the value representation between vector and scalar types integer constitutes a corner case that is not widely contemplated and often unnecessarily introduces undefined behavior.\n\nImplementing the Byte Type\n\nBack in 2021, a GSoC project with a similar goal, produced a working prototype of the byte type. This prototype introduced the byte type to the IR, lowered C and C++’s raw memory access types to the byte type and implemented some optimizations over the new type.\n\nThe current project began by porting these patches to the latest version of LLVM, adapting the code to support the newly introduced opaque pointers. As the work progressed and new challenges emerged, the original proposal was iteratively refined. The implementation of the byte type in LLVM and Alive2 can be found here and here, respectively.\n\nByte Type\n\nThe byte type is a first-class single-value type, with the same size and alignment as the equivalently sized integer type. Memory loads through the byte type yield the value’s raw representation, without introducing any implicit casts. This allows the byte type to represent both pointer and non-pointer values.\n\nAdditionally, the byte type is equipped with the necessary granularity to represent poison values at the bit-level, such that loads of padded values through the byte type do not taint the loaded value. As a consequence, a bitcast between vector and scalar byte types preserves the raw byte value. In the following example, a poison lane does not taint the cast result, unlike with equivalently sized integer types.\n\ndefine b 64 @f( ptr %ptr) { %v = load < 2 x b 32 >, ptr %ptr %c = bitcast < 2 x b 32 > %v to b 64 ret b 64 %c }\n\nThese two properties of the byte type directly addressed the aforementioned problems, enabling the implementation of a user-defined memcpy in the IR, as shown in the following example. In a similar manner, a native implementation of memmove can be achieved.\n\ndefine ptr @my_memcpy( ptr %dst, ptr %src, i64 %n) { entry: br label %for.cond for.cond: %i = phi i64 [ 0 , %entry ], [ %inc, %for.body ] %cmp = icmp ult i64 %i, %n br i1 %cmp, label %for.body, label %for.end for.body: %arrayidx = getelementptr inbounds b 8 , ptr %src, i64 %i %byte = load b 8 , ptr %arrayidx %arrayidx1 = getelementptr inbounds b 8 , ptr %dst, i64 %i store b 8 %byte, ptr %arrayidx1 %inc = add i64 %i, 1 br label %for.cond for.end: ret ptr %dst }\n\nThe newly implemented type also fixes existing optimizations. Previously, InstCombine lowered small calls to memcpy and memmove into integer load/store pairs. Due to the aforementioned reasons, this lowering is unsound. By using byte load/store pairs instead, the transformation, as shown in the following example, is now valid.\n\ndefine void @my_memcpy( ptr %dst, ptr %src) { call void @llvm.memcpy( ptr %dst, ptr %src, i64 8 ) ret void } define void @my_memmove( ptr %dst, ptr %src) { call void @llvm.memmove( ptr %dst, ptr %src, i64 8 ) ret void } define void @my_memcpy( ptr %dst, ptr %src) { %l = load b 64 , ptr %src store b 64 %l, ptr %dst ret void } define void @my_memmove( ptr %d, ptr %s) { %l = load b 64 , ptr %s store b 64 %l, ptr %d ret void }\n\nSROA performs a similar transformation, lowering memcpy calls to integer load/store pairs. Similarly, this optimization pass was changed to use byte load/store pairs, as depicted in the following example.\n\ndefine void @src( ptr %a, ptr %b) { %mem = alloca i8 call void @llvm.memcpy( ptr %mem, ptr %a, i32 1 ) call void @llvm.memcpy( ptr %a, ptr %mem, i32 1 ) ret void } define void @tgt( ptr %a, ptr %b) { %mem.copyload = load b 8 , ptr %a store b 8 %mem.copyload, ptr %a ret void }\n\nBytecast Instruction\n\nByte values can be reinterpreted as values of other primitive types. This is achieved through the bytecast instruction. This cast instruction comes in two flavors, either allowing or disallowing type punning. Considering that a byte might hold a pointer or a non-pointer value, the bytecast follows the following semantics:\n\nA vanilla bytecast , distinguished by the absence of the exact flag, is used to cast a byte to any other primitive type, allowing type punning. More precisely, If the type of the value held by the byte matches the destination type of the cast, it is a no-op. Otherwise, the cast operand undergoes a conversion to the destination type, converting pointers to non-pointer values and vice-versa, respectively wrapping a ptrtoint or inttoptr cast.\n\nA bytecast with the exact flag succeeds if both the type of the value held by the byte and the destination type are either both pointer or non-pointer types. More specifically, If the type of the value held by the byte matches the destination type of the cast, it is a no-op. Otherwise, the result is poison , preventing type punning between pointer and non-pointer values.\n\n\n\nThe exact version of the bytecast mimics the reinterpretation of a value, as if it had been stored in memory and loaded back through the cast destination type. This is aligned with the semantics adopted by the bitcast instruction, which “is done as if the value had been stored to memory and read back as [the destination type]”\", enabling store-to-load forwarding optimizations, such as the one depicted in the next example.\n\ndefine i8 @src( b 8 %x) { %a = alloca b 8 store b 8 %x, ptr %a %v = load i8 , ptr %a ret i8 %v } define i8 @tgt( b 8 %x) { %cast = bytecast exact b 8 %x to i8 ret i8 %cast }\n\nMemcmp Lowering\n\nThe standard version of the bytecast enables the implementation of memcmp in the IR. Currently, calls to memcmp of small sizes are lowered to integer loads, followed by a subtraction, comparing the two loaded values. Due to the aforementioned problems, this lowering is unsound. Loading the two memory values as bytes is insufficient as comparisons between bytes are undefined, as to avoid overloading the IR by supporting comparisons between pointers and provenance-unaware values. To that end, the version of the bytecast which performs type punning is used, forcefully converting possible pointer values into their integer representation. The two values, then converted to integers, can be compared as before. The following example depicts the previous and new lowerings of a memcmp of 1 byte.\n\ndefine i32 @before( ptr %p, ptr %q) { %lhsc = load i8 , ptr %p %lhsv = zext i8 %lhsc to i32 %rhsc = load i8 , ptr %q %rhsv = zext i8 %rhsc to i32 %chardiff = sub i32 %lhsv, %rhsv ret i32 %chardiff } define i32 @after( ptr %p, ptr %q) { %lhsb = load b 8 , ptr %p %lhsc = bytecast b 8 %lhsb to i8 %lhsv = zext i8 %lhsc to i32 %rhsb = load b 8 , ptr %q %rhsc = bytecast b 8 %rhsb to i8 %rhsv = zext i8 %rhsc to i32 %chardiff = sub i32 %lhsv, %rhsv ret i32 %chardiff }\n\nLoad Widening\n\nA common optimization performed by LLVM is to widen memory loads when lowering calls to memcmp . The previously proposed lowering falls short in the presence of such optimizations. Whilst using a larger byte type to load the memory value preserves its raw value, the bytecast to an integer type yields poison if any of the loaded bits are poison . This is problematic as the remaining bits added by the widened load could assume any value or even be uninitialized. As such, when performing load widening, the following lowering, depicted in the next example, is performed. The !uninit_is_nondet , proposed in the RFC proposing uninitialized memory loads to return poison , converts any poison bits to a non-deterministic value, preventing the bytecast to an integer type from yielding poison .\n\ndefine i32 @src( ptr %x, ptr %y) { %call = tail call i32 @memcmp( ptr %x, ptr %y, i64 2 ) ret i32 %call } define i32 @tgt( ptr %x, ptr %y) { %1 = load b 16 , ptr %x, !uninit_is_nondet %2 = load b 16 , ptr %y, !uninit_is_nondet %3 = bytecast b 16 %1 to i16 %4 = bytecast b 16 %2 to i16 %5 = call i16 @llvm.bswap.i16( i16 %3) %6 = call i16 @llvm.bswap.i16( i16 %4) %7 = zext i16 %5 to i32 %8 = zext i16 %6 to i32 %9 = sub i32 %7, %8 ret i32 %9 }\n\nCasts, Bitwise and Arithmetic Operations\n\nValues of other primitive types can be cast to the byte type using the bitcast instruction, as shown in the following example.\n\n%1 = bitcast i8 %val to b 8 %2 = bitcast i64 %val to b 64 %3 = bitcast ptr to b 64 ; assuming pointers to be 64 bits wide %4 = bitcast < 8 x i8 > to < 8 x b 8 >\n\nFurthermore, bytes can also be truncated, enabling store-to-load forwarding optimizations, such as the one presented in the next example. Performing an exact bytecast to i32 , followed by a trunc to i8 and a bitcast to b8 would be unsound, as if any of the unobserved bits of the byte value were poison , the bytecast would yield poison , invalidating the transformation.\n\ndefine b 8 @src( b 32 %x) { %a = alloca b 32 store b 32 %x, ptr %a %v = load b 8 , ptr %a ret b 8 %v } define b 8 @tgt( b 32 %x) { %trunc = trunc b 32 %x to b 8 ret b 8 %trunc }\n\nDue to the cumbersome semantics of performing arithmetic on provenance-aware values, arithmetic operations on the byte type are disallowed. Bitwise binary operations are also disallowed, with the exception of logical shift right. This instruction enables store-to-load forwarding optimization with offsets, such as the one performed in the following example. To rule out sub-byte accesses, its use is restricted to shift amounts that are multiples of 8.\n\ndefine i8 @src( b 32 %x) { %a = alloca b 32 %gep = getelementptr i8 , ptr %a, i64 2 store b 32 %x, ptr %a %v = load i8 , ptr %gep ret i8 %v } define i8 @tgt( b 32 %x) { %shift = lshr b 32 %x, 16 %trunc = trunc b 32 %shift to b 8 %cast = bytecast exact b 8 to i8 ret i8 %cast }\n\nValue Coercion Optimizations\n\nSome optimization passes perform transformations that are unsound under the premise that type punning is disallowed. Such an optimization pass is GVN, which performs value coercion in order to eliminate redundant loads. Currently, a class of optimization where a pointer load is coerced to a non-pointer value or a non-pointer load is coerced to a pointer value is reported as unsound by Alive2.\n\nThe following example illustrates one such optimization, in which GVN replaces the pointer load at %v3 by a phi node, merging the pointer load at %v2 with the coerced value at %1 , resulting from an inttoptr cast. If the value stored in memory is a pointer, the source function returns the pointer value, while, in the target function, the load at %v1 returns poison .\n\ndeclare void @use(...) readonly define ptr @src( ptr %p, i1 %cond) { br i1 %cond, label %bb1, label %bb2 bb1: %v1 = load i64 , ptr %p call void @use( i64 %v1) %1 = inttoptr i64 %v1 to ptr br label %merge bb2: %v2 = load ptr , ptr %p call void @use( ptr %v2) br label %merge merge: %v3 = load ptr , ptr %p ret ptr %v3 } define ptr @tgt( ptr %p, i1 %cond) { br i1 %cond, label %bb1, label %bb2 bb1: %v1 = load i64 , ptr %p call void @use( i64 %v1) %1 = inttoptr i64 %v1 to ptr br label %merge bb2: %v2 = load ptr , ptr %p call void @use( ptr %v2) br label %merge merge: %v3 = phi ptr [ %v2, %bb2 ], [ %1, %bb1 ] ret ptr %v3 }\n\nThe byte type can be leveraged to avoid the implicit type punning that hinders this kind of optimizations, as depicted in the following example. Since the byte type can represent both pointer and non-pointer values, the loads at %v1 and %v2 can instead be performed using the byte type. The bytecast instruction is then used to convert the byte into the desired type. As the load through the byte type accurately models the loaded value, avoiding implicit casts, the bytecast , yields the pointer stored in memory. This value can then be used to replace the load at %v3 .\n\ndeclare void @use(...) readonly define ptr @src( ptr %p, i1 %cond) { br i1 %cond, label %bb1, label %bb2 bb1: %v1 = load i64 , ptr %p call void @use( i64 %v1) %1 = inttoptr i64 %v1 to ptr br label %merge bb2: %v2 = load ptr , ptr %p call void @use( ptr %v2) br label %merge merge: %v3 = load ptr , ptr %p ret ptr %v3 } define ptr @tgt( ptr %p, i1 %cond) { %load = load b 64 , ptr %p br i1 %cond, label %bb1, label %bb2 bb1: %v1 = bytecast exact b 64 %load to i64 call void @use( i64 %v1) %1 = bytecast exact b 64 %load to ptr br label %merge bb2: %v2 = bytecast exact b 64 %load to ptr call void @use( ptr %v2) br label %merge merge: %v3 = phi ptr [ %v2, %bb2 ], [ %1, %bb1 ] ret ptr %v3 }\n\nOther Optimizations\n\nAdditional optimizations were also implemented. While these do not affect program correctness, they do contribute to performance improvements. Some of them include cast pair eliminations and combining of load and bytecast pairs with a single use, depicted in the following examples.\n\ndefine b 32 @src_float( b 32 %b) { %1 = bytecast exact b 32 %b to float %2 = bitcast float %1 to b 32 ret b 32 %2 } define i8 @src_int( i8 %i) { %b = bitcast i8 %i to b 8 %c = bytecast exact b 8 %1 to i8 ret i8 %c } define b 32 @tgt_float( b 32 %b) { ret b 32 %b } define i8 @tgt_int( i8 %i) { ret i8 %i }\n\ndefine i8 @src( ptr %p) { %b = load b 8 , ptr %p %c = bytecast exact b 8 %b to i8 ret i8 %c } define i8 @tgt( ptr %p) { %i = load i8 , ptr %p ret i8 %i }\n\nClang\n\nGiven the raw memory access capabilities of the byte type, Clang was altered to lower C and C++’s raw memory access types were lowered to the byte type. These include char , signed char , unsigned char and std::byte . The new lowerings are depicted in the next example.\n\nvoid foo ( unsigned char arg1, char arg2, signed char arg3, std :: byte arg4 );\n\nvoid @foo( b 8 zeroext %arg1, b 8 signext %arg2, b 8 signext %arg3, b 8 zeroext %arg4 ) ;\n\nAdditionally, code generation was updated to insert missing bytecast instructions where integer values were previously expected, such as in arithmetic and comparison operations involving character types. The next example depicts an example function in C, adding two char values, and the corresponding lowering to LLVM IR as performed by Clang.\n\nchar sum ( char a, char b) { return a + b; }\n\ndefine b 8 @sum( b 8 %a, b 8 %b) { %conv = bytecast exact b 8 %a to i8 %conv1 = sext i8 %conv to i32 %conv2 = bytecast exact b 8 %b to i8 %conv3 = sext i8 %conv2 to i32 %add = add nsw i32 %conv1, %conv3 %conv4 = trunc i32 %add to i8 %res = bitcast i8 %conv4 to b 8 ret b 8 %res }\n\nSummary\n\nIn summary, the byte type contributes with the following changes/additions to the IR:\n\nRaw memory representation: Optimization passes can use the byte type to represent raw memory values, avoiding the introduction of implicit casts and treating both pointer and non-pointer values uniformly.\n\nBit-level poison representation: The byte type provides the necessary granularity to represent individual poison bits, providing greater flexibility than integer types, which either have a fully-defined value or are tainted by poison bits.\n\nbitcast instruction: This instruction allows conversions from other primitive types to equivalently-sized byte types. Casts between vector and scalar byte types do not taint the cast result in the presence of poison lanes, as occurs with integer types.\n\nbytecast instruction: This instruction enables the conversion of byte values to other primitive types. The standard version of the cast performs type punning, reinterpreting pointers as integers and vice-versa. The exact flag disallows type punning by returning poison if the type of the value held by the byte does not match the cast destination type.\n\ntrunc and lshr instructions: The trunc and lshr instructions accept byte operands, behaving similarly to their integer counterparts. The latter only accepts shift amounts that are multiples of 8, ruling out sub-byte accesses.\n\nResults\n\nBenchmarks\n\nThe implementation was evaluated using the Phoronix Test Suite automated benchmarking tool, from which a set of 20 C/C++ applications, listed below, were selected.\n\nBenchmark Version LoC Description aircrack-ng 1.7 66,988 Tool suite to test WiFi/WLAN network security botan 2.17.3 147,832 C++ library for cryptographic operations compress-7zip 24.05 247,211 File archiving tool based on the 7-Zip format compress-pbzip2 1.1.13 10,187 Parallel implementation of bzip2 compress-zstd 1.5.4 90,489 Lossless compression tool using Zstandard draco 1.5.6 50,007 3D mesh and point cloud compressing library espeak 1.51 45,192 Compact open-source speech synthesizer ffmpeg 7.0 1,291,957 Audio and video processing framework fftw 3.3.10 264,128 Library for computing FFTs graphics-magick 1.3.43 267,450 Toolkit for image editing and conversion luajit 2.1-git 68,833 JIT-compiler of the Lua programming language ngspice 34 527,637 Open-source circuit simulator openssl 3.3 597,713 Implementation of SSL/TLS redis 7.0.4 178,014 In-memory data store rnnoise 0.2 146,693 Neural network for audio noise reduction scimark2 2.0 800 Scientific computing suite written in ANSI C sqlite-speedtest 3.30 250,607 Program for executing SQLite database tests stockfish 17 11,054 Advanced open-source chess engine tjbench 2.1.0 57,438 JPEG encoding and decoding tool z3 4.14.1 512,002 SMT solver and theorem prover\n\nAll programs were compiled with the -O3 pipeline on an AMD EPYC 9554P 64-Core CPU. In order to minimize result variance, turbo boost, hyperthreading, and ASLR were disabled, the performance governor was used, and core pinning was applied. The plots, depicted below, display the compile time, object size, peak memory usage (maximum redisent set size) and run-time performance differences between the implementation and upstream LLVM. The results reveal that the addition of the byte type had a minimal impact on all of the addressed performance metrics. Each result is averaged over three runs. The run-time results represent the average regression percentage across all tests of each benchmark.\n\n\n\n\n\nThe following plots show per-function assembly size distributions and differences, indicating that the addition of the byte type results in minor changes to the generated code, with the largest observed shift being approximately 5%. Each subplot includes the net byte size change and the percentage of functions with differing assembly, disregarding non-semantic differences such as varying jump and call target addresses.\n\n\n\n\n\n\n\nAlive2\n\nLLVM Test Suite\n\nThe byte type was implemented in Alive2, enabling the verification of both the reworked and newly added optimizations. Accessing both the correctness of the implementation and the broader impact of introducing the byte type into the IR, Alive2 was run over the LLVM test suite. Several previously unsound optimizations, which were addressed by the byte type, were identified in the tests listed below.\n\nTest Reason ExpandMemCmp/AArch64/memcmp.ll memcmp to integer load/store pairs ExpandMemCmp/X86/bcmp.ll bcmp to integer load/store pairs ExpandMemCmp/X86/memcmp-x32.ll memcmp to integer load/store pairs ExpandMemCmp/X86/memcmp.ll memcmp to integer load/store pairs GVN/metadata.ll Unsound pointer coercions GVN/pr24397.ll Unsound pointer coercions InstCombine/bcmp-1.ll bcmp to integer load/store pairs InstCombine/memcmp-1.ll memcmp to integer load/store pairs InstCombine/memcpy-to-load.ll memcpy to integer load/store pairs PhaseOrdering/swap-promotion.ll memcpy to integer load/store pairs SROA/alignment.ll memcpy to integer load/store pairs\n\nIt is worth noting that some additional tests containing unsound optimizations were addressed. However, Alive2 did not report them as unsound, due to the presence of unsupported features, such as multiple address spaces. Moreover, the ExpandMemCmp tests continue to be flagged as unsound by Alive2. This is because the required !uninit_is_nondet metadata has not yet been upstreamed and therefore remains absent in memcmp load widenings optimizations.\n\nSingle File Programs\n\nThe alivecc tool was used to verify the compilation of two single-file C programs, both compiled with the -O2 optimization level. The results are presented below.\n\nbzip2 : No differences were detected during verification.\n\n: No differences were detected during verification. sqlite3 : Two optimizations previously flagged as unsound by Alive2 were fixed. These occurred in the sqlite3WhereOkOnePass and dup8bytes functions. The reduced IR reveals that these were caused by lowerings of memcpy to integer load/store pairs.\n\nFuture Work\n\nAfter modifying Clang to lower the char , unsigned char and signed char types to the byte type, approximately 1800 Clang regression tests began failing. Over the course of the project, the number of failing tests was gradually reduced and, currently, around 100 regression tests are still failing. LLVM is a fast-moving codebase, and due to the sheer number of Clang tests affected by the introduction of the byte type, maintaining a clean test suite constitutes a continuous effort.\n\nThe benchmarks were run on an x86-64 system. However, LLVM also supports other popular architectures such as AArch64 and RISC-V, which may require additional performance evaluation.\n\nFurthermore, the patches do not include any additions to the Language Reference.\n\nConclusion\n\nThe addition of the byte type to the IR solves one of the long lasting problems in LLVM, with a minimal performance impact. Optimization passes can now safely represent and manipulate raw memory values, fixing existing optimizations, and setting up a solid foundation for new, previously inexpressible optimizations.\n\nParticipating in GSoC was both a great honor and a tremendous learning opportunity. Over the course of this project, I’ve learned a lot about compilers, optimizations and LLVM. It was also a valuable opportunity to get in touch with the LLVM community and contribute through the following pull requests:\n\nI would like to thank my mentor, Nuno Lopes, for his guidance and support. Not only did his experience and expertise help me get through some of the most challenging parts of the project, but his presence also made the whole process genuinely enjoyable. I also believe few people in the world could guide me so well through the Alive2 codebase!\n\nI would also like to thank George Mitenkov, who laid the groundwork by developing the original prototype introducing the byte type. Not only did he accomplish quite a lot in a single summer, but he also wrote a phenomenal write-up, which greatly contributed to my understanding of the problem.",
      "source": "Llvm.org",
      "url": "https://blog.llvm.org/posts/2025-08-29-gsoc-byte-type/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "HP EliteBook 8 G1a 16 AI laptop review: Redesigned inside and out",
      "content": "The business-centric EliteBook 8 series directly replaces the outgoing EliteBook 800 series. The new naming convention makes it easier to identify the price category, generation, and type of processor. In this case, the EliteBook 8 G1a 16 in review is an entry-level (8) first generation (G1) model powered by an AMD (a) processor. Higher-end EliteBook models sport the \"X\" or \"Ultra\" name instead of the \"8\".\n\nOur test configuration is a costlier SKU with the Zen 5 Ryzen AI 7 PRO 350 CPU, 32 GB of RAM, and 1200p IPS display for approximately $1900 USD. Lower-end options start with the Zen 4 Ryzen 5 Pro 230 while the 1200p native resolution is fixed across the board.\n\nAlternatives to the 16-inch EliteBook 8 G1a include other entry-level to midrange business or office laptops like the Asus ExpertBook B5, Lenovo ThinkPad L16, or Dell Latitude 5000 to 7000 series. A 14-inch version of this model is also available called the EliteBook 8 G1a 14. For Intel fans, SKUs with Core Ultra CPUs are aptly named the EliteBook 8 G1i 16.\n\nMore HP reviews:",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/HP-EliteBook-8-G1a-16-AI-laptop-review-Redesigned-inside-and-out.1103659.0.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Easy online access to active mobility device parts driving illegal modifications, say industry players",
      "content": null,
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/singapore/active-mobility-devices-amd-illegal-modification-parts-online-5339241",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia Announces Rubin CPX GPU To Speed Long-Context AI",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/karlfreund/2025/09/09/nvidia-announces-rubin-cpx-gpu-to-speed-long-context-ai/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD’s CEO Lisa Su to Make a CES 2026 Comeback After Three Years, Unveiling ‘Bold’ Plans for Next-Gen Ryzen CPUs, Radeon GPUs, and AI Computing",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/amd-ceo-lisa-su-to-make-a-return-at-ces-2026-after-three-years/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Refurbished CyberPowerPC Gamer Master GMA6900WST Ryzen 5 7600 16GB DDR5 AMD Radeon RX 7600 8GB 1TB SSD Wifi BT Win11H + Free Shipping $632",
      "content": "VIP Outlet via eBay has Refurbished CyberPowerPC Gamer Master GMA6900WST Ryzen 5 7600 16GB DDR5 AMD Radeon RX 7600 8GB 1TB SSD Wifi BT Win11H for $632.00. Shipping is free. 1 year warranty provided by Allstate.OP Notes: Only 5 in stock at time of posting. Nice specs for the $630 price point (latest socket AM5 processor with 27,000+ CPU Mark score, DDR5 system RAM upgradeable to 128GB, GDDR6 graphics RAM, respectable graphics card, 1TB PCIe Gen4 SSD). Reviews indicate excellent performance with modern games.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18593395-refurbished-cyberpowerpc-gamer-master-gma6900wst-ryzen-5-7600-16gb-ddr5-amd-radeon-rx-7600-8gb-1tb-ssd-wifi-bt-win11h-free-shipping-632",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "YMMV: HP OMEN MAX: 16\" QHD+ 240Hz IPS, Ryzen AI 9 HX 375, RTX 5080, 32GB DDR5, 1TB SSD $1999.99",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired Dr.W posted Item 1 of 2 Item 1 of 2 expired Dr.W posted YMMV: HP OMEN MAX: 16\" QHD+ 240Hz IPS, Ryzen AI 9 HX 375, RTX 5080, 32GB DDR5, 1TB SSD $1999.99 $2,000 $2,400 16% off Micro Center 9 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 5,787 Views Visit Micro Center Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details Available In-store Only at selective stores, YMMV.\n\n\n\nSPECS: AMD Ryzen AI 9 HX 375 (2.0GHz) Processor\n\n32GB DDR5-5600 RAM\n\nNVIDIA GeForce RTX 5080 Graphics Card\n\n1TB PCIe Gen4 NVMe M.2 SSD\n\n16\" WQXGA IPS Anti-Glare Display\n\n2.5Gb LAN, 2x2 WiFi 7 (802.11be), Bluetooth 5.4\n\n5.88 lbs. (2.67 kg)\n\nWindows 11 Home\n\nhttps://www.microcenter .com/produ...-processor Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster Dr.W Follow Give Rep Message 8,032 Deal Posts 11,542 Comments Posts 16,996 Reputation Points 10,806 Votes Submitted Deal Details Community Notes About the Poster Available In-store Only at selective stores, YMMV.\n\n\n\nSPECS: AMD Ryzen AI 9 HX 375 (2.0GHz) Processor\n\n32GB DDR5-5600 RAM\n\nNVIDIA GeForce RTX 5080 Graphics Card\n\n1TB PCIe Gen4 NVMe M.2 SSD\n\n16\" WQXGA IPS Anti-Glare Display\n\n2.5Gb LAN, 2x2 WiFi 7 (802.11be), Bluetooth 5.4\n\n5.88 lbs. (2.67 kg)\n\nWindows 11 Home\n\nhttps://www.microcenter .com/produ...-processor",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18593653-ymmv-hp-omen-max-16-qhd-240hz-ips-ryzen-ai-9-hx-375-rtx-5080-32gb-ddr5-1tb-ssd-1999-99",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Microsoft Patch Tuesday September 2025, (Tue, Sep 9th)",
      "content": "As part of its September patch Tuesday, Microsoft addressed 177 different vulnerabilities, 86 of which affect Microsoft products. None of the vulnerabilities has been exploited before today. Two of the vulnerabilities were already made public. Microsoft rates 13 of the vulnerabilities are critical.\n\nYou will see a number of vulnerabilities without assigned severity. These vulnerabilities affect Linux distributions like Mariner, Microsoft's Linux distribution used in its cloud environments, and Azure Linux.\n\nVulnerabilities of Interest:\n\nCVE-2025-54107, CVE-2025-54917: Microsoft assigns URLs to different security zones, like \"Intranet\" and \"Internet\". URLs may be misclassified. An attacker could use this vulnerability to bypass security features that restrict more risky URLs.\n\nCVE-2025-55226, CVE-2025-55236: The description for these vulnerabilities is a bit odd. Microsoft labels them as \"remote code execution\" vulnerabilities, but states that they allow an \"authorized attacker to execute code locally.\" I suspect that the remote part refers to a user unknowingly executing the code by viewing an image. The CVSS score is still low for a \"critical\" vulnerability.\n\nOverall, there is no \"patch now\" vulnerability included. Apply patches in line with your local vulnerability management policy (hopefully before next month's patch Tuesday).\n\nDescription CVE Disclosed Exploited Exploitability (old versions) current version Severity CVSS Base (AVG) CVSS Temporal (AVG) ACPI: pfr_update: Fix the driver update version check CVE-2025-39701 No No - - - ALSA: usb-audio: Validate UAC3 power domain descriptors, too CVE-2025-38729 No No - - - 7.0 7.0 ASoC: core: Check for rtd == NULL in snd_soc_remove_pcm_runtime() CVE-2025-38706 No No - - - 4.7 4.7 Azure Arc Elevation of Privilege Vulnerability CVE-2025-55316 No No - - Important 7.8 6.8 Azure Bot Service Elevation of Privilege Vulnerability CVE-2025-55244 No No - - Critical 9.0 7.8 Azure Connected Machine Agent Elevation of Privilege Vulnerability CVE-2025-49692 No No - - Important 7.8 6.8 Azure Entra Elevation of Privilege Vulnerability CVE-2025-55241 No No - - Critical 9.0 7.8 Azure Networking Elevation of Privilege Vulnerability CVE-2025-54914 No No - - Critical 10.0 8.7 Capability Access Management Service (camsvc) Elevation of Privilege Vulnerability CVE-2025-54108 No No - - Important 7.0 6.1 DirectX Graphics Kernel Elevation of Privilege Vulnerability CVE-2025-55223 No No - - Important 7.0 6.1 Dynamics 365 FastTrack Implementation Assets Information Disclosure Vulnerability CVE-2025-55238 No No - - Critical 7.5 6.5 Glib: buffer under-read on glib through glib/gfileutils.c via get_tmp_file() CVE-2025-7039 No No - - - 3.7 3.7 Graphics Kernel Remote Code Execution Vulnerability CVE-2025-55226 No No - - Critical 6.7 5.8 CVE-2025-55236 No No - - Critical 7.3 6.4 HTTP.sys Denial of Service Vulnerability CVE-2025-53805 No No - - Important 7.5 6.5 Libsoup: improper handling of http vary header in libsoup caching CVE-2025-9901 No No - - - 5.9 5.6 Local Security Authority Subsystem Service (LSASS) Denial of Service Vulnerability CVE-2025-53809 No No - - Important 6.5 5.7 Local Security Authority Subsystem Service Elevation of Privilege Vulnerability CVE-2025-54894 No No - - Important 7.8 6.8 LoongArch: BPF: Fix jump offset calculation in tailcall CVE-2025-38723 No No - - - 5.5 5.5 MIPS: Don't crash in stack_top() for tasks without ABI or vDSO CVE-2025-38696 No No - - - 5.5 5.5 MapUrlToZone Security Feature Bypass Vulnerability CVE-2025-54107 No No - - Important 4.3 3.8 CVE-2025-54917 No No - - Important 4.3 3.8 Microsoft AutoUpdate (MAU) Elevation of Privilege Vulnerability CVE-2025-55317 No No - - Important 7.8 6.8 Microsoft Brokering File System Elevation of Privilege Vulnerability CVE-2025-54105 No No - - Important 7.0 6.1 Microsoft DWM Core Library Elevation of Privilege Vulnerability CVE-2025-53801 No No - - Important 7.8 6.8 Microsoft Edge (Chromium-based) Security Feature Bypass Vulnerability CVE-2025-53791 No No - - Moderate 4.7 4.1 Microsoft Excel Information Disclosure Vulnerability CVE-2025-54901 No No - - Important 5.5 4.8 Microsoft Excel Remote Code Execution Vulnerability CVE-2025-54896 No No - - Important 7.8 6.8 CVE-2025-54898 No No - - Important 7.8 6.8 CVE-2025-54899 No No - - Important 7.8 6.8 CVE-2025-54902 No No - - Important 7.8 6.8 CVE-2025-54903 No No - - Important 7.8 6.8 CVE-2025-54904 No No - - Important 7.8 6.8 CVE-2025-54900 No No - - Important 7.8 6.8 Microsoft High Performance Compute (HPC) Pack Remote Code Execution Vulnerability CVE-2025-55232 No No - - Important 9.8 8.5 Microsoft Office Remote Code Execution Vulnerability CVE-2025-54906 No No - - Important 7.8 6.8 CVE-2025-54910 No No - - Critical 8.4 7.3 Microsoft Office Visio Remote Code Execution Vulnerability CVE-2025-54907 No No - - Important 7.8 6.8 Microsoft OfficePlus Spoofing Vulnerability CVE-2025-55243 No No - - Important 7.5 6.5 Microsoft PowerPoint Remote Code Execution Vulnerability CVE-2025-54908 No No - - Important 7.8 6.8 Microsoft SQL Server Elevation of Privilege Vulnerability CVE-2025-55227 No No - - Important 8.8 7.7 Microsoft SQL Server Information Disclosure Vulnerability CVE-2025-47997 No No - - Important 6.5 5.7 Microsoft SharePoint Remote Code Execution Vulnerability CVE-2025-54897 No No - - Important 8.8 7.7 Microsoft Virtual Hard Disk Elevation of Privilege Vulnerability CVE-2025-54112 No No - - Important 7.0 6.1 Microsoft Word Information Disclosure Vulnerability CVE-2025-54905 No No - - Important 7.1 6.2 NFS: Fix a race when updating an existing write CVE-2025-39697 No No - - - 5.5 5.5 NFS: Fix filehandle bounds checking in nfs_fh_to_dentry() CVE-2025-39730 No No - - - 7.5 7.5 Podman: podman kube play command may overwrite host files CVE-2025-9566 No No - - - 8.1 8.1 PowerShell Direct Elevation of Privilege Vulnerability CVE-2025-49734 No No - - Important 7.0 6.1 SPNEGO Extended Negotiation (NEGOEX) Security Mechanism Elevation of Privilege Vulnerability CVE-2025-54895 No No - - Important 7.8 6.8 VulnCheck: CVE-2024-21907 Improper Handling of Exceptional Conditions in Newtonsoft.Json CVE-2024-21907 Yes No - - - Windows Ancillary Function Driver for WinSock Elevation of Privilege Vulnerability CVE-2025-54099 No No - - Important 7.0 6.1 Windows BitLocker Elevation of Privilege Vulnerability CVE-2025-54911 No No - - Important 7.3 6.4 CVE-2025-54912 No No - - Important 7.8 6.8 Windows Bluetooth Service Elevation of Privilege Vulnerability CVE-2025-53802 No No - - Important 7.0 6.1 Windows Connected Devices Platform Service (Cdpsvc) Denial of Service Vulnerability CVE-2025-54114 No No - - Important 7.0 6.1 Windows Connected Devices Platform Service Elevation of Privilege Vulnerability CVE-2025-54102 No No - - Important 7.8 6.8 Windows Defender Firewall Service Elevation of Privilege Vulnerability CVE-2025-53808 No No - - Important 6.7 5.8 CVE-2025-53810 No No - - Important 6.7 5.8 CVE-2025-54094 No No - - Important 6.7 5.8 CVE-2025-54104 No No - - Important 6.7 5.8 CVE-2025-54109 No No - - Important 6.7 5.8 CVE-2025-54915 No No - - Important 6.7 5.8 Windows Graphics Component Elevation of Privilege Vulnerability CVE-2025-53800 No No - - Critical 7.8 6.8 CVE-2025-53807 No No - - Important 7.0 6.1 Windows Graphics Component Remote Code Execution Vulnerability CVE-2025-54919 No No - - Important 7.5 6.5 CVE-2025-55228 No No - - Critical 7.8 6.8 Windows Hyper-V Elevation of Privilege Vulnerability CVE-2025-54091 No No - - Important 7.8 6.8 CVE-2025-54092 No No - - Important 7.8 6.8 CVE-2025-54098 No No - - Important 7.8 6.8 CVE-2025-54115 No No - - Important 7.0 6.1 Windows Hyper-V Remote Code Execution Vulnerability CVE-2025-55224 No No - - Critical 7.8 6.8 Windows Imaging Component Information Disclosure Vulnerability CVE-2025-53799 No No - - Critical 5.5 4.8 Windows Kernel Elevation of Privilege Vulnerability CVE-2025-54110 No No - - Important 8.8 7.7 Windows Kernel Memory Information Disclosure Vulnerability CVE-2025-53803 No No - - Important 5.5 4.8 Windows Kernel-Mode Driver Information Disclosure Vulnerability CVE-2025-53804 No No - - Important 5.5 4.8 Windows Management Service Elevation of Privilege Vulnerability CVE-2025-54103 No No - - Important 7.4 6.4 Windows MultiPoint Services Elevation of Privilege Vulnerability CVE-2025-54116 No No - - Important 7.3 6.4 Windows NTFS Remote Code Execution Vulnerability CVE-2025-54916 No No - - Important 7.8 6.8 Windows NTLM Elevation of Privilege Vulnerability CVE-2025-54918 No No - - Critical 8.8 7.7 Windows Routing and Remote Access Service (RRAS) Information Disclosure Vulnerability CVE-2025-53797 No No - - Important 6.5 5.7 CVE-2025-53798 No No - - Important 6.5 5.7 CVE-2025-54095 No No - - Important 6.5 5.7 CVE-2025-54096 No No - - Important 6.5 5.7 CVE-2025-54097 No No - - Important 6.5 5.7 CVE-2025-55225 No No - - Important 6.5 5.7 CVE-2025-53796 No No - - Important 6.5 5.7 CVE-2025-53806 No No - - Important 6.5 5.7 Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability CVE-2025-54106 No No - - Important 8.8 7.7 CVE-2025-54113 No No - - Important 8.8 7.7 Windows SMB Client Remote Code Execution Vulnerability CVE-2025-54101 No No - - Important 4.8 4.2 Windows SMB Elevation of Privilege Vulnerability CVE-2025-55234 Yes No - - Important 8.8 7.7 Windows TCP/IP Driver Elevation of Privilege Vulnerability CVE-2025-54093 No No - - Important 7.0 6.1 Windows UI XAML Maps MapControlSettings Elevation of Privilege Vulnerability CVE-2025-54913 No No - - Important 7.8 6.8 Windows UI XAML Phone DatePickerFlyout Elevation of Privilege Vulnerability CVE-2025-54111 No No - - Important 7.8 6.8 Xbox Certification Bug Copilot Djando Information Disclosure Vulnerability CVE-2025-55242 No No - - Critical 6.5 5.7 Xbox Gaming Services Elevation of Privilege Vulnerability CVE-2025-55245 No No - - Important 7.8 6.8 cJSON 1.5.0 through 1.7.18 allows out-of-bounds access via the decode_array_index_from_pointer function in cJSON_Utils.c, allowing remote attackers to bypass array bounds checking and access restricted data via malformed JSON pointer strings containing alphanumeric characters. CVE-2025-57052 No No - - - 9.8 9.8 comedi: Fix use of uninitialized memory in do_insn_ioctl() and do_insnlist_ioctl() CVE-2025-39684 No No - - - 5.5 5.5 comedi: Make insn_rw_emulate_bits() do insn->n samples CVE-2025-39686 No No - - - 5.5 5.5 comedi: fix race between polling and detaching CVE-2025-38687 No No - - - 5.5 5.5 comedi: pcl726: Prevent invalid irq number CVE-2025-39685 No No - - - 5.5 5.5 crypto: qat - flush misc workqueue during device shutdown CVE-2025-39721 No No - - - 7.0 7.0 drbd: add missing kref_get in handle_write_conflicts CVE-2025-38708 No No - - - 6.3 6.3 drm/amd/display: Add null pointer check in mod_hdcp_hdcp1_create_session() CVE-2025-39675 No No - - - 5.5 5.5 drm/amd/display: Avoid a NULL pointer dereference CVE-2025-39693 No No - - - 5.5 5.5 drm/amd/display: fix a Null pointer dereference vulnerability CVE-2025-39705 No No - - - 5.5 5.5 drm/amd/pm: fix null pointer access CVE-2025-38705 No No - - - 5.5 5.5 drm/amdgpu: check if hubbub is NULL in debugfs/amdgpu_dm_capabilities CVE-2025-39707 No No - - - 5.5 5.5 drm/amdkfd: Destroy KFD debugfs after destroy KFD wq CVE-2025-39706 No No - - - 5.5 5.5 drm/nouveau/nvif: Fix potential memory leak in nvif_vmm_ctor(). CVE-2025-39679 No No - - - 5.5 5.5 drm/xe: Make dma-fences compliant with the safe access rules CVE-2025-38703 No No - - - 7.8 7.8 exfat: add cluster chain loop check for dir CVE-2025-38692 No No - - - 7.0 7.0 ext4: do not BUG when INLINE_DATA_FL lacks system.data xattr CVE-2025-38701 No No - - - 7.0 6.4 f2fs: vm_unmap_ram() may be called from an invalid context CVE-2025-39731 No No - - - 5.5 5.5 fbdev: Fix vmalloc out-of-bounds write in fast_imageblit CVE-2025-38685 No No - - - 7.8 7.8 fbdev: fix potential buffer overflow in do_register_framebuffer() CVE-2025-38702 No No - - - 7.8 7.1 fs/buffer: fix use-after-free when call bh_read() helper CVE-2025-39691 No No - - - 7.1 7.1 fs/ntfs3: Add sanity check for file name CVE-2025-38707 No No - - - 5.5 5.5 ftrace: Also allocate and copy hash for reading of filter files CVE-2025-39689 No No - - - 7.1 6.5 gfs2: Validate i_depth for exhash directories CVE-2025-38710 No No - - - 7.0 6.4 gve: prevent ethtool ops after shutdown CVE-2025-38735 No No - - - 7.0 7.0 habanalabs: fix UAF in export_dmabuf() CVE-2025-38722 No No - - - 5.5 5.5 hfs: fix general protection fault in hfs_find_init() CVE-2025-38716 No No - - - 5.5 5.5 hfs: fix slab-out-of-bounds in hfs_bnode_read() CVE-2025-38715 No No - - - 5.5 5.5 hfsplus: don't use BUG_ON() in hfsplus_create_attributes_file() CVE-2025-38712 No No - - - 5.5 5.5 hfsplus: fix slab-out-of-bounds in hfsplus_bnode_read() CVE-2025-38714 No No - - - 9.0 8.2 hfsplus: fix slab-out-of-bounds read in hfsplus_uni2asc() CVE-2025-38713 No No - - - 6.1 6.1 iio: imu: bno055: fix OOB access of hw_xlate array CVE-2025-39719 No No - - - 5.5 5.5 iio: light: as73211: Ensure buffer holes are zeroed CVE-2025-39687 No No - - - 5.5 5.5 io_uring/net: commit partial buffers on retry CVE-2025-38730 No No - - - 5.5 5.5 iommufd: Prevent ALIGN() overflow CVE-2025-38688 No No - - - 7.1 7.1 ipv6: sr: Fix MAC comparison to be constant-time CVE-2025-39702 No No - - - 7.1 7.1 jfs: Regular file corruption check CVE-2025-38698 No No - - - 7.1 6.5 jfs: upper bound check of tree index in dbAllocAG CVE-2025-38697 No No - - - 7.1 7.1 ksmbd: fix refcount leak causing resource not released CVE-2025-39720 No No - - - 5.5 5.5 loop: Avoid updating block size under exclusive owner CVE-2025-38709 No No - - - 7.0 6.4 media: ivsc: Fix crash at shutdown due to missing mei_cldev_disable() calls CVE-2025-39711 No No - - - 7.0 7.0 media: rainshadow-cec: fix TOCTOU race condition in rain_interrupt() CVE-2025-39713 No No - - - 7.0 7.0 media: usbtv: Lock resolution while streaming CVE-2025-39714 No No - - - 5.5 5.5 media: uvcvideo: Fix 1-byte out-of-bounds read in uvc_parse_format() CVE-2025-38680 No No - - - 3.3 3.3 media: venus: Add a check for packet size after reading from shared memory CVE-2025-39710 No No - - - media: venus: Fix OOB read due to missing payload bound check CVE-2025-38679 No No - - - 5.5 5.5 media: venus: protect against spurious interrupts during probe CVE-2025-39709 No No - - - 5.5 5.5 mm/ptdump: take the memory hotplug lock inside ptdump_walk_pgd() CVE-2025-38681 No No - - - 5.5 5.5 net, hsr: reject HSR frame if skb can't hold tag CVE-2025-39703 No No - - - 7.0 6.4 net/sched: Fix backlog accounting in qdisc_dequeue_internal CVE-2025-39677 No No - - - 7.0 6.4 net/sched: ets: use old 'nbands' while purging unused classes CVE-2025-38684 No No - - - 7.0 7.0 net/smc: fix UAF on smcsk after smc_listen_out() CVE-2025-38734 No No - - - 5.5 5.5 net: kcm: Fix race condition in kcm_unattach() CVE-2025-38717 No No - - - 5.5 5.5 net: usb: asix_devices: Fix PHY address mask in MDIO bus initialization CVE-2025-38736 No No - - - 5.5 5.5 net: usb: asix_devices: add phy_mask for ax88772 mdio bus CVE-2025-38725 No No - - - 5.5 5.5 netfilter: ctnetlink: fix refcount leak on table dump CVE-2025-38721 No No - - - 5.5 5.5 netfilter: nf_reject: don't leak dst refcount for loopback packets CVE-2025-38732 No No - - - 7.0 7.0 netfilter: nf_tables: reject duplicate device on updates CVE-2025-38678 No No - - - 6.0 6.0 nfsd: handle get_client_locked() failure in nfsd4_setclientid_confirm() CVE-2025-38724 No No - - - 6.8 6.8 pNFS: Fix uninited ptr deref in block/scsi layout CVE-2025-38691 No No - - - 5.5 5.5 parisc: Revise __get_user() to probe user read access CVE-2025-39716 No No - - - 5.5 5.5 parisc: Revise gateway LWS calls to probe user read access CVE-2025-39715 No No - - - 5.5 5.5 ppp: fix race conditions in ppp_fill_forward_path CVE-2025-39673 No No - - - 7.0 7.0 rcu/nocb: Fix possible invalid rdp's->nocb_cb_kthread pointer access CVE-2025-38704 No No - - - 5.5 5.5 s390/ism: fix concurrency management in ism_cmd() CVE-2025-39726 No No - - - 5.5 5.5 s390/sclp: Fix SCCB present check CVE-2025-39694 No No - - - 7.0 7.0 scsi: bfa: Double-free fix CVE-2025-38699 No No - - - 7.8 7.8 scsi: libiscsi: Initialize iscsi_conn->dd_data only if memory is allocated CVE-2025-38700 No No - - - 4.7 4.7 scsi: lpfc: Check for hdwq null ptr when cleaning up lpfc_vport structure CVE-2025-38695 No No - - - 7.0 6.4 scsi: qla4xxx: Prevent a potential error pointer dereference CVE-2025-39676 No No - - - 5.5 5.5 sctp: linearize cloned gso packets in sctp_rcv CVE-2025-38718 No No - - - 7.0 6.4 serial: 8250: fix panic due to PSLVERR CVE-2025-39724 No No - - - 5.5 5.5 smb/server: avoid deadlock when linking with ReplaceIfExists CVE-2025-38711 No No - - - 5.5 5.5 smb3: fix for slab out of bounds on mount to ksmbd CVE-2025-38728 No No - - - 5.5 5.5 smb: server: split ksmbd_rdma_stop_listening() out of ksmbd_rdma_destroy() CVE-2025-39692 No No - - - 5.5 5.5 tls: fix handling of zero-length records on the rx_list CVE-2025-39682 No No - - - 6.5 6.5 tracing: Limit access to parser->buffer when trace_get_user failed CVE-2025-39683 No No - - - 7.1 7.1 vsock/virtio: Validate length in packet header before skb_put() CVE-2025-39718 No No - - - 5.5 5.5 wifi: ath11k: fix sleeping-in-atomic in ath11k_mac_op_set_bitrate_mask() CVE-2025-39732 No No - - - 7.0 7.0 x86/cpu/hygon: Add missing resctrl_cpu_detect() in bsp_init helper CVE-2025-39681 No No - - - 5.5 5.5\n\n--\n\nJohannes B. Ullrich, Ph.D. , Dean of Research, SANS.edu\n\nTwitter|",
      "source": "Sans.edu",
      "url": "https://isc.sans.edu/diary/32270",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "PlayStation 5 Pro AMD FSR 4 Support Is Coming In First Quarter of 2026 – Rumor",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/playstation-5-pro-amd-fsr-first-quarter-2026/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Reorg Puts 40-Year Vet in Charge of PC Group",
      "content": "Intel announced a corporate reorganization that puts Jim Johnson, a 40-year veteran of the company, in charge of the Client Computing Group responsible for its x86-based chip designs for PCs. He was previously serving in this role in an interim basis.\n\n“Jim’s steady leadership and trusted relationships across the computing industry are driving continued progress in our client business as we prepare to launch a new generation of products,” Intel CEO Lip-Bu Tan said.\n\nThurrott.com readers may recognize Johnson as the face of “Lunar Lake,” the controversial—and, I would argue, unsuccessful—attempt to quickly scale Intel’s x86 silicon to battery compete with more efficient Arm-based designs. He anchored the Intel announcement event for Lunar Lake at last year’s IFA in Berlin, Germany. And then he appeared at the Lenovo Innovation World press conference at this year’s show, which was held last week.\n\nHis appearance at Lenovo Innovation World was, to put it mildly, awkward, though he gets an A for confidence and staying on-message.\n\n“With Core Ultra Series 2 [Lunar Lake], we re-engineered the CPU, the GPU, and the NPU and delivered faster compute, improved AI experience, and busted the myth that x86 can’t be power efficient,” Johnson said at the event, which is available for rewatching on YouTube. Here, he paused, presumably for applause.\n\nIt never came. As most in the audience understood, and as my unpredictable and mostly lackluster experiences with Lunar Lake-based PCs show, this isn’t the home run that Johnson promoted. Lunar Lake is more efficient than previous Intel chips, but it’s also incredibly unreliable and unpredictable. Indeed, Lunar Lake is such a disaster that Intel will never make a chip design like it again, and it loses money on every unit sold. Subsequent Core Ultra Series 2 designs have all used different architectures.\n\nTo be clear, this is no one person’s fault in the sense that a cascading series of strategic mistakes over a decade or more led to Intel’s problems today. The company was forced to rush Lunar Lake to market so it could have a Copilot+ PC-compatible chip to compete with more efficient designs from AMD and Qualcomm.\n\nAnd Johnson wasn’t in charge of Intel’s Client Computing Group at that time. Michelle Johnston Holthaus was. And as it turns out, she’s leaving Intel as Johnson is elevated into her former role. She had become CEO of Intel products briefly, after Pat Gelsinger, the previous Intel CEO, left the company.\n\n“Throughout her incredible career, Michelle has transformed major businesses, built high-performing teams, and worked to delight our customers,” Tan said. “She has made a lasting impact on our company and inspired so many of us with her leadership. We are grateful for all Michelle has given Intel and wish her the best.”\n\nAs part of the reorg, Intel also revealed that Naga Chandrasekaran, the executive vice president and chief technology and operations officer of Intel Foundry, will expand his role to include Foundry Services. He joined Intel last year after a stint at Micron.\n\nIntel is also creating a new Central Engineering Group that will “build a new custom silicon business to serve a broad range of external customers.” This will be led by Srini Iyengar, who joined Intel this past June. And former Arm executive Kevork Kechichian has joined Intel as executive vice president and general manager of the Data Center Group (DCG).\n\nChandrasekaran was already reporting directly to the Intel CEO, and now Johnson, Kechichian, and Iyengar will as well, Intel says.",
      "source": "Thurrott.com",
      "url": "https://www.thurrott.com/hardware/326233/intel-reorg-puts-40-year-vet-in-charge-of-pc-group",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Patch Tuesday Arrives with New Features for Windows 11",
      "content": "It’s Patch Tuesday, and those on Windows 11 can look forward to a long list of new features. You know, once Microsoft gets around to delivering them on your PC, as most of them are being rolled out gradually.\n\nCumulative update KB5065426 is available for PCs running Windows 11 version 23H2. And cumulative update KB5065426 is available now for PCs running Windows 11 version 24H2. Both builds include numerous new features that were first previewed two weeks ago.\n\nKey new features include:\n\nRecall improvements (Copilot+ PCs only). Recall provides a new homepage experience with shortcuts for your recent activity, most-used apps, and most-visited websites. There are new controls for filtering the apps and websites that Recall shouldn’t record, plus a new navigation bar on the left with links to Home, Timeline, Feedback, and Settings.\n\nClick to Do improvements (Copilot+ PCs only). Click to Do now provides an interactive tutorial when you first launch it, and you can access it later by navigating to More options (“…”) > Start tutorial.\n\nAgent in Settings (Copilot+ PCs only). Previously available on Snapdragon X-based Copilot+ PCs, the new Agent in Settings is now available to those with AMD- and Intel-based Copilot+ PCs too. But it’s still limited to English, which must be configured as your primary display language.\n\nSearch improvements. When you initiate Search from the Taskbar item, a new grid view is used for image results so you can more easily find what you’re looking for. The Search window will now display a status pane if Windows 11 is still indexing your search locations. And search results will clearly differentiate between local and cloud-stored files.\n\nLarger clock option in Notification center. As was the case in Windows 10, you can now enable a larger clock with settings in the Date and Calendar window that appears when you display the Notification center. (To do so, open Settings, navigate to Time & language > Date & time, and enable the option “Show time in the Notification Center.”)\n\nSystem dialog improvements. System dialogs now appear modally over the rest of the Desktop, which is dimmed to give emphasis to the dialog.\n\nLock screen widgets improvements. You can now add, remove, and rearrange Lock screen widgets. And these widgets now support a new small sizing option.\n\nFile Explorer improvements. Microsoft has made minor visual changes to the context menu that appears when you right-click in File Explorer.\n\nWindows Hello improvements. The Windows Hello user experience is completely redesigned with more modern visuals. It’s nicer looking but, truth be told, slower and more tedious to use now. But it does let you switch between available authentication options such as passkeys or connected devices.\n\nGenerative AI privacy and security settings. A new page in the Settings app, found at Privacy & security > Text and Image Generation, displays which third-party apps have recently used generative AI models built into Windows. You can also manage which apps can use these features, and then disable those you don’t want.\n\nWidgets improvements. You can now configure multiple dashboards in the Widgets board, and there’s a new navigation bar on the left for switching between the widget dashboards and other views like the Discover feed, which is “more organized, personalized, and engaging.”\n\nTask Manager improvements. Task Manager has been updated to more accurately display CPU usage across all views. The Details view now has an optional CPU Utility column, as per the Processes view.\n\nFixes. As you might imagine, these builds also deliver multiple security and bug fixes across ReFS, the Chinese (Simplified) Input Method Editor (IME), Arm64 performance, and more.\n\nYes, you will need to reboot as usual.",
      "source": "Thurrott.com",
      "url": "https://www.thurrott.com/windows/windows-11/326263/patch-tuesday-arrives-with-new-features-for-windows-11",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "China’s AI Chip Ambitions Limited by HBM Memory Supply, Notes Report",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/chinas-ai-chip-ambitions-limited-by-hbm-memory-supply-notes-report/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 “Battlemage” Nears Launch as Intel Prepares Packaging",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Wall Street Loves Taiwan Semi. Should You Buy TSM Stock Now?",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/34699828/wall-street-loves-taiwan-semi-should-you-buy-tsm-stock-now",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Vultr Announces Availability of AMD Instinct™ MI355X GPUs Worldwide",
      "content": null,
      "source": "Financial Post",
      "url": "https://financialpost.com/pmn/business-wire-news-releases-pmn/vultr-announces-availability-of-amd-instinct-mi355x-gpus-worldwide",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Why JPMorgan is warning the Fed rate cut everyone expects could sink stocks",
      "content": null,
      "source": "MarketWatch",
      "url": "https://www.marketwatch.com/story/why-jpmorgan-is-warning-the-fed-rate-cut-everyone-expects-could-sink-stocks-0179698d",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD Ryzen 7 9800X3D vs AMD Ryzen 9 9950X3D Faceoff",
      "content": "If you're looking for the fastest gaming chips on the market, AMD has no peer: In fact, the company's own Ryzen 9 9950X3D vs Ryzen 7 9800X3D is really the only competition that most hardcore gamers care about - Intel isn't a factor with its latest-gen chips due to lackluster performance on the gaming front.\n\nAt first glance, comparing the $470 AMD Ryzen 7 9800X3D with the flagship $670 Ryzen 9 9950X3D might seem like an uneven match. After all, the Ryzen 9 9950X3D commands a $200 higher price point and boasts twice the number of cores, which naturally suggests superior performance.\n\nHowever, this faceoff dives deeper than just raw numbers and sticker price. It explores how these two processors, both from AMD’s gaming-optimized Zen 5 X3D lineup, cater to different needs and whether the premium flagship truly justifies its cost in real-world scenarios.\n\nThe Ryzen 9 9950X3D sits at the very top of AMD’s desktop CPU hierarchy, aimed at enthusiasts and professionals who demand the utmost in multi-threaded performance alongside gaming capabilities. It's the \"no compromises\" option, commanding a premium price befitting its halo status.\n\nIn contrast, the Ryzen 7 9800X3D offers a more focused approach, targeting gamers and mainstream users who seek exceptional gaming performance and efficiency without the complexity or cost of a higher-core-count processor.\n\nPriced around $450 compared to the 9950X3D’s $700 tag, the 9800X3D challenges the notion that more cores and higher prices always translate to a better CPU. Forget assumptions, let's dissect where these two exceptional gaming processors truly excel and uncover which one deserves a place in your ultimate rig.\n\nFeatures and Specifications: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nSwipe to scroll horizontally AMD Ryzen 9 9950X3D and Ryzen 9 9900X3D — Pricing and Specifications CPU Street (MSRP) Arch Cores / Threads (P+E) P-Core Base / Boost Clock (GHz) Cache (L2/L3) TDP / PBP or MTP Memory Ryzen 9 9950X3D $699 Zen 5 X3D 16 / 32 4.3 / 5.7 144 MB (16+128) 170W / 230W DDR5-5600 Ryzen 7 9800X3D $450 Zen 5 X3D 8 / 16 4.7 / 5.2 104MB (8+96) 120W / 162W DDR5-5600\n\nBoth the AMD Ryzen 9 9950X3D and Ryzen 7 9800X3D represent the pinnacle of AMD's desktop processor engineering, built on the sophisticated Zen 5 architecture fabbed on TSMC's advanced 4nm manufacturing process. These processors share the same foundational architecture but differ significantly in their core configurations and target use cases.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe 9950X3D is a dual-CCD powerhouse featuring 16 cores and 32 threads, while the 9800X3D adopts a streamlined single-CCD design with 8 cores and 16 threads. This architectural divergence creates distinct performance profiles, with the 9950X3D targeting users requiring substantial multi-threaded performance alongside gaming excellence, whereas the 9800X3D focuses exclusively on delivering optimal gaming performance without the complexity of a multi-die design.\n\nThe 9950X3D's dual-CCD configuration incorporates two separate 8-core complexes, with only one CCD receiving the 3D V-Cache treatment. This asymmetric design results in 128MB of layered L3 cache, creating a complex but powerful architecture that requires sophisticated thread scheduling. Thankfully its automated through AMD's innovative driver.\n\nIn contrast, the 9800X3D's single-CCD design features a uniform 8-core complex with 96MB of total L3 cache, providing consistent performance characteristics across all cores and simplifying both hardware design and driver optimization.\n\nClock speed specifications reveal differences between these processors, with the 9950X3D operating at a 4.3GHz base clock with boost capabilities reaching 5.7GHz, representing the highest boost clock in the X3D lineup. The 9800X3D, conversely, features a 4.7GHz base clock with boost frequencies of 5.2GHz.\n\nThe second-gen 3D V-Cache tech represents a revolutionary architectural advancement that marks a big improvement over their predecessors. Unlike previous X3D generations, where the 3D V-Cache was positioned above the CCD, both processors feature the cache positioned below the CCD, enabling direct thermal contact between the cores and the integrated heat spreader.\n\nThis design transformation dramatically improves thermal characteristics, allowing both processors to achieve full overclocking capabilities (a first for X3D processors) while maintaining higher boost frequencies than their predecessors. The thermal improvements are particularly significant for the 9950X3D, which maintains its 170W TDP despite its larger cache capacity.\n\nPlatform support and connectivity specifications show AMD's commitment to the AM5 ecosystem. Both CPUs drop into the AM5 socket (LGA 1718) and are compatible with the full range of AM5 chipsets, including A620, B650, B650E, X670, X670E, X870, X870E, B840, and B850. Memory support extends to DDR5 with official specifications up to 5600 MT/s, though both processors can achieve higher speeds through AMD EXPO memory overclocking technology.\n\nThe processors provide 24 usable PCIe 5.0 lanes from the CPU, four native USB 3.2 Gen 2 ports, and comprehensive storage support including NVMe RAID configurations. Power consumption differs significantly, with the 9950X3D coming with a 170W TDP compared to the 9800X3D's 120W TDP, reflecting the increased thermal and power demands of the dual-CCD configuration.\n\n⭐Winner: AMD Ryzen 9 9950X3D\n\nThe Ryzen 9 9950X3D and Ryzen 7 9800X3D share a common Zen 5 foundation but diverge in their feature sets to serve distinct purposes. On paper alone, the Ryzen 9 9950X3D is more impressive due to its higher clocks and additional cores, thus taking this round.\n\nGaming Benchmarks and Performance: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nWhile our in-depth Ryzen 9 9950X3D and Ryzen 7 9800X3D reviews offer a more comprehensive analysis and our test system specs, in this section, we will focus on a gaming performance overview. The following benchmark graphs display average FPS and 1% lows for various games at 1080p. Using a high-end Nvidia GeForce RTX 5090 graphics card ensures GPU limitations are removed, making this setup ideal for comparing pure CPU performance.\n\nImage 1 of 20 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nIn our 16-game geometric mean at 1080p with High/Ultra settings, the Ryzen 7 9800X3D narrowly edges out the Ryzen 9 9950X3D with an average of 195.5 FPS versus 194.8 FPS, which is a negligible 0.4% difference. This parity stems from AMD’s 3D V-Cache technology, which minimizes latency in cache-sensitive titles.\n\nHowever, the 9950X3D’s higher core count rarely translates to gaming gains, as most games prioritize cache and clock speeds over core quantity. For example, in A Plague Tale: Requiem, the 9800X3D leads by 5.9% on average, likely due to its optimized single-CCD design reducing inter-core latency.\n\nOn the flip side, the 9950X3D pulls ahead in 1% lows according to our testing, scoring 136 FPS in the geomean compared to the 9800X3D’s 134 FPS, gaining a minor 1.4% advantage. This reflects its superior multi-core capabilities, mitigating stutter during asset streaming or background tasks.\n\nMoving on to individual results, the picture becomes even more nuanced and needs analysis on a case-by-case basis. In our testing, we typically see that cache-bound games favor the 9800X3D. Minecraft RT shows a 10.9% average FPS lead. In Starfield, the Ryzen 7 leads by 1.7% in average FPS.\n\nOn the contrary, heavily multi-threaded titles seem to lean toward the 9950X3D. In Baldur’s Gate 3, the Ryzen 9 leads by about 2.6%, exploiting its dual-CCD design to gain an advantage in this title.\n\nThe 9800X3D dominates efficiency, achieving 2.46 FPS/W versus the 9950X3D’s 1.61 FPS/W, which is a tremendous 52.8% improvement. It consumes just 79.4W under load according to our testing, while the 9950X3D draws 52% more power at 120.9W. This gap arises from the 9800X3D’s monolithic 8-core design, which avoids the power overhead of the 9950X3D’s dual-CCD configuration.\n\nThe 9800X3D also offers superior value for money, gaining a staggering 50% advantage in our FPS per dollar chart. Priced 33% lower, the Ryzen 7 achieves almost the same average FPS in our Geomean as the 9950X3D. Even in titles where the 9950X3D wins, like Far Cry 6, the 9800X3D’s cost efficiency remains unmatched. The 9950X3D does not justify its price premium in the gaming category when compared to its younger sibling.\n\n⭐Winner: AMD Ryzen 7 9800X3D\n\nUnless you are pairing gaming with heavy streaming or rendering, the 9800X3D’s cache-optimized design and aggressive pricing make it AMD’s gaming champion.\n\nUltimately, the Ryzen 7 9800X3D emerges as the smarter gaming investment. It matches the 9950X3D in average framerates while excelling in efficiency and value. The 9950X3D’s edge in 1% lows is nice, but it cannot be justified by its hefty price premium.\n\nProductivity Performance: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nAccording to our benchmark results, the Ryzen 9 9950X3D demonstrates a substantial productivity advantage over the Ryzen 7 9800X3D across both single-threaded and multi-threaded workloads.\n\nImage 1 of 6 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nIn the aggregated single-threaded geomean, the 9950X3D scores 258, while the 9800X3D trails at 243, leaving a 5.8% performance gap. For multi-threaded geomean, the disparity widens dramatically: the 9950X3D achieves 635 versus the 9800X3D’s 367, translating to a 42% delta. This underscores the 9950X3D’s superior power budget and higher core count.\n\nImage 1 of 10 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nThe 9950X3D’s 16-core design obliterates the 9800X3D’s 8-core setup in heavily parallelized tasks. Cinebench 2024 multi-core reveals a massive 43% performance delta; meanwhile, the POV-Ray multi-core test exacerbates this further as the 9950X3D scores a whopping 69% higher than the 9800X3D.\n\nReal-world encoding tests like HandBrake x265 further validate this trend, with the 9950X3D achieving a 63% leap over the 9800X3D. This makes the 9950X3D a powerhouse for video rendering, 3D compilation, or scientific simulations where core scalability is paramount.\n\nIn tasks reliant on single-core speed, the 9950X3D also maintains a consistent lead, even though the gap narrows significantly. Cinebench 2024 single-core shows a 4.7% advantage, and the gap expands in POV-Ray single-core, where the 9950X3D has a 7.6% higher score than its younger sibling.\n\nEven in lighter workloads like WebXPRT4 (browser-based tasks), the 9950X3D maintains a modest but notable 4.4% edge. The narrower gap confirms that browser-based tasks are less core-dependent, favoring cache/clock speed, yet the 9950X3D still leads. These modest gains reflect the close architectural similarities between the two CPUs in tasks that don’t necessarily scale with core count.\n\nThe 9950X3D’s dual-CCD layout (one with 3D V-Cache, one with higher clocks) optimizes it for hybrid productivity: cache-sensitive tasks leverage the stacked die, while all-core workloads engage both CCDs. The 9800X3D’s single-CCD design restricts it in lighter multi-threaded tasks despite its cache advantage.\n\nPutting it all together, for productivity alone, the Ryzen 9 9950X3D is decisively superior, delivering 10-40% higher performance on average, with peaks exceeding 60% in core-heavy tasks. The Ryzen 7 9800X3D remains viable for budget-focused users handling lighter workloads, but professionals demanding uncompromised rendering, encoding, or compilation speed should opt for the 9950X3D.\n\n⭐Winner: AMD Ryzen 9 9950X3D\n\nIts massive compute throughput advantage, driven by its doubled core count, makes the 9950X3D the unequivocal choice for professional productivity, while the 9800X3D serves well for mainstream users where its strong gaming performance and lower cost are prioritized over extreme multi-threaded muscle.\n\nOverclocking: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nBoth the AMD Ryzen 9 9950X3D and Ryzen 7 9800X3D represent a significant advancement in X3D processor overclocking capabilities compared to their predecessors. Unlike previous X3D generations that had severe overclocking limitations, both Zen 5-based processors support full manual overclocking, including multiplier adjustments, voltage modifications, and extensive tuning options.\n\nThis is a revolutionary change from the Zen 4 X3D processors that were largely locked down, with the 7800X3D only supporting limited PBO and Curve Optimizer adjustments. The key architectural improvement enabling this overclocking freedom is AMD's redesigned 3D V-Cache placement.\n\nIn Zen 5 X3D processors, the 3D V-Cache is positioned underneath the Core Complex Dies (CCDs) rather than on top, dramatically improving thermal management and reducing the voltage sensitivity that previously restricted overclocking. This design change allows both processors to maintain higher boost frequencies while supporting the same overclocking toolkit as the regular Zen 5 processors.\n\nThe processors responds well to both traditional overclocking methods and AMD's advanced tuning tools, including Precision Boost Overdrive 2 (PBO2), Curve Optimizer, and the new Curve Shaper feature exclusive to Zen 5 processors. AMD has plenty of manual tuning option available, but most users are best just engaging the automated Precision Boost Overdrive (PBO) feature.\n\n⭐Winner: Tie\n\nBoth chips leverage the same AMD overclocking suite, so this section works out to a tie.\n\nPower Consumption, Efficiency, and Cooling: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nImage 1 of 10 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nAccording to our test results, the power profiles of the Ryzen 9 9950X3D and Ryzen 7 9800X3D reveal significant differences under load while showing remarkable similarity at idle, directly impacting efficiency and cooling requirements.\n\nImage 1 of 7 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nUnder sustained AVX workloads, the 9950X3D consumes substantially more power than the 9800X3D, reflecting its higher core count and performance ceiling. In the grueling Prime95 Small FFTs test, the 9950X3D averages 215W compared to the 9800X3D's 171W, which is a substantial 25.7% increase. This pattern repeats in y-cruncher's AVX test, where the 9950X3D draws 23.9% more power than the 9800X3D.\n\nEven in Cinebench 2024 multi-core rendering, which favors thread scaling, the 9950X3D requires 57.8% more power than its younger brother. This consistently higher power draw under heavy vectorized or multi-threaded loads is inherent to the 9950X3D's doubled core resources.\n\nRemarkably, both CPUs demonstrate nearly identical power efficiency during low-activity states. In active idle states (such as YouTube playback), the 9950X3D uses 31% more power than the 9800X3D, but the actual difference is 9W. However, in true idle scenarios, the gap narrows to just 3W, which is pretty negligible in the big picture. This parity highlights that the 9950X3D efficiently powers down unused cores, but also highlights that both chips carry the same power burden of the central I/O die, which ultimately results in higher idle power consumption for Zen 5 processors compared to Intel offerings.\n\nDespite its higher power consumption, the 9950X3D often delivers superior performance-per-watt in multi-threaded tasks. In our Cinebench 2024 \"Watts per Point\" metric, the 9950X3D scores a 10.8% efficiency advantage over the 9800X3D. Similarly, in HandBrake x265 encoding, the 9950X3D achieves a 6.4% lead in efficiency despite consuming more raw power in the test itself.\n\nThis indicates the 9950X3D's additional cores translate workloads into completed tasks more efficiently under heavy utilization. The \"Estimated Task Energy\" graph further confirms this trend, placing the 9950X3D in a significantly better (lower-right) position than Intel competitors and delivering way more FPS than the 9800X3D despite consuming almost similar task energy.\n\nThe 9950X3D's higher sustained power load necessitates more robust cooling. A 360mm AIO liquid cooler is optimal for the 9950X3D to maintain optimal boost clocks during extended AVX workloads. The 9800X3D, with its peak draw nearly 20-25% lower, is far more forgiving. A capable dual-tower air cooler or 240mm AIO should suffice in most cases.\n\nAt the end of the day, the Ryzen 7 9800X3D is the clear winner if you just compare the two CPUs by their peak power consumption, especially under heavy AVX loads, making it ideal for users prioritizing low heat output, quieter cooling, or constrained thermal environments.\n\nHowever, the Ryzen 9 9950X3D consumes 25-58% more power under load but delivers 6-11% better performance efficiency (work completed per watt) in multi-threaded scenarios like rendering and encoding. For users needing maximum multi-core throughput, the 9950X3D's efficiency may justify its higher power ceiling, though it demands stronger cooling to realize its full potential.\n\n⭐Winner: Tie\n\nIf you want the absolute lowest power draw, the Ryzen 7 9800X3D is the obvious pick among these two CPUs. It is also easier to cool and is generally quite tame compared to the Ryzen 9 9950X3D, which consumes significantly more power under load.\n\nIn contrast, the 9950X3D takes a significant win in power efficiency (performance-per-watt), highlighting that it delivers exceptional power characteristics of its own.\n\nOverall both chips have their charms, depending on the target workload. That leaves us with yet another tie -- the winner just depends on your personal use-case.\n\nPricing: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nWhen comparing the AMD Ryzen 9 9950X3D and the Ryzen 7 9800X3D, the starting point is their respective CPU prices: the Ryzen 9 9950X3D costs $670 at the time of writing, while the Ryzen 7 9800X3D is priced at $470, a difference of $200. However, to truly assess which CPU offers better value for the money, it’s essential to consider the entire platform cost, including the motherboard, RAM, and CPU cooler.\n\nWhen examining the complete platform cost, both processors share identical requirements for supporting components, but they do have different needs in some areas. DDR5 memory pricing remains consistent across both builds, with 32GB of DDR5-6000 memory costing around $120-$150.\n\nThe AM5 socket requirement means both CPUs could use the same types of motherboards, ranging from budget B650 boards at $125-$160 to premium X870 motherboards that can cost $320-$500. However, the 9950X3D's higher power consumption and thermal output requires a better motherboard than the 9800X3D.\n\nWith a higher TDP and peak power consumption, the 16-core 9950X3D necessitates more robust VRM designs on motherboards for full performance, potentially adding $50-$100 to the platform cost.\n\nCooling the Ryzen 7 9800X3D, which has a lower TDP (120W) compared to its higher-end sibling (170W), can be adequately handled by a mid-tier solution. Options include a $50 to $70 air cooler or a $100 to $150 240mm AIO liquid cooler. In contrast, the Ryzen 9 9950X3D would benefit from a more capable solution, with a 360mm AIO liquid cooler being optimal, which can cost you about $150-200.\n\nConclusively, the 9800X3D emerges as the superior choice for value-conscious builders, despite both processors delivering nearly identical gaming performance, as we already saw. The nearly $230 price difference represents money that could be allocated toward a better graphics card, faster storage, or premium peripherals, which are components that would provide more tangible benefits for gaming performance.\n\nAs for the 9950X3D, its additional productivity capabilities justify its premium only for users who can leverage its extra cores for content creation, streaming, or professional workloads.\n\n⭐Winner: AMD Ryzen 7 9800X3D\n\nFor the vast majority of enthusiasts prioritizing gaming and overall bang-for-buck, the 9800X3D's combination of potent gaming performance and lower total platform cost makes it the clear winner for value. The 9950X3D is best reserved for users who explicitly need its extra cores and are willing to invest in the supporting high-end platform.\n\nBottom Line: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nSwipe to scroll horizontally Row 0 - Cell 0 AMD Ryzen 9 9950X3D AMD Ryzen 7 9800X3D Features and Specifications ❌ Row 1 - Cell 2 Gaming Row 2 - Cell 1 ❌ Productivity Applications ❌ Row 3 - Cell 2 Overclocking ❌ ❌ Power Consumption, Efficiency and Cooling ❌ ❌ Pricing Row 6 - Cell 1 ❌ Total 4 4\n\nThe AMD Ryzen 9 9950X3D and Ryzen 7 9800X3D both bring impressive strengths to the table, ultimately leaving us with a 4-4 tie, but the winner for you will be clear based on your target workloads and budget.\n\nThe Ryzen 7 9800X3D is the clear champion for most users, particularly those prioritizing gaming performance and value. Its dominance in gaming performance, power efficiency, and pricing creates a compelling package that delivers exceptional results without unnecessary complexity. The single-CCD design eliminates the scheduling challenges that can plague dual-CCD configurations, making it the ideal choice for gamers who want maximum performance with minimal fuss.\n\nOn the other hand, the Ryzen 9 9950X3D remains the superior choice for a specific audience: professionals and content creators who demand both exceptional gaming performance and serious productivity capabilities. Its 16-core, 32-thread configuration provides superb multi-core performance that makes it the ultimate all-round CPU for users who refuse to compromise between gaming and professional workloads.\n\nFor the vast majority of gaming enthusiasts and high-performance PC builders, the AMD Ryzen 7 9800X3D is the unequivocal recommendation and king of gaming value. It delivers virtually identical top-tier gaming performance to the 9950X3D while being significantly cheaper, more power-efficient, easier to cool, and less demanding on the supporting platform.\n\nThe Ryzen 9 9950X3D remains a formidable, niche processor, but its considerable price premium and higher platform costs are only justifiable for users who simultaneously require maximum gaming performance and very high levels of multi-threaded productivity performance on a daily basis.\n\nBoth chips have their place, and the clear swim lanes for the 9950X3D and 9800X3D show that AMD has done an excellent job in stratifying the Ryzen 9000 X3D lineup, delivering strong value for two very different chips and ultimately earning its price tag for each chip. Meanwhile, Intel's chips simply can't compete with either of these chips in gaming. Here's hoping for a more competitive Intel with its next-gen chips.\n\n🏆Winner: Tie\n\nMore CPU Faceoffs",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/amd-ryzen-9-9950x3d-vs-amd-ryzen-7-9800x3d-faceoff",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The GAIN AI Act Looks More Like Protectionism Than National Security",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b46e3827ffda946c",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "KG Series is a new collection of 12 FREE plugins for Windows by KageMusicKorea",
      "content": "KageMusicKorea, an independent record label and audio developer based in Seoul, South Korea, has released the KG Series, a free collection of 12 audio plugins designed to provide affordable (or rather, free) creative tools for music producers.\n\nThe KG Series is aimed at breaking down the financial barriers one might associate with music production. Of course, since you’re reading BPB, you learn about hundreds of free plugins each year.\n\nBut even so, getting twelve free plugins in one purpose-built bundle is a nice touch.\n\nThe developers describe the KG Series project as a way to help artists, both beginners and seasoned pros, focus on creativity without worrying about cost. No registration is required to download, and the complete set comes as a 0.9 GB ZIP hosted on Google Drive.\n\nEach plugin in the KG Series is lightweight and tailored toward practical mixing and sound-shaping tasks. The lineup includes multiple EQs, dynamics processors, saturation tools, and time-based effects, all designed with analog-style circuitry emulation.\n\nSome of the highlights include KG-EQP, a two-band analog-style EQ for adding warmth and subtle shaping, and KG-SSQ, a five-band precision EQ suitable for detailed mix sculpting.\n\nThere’s also KG-FREQ6, a six-band parametric EQ with wide gain ranges and a clean layout, and KG-SUB, which enhances sub-bass content with crossover and delay blending for a tighter low-end.\n\nDynamics processors in the collection include KG-COMP, a two-stage RMS compressor with vintage-style warmth controls, and KG-2A, a simple yet effective optical compressor. You also get KG-DEESSER for transparent vocal control and KG-ARCL, an auto-release limiter offering smooth, adaptive gain reduction.\n\nOn the saturation front, KG-TUBE delivers analog-style warmth with independent low and high-frequency control, while KG-SATURATOR gives more precise three-band saturation with added tonal coloring options.\n\nRounding out the set are KG-CLARITY, which boosts upper frequencies to add presence, and KG-VERB, an analog-style reverb with a flexible filter section and pre-delay controls.\n\nAll of this sounds fantastic, apart from one caveat. The plugins are Windows-only.\n\nAnd that being so, I haven’t been able to test these plugins yet because I’m currently on the road with only my MacBook. If any Windows users reading this give these plugins a try, please feel free to share your impressions in the comments.\n\nYou can download the full set directly from the KageMusicKorea website as a ZIP file. No registration is required.\n\nPlugin formats include VST3 only. Minimum system requirements: Windows PC with a modern Intel or AMD processor (SSE2 support), 8GB RAM, and a DirectX 11-compatible GPU.\n\nDownload: KG Series (Windows-only)\n\nMore:\n\nLast Updated on September 9, 2025 by Tomislav Zlatic.",
      "source": "Bedroomproducersblog.com",
      "url": "https://bedroomproducersblog.com/2025/09/09/kg-series/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "America’s Richest Sports Team Owners 2025",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/justinbirnbaum/2025/09/09/americas-richest-sports-team-owners-2025/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Orange Rivers in Alaska Signify a Color-Changing Crisis, Exposing Fish to Toxic Metals",
      "content": "In the northern Alaskan wilderness, a bizarre symptom of climate change is emerging: The rivers there are turning unnaturally orange. This phenomenon paints a worrisome picture for watersheds all across the Arctic, now faced with toxic metals being released by melting permafrost.\n\nA new study published in the Proceedings of the National Academy of Sciences shows how orange rivers may start to become a familiar sight in the Arctic as the planet warms. But for ecosystems like those along the Brooks Range — a mountain range stretching from northern Alaska to Canada’s Yukon Territory — the color change underlies a host of problems.\n\nThe Rivers Turning Orange\n\nWhen the water in a river or stream appears orange, it usually comes as a byproduct of mining activities. Oftentimes, sulfide minerals within abandoned mines are exposed to air and water, causing them to oxidize.\n\nThis process, called acid mine drainage (AMD), creates dissolved iron that changes the color of streams as it precipitates to form red, orange, or yellow sediments at the bottom of a stream. AMD also infuses streams with sulfuric acid that dissolves other heavy metals like copper, lead, and mercury into the water.\n\nThese rust-colored, highly acidic streams are often found where surface coal mining is prevalent — in the U.S., it occurs mostly in Central Appalachia and the Great Plains.\n\nBut much farther north, the orange rivers observed in the Brooks Range have nothing to do with AMD. The color-changing culprit, instead, is melting permafrost.\n\n“This is what acid mine drainage looks like,” said author Tim Lyons, a biogeochemist at the University of California, Riverside, in a statement. “But here, there’s no mine. The permafrost is thawing and changing the chemistry of the landscape.”\n\nRead More: Climate Change Threatens Global Milk Supply, Even On Cooled Dairy Farms\n\nA Toxic Threat to Fish\n\nThe new study shows how the thawing of permafrost due to global warming is letting water and oxygen reach sulfide minerals that have been confined underground for thousands of years. The weathering of sulfide-rich rocks is now delivering iron and other metals to rivers, turning them orange just like AMD would.\n\nThe new study is centered around the Salmon River, which had clear water up until the summer of 2019, when it began to show signs of discoloration that still persist to this day.\n\nAdvertisement\n\nThe researchers involved with the study were determined to find out just how toxic the river has become. After three sampling dates between August 2022 and August 2023, they found that the levels of metals in the river’s waters exceeded the EPA’s toxicity thresholds for aquatic life.\n\nMost alarming is the concentration of dissolved cadmium detected in the Salmon River. This metal, normally rare in aquatic ecosystems, is highly toxic to aquatic organisms. It can accumulate on the tissues of fish and trigger neurotoxic effects, leading to erratic behaviors that contribute to mortality. Bears and other mammals that eat fish with high cadmium levels could also suffer from oxidative stress and DNA damage.\n\nAdvertisement\n\nNonstop Melting in the Arctic\n\nThe researchers say that current metal concentrations in edible fish tissue aren’t considered hazardous to humans, although the effects on some species may have additional indirect consequences. For example, chum salmon, eaten by many Indigenous communities in the area, may have trouble spawning in gravel beds congested with fine sediment.\n\nBeyond the Salmon River, other Arctic watersheds have already begun to see the effects of permafrost thaw. One 2024 study found that 75 streams in the Brooks Range had recently turned orange and turbid (or cloudy) from an abundance of iron and toxic metals.\n\nWith so many potential contamination sources and no infrastructure in place to stop this process from occurring, the pattern of continued permafrost thaw will likely spread to more rivers across the Arctic.\n\n“There are few places left on Earth as untouched as these rivers,” said Lyons. “But even here, far from cities and highways, the fingerprint of global warming is unmistakable. No place is spared.”\n\nAdvertisement\n\nRead More: Permafrost Thaw and Wildfires Are Raising CO2 Emissions in Arctic Tundras\n\nArticle Sources\n\nOur writers at Discovermagazine.com use peer-reviewed studies and high-quality sources for our articles, and our editors review for scientific accuracy and editorial standards. Review the sources used below for this article:",
      "source": "Discover Magazine",
      "url": "https://www.discovermagazine.com/orange-rivers-point-to-a-colorful-crisis-in-alaska-exposing-fish-to-toxic-metals-48011",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Axelera Metis M.2 Max Edge AI module doubles LLM and VLM processing speed",
      "content": "Axelera AI’s Metis M.2 Max is an M.2 module based on an upgraded Metis AI processor unit (AIPU) delivering twice the memory bandwidth of the current Metis M.2 module for compute-intensive Edge AI inference applications such as large language models (LLMs) and vision language models (VLMs).\n\nThe new Metis M.2 Max also offers a slimmer profile, advanced thermal management features, and additional security capabilities. It is equipped with up to 16 GB of memory, and versions for both a standard operating temperature range (-20°C to +70°C) and an extended operating temperature range (-40°C to +85°C) will be offered. These enhancements make Metis M.2 Max ideal for applications in industrial manufacturing, retail, security, healthcare, and public safety.\n\nAxelera AI Metis M.2 Max specifications and host requirements:\n\nAccelerator – Metis AIPU’\n\nSystem Memory – 1GB, 4GB, 8GB, or 16GB memory\n\nHost Interface – M.2 2280 M-key edge connector with PCIe Gen. 3.0 x4\n\nCompatibility – Intel Core processors, AMD Ryzen processors, Arm64 (aarch64) based processors.\n\nSecurity – Firmware integrity via secure boot and secure upgrade features built on a hardware Root-of-Trust\n\nMisc An onboard power probe that can be used to automatically adjust performance to specific settings for power- and thermal-constrained deployments. Optional low-profile heatsink for cooling (reduces the height of the card by 27% over the current M.2 card)\n\nPower – Compliant with PCI-SIG’s M.2 Specification revision 4.0 (11.55 W average power, 23.1 W peak power).\n\nTemperature Range Standard – -20°C to +70°C Extended – -40°C to +85°C\n\n\n\nLike the previous Metis M.2 module, the Max variant is supported by the Voyager SDK. Axelera AI claims that native Linux support is tested on Ubuntu 22.04, while a docker guide (sign-in required) is available for other Linux distributions.\n\nThe company provides additional information about performance in the press release:\n\nM.2 Max delivers a 33% performance uplift in convolutional neural networks (CNNs) and double the token/second for LLMs and VLMs, all while staying within a typical average power range of 6.5W.\n\nInterestingly, they’ve not included any information about TOPS this time around, or even clear benchmark results. For reference, the Metis AIPU can deliver up to 214 TOPS, albeit likely not in the M.2 form factor.\n\nThe Metis M.2 Max will start shipping in Q4 2025. It is listed on the Axelera webstore without price information for now, but for reference, the existing Metis M.2 card is sold for €229,95 without a cooling solution or €241,95 with the active cooling solution shown above. The new model should be more expensive, maybe in the 300 to 400 Euros range.\n\nThanks to TLS for the tip.\n\nJean-Luc started CNX Software in 2010 as a part-time endeavor, before quitting his job as a software engineering manager, and starting to write daily news, and reviews full time later in 2011.\n\nShare this:\n\nSupport CNX Software! Donate via cryptocurrencies, become a Patron on Patreon, or purchase goods on Amazon or Aliexpress. We also use affiliate links in articles to earn commissions if you make a purchase after clicking on those links.",
      "source": "CNX Software",
      "url": "https://www.cnx-software.com/2025/09/09/axelera-metis-m-2-max-edge-ai-module-doubles-llm-and-vlm-processing-speed/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Acrobat Pro DC 2025.001.20693",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-acrobat-pro-dc-2025-001-20693/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD expands FSR 4 with drop-in support for 85 games with latest Radeon driver update - but you still need an RDNA 4 GPU",
      "content": "AMD’s latest Radeon driver update (Adrenalin Edition 25.9.1) is expanding support for FSR 4 upscaling and frame generation. According to the official patch notes, FSR 4 can now be enabled in most DirectX 12 titles that already support FSR 3.1. With the latest update, FSR 4 is now compatible with 85 games in total, however it is still limited to RDNA 4-based Radeon 9000 series GPUs.\n\nIn a separate announcement post, AMD has explained how this works and notes that enabling FSR 4 through its new driver update is a pretty seamless process. Once users update to the latest Adrenalin Edition driver, their Radeon RX 9000 Series graphics cards should automatically gain access to FSR 4. Additionally, users need to switch to FSR 3.1 in their supported game settings and then toggle FSR 4 within AMD”s Adrenalin Edition software. This enables the driver to override the in-game FSR 3.1 implementation with the newer FSR 4 version.\n\nThe company has also made it clear that this works only with DirectX 12 titles that have integrated a signed FSR 3.1 DLL as per AMD’s developer guidelines. Any games running on Vulkan, or those that use non-standard methods such as third-party plug-ins, are not compatible with the FSR 4 driver upgrade.\n\nDespite this update, AMD’s upscaling technology still trails Nvidia’s DLSS in terms of adoption and flexibility. In the meantime, community developers have stepped in with tools like OptiScaler, which can reroute existing upscalers such as DLSS, XeSS, or FSR 2 into FSR 4 with frame generation, effectively widening its reach. Similarly, certain GitHub users pointed out that FSR 3.1 games can be upgraded to FSR 4 by simply replacing the game's FSR 3.1 DLL files manually with DLL files from AMD's latest FSR SDK 2.0, although these unofficial solutions may have limitations.\n\nJust last month, the company accidentally uploaded the full FSR 4 source code to GitHub while updating its FidelityFX SDK, revealing work on an alternate int8-based version of the upscaler. This suggests AMD might be preparing broader GPU support for FSR 4 beyond its current RDNA 4 hardware.\n\n\n\nFor now, AMD’s official rollout of FSR 4 ensures stability and broader compatibility for supported titles, but the modding community’s efforts suggest a strong demand for wider adoption.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/gpu-drivers/amd-expands-fsr-4-with-drop-in-support-for-85-games-with-latest-radeon-driver-update-but-you-still-need-an-rdna-4-gpu",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Stocks Settle Higher on Hopes of Accelerated Fed Rate Cuts",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/34703550/stocks-settle-higher-on-hopes-of-accelerated-fed-rate-cuts",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Citron gets full rewrite, promises better Nintendo Switch emulation on Android and PC",
      "content": "The Nintendo Switch emulator Citron has received a long-overdue update. This release is said to be a \"complete ground-up rewrite,\" and the devs are promising significant improvements and better emulation performance.\n\n4 Reviews ← exclude selected types\n\nWhile the Nintendo Switch emulation scene got a little muddy after a popular emulator, Sudachi, was shut down, the team behind Citron has brought some good news. The Yuzu fork has just been updated to version 0.7, and per the developers, it's a \"complete ground-up rewrite.\"\n\nWith such a major overhaul, there's a big potential for a significant emulation performance bump. Most notably, the Vulkan rendering pipeline has been overhauled in the new update of Citron, and many core components of the Nintendo Switch emulator have been rewritten.\n\nAnother notable highlight is the implementation of AMD FSR 2, but as the devs note, it's currently \"half-baked and experimental.\" This means that the Nintendo Switch emulator for Android and PC could throw random crashes, and there could be visual glitches.\n\nGame compatibility issues may also arise when trying to emulate the Nintendo Switch games with FSR 2 on the emulator. Speaking of which, with support for a more recent firmware, Citron now has better compatibility for Nintendo Switch games than before (multi-platform EasySMX X20 controller curr. $49.78 on Amazon).\n\nTo be specific, with the update, Citron works with firmware 20.4.0. This is a big highlight when compared to Eden, which is also a Switch emulator, as the latter has support for firmware 19.0.1.\n\nOther than that, as the Citron version 0.7 is a complete rewrite, the devs warn that there could be UI/UX problems, memory leaks, and audio sync issues. Regardless, this update marks major progress in the development of the Nintendo Switch emulator, as the last notable update was in March 2025. For those interested in giving the update a try, it's available on the official website.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Citron-gets-full-rewrite-promises-better-Nintendo-Switch-emulation-on-Android-and-PC.1110069.0.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Windows 11 KB5065426 & KB5065431 cumulative updates released",
      "content": "Microsoft has released Windows 11 KB5065426 and KB5065431 cumulative updates for versions 24H2 and 23H2 to fix security vulnerabilities and issues.\n\nToday's updates are mandatory as they contain the September 2025 Patch Tuesday security patches for vulnerabilities discovered in previous months.\n\nYou can install today's update by going to Start > Settings > Windows Update and clicking on 'Check for Updates.'\n\nWindows Update (KB5065426)\n\nYou can also manually download and install the update from the Microsoft Update Catalog.\n\nIf you use Windows 11 Enterprise or Windows Server with Hotpatch, you'll see KB5065474 and it includes the same set of fixes, but the build number is 26100.6508.\n\nWhat's new in the September 2025 Patch Tuesday update\n\nAfter installing today's security updates, Windows 11 24H2 (KB5065426 ) will have its build number changed to Build 26100.6584, and 23H2 (KB5065431) will be changed to 226x1.5909.\n\nIn case of Windows 11 23H2, Microsoft warned that support for 23H2 ends on November 11, 2025. You'll be either force upgraded to 24H2 or stop receiving updates after the deadline.\n\nHere's the full list of improvements:\n\n[Recall] New! Recall opens to a personalized homepage that puts your recent activity and top-used apps and websites front and center, making it easy to pick up where you left off. After turning on snapshot collection, the homepage highlights key productivity features like Recent Snapshots , which show the latest snapshots to help you quickly resume tasks, and Top Apps and Websites , which display the three apps and websites you’ve used most in the past 24 hours. You can set filters in Settings to control which apps and websites are saved in snapshots. A new navigation bar on the leftmost side of the screen provides quick access to Home, Timeline, Feedback, and Settings.\n\n[Click to Do] New! When you launch Click to Do for the first time, you'll see a quick interactive tutorial. It shows how to complete tasks faster by demonstrating actions on both text and images—such as summarizing large blocks of text or removing image backgrounds. To revisit the tutorial later, select More options > Start tutorial .\n\n[General] New! When an app requests access to location, camera, microphone, or other device capabilities, Windows shows a redesigned system dialog box. To emphasize the privacy prompt, the screen dims slightly, and the prompt appears at the center of the screen.\n\n[Taskbar] New! The larger clock with seconds is now back in the notification center, displayed above the date and calendar. To turn this option on, go to Settings > Time & language > Date & time , and turn on Show time in the Notification Center . Fixed: If you accidentally click and drag your mouse across the taskbar preview thumbnail, the preview might stop working.\n\n[Search on the Taskbar] New! ​​​​​​​ When you use Search from the Windows taskbar , a new grid view will help you more quickly and accurately identify the desired image within your search. New! Search on the taskbar now provides clearer status information. If your search results are incomplete while your PC is organizing files in the background, Windows shows a notice with a link to check progress. You can dismiss the notice when you're done. There is also a status for files and folders, so you can easily tell whether they’re available online (cloud) or stored on your device.\n\n[Lock screen] New! ​​​​​​​ More widget options and support for lock screen widget personalization (previously referred to as “Weather and more”) are rolling out. After initial launch with Windows Insiders in the European Economic Area (EEA), these updates are expanding to all regions. You can add, remove, and rearrange lock screen widgets such as Weather, Watchlist, Sports, Traffic, and more. Any widget that supports the small sizing option can be added. To customize your lock screen widgets, go to Settings > Personalization > Lock screen .\n\n[File Explorer] ​​​​​​​​​​​​​​ New! Dividers now separate top-level icons in the File Explorer context menu. New! ​​​​​​​ When you're signed in with a work or school account (Entra ID), File Explorer will display people icons in the Activity column and the Recommended section at the top of File Explorer Home. Hover over or select a person's icon to open their Microsoft 365 Live Persona Card, which shows who they are and how they're connected to the file. Fixed: If you try to use the unblock open in Properties for a file, it still shows as blocked when you open Properties the next time.\n\n[Windows Hello] New! ​​​​​​​ As part of the enhanced passkey features released in September 2023, you’ll see a redesigned Windows Hello interface. These modernized visual updates support fast, clear communication that appear across multiple authentication flows, including the Windows sign-in screen, passkey, Recall, the Microsoft Store, and more.\n\n\n\nThe Windows security credential experience for passkey offers a cleaner, more intuitive interface designed to support fast, secure sign-in. You can now easily switch between authentication options such as passkeys or connected devices. Fixed: Windows Hello might recognize your face on the login screen, however it would still fail and then prompt you to enter your pin. If you continue experiencing issues, you might need to go to the Facial Recognition section under Settings > Accounts > Sign-in options and select Improve recognition . Improved: Fingerprint login after standby is now more robust.\n\n[Settings] New! Windows activation and expiration prompts match the Windows 11 design and appear as system notifications when action is required. There also have been improvements to messaging under Settings > System > Activation . New! You can go to Settings > Privacy & security > Text and Image Generation to see which third-party apps have recently used generative AI models provided by Windows. You can also choose which apps are permitted to use them—putting you in charge of your device’s AI experience. New! As part of the Copilot+ PC experience, the agent in Settings helps you quickly find and change settings. Initially available on Snapdragon®-powered Copilot+ PCs, agent in Settings now supports AMD- and Intel™-powered Copilot+ PCs. It currently works only when your primary display language is set to English. Fixed: Settings might crash if you attempt to add a security key under Settings > Account > Sign-in options .\n\n[Task Manager] New! Task Manager now uses standard metrics to show CPU workload consistently across all pages, aligning with industry standards and third-party tools. If you prefer the previous view, you can enable a new optional column called CPU Utility in the Details tab to display the earlier CPU usage value shown on the Processes page.\n\n[Widgets] ​​​​​​​​​​​​​​ New! Multiple dashboards are now available in your Widgets Board . This gives you more space for your favorite widgets and helps you stay informed with a feed that connects you to current events. A new navigation bar on the left side makes it easy to switch between your widget’s dashboard and other views like the Discover feed. After initial launch in the EEA, these updates are expanding to all regions. New! A new visual experience is available for the Discover feed on the Widgets Board . The layout is more organized, personalized, and engaging. Copilot-curated stories are now included, offering a well-rounded view of each topic with summaries, videos, and images from trusted MSN premium publishers. To customize your feed, go to Widgets > Discover dashboard > Personalization settings .\n\n[Windows Backup for Organizations] New! ​​​​​​​ Windows Backup for Organizations is now generally available! Experience seamless device transitions with enterprise-grade backup and restore. Whether you're refreshing your organization’s devices, upgrading to Windows 11, or deploying AI-powered PCs, this solution helps sustain productivity with minimal disruption, ensuring business continuity and organizational resilience.\n\n[PowerShell 2.0] Starting in August 2025, Windows 11, version 24H2, will no longer include Windows PowerShell 2.0. This legacy component was introduced in Windows 7 and officially deprecated in 2017. Most users won’t be affected, as newer versions such as PowerShell 5.1 and PowerShell 7.x remain available and supported. If you use older scripts or tools that depend on PowerShell 2.0, update them to avoid compatibility issues.\n\n[Live captions] Fixed: Changing the opacity of live captions in Settings > Accessibility > Captions > Caption Style , has no effect.\n\n[Input] Fixed: Attempting to type Chinese with an IME after copying something with CTRL + C can result in the first character not displaying. Fixed: An underlying issue related to textinputframework.dll could result in certain apps like Sticky Notes and Notepad crashing.\n\n[dbgcore.dll] Fixed: An underlying issue with dbgcore.dll could result in certain apps, including explorer.exe, crashing.\n\n[Kerberos] ​​​​​​​ Fixed: There might be an underlying crash in Kerberos when attempting to access a cloud file share.\n\n[Login] Improved: Addressed some underlying cases which could lead to you seeing a blank white screen, or a screen saying, \"just a moment\", for a few minutes when logging into your PC.\n\n[Miracast] Fixed: An issue where, on certain devices, audio would initially play but stop a few seconds after casting to a TV.\n\n[Audio] Improved: Addressed an underlying audio service stops responding which could impact the ability to play audio in certain cases.\n\n[Cryptographic Provider (known issue)] Fixed: Fixed: This update addresses an issue where you might see an error in Windows Event Viewer with Error ID 57. The event displays the following message: The 'Microsoft Pluton Cryptographic Provider' provider was not loaded because initialization failed.\n\nMost of these changes are rolling out gradually, so they'll not show up right away.\n\nMicrosoft is not currently aware of any issues with this update.",
      "source": "BleepingComputer",
      "url": "https://www.bleepingcomputer.com/news/microsoft/windows-11-kb5065426-and-kb5065431-cumulative-updates-released/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Cohere looks to shed its underdog status with a star AI hire, new CFO and $7 billion valuation — chasing ‘ROI over AGI’",
      "content": "In interviews with Fortune, Pineau, new CFO Francois Chadwick (who was previously acting CFO at Uber) and cofounder Frosst emphasized Cohere’s focus on the enterprise market. While rivals race toward human-like artificial general intelligence (AGI), Cohere is betting that businesses want something simpler: tools that deliver ROI today.\n\nUnlike peers that have tied themselves closely to Big Tech cloud providers—or, in some cases, sold outright—Cohere has resisted acquisition offers and avoided dependence on any single cloud ecosystem. “Acquisition is failure—it’s ending this process of building,” Gomez, Cohere’s CEO, recently said at a Toronto Tech Week event. The company also leans into its Canadian roots, touting both its Toronto headquarters and lucrative contracts with the Canadian government, even as it maintains a presence in Silicon Valley and an office in London.\n\nCohere was founded in 2019 by three Google Brain alumni — Nick Frosst, Ivan Zhang and Aidan Gomez, a coauthor on the seminal 2017 research paper, titled “Attention Is All You Need,” that jump-started the generative AI boom. According to Frosst, in May the startup reached $100 million in annual recurring revenue. It’s an important milestone, and there have been unconfirmed reports that Cohere projects doubling that by the end of year. But it is still a fraction of what larger rivals like Anthropic and OpenAI are generating.\n\nPineau announced her departure from Meta in April, just weeks before Mark Zuckerberg unveiled a sweeping AI reorganization that included acquiring Scale AI, elevating its cofounder Alex Wang to chief AI officer, and launching a costly spree to poach dozens of top researchers. For Cohere, her arrival is a coup and a reputational boost at a moment when many in the industry wondered whether the company could go the distance—or whether it would be acquired or fade away.\n\nCohere, the Toronto-based startup building large language models for business customers, has long had a lot in common with its hometown hockey team, the Maple Leafs. They are a solid franchise and a big deal in Canada, but they’ve not made a Stanley Cup Final since 1967. Similarly, Cohere has built a string of solid, if not spectacular, LLMs and has established itself as the AI national champion of Canada. But it’s struggled for traction against better-known and better-funded rivals like OpenAI, Anthropic, and Google DeepMind. Now it’s making a renewed bid for relevancy: Last month the company raised $500 million, boosting its valuation to nearly $7 billion; hired its first CFO; and landed a marquee recruit in Joelle Pineau, Meta’s longtime head of AI research.\n\nStory continues\n\nA focus on ROI over AGI\n\n“We have been under the radar a little bit, I think that’s fair,” cofounder Nick Frosst said. “We’re not trying to sell to consumers, so we don’t need to be at the top of consumer minds—and we are not.” Part of the reason, he added with a laugh, is cultural: “We’re pretty Canadian. It’s not in our DNA to be out there talking about how amazing we are.”\n\n\n\nFrosst did, however, tout the billboards that recently debuted in San Francisco, Toronto and London, including one for Cohere’s North AI platform that says “AI that can access your info without giving any of it away.”\n\nThat quiet approach is starting to shift, he said, a reflection of the traction it’s seeing with enterprise customers like the Royal Bank of Canada, Dell and SAP. Cohere’s pitch, he argued, is “pretty unique” among foundation model companies: a focus on ROI, not AGI.\n\n\n\n“When I talk to businesses, a lot of them are like, yeah, we made some cool demos, and they didn’t get anywhere. So our focus has been on getting people into production, getting ROI for them with LLMs,” he said. That means prioritizing security and privacy, building smaller models that can run efficiently on GPUs, and tailoring systems for specific languages, verticals and business workflows. Recent releases such as Command A (for reasoning) and Command A Vision are designed to hit “top of their class” performance while still fitting within customers’ hardware budgets.\n\nIt also means resisting the temptation to chase consumer-style engagement. On a recent episode of the 20VC podcast, Frosst said Cohere isn’t trying to make its models chatty or addictive. “When we train our model, we’re not training it to be an amazing conversationalist with you,” he said. “We’re not training it to keep you interested and keep you engaged and occupied. We don’t have engagement metrics or things like that.”\n\nLack of drama is ‘wonderful’\n\nFor Pineau—who at Cohere will help oversee strategy across research, product, and policy teams—the company’s low-key profile was part of the appeal. The absence of drama, she said, is “wonderful” — and “a good fit for my personality. I prefer to fly a little bit under the radar and just get work done.”\n\nPineau, a highly-respected AI scientist and McGill University professor based in Montreal, was known for pushing the AI field to be more rigorous and reproducible. At Meta, she helmed the Fundamental AI Research (FAIR) lab, where she led the development of company’s family of open models, called Llama, and worked alongside Meta’s chief scientist Yann LeCun.\n\nThere was certainly no absence of drama in her most recent years at Meta, as Mark Zuckerberg spearheaded a sweeping pivot to generative AI after OpenAI debuted ChatGPT in November 2022. The strategy created momentum, but Llama 4 flopped when it was released in early April 2025—at which point, Pineau had already submitted her resignation. In June, Zuckerberg handed 28-year-old Alex Wang control of Meta’s entire AI operations as part of a $14.3 billion investment in Scale AI. Wang now leads a newly formed “Superintelligence” group packed with industry stars paid like high-priced athletes, and oversees Meta’s other AI product and research teams under the umbrella of Meta Superintelligence Labs.\n\nPineau said Zuckerberg’s plans to hire Wang did not contribute to her decision to leave. After leaving Meta, she had several months to decide her next steps: Based in Montreal, where Cohere is opening a new office, Pineau said she had been watching the company closely: “It’s one of very few companies around the world that I think has both the ambition and the abilities to train foundation models at scale.”\n\nWhat stood out to her was not leaderboard glory but enterprise pragmatism. For example, much of the industry chases bragging rights on public benchmarks, which rank models on tasks like math or logic puzzles. Pineau said those benchmarks are “nice to have” but far less relevant than making models work securely inside a business. “They’re not necessarily the must-have for most enterprises,” she said. Cohere, by contrast, has focused on models that run securely on-premise, handle sensitive corporate data, and prioritize characteristics like confidentiality, privacy and security.\n\n“In a lot of cases, responsibility aspects come late in the design cycle,” she said. “Here, it’s built into the research teams, the modeling approach, the product.” She also cited the company’s “small but mighty” research team and its commitment to open science — values that drew her to Meta years earlier.\n\nPineau considered returning to academia, but the pace and scale of today’s AI industry convinced her otherwise. “Given the speed at which things are moving, and the resources you need to really have an impact, having most of my energies in an industry setting is where I’m going to be closer to the frontier,” she said. “While I considered both, it wasn’t a hard choice to jump back into an industry role.”\n\nHer years at Meta, where she rose to lead a global research organization and spent 18 months in Zuckerberg’s inner leadership circle, left her with lessons she hopes to apply at Cohere: how to bridge research and product, navigate policy questions, and think through the societal implications of technology. “Cohere is on a trajectory to play a huge role in enterprise, but also in important policy and society questions,” she said. “It’s an opportunity for me to take all I’ve learned and carry it into this new role.”\n\nThe Cohere leadership moved quickly. “When we found out she was leaving Meta, we were definitely very interested,” Frosst said, although he denied that the hire was intended as a poke at Meta CEO Mark Zuckerberg. “I don’t think about Zuck that often,” he said. “[Pineau is] a legend in the community — and building with her in Montreal, in Canada, is particularly exciting.”\n\nA move to growth and path to profitability\n\nPineau is not Cohere’s only new big league hire. It also tapped Chadwick, an Uber alum who served there as acting CFO. “I was the guy that put Uber in over 100 countries,” he noted. “I want to bring that skill set here—understanding how to scale, how to grow, and continue to deliver.”\n\nWhat stands out to him about Cohere, he explained, is the economics of its enterprise-focused business model. Unlike consumer-facing peers that absorb massive compute costs directly onto their own balance sheets, Cohere’s approach shifts much of that burden to partners and customers who pay for their own inference. “They’re building and implementing these systems in a way that ensures efficiency and real ROI—without the same heavy drag on our P&L for compute power,” he said.\n\nThat contrasts with rivals like Anthropic, which The Information recently reported has grown to $4 billion in annualized revenue over the last six months but is likely burning far more cash in the process. OpenAI, meanwhile, has reportedly told investors it now expects to spend $115 billion through 2029—an $80 billion increase from prior forecasts—to keep up with the compute demands of powering ChatGPT.\n\nFor Chadwick, that means Cohere’s path to profitability looks markedly different than other generative AI players. “I’m going to have to get under the hood and look at the numbers more, but I think the path to profitability will be much shorter,” he said. “We probably have all the right levers to pull to get us there as quickly as possible.”\n\nDaniel Newman, CEO of research firm The Futurum Group, agreed that as OpenAI and Anthropic valuations have ballooned to eye-watering levels while burning through cash, there is a strong need for companies like Cohere (as well as the Paris-based Mistral) which are providing specialized models for regulated industries and enterprise use cases.\n\n“I believe Cohere has a unique opportunity to zero in on the enterprise AI opportunity, which is more nascent than the consumer use cases that have seen remarkable scale on platforms like OpenAI and Anthropic,” he said. “This is the intersection of software-as-a-service companies, of cloud and hyperscalers, and some of these new AI companies like Cohere.”\n\nStill, others say it’s too early for Cohere to declare victory. Steven Dickens, CEO and principal analyst at Hyperframe Research, said the company “has a ways to go to get to profitability.” That said, he agreed that the recent capital raise “from some storied strategic investors” is “a strong indication of the progress the company has made and the trajectory ahead.”\n\n\n\nAmong those who participated in the most recent $500 million venture capital round for Cohere were the venture capital arms of Nvidia, AMD, and Salesforce, also of which might see Cohere as strategic partner. The round was led by venture capital firms Radical Ventures and Inovia Capital, with PSP Investments and Healthcare of Ontario Pension Plan also joining the round.\n\nVindication in ‘vibe shift’ away from AGI\n\nFor his part, Frosst sees some vindication in the rest of the industry’s recent “vibe shift” away from framing AGI as the sector’s monocular goal. In a way, the rest of the industry is moving towards the position Cohere has already staked out.\n\n\n\nBut Cohere’s skepticism about AGI hasn’t always felt comfortable for the company and its cofounders. Frosst said it’s meant that he has found himself in disagreement with friends who believe throwing more computing power at LLMs will get the world closer to AGI. Those include his mentor and fellow Torontonian Geoffrey Hinton, widely known as the “godfather of AI,” who has said that “AGI is the most important and potentially dangerous technology of our time. “\n\n“I think it’s credibility-building to say, ‘I believe in the power of this technology exactly as powerful as it is,’” Frosst said. He and Hinton may differ, but it hasn’t affected their friendship. “I think I’m slowly winning him over,” he added with a laugh — though he acknowledged Hinton would probably deny it.\n\nAnd Cohere, too, is hoping to win over more than friends — by convincing enterprises, investors, and skeptics alike that ROI, not AGI, is the smarter bet. The Toronto Maple Leafs of AI thinks it might just win the Stanley Cup yet.\n\nThis story was originally featured on Fortune.com",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/cohere-looks-shed-underdog-status-184430417.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Clearside Biomedical, Inc. (NASDAQ:CLSD) Receives $4.20 Average PT from Analysts",
      "content": "Clearside Biomedical, Inc. (NASDAQ:CLSD – Get Free Report) has earned a consensus recommendation of “Hold” from the six ratings firms that are presently covering the stock, MarketBeat reports. Five analysts have rated the stock with a hold recommendation and one has given a buy recommendation to the company. The average 12 month price objective among brokerages that have covered the stock in the last year is $4.20.\n\nA number of research firms have recently issued reports on CLSD. Chardan Capital cut shares of Clearside Biomedical from a “buy” rating to a “neutral” rating in a research report on Friday, July 18th. Needham & Company LLC cut shares of Clearside Biomedical from a “moderate buy” rating to a “hold” rating and set a $3.00 price objective on the stock. in a research report on Thursday, July 17th. HC Wainwright cut shares of Clearside Biomedical from a “buy” rating to a “neutral” rating and set a $5.00 price objective on the stock. in a research report on Friday, July 18th. Wall Street Zen raised shares of Clearside Biomedical from a “sell” rating to a “hold” rating in a research report on Saturday, May 17th. Finally, Jones Trading cut shares of Clearside Biomedical from a “strong-buy” rating to a “hold” rating in a research report on Thursday, July 17th.\n\nGet Clearside Biomedical alerts:\n\nCheck Out Our Latest Analysis on Clearside Biomedical\n\nHedge Funds Weigh In On Clearside Biomedical\n\nClearside Biomedical Price Performance\n\nA hedge fund recently bought a new stake in Clearside Biomedical stock. Investor s Fiduciary Advisor Network LLC purchased a new stake in Clearside Biomedical, Inc. ( NASDAQ:CLSD Free Report ) during the 4th quarter, according to the company in its most recent disclosure with the Securities and Exchange Commission. The firm purchased 33,800 shares of the company’s stock, valued at approximately $32,000. Hedge funds and other institutional investors own 18.75% of the company’s stock.\n\nCLSD stock opened at $0.34 on Friday. The stock has a market capitalization of $26.39 million, a PE ratio of -0.91 and a beta of 2.11. The company’s 50-day moving average is $0.52 and its 200-day moving average is $0.74. Clearside Biomedical has a 1 year low of $0.29 and a 1 year high of $1.65.\n\nClearside Biomedical (NASDAQ:CLSD – Get Free Report) last released its quarterly earnings data on Friday, August 8th. The company reported ($0.06) earnings per share (EPS) for the quarter, topping analysts’ consensus estimates of ($0.12) by $0.06. The company had revenue of $0.49 million for the quarter, compared to the consensus estimate of $0.50 million. On average, analysts anticipate that Clearside Biomedical will post -0.48 earnings per share for the current fiscal year.\n\nAbout Clearside Biomedical\n\n(Get Free Report)\n\nClearside Biomedical, Inc, a biopharmaceutical company, focuses on the revolutionizing the delivery of therapies to the back of the eye through the suprachoroidal space. It offers XIPERE, a triamcinolone acetonide suprachoroidal injectable suspension for the treatment of uveitis macular edema. It also develops CLS-AX, an axitinib injectable suspension for suprachoroidal injection, which is in Phase IIb clinical trial to treat wet AMD.\n\nFeatured Articles\n\nReceive News & Ratings for Clearside Biomedical Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Clearside Biomedical and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/09/clearside-biomedical-inc-nasdaqclsd-receives-4-20-average-pt-from-analysts/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Why Trump Went To Riyadh And What He Achieved",
      "content": "Middle East\n\nDetermining America's Role in the World\n\nAs he had done in his previous term, Donald Trump made the first foreign visit of his second term to Saudi Arabia. He had sound reasons for doing so. Saudi Arabia remains an important and stable leader in an important, but very unstable part of the world. Whether you want to secure moderate oil prices, maintain peace in the Middle East, resolve the Arab Israeli conflict or confront terrorism, it helps to talk to the Saudis. Saudi Arabia is also changing in ways that the United States has long encouraged and now seeks to support.\n\nUnfortunately, Saudi American relations had deteriorated under the Biden administration while Russia and China had become increasingly important players in Riyadh. Russia is now Saudi Arabia’s most important partner in the OPEC+ oil cartel. China is now the Saudis largest trading partner and most important oil customer. The United States has been losing influence in Riyadh, and Trump needed to reset the relationship.To a considerable extent, he succeeded.\n\nDespite plans for transition away from hydrocarbons, oil and gas remain the dominant fuels on our planet. No price affects the American economy more than the price of oil and that price is determined in a global market. Far from declining, global oil demand continues to rise by about 1 percent a year. While the United States imports very little Saudi oil, key allies such as Japan, Taiwan and South Korea remain heavily dependent on Saudi supplies.\n\nSaudi Arabia is the world’s largest oil exporter. It possesses large reserves that are both inexpensive to produce and easy to transport. At current production rates, its reserves will last at least another 50 years. More importantly, Saudi Arabia is the only country in the world that can quickly bring large volumes of oil into the market. It is this surge capacity, not its total reserves or current production rates, that make Saudi Arabia the central bank of oil.\n\nThe Saudis certainly want to maximize their oil revenues, but they have learned from bitter experience that excessively high or excessively volatile oil prices will destroy demand. Unlike many producers with limited reserves, the Saudis are long term players. They are more interested in keeping oil part of the global energy mix than maximizing short-term profits. It is in their self-interest to support global economic growth and not create a global recession as they did with the 1973 oil embargo. Thus, the Saudis increase oil production as often as they reduce it. They have often helped calm markets when supplies were interrupted by war, weather, labor unrest or U.S. imposed economic sanctions. It is very much in America’s interest that Saudi Aramco, the world’s largest oil company, remains well managed, responsive to global energy needs and based in a politically stable country.\n\nLike the United States, Saudi Arabia has a lot to lose from political unrest in the Middle East. On numerous occasions Saudi financial aid and political intervention have supported stability in places like Lebanon, Syria, Jordan and Egypt. Saudi kings Fahd, Abdullah and Salman all sought a settlement of the Arab Israeli conflict and consistently encouraged other Arab states in that direction. While Saudi Arabia is not a militarily powerful nation, its geographic location and purchasing power make it important to the U.S. military. Many times large Saudi arms purchases have reduced the unit cost paid by the American military and helped keep American defense industry production lines open. All of these issues were on the table during President Trump’s visit.\n\nFinally, talking with the Saudis is important because a quarter of the human race turns to Mecca in prayer five times a day. Millions more travel there every year for the Hajj. What is preached from the pulpit in Mecca shapes public opinion across the Muslim world. As Custodian of the Two Holy Mosques, the King of Saudi Arabia has the prestige, as well as the financial resources, to influence political outcomes in dozens of Muslim countries. Saudi-based multilateral bodies such as the Organization of Islamic Cooperation, the Islamic Development Bank and the Muslim World League all amplify Saudi influence in the Muslim World. Today the Saudis are actively promoting a moderate version of Islam as well as tolerant social practices which can serve as a model for other Muslim nations. The president sought to recognize and support those policies.\n\nFor many years oil prices and counterterrorism were often the focus of presidential visits to Riyadh, but not this time. In May of 2025, oil prices had come down from $100 a barrel in 2022 to only $65 a barrel and OPEC was, in fact, gradually increasing production. With Saudi support, the War on Terror had largely been won. The Saudis had defeated a local Al Qaeda insurrection, tightened controls on their charities, removed or retrained hundreds of mosque preachers, jailed the most radical imams and revised their school textbooks. Neither Al Qaeda nor ISIS posed a significant threat to either Saudi Arabia or the United States.\n\nInstead, as might be expected, President Trump sought to strengthen Saudi American ties through trade and investments. Not since 1973 when Secretary of State Henry Kissinger sought to tie the Saudi economy to American prosperity had there been such an intense effort to recycle petrol dollars back to the United States. Only this time most of those recycled dollars did not come directly from the United States, which actually runs a trade surplus with Saudi Arabia. They came from Aramco’s other customers, including China.\n\nThe President’s economic focus aligned with Saudi Arabia’s Vision 2030, a development plan designed to diversify the economy away from oil, balance the government budget and create jobs for young Saudis. For the plan to succeed Saudi Arabia needs regional stability and foreign investment. It was no coincidence that Trump’s visit coincided with the U.S. Saudi Investment Forum. Numerous American executives traveled with the president and signed significant contracts for military equipment, commercial aircraft, and electric generators. These are three key sectors of the Saudi economy which the United States has dominated and will now continue to do with Raytheon missiles, Boeing aircraft and GE turbines. In addition to their size, reportedly 600 billion dollars, what made these transactions interesting was the level of commitment made by American firms to help Saudi Arabia develop its own defense and manufacturing capacity.\n\nThe most significant new area of cooperation is artificial intelligence which is fast becoming the third leg of a relationship traditionally based on oil prices and counter terrorism. Because of its low electricity costs, Saudi Arabia has a competitive advantage in hosting power-hungry data centers. The kingdom welcomed technology executives from: Google, Amazon, Starlink, Salesforce, Nvidia and Oracle who accompanied the president. Agreements were reached to help the Saudi AI champion Humain build data centers and research facilities. Most significantly the Saudis were granted access to high end AMD chips.\n\nCrown Prince Mohammad bin Salman (MBS) wanted public recognition of the profound social changes he has brought to Saudi Arabia. On the streets of Riyadh, the once feared religious police have been defanged. Stores no longer rigorously enforce prayer time closure. School curriculums now contain less religion and more foreign languages. Valentine’s Day and Christmas celebrations that were once illegal are now tolerated as are private non-Muslim religious services. There is even a chief rabbi of Saudi Arabia quietly serving Jewish expatriates.\n\nMBS understands that Saudis under 30 do not want to live in their grandparents theocratic, puritanical Saudi Arabia. They want entertainment and more social freedom. He is giving it to them. There are now festivals, concerts and movie theaters to go to. Riyadh has its first gay bar, though still without alcohol. People are having fun. Saudi nationalism is on the rise while Islamic fundamentalism is declining.\n\nBy far the most striking changes relate to the role of women. The guardianship regulations, which once required a woman to seek permission from her father or husband to travel, open a bank account, go to university, get married, or even have a cesarean delivery have largely been abolished. In a place where women could once not go to school they now comprise the majority of university students. In a place where women were legally barred from most jobs there is now an aggressive affirmative action program to bring them into the workforce. Saudi women can now drive, dress as they please and sit where they like in restaurants.\n\nMany of these changes faced strong opposition in an inherently religious and conservative society. MBS has firmly controlled the pace of change. He has jailed those who complained that things were moving either too fast or too slowly. While his government has become more autocratic, MBS did not want to hear another lecture on human rights. President Trump obliged. The president praised the social changes MBS has made while stating clearly that the United States is no longer in the business of telling other nations how to manage their internal affairs.\n\nAs mentioned previously, regional stability is a prerequisite for the success of Vision 2030. Towards that end the Saudis expressed their concern over events in Syria, Palestine and Iran. The Saudis want to give Syria’s new government a chance to stabilize the country and avoid potentially exportable chaos. President Trump obliged by meeting Syria’s new leader Ahmed al-Sharaa. He lifted American sanctions on Syria thereby allowing Saudi Arabia to provide al-Sharaa with economic support. MBS’s foremost concern regarding Iran was to avoid being drawn into any military conflict. In this he succeeded.\n\nNeither leader got everything he wanted. President Trump’s call to expand the Abraham Accords fell largely on deaf ears. The Saudis view the Palestinian issue as a security problem not a morality play. They want it resolved because it is destabilizing. Any solution that does not address underlying Palestinian grievances will not solve the problem and MBS made that clear again during the President’s visit. MBS did not get a formal American security guarantee, though how much he really sought one is an open question. Nor did he get an agreement on providing American nuclear power technology where issues of enrichment and inspection remain unresolved.\n\nNevertheless, the Strategic Economic Partnership Agreement, contracts, letters of intent, memoranda of understanding and executive agreements signed during the visit reasserted Washington’s leading role in Riyadh, a role underlined by the ongoing construction of a massive new American embassy complex there. At the same time MBS received recognition as the leader of a nation that is open for business, changing in positive ways and an anchor of American influence in the Middle East.",
      "source": "Hoover.org",
      "url": "https://www.hoover.org/research/why-trump-went-riyadh-and-what-he-achieved",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Cohere looks to shed its underdog status with a star AI hire, new CFO and $7 billion valuation — chasing ‘ROI over AGI’",
      "content": "Cohere, the Toronto-based startup building large language models for business customers, has long had a lot in common with its hometown hockey team, the Maple Leafs. They are a solid franchise and a big deal in Canada, but they’ve not made a Stanley Cup Final since 1967. Similarly, Cohere has built a string of solid, if not spectacular, LLMs and has established itself as the AI national champion of Canada. But it’s struggled for traction against better-known and better-funded rivals like OpenAI, Anthropic, and Google DeepMind. Now it’s making a renewed bid for relevancy: Last month the company raised $500 million, boosting its valuation to nearly $7 billion; hired its first CFO; and landed a marquee recruit in Joelle Pineau, Meta’s longtime head of AI research.\n\nPineau announced her departure from Meta in April, just weeks before Mark Zuckerberg unveiled a sweeping AI reorganization that included acquiring Scale AI, elevating its cofounder Alex Wang to chief AI officer, and launching a costly spree to poach dozens of top researchers. For Cohere, her arrival is a coup and a reputational boost at a moment when many in the industry wondered whether the company could go the distance—or whether it would be acquired or fade away.\n\nCohere was founded in 2019 by three Google Brain alumni — Nick Frosst, Ivan Zhang and Aidan Gomez, a coauthor on the seminal 2017 research paper, titled “Attention Is All You Need,” that jump-started the generative AI boom. According to Frosst, in May the startup reached $100 million in annual recurring revenue. It’s an important milestone, and there have been unconfirmed reports that Cohere projects doubling that by the end of year. But it is still a fraction of what larger rivals like Anthropic and OpenAI are generating.\n\nUnlike peers that have tied themselves closely to Big Tech cloud providers—or, in some cases, sold outright—Cohere has resisted acquisition offers and avoided dependence on any single cloud ecosystem. “Acquisition is failure—it’s ending this process of building,” Gomez, Cohere’s CEO, recently said at a Toronto Tech Week event. The company also leans into its Canadian roots, touting both its Toronto headquarters and lucrative contracts with the Canadian government, even as it maintains a presence in Silicon Valley and an office in London.\n\nIn interviews with Fortune, Pineau, new CFO Francois Chadwick (who was previously acting CFO at Uber) and cofounder Frosst emphasized Cohere’s focus on the enterprise market. While rivals race toward human-like artificial general intelligence (AGI), Cohere is betting that businesses want something simpler: tools that deliver ROI today.\n\nA focus on ROI over AGI\n\n“We have been under the radar a little bit, I think that’s fair,” cofounder Nick Frosst said. “We’re not trying to sell to consumers, so we don’t need to be at the top of consumer minds—and we are not.” Part of the reason, he added with a laugh, is cultural: “We’re pretty Canadian. It’s not in our DNA to be out there talking about how amazing we are.”\n\n\n\nFrosst did, however, tout the billboards that recently debuted in San Francisco, Toronto and London, including one for Cohere’s North AI platform that says “AI that can access your info without giving any of it away.”\n\nThat quiet approach is starting to shift, he said, a reflection of the traction it’s seeing with enterprise customers like the Royal Bank of Canada, Dell and SAP. Cohere’s pitch, he argued, is “pretty unique” among foundation model companies: a focus on ROI, not AGI.\n\n\n\n“When I talk to businesses, a lot of them are like, yeah, we made some cool demos, and they didn’t get anywhere. So our focus has been on getting people into production, getting ROI for them with LLMs,” he said. That means prioritizing security and privacy, building smaller models that can run efficiently on GPUs, and tailoring systems for specific languages, verticals and business workflows. Recent releases such as Command A (for reasoning) and Command A Vision are designed to hit “top of their class” performance while still fitting within customers’ hardware budgets.\n\nIt also means resisting the temptation to chase consumer-style engagement. On a recent episode of the 20VC podcast, Frosst said Cohere isn’t trying to make its models chatty or addictive. “When we train our model, we’re not training it to be an amazing conversationalist with you,” he said. “We’re not training it to keep you interested and keep you engaged and occupied. We don’t have engagement metrics or things like that.”\n\nLack of drama is ‘wonderful’\n\nFor Pineau—who at Cohere will help oversee strategy across research, product, and policy teams—the company’s low-key profile was part of the appeal. The absence of drama, she said, is “wonderful” — and “a good fit for my personality. I prefer to fly a little bit under the radar and just get work done.”\n\nPineau, a highly-respected AI scientist and McGill University professor based in Montreal, was known for pushing the AI field to be more rigorous and reproducible. At Meta, she helmed the Fundamental AI Research (FAIR) lab, where she led the development of company’s family of open models, called Llama, and worked alongside Meta’s chief scientist Yann LeCun.\n\nThere was certainly no absence of drama in her most recent years at Meta, as Mark Zuckerberg spearheaded a sweeping pivot to generative AI after OpenAI debuted ChatGPT in November 2022. The strategy created momentum, but Llama 4 flopped when it was released in early April 2025—at which point, Pineau had already submitted her resignation. In June, Zuckerberg handed 28-year-old Alex Wang control of Meta’s entire AI operations as part of a $14.3 billion investment in Scale AI. Wang now leads a newly formed “Superintelligence” group packed with industry stars paid like high-priced athletes, and oversees Meta’s other AI product and research teams under the umbrella of Meta Superintelligence Labs.\n\nPineau said Zuckerberg’s plans to hire Wang did not contribute to her decision to leave. After leaving Meta, she had several months to decide her next steps: Based in Montreal, where Cohere is opening a new office, Pineau said she had been watching the company closely: “It’s one of very few companies around the world that I think has both the ambition and the abilities to train foundation models at scale.”\n\nWhat stood out to her was not leaderboard glory but enterprise pragmatism. For example, much of the industry chases bragging rights on public benchmarks, which rank models on tasks like math or logic puzzles. Pineau said those benchmarks are “nice to have” but far less relevant than making models work securely inside a business. “They’re not necessarily the must-have for most enterprises,” she said. Cohere, by contrast, has focused on models that run securely on-premise, handle sensitive corporate data, and prioritize characteristics like confidentiality, privacy and security.\n\n“In a lot of cases, responsibility aspects come late in the design cycle,” she said. “Here, it’s built into the research teams, the modeling approach, the product.” She also cited the company’s “small but mighty” research team and its commitment to open science — values that drew her to Meta years earlier.\n\nPineau considered returning to academia, but the pace and scale of today’s AI industry convinced her otherwise. “Given the speed at which things are moving, and the resources you need to really have an impact, having most of my energies in an industry setting is where I’m going to be closer to the frontier,” she said. “While I considered both, it wasn’t a hard choice to jump back into an industry role.”\n\nHer years at Meta, where she rose to lead a global research organization and spent 18 months in Zuckerberg’s inner leadership circle, left her with lessons she hopes to apply at Cohere: how to bridge research and product, navigate policy questions, and think through the societal implications of technology. “Cohere is on a trajectory to play a huge role in enterprise, but also in important policy and society questions,” she said. “It’s an opportunity for me to take all I’ve learned and carry it into this new role.”\n\nThe Cohere leadership moved quickly. “When we found out she was leaving Meta, we were definitely very interested,” Frosst said, although he denied that the hire was intended as a poke at Meta CEO Mark Zuckerberg. “I don’t think about Zuck that often,” he said. “[Pineau is] a legend in the community — and building with her in Montreal, in Canada, is particularly exciting.”\n\nA move to growth and path to profitability\n\nPineau is not Cohere’s only new big league hire. It also tapped Chadwick, an Uber alum who served there as acting CFO. “I was the guy that put Uber in over 100 countries,” he noted. “I want to bring that skill set here—understanding how to scale, how to grow, and continue to deliver.”\n\nWhat stands out to him about Cohere, he explained, is the economics of its enterprise-focused business model. Unlike consumer-facing peers that absorb massive compute costs directly onto their own balance sheets, Cohere’s approach shifts much of that burden to partners and customers who pay for their own inference. “They’re building and implementing these systems in a way that ensures efficiency and real ROI—without the same heavy drag on our P&L for compute power,” he said.\n\nThat contrasts with rivals like Anthropic, which The Information recently reported has grown to $4 billion in annualized revenue over the last six months but is likely burning far more cash in the process. OpenAI, meanwhile, has reportedly told investors it now expects to spend $115 billion through 2029—an $80 billion increase from prior forecasts—to keep up with the compute demands of powering ChatGPT.\n\nFor Chadwick, that means Cohere’s path to profitability looks markedly different than other generative AI players. “I’m going to have to get under the hood and look at the numbers more, but I think the path to profitability will be much shorter,” he said. “We probably have all the right levers to pull to get us there as quickly as possible.”\n\nDaniel Newman, CEO of research firm The Futurum Group, agreed that as OpenAI and Anthropic valuations have ballooned to eye-watering levels while burning through cash, there is a strong need for companies like Cohere (as well as the Paris-based Mistral) which are providing specialized models for regulated industries and enterprise use cases.\n\n“I believe Cohere has a unique opportunity to zero in on the enterprise AI opportunity, which is more nascent than the consumer use cases that have seen remarkable scale on platforms like OpenAI and Anthropic,” he said. “This is the intersection of software-as-a-service companies, of cloud and hyperscalers, and some of these new AI companies like Cohere.”\n\nStill, others say it’s too early for Cohere to declare victory. Steven Dickens, CEO and principal analyst at Hyperframe Research, said the company “has a ways to go to get to profitability.” That said, he agreed that the recent capital raise “from some storied strategic investors” is “a strong indication of the progress the company has made and the trajectory ahead.”\n\n\n\nAmong those who participated in the most recent $500 million venture capital round for Cohere were the venture capital arms of Nvidia, AMD, and Salesforce, also of which might see Cohere as strategic partner. The round was led by venture capital firms Radical Ventures and Inovia Capital, with PSP Investments and Healthcare of Ontario Pension Plan also joining the round.\n\nVindication in ‘vibe shift’ away from AGI\n\nFor his part, Frosst sees some vindication in the rest of the industry’s recent “vibe shift” away from framing AGI as the sector’s monocular goal. In a way, the rest of the industry is moving towards the position Cohere has already staked out.\n\n\n\nBut Cohere’s skepticism about AGI hasn’t always felt comfortable for the company and its cofounders. Frosst said it’s meant that he has found himself in disagreement with friends who believe throwing more computing power at LLMs will get the world closer to AGI. Those include his mentor and fellow Torontonian Geoffrey Hinton, widely known as the “godfather of AI,” who has said that “AGI is the most important and potentially dangerous technology of our time. “\n\n“I think it’s credibility-building to say, ‘I believe in the power of this technology exactly as powerful as it is,’” Frosst said. He and Hinton may differ, but it hasn’t affected their friendship. “I think I’m slowly winning him over,” he added with a laugh — though he acknowledged Hinton would probably deny it.\n\nAnd Cohere, too, is hoping to win over more than friends — by convincing enterprises, investors, and skeptics alike that ROI, not AGI, is the smarter bet. The Toronto Maple Leafs of AI thinks it might just win the Stanley Cup yet.",
      "source": "Fortune",
      "url": "https://fortune.com/2025/09/09/cohere-looks-to-shed-its-underdog-status-with-a-star-ai-hire-new-cfo-and-7-billion-valuation-chasing-roi-over-agi/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nissan and ChargeScape Announce New Vehicle-to-Grid Pilot with Silicon Valley Power",
      "content": "SANTA CLARA, Calif., Sept. 09, 2025 (GLOBE NEWSWIRE) -- ChargeScape , the automotive joint venture focused on electric vehicle-grid integration, and Nissan, one of the world’s largest automakers, today announced the launch of a new vehicle-to-grid (V2G) pilot in the utility territory covered by Silicon Valley Power (SVP). This pilot is possible through the California Energy Commission’s Demand Side Grid Support (DSGS) program Option 3.\n\nSilicon Valley is one of the world’s data center hotspots. The rise of AI has caused a surge in electricity demand coming from data centers, which many power grids were not designed to withstand. Forward-thinking utilities such as Silicon Valley Power are seeking innovative ways to quickly increase power supply to meet this new demand, in order to ensure grid reliability for all customers. At Nissan’s Advanced Technology Center in Silicon Valley, this pilot will use energy stored in EV batteries from Nissan electric vehicles, managed by Fermata Energy’s bidirectional chargers, to export power during periods of grid strain. ChargeScape will coordinate with market partner Leap to discharge power from Nissan vehicles and free up supply for data center loads. The pilot is part of ChargeScape and Leap’s broader California Virtual Power Plant .\n\n“Through this collaboration, we’re showcasing how electric vehicles can reinforce our communities’ electrical needs and deliver meaningful benefits to drivers,” said Rich Miller, Vice President of Vehicle Connected Services at Nissan U.S.\n\n“AI is a fundamental component of American Dynamism, and our nation’s power grids must quickly adapt to supply data centers with the energy needed to maintain America’s competitive edge in places like Silicon Valley,” said Joseph Vellone, CEO of ChargeScape. “Integrating Nissan’s EV batteries into Silicon Valley Power’s grid is a crucial first step to shoring up long-term grid reliability and rewarding the EV drivers who are part of the solution.”\n\n“At Fermata Energy, we are demonstrating how AI-enabled V2X optimization can transform electric vehicles into intelligent grid resources,” said Hamza Lemsaddek, Chief Operating Officer of Fermata Energy. “By pairing our platform with bidirectional chargers at Nissan’s Innovation Lab, we’re proving that EVs can strengthen data center reliability, support utilities like Silicon Valley Power, and deliver real economic value back to drivers and communities.”\n\n“Our work with ChargeScape has shown the powerful potential of harnessing the EVs already on the road today to tackle urgent grid reliability challenges,” said Jason Michaels, CEO of Leap. “Activating these vehicles as flexible, dispatchable grid resources is a game-changing tool to help utilities manage higher loads and unlock economic growth while putting dollars back in the hands of ratepayers. We look forward to expanding our partnership with ChargeScape to serve more communities.”\n\nThe pilot is part of ChargeScape’s mission to accelerate vehicle-grid integration and will lay the groundwork for other V2G programs across California and other U.S. states. Through this and other ChargeScape programs, participating EV drivers will earn money for helping the power grid, a mechanism the company believes will help make EVs more affordable in the long run.\n\nAbout Leap\n\nLeap is the leading platform for building and scaling virtual power plants (VPPs). Through its software-only solution, Leap facilitates fast, easy and automated access to demand response and other grid services revenue streams for the providers of battery storage systems, EV chargers, smart building technologies, and other distributed energy resources (DERs). Managing over 300,000 energy sites and devices across U.S. energy markets, Leap empowers more than 90 technology partners and their customers to unlock new value and help create a more flexible, resilient grid powered by renewable resources. Visit leap.energy to learn more.\n\nAbout ChargeScape\n\nChargeScape is a software company that connects electric utilities, automakers and electric vehicle drivers through its integrated platform. From its headquarters in Austin, ChargeScape helps stabilize electric grids by optimizing EV demand while helping EV drivers to save money on their at-home charging through cash-back and other incentives. The company currently counts BMW, Ford, Honda and Nissan as investors.\n\nAbout Nissan\n\nFor more information about our products, services and commitment to sustainable mobility, visit nissanusa.com . You can also follow us on Facebook , Instagram , X (Twitter) and LinkedIn and see all our latest videos on YouTube .\n\nAbout Fermata Energy\n\nFermata Energy is a leading platform services provider focused on intelligent grid asset management and monetization, with capabilities spanning Vehicle-to-Everything (V2X) bidirectional charging, stationary storage, and other distributed energy resources (DERs). The company’s proprietary AI-enabled optimization platform and bidirectional charging hardware transform electric vehicles and other assets into dispatchable, revenue-generating grid resources. Fermata Energy’s solutions enable utilities, fleets, and businesses to stabilize the grid, reduce costly peak demand charges, unlock new value streams, and ensure the reliable operation of critical facilities such as data centers. To learn more, please visit https://fermataenergy.com and follow the company on LinkedIn.\n\nAbout the City of Santa Clara\n\nLocated at the heart of Silicon Valley about 45 miles south of San Francisco, the City of Santa Clara truly is “The Center of What’s Possible.” Incorporated in 1852, Santa Clara covers an area of 19.3 square miles with an estimated population of 129,498. Santa Clara is home to an extraordinary array of high-tech companies, including Applied Materials, AMD, Intel, Nvidia, and Ericsson. The City of Santa Clara is also home to Santa Clara University, California’s Great America Theme Park, and Levi’s® Stadium, home of the San Francisco 49ers and future host site of Super Bowl LX and FIFA World Cup in 2026. For more information, visit SantaClaraCA.gov .\n\nAbout Silicon Valley Power\n\nSilicon Valley Power (SVP) is the trademark adopted for use by the not-for-profit electric municipal utility of Santa Clara, CA , serving residents and businesses since 1896. SVP provides power to over 60,000 customers at rates 36 to 59 percent below neighboring communities. SVP is the only full-service, vertically integrated publicly owned utility in Silicon Valley, owning generation, transmission, and distribution assets. See more at: SiliconValleyPower.com .\n\nChargeScape Media Contact\n\nchargescape@skyya.com\n\nFermata Energy Media Contact\n\nmedia@fermataenergy.com\n\nLeap Media Contact\n\ncaroline@leap.energy\n\nNissan Media Contact\n\nJeff.Wandell@nissan-usa.com",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/09/3146731/0/en/Nissan-and-ChargeScape-Announce-New-Vehicle-to-Grid-Pilot-with-Silicon-Valley-Power.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Dell reportedly cutting staff from China operations — affected employees have until October 10 to apply for internal transfer",
      "content": "Dell is reportedly laying off staff from its China operations, with affected personnel only having until October 10 to apply for open internal positions. Some of the affected departments include its EMC storage division and the Client Solution Group (CSG), which according to Digitimes, affects Dell's offices in Shanghai and Xiamen. However, the company has not publicly announced this reduction-in-force yet, so it’s unclear how many people are affected.\n\nThis latest news of layoffs comes amid the company’s restructuring to boost profitability. Around a year ago, it was estimated that Dell let go of over 12,000 positions, reducing its workforce by around 10%. The company has not been hiring externally and has even made a leadership adjustment with the departure of Yvonne McGill as its CFO, after nearly 30 years of working with the PC maker. Dell did not say why McGill is leaving her position, but clarified that it was not related to the company’s financial reporting or internal controls.\n\nThe EMC storage division is the company’s enterprise storage arm, focusing on delivering solutions to storage, server, and data protection services to IT departments, data centers, and other institutions. On the other hand, CSG delivers end-user hardware, like laptops and monitors, to consumers and companies. These divisions are historically important for Dell’s presence in China, but the changing geopolitical landscape and market demands are making strategic contraction a necessity for the company to adjust to shifting realities.\n\nOther companies have also been caught in the crossfire between the U.S. and China’s trade war. Microsoft closed its AI and IoT labs in the East Asian nation last year, with Redmond asking nearly 10% of its China-based workforce to relocate to the U.S., Ireland, Australia, or New Zealand. IBM also shuttered its research and development facilities in the country in August 2024, resulting in the retrenchment of over 1,000 people.\n\nEven Nvidia is facing some trouble in China after the U.S. banned the export of its H20 AI GPUs in April. The White House eventually allowed it to sell the advanced chips again, this time by issuing export licenses to the company. However, it only allowed this after Nvidia and AMD agreed to share 15% of their China revenue with the federal government. Deliveries still aren’t being made, though, as the Commerce Department still has a massive backlog of export licenses to process, and Washington’s lawyers are still figuring out the legality of the 15% ‘export tax’.\n\nFollow Tom's Hardware on Google News , or add us as a preferred source , to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/dell-reportedly-cutting-staff-from-china-operations-affected-employees-have-until-october-10-to-apply-for-internal-transfer",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Retired Japanese racehorse Haru Urara that inspired the 'Umamusume' character dies at 29",
      "content": "Live Events\n\nHaru Uraru inspired Umamusume\n\nHaru Urara's life and career\n\nas a Reliable and Trusted News Source Addas a Reliable and Trusted News Source Add Now!\n\n\n\n\n\n(You can now subscribe to our\n\n(You can now subscribe to our Economic Times WhatsApp channel\n\nRetired Japanese racehorse Haru Urara that inspired the Umamusume character, has died. Haru Urara saw an unexpected surge in popularity in recent months after the global launch of a mobile game has died at the age of 29, reported The Strait Times.Despite not winning a race during her professional career, Haru Urara was beloved for being \"the shining star of losers everywhere.\" Once dubbed “the shining star of losers everywhere”, Haru Urara died in the early hours of Sept 9.According to Yahoo Japan, Haru Urara passed away in the early hours of Tuesday, September 9 surrounded by staff members from Martha Farm in Chiba prefecture, where she was kept in her twilight years. Her cause of death was revealed to be Horse Colic, a condition that occurs when gas builds up in the intestines due to poor digestion of food and slows down intestinal movement. It is a dangerous condition in horses, with a high mortality rate.Dubbed as “the shining star of losers everywhere”, Haru Urara became sick on September 8 and a vet was called, Yuko Miyahara, her caretaker at Martha Farm told Friday Digital.The official Umamusume: Pretty Derby social media accounts also released a statement where developer Cygames' shared their condolences over Haru Urara's passing. \"It is with heavy hearts that we share that Haru Urara passed away on September 9. The legendary racehorse's legacy serves as the inspiration for the character of the same name in Umamusume: Pretty Derby. We share our condolences to all the staff involved in Haru Urara's care,\" the post read.Staff members accompanied her through the night, but her condition suddenly worsened at dawn on Sept 9, leading to her death. “Haru Urara was 29 years old, which would be nearly 90 years old in human terms, but she was in great health until yesterday,” Ms Miyahara told Friday Digital.“Recently, more and more people, not only from Japan but also from overseas, have been coming to see Haru Urara. So it’s really unfortunate.” Haru Urara was still fielding visits from fans, and was reportedly still in good health the weekend before it passed away.Born on February 27, 1996 in Hokkaido, Haru Urara was sired by Nippo Teio, a top-class racehorse. Her name means \"Glorious Spring\" or \"Gentle Spring\" in Japanese. Despite her strong lineage, Haru Urara never managed to win a single race during her professional career. She debuted on 17 November, 1998 at the Kōchi Racetrack amd placed last among fifth racers. She would continue competing in races once or twice every month without winning over the course of the next four years.After losing 80 consecutive races, Haru Urara's story was picked up by Japanese media in June 2003. She became a household name in Japan as a result and was branded as “the shining star of losers everywhere” for continuing to race despite her infamous losing streak.Haru Urara ran her last race in August 2004, retiring with a record of zero wins and 113 losses. However, Haru Urara did finally win a race after she retired, setting the best time in a time trial race for older horses in May 2019.In July 2025, Haru Urara dominated headlines again following the global launch of the Uma Musume Pretty Derby mobile game, where she appeared as a pink-haired anime character.When Umamusume: Pretty Derby launched in Japan in February 2021, Haru Urara was among the original characters featured alongside fan favorites like Special Week, Silence Suzuka, Tokai Teio, Mejiro McQueen, Gold Ship, and Grass Wonder, among many others. The game quickly became a hit in Japan, but its global release on June 26 this year sparked an even bigger wave of enthusiasm.Haru Urara’s heartfelt story struck a chord with players around the world, inspiring many to contribute funds through the Fresh Hay Bank—a crowdfunding platform where fans could donate fresh ryegrass to support retired and celebrated racehorses. The overwhelming response in July was so immense that the website crashed, with over 2,500 kilograms of ryegrass gifted to Haru Urara.Several other racehorses that inspired Umamusume characters, such as Meisho Doto, Hishi Miracle, Nice Nature, Fine Motion, and Tanino Gimlet, also received generous donations through the Fresh Hay Bank. Haru Urara is the second Japanese racehorse used as a basis for an Umamusume character to pass away this year after Grass Wonder, who died in early August at 30 years of age.",
      "source": "The Times of India",
      "url": "https://economictimes.indiatimes.com/news/international/global-trends/us-news-retired-japanese-racehorse-haru-urara-that-inspired-the-umamusume-character-dies-at-29/articleshow/123785780.cms",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD 25.9.1 Driver Enables FSR 4 In FSR 3.1 “DX12” Games, Expanding The List To 85+ Titles, Several Fixes & Improvements For Radeon GPUs - Wccfte",
      "content": null,
      "source": "Slashdot.org",
      "url": "https://slashdot.org/firehose.pl?op=view&amp;id=179098616",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD’s AI-powered FSR 4 upscaling is now available in most FSR 3.1 games - The Verge",
      "content": "Catch up on stories from the past week (and beyond) at the Slashdot story archive",
      "source": "Slashdot.org",
      "url": "https://slashdot.org/firehose.pl?op=view&amp;id=179098264",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Borderlands 4 will get a day one patch, but Gearbox CEO warns not to expect 'a miracle' if you're playing on an older PC",
      "content": "We now know that Borderlands 4 will get a day one patch\n\nGearbox CEO Randy Pitchford said that it \"does a lot\" but warned that it won't do much for those using older hardware\n\nHe said the game should be \"unplayable\" for those below the recommended spec\n\nWe now know that upcoming co-op looter shooter Borderlands 4 will be getting a day one patch, though the CEO of developer Gearbox has warned that it won't be a magic bullet for those playing on dated hardware.\n\nSpeaking in an X / Twitter post, CEO Randy Pitchford said that while \"the day one patch does a lot\" with regards to performance, those using a PC below the minimum recommended specs should expect the game to be \"unplayable\".\n\nIf you need a quick reminder, here are the minimum and recommended system requirements for Borderlands 4 found on the official Steam page.\n\nMinimum:\n\nOS: Windows 10 / Windows 11\n\nWindows 10 / Windows 11 Processor: Intel Core i7-9700 / AMD Ryzen 7 2700X\n\nIntel Core i7-9700 / AMD Ryzen 7 2700X Memory: 16 GB RAM\n\n16 GB RAM Graphics: NVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580\n\nNVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 Storage: 100 GB available space\n\nRecommended:\n\nOS: Windows 10 / Windows 11\n\nWindows 10 / Windows 11 Processor: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nIntel Core i7-12700 / AMD Ryzen 7 5800X Memory: 32 GB RAM\n\n32 GB RAM Graphics: NVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nNVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580 Storage: 100 GB available space\n\nThe page also notes that SSD storage is required and Pitchford's post warns that using a slower hard disk drive (HDD) could lead to \"hitching\".\n\nAll things considered, it requires a pretty beefy setup, especially in comparison to the previous game.\n\nGet daily insight, inspiration and deals in your inbox Sign up for breaking news, reviews, opinion, top tech deals, and more. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n\"It's a big, bold, new, seamless world,\" explained Pitchford. \"I'm sorry to say that older hardware may not provide buttery smooth performance for the latest gen AAA games, as has always been the case since the dawn of PC gaming.\"\n\nIf your PC isn't up to the task, Borderlands 4 is also releasing for PlayStation 5 and Xbox Series X and Series S on September 12.\n\nA Nintendo Switch 2 version is set to follow a little later on October 3.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/gaming/borderlands-4-will-get-a-day-one-patch-but-gearbox-ceo-warns-not-to-expect-a-miracle-if-youre-playing-on-an-older-pc",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Confirms Arrow Lake Desktop Refresh Next Year, Nova Lake Desktop CPUs With An 18A Tile In Late 2026, 14A More Suitable For External Customers, Every 7 Out of 10 PC Has Intel Inside",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/intel-arrow-lake-refresh-2026-nova-lake-desktop-late-2026-18a-14a-updates/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Beefy Borderlands 4 system requirements promise \"solid performance on older PC hardware,\" but after Randy Pitchford's warnings about \"realistic expectations\" I'm starting to feel a little scared",
      "content": "Gearbox has confirmed it really was serious about those beefy Borderlands 4 system requirements that went live on the game's Steam page months ago. While some older hardware is supported here, the recommendations are still pretty mighty, and with Randy Pitchford's recent warnings about the game's performance you might, indeed, want to keep your expectations in check.\n\nIn a new blog post, Gearbox reiterates its previously announced specs, but now promises that the minimum loadout can offer \"solid performance on older PC hardware.\"\n\nThe hardware in question here is an Intel Core i7-9700 or AMD Ryzen 7 2700X paired with an Nvidia GeForce RTX 2070 or AMD Radeon RX 5700 XT and 16GB of RAM.\n\nThose are, technically, older pieces of hardware, but they're still fairly meaty and much closer to the recommended specs for most modern games. Another key missing detail is what \"solid performance\" means. Is that 60 FPS at 1440p? 30 FPS at 1080p? Better? Worse? Somewhere in between? Your guess is as good as mine.\n\nThere isn't a huge gap between the minimum and recommended specs, either. The higher end will give you \"the intended experience for Borderlands 4, striking a solid balance of smooth performance and graphical detail.\" Again, there aren't any details on what that means, but to achieve it you'll need an Intel Core i7-12700 or AMD Ryzen 7 5800X paired with an Nvidia GeForce RTX 3080 or AMD Radeon RX 6800 XT and 32GB of RAM.\n\nWith Pitchford actively warning \"everyone to have realistic expectations for performance\" ahead of the Borderlands 4 release times, I think it's fair to guess you won't be able to run this game on a potato. Exactly how well it runs on machines that meet the recommended spec, however, remains to be seen, and we won't have the answer to that question until later this week.\n\nIf you want details on the Borderlands 4 classes as you start considering your build ahead of launch, you know where to click.",
      "source": "GamesRadar+",
      "url": "https://www.gamesradar.com/games/borderlands/beefy-borderlands-4-system-requirements-promise-solid-performance-on-older-pc-hardware-but-after-randy-pitchfords-warnings-about-realistic-expectations-im-starting-to-feel-a-little-scared/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "VicRoads: still in the 20th century",
      "content": "AI: enough! Topic: technology, general, opinion Link here\n\nSunday's detailed investigation of generative artificial intelligence should have been enough, but it occurred to me that there was one thing I hadn't tried: graphics. OK, draw me a caricature of Greg Lehey.\n\nGoogle Gemini came up with this:\n\nOf course I don't need to like the results, but this shows very little understanding: no mention of BSD, just Linux (or even “Linix”). Yvonne tells me that it looks nothing like me. Compared to the text results, quite disappointing.\n\nAnd that was all. My other bots all couldn't do it. But their attempts were worth mentioning:\n\nChatAI\n\nI'm unable to draw images directly, but I can help you imagine a caricature of Greg Lehey! Picture a gentleman with a thoughtful expression, perhaps with glasses perched on his nose, and a hint of a smile suggesting a keen sense of humor. His hair might be slightly tousled, giving him a scholarly yet approachable look. You could exaggerate his features, like giving him a larger forehead to symbolize his intellect or a prominent chin to represent determination. Add a background filled with books and computers to reflect his interests in technology and writing\n\nI suppose that's acceptable for as far as it goes.\n\nClaude\n\nClaude did the best with the diary entry, but it failed completely with the caricature:\n\nClaude: I'd be happy to help you create a caricature, but I'll need a bit more information! There are likely multiple people named Greg Lehey, and I want to make sure I'm drawing the right person..\n\nClaude, you know who I am. There are “likely” multiple people named Greg Lehey? That wasn't a problem on Sunday. And as it happens, there is nobody else that I can find with the same name as mine. But OK, draw me a caricature of Greg Lehey, the FreeBSD person.\n\nI can't create visual caricatures or drawings as I'm a text-based AI. However, I'd be happy to help you in other ways: Written description: I could write a humorous written \"caricature\" or character sketch of Greg Lehman (assuming you meant Greg Lehman, a notable FreeBSD contributor) that captures his programming style, contributions to FreeBSD, or personality traits in an exaggerated, caricature-like way.\n\nWhat a cop-out! Now it says that it can't draw. And it comes up with a fictive Greg Lehman. That's completely useless.\n\nDeepSeek\n\nAs before, DeepSeek is inventive:\n\nWhile I can't physically draw for you, I can create a detailed \"blueprint\" for a caricature of the legendary BSD developer Greg \"Groggy\" Lehey. An artist could follow this description to create the perfect caricature. Here is a description designed for an artist to illustrate. Caricature of Greg \"Groggy\" Lehey Concept: The caricature should capture his iconic, jovial, and slightly mischievous personality, deeply intertwined with his life's work: BSD and Unix. Key Features to Exaggerate: The Beard and Hair: This is the #1 feature. Exaggerate his magnificent, full, and sprawling white beard. Make it vast and wizard-like, almost as if it's its own entity. It should be big enough to have a Daemon (the BSD logo) peeking out from within the whiskers, as if it lives there. His hair (what's visible under his hat) should be similarly wild and unkempt. The Headwear: He is almost never seen without a hat. Draw a slightly battered, well-loved flat cap or a beret perched on his head at a jaunty angle. Where did it get the hat from? I am almost never seen with a hat. The Expression: A wide, knowing, and cheerful grin. His eyes should be crinkled with laughter and wisdom, suggesting he's both a kind mentor and someone who knows where all the bugs in the code are hidden. The Props & Surroundings: In his hand: Instead of a coffee mug, he should be holding a massive, steaming beer stein. This is a nod to his famous \"Buy me a beer\" link on his website and his good-humored nature. Steaming beer? I can't even imagine that. And instead of referring to my brewing activities, it refers to a fictive “buy me a beer” link, which may be related to Poul-Henning Kamp. Under his arm: A well-worn copy of his magnum opus, \"The Complete FreeBSD\" book. Background Element: Have a Tux (the Linux penguin) peeking from around a corner, looking slightly nervous or annoyed, while Groggy pays it no mind. This playfully hints at the good-natured rivalry between BSD and Linux. Code: Faint lines of C code ( #include <beard.h> , printf(\"Cheers!\n\n\"); ) can be subtly woven into the texture of his shirt or the background. Overall Vibe: The image should feel warm, intelligent, and full of character. He is the friendly, brilliant, and slightly eccentric \"Unix Beard\" wizard, a beloved figure in the open-source community. Color Palette: Warm tones. Earthy browns for the hat, a rich color for the shirt (green or blue), the brilliant white of the beard, and the gold of the beer.\n\nStill, I suppose that could produce something useful. But where are all the image generators? Do I want to look? I've spent enough time on this already.\n\nWhy don't people read any more? Topic: language, general, technology, opinion Link here\n\nRecently I saw (but didn't read) a newspaper article, possibly from the New York Times, asking why people don't read books any more. The answer appears simple: information overload. When I was a lad I read lots of books, but it has been some time since I finished reading any, and then the relatively thin “Brave New World”.\n\nBut then we watched A Town Like Alice, and Yvonne borrowed the book. I have always liked Nevil Shute, and I have a number of his books, so I read it when she finished. It took me two weeks. While reading I was continually following up on details mentioned in the book—that's what the web is for, after all. In general, I ended up with a much broader view than I would have had if I had just read the book.\n\nAnd how did I like it? Not much. Clearly it's two different stories stuck together: the ordeals in Malaya at the hand of the Japanese occupation and the transformation of a tiny bush village in Queensland into a small town. The latter, in particular, seems very improbable.\n\nThe geographical details are what interested me most. Particularly in Malay(si)a I knew most of the real places. But I'm puzzled about why Shute spends a lot of time in the area Maran and Jerantut in the Jengka Triangle, places that must have been almost completely unknown at the time, but puts the women in a place called Kuala Telang “about half-way between Kuantan and Kota Bahru”. There is a town in that position, but it's called Kuala Terengganu, and it's a big town (capital of the state of Terengganu), not a small village. My guess is that Shute had never heard of it.\n\nSpelling is also strange. In the first half of the book, Kota Bharu was spelt “Kota Bahru”, and in the second half “Khota Bahru”. Tennant Creek became “Tennants Creek”. These spellings are the same both in the online book and the physical book that I read. And there are a couple of irritating US Americanisms that I don't understand: the animals central to the theme are called alligators, not crocodiles. The stockmen use lariats.\n\nThen there's the question of racial attitudes. The local aborigines (or aboriginals, to use the modern politically correct term) are called “boongs” or “abos”. Both are offensive nowadays. And there was talk of racial segregation, a separate milk bar for the boongs. This would have been about 1948, the time of my birth. Did such segregation really exist then?\n\nMy favourite one, though, is when the main characters (Jean and Joe) fall in love, and she decides not to sleep with him until after they are married. Given that Joe had been crucified in the first half of the story, I was half guessing that he might have been castrated at the same time, and Jean would not have found out until too late.\n\nIn summary: reading books has become much more of an exercise than it used to be. For light entertainment we have TV. I don't think I'll read another novel for some time to come.\n\nPredicting the past Topic: general, technology, opinion Link here\n\nI keep a close eye on the weather forecasts from the Bureau of Meteorology, both of them. There's one on the web and another for mobile phones. They don't often agree with each other, and of course they're both frequently wrong.\n\nToday, though, the mobile phone app excelled itself. We finally have rain, 6 mm over the last 24 hours. Or, as the app put it,\n\nPart of the app is a rainfall map showing precipitation. That showed that there was much more rain. How can that happen?\n\nWhatsApp: bug after bug? Topic: technology, opinion Link here\n\nI've been trying for a week now to set up video telephony on fossil, Yvonne's mobile phone. Somehow the “modern” approach to user interfaces shows itself at its worst here. But I had come to the conclusion that if I can work beyond WhatsApps bizarre interface, and explain it to Yvonne so that she doesn't have a panic attack every time she uses it, we might have something useful, especially since WhatsApp can communicate by an Internet link, which could be much cheaper.\n\nOK, try out on hirse first. It doesn't have a SIM card, so any communication has to go by the Internet. Migrate my main number to hirse. No problem. Make a call. Some message like “need to use the phone network”. Oh.\n\nTry calling in. The problem: hirse has the phone number associated with a SIM card in albo, which has a different WhatsApp number. Which does WhatsApp call? albo! Somehow there's more to this than meets the eye.\n\nWhen Yvonne got back from shopping, I changed her WhatsApp number to the number of second SIM on her phone. All sorts of things didn't work, and it couldn't call the number on hirse. hirse claimed that she wasn't registered, though I had set the “notify contacts” during the migration. In the end I moved the number back to the old one. And things still didn't work correctly! In particular, I could call the number, but WhatsApp didn't respond in any way, not even registering a missed call. Went through the settings and set tones for all notifications. Still no response. Restart the app. No response.\n\nNothing for it, the Microsoft solution: reboot. And yes, now it responds. Clearly some kind of bug. And it repeats the call tone for every notification, including messages. Oh, my bad. Get rid of the tone. Sorry, there's no provision for that. Select something at random, since it's too polite to play the tone when you're selecting it. I still get the ring tone for messages! I can't see any explanation except that it's another bug. It was getting late, so I turned off sounds to wait until tomorrow.\n\nAll this is made worse by the horrible user interface. So far I haven't found a way to display the associated phone number in the contact details. At one point I made the mistake of using the same name (mine) for both my phones, so there was no way at all to find out what “number” it had called.\n\nI hate WhatsApp! Topic: technology, general, opinion Link here\n\nMore fun with WhatsApp today. The first question, which decides whether it's even worthwhile: can I make a call over the Internet? Yesterday's experiments were overshadowed by other bugs. Today I tried making a call from fossil (Yvonne's phone) to hirse, the one without a SIM card. I have set it up with the main number of albo, so a normal call to that number should go to albo, and a WhatsApp call should go to hirse. Does it?\n\nYes! So yesterday's issues were probably due to other bugs.\n\nAnd the incorrect notification tones? Gone since the last reboot, Yvonne says. But later she changed her mind: once again the wrong tone when all notification tones were turned off.\n\nDammit, begone, WhatsApp! Removed it. Reinstalled it. And how about that, setup was almost completely without problem. She lost her image (“Avatar”, “The manifestation of a god in bodily form on earth” according to the OED). We can live with that. And somehow now everything Just Works—until the next unpleasant surprise.\n\nApart from that and the horrible user interface, established that you can change an audio call into a video call simply by pressing the button with the box with a loudspeaker on the right:\n\nInterestingly, it only works in one direction. To go in the other direction requires that the person at the other end do the same.\n\nVirtualBox again Topic: technology, photography, opinion Link here\n\nDxO PhotoLab 9 is out, and it looks worth trying. Time to reinstate one of my Microsoft virtual machines, which run under VirtualBox.\n\nI stopped using VirtualBox on hydra a year ago, though it was the main reason that I had so much memory (192 GB): I ran into network problems that I couldn't fix.\n\nNow FreeBSD has a port of VirtualBox 7. Time to try again? Tried first on dereel, with only 24 GB of memory. Where's my HOWTO? All fine, but it doesn't tell me how to add an existing VM. It must be in this diary somewhere, but where? I really should keep these HOWTOs up to date.\n\nStarting up the GUI was different from before, of course. And it wanted to set things up in the root file system. To go elsewhere I had to do this horrible tree walking. Finally I got to where I wanted (/src/VirtualBox/echuca). Tried to create a new VM. “Can't overwrite machine folder...\". What does that mean? They should know better than to call a directory a folder, but what's a “machine folder”? Lots of experimentation, continually being returned to the /root directory and having to climb my way out again. What does “help” say? Nothing. I wonder if the port forgot to install something important. After a while I discovered that it really wanted the parent directory /src/VirtualBox, but then I ran into other issues.\n\nAfter some time decided to create a new VM with the old virtual disk. Link? Yes, but VirtualBox detected the UUID and used the old name.\n\nYes, there are other possibilities. But I think that the best is to go through my diary and extract the information that I need to do things sanely. And maybe I should use the commands rather than the GUI, which seems to be getting more stupid as time goes on.\n\nWhatsApp an Avatar? Topic: technology, general, opinion Link here\n\nYesterday I established that an Avatar is a earthly manifestation of a Hindu god, but WhatsApp apparently wants to elevate Yvonne and me to deities. Until then, only initials appear to identify us on calls.\n\nOK, how do we do that? Settings, of course, “make your own avatar”, “Create from selfie”. OK. Take a suitably horrified photo of myself. Briefly it showed “There was an error with the avatar gen...”, so briefly that I didn't see it the first three times. What does that mean? Why can't it finish its sentences? So instead it presented me with a manual generation.\n\nWhy? What does the half message mean? It's repeatable on two different phones. And there seems to be no way to just add a normal photo. What a mess!\n\nVirtualBox progress Topic: technology, opinion Link here\n\nSo what's wrong with my VirtualBox installation? My current situation was exactly what I had a year ago: most VMs worked, but Microsoft VMs had networking problems. They could send data, but they didn't see the replies, so they hung in ARP. I attributed that to the version of VirtualBox (6.1.50 r161033), so I waited until version 7 came out. And then I discovered that I had exactly the same problem.\n\nThat didn't help just getting things running. After some searching, discovered that VirtualBox stores a configuration in the home directory, ~/.config/VirtualBox/ with a number of files, including log files that have no business there, but importantly VirtualBox.xml. OK, make a copy of that on dereel, and how about that, VirtualBox came up with all the VMs I knew.\n\nStart disaster, the only VM that would fit in dereel's memory.\n\nVT-x is disabled in the BIOS for all CPU modes (VERR_VMX_MSR_ALL_VMX_DISABLED).\n\n\n\nOh. There was something there, but can the twins help? Yes, specifically for a ThinkCentre:\n\nOnce in the BIOS, use the arrow keys to navigate to the Advanced tab. From the Advanced menu, select CPU Setup and press Enter. Look for an option labeled Intel(R) Virtualization Technology and select it. Using the arrow keys, change the setting from Disabled to Enabled.\n\nAfter that and rebooting, and with a change of network adapter name, it still didn't start. I got this message:\n\nX86_CPUID_AMD_FEATURE_EDX_AXMMX is not supported by the host but has already exposed to the guest [ver=19 pass=final] (VERR_SSM_LOAD_CPUID_MISMATCH).\n\nMore help from the twins. The saved state includes information from an AMD processor (hydra), but this is Intel. Discard saved state and start again.\n\nAfter that, and with a change of network adapter name, it started. I got this message, which I haven't seen before, but which seems harmless:\n\nerror: XDG_RUNTIME_DIR is invalid or not set in the environment.\n\nThat variable isn't set on hydra either.\n\nWe're still not done. Trying to start an xterm from current gave me the message\n\nThe Virtual Machine reports that the guest OS does not support mouse pointer integration\n\nWhat's that? Gemini tells me:\n\nThe message \"The Virtual Machine reports that the guest OS does not support mouse pointer integration...\" in a FreeBSD virtual machine is common and means you need to install and configure the necessary guest additions for the mouse to work seamlessly. FreeBSD does not include these drivers out of the box, so you must install them yourself.\n\nThat sounds like the Ports Collection. But there is no additions package for VirtualBox 7.1, only for 6.50 and 5.2. Mañana.\n\nOn with disaster. So: ARP issue? While messing around on disaster, found the help message for ARP. It uses Unix-style option delimiters, and -s sets a permanent MAC address. OK, if this is an ARP issue, we can fix that:\n\nOh: Microsoft has a different format for MAC addresses. Try again:\n\nAnd that as Administrator . Time to ask the twins.\n\nQ: What does \"The ARP entry addition failed: Access is denied\" when running CMD as administrator under \"windows\" 10? A: The \"ARP entry addition failed: Access is denied\" error in Windows 10, even when running Command Prompt as an administrator, typically happens when trying to add a static Address Resolution Protocol (ARP) entry for a reason other than a permission issue.\n\nInteresting. “Access is denied” is not a permission issue? Something's wrong here, either Gemini or Microsoft. My money is on Microsoft.\n\nAnd that's what Gemini suggests too:\n\nUse netsh instead: In some cases, especially on newer versions of Windows, the arp command may have issues with Access is denied errors even when the user has administrator privileges.\n\nSo I ended up with this simple invocation:\n\nAnd how about that, it worked. Well, at least it put the address in the ARP table, and I was able to ping out, so disaster knew the address. But it still didn't hear any reply.\n\nYet another question to Gemini:\n\nWhat could cause a Microsoft guest under VirtualBox to send network data but not receive it, when other guests have no problem with the same configuration?\n\nThe obvious answer: firewall. Check to be on the safe side. No, no firewall enabled. How about an Ethernet adapter issue?\n\nIf you are using an Intel PRO/1000, try switching to a different type, such as the AMD PCnet-FAST III.\n\nOK, try that. No improvement. Next idea: this video\n\nOK, try anything once. Follow the instructions step by step, none of which showed any obvious issues. Change the interface back to (specifically) Intel PRO/1000 MT Deskop (8254EM). Not much hope there: that's what I had.\n\nBut it worked! My final configuration looks identical to the start configuration. What changed? There's something lurking under the surface that I don't understand. Can I now get it to run on hydra?\n\nMore VirtualBox pain Topic: technology, opinion Link here\n\nYesterday I finally got networking working using VirtualBox 7.1 and Microsoft “Windows” 10. Time to refine a few things. First, start the windows on hydra:0.0, a 1920×1080 display, rather than on hydra:0.1, which has 3840×2160, giving windows that are too small.\n\nBut it didn't work! I could start on hydra:0.1, but on hydra:0.0 nothing happened. Is there some kind of built-in memory in the configuration file?\n\nSo, time to upgrade current.lemis.com, another VM running FreeBSD-CURRENT. It was a year out of date.\n\nStart a make buildworld , not for the first time. But nothing happened!\n\nFurther investigation showed that I had a network hang. And disaster was also hanging! Shut down disaster and current regained network access—for a while. Then it hung again.\n\nThis seems worse than my experience on hydra with VirtualBox 6.5. Tried it there and it worked.\n\nWhat a pain! What does Google Gemini say?\n\nQ: Are there known networking issues with VirtualBox under FreeBSD? A: Yes, there are known networking issues and quirks with VirtualBox when used as a host on a FreeBSD system. While VirtualBox works, it is not an officially \"supported\" host platform by Oracle, which means users often have to rely on the community and package maintainers to troubleshoot and resolve issues. (much irrelevant information omitted) Users sometimes experience slow network speeds, particularly with upload speeds, when using bridged adapters. This can be more pronounced on specific emulated network card types. While VirtualBox can function as a host on FreeBSD, it is not a \"fire-and-forget\" solution... If you encounter speed or reliability issues, experimenting with different emulated network adapter types can often resolve the problem.\n\nThat's not encouraging, though it doesn't directly relate to my problems. But what else can it be? Two different versions of FreeBSD, two different machines, two different versions of VirtualBox. Does it work better on Linux? That would be a real let-down, but possibly I should try it. How much pain would that be?\n\nTesting RSS feeds Topic: technology Link here\n\nI write all my web markup myself, with the aid of a number of PHP scripts. The result is that the RSS feed looks nothing much like my sources. So when something goes wrong with the markup, it's hard to find where, not helped by things like the W3.org validator, which typically points to where the error is detected, not where it occurred, and which at the moment caches input, so even after fixing the problem it reports the old problem.\n\nCallum Gibson is the main user of RSS feeds whom I know of. He pointed me to this validator. It also points to where the error was found, but at least I can try things and repeat them. That fixed an issue I had with earlier this month, where the error was over 100 lines from where it was detected.\n\nChasing the VirtualBox bug Topic: technology Link here\n\nSo why was VirtualBox version 7.1 on dereel even worse than version 6.50 on hydra? One possibility might be that the VMs themselves were NFS mounted. OK, find a 1 TB disk and copy them there. Put it in in place of the DVD drive, and was amazed to find that it came up as /dev/ada0, relegating the system disk to /dev/ada1 and requiring manual intervention (/etc/fstab) to continue. How could that happen?\n\nThen copying the VMs from hydra. That took a few hours, of course, so I'll continue tomorrow.\n\nWhile looking for the disks also found one marked “MS “Windows” 10 disgust”, dated 10.XII.2020. Comparing with my diary, that proves to be the disk that came with the machine I'm working on. So I should be able to just put it in and run it. That's the next thing to do if I still can't get VirtualBox to run reliably.\n\nDxO PhotoLab 9: worth the trouble? Topic: photography, technology, opinion Link here\n\nI've spent a lot of time looking at the new features of DxO PhotoLab 9. Even better noise reduction, of course, but the big new thing is what appears to be excellent object recognition (“masking”). But that's only part of the story. Can I remove objects? Replace them with something else? It seems that the answer is “no”.\n\nSomewhere I also thought I saw a way to merge HDR images, but that seems to be a misunderstanding. Instead they have improved file handling, including collapsing related image groups and automatic file naming. None of them seem to be anywhere near as flexible as the method I worked out 13 years ago, so it's of no use to me.\n\nSo: what will the future bring? The masking is good, but is it enough to spend US $240 on? There's a very good chance that they'll come up with a version 10 in the not-too-distant future and want $120 for an upgrade. Maybe I should just wait.\n\nVicRoads: still in the 20th century Topic: general, technology, opinion Link here\n\nAfter scrapping my Hyundai Elantra at the end of July I was due a refund for the registration.\n\nAnd they sent me a cheque! I thought they went out of fashion well over a year ago. And yes, the bank refused to accept it.\n\nBut why? I really don't understand. They should have transferred it to my bank account, like any sane company. But no, I had to call their customer service line (1300 555 165, which looks suspiciously like a fake US phone number) and go through their silly authentication process (including a form of 2FA, sending a PIN to my phone. That would have helped a lot if I had been calling from that phone). But yes, relatively quickly they took the details and told me that the transfer would occur in the next 2 to 3 weeks. Receipt number HD1155831.\n\n2 to 3 weeks? Why? Ah, we need human intervention. Why? Nowadays we have computers. With only marginally good programming the money could have been in my bank account before the end of the call. But clearly they don't have that.\n\nMore VirtualBox insights Topic: technology, opinion Link here\n\nSo what's wrong with VirtualBox networking? Google Gemini had suggested that it might depend on the emulated network adapter, so spent some time trying different adapters, with no improvement. About the only thing that was clear was the ping time: from guest to host the expected 0.15 ms, but in the other direction much longer, and with wildly different times:\n\nround-trip min/avg/max/stddev = 29.752/61.679/175.892/36.953 ms\n\nGave that up and looked at some bug reports, which showed surprisingly few network issues. But one, by Ivan Rozhuk, was interesting:\n\nTry to disable HW offloads on NIC:\n\nifconfig igb0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n\n\nAnd how about that, that worked. So why is this not better known? There's also a wiki with surprisingly little of use.\n\nLater I discovered that my guest current.lemis.com had 8 CPUs, while the host dereel only has four. That's quite impressive that it worked at all. Reducing the number of CPUs on current got rid of the slow ping times.\n\nSo: are we done? I don't think so. I still need to find whether the Microsoft guests work reliably.\n\nBruce Evans' C compiler Topic: technology, opinion Link here\n\nMail in the TUHS mailing list today:\n\nSubject: [TUHS] Bruce Evans 386 Minix patches & compiler source\n\n\n\nIt's been quite a while since I was messing with Minix386 back in the days\n\nwhen Bruce Evans released a set of patches to bring 386 support.\n\nI'm pretty sure over on oldlinux.org the patch set exists, but I can only\n\nfind the one set of binaries of his 386 toolchain.\n\nI know it eventually evolved into the bin86 toolchain that Linus would go on\n\nto use to create real mode boot code, but I don't know if any of the source\n\ncode to his 1991/1992 386 toolchain ever got published?\n\n\n\nIs it somewhere on the disk images that Peter Jeremy saved? I haven't looked at them for over three years, and I only had the smaller ones that I could download. Sent off a message to the other people who have access, Warren Toomey (who also coincidentally runs TUHS) and Warner Losh, and only got a brief response from the first.\n\nBack to look at what I have: three files, /src/bde/ad1.img, /src/bde/ad2.img and /src/bde/ad3.img. I had only looked at /ad0.img, requiring gnop to access the individual partitions. There was a good reason: I had renamed ad2.img.xz to ad2.img without uncompressing it. Did that now and ended up with 60 GB of data.\n\nAnd the contents?\n\n=== root@dereel (/dev/pts/1) /bde 13 -> mdconfig -a -t vnode -f /src/bde/besplex/ad2.img\n\nmd0\n\n=== root@dereel (/dev/pts/1) /bde 14 -> l /dev/md0\n\nmd0 md0s1 md0s2 md0s2a md0s2b md0s2d md0s2e md0s2f md0s2g md0s2h\n\n\n\nAll the BSD partitions there! So I can just mount them:\n\n=== root@dereel (/dev/pts/1) /bde 15 -> mkdir a b d e f g h\n\n=== root@dereel (/dev/pts/1) /bde 16 -> l\n\ntotal 1\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 a\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 b\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 d\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 e\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 f\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 g\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 h\n\n=== root@dereel (/dev/pts/1) /bde 35 -> for i in `echo a b d e f g h`; do mount -o ro /dev/md0s2$i $i; done\n\nmount: /dev/md0s2a: No such file or directory\n\n=== root@dereel (/dev/pts/1) /bde 36 -> df\n\nFilesystem 1048576-blocks Used Avail Capacity Mounted on\n\n...\n\n/dev/md0s2b 3,952 3,542 93 97% /bde/b\n\n/dev/md0s2d 3,952 2,971 664 82% /bde/d\n\n/dev/md0s2e 3,952 3,658 -21 101% /bde/e\n\n/dev/md0s2f 3,952 3,514 121 97% /bde/f\n\n/dev/md0s2g 11,754 8,842 1,972 82% /bde/g\n\n/dev/md0s2h 29,525 14,599 14,926 49% /bde/h\n\n=== root@dereel (/dev/pts/1) /bde 37 ->\n\n\n\nAnd in one of the partitions I found a file /bde/e/besplex/home/bde/dist/minix.tar.gz, which may be just what Jason is looking for. That was much easier than I thought. Is it correct? That would be too easy.\n\nMore fun with VirtualBox and bde Topic: technology, opinion Link here\n\nMore playing around with VirtualBox today, with no breakthrough. I had paused dereel with zzz, and when I restarted it the networking had gone to hell again. Here a repeat of what I had done yesterday:\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 1 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500 options=4e524bb<RXCSUM,TXCSUM,VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,LRO,WOL_MAGIC,VLAN_HWFILTER,VLAN_HWTSO,RXCSUM_IPV6,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 2 -> ifconfig em0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 3 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500\n\noptions=4c120b8<VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,WOL_MAGIC,VLAN_HWFILTER,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n\n\nAfter that it worked normally again, but the Microsoft boxen still didn't want to know. Do I have to cold start them every time?\n\nAnd Bruce Evans' C compiler? I posted what I had and got no answer. I'm not convinced that I have the right files, though the name usr/src/mx386/bcc (from the archive e/bde/dist/minix.tar.gz) does raise some hope.\n\nPower fail! Topic: general, technology, opinion Link here\n\nAt 11:04, while preparing breakfast, we had a grid power failure. Not a problem: we have a PV system. But the power dropped totally! Almost before we knew it, it was back again. The inverter log shows less than a minute.\n\nThat's not the first time. It happens far too often, most recently two months ago. And today, as then, my main machines eureka and hydra lost power, because I still hadn't got round to getting a UPS installed. Today I made up for that: I have a ten-year-old 1000 VA 650 W UPS just lying around. It is still functional? In contrast to the CyberPower UPS that I bought 2½ years ago, it seems still to work. While the power was down, took the opportunity to tidy up the mess to the left of my desk top, removing this display card from eureka and making a cut in my fingertip in the process:\n\nThat once drove three of the four monitors then connected to eureka, but that was years ago, as the dust suggests.\n\nWhat caused the outage? Hard to say. The inverter logs show no sign of overvoltage before the outage, though afterwards the voltage hung over 250 V for over an hour. I suppose it's time to brave the potential issues and update the firmware.\n\nPowercor had a different view. An hour later I received a message:\n\nAnd then\n\nOn checking, I found that I also had similar messages from the day before, where there was no outage at all. Still, rather phantom outages than real ones.\n\nhydra upgrade Topic: technology, opinion Link here\n\nI've had hydra for nearly 2 years, and I still haven't got round to configuring it quite the way I want; much is in the X menus. But of course the system is now down-rev. What better time then after a power failure to bring it up to date?\n\nMy real concern after an update is that the ports will no longer work the way I want. Building a new world is relatively simple, and it took just shy of 1000 seconds to build the world and new kernel. And rebooting went relatively smoothly, though it no longer found the Ethernet card on the motherboard. I had suspected issues in that area (it's a 2.5 Gb/s Realtek card) and installed a second, which showed up as re0 , so all I needed to do was to change where I plugged in the network cable.\n\nAs I feared, the ports were a different matter. They were worse then ever before, taking 3 iterations to delete 100—no, 101—no, 103 ports, including chromium curl, emacs of course, enblend, exiv2, feh, ffmpeg, firefox, fusefs-curlftpfs, gdb, git, gnupg, groff, hugin, mplayer, mpv, mutt, rdesktop, rsync, rtorrent, vigra, virtualbox-ose, xpdf and xv. And even then I missed ImageMagick, which further annoys me with a change of name. Yes, convert is a subcommand of ImageMagic, but now they have decided that the name is too invasive, so I'll have to change all invocations to magick convert. I suppose that one's fair enough.\n\nAnd firefox has new messages, which it spews by the hundred where it presumably suspects nobody is looking, on the home terminal:\n\nconsole.warn: services.settings: Could not determine network status. Message: TypeError: can't access prop \"isLinkUp\", lazy.gNetworkLinkService is undefined\n\nGradually the issues became clear: I can no longer connect to eureka with ssh, nor at all to hydra. I was expecting issues with eureka, but not with hydra. Was it because it came up before the network was ready? I had to restart syslogd to get it to write to eureka, and to change the permissions on wake for normal users to use it.\n\nWhat am I left with? I can no longer use erc, the Emacs IRC command:\n\nerc: missing symbol (.at)\n\n⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.\n\n\n\nWhat does that mean? I'll find out some time. Fortunately it still works on eureka, so there's no hurry.\n\nAnd independently of all that I need to pay more attention to my X configuration. I still don't get my mice set up correctly at startup. But that's fun for another day.\n\nCompleting the upgrade Topic: technology, general, photography, opinion Link here\n\nInto the office this morning as usual. No mail from hydra. What happened there? /var/log/maillog showed a number of:\n\nSep 20 03:03:54 hydra postfix/cleanup[70392]: B1BC41AB5: message-id=<202509191703.58JH3sRP070451@hydra.lemis.com>\n\nSep 20 03:03:54 hydra sendmail[70451]: 58JH3sRP070451: to=root, ctladdr=root (0/0), delay=00:00:00, xdelay=00:00:00, mailer=relay, pri=33687, relay=[127.0.0.1] [127.0.0.1], dsn=2.0.0, stat=Sent (Ok: queued as B1BC41AB5)\n\nSep 20 03:03:54 hydra postfix/qmgr[1845]: B1BC41AB5: from=<root@hydra.lemis.com>, size=4303, nrcpt=1 (queue active)\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: unexpected attribute smtputf8 from local socket (expecting: sendopts)\n\nSep 20 03:03:54 hydra postfix/smtpd[70368]: disconnect from localhost[127.0.0.1] ehlo=1 mail=1 rcpt=1 data=1 quit=1 commands=5\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: deliver_request_get: error receiving common attributes\n\n\n\nWhat's smtputf8 ? Checking /usr/local/etc/postfix/ showed that a number of files, which should have been symlinks to the same directory on eureka, were missing. Forgot to mount a NFS file system. After mounting and restarting postfix, all was well. But what does the strange message mean? It seems that it's a default.\n\nAnd then there was Hugin. I had expected some issues, but not what I got: when I tried to start the “fast panorama preview” I got\n\nerror installing GLEW\n\nFast preview window can not be opened\n\nWhat does that mean? I have a package installed, which pkg reports as\n\nglew-2.2.0_3 OpenGL Extension Wrangler Library\n\nAnd there doesn't seem to be anything else that was there before. But when I retried the attempt, it worked. Where is the bug? Hugin or FreeBSD? In addition, irritatingly it resized the windows on every start. I thought I had got rid of that with some script magic, but it seems to be gone.\n\nAnd then there's the mouse. That's simple enough: instead of searching for the index for the mouse, it's easy enough to write\n\nxinput set-button-map \"Telink 2.4G Mouse\" 1 2 3 4 5 6 7 2 2 10\n\nOne of the messages I received was completely misleading:\n\n=== grog@hydra (/dev/pts/16) ~/Photos/20250920 47 -> (EE) event4 - Telink 2.4G Mouse, class 0/0, rev 1.10/1.00, addr 4: client bug: event processing lagging behind by 32ms, your system is too slow\n\n(EE) client bug: timer event4 debounce: scheduled expiry is in the past (-48ms), your system is too slow\n\n(EE) client bug: timer event4 debounce short: scheduled expiry is in the past (-61ms), your system is too slow\n\n\n\nThat's not hydra at all, despite the prompt. I started X on teevee from hydra, and this appears to be its way of saying “the cat got on my mouse”.\n\nAccessing systems with ssh from eureka Topic: technology Link here\n\neureka is now running a nearly 10 year old system, but I don't want to update it: it works.\n\nBut some issues remain. One was that I couldn't automatically log on with ssh: I had to enter a password, which is irritating in scripts. Once again Google Gemini to my aid. Add this to /etc/ssh/sshd_config:\n\nPubkeyAcceptedKeyTypes=ssh-ed25519,ssh-rsa,rsa-sha2-512,rsa-sha2-256\n\nNow I just need to see why I can't access eureka from hydra without a password.\n\nFinally the birding photos Topic: photography, animals, technology, opinion Link here\n\nIt's been 4 days since the latest OM System birding “workshop”, and I've only just got round to processing the best photos. Are these the best?\n\nIt's a lot of work making up my mind out of over 250 photos. Yvonne did it for me, and those were the ones she liked.\n\nMore ssh strangeness Topic: technology, opinion Link here\n\nI've already established issues with ssh sessions from hydra to eureka, but not from other systems. Once again Google Gemini to my aid, this time less useful. It tells me to allow ssh-rsa in /etc/ssh/sshd_config by adding this line:\n\nPubkeyAcceptedKeyTypes=+ssh-rsa\n\nWe've seen that before on the other side. But that's a non-starter: sshd doesn't want to know:\n\n=== root@eureka (/dev/pts/1) /etc/ssh 28 -> service sshd restart\n\nPerforming sanity check on sshd configuration.\n\n/etc/ssh/sshd_config: line 54: Bad configuration option: PubkeyAcceptedKeyTypes\n\n/etc/ssh/sshd_config: terminating, 1 bad configuration options\n\nOK, what about the alternative of using a key?\n\n=== root@eureka (/dev/pts/1) /etc/ssh 32 -> service sshd restart; date\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStopping sshd.\n\nWaiting for PIDS: 22656.\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStarting sshd.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\n\n\nWhy? It doesn't seem to affect other key forms. And comparing hydra and tiwi gives me on hydra:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: send_pubkey_test: no mutual signature algorithm\n\n\n\nBut on tiwi it works as expected:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: Server accepts key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\nAuthenticated to eureka.lemis.com ([192.109.197.137]:22) using \"publickey\".\n\n\n\nWhat's the difference?\n\nMutt problems Topic: technology, opinion Link here\n\nFirst thing I do in the morning is to read the overnight mail, typically a couple of hundred messages. But this morning I tried to delete the messages I had read, I received the message “unable to write mailbox” or something similar. Why? Normally I see a message like that when I'm out of disk space, but this wasn't the case. Return, painfully delete the messages again, and it worked. Is that an NFS issue? It has happened before. Was that also overnight? I'll have to look more carefully next time.\n\nMore ssh pain Topic: technology, general, opinion Link here\n\nInto the office this morning to find eureka maxed out with at least 35 ssh-add processes, all looping at 100% CPU time.\n\nWhy? This is not a new program:\n\n3054180 -r-xr-xr-x 1 root wheel 17576 25 Nov 2015 /usr/bin/ssh-add\n\nOnce again Google Gemini to my aid, coming with the suggestion that it could be that ssh-add was running already, and that I should put in code like\n\nssh-add -l >/dev/null || ssh-add\n\nThat worked up to a point, but it doesn't explain why it is only happening now, after nearly 10 years. It's much more likely that it's related to the playing around I have been doing lately, though it didn't affect ssh-add, and I had backed out the changes anyway. And in the course of the day I found another instance in my weather software, but that found further breakage: the external view of my weather stopped in early June when I got the new weather station. More to fix when the current problems are over.\n\nssh-add: A clue Topic: technology, opinion Link here\n\nI haven't done much to investigate the ssh-add problem for the moment. It seems that I call ssh-add in a number of places, all of which need fixing. But while playing around I found:\n\n=== grog@eureka (/dev/pts/3) ~/public_html 32 -> ssh-add < /dev/null\n\nEnter passphrase for /home/grog/.ssh/id_rsa:\n\nCould it be that the looping is the incorrect handling of a prompt? It doesn't help much in fixing it, but it could help understand.\n\nThe advantages of upgrades Topic: technology, opinion Link here\n\nAs expected, upgrading hydra caused a number of problems, most of which I have described. And this time it was Chromium, which has forgotten all its editing keys, or at least the ones I want. More searching required.\n\nOn the other hand, one bug has gone away: xv can now display PNG again. Not exactly a big improvement, but at least a fixed bug.\n\nThe daily Android bug Topic: technology, opinion Link here\n\nSomehow the Android operating system seems to be the least reliable I know. I'm gradually coming to terms with it, but today there was another one: trying to download files to a Real Computer, albo didn't respond, though it claimed to be working. Disable Wi-Fi, reeenable, and it worked. No change of connection.\n\nWhat a mess Android is!\n\nAnother web server overload Topic: technology, opinion Link here\n\nIt's been well over 4 months since I set up a new external web server, fra.lemis.com, to address the really heavy load, with load averages up to 170. And so, of course, it dropped back to under 1.\n\nBut now it's increasing again, both servers now well over 200. Why? I had thought it was related to the imagesizes parameter, but that doesn't seem to be the case. Let's see how long the overload lasts this time.\n\nFast postal service Topic: general, technology, opinion Link here\n\nI've bought a couple of cameras in the United Kingdom. The usual tracking information, with a twist:\n\nIt's in Leeds, but it'll be here tomorrow! Now that's a lot faster than Australia Post. Or just plain stupid.\n\nYour cameras have been delivered! Topic: technology, photography, general, opinion Link here\n\nYesterday's claim of fast delivery was amusing enough, but they haven't given up:\n\nThey have been delivered! How did we do?\n\nI'm amazed. Clearly the cameras are still in the United Kingdom. My best guess is that Royal Mail have delivered the cameras to the people who are currently in the process of sending them half way round the world, or at least they have received documentation from them. So from their limited viewpoint they have been delivered. No concept of them only having travelled a fraction of the distance.\n\nWeb server load: dropping Topic: technology Link here\n\nYesterday's web server overload didn't last long. It's back to round 1 again. I suppose that's what we're going to have to live with for the foreseeable future. It's interesting that even at this extreme overload people claimed that response was satisfactory. That's significantly different from last time, where some sites got timeouts.\n\nArtificially intelligent breakfast Topic: food and drink, technology, opinion Link here\n\nFor some reason we bought a quarter cabbage recently. I forget why, but it was intended for breakfast. All right, Google Gemini, give me some east asian recipes with fried cabbage.\n\nAnd the twins obliged: 手撕包菜 - Shǒu Sī Bāo Cài, “hand shredded cabbage\", which didn't look too bad, modulo these horrible cups measurements. I can't even blame the twins for that: so many recipes use it. But it's the biggest hindrance I can find for trying out recipes. OK, Gemini, give me a Chinese recipe with fried cabbage and noodles using metric units. OK, how about 包菜炒粉/麵, which Google Translate translates as “cabbage fried rice noodles”? A completely different recipe! The best I can guess from the two recipes is that 4 cups of cabbage weigh about 300 g.\n\nSpent some time—probably more than cooking—writing a sane version of the second recipe.\n\nSoftware upgrades: the sting in the tail Topic: technology, photography, opinion Link here\n\nHouse photos again today, the second time since I upgraded hydra to FreeBSD 14.3 last week. And once again I had pain.\n\nFirstly, creating HDR didn't work well. It took me a while to discover that it was an unrelated bug in one of my scripts: I managed to mix images from the OM System OM-1 Mark II with the correct images from the Olympus OM-D E-M1 Mark II. I had already expected problems like that, and /Photos/Tools/housephtos.awk contained appropriate comments. Here the fix:\n\n-# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n+# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n# Create a makejpeg file from housephoto.notes file.\n\nBEGIN {\n\ni = 0;\n\n-# XXX Only look at photos from E-M1 Mark II.\n\n+# Only look at photos from E-M1 Mark II.\n\n# Is this safe?\n\n-# Was: 4*.ORF, E-M1 /2 only\n\n- while (\"ls -rt *.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n+# It's better than the alternative.\n\n+ while (\"ls -rt 4*.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n\n\nThe problem was that I didn't limit the choice to photos from the E-M1 Mark II. Not an upgrade problem at all.\n\nThe other, though, seems to be related to the upgrade of Hugin, now version 2024.0.1. The screens appear in the wrong place and at the wrong (tiny) size, and the directories are wrong. That's almost certainly related to the scripts that I wrote over 16 years ago which frob the ~/.hugin file to get rid of this horrible directory name retention. But that's all they do, and somehow it doesn't seem to work. A small detail, but irritating. Will I get round to it by next week?\n\nRevisiting old photos Topic: photography, technology, opinion Link here\n\nLooking back through old photos, found some of my first panoramas:\n\nIt dates from 11 April 2009 with the Olympus E-510, so old that I don't even have Exif data for it. I had already attempted to improve it 8 years later:\n\nBut that was still with the Ashampoo Photo Optimizer, which I have stopped using. Another attempt with “Perfectly Clear” gave me further improvements. Here are the three together (run the cursor over an image to compare it with its neighbour):\n\nIn particular the highlights and shadows are greatly improved.\n\nfra rebooted! Topic: technology, general, opinion Link here\n\nThe vultures have rebooted fra! Yes, they warned they would do so because of some unspecific bug in Linux, so they rebooted my FreeBSD box as well. The good news is that it came back without any intervention on my part, but of course the up time has gone to hell.\n\nAnother bloody power fail Topic: technology, general, opinion Link here\n\nIn the evening, another grid power failure. And another directly behind it. Both were sub-second, but once again eureka and hydra failed. So much for the UPS.\n\nWhy? Yes, it's an old UPS, but it claims to have plenty of charge, and the failures were so short that most clocks in the kitchen kept going. Can it be that it was a power surge, and that this UPS didn't handle it? The UPSs for lagune, teevee and tiwi had no problems.\n\nAnd the fallout? I got things running relatively quickly, but firefox didn't recover its many tabs. I had to start a different profile to get anything. And of course X on teevee failed, because I had started it from hydra.\n\nSo what do I do now? Buy more of UPSs of the kind that power the other machines?\n\nTuesday, 30 September 2025 Dereel Top of page previous day\n\nMore firefox pain Topic: technology, general, opinion Link here\n\nSo what's wrong with firefox? My standard profile just hangs. Why? How do I debug such a mess?\n\nI tried setting up a different profile, losing a number of tabs in the process, but nothing I could do could get the font sizes right. Get them right for my diary (without any trickery) and they're far too small for things like Wikipedia and friends. Migrate from hydra:0.2 (3840×2160) to hydra:0.0 (1920×1080)? Yes, that works, but why did it happen?\n\nThen it occured to me: yes, the standard profile still hangs. But I can check the settings. And it seems that the big thing is the Zoom setting, which was at 150%. After setting that, things were OK. But why the difference between my diary and Wikipedia and Co.? And why are font sizes such an issue with firefox?",
      "source": "Lemis.com",
      "url": "http://www.lemis.com/grog/diary-sep2025.php?topics=c#D-20250909-004539",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "DxO PhotoLab 9: worth the trouble?",
      "content": "AI: enough! Topic: technology, general, opinion Link here\n\nSunday's detailed investigation of generative artificial intelligence should have been enough, but it occurred to me that there was one thing I hadn't tried: graphics. OK, draw me a caricature of Greg Lehey.\n\nGoogle Gemini came up with this:\n\nOf course I don't need to like the results, but this shows very little understanding: no mention of BSD, just Linux (or even “Linix”). Yvonne tells me that it looks nothing like me. Compared to the text results, quite disappointing.\n\nAnd that was all. My other bots all couldn't do it. But their attempts were worth mentioning:\n\nChatAI\n\nI'm unable to draw images directly, but I can help you imagine a caricature of Greg Lehey! Picture a gentleman with a thoughtful expression, perhaps with glasses perched on his nose, and a hint of a smile suggesting a keen sense of humor. His hair might be slightly tousled, giving him a scholarly yet approachable look. You could exaggerate his features, like giving him a larger forehead to symbolize his intellect or a prominent chin to represent determination. Add a background filled with books and computers to reflect his interests in technology and writing\n\nI suppose that's acceptable for as far as it goes.\n\nClaude\n\nClaude did the best with the diary entry, but it failed completely with the caricature:\n\nClaude: I'd be happy to help you create a caricature, but I'll need a bit more information! There are likely multiple people named Greg Lehey, and I want to make sure I'm drawing the right person..\n\nClaude, you know who I am. There are “likely” multiple people named Greg Lehey? That wasn't a problem on Sunday. And as it happens, there is nobody else that I can find with the same name as mine. But OK, draw me a caricature of Greg Lehey, the FreeBSD person.\n\nI can't create visual caricatures or drawings as I'm a text-based AI. However, I'd be happy to help you in other ways: Written description: I could write a humorous written \"caricature\" or character sketch of Greg Lehman (assuming you meant Greg Lehman, a notable FreeBSD contributor) that captures his programming style, contributions to FreeBSD, or personality traits in an exaggerated, caricature-like way.\n\nWhat a cop-out! Now it says that it can't draw. And it comes up with a fictive Greg Lehman. That's completely useless.\n\nDeepSeek\n\nAs before, DeepSeek is inventive:\n\nWhile I can't physically draw for you, I can create a detailed \"blueprint\" for a caricature of the legendary BSD developer Greg \"Groggy\" Lehey. An artist could follow this description to create the perfect caricature. Here is a description designed for an artist to illustrate. Caricature of Greg \"Groggy\" Lehey Concept: The caricature should capture his iconic, jovial, and slightly mischievous personality, deeply intertwined with his life's work: BSD and Unix. Key Features to Exaggerate: The Beard and Hair: This is the #1 feature. Exaggerate his magnificent, full, and sprawling white beard. Make it vast and wizard-like, almost as if it's its own entity. It should be big enough to have a Daemon (the BSD logo) peeking out from within the whiskers, as if it lives there. His hair (what's visible under his hat) should be similarly wild and unkempt. The Headwear: He is almost never seen without a hat. Draw a slightly battered, well-loved flat cap or a beret perched on his head at a jaunty angle. Where did it get the hat from? I am almost never seen with a hat. The Expression: A wide, knowing, and cheerful grin. His eyes should be crinkled with laughter and wisdom, suggesting he's both a kind mentor and someone who knows where all the bugs in the code are hidden. The Props & Surroundings: In his hand: Instead of a coffee mug, he should be holding a massive, steaming beer stein. This is a nod to his famous \"Buy me a beer\" link on his website and his good-humored nature. Steaming beer? I can't even imagine that. And instead of referring to my brewing activities, it refers to a fictive “buy me a beer” link, which may be related to Poul-Henning Kamp. Under his arm: A well-worn copy of his magnum opus, \"The Complete FreeBSD\" book. Background Element: Have a Tux (the Linux penguin) peeking from around a corner, looking slightly nervous or annoyed, while Groggy pays it no mind. This playfully hints at the good-natured rivalry between BSD and Linux. Code: Faint lines of C code ( #include <beard.h> , printf(\"Cheers!\n\n\"); ) can be subtly woven into the texture of his shirt or the background. Overall Vibe: The image should feel warm, intelligent, and full of character. He is the friendly, brilliant, and slightly eccentric \"Unix Beard\" wizard, a beloved figure in the open-source community. Color Palette: Warm tones. Earthy browns for the hat, a rich color for the shirt (green or blue), the brilliant white of the beard, and the gold of the beer.\n\nStill, I suppose that could produce something useful. But where are all the image generators? Do I want to look? I've spent enough time on this already.\n\nWhy don't people read any more? Topic: language, general, technology, opinion Link here\n\nRecently I saw (but didn't read) a newspaper article, possibly from the New York Times, asking why people don't read books any more. The answer appears simple: information overload. When I was a lad I read lots of books, but it has been some time since I finished reading any, and then the relatively thin “Brave New World”.\n\nBut then we watched A Town Like Alice, and Yvonne borrowed the book. I have always liked Nevil Shute, and I have a number of his books, so I read it when she finished. It took me two weeks. While reading I was continually following up on details mentioned in the book—that's what the web is for, after all. In general, I ended up with a much broader view than I would have had if I had just read the book.\n\nAnd how did I like it? Not much. Clearly it's two different stories stuck together: the ordeals in Malaya at the hand of the Japanese occupation and the transformation of a tiny bush village in Queensland into a small town. The latter, in particular, seems very improbable.\n\nThe geographical details are what interested me most. Particularly in Malay(si)a I knew most of the real places. But I'm puzzled about why Shute spends a lot of time in the area Maran and Jerantut in the Jengka Triangle, places that must have been almost completely unknown at the time, but puts the women in a place called Kuala Telang “about half-way between Kuantan and Kota Bahru”. There is a town in that position, but it's called Kuala Terengganu, and it's a big town (capital of the state of Terengganu), not a small village. My guess is that Shute had never heard of it.\n\nSpelling is also strange. In the first half of the book, Kota Bharu was spelt “Kota Bahru”, and in the second half “Khota Bahru”. Tennant Creek became “Tennants Creek”. These spellings are the same both in the online book and the physical book that I read. And there are a couple of irritating US Americanisms that I don't understand: the animals central to the theme are called alligators, not crocodiles. The stockmen use lariats.\n\nThen there's the question of racial attitudes. The local aborigines (or aboriginals, to use the modern politically correct term) are called “boongs” or “abos”. Both are offensive nowadays. And there was talk of racial segregation, a separate milk bar for the boongs. This would have been about 1948, the time of my birth. Did such segregation really exist then?\n\nMy favourite one, though, is when the main characters (Jean and Joe) fall in love, and she decides not to sleep with him until after they are married. Given that Joe had been crucified in the first half of the story, I was half guessing that he might have been castrated at the same time, and Jean would not have found out until too late.\n\nIn summary: reading books has become much more of an exercise than it used to be. For light entertainment we have TV. I don't think I'll read another novel for some time to come.\n\nPredicting the past Topic: general, technology, opinion Link here\n\nI keep a close eye on the weather forecasts from the Bureau of Meteorology, both of them. There's one on the web and another for mobile phones. They don't often agree with each other, and of course they're both frequently wrong.\n\nToday, though, the mobile phone app excelled itself. We finally have rain, 6 mm over the last 24 hours. Or, as the app put it,\n\nPart of the app is a rainfall map showing precipitation. That showed that there was much more rain. How can that happen?\n\nWhatsApp: bug after bug? Topic: technology, opinion Link here\n\nI've been trying for a week now to set up video telephony on fossil, Yvonne's mobile phone. Somehow the “modern” approach to user interfaces shows itself at its worst here. But I had come to the conclusion that if I can work beyond WhatsApps bizarre interface, and explain it to Yvonne so that she doesn't have a panic attack every time she uses it, we might have something useful, especially since WhatsApp can communicate by an Internet link, which could be much cheaper.\n\nOK, try out on hirse first. It doesn't have a SIM card, so any communication has to go by the Internet. Migrate my main number to hirse. No problem. Make a call. Some message like “need to use the phone network”. Oh.\n\nTry calling in. The problem: hirse has the phone number associated with a SIM card in albo, which has a different WhatsApp number. Which does WhatsApp call? albo! Somehow there's more to this than meets the eye.\n\nWhen Yvonne got back from shopping, I changed her WhatsApp number to the number of second SIM on her phone. All sorts of things didn't work, and it couldn't call the number on hirse. hirse claimed that she wasn't registered, though I had set the “notify contacts” during the migration. In the end I moved the number back to the old one. And things still didn't work correctly! In particular, I could call the number, but WhatsApp didn't respond in any way, not even registering a missed call. Went through the settings and set tones for all notifications. Still no response. Restart the app. No response.\n\nNothing for it, the Microsoft solution: reboot. And yes, now it responds. Clearly some kind of bug. And it repeats the call tone for every notification, including messages. Oh, my bad. Get rid of the tone. Sorry, there's no provision for that. Select something at random, since it's too polite to play the tone when you're selecting it. I still get the ring tone for messages! I can't see any explanation except that it's another bug. It was getting late, so I turned off sounds to wait until tomorrow.\n\nAll this is made worse by the horrible user interface. So far I haven't found a way to display the associated phone number in the contact details. At one point I made the mistake of using the same name (mine) for both my phones, so there was no way at all to find out what “number” it had called.\n\nI hate WhatsApp! Topic: technology, general, opinion Link here\n\nMore fun with WhatsApp today. The first question, which decides whether it's even worthwhile: can I make a call over the Internet? Yesterday's experiments were overshadowed by other bugs. Today I tried making a call from fossil (Yvonne's phone) to hirse, the one without a SIM card. I have set it up with the main number of albo, so a normal call to that number should go to albo, and a WhatsApp call should go to hirse. Does it?\n\nYes! So yesterday's issues were probably due to other bugs.\n\nAnd the incorrect notification tones? Gone since the last reboot, Yvonne says. But later she changed her mind: once again the wrong tone when all notification tones were turned off.\n\nDammit, begone, WhatsApp! Removed it. Reinstalled it. And how about that, setup was almost completely without problem. She lost her image (“Avatar”, “The manifestation of a god in bodily form on earth” according to the OED). We can live with that. And somehow now everything Just Works—until the next unpleasant surprise.\n\nApart from that and the horrible user interface, established that you can change an audio call into a video call simply by pressing the button with the box with a loudspeaker on the right:\n\nInterestingly, it only works in one direction. To go in the other direction requires that the person at the other end do the same.\n\nVirtualBox again Topic: technology, photography, opinion Link here\n\nDxO PhotoLab 9 is out, and it looks worth trying. Time to reinstate one of my Microsoft virtual machines, which run under VirtualBox.\n\nI stopped using VirtualBox on hydra a year ago, though it was the main reason that I had so much memory (192 GB): I ran into network problems that I couldn't fix.\n\nNow FreeBSD has a port of VirtualBox 7. Time to try again? Tried first on dereel, with only 24 GB of memory. Where's my HOWTO? All fine, but it doesn't tell me how to add an existing VM. It must be in this diary somewhere, but where? I really should keep these HOWTOs up to date.\n\nStarting up the GUI was different from before, of course. And it wanted to set things up in the root file system. To go elsewhere I had to do this horrible tree walking. Finally I got to where I wanted (/src/VirtualBox/echuca). Tried to create a new VM. “Can't overwrite machine folder...\". What does that mean? They should know better than to call a directory a folder, but what's a “machine folder”? Lots of experimentation, continually being returned to the /root directory and having to climb my way out again. What does “help” say? Nothing. I wonder if the port forgot to install something important. After a while I discovered that it really wanted the parent directory /src/VirtualBox, but then I ran into other issues.\n\nAfter some time decided to create a new VM with the old virtual disk. Link? Yes, but VirtualBox detected the UUID and used the old name.\n\nYes, there are other possibilities. But I think that the best is to go through my diary and extract the information that I need to do things sanely. And maybe I should use the commands rather than the GUI, which seems to be getting more stupid as time goes on.\n\nWhatsApp an Avatar? Topic: technology, general, opinion Link here\n\nYesterday I established that an Avatar is a earthly manifestation of a Hindu god, but WhatsApp apparently wants to elevate Yvonne and me to deities. Until then, only initials appear to identify us on calls.\n\nOK, how do we do that? Settings, of course, “make your own avatar”, “Create from selfie”. OK. Take a suitably horrified photo of myself. Briefly it showed “There was an error with the avatar gen...”, so briefly that I didn't see it the first three times. What does that mean? Why can't it finish its sentences? So instead it presented me with a manual generation.\n\nWhy? What does the half message mean? It's repeatable on two different phones. And there seems to be no way to just add a normal photo. What a mess!\n\nVirtualBox progress Topic: technology, opinion Link here\n\nSo what's wrong with my VirtualBox installation? My current situation was exactly what I had a year ago: most VMs worked, but Microsoft VMs had networking problems. They could send data, but they didn't see the replies, so they hung in ARP. I attributed that to the version of VirtualBox (6.1.50 r161033), so I waited until version 7 came out. And then I discovered that I had exactly the same problem.\n\nThat didn't help just getting things running. After some searching, discovered that VirtualBox stores a configuration in the home directory, ~/.config/VirtualBox/ with a number of files, including log files that have no business there, but importantly VirtualBox.xml. OK, make a copy of that on dereel, and how about that, VirtualBox came up with all the VMs I knew.\n\nStart disaster, the only VM that would fit in dereel's memory.\n\nVT-x is disabled in the BIOS for all CPU modes (VERR_VMX_MSR_ALL_VMX_DISABLED).\n\n\n\nOh. There was something there, but can the twins help? Yes, specifically for a ThinkCentre:\n\nOnce in the BIOS, use the arrow keys to navigate to the Advanced tab. From the Advanced menu, select CPU Setup and press Enter. Look for an option labeled Intel(R) Virtualization Technology and select it. Using the arrow keys, change the setting from Disabled to Enabled.\n\nAfter that and rebooting, and with a change of network adapter name, it still didn't start. I got this message:\n\nX86_CPUID_AMD_FEATURE_EDX_AXMMX is not supported by the host but has already exposed to the guest [ver=19 pass=final] (VERR_SSM_LOAD_CPUID_MISMATCH).\n\nMore help from the twins. The saved state includes information from an AMD processor (hydra), but this is Intel. Discard saved state and start again.\n\nAfter that, and with a change of network adapter name, it started. I got this message, which I haven't seen before, but which seems harmless:\n\nerror: XDG_RUNTIME_DIR is invalid or not set in the environment.\n\nThat variable isn't set on hydra either.\n\nWe're still not done. Trying to start an xterm from current gave me the message\n\nThe Virtual Machine reports that the guest OS does not support mouse pointer integration\n\nWhat's that? Gemini tells me:\n\nThe message \"The Virtual Machine reports that the guest OS does not support mouse pointer integration...\" in a FreeBSD virtual machine is common and means you need to install and configure the necessary guest additions for the mouse to work seamlessly. FreeBSD does not include these drivers out of the box, so you must install them yourself.\n\nThat sounds like the Ports Collection. But there is no additions package for VirtualBox 7.1, only for 6.50 and 5.2. Mañana.\n\nOn with disaster. So: ARP issue? While messing around on disaster, found the help message for ARP. It uses Unix-style option delimiters, and -s sets a permanent MAC address. OK, if this is an ARP issue, we can fix that:\n\nOh: Microsoft has a different format for MAC addresses. Try again:\n\nAnd that as Administrator . Time to ask the twins.\n\nQ: What does \"The ARP entry addition failed: Access is denied\" when running CMD as administrator under \"windows\" 10? A: The \"ARP entry addition failed: Access is denied\" error in Windows 10, even when running Command Prompt as an administrator, typically happens when trying to add a static Address Resolution Protocol (ARP) entry for a reason other than a permission issue.\n\nInteresting. “Access is denied” is not a permission issue? Something's wrong here, either Gemini or Microsoft. My money is on Microsoft.\n\nAnd that's what Gemini suggests too:\n\nUse netsh instead: In some cases, especially on newer versions of Windows, the arp command may have issues with Access is denied errors even when the user has administrator privileges.\n\nSo I ended up with this simple invocation:\n\nAnd how about that, it worked. Well, at least it put the address in the ARP table, and I was able to ping out, so disaster knew the address. But it still didn't hear any reply.\n\nYet another question to Gemini:\n\nWhat could cause a Microsoft guest under VirtualBox to send network data but not receive it, when other guests have no problem with the same configuration?\n\nThe obvious answer: firewall. Check to be on the safe side. No, no firewall enabled. How about an Ethernet adapter issue?\n\nIf you are using an Intel PRO/1000, try switching to a different type, such as the AMD PCnet-FAST III.\n\nOK, try that. No improvement. Next idea: this video\n\nOK, try anything once. Follow the instructions step by step, none of which showed any obvious issues. Change the interface back to (specifically) Intel PRO/1000 MT Deskop (8254EM). Not much hope there: that's what I had.\n\nBut it worked! My final configuration looks identical to the start configuration. What changed? There's something lurking under the surface that I don't understand. Can I now get it to run on hydra?\n\nMore VirtualBox pain Topic: technology, opinion Link here\n\nYesterday I finally got networking working using VirtualBox 7.1 and Microsoft “Windows” 10. Time to refine a few things. First, start the windows on hydra:0.0, a 1920×1080 display, rather than on hydra:0.1, which has 3840×2160, giving windows that are too small.\n\nBut it didn't work! I could start on hydra:0.1, but on hydra:0.0 nothing happened. Is there some kind of built-in memory in the configuration file?\n\nSo, time to upgrade current.lemis.com, another VM running FreeBSD-CURRENT. It was a year out of date.\n\nStart a make buildworld , not for the first time. But nothing happened!\n\nFurther investigation showed that I had a network hang. And disaster was also hanging! Shut down disaster and current regained network access—for a while. Then it hung again.\n\nThis seems worse than my experience on hydra with VirtualBox 6.5. Tried it there and it worked.\n\nWhat a pain! What does Google Gemini say?\n\nQ: Are there known networking issues with VirtualBox under FreeBSD? A: Yes, there are known networking issues and quirks with VirtualBox when used as a host on a FreeBSD system. While VirtualBox works, it is not an officially \"supported\" host platform by Oracle, which means users often have to rely on the community and package maintainers to troubleshoot and resolve issues. (much irrelevant information omitted) Users sometimes experience slow network speeds, particularly with upload speeds, when using bridged adapters. This can be more pronounced on specific emulated network card types. While VirtualBox can function as a host on FreeBSD, it is not a \"fire-and-forget\" solution... If you encounter speed or reliability issues, experimenting with different emulated network adapter types can often resolve the problem.\n\nThat's not encouraging, though it doesn't directly relate to my problems. But what else can it be? Two different versions of FreeBSD, two different machines, two different versions of VirtualBox. Does it work better on Linux? That would be a real let-down, but possibly I should try it. How much pain would that be?\n\nTesting RSS feeds Topic: technology Link here\n\nI write all my web markup myself, with the aid of a number of PHP scripts. The result is that the RSS feed looks nothing much like my sources. So when something goes wrong with the markup, it's hard to find where, not helped by things like the W3.org validator, which typically points to where the error is detected, not where it occurred, and which at the moment caches input, so even after fixing the problem it reports the old problem.\n\nCallum Gibson is the main user of RSS feeds whom I know of. He pointed me to this validator. It also points to where the error was found, but at least I can try things and repeat them. That fixed an issue I had with earlier this month, where the error was over 100 lines from where it was detected.\n\nChasing the VirtualBox bug Topic: technology Link here\n\nSo why was VirtualBox version 7.1 on dereel even worse than version 6.50 on hydra? One possibility might be that the VMs themselves were NFS mounted. OK, find a 1 TB disk and copy them there. Put it in in place of the DVD drive, and was amazed to find that it came up as /dev/ada0, relegating the system disk to /dev/ada1 and requiring manual intervention (/etc/fstab) to continue. How could that happen?\n\nThen copying the VMs from hydra. That took a few hours, of course, so I'll continue tomorrow.\n\nWhile looking for the disks also found one marked “MS “Windows” 10 disgust”, dated 10.XII.2020. Comparing with my diary, that proves to be the disk that came with the machine I'm working on. So I should be able to just put it in and run it. That's the next thing to do if I still can't get VirtualBox to run reliably.\n\nDxO PhotoLab 9: worth the trouble? Topic: photography, technology, opinion Link here\n\nI've spent a lot of time looking at the new features of DxO PhotoLab 9. Even better noise reduction, of course, but the big new thing is what appears to be excellent object recognition (“masking”). But that's only part of the story. Can I remove objects? Replace them with something else? It seems that the answer is “no”.\n\nSomewhere I also thought I saw a way to merge HDR images, but that seems to be a misunderstanding. Instead they have improved file handling, including collapsing related image groups and automatic file naming. None of them seem to be anywhere near as flexible as the method I worked out 13 years ago, so it's of no use to me.\n\nSo: what will the future bring? The masking is good, but is it enough to spend US $240 on? There's a very good chance that they'll come up with a version 10 in the not-too-distant future and want $120 for an upgrade. Maybe I should just wait.\n\nVicRoads: still in the 20th century Topic: general, technology, opinion Link here\n\nAfter scrapping my Hyundai Elantra at the end of July I was due a refund for the registration.\n\nAnd they sent me a cheque! I thought they went out of fashion well over a year ago. And yes, the bank refused to accept it.\n\nBut why? I really don't understand. They should have transferred it to my bank account, like any sane company. But no, I had to call their customer service line (1300 555 165, which looks suspiciously like a fake US phone number) and go through their silly authentication process (including a form of 2FA, sending a PIN to my phone. That would have helped a lot if I had been calling from that phone). But yes, relatively quickly they took the details and told me that the transfer would occur in the next 2 to 3 weeks. Receipt number HD1155831.\n\n2 to 3 weeks? Why? Ah, we need human intervention. Why? Nowadays we have computers. With only marginally good programming the money could have been in my bank account before the end of the call. But clearly they don't have that.\n\nMore VirtualBox insights Topic: technology, opinion Link here\n\nSo what's wrong with VirtualBox networking? Google Gemini had suggested that it might depend on the emulated network adapter, so spent some time trying different adapters, with no improvement. About the only thing that was clear was the ping time: from guest to host the expected 0.15 ms, but in the other direction much longer, and with wildly different times:\n\nround-trip min/avg/max/stddev = 29.752/61.679/175.892/36.953 ms\n\nGave that up and looked at some bug reports, which showed surprisingly few network issues. But one, by Ivan Rozhuk, was interesting:\n\nTry to disable HW offloads on NIC:\n\nifconfig igb0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n\n\nAnd how about that, that worked. So why is this not better known? There's also a wiki with surprisingly little of use.\n\nLater I discovered that my guest current.lemis.com had 8 CPUs, while the host dereel only has four. That's quite impressive that it worked at all. Reducing the number of CPUs on current got rid of the slow ping times.\n\nSo: are we done? I don't think so. I still need to find whether the Microsoft guests work reliably.\n\nBruce Evans' C compiler Topic: technology, opinion Link here\n\nMail in the TUHS mailing list today:\n\nSubject: [TUHS] Bruce Evans 386 Minix patches & compiler source\n\n\n\nIt's been quite a while since I was messing with Minix386 back in the days\n\nwhen Bruce Evans released a set of patches to bring 386 support.\n\nI'm pretty sure over on oldlinux.org the patch set exists, but I can only\n\nfind the one set of binaries of his 386 toolchain.\n\nI know it eventually evolved into the bin86 toolchain that Linus would go on\n\nto use to create real mode boot code, but I don't know if any of the source\n\ncode to his 1991/1992 386 toolchain ever got published?\n\n\n\nIs it somewhere on the disk images that Peter Jeremy saved? I haven't looked at them for over three years, and I only had the smaller ones that I could download. Sent off a message to the other people who have access, Warren Toomey (who also coincidentally runs TUHS) and Warner Losh, and only got a brief response from the first.\n\nBack to look at what I have: three files, /src/bde/ad1.img, /src/bde/ad2.img and /src/bde/ad3.img. I had only looked at /ad0.img, requiring gnop to access the individual partitions. There was a good reason: I had renamed ad2.img.xz to ad2.img without uncompressing it. Did that now and ended up with 60 GB of data.\n\nAnd the contents?\n\n=== root@dereel (/dev/pts/1) /bde 13 -> mdconfig -a -t vnode -f /src/bde/besplex/ad2.img\n\nmd0\n\n=== root@dereel (/dev/pts/1) /bde 14 -> l /dev/md0\n\nmd0 md0s1 md0s2 md0s2a md0s2b md0s2d md0s2e md0s2f md0s2g md0s2h\n\n\n\nAll the BSD partitions there! So I can just mount them:\n\n=== root@dereel (/dev/pts/1) /bde 15 -> mkdir a b d e f g h\n\n=== root@dereel (/dev/pts/1) /bde 16 -> l\n\ntotal 1\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 a\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 b\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 d\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 e\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 f\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 g\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 h\n\n=== root@dereel (/dev/pts/1) /bde 35 -> for i in `echo a b d e f g h`; do mount -o ro /dev/md0s2$i $i; done\n\nmount: /dev/md0s2a: No such file or directory\n\n=== root@dereel (/dev/pts/1) /bde 36 -> df\n\nFilesystem 1048576-blocks Used Avail Capacity Mounted on\n\n...\n\n/dev/md0s2b 3,952 3,542 93 97% /bde/b\n\n/dev/md0s2d 3,952 2,971 664 82% /bde/d\n\n/dev/md0s2e 3,952 3,658 -21 101% /bde/e\n\n/dev/md0s2f 3,952 3,514 121 97% /bde/f\n\n/dev/md0s2g 11,754 8,842 1,972 82% /bde/g\n\n/dev/md0s2h 29,525 14,599 14,926 49% /bde/h\n\n=== root@dereel (/dev/pts/1) /bde 37 ->\n\n\n\nAnd in one of the partitions I found a file /bde/e/besplex/home/bde/dist/minix.tar.gz, which may be just what Jason is looking for. That was much easier than I thought. Is it correct? That would be too easy.\n\nMore fun with VirtualBox and bde Topic: technology, opinion Link here\n\nMore playing around with VirtualBox today, with no breakthrough. I had paused dereel with zzz, and when I restarted it the networking had gone to hell again. Here a repeat of what I had done yesterday:\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 1 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500 options=4e524bb<RXCSUM,TXCSUM,VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,LRO,WOL_MAGIC,VLAN_HWFILTER,VLAN_HWTSO,RXCSUM_IPV6,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 2 -> ifconfig em0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 3 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500\n\noptions=4c120b8<VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,WOL_MAGIC,VLAN_HWFILTER,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n\n\nAfter that it worked normally again, but the Microsoft boxen still didn't want to know. Do I have to cold start them every time?\n\nAnd Bruce Evans' C compiler? I posted what I had and got no answer. I'm not convinced that I have the right files, though the name usr/src/mx386/bcc (from the archive e/bde/dist/minix.tar.gz) does raise some hope.\n\nPower fail! Topic: general, technology, opinion Link here\n\nAt 11:04, while preparing breakfast, we had a grid power failure. Not a problem: we have a PV system. But the power dropped totally! Almost before we knew it, it was back again. The inverter log shows less than a minute.\n\nThat's not the first time. It happens far too often, most recently two months ago. And today, as then, my main machines eureka and hydra lost power, because I still hadn't got round to getting a UPS installed. Today I made up for that: I have a ten-year-old 1000 VA 650 W UPS just lying around. It is still functional? In contrast to the CyberPower UPS that I bought 2½ years ago, it seems still to work. While the power was down, took the opportunity to tidy up the mess to the left of my desk top, removing this display card from eureka and making a cut in my fingertip in the process:\n\nThat once drove three of the four monitors then connected to eureka, but that was years ago, as the dust suggests.\n\nWhat caused the outage? Hard to say. The inverter logs show no sign of overvoltage before the outage, though afterwards the voltage hung over 250 V for over an hour. I suppose it's time to brave the potential issues and update the firmware.\n\nPowercor had a different view. An hour later I received a message:\n\nAnd then\n\nOn checking, I found that I also had similar messages from the day before, where there was no outage at all. Still, rather phantom outages than real ones.\n\nhydra upgrade Topic: technology, opinion Link here\n\nI've had hydra for nearly 2 years, and I still haven't got round to configuring it quite the way I want; much is in the X menus. But of course the system is now down-rev. What better time then after a power failure to bring it up to date?\n\nMy real concern after an update is that the ports will no longer work the way I want. Building a new world is relatively simple, and it took just shy of 1000 seconds to build the world and new kernel. And rebooting went relatively smoothly, though it no longer found the Ethernet card on the motherboard. I had suspected issues in that area (it's a 2.5 Gb/s Realtek card) and installed a second, which showed up as re0 , so all I needed to do was to change where I plugged in the network cable.\n\nAs I feared, the ports were a different matter. They were worse then ever before, taking 3 iterations to delete 100—no, 101—no, 103 ports, including chromium curl, emacs of course, enblend, exiv2, feh, ffmpeg, firefox, fusefs-curlftpfs, gdb, git, gnupg, groff, hugin, mplayer, mpv, mutt, rdesktop, rsync, rtorrent, vigra, virtualbox-ose, xpdf and xv. And even then I missed ImageMagick, which further annoys me with a change of name. Yes, convert is a subcommand of ImageMagic, but now they have decided that the name is too invasive, so I'll have to change all invocations to magick convert. I suppose that one's fair enough.\n\nAnd firefox has new messages, which it spews by the hundred where it presumably suspects nobody is looking, on the home terminal:\n\nconsole.warn: services.settings: Could not determine network status. Message: TypeError: can't access prop \"isLinkUp\", lazy.gNetworkLinkService is undefined\n\nGradually the issues became clear: I can no longer connect to eureka with ssh, nor at all to hydra. I was expecting issues with eureka, but not with hydra. Was it because it came up before the network was ready? I had to restart syslogd to get it to write to eureka, and to change the permissions on wake for normal users to use it.\n\nWhat am I left with? I can no longer use erc, the Emacs IRC command:\n\nerc: missing symbol (.at)\n\n⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.\n\n\n\nWhat does that mean? I'll find out some time. Fortunately it still works on eureka, so there's no hurry.\n\nAnd independently of all that I need to pay more attention to my X configuration. I still don't get my mice set up correctly at startup. But that's fun for another day.\n\nCompleting the upgrade Topic: technology, general, photography, opinion Link here\n\nInto the office this morning as usual. No mail from hydra. What happened there? /var/log/maillog showed a number of:\n\nSep 20 03:03:54 hydra postfix/cleanup[70392]: B1BC41AB5: message-id=<202509191703.58JH3sRP070451@hydra.lemis.com>\n\nSep 20 03:03:54 hydra sendmail[70451]: 58JH3sRP070451: to=root, ctladdr=root (0/0), delay=00:00:00, xdelay=00:00:00, mailer=relay, pri=33687, relay=[127.0.0.1] [127.0.0.1], dsn=2.0.0, stat=Sent (Ok: queued as B1BC41AB5)\n\nSep 20 03:03:54 hydra postfix/qmgr[1845]: B1BC41AB5: from=<root@hydra.lemis.com>, size=4303, nrcpt=1 (queue active)\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: unexpected attribute smtputf8 from local socket (expecting: sendopts)\n\nSep 20 03:03:54 hydra postfix/smtpd[70368]: disconnect from localhost[127.0.0.1] ehlo=1 mail=1 rcpt=1 data=1 quit=1 commands=5\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: deliver_request_get: error receiving common attributes\n\n\n\nWhat's smtputf8 ? Checking /usr/local/etc/postfix/ showed that a number of files, which should have been symlinks to the same directory on eureka, were missing. Forgot to mount a NFS file system. After mounting and restarting postfix, all was well. But what does the strange message mean? It seems that it's a default.\n\nAnd then there was Hugin. I had expected some issues, but not what I got: when I tried to start the “fast panorama preview” I got\n\nerror installing GLEW\n\nFast preview window can not be opened\n\nWhat does that mean? I have a package installed, which pkg reports as\n\nglew-2.2.0_3 OpenGL Extension Wrangler Library\n\nAnd there doesn't seem to be anything else that was there before. But when I retried the attempt, it worked. Where is the bug? Hugin or FreeBSD? In addition, irritatingly it resized the windows on every start. I thought I had got rid of that with some script magic, but it seems to be gone.\n\nAnd then there's the mouse. That's simple enough: instead of searching for the index for the mouse, it's easy enough to write\n\nxinput set-button-map \"Telink 2.4G Mouse\" 1 2 3 4 5 6 7 2 2 10\n\nOne of the messages I received was completely misleading:\n\n=== grog@hydra (/dev/pts/16) ~/Photos/20250920 47 -> (EE) event4 - Telink 2.4G Mouse, class 0/0, rev 1.10/1.00, addr 4: client bug: event processing lagging behind by 32ms, your system is too slow\n\n(EE) client bug: timer event4 debounce: scheduled expiry is in the past (-48ms), your system is too slow\n\n(EE) client bug: timer event4 debounce short: scheduled expiry is in the past (-61ms), your system is too slow\n\n\n\nThat's not hydra at all, despite the prompt. I started X on teevee from hydra, and this appears to be its way of saying “the cat got on my mouse”.\n\nAccessing systems with ssh from eureka Topic: technology Link here\n\neureka is now running a nearly 10 year old system, but I don't want to update it: it works.\n\nBut some issues remain. One was that I couldn't automatically log on with ssh: I had to enter a password, which is irritating in scripts. Once again Google Gemini to my aid. Add this to /etc/ssh/sshd_config:\n\nPubkeyAcceptedKeyTypes=ssh-ed25519,ssh-rsa,rsa-sha2-512,rsa-sha2-256\n\nNow I just need to see why I can't access eureka from hydra without a password.\n\nFinally the birding photos Topic: photography, animals, technology, opinion Link here\n\nIt's been 4 days since the latest OM System birding “workshop”, and I've only just got round to processing the best photos. Are these the best?\n\nIt's a lot of work making up my mind out of over 250 photos. Yvonne did it for me, and those were the ones she liked.\n\nMore ssh strangeness Topic: technology, opinion Link here\n\nI've already established issues with ssh sessions from hydra to eureka, but not from other systems. Once again Google Gemini to my aid, this time less useful. It tells me to allow ssh-rsa in /etc/ssh/sshd_config by adding this line:\n\nPubkeyAcceptedKeyTypes=+ssh-rsa\n\nWe've seen that before on the other side. But that's a non-starter: sshd doesn't want to know:\n\n=== root@eureka (/dev/pts/1) /etc/ssh 28 -> service sshd restart\n\nPerforming sanity check on sshd configuration.\n\n/etc/ssh/sshd_config: line 54: Bad configuration option: PubkeyAcceptedKeyTypes\n\n/etc/ssh/sshd_config: terminating, 1 bad configuration options\n\nOK, what about the alternative of using a key?\n\n=== root@eureka (/dev/pts/1) /etc/ssh 32 -> service sshd restart; date\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStopping sshd.\n\nWaiting for PIDS: 22656.\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStarting sshd.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\n\n\nWhy? It doesn't seem to affect other key forms. And comparing hydra and tiwi gives me on hydra:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: send_pubkey_test: no mutual signature algorithm\n\n\n\nBut on tiwi it works as expected:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: Server accepts key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\nAuthenticated to eureka.lemis.com ([192.109.197.137]:22) using \"publickey\".\n\n\n\nWhat's the difference?\n\nMutt problems Topic: technology, opinion Link here\n\nFirst thing I do in the morning is to read the overnight mail, typically a couple of hundred messages. But this morning I tried to delete the messages I had read, I received the message “unable to write mailbox” or something similar. Why? Normally I see a message like that when I'm out of disk space, but this wasn't the case. Return, painfully delete the messages again, and it worked. Is that an NFS issue? It has happened before. Was that also overnight? I'll have to look more carefully next time.\n\nMore ssh pain Topic: technology, general, opinion Link here\n\nInto the office this morning to find eureka maxed out with at least 35 ssh-add processes, all looping at 100% CPU time.\n\nWhy? This is not a new program:\n\n3054180 -r-xr-xr-x 1 root wheel 17576 25 Nov 2015 /usr/bin/ssh-add\n\nOnce again Google Gemini to my aid, coming with the suggestion that it could be that ssh-add was running already, and that I should put in code like\n\nssh-add -l >/dev/null || ssh-add\n\nThat worked up to a point, but it doesn't explain why it is only happening now, after nearly 10 years. It's much more likely that it's related to the playing around I have been doing lately, though it didn't affect ssh-add, and I had backed out the changes anyway. And in the course of the day I found another instance in my weather software, but that found further breakage: the external view of my weather stopped in early June when I got the new weather station. More to fix when the current problems are over.\n\nssh-add: A clue Topic: technology, opinion Link here\n\nI haven't done much to investigate the ssh-add problem for the moment. It seems that I call ssh-add in a number of places, all of which need fixing. But while playing around I found:\n\n=== grog@eureka (/dev/pts/3) ~/public_html 32 -> ssh-add < /dev/null\n\nEnter passphrase for /home/grog/.ssh/id_rsa:\n\nCould it be that the looping is the incorrect handling of a prompt? It doesn't help much in fixing it, but it could help understand.\n\nThe advantages of upgrades Topic: technology, opinion Link here\n\nAs expected, upgrading hydra caused a number of problems, most of which I have described. And this time it was Chromium, which has forgotten all its editing keys, or at least the ones I want. More searching required.\n\nOn the other hand, one bug has gone away: xv can now display PNG again. Not exactly a big improvement, but at least a fixed bug.\n\nThe daily Android bug Topic: technology, opinion Link here\n\nSomehow the Android operating system seems to be the least reliable I know. I'm gradually coming to terms with it, but today there was another one: trying to download files to a Real Computer, albo didn't respond, though it claimed to be working. Disable Wi-Fi, reeenable, and it worked. No change of connection.\n\nWhat a mess Android is!\n\nAnother web server overload Topic: technology, opinion Link here\n\nIt's been well over 4 months since I set up a new external web server, fra.lemis.com, to address the really heavy load, with load averages up to 170. And so, of course, it dropped back to under 1.\n\nBut now it's increasing again, both servers now well over 200. Why? I had thought it was related to the imagesizes parameter, but that doesn't seem to be the case. Let's see how long the overload lasts this time.\n\nFast postal service Topic: general, technology, opinion Link here\n\nI've bought a couple of cameras in the United Kingdom. The usual tracking information, with a twist:\n\nIt's in Leeds, but it'll be here tomorrow! Now that's a lot faster than Australia Post. Or just plain stupid.\n\nYour cameras have been delivered! Topic: technology, photography, general, opinion Link here\n\nYesterday's claim of fast delivery was amusing enough, but they haven't given up:\n\nThey have been delivered! How did we do?\n\nI'm amazed. Clearly the cameras are still in the United Kingdom. My best guess is that Royal Mail have delivered the cameras to the people who are currently in the process of sending them half way round the world, or at least they have received documentation from them. So from their limited viewpoint they have been delivered. No concept of them only having travelled a fraction of the distance.\n\nWeb server load: dropping Topic: technology Link here\n\nYesterday's web server overload didn't last long. It's back to round 1 again. I suppose that's what we're going to have to live with for the foreseeable future. It's interesting that even at this extreme overload people claimed that response was satisfactory. That's significantly different from last time, where some sites got timeouts.\n\nArtificially intelligent breakfast Topic: food and drink, technology, opinion Link here\n\nFor some reason we bought a quarter cabbage recently. I forget why, but it was intended for breakfast. All right, Google Gemini, give me some east asian recipes with fried cabbage.\n\nAnd the twins obliged: 手撕包菜 - Shǒu Sī Bāo Cài, “hand shredded cabbage\", which didn't look too bad, modulo these horrible cups measurements. I can't even blame the twins for that: so many recipes use it. But it's the biggest hindrance I can find for trying out recipes. OK, Gemini, give me a Chinese recipe with fried cabbage and noodles using metric units. OK, how about 包菜炒粉/麵, which Google Translate translates as “cabbage fried rice noodles”? A completely different recipe! The best I can guess from the two recipes is that 4 cups of cabbage weigh about 300 g.\n\nSpent some time—probably more than cooking—writing a sane version of the second recipe.\n\nSoftware upgrades: the sting in the tail Topic: technology, photography, opinion Link here\n\nHouse photos again today, the second time since I upgraded hydra to FreeBSD 14.3 last week. And once again I had pain.\n\nFirstly, creating HDR didn't work well. It took me a while to discover that it was an unrelated bug in one of my scripts: I managed to mix images from the OM System OM-1 Mark II with the correct images from the Olympus OM-D E-M1 Mark II. I had already expected problems like that, and /Photos/Tools/housephtos.awk contained appropriate comments. Here the fix:\n\n-# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n+# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n# Create a makejpeg file from housephoto.notes file.\n\nBEGIN {\n\ni = 0;\n\n-# XXX Only look at photos from E-M1 Mark II.\n\n+# Only look at photos from E-M1 Mark II.\n\n# Is this safe?\n\n-# Was: 4*.ORF, E-M1 /2 only\n\n- while (\"ls -rt *.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n+# It's better than the alternative.\n\n+ while (\"ls -rt 4*.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n\n\nThe problem was that I didn't limit the choice to photos from the E-M1 Mark II. Not an upgrade problem at all.\n\nThe other, though, seems to be related to the upgrade of Hugin, now version 2024.0.1. The screens appear in the wrong place and at the wrong (tiny) size, and the directories are wrong. That's almost certainly related to the scripts that I wrote over 16 years ago which frob the ~/.hugin file to get rid of this horrible directory name retention. But that's all they do, and somehow it doesn't seem to work. A small detail, but irritating. Will I get round to it by next week?\n\nRevisiting old photos Topic: photography, technology, opinion Link here\n\nLooking back through old photos, found some of my first panoramas:\n\nIt dates from 11 April 2009 with the Olympus E-510, so old that I don't even have Exif data for it. I had already attempted to improve it 8 years later:\n\nBut that was still with the Ashampoo Photo Optimizer, which I have stopped using. Another attempt with “Perfectly Clear” gave me further improvements. Here are the three together (run the cursor over an image to compare it with its neighbour):\n\nIn particular the highlights and shadows are greatly improved.\n\nfra rebooted! Topic: technology, general, opinion Link here\n\nThe vultures have rebooted fra! Yes, they warned they would do so because of some unspecific bug in Linux, so they rebooted my FreeBSD box as well. The good news is that it came back without any intervention on my part, but of course the up time has gone to hell.\n\nAnother bloody power fail Topic: technology, general, opinion Link here\n\nIn the evening, another grid power failure. And another directly behind it. Both were sub-second, but once again eureka and hydra failed. So much for the UPS.\n\nWhy? Yes, it's an old UPS, but it claims to have plenty of charge, and the failures were so short that most clocks in the kitchen kept going. Can it be that it was a power surge, and that this UPS didn't handle it? The UPSs for lagune, teevee and tiwi had no problems.\n\nAnd the fallout? I got things running relatively quickly, but firefox didn't recover its many tabs. I had to start a different profile to get anything. And of course X on teevee failed, because I had started it from hydra.\n\nSo what do I do now? Buy more of UPSs of the kind that power the other machines?\n\nTuesday, 30 September 2025 Dereel Top of page previous day\n\nMore firefox pain Topic: technology, general, opinion Link here\n\nSo what's wrong with firefox? My standard profile just hangs. Why? How do I debug such a mess?\n\nI tried setting up a different profile, losing a number of tabs in the process, but nothing I could do could get the font sizes right. Get them right for my diary (without any trickery) and they're far too small for things like Wikipedia and friends. Migrate from hydra:0.2 (3840×2160) to hydra:0.0 (1920×1080)? Yes, that works, but why did it happen?\n\nThen it occured to me: yes, the standard profile still hangs. But I can check the settings. And it seems that the big thing is the Zoom setting, which was at 150%. After setting that, things were OK. But why the difference between my diary and Wikipedia and Co.? And why are font sizes such an issue with firefox?",
      "source": "Lemis.com",
      "url": "http://www.lemis.com/grog/diary-sep2025.php?topics=c#D-20250909-003710",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Chasing the VirtualBox bug",
      "content": "AI: enough! Topic: technology, general, opinion Link here\n\nSunday's detailed investigation of generative artificial intelligence should have been enough, but it occurred to me that there was one thing I hadn't tried: graphics. OK, draw me a caricature of Greg Lehey.\n\nGoogle Gemini came up with this:\n\nOf course I don't need to like the results, but this shows very little understanding: no mention of BSD, just Linux (or even “Linix”). Yvonne tells me that it looks nothing like me. Compared to the text results, quite disappointing.\n\nAnd that was all. My other bots all couldn't do it. But their attempts were worth mentioning:\n\nChatAI\n\nI'm unable to draw images directly, but I can help you imagine a caricature of Greg Lehey! Picture a gentleman with a thoughtful expression, perhaps with glasses perched on his nose, and a hint of a smile suggesting a keen sense of humor. His hair might be slightly tousled, giving him a scholarly yet approachable look. You could exaggerate his features, like giving him a larger forehead to symbolize his intellect or a prominent chin to represent determination. Add a background filled with books and computers to reflect his interests in technology and writing\n\nI suppose that's acceptable for as far as it goes.\n\nClaude\n\nClaude did the best with the diary entry, but it failed completely with the caricature:\n\nClaude: I'd be happy to help you create a caricature, but I'll need a bit more information! There are likely multiple people named Greg Lehey, and I want to make sure I'm drawing the right person..\n\nClaude, you know who I am. There are “likely” multiple people named Greg Lehey? That wasn't a problem on Sunday. And as it happens, there is nobody else that I can find with the same name as mine. But OK, draw me a caricature of Greg Lehey, the FreeBSD person.\n\nI can't create visual caricatures or drawings as I'm a text-based AI. However, I'd be happy to help you in other ways: Written description: I could write a humorous written \"caricature\" or character sketch of Greg Lehman (assuming you meant Greg Lehman, a notable FreeBSD contributor) that captures his programming style, contributions to FreeBSD, or personality traits in an exaggerated, caricature-like way.\n\nWhat a cop-out! Now it says that it can't draw. And it comes up with a fictive Greg Lehman. That's completely useless.\n\nDeepSeek\n\nAs before, DeepSeek is inventive:\n\nWhile I can't physically draw for you, I can create a detailed \"blueprint\" for a caricature of the legendary BSD developer Greg \"Groggy\" Lehey. An artist could follow this description to create the perfect caricature. Here is a description designed for an artist to illustrate. Caricature of Greg \"Groggy\" Lehey Concept: The caricature should capture his iconic, jovial, and slightly mischievous personality, deeply intertwined with his life's work: BSD and Unix. Key Features to Exaggerate: The Beard and Hair: This is the #1 feature. Exaggerate his magnificent, full, and sprawling white beard. Make it vast and wizard-like, almost as if it's its own entity. It should be big enough to have a Daemon (the BSD logo) peeking out from within the whiskers, as if it lives there. His hair (what's visible under his hat) should be similarly wild and unkempt. The Headwear: He is almost never seen without a hat. Draw a slightly battered, well-loved flat cap or a beret perched on his head at a jaunty angle. Where did it get the hat from? I am almost never seen with a hat. The Expression: A wide, knowing, and cheerful grin. His eyes should be crinkled with laughter and wisdom, suggesting he's both a kind mentor and someone who knows where all the bugs in the code are hidden. The Props & Surroundings: In his hand: Instead of a coffee mug, he should be holding a massive, steaming beer stein. This is a nod to his famous \"Buy me a beer\" link on his website and his good-humored nature. Steaming beer? I can't even imagine that. And instead of referring to my brewing activities, it refers to a fictive “buy me a beer” link, which may be related to Poul-Henning Kamp. Under his arm: A well-worn copy of his magnum opus, \"The Complete FreeBSD\" book. Background Element: Have a Tux (the Linux penguin) peeking from around a corner, looking slightly nervous or annoyed, while Groggy pays it no mind. This playfully hints at the good-natured rivalry between BSD and Linux. Code: Faint lines of C code ( #include <beard.h> , printf(\"Cheers!\n\n\"); ) can be subtly woven into the texture of his shirt or the background. Overall Vibe: The image should feel warm, intelligent, and full of character. He is the friendly, brilliant, and slightly eccentric \"Unix Beard\" wizard, a beloved figure in the open-source community. Color Palette: Warm tones. Earthy browns for the hat, a rich color for the shirt (green or blue), the brilliant white of the beard, and the gold of the beer.\n\nStill, I suppose that could produce something useful. But where are all the image generators? Do I want to look? I've spent enough time on this already.\n\nWhy don't people read any more? Topic: language, general, technology, opinion Link here\n\nRecently I saw (but didn't read) a newspaper article, possibly from the New York Times, asking why people don't read books any more. The answer appears simple: information overload. When I was a lad I read lots of books, but it has been some time since I finished reading any, and then the relatively thin “Brave New World”.\n\nBut then we watched A Town Like Alice, and Yvonne borrowed the book. I have always liked Nevil Shute, and I have a number of his books, so I read it when she finished. It took me two weeks. While reading I was continually following up on details mentioned in the book—that's what the web is for, after all. In general, I ended up with a much broader view than I would have had if I had just read the book.\n\nAnd how did I like it? Not much. Clearly it's two different stories stuck together: the ordeals in Malaya at the hand of the Japanese occupation and the transformation of a tiny bush village in Queensland into a small town. The latter, in particular, seems very improbable.\n\nThe geographical details are what interested me most. Particularly in Malay(si)a I knew most of the real places. But I'm puzzled about why Shute spends a lot of time in the area Maran and Jerantut in the Jengka Triangle, places that must have been almost completely unknown at the time, but puts the women in a place called Kuala Telang “about half-way between Kuantan and Kota Bahru”. There is a town in that position, but it's called Kuala Terengganu, and it's a big town (capital of the state of Terengganu), not a small village. My guess is that Shute had never heard of it.\n\nSpelling is also strange. In the first half of the book, Kota Bharu was spelt “Kota Bahru”, and in the second half “Khota Bahru”. Tennant Creek became “Tennants Creek”. These spellings are the same both in the online book and the physical book that I read. And there are a couple of irritating US Americanisms that I don't understand: the animals central to the theme are called alligators, not crocodiles. The stockmen use lariats.\n\nThen there's the question of racial attitudes. The local aborigines (or aboriginals, to use the modern politically correct term) are called “boongs” or “abos”. Both are offensive nowadays. And there was talk of racial segregation, a separate milk bar for the boongs. This would have been about 1948, the time of my birth. Did such segregation really exist then?\n\nMy favourite one, though, is when the main characters (Jean and Joe) fall in love, and she decides not to sleep with him until after they are married. Given that Joe had been crucified in the first half of the story, I was half guessing that he might have been castrated at the same time, and Jean would not have found out until too late.\n\nIn summary: reading books has become much more of an exercise than it used to be. For light entertainment we have TV. I don't think I'll read another novel for some time to come.\n\nPredicting the past Topic: general, technology, opinion Link here\n\nI keep a close eye on the weather forecasts from the Bureau of Meteorology, both of them. There's one on the web and another for mobile phones. They don't often agree with each other, and of course they're both frequently wrong.\n\nToday, though, the mobile phone app excelled itself. We finally have rain, 6 mm over the last 24 hours. Or, as the app put it,\n\nPart of the app is a rainfall map showing precipitation. That showed that there was much more rain. How can that happen?\n\nWhatsApp: bug after bug? Topic: technology, opinion Link here\n\nI've been trying for a week now to set up video telephony on fossil, Yvonne's mobile phone. Somehow the “modern” approach to user interfaces shows itself at its worst here. But I had come to the conclusion that if I can work beyond WhatsApps bizarre interface, and explain it to Yvonne so that she doesn't have a panic attack every time she uses it, we might have something useful, especially since WhatsApp can communicate by an Internet link, which could be much cheaper.\n\nOK, try out on hirse first. It doesn't have a SIM card, so any communication has to go by the Internet. Migrate my main number to hirse. No problem. Make a call. Some message like “need to use the phone network”. Oh.\n\nTry calling in. The problem: hirse has the phone number associated with a SIM card in albo, which has a different WhatsApp number. Which does WhatsApp call? albo! Somehow there's more to this than meets the eye.\n\nWhen Yvonne got back from shopping, I changed her WhatsApp number to the number of second SIM on her phone. All sorts of things didn't work, and it couldn't call the number on hirse. hirse claimed that she wasn't registered, though I had set the “notify contacts” during the migration. In the end I moved the number back to the old one. And things still didn't work correctly! In particular, I could call the number, but WhatsApp didn't respond in any way, not even registering a missed call. Went through the settings and set tones for all notifications. Still no response. Restart the app. No response.\n\nNothing for it, the Microsoft solution: reboot. And yes, now it responds. Clearly some kind of bug. And it repeats the call tone for every notification, including messages. Oh, my bad. Get rid of the tone. Sorry, there's no provision for that. Select something at random, since it's too polite to play the tone when you're selecting it. I still get the ring tone for messages! I can't see any explanation except that it's another bug. It was getting late, so I turned off sounds to wait until tomorrow.\n\nAll this is made worse by the horrible user interface. So far I haven't found a way to display the associated phone number in the contact details. At one point I made the mistake of using the same name (mine) for both my phones, so there was no way at all to find out what “number” it had called.\n\nI hate WhatsApp! Topic: technology, general, opinion Link here\n\nMore fun with WhatsApp today. The first question, which decides whether it's even worthwhile: can I make a call over the Internet? Yesterday's experiments were overshadowed by other bugs. Today I tried making a call from fossil (Yvonne's phone) to hirse, the one without a SIM card. I have set it up with the main number of albo, so a normal call to that number should go to albo, and a WhatsApp call should go to hirse. Does it?\n\nYes! So yesterday's issues were probably due to other bugs.\n\nAnd the incorrect notification tones? Gone since the last reboot, Yvonne says. But later she changed her mind: once again the wrong tone when all notification tones were turned off.\n\nDammit, begone, WhatsApp! Removed it. Reinstalled it. And how about that, setup was almost completely without problem. She lost her image (“Avatar”, “The manifestation of a god in bodily form on earth” according to the OED). We can live with that. And somehow now everything Just Works—until the next unpleasant surprise.\n\nApart from that and the horrible user interface, established that you can change an audio call into a video call simply by pressing the button with the box with a loudspeaker on the right:\n\nInterestingly, it only works in one direction. To go in the other direction requires that the person at the other end do the same.\n\nVirtualBox again Topic: technology, photography, opinion Link here\n\nDxO PhotoLab 9 is out, and it looks worth trying. Time to reinstate one of my Microsoft virtual machines, which run under VirtualBox.\n\nI stopped using VirtualBox on hydra a year ago, though it was the main reason that I had so much memory (192 GB): I ran into network problems that I couldn't fix.\n\nNow FreeBSD has a port of VirtualBox 7. Time to try again? Tried first on dereel, with only 24 GB of memory. Where's my HOWTO? All fine, but it doesn't tell me how to add an existing VM. It must be in this diary somewhere, but where? I really should keep these HOWTOs up to date.\n\nStarting up the GUI was different from before, of course. And it wanted to set things up in the root file system. To go elsewhere I had to do this horrible tree walking. Finally I got to where I wanted (/src/VirtualBox/echuca). Tried to create a new VM. “Can't overwrite machine folder...\". What does that mean? They should know better than to call a directory a folder, but what's a “machine folder”? Lots of experimentation, continually being returned to the /root directory and having to climb my way out again. What does “help” say? Nothing. I wonder if the port forgot to install something important. After a while I discovered that it really wanted the parent directory /src/VirtualBox, but then I ran into other issues.\n\nAfter some time decided to create a new VM with the old virtual disk. Link? Yes, but VirtualBox detected the UUID and used the old name.\n\nYes, there are other possibilities. But I think that the best is to go through my diary and extract the information that I need to do things sanely. And maybe I should use the commands rather than the GUI, which seems to be getting more stupid as time goes on.\n\nWhatsApp an Avatar? Topic: technology, general, opinion Link here\n\nYesterday I established that an Avatar is a earthly manifestation of a Hindu god, but WhatsApp apparently wants to elevate Yvonne and me to deities. Until then, only initials appear to identify us on calls.\n\nOK, how do we do that? Settings, of course, “make your own avatar”, “Create from selfie”. OK. Take a suitably horrified photo of myself. Briefly it showed “There was an error with the avatar gen...”, so briefly that I didn't see it the first three times. What does that mean? Why can't it finish its sentences? So instead it presented me with a manual generation.\n\nWhy? What does the half message mean? It's repeatable on two different phones. And there seems to be no way to just add a normal photo. What a mess!\n\nVirtualBox progress Topic: technology, opinion Link here\n\nSo what's wrong with my VirtualBox installation? My current situation was exactly what I had a year ago: most VMs worked, but Microsoft VMs had networking problems. They could send data, but they didn't see the replies, so they hung in ARP. I attributed that to the version of VirtualBox (6.1.50 r161033), so I waited until version 7 came out. And then I discovered that I had exactly the same problem.\n\nThat didn't help just getting things running. After some searching, discovered that VirtualBox stores a configuration in the home directory, ~/.config/VirtualBox/ with a number of files, including log files that have no business there, but importantly VirtualBox.xml. OK, make a copy of that on dereel, and how about that, VirtualBox came up with all the VMs I knew.\n\nStart disaster, the only VM that would fit in dereel's memory.\n\nVT-x is disabled in the BIOS for all CPU modes (VERR_VMX_MSR_ALL_VMX_DISABLED).\n\n\n\nOh. There was something there, but can the twins help? Yes, specifically for a ThinkCentre:\n\nOnce in the BIOS, use the arrow keys to navigate to the Advanced tab. From the Advanced menu, select CPU Setup and press Enter. Look for an option labeled Intel(R) Virtualization Technology and select it. Using the arrow keys, change the setting from Disabled to Enabled.\n\nAfter that and rebooting, and with a change of network adapter name, it still didn't start. I got this message:\n\nX86_CPUID_AMD_FEATURE_EDX_AXMMX is not supported by the host but has already exposed to the guest [ver=19 pass=final] (VERR_SSM_LOAD_CPUID_MISMATCH).\n\nMore help from the twins. The saved state includes information from an AMD processor (hydra), but this is Intel. Discard saved state and start again.\n\nAfter that, and with a change of network adapter name, it started. I got this message, which I haven't seen before, but which seems harmless:\n\nerror: XDG_RUNTIME_DIR is invalid or not set in the environment.\n\nThat variable isn't set on hydra either.\n\nWe're still not done. Trying to start an xterm from current gave me the message\n\nThe Virtual Machine reports that the guest OS does not support mouse pointer integration\n\nWhat's that? Gemini tells me:\n\nThe message \"The Virtual Machine reports that the guest OS does not support mouse pointer integration...\" in a FreeBSD virtual machine is common and means you need to install and configure the necessary guest additions for the mouse to work seamlessly. FreeBSD does not include these drivers out of the box, so you must install them yourself.\n\nThat sounds like the Ports Collection. But there is no additions package for VirtualBox 7.1, only for 6.50 and 5.2. Mañana.\n\nOn with disaster. So: ARP issue? While messing around on disaster, found the help message for ARP. It uses Unix-style option delimiters, and -s sets a permanent MAC address. OK, if this is an ARP issue, we can fix that:\n\nOh: Microsoft has a different format for MAC addresses. Try again:\n\nAnd that as Administrator . Time to ask the twins.\n\nQ: What does \"The ARP entry addition failed: Access is denied\" when running CMD as administrator under \"windows\" 10? A: The \"ARP entry addition failed: Access is denied\" error in Windows 10, even when running Command Prompt as an administrator, typically happens when trying to add a static Address Resolution Protocol (ARP) entry for a reason other than a permission issue.\n\nInteresting. “Access is denied” is not a permission issue? Something's wrong here, either Gemini or Microsoft. My money is on Microsoft.\n\nAnd that's what Gemini suggests too:\n\nUse netsh instead: In some cases, especially on newer versions of Windows, the arp command may have issues with Access is denied errors even when the user has administrator privileges.\n\nSo I ended up with this simple invocation:\n\nAnd how about that, it worked. Well, at least it put the address in the ARP table, and I was able to ping out, so disaster knew the address. But it still didn't hear any reply.\n\nYet another question to Gemini:\n\nWhat could cause a Microsoft guest under VirtualBox to send network data but not receive it, when other guests have no problem with the same configuration?\n\nThe obvious answer: firewall. Check to be on the safe side. No, no firewall enabled. How about an Ethernet adapter issue?\n\nIf you are using an Intel PRO/1000, try switching to a different type, such as the AMD PCnet-FAST III.\n\nOK, try that. No improvement. Next idea: this video\n\nOK, try anything once. Follow the instructions step by step, none of which showed any obvious issues. Change the interface back to (specifically) Intel PRO/1000 MT Deskop (8254EM). Not much hope there: that's what I had.\n\nBut it worked! My final configuration looks identical to the start configuration. What changed? There's something lurking under the surface that I don't understand. Can I now get it to run on hydra?\n\nMore VirtualBox pain Topic: technology, opinion Link here\n\nYesterday I finally got networking working using VirtualBox 7.1 and Microsoft “Windows” 10. Time to refine a few things. First, start the windows on hydra:0.0, a 1920×1080 display, rather than on hydra:0.1, which has 3840×2160, giving windows that are too small.\n\nBut it didn't work! I could start on hydra:0.1, but on hydra:0.0 nothing happened. Is there some kind of built-in memory in the configuration file?\n\nSo, time to upgrade current.lemis.com, another VM running FreeBSD-CURRENT. It was a year out of date.\n\nStart a make buildworld , not for the first time. But nothing happened!\n\nFurther investigation showed that I had a network hang. And disaster was also hanging! Shut down disaster and current regained network access—for a while. Then it hung again.\n\nThis seems worse than my experience on hydra with VirtualBox 6.5. Tried it there and it worked.\n\nWhat a pain! What does Google Gemini say?\n\nQ: Are there known networking issues with VirtualBox under FreeBSD? A: Yes, there are known networking issues and quirks with VirtualBox when used as a host on a FreeBSD system. While VirtualBox works, it is not an officially \"supported\" host platform by Oracle, which means users often have to rely on the community and package maintainers to troubleshoot and resolve issues. (much irrelevant information omitted) Users sometimes experience slow network speeds, particularly with upload speeds, when using bridged adapters. This can be more pronounced on specific emulated network card types. While VirtualBox can function as a host on FreeBSD, it is not a \"fire-and-forget\" solution... If you encounter speed or reliability issues, experimenting with different emulated network adapter types can often resolve the problem.\n\nThat's not encouraging, though it doesn't directly relate to my problems. But what else can it be? Two different versions of FreeBSD, two different machines, two different versions of VirtualBox. Does it work better on Linux? That would be a real let-down, but possibly I should try it. How much pain would that be?\n\nTesting RSS feeds Topic: technology Link here\n\nI write all my web markup myself, with the aid of a number of PHP scripts. The result is that the RSS feed looks nothing much like my sources. So when something goes wrong with the markup, it's hard to find where, not helped by things like the W3.org validator, which typically points to where the error is detected, not where it occurred, and which at the moment caches input, so even after fixing the problem it reports the old problem.\n\nCallum Gibson is the main user of RSS feeds whom I know of. He pointed me to this validator. It also points to where the error was found, but at least I can try things and repeat them. That fixed an issue I had with earlier this month, where the error was over 100 lines from where it was detected.\n\nChasing the VirtualBox bug Topic: technology Link here\n\nSo why was VirtualBox version 7.1 on dereel even worse than version 6.50 on hydra? One possibility might be that the VMs themselves were NFS mounted. OK, find a 1 TB disk and copy them there. Put it in in place of the DVD drive, and was amazed to find that it came up as /dev/ada0, relegating the system disk to /dev/ada1 and requiring manual intervention (/etc/fstab) to continue. How could that happen?\n\nThen copying the VMs from hydra. That took a few hours, of course, so I'll continue tomorrow.\n\nWhile looking for the disks also found one marked “MS “Windows” 10 disgust”, dated 10.XII.2020. Comparing with my diary, that proves to be the disk that came with the machine I'm working on. So I should be able to just put it in and run it. That's the next thing to do if I still can't get VirtualBox to run reliably.\n\nDxO PhotoLab 9: worth the trouble? Topic: photography, technology, opinion Link here\n\nI've spent a lot of time looking at the new features of DxO PhotoLab 9. Even better noise reduction, of course, but the big new thing is what appears to be excellent object recognition (“masking”). But that's only part of the story. Can I remove objects? Replace them with something else? It seems that the answer is “no”.\n\nSomewhere I also thought I saw a way to merge HDR images, but that seems to be a misunderstanding. Instead they have improved file handling, including collapsing related image groups and automatic file naming. None of them seem to be anywhere near as flexible as the method I worked out 13 years ago, so it's of no use to me.\n\nSo: what will the future bring? The masking is good, but is it enough to spend US $240 on? There's a very good chance that they'll come up with a version 10 in the not-too-distant future and want $120 for an upgrade. Maybe I should just wait.\n\nVicRoads: still in the 20th century Topic: general, technology, opinion Link here\n\nAfter scrapping my Hyundai Elantra at the end of July I was due a refund for the registration.\n\nAnd they sent me a cheque! I thought they went out of fashion well over a year ago. And yes, the bank refused to accept it.\n\nBut why? I really don't understand. They should have transferred it to my bank account, like any sane company. But no, I had to call their customer service line (1300 555 165, which looks suspiciously like a fake US phone number) and go through their silly authentication process (including a form of 2FA, sending a PIN to my phone. That would have helped a lot if I had been calling from that phone). But yes, relatively quickly they took the details and told me that the transfer would occur in the next 2 to 3 weeks. Receipt number HD1155831.\n\n2 to 3 weeks? Why? Ah, we need human intervention. Why? Nowadays we have computers. With only marginally good programming the money could have been in my bank account before the end of the call. But clearly they don't have that.\n\nMore VirtualBox insights Topic: technology, opinion Link here\n\nSo what's wrong with VirtualBox networking? Google Gemini had suggested that it might depend on the emulated network adapter, so spent some time trying different adapters, with no improvement. About the only thing that was clear was the ping time: from guest to host the expected 0.15 ms, but in the other direction much longer, and with wildly different times:\n\nround-trip min/avg/max/stddev = 29.752/61.679/175.892/36.953 ms\n\nGave that up and looked at some bug reports, which showed surprisingly few network issues. But one, by Ivan Rozhuk, was interesting:\n\nTry to disable HW offloads on NIC:\n\nifconfig igb0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n\n\nAnd how about that, that worked. So why is this not better known? There's also a wiki with surprisingly little of use.\n\nLater I discovered that my guest current.lemis.com had 8 CPUs, while the host dereel only has four. That's quite impressive that it worked at all. Reducing the number of CPUs on current got rid of the slow ping times.\n\nSo: are we done? I don't think so. I still need to find whether the Microsoft guests work reliably.\n\nBruce Evans' C compiler Topic: technology, opinion Link here\n\nMail in the TUHS mailing list today:\n\nSubject: [TUHS] Bruce Evans 386 Minix patches & compiler source\n\n\n\nIt's been quite a while since I was messing with Minix386 back in the days\n\nwhen Bruce Evans released a set of patches to bring 386 support.\n\nI'm pretty sure over on oldlinux.org the patch set exists, but I can only\n\nfind the one set of binaries of his 386 toolchain.\n\nI know it eventually evolved into the bin86 toolchain that Linus would go on\n\nto use to create real mode boot code, but I don't know if any of the source\n\ncode to his 1991/1992 386 toolchain ever got published?\n\n\n\nIs it somewhere on the disk images that Peter Jeremy saved? I haven't looked at them for over three years, and I only had the smaller ones that I could download. Sent off a message to the other people who have access, Warren Toomey (who also coincidentally runs TUHS) and Warner Losh, and only got a brief response from the first.\n\nBack to look at what I have: three files, /src/bde/ad1.img, /src/bde/ad2.img and /src/bde/ad3.img. I had only looked at /ad0.img, requiring gnop to access the individual partitions. There was a good reason: I had renamed ad2.img.xz to ad2.img without uncompressing it. Did that now and ended up with 60 GB of data.\n\nAnd the contents?\n\n=== root@dereel (/dev/pts/1) /bde 13 -> mdconfig -a -t vnode -f /src/bde/besplex/ad2.img\n\nmd0\n\n=== root@dereel (/dev/pts/1) /bde 14 -> l /dev/md0\n\nmd0 md0s1 md0s2 md0s2a md0s2b md0s2d md0s2e md0s2f md0s2g md0s2h\n\n\n\nAll the BSD partitions there! So I can just mount them:\n\n=== root@dereel (/dev/pts/1) /bde 15 -> mkdir a b d e f g h\n\n=== root@dereel (/dev/pts/1) /bde 16 -> l\n\ntotal 1\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 a\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 b\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 d\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 e\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 f\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 g\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 h\n\n=== root@dereel (/dev/pts/1) /bde 35 -> for i in `echo a b d e f g h`; do mount -o ro /dev/md0s2$i $i; done\n\nmount: /dev/md0s2a: No such file or directory\n\n=== root@dereel (/dev/pts/1) /bde 36 -> df\n\nFilesystem 1048576-blocks Used Avail Capacity Mounted on\n\n...\n\n/dev/md0s2b 3,952 3,542 93 97% /bde/b\n\n/dev/md0s2d 3,952 2,971 664 82% /bde/d\n\n/dev/md0s2e 3,952 3,658 -21 101% /bde/e\n\n/dev/md0s2f 3,952 3,514 121 97% /bde/f\n\n/dev/md0s2g 11,754 8,842 1,972 82% /bde/g\n\n/dev/md0s2h 29,525 14,599 14,926 49% /bde/h\n\n=== root@dereel (/dev/pts/1) /bde 37 ->\n\n\n\nAnd in one of the partitions I found a file /bde/e/besplex/home/bde/dist/minix.tar.gz, which may be just what Jason is looking for. That was much easier than I thought. Is it correct? That would be too easy.\n\nMore fun with VirtualBox and bde Topic: technology, opinion Link here\n\nMore playing around with VirtualBox today, with no breakthrough. I had paused dereel with zzz, and when I restarted it the networking had gone to hell again. Here a repeat of what I had done yesterday:\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 1 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500 options=4e524bb<RXCSUM,TXCSUM,VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,LRO,WOL_MAGIC,VLAN_HWFILTER,VLAN_HWTSO,RXCSUM_IPV6,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 2 -> ifconfig em0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 3 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500\n\noptions=4c120b8<VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,WOL_MAGIC,VLAN_HWFILTER,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n\n\nAfter that it worked normally again, but the Microsoft boxen still didn't want to know. Do I have to cold start them every time?\n\nAnd Bruce Evans' C compiler? I posted what I had and got no answer. I'm not convinced that I have the right files, though the name usr/src/mx386/bcc (from the archive e/bde/dist/minix.tar.gz) does raise some hope.\n\nPower fail! Topic: general, technology, opinion Link here\n\nAt 11:04, while preparing breakfast, we had a grid power failure. Not a problem: we have a PV system. But the power dropped totally! Almost before we knew it, it was back again. The inverter log shows less than a minute.\n\nThat's not the first time. It happens far too often, most recently two months ago. And today, as then, my main machines eureka and hydra lost power, because I still hadn't got round to getting a UPS installed. Today I made up for that: I have a ten-year-old 1000 VA 650 W UPS just lying around. It is still functional? In contrast to the CyberPower UPS that I bought 2½ years ago, it seems still to work. While the power was down, took the opportunity to tidy up the mess to the left of my desk top, removing this display card from eureka and making a cut in my fingertip in the process:\n\nThat once drove three of the four monitors then connected to eureka, but that was years ago, as the dust suggests.\n\nWhat caused the outage? Hard to say. The inverter logs show no sign of overvoltage before the outage, though afterwards the voltage hung over 250 V for over an hour. I suppose it's time to brave the potential issues and update the firmware.\n\nPowercor had a different view. An hour later I received a message:\n\nAnd then\n\nOn checking, I found that I also had similar messages from the day before, where there was no outage at all. Still, rather phantom outages than real ones.\n\nhydra upgrade Topic: technology, opinion Link here\n\nI've had hydra for nearly 2 years, and I still haven't got round to configuring it quite the way I want; much is in the X menus. But of course the system is now down-rev. What better time then after a power failure to bring it up to date?\n\nMy real concern after an update is that the ports will no longer work the way I want. Building a new world is relatively simple, and it took just shy of 1000 seconds to build the world and new kernel. And rebooting went relatively smoothly, though it no longer found the Ethernet card on the motherboard. I had suspected issues in that area (it's a 2.5 Gb/s Realtek card) and installed a second, which showed up as re0 , so all I needed to do was to change where I plugged in the network cable.\n\nAs I feared, the ports were a different matter. They were worse then ever before, taking 3 iterations to delete 100—no, 101—no, 103 ports, including chromium curl, emacs of course, enblend, exiv2, feh, ffmpeg, firefox, fusefs-curlftpfs, gdb, git, gnupg, groff, hugin, mplayer, mpv, mutt, rdesktop, rsync, rtorrent, vigra, virtualbox-ose, xpdf and xv. And even then I missed ImageMagick, which further annoys me with a change of name. Yes, convert is a subcommand of ImageMagic, but now they have decided that the name is too invasive, so I'll have to change all invocations to magick convert. I suppose that one's fair enough.\n\nAnd firefox has new messages, which it spews by the hundred where it presumably suspects nobody is looking, on the home terminal:\n\nconsole.warn: services.settings: Could not determine network status. Message: TypeError: can't access prop \"isLinkUp\", lazy.gNetworkLinkService is undefined\n\nGradually the issues became clear: I can no longer connect to eureka with ssh, nor at all to hydra. I was expecting issues with eureka, but not with hydra. Was it because it came up before the network was ready? I had to restart syslogd to get it to write to eureka, and to change the permissions on wake for normal users to use it.\n\nWhat am I left with? I can no longer use erc, the Emacs IRC command:\n\nerc: missing symbol (.at)\n\n⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.\n\n\n\nWhat does that mean? I'll find out some time. Fortunately it still works on eureka, so there's no hurry.\n\nAnd independently of all that I need to pay more attention to my X configuration. I still don't get my mice set up correctly at startup. But that's fun for another day.\n\nCompleting the upgrade Topic: technology, general, photography, opinion Link here\n\nInto the office this morning as usual. No mail from hydra. What happened there? /var/log/maillog showed a number of:\n\nSep 20 03:03:54 hydra postfix/cleanup[70392]: B1BC41AB5: message-id=<202509191703.58JH3sRP070451@hydra.lemis.com>\n\nSep 20 03:03:54 hydra sendmail[70451]: 58JH3sRP070451: to=root, ctladdr=root (0/0), delay=00:00:00, xdelay=00:00:00, mailer=relay, pri=33687, relay=[127.0.0.1] [127.0.0.1], dsn=2.0.0, stat=Sent (Ok: queued as B1BC41AB5)\n\nSep 20 03:03:54 hydra postfix/qmgr[1845]: B1BC41AB5: from=<root@hydra.lemis.com>, size=4303, nrcpt=1 (queue active)\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: unexpected attribute smtputf8 from local socket (expecting: sendopts)\n\nSep 20 03:03:54 hydra postfix/smtpd[70368]: disconnect from localhost[127.0.0.1] ehlo=1 mail=1 rcpt=1 data=1 quit=1 commands=5\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: deliver_request_get: error receiving common attributes\n\n\n\nWhat's smtputf8 ? Checking /usr/local/etc/postfix/ showed that a number of files, which should have been symlinks to the same directory on eureka, were missing. Forgot to mount a NFS file system. After mounting and restarting postfix, all was well. But what does the strange message mean? It seems that it's a default.\n\nAnd then there was Hugin. I had expected some issues, but not what I got: when I tried to start the “fast panorama preview” I got\n\nerror installing GLEW\n\nFast preview window can not be opened\n\nWhat does that mean? I have a package installed, which pkg reports as\n\nglew-2.2.0_3 OpenGL Extension Wrangler Library\n\nAnd there doesn't seem to be anything else that was there before. But when I retried the attempt, it worked. Where is the bug? Hugin or FreeBSD? In addition, irritatingly it resized the windows on every start. I thought I had got rid of that with some script magic, but it seems to be gone.\n\nAnd then there's the mouse. That's simple enough: instead of searching for the index for the mouse, it's easy enough to write\n\nxinput set-button-map \"Telink 2.4G Mouse\" 1 2 3 4 5 6 7 2 2 10\n\nOne of the messages I received was completely misleading:\n\n=== grog@hydra (/dev/pts/16) ~/Photos/20250920 47 -> (EE) event4 - Telink 2.4G Mouse, class 0/0, rev 1.10/1.00, addr 4: client bug: event processing lagging behind by 32ms, your system is too slow\n\n(EE) client bug: timer event4 debounce: scheduled expiry is in the past (-48ms), your system is too slow\n\n(EE) client bug: timer event4 debounce short: scheduled expiry is in the past (-61ms), your system is too slow\n\n\n\nThat's not hydra at all, despite the prompt. I started X on teevee from hydra, and this appears to be its way of saying “the cat got on my mouse”.\n\nAccessing systems with ssh from eureka Topic: technology Link here\n\neureka is now running a nearly 10 year old system, but I don't want to update it: it works.\n\nBut some issues remain. One was that I couldn't automatically log on with ssh: I had to enter a password, which is irritating in scripts. Once again Google Gemini to my aid. Add this to /etc/ssh/sshd_config:\n\nPubkeyAcceptedKeyTypes=ssh-ed25519,ssh-rsa,rsa-sha2-512,rsa-sha2-256\n\nNow I just need to see why I can't access eureka from hydra without a password.\n\nFinally the birding photos Topic: photography, animals, technology, opinion Link here\n\nIt's been 4 days since the latest OM System birding “workshop”, and I've only just got round to processing the best photos. Are these the best?\n\nIt's a lot of work making up my mind out of over 250 photos. Yvonne did it for me, and those were the ones she liked.\n\nMore ssh strangeness Topic: technology, opinion Link here\n\nI've already established issues with ssh sessions from hydra to eureka, but not from other systems. Once again Google Gemini to my aid, this time less useful. It tells me to allow ssh-rsa in /etc/ssh/sshd_config by adding this line:\n\nPubkeyAcceptedKeyTypes=+ssh-rsa\n\nWe've seen that before on the other side. But that's a non-starter: sshd doesn't want to know:\n\n=== root@eureka (/dev/pts/1) /etc/ssh 28 -> service sshd restart\n\nPerforming sanity check on sshd configuration.\n\n/etc/ssh/sshd_config: line 54: Bad configuration option: PubkeyAcceptedKeyTypes\n\n/etc/ssh/sshd_config: terminating, 1 bad configuration options\n\nOK, what about the alternative of using a key?\n\n=== root@eureka (/dev/pts/1) /etc/ssh 32 -> service sshd restart; date\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStopping sshd.\n\nWaiting for PIDS: 22656.\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStarting sshd.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\n\n\nWhy? It doesn't seem to affect other key forms. And comparing hydra and tiwi gives me on hydra:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: send_pubkey_test: no mutual signature algorithm\n\n\n\nBut on tiwi it works as expected:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: Server accepts key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\nAuthenticated to eureka.lemis.com ([192.109.197.137]:22) using \"publickey\".\n\n\n\nWhat's the difference?\n\nMutt problems Topic: technology, opinion Link here\n\nFirst thing I do in the morning is to read the overnight mail, typically a couple of hundred messages. But this morning I tried to delete the messages I had read, I received the message “unable to write mailbox” or something similar. Why? Normally I see a message like that when I'm out of disk space, but this wasn't the case. Return, painfully delete the messages again, and it worked. Is that an NFS issue? It has happened before. Was that also overnight? I'll have to look more carefully next time.\n\nMore ssh pain Topic: technology, general, opinion Link here\n\nInto the office this morning to find eureka maxed out with at least 35 ssh-add processes, all looping at 100% CPU time.\n\nWhy? This is not a new program:\n\n3054180 -r-xr-xr-x 1 root wheel 17576 25 Nov 2015 /usr/bin/ssh-add\n\nOnce again Google Gemini to my aid, coming with the suggestion that it could be that ssh-add was running already, and that I should put in code like\n\nssh-add -l >/dev/null || ssh-add\n\nThat worked up to a point, but it doesn't explain why it is only happening now, after nearly 10 years. It's much more likely that it's related to the playing around I have been doing lately, though it didn't affect ssh-add, and I had backed out the changes anyway. And in the course of the day I found another instance in my weather software, but that found further breakage: the external view of my weather stopped in early June when I got the new weather station. More to fix when the current problems are over.\n\nssh-add: A clue Topic: technology, opinion Link here\n\nI haven't done much to investigate the ssh-add problem for the moment. It seems that I call ssh-add in a number of places, all of which need fixing. But while playing around I found:\n\n=== grog@eureka (/dev/pts/3) ~/public_html 32 -> ssh-add < /dev/null\n\nEnter passphrase for /home/grog/.ssh/id_rsa:\n\nCould it be that the looping is the incorrect handling of a prompt? It doesn't help much in fixing it, but it could help understand.\n\nThe advantages of upgrades Topic: technology, opinion Link here\n\nAs expected, upgrading hydra caused a number of problems, most of which I have described. And this time it was Chromium, which has forgotten all its editing keys, or at least the ones I want. More searching required.\n\nOn the other hand, one bug has gone away: xv can now display PNG again. Not exactly a big improvement, but at least a fixed bug.\n\nThe daily Android bug Topic: technology, opinion Link here\n\nSomehow the Android operating system seems to be the least reliable I know. I'm gradually coming to terms with it, but today there was another one: trying to download files to a Real Computer, albo didn't respond, though it claimed to be working. Disable Wi-Fi, reeenable, and it worked. No change of connection.\n\nWhat a mess Android is!\n\nAnother web server overload Topic: technology, opinion Link here\n\nIt's been well over 4 months since I set up a new external web server, fra.lemis.com, to address the really heavy load, with load averages up to 170. And so, of course, it dropped back to under 1.\n\nBut now it's increasing again, both servers now well over 200. Why? I had thought it was related to the imagesizes parameter, but that doesn't seem to be the case. Let's see how long the overload lasts this time.\n\nFast postal service Topic: general, technology, opinion Link here\n\nI've bought a couple of cameras in the United Kingdom. The usual tracking information, with a twist:\n\nIt's in Leeds, but it'll be here tomorrow! Now that's a lot faster than Australia Post. Or just plain stupid.\n\nYour cameras have been delivered! Topic: technology, photography, general, opinion Link here\n\nYesterday's claim of fast delivery was amusing enough, but they haven't given up:\n\nThey have been delivered! How did we do?\n\nI'm amazed. Clearly the cameras are still in the United Kingdom. My best guess is that Royal Mail have delivered the cameras to the people who are currently in the process of sending them half way round the world, or at least they have received documentation from them. So from their limited viewpoint they have been delivered. No concept of them only having travelled a fraction of the distance.\n\nWeb server load: dropping Topic: technology Link here\n\nYesterday's web server overload didn't last long. It's back to round 1 again. I suppose that's what we're going to have to live with for the foreseeable future. It's interesting that even at this extreme overload people claimed that response was satisfactory. That's significantly different from last time, where some sites got timeouts.\n\nArtificially intelligent breakfast Topic: food and drink, technology, opinion Link here\n\nFor some reason we bought a quarter cabbage recently. I forget why, but it was intended for breakfast. All right, Google Gemini, give me some east asian recipes with fried cabbage.\n\nAnd the twins obliged: 手撕包菜 - Shǒu Sī Bāo Cài, “hand shredded cabbage\", which didn't look too bad, modulo these horrible cups measurements. I can't even blame the twins for that: so many recipes use it. But it's the biggest hindrance I can find for trying out recipes. OK, Gemini, give me a Chinese recipe with fried cabbage and noodles using metric units. OK, how about 包菜炒粉/麵, which Google Translate translates as “cabbage fried rice noodles”? A completely different recipe! The best I can guess from the two recipes is that 4 cups of cabbage weigh about 300 g.\n\nSpent some time—probably more than cooking—writing a sane version of the second recipe.\n\nSoftware upgrades: the sting in the tail Topic: technology, photography, opinion Link here\n\nHouse photos again today, the second time since I upgraded hydra to FreeBSD 14.3 last week. And once again I had pain.\n\nFirstly, creating HDR didn't work well. It took me a while to discover that it was an unrelated bug in one of my scripts: I managed to mix images from the OM System OM-1 Mark II with the correct images from the Olympus OM-D E-M1 Mark II. I had already expected problems like that, and /Photos/Tools/housephtos.awk contained appropriate comments. Here the fix:\n\n-# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n+# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n# Create a makejpeg file from housephoto.notes file.\n\nBEGIN {\n\ni = 0;\n\n-# XXX Only look at photos from E-M1 Mark II.\n\n+# Only look at photos from E-M1 Mark II.\n\n# Is this safe?\n\n-# Was: 4*.ORF, E-M1 /2 only\n\n- while (\"ls -rt *.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n+# It's better than the alternative.\n\n+ while (\"ls -rt 4*.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n\n\nThe problem was that I didn't limit the choice to photos from the E-M1 Mark II. Not an upgrade problem at all.\n\nThe other, though, seems to be related to the upgrade of Hugin, now version 2024.0.1. The screens appear in the wrong place and at the wrong (tiny) size, and the directories are wrong. That's almost certainly related to the scripts that I wrote over 16 years ago which frob the ~/.hugin file to get rid of this horrible directory name retention. But that's all they do, and somehow it doesn't seem to work. A small detail, but irritating. Will I get round to it by next week?\n\nRevisiting old photos Topic: photography, technology, opinion Link here\n\nLooking back through old photos, found some of my first panoramas:\n\nIt dates from 11 April 2009 with the Olympus E-510, so old that I don't even have Exif data for it. I had already attempted to improve it 8 years later:\n\nBut that was still with the Ashampoo Photo Optimizer, which I have stopped using. Another attempt with “Perfectly Clear” gave me further improvements. Here are the three together (run the cursor over an image to compare it with its neighbour):\n\nIn particular the highlights and shadows are greatly improved.\n\nfra rebooted! Topic: technology, general, opinion Link here\n\nThe vultures have rebooted fra! Yes, they warned they would do so because of some unspecific bug in Linux, so they rebooted my FreeBSD box as well. The good news is that it came back without any intervention on my part, but of course the up time has gone to hell.\n\nAnother bloody power fail Topic: technology, general, opinion Link here\n\nIn the evening, another grid power failure. And another directly behind it. Both were sub-second, but once again eureka and hydra failed. So much for the UPS.\n\nWhy? Yes, it's an old UPS, but it claims to have plenty of charge, and the failures were so short that most clocks in the kitchen kept going. Can it be that it was a power surge, and that this UPS didn't handle it? The UPSs for lagune, teevee and tiwi had no problems.\n\nAnd the fallout? I got things running relatively quickly, but firefox didn't recover its many tabs. I had to start a different profile to get anything. And of course X on teevee failed, because I had started it from hydra.\n\nSo what do I do now? Buy more of UPSs of the kind that power the other machines?\n\nTuesday, 30 September 2025 Dereel Top of page previous day\n\nMore firefox pain Topic: technology, general, opinion Link here\n\nSo what's wrong with firefox? My standard profile just hangs. Why? How do I debug such a mess?\n\nI tried setting up a different profile, losing a number of tabs in the process, but nothing I could do could get the font sizes right. Get them right for my diary (without any trickery) and they're far too small for things like Wikipedia and friends. Migrate from hydra:0.2 (3840×2160) to hydra:0.0 (1920×1080)? Yes, that works, but why did it happen?\n\nThen it occured to me: yes, the standard profile still hangs. But I can check the settings. And it seems that the big thing is the Zoom setting, which was at 150%. After setting that, things were OK. But why the difference between my diary and Wikipedia and Co.? And why are font sizes such an issue with firefox?",
      "source": "Lemis.com",
      "url": "http://www.lemis.com/grog/diary-sep2025.php?topics=c#D-20250908-235445",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "An Officer and a Gentleman",
      "content": "Posted 08 September 2025 - 07:48 PM\n\nWhen, in the 1982 movie, Zack Mayo cries to Sgt. Emil Foley, \"I have no place else to go!\" I know how he must feel. Although I've owned one of these infernal machines since the first one was on the market, five-inch green-lettered screen, no hard drive, two floppy disks, I've been using them as a production tool so consistently that I haven't had the time nor energy to comb out much of an idea of how they work. For that reason I've been relying on the wizardry of Bleeping Computer for the save for close to ten years. Not once have you people ever steered me wrong.\n\nHere's my computer specs:\n\n2023 Velocity Micro Pro Magic HD80\n\nDevice name VM-900649\n\nProcessor AMD Ryzen 5 7600X 6-Core Processor (4.70 GHz)\n\nInstalled RAM 32.0 GB (31.2 GB usable)\n\nDevice ID 57C113A0-86B4-4E66-A907-7EE709105884\n\nProduct ID 00330-73771-05884-AAOEM\n\nSystem type 64-bit operating system, x64-based processor\n\nWindows 11 PRO OS\n\nNo pen or touch input is available for this display\n\nYears ago, when my computer of that era was acting weird, wouldn't do what I asked, screens weren't looking right, slow as grandma in a tar pit, you sent me an in-house program that stripped all the crap out and made that other computer run good as new. I'm just guessing, but I think this one might need one of those massages. I couldn't really count the times you have saved my adze, sometimes when deadlines were just short of lethal.\n\nNow it's half the speed when new, it does really ugly things like shifting screens to something I didn't want, taking a very long time to upload or download the internet, failure to cut-and-paste. One program interfering with another, won't copy a URL to my digital notebook in a manner that will run when clicked, adding belligerent software that I didn't order. A time or two it turned itself back on in the middle of the night after I had turned it off. Pop-ups popup even though I have a lot of software that is supposed to prevent that. This old friend is acting like it's possessed, which of course it might be, with a rider of some kind or a malignant virus scraped off from somewhere or something else dastardly.\n\nI work this unit pretty hard, using Presonus Studio One Pro + DAW, Final Draft screenwriting software and Chief Architect X15 Premier. I'm retired now so it seldom gets a rest. Maybe it's just bogged down like they get sometimes, but I wanted to ask you how to properly accomplish whatever it is that needs to be done so this great machine can get back to being great again without me making it any worse.\n\nThanks a million to all of you for the magnificent help you've given to me over the years. It's a pretty sure thing that I've sent over twenty customers to you since we met a decade ago. I'll continue with that until I fall over. Jason Brooks",
      "source": "BleepingComputer",
      "url": "https://www.bleepingcomputer.com/forums/t/810602/an-officer-and-a-gentleman/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Acrobat Pro DC 2025.001.20693",
      "content": null,
      "source": "Rlsbb.ru",
      "url": "https://post.rlsbb.ru/adobe-acrobat-pro-dc-2025-001-20693/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD's New 25.9.1 GPU Driver Makes FSR 4 Available In Most FSR 3.1 Games",
      "content": "Yesterday, AMD released version 25.9.1 of its new Radeon GPU driver, bringing the total of fully-supported FSR 4 games to 85 (including the newly-released Borderlands 4) and adding a driver toggle to force FSR 4 into compatible FSR 3.1 games running under DirectX12.\n\n\n\n\n\nThis now means that most games supporting AMD FSR 3.1 games can be retrofitted with AMD FSR 4 without further developer support required, though this brute-force method is still limited to DirectX12 games that have a standard FSR 3.1 integration with an officially-signed FSR 3.1 DLL. Games that only support Vulkan or use a non-standard FSR 3.1 implementation unfortunately cannot be retrofitted with AMD's machine learning-accelerated FSR 4 implementation without developer updates. As always, AMD still hosts a full list of AMD FSR 4-supported games.\n\nFor gamers hoping to start using AMD FSR 4 right away, make sure that you're on a supported AMD RDNA 4 GPU, like the Radeon RX 9070 XT , since the latest AMD GPUs are required to make use of FSR 4, unlike previous versions of FSR. A simple driver update from your Radeon Software should do the job from there, but there's always the manual driver download page, if you need to use that.\n\n\n\n\n\nFortunately for AMD users, FSR 4's image quality has greatly improved compared to previous versions of FSR, providing an image more in line with NVIDIA's excellent DLSS upscaler thanks to making better use of the onboard RDNA 4 hardware. For RDNA 4 GPU users hoping to use FSR 4 in even more games, there's even a method utilizing OptiScaler allowing you to hack in FSR 4 to replace DLSS and XeSS in certain games, though your results may vary,\n\nImage Credit: AMD\n\nBesides updates to AMD FSR 4, the new GPU driver also fixes some issues impacting Mafia: The Old Country, WUCHANG: Fallen Feathers, and Monster Hunter Wilds, as well as a peculiar bug preventing PlayStation VR controllers being detected within SteamVR. The manual download page also lists some known issues impacting The Last of Us Part II, Call of Duty: Black Ops 6, FBC Firebreak, Cyberpunk 2077 (with path tracing), GTFO, and some stuttering on VR headsets connected to older AMD GPUs.",
      "source": "Hot Hardware",
      "url": "https://hothardware.com/news/amd-2591-gpu-driver-makes-fsr-4-available-in-most-fsr-31-games",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "RPCS3 Developer Claims AVX-512 Is Power-Efficient, Blames Skylake-X For Its Poor Reputation",
      "content": "Yesterday, developer of PS3 emulator RPCS3 Whatcookie posted a 20-minute YouTube video to their YouTube channel in defense of AVX-512, a maligned CPU instruction set that debuted with Intel's Skylake-X architecture in 2015 and didn't see adoption by AMD CPUs until 2022's Zen 4. Specifically, Whatcookie debunks claims that modern implementations of AVX-512 are inefficient by showcasing benchmarks of both RPCS3 and other pieces of software using AVX-512 on modern CPU architectures, showing that the instruction set still manages higher performance at the same wattage levels, the same performance at lower wattage levels, and much higher performance at slightly-higher wattage levels.\n\n\n\n\n\nWhatcookie doesn't stop there, though. He also includes a mini history lesson on the instruction set in his 20-minute video, highlighting how the initial Skylake-X implementation actually did substantially lower clock speeds and boost power draw when AVX-512 was in use. These issues were mitigated on Intel's high-end server-grade Xeon CPUs, and were seemingly artificially exaggerated on consumer-grade Skylake-X chips thanks to more severe downclocking enforced in firmware.\n\nTo those who have been keeping track of RPCS3 development or AVX-512 adoption in recent years, this actually shouldn't be that surprising. Back in 2022, we covered performance gains of up to 30% on RPCS3 when using AVX-512 ourselves, and just last month we reported on Phoronix's benchmarks showing major performance benefits of AVX-512 on the AMD Ryzen 9 9950X\n\n\n\n\n\nSadly, while modern benchmarks on modern hardware should seemingly have cleared AVX-512's name by now, popular consensus of the AVX-512 instruction set still points to a maligned reception tainted by Intel Skylake-X all these years later. Perhaps that shouldn't be surprising, though, considering how long Intel iterated upon Skylake's 12nm architecture before finally adopting an all-new 10nm architecture with Alder Lake in 2021— an architecture that outright disabled AVX-512 because the new E-cores couldn't support it, although P-cores could.\n\nImage Credit: Der8auer for Skylake-X delidded thumbnail, Whatcookie for RPCS3 benchmark images\n\nAll this isn't to say that AVX-512 is a perfect CPU instruction set, by any means. On modern architectures from Intel and AMD, some minor downclocking is still present when executing enough full-length AVX-512 instructions at once, but these are enforced by more typical thermal and power constraints, not firmware constraints as with consumer Skylake-X chips. This means that AVX-512 still shows much higher performance and efficiency were in use on modern CPUs compared to AVX2, and this discrepancy has already been highlighted by benchmarks from several sources including Phoronix and VideoLAN, not just RPCS3 development.Thankfully, AVX-512 seems to be a straightforward power and performance win on modern CPU architectures from Intel and AMD alike, despite how poorly it fared with Skylake-X's launch. That bitter aftertaste will linger for some time, though— and as Whatcookie highlights in a concluding skit, even the likes of the supposedly PhD-level GPT-5 still uncritically repeats critique of Skylake-X-distorted AVX-512 performance as gospel.",
      "source": "Hot Hardware",
      "url": "https://hothardware.com/news/rpcs3-developer-claims-avx-512-is-power-efficient-blames-skylake-x",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Advanced Micro Devices, Inc. (AMD) Becomes the Most Under-Owned U.S. Semiconductor Stock",
      "content": "Advanced Micro Devices, Inc. (NASDAQ:AMD) is included in our list of the 14 Tech Stocks to Sell Now According to Ken Fisher.\n\nAdvanced Micro Devices, Inc. (AMD) Becomes the Most Under-Owned U.S. Semiconductor Stock\n\nClose-up of Silicon Die are being Extracted from Semiconductor Wafer and Attached to Substrate by Pick and Place Machine. Computer Chip Manufacturing at Fab. Semiconductor Packaging Process.\n\nBank of America reported on September 3, 2025, that Advanced Micro Devices, Inc. (NASDAQ:AMD), despite being an outperformer in the sector, has become the most under-owned U.S. semiconductor stock among active managers. Active ownership fell to 20% in August from 23% in May and 39% a year earlier.\n\nMeanwhile, Advanced Micro Devices, Inc. (NASDAQ:AMD)’s relative weighting has gone down by 80% year-over-year compared to the S&P 500. This is in line with consensus forecasts, which project 22% sales growth and AMD’s continued gains over the Philadelphia Semiconductor Index. At the same time, the investment firm reiterated its ‘Buy’ rating on AMD, thanks to strong tailwinds from rising artificial intelligence adoption and the company’s sustained market share gains against Intel.\n\nAdvanced Micro Devices, Inc. (NASDAQ:AMD) focuses on designing and developing semiconductors, offering CPUs, GPUs, AI accelerators, and embedded solutions. It serves data centers, client computing, gaming, and specialized applications globally.\n\nWhile we acknowledge the potential of AMD as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 15 Stocks That Will Benefit From AI and 10 Must-Buy Canadian Stocks to Invest in.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/advanced-micro-devices-inc-amd-085831164.html",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "This Dell Laptop with Ryzen 7 and Crazy Specs Is 73% Off on Amazon, Stock Is Flying Out",
      "content": "Dell is a bit of a favorite when it comes to Windows laptops. They offer options for every budget but it’s rare to find one priced under $1,000. So, if you’re in the mood to hit the jackpot, there’s currently a Dell Inspiron 15.6-inch touchscreen laptop (32GB RAM, 1TB SSD, Windows 11 Pro, AMD Ryzen 7 7730U) valued at $3,000 going for $799 on Amazon—talk about a huge deal.\n\nSee at Amazon\n\nWhy Buy That Dell Laptop?\n\nThis laptop comes with a 15.6-inch widescreen display that delivers Full HD visuals with a resolution of 1920 by 1080 pixels. The screen uses Wide Viewing Angle technology, which means the colors stay crisp and accurate even when you’re not looking at the screen head-on. Furthermore, the anti-glare coating reduces reflections so you don’t strain your eyes doing work in a brightly lit room or near a window. The thin bezels on the sides of the screen give you more screen space without interruptions, and the LED backlight shines on the screen without wasting power so your battery will last longer.\n\nThe brain behind this machine is the AMD Ryzen 7 7730U processor, which clocks 4.5 GHz at its best: It’s optimized to provide snappy performance without draining the battery. So, if you’re doing work life seriously or studying, it won’t slow you down, and you’ll get decent battery life for it.\n\nInternally, the laptop comes with 32GB of RAM which is the memory that enables your computer to have several programs open at the same time without lagging. Put simply, the more RAM you have, the more smoothly things go when switching between tasks or working with large files. This laptop’s generous memory puts you ready to handle demanding programs, so you won’t find yourself waiting around for things to load. Besides that, it also comes with a generous 1TB solid-state drive where all of your apps and documents reside.\n\nYou’ll be running Windows 11 Pro, the professional version of Microsoft’s latest operating system. It’s designed for business and serious users and offers strong security features along with tools that make managing your work easier.\n\nWhat makes this deal even sweeter is the bundle of accessories included: You get a stylus pen for easy touchscreen operation, a camera privacy cover to ensure your privacy during video calls, a 128GB USB flash drive for extra portable storage, a dust plug to ensure the ports remain free from dust, a carrying sleeve for protective transport of the laptop, and a microfiber cleaning cloth to have everything spick and span.\n\nThis deal won’t last forever, make sure you don’t miss it.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/this-dell-laptop-with-ryzen-7-and-crazy-specs-is-73-off-on-amazon-stock-is-flying-out-2000624609",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Elon Musk Was Just Unseated as the World’s Richest Person",
      "content": "Oracle Chairman Larry Ellison is having a good morning.\n\nOracle’s stock is up more than 42% on Wednesday, thanks to an earnings call on Tuesday that left investors stunned.\n\nThe company missed earnings and revenue estimates, but the forward looking guidance alone was apparently good enough to get investors to rally around it. A bulk of that reaction had to do with the revenue that AI computing demand was expected to bring to Oracle’s cloud infrastructure service.\n\nThe shares skyrocketed in response. Oracle’s stock is now on pace to have its largest single session surge since the dot-com boom, according to CNBC.\n\nWith the current surge in shares, Ellison has increased his wealth by more than $100 billion, thanks to the roughly 1.16 billion shares he owns. This meteoric rise grabbed him the title of the richest person on Earth from the former title holder, Elon Musk, according to the Bloomberg Billionaires Index.\n\nAs of Tuesday, Ellison’s current total fortune was worth $295 billion, having increased by $100 billion in worth in just the past year. Today’s additional increase has catapulted him to a staggering $389 billion, surpassing Elon Musk’s whopping $384 billion fortune.\n\nMusk was first named the richest man in the world in 2021, and has since been up and down on the list. He has held the title consistently since last year and briefly became the first person to surpass $400 billion net worth in December. Although Ellison has overtaken him on the list, Musk might reverse that yet again soon. Musk is facing the potential of becoming the world’s first trillionaire, that is if the massive and unprecedented proposed pay package plan by the Tesla board gets approved by shareholders.\n\nOracle’s AI success story\n\nLarry Ellison co-founded Oracle in the late 1970s with the CIA as an early customer. Decades down the line, the database software company now specializes in AI-first cloud computing and competes with other giants like Microsoft’s Azure, Alphabet’s Google Cloud, and Amazon’s AWS. It’s the aggressively positive and AI-driven outlook for its cloud infrastructure business that has led to investor delight and the 81-year-old Ellison is benefiting handsomely from it.\n\nAlthough the revenue estimates were down, the company said it was expecting to collect more than half a trillion dollars extra thanks to four multi-billion-dollar contracts it signed in the past quarter. At the company’s earnings call, CEO Safra Catz mentioned OpenAI, Meta, Nvidia, AMD, and Elon Musk’s xAI as some of the company it has “significant cloud contracts with.”\n\nCompany executives shared that they are expecting to finalize even more multi-billion-dollar deals in the near future.\n\nOracle, and Ellison, are hell-bent on AI. The company recently made headlines for an alleged plan to spend more than $1 billion a year to run a new data center in Texas on gas generators rather than wait for approval and infrastructure to pull the electricity from the local grid. Oracle is also one of the partners in the Trump administration’s ambitious AI project Stargate.\n\nCloud computing is the hot name in AI earnings\n\nCloud computing might be one of the clearest early winners of the AI hype. AI companies are scouring for more computing capacity as they try to compete with each other and scale operations, and they are willing to spend a hefty amount of money for it. Enter cloud infrastructure providers, like Oracle and Microsoft, that provide computing power for large AI models. Both the companies showed a meteoric stock increase after their recent earnings report.\n\nIn its latest earnings report in July, Microsoft reported that sales were up 18% from last year and that revenue for its cloud computing platform Azure had surpassed $75 billion this year, up 34% from last. Despite these numbers accompanying Microsoft’s largest ever quarterly capital expenditure forecast, the market went crazy for it. The shares jumped and the tech giant briefly became the second-ever company to hit $4 trillion market valuation.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/elon-musk-was-just-unseated-as-the-worlds-richest-person-2000656741",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Despite cutting the gags, Borderlands 4's PC specs say it still needs 100GB of SSD space",
      "content": "Two days before launch, Borderlands 4 has its PC system requirements. They’re generally on the higher side without teetering over into full-on tech demo lunacy – the RTX 2070 is a minimum-spec graphics card, for instance – though anyone with a smaller SSD will need to make room for the looty FPS sequel’s bumper-size 100GB storage requirement.\n\nI have mixed feelings about this. On the one hand, gargantuan install sizes are kind of obnoxious (even the infamously bloated Call of Duty agrees), and are partly caused by merely visual, high-resolution textures that we increasingly need madly expensive GPUs to even enable. Or at least, to enable without simultaneously committing framerateicide.\n\nOn the other hand, 100 is a very round and satisfying number. Just look at it. Way better than 112 or some garbage. I do wonder if anyone working in Gearbox’s gigabyte dieting department saw it was possible to compress it down to 99GB, potentially avoiding the shock of entering the triple digits, but left it at 100GB just because it’s vaguely nicer. I suspect I’d do the same.\n\nAnyway, here’s the hardware:\n\nBorderlands 4 minimum PC specs\n\nOS: Windows 10 / 11\n\nWindows 10 / 11 CPU: Intel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum)\n\nIntel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum) RAM: 16GB\n\n16GB GPU: Nvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum)\n\nNvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum) Storage: 100GB (SSD required)\n\nBorderlands 4 recommended PC specs\n\nOS: Windows 10 / Windows 11\n\nWindows 10 / Windows 11 CPU: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nIntel Core i7-12700 / AMD Ryzen 7 5800X RAM: 32GB\n\n32GB GPU: Nvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nNvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580 Storage: 100GB (SSD required)\n\nSolid state hungriness aside, it’s a bit strange seeing the Arc B580 in the recommended tier, alongside the RTX 3080 and RX 6800 XT – it’s a good little budget card but not on the same level as those two older, yet bonafide high-end GPUs. Though maybe that means Borderlands 4 performs better-than-recommended on this Nvidia/AMD kit?\n\nAlso, 2K’s post doesn’t mention it specifically, but DLSS 4 Multi Frame Generation is supported as well. This needs a GeForce RTX 50 series card to operate at full pelt, with RTX 40 models making do with DLSS 3-style 2x frame gen.\n\nI’m generally in the 'wait and see how it is' camp on Fourderlands, with its new planet and its many billions of randomly generated firearms, having previously been interested enough to mulch through Borderlands 3 with mates but jointly concluding it wasn’t worth our time. This new one is something of a reset, with its lead writer Taylor Clark claiming it won’t have as many jokes. Which is, at once, likely an improvement and also a weird thing to make a selling point of. B4's out on September 12th.",
      "source": "Rock Paper Shotgun",
      "url": "https://www.rockpapershotgun.com/despite-cutting-the-gags-borderlands-4s-pc-specs-say-it-still-needs-100gb-of-ssd-space",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Intel promises 'leadership across the board on desktop' when its next-gen Nova Lake CPU launches in late 2026",
      "content": "Intel's been on a roll of late in all the wrong ways. Borked CPUs, failing fabs, haemorrhaging cash, run-ins with the President of the USA. The woes never end. Until next year, that is, and the launch of Nova Lake. That's right, peeps, when Intel's next-gen CPU architecture arrives at the end of 2026, Intel will ascend to a leadership position across the board on desktop.\n\nTo quote John Pitzer, Intel's Corporate Vice President of Corporate Planning & Investor Relations, precisely, \"as Nova Lake comes out at the end of next year into 2027, I think we're going to have a leadership position across the board on desktop.\"\n\nThat is one heck of a bold claim, even for a chip that's rumoured to pack up to 52 cores. Of course, it will at least in part hinge on the quality of Intel's upcoming 18A process, the node formerly known as the one upon which Pat Gelsinger bet the entire company, but latterly more of a stepping stone back to profitability, with 14A being the node on which Intel's hopes to build chips for customers now depends on.\n\nUnsurprisingly, Pitzer is bullish on 18A, too. He says Intel is planning to spend heavily on tooling up to produce lots of chips on 18A and return Intel to profitability. Famously, or you might say notoriously, both of Intel's latest CPU families, namely Arrow Lake and Lunar Lake, are largely manufactured by TSMC.\n\nIntel will start the process of moving that production in-house with Panther Lake. However, Panther Lake is a mobile CPU and is also aimed at more power-efficient laptops as opposed to larger desktop-replacement rigs. More to the point, it's thought only certain versions of Panther Lake will have CPU dies made by Intel. The bulk of production may well end up being handled by Taiwanese chip foundry TSMC.\n\nLunar Lake is a good mobile chip, but Intel pays TSMC handsomely to manufacture it. (Image credit: Intel)\n\nIn other words, Panther Lake will only entail fairly limited quantities of Intel's 18A silicon. That changes with Nova Lake. \"Nova Lake itself being both a notebook and a desktop part has pretty meaningful implications for the amount of wafer starts that we need on 18A,\" Pitzer says.\n\nAnd that should mean improved profitability because it means Intel won't have to pay those pricey TSMC wafer fees. \"As you look at it through the lens of Intel Foundry, the move from Intel 7 to Intel 18A, ASPs per wafer will go up three times faster than their cost. And so just driving more volume through the fab on 18A is a pretty profitable dynamic for Intel Foundry,\" Pitzer.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nMorever, Pitzer says Intel can get back to making money just by executing on its own products, it doesn't absolutely need to win big foundry customers. \"We don't need to see a lot of external foundry revenue to breakeven exiting 2027,\" he says.\n\nThe question is, can Intel actually deliver on its own products? If you examine Intel's recent CPU families, it's not altogether promising. The Raptor Lake generation has turned out to suffer from major bugs, the Meteor Lake mobile architecture was underwhelming, and Intel's latest desktop chips, known as Arrow Lake arrived half baked and even after a little tweaking remain well behind AMD by most estimates.\n\nThe only unambiguous exception to all that has been Lunar Lake, which is a decent low-power mobile CPU, but according to Intel itself, isn't a money spinner on account of being made mostly by TSMC and having integrated memory, which limits configuration options for laptop makers.\n\nWe'll get an initial feel for whether Intel is getting back on track with Panther Lake at the end of this year, which will be our first taste of the 18A process. But that's another low-power CPU. So, it will really be Nova Lake at the end of 2026; that's the real test.\n\nNova Lake will span the whole gambit from lower-power laptops to high-performance desktops and is shaping up to be an absolutely vital processor family for Intel. Nova Lake simply has to be at least competitive with AMD if Intel is going to turn things around.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/processors/intel-promises-leadership-across-the-board-on-desktop-when-its-next-gen-nova-lake-cpu-launches-in-late-2026/",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "AMD Megapod set to face Nvidia's Superpod with a 256-GPU rack full of Instinct MI500 chips",
      "content": "AMD MegaPod design emphasizes raw GPU count and interconnect efficiency\n\nNvidia’s packaging method complicates direct comparisons with AMD’s approach\n\nThree racks will form the backbone of AMD’s MegaPod, and each compute tray may combine Verano CPUs with MI500 accelerators\n\nAMD appears to be preparing a new large-scale computing system aimed at high-performance computing.\n\nAccording to industry analysis, the so-called \"MegaPod\" is projected to house a large number of accelerators, positioning it as a direct response to Nvidia’s established \"SuperPod.\"\n\nThe first signs of its design point to an emphasis on raw GPU count and interconnect efficiency, although exact details remain speculative.\n\nA system with 256 MI500 chips\n\nReports suggest that AMD will arrange the MegaPod across three separate racks.\n\nThe two outer racks are expected to hold 32 compute trays each, while the central rack will contain 18 trays for networking switches.\n\nWithin each compute tray, a single Verano CPU may be paired with four Instinct MI500 GPUs.\n\nThis layout would deliver 32 CPUs and 128 GPUs per rack, producing a total of 64 CPUs and 256 GPUs for the entire system.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe proposed design, sometimes referred to as \"UAL256,\" reflects AMD’s intent to expand capacity in ways meant to outmatch competitors.\n\nThe comparison between AMD’s MegaPod and Nvidia’s SuperPod is not straightforward.\n\nOn paper, the AMD system would offer 256 physical or logical GPU packages, while Nvidia’s Kyber VR300 NVL576 lists only 144.\n\nHowever, Nvidia’s architecture organizes four GPUs per package, yielding 576 GPUs overall.\n\nAMD’s reliance on single-GPU packages means its structure may appear larger in physical package count but not necessarily in total core density.\n\nThis complicates any attempt to declare one system as superior. For now, the MegaPod looks positioned more as a counterbalance than a clear leap ahead.\n\nThe central rack of the projected system is designed for switching infrastructure.\n\nAnalysts expect AMD’s new Vulcano network cards, derived from the Pensando line, to be deployed here.\n\nThe use of these cards could determine whether the MegaPod can deliver enough bandwidth to make full use of its GPU-heavy configuration.\n\nWhile the physical layout of racks and trays seems straightforward, network latency and throughput will play as critical a role as raw GPU numbers.\n\nThe system is expected toward the end of 2027, placing it on the same development horizon as other major HPC installations and large-scale data centers, including the German Herder supercomputer.\n\nAMD has acknowledged plans to combine Verano CPUs, MI500 accelerators, and Pensando Vulcano network cards, but exact details of the MegaPod remain unverified.\n\nVia Computerbase (originally in German)",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/amd-megapod-set-to-face-nvidias-superpod-with-a-256-gpu-rack-full-with-instinct-mi500-chips",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Why Is Advanced Micro Devices (AMD) Stock Jumping Today?",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_856ccd2f-0ce1-4af4-bfb4-66b7e9116ac0",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Borderlands 4 PC hardware requirements ask for an RTX 2070 as a minimum, but a 3080 is recommended",
      "content": "Borderlands 4 releases on 12th September, and just in time developer Gearbox has revealed the PC hardware specs you'll need to run the game at a decent or intended level - essentially the minimum and recommended PC specs.\n\nGearbox says that the minimum hardware requirements will let you run the game with solid performance on older PCs, while the recommended specs will let you play Borderlands 4 with high performance and graphical detail the studio set out to deliver.\n\nImage credit: Gearbox Software\n\nBorderlands 4 PC Specs Borderlands 4 Minimum PC Hardware requirements: Requires a 64-bit processor and operating system\n\nRequires SSD\n\nOS: Windows 10 / 11\n\nProcessor: Intel Core i7-9700 / AMD Ryzen 7 2700X\n\nMemory: 16 GB RAM\n\nGraphics: NVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580\n\nRequires 8 CPU Cores for processor and 8 GB VRAM for graphics.\n\nStorage: 100 GB available space Borderlands 4 Recommended PC Hardware requirements: Requires a 64-bit processor and operating system\n\nRequires SSD\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nMemory: 32 GB RAM\n\nGraphics: NVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nStorage: 100 GB available space Borderlands 4 PC graphics settings: Basic: Display Mode: Fullscreen, Windowed Fullscreen, Windowed\n\nResolution (Varies by setup)\n\nDisplay Stats: None, FPS, All\n\nLimit Frame Rate: Off, On\n\nCustom FPS Limit (Varies by setup)\n\nVertical Sync: Off, On\n\nField of View (ultrawide monitors supported)\n\nVehicle Field of View (ultrawide monitors supported) Advanced: Graphics Preset: Low, Medium, High, Very High, Badass\n\nAnti-Aliasing: Disabled, Enabled\n\nResolution Scaling\n\nUpscaling Method: Disabled, DLSS, FSR, TSR, XeSS\n\nUpscaling Quality: Ultra Performance, Performance, Balanced, Quality, Full Resolution\n\nSpatial Upscaling Quality: Performance, Balanced, Quality, Ultra Quality, Disabled\n\nScene Capture Quality: Low, High, Full Resolution\n\nFrame Generation: Off, On\n\nNVIDIA Reflex Low Latency: Off, On, Boost Environment: HLOD Loading Range: Near, Medium, Far\n\nGeometry Quality: Low, Medium, High\n\nTexture Quality: Low, Medium, High, Very High\n\nTextures Streaming Speed: Medium, High, Very High\n\nAnisotropic Filtering Quality: Off, x1, x2, x4, x8, x16\n\nFoliage Density: Off, Very Low, Low, Medium, High, Very High\n\nVolumetric Fog: Low, Medium, High, Very High\n\nVolumetric Cloud: Low, Medium, High, Very High\n\nShadow Quality: Low, Medium, High, Very High\n\nDirectional Shadow Quality: Low, Medium, High, Very High\n\nVolumetric Cloud Shadows: Disabled, Enabled\n\nLighting Quality: Low, Medium, High, Very High\n\nReflections Quality: Low, Medium, High, Very High\n\nShading Quality: Low, Medium, High Post-Processing: Post-Process Quality: Low, Medium, High, Very High\n\nMotion Blur Amount\n\nMotion Blur Quality: Off, Low, Medium, High, Very High\n\nBorderlands 4's accessibility features have also been detailed by Gearbox, as listed below:",
      "source": "Eurogamer.net",
      "url": "https://www.eurogamer.net/borderlands-4-pc-hardware-requirements-ask-for-an-rtx-2070-as-a-minimum-but-a-3080-is-recommended",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "3 Solid Stocks to Buy on Steady Growth in Semiconductor Sales",
      "content": "The semiconductor market has seen steady growth this year after an impressive 2024, thanks to the continued optimism surrounding artificial intelligence and demand from a range of industries. Revenues have soared over the past two quarters, and the third quarter has started on a high note.\n\nIn fact, semiconductors have played a key role in the overall tech rally, which has been driving the broader market.\n\nGiven this scenario, it would be ideal to invest in semiconductor stocks, such as Advanced Micro Devices AMD, NVIDIA Corporation NVDA and Advanced Energy Industries, Inc. AEIS. Each of these stocks carries a Zacks Rank #1 (Strong Buy) or 2 (Buy). You can see the complete list of today’s Zacks #1 Rank stocks here.\n\nChip Sales Continue to Soar\n\nGlobal semiconductor sales totaled $62.1 billion in July 2025, jumping a solid 20.6% year over year and 3.6% sequentially from June’s total of $59.9 billion, the Semiconductor Industry Association (SIA) said last week.\n\nSIA also said that regional sales rose at an impressive pace on an annual basis. Year over year, semiconductor sales rose 35.6% in the Asia Pacific/All Other. In the Americas and China, sales rose 29.3% and 19.4%, respectively.\n\nThe impressive July figures come after a robust second quarter, wherein sales totaled $179.7 billion, up 7.8% from the previous quarter.\n\nSemiconductor Sales Poised to Grow\n\nEarlier this year, semiconductor sales slowed unexpectedly after worries emerged about U.S. tech firms losing ground to China’s low-cost AI platform, DeepSeek. However, the concerns were short-lived as experts quickly called DeepSeek overhyped and not a serious challenge to American companies.\n\nSales have mostly been growing at a steady pace this year. After an impressive 2024 — when global semiconductor revenues hit $627.6 billion, up 19.1% from $526.8 billion in 2023 — both the first and second quarters of 2025 have shown solid growth.\n\nMuch of this momentum comes from soaring demand for data center chips and memory products. With AI investments continuing to accelerate, analysts expect the semiconductor market to sustain double-digit growth throughout 2025.\n\n3 Semiconductor Stocks With Upside\n\nAdvanced Micro Devices\n\nAdvanced Micro Devices has strengthened its position in the semiconductor market on the back of its evolution as an enterprise-focused company from a pure-bred consumer-PC chip provider. AMD has emerged as a strong challenger to NVIDIA's dominance in the graphic processing unit or GPU market based on its Radeon chips.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/3-solid-stocks-buy-steady-141300903.html",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "\"Every PC will be an AI PC in four, maximum five years\" — Lenovo lays out a radical vision for computing's future at IFA",
      "content": "IFA 2025, the annual tech convention hosted in Berlin, was a huge event for Lenovo. From a new TrackPoint-less ThinkPad in a Glacier White color scheme to new foldable phones to AR glasses, gaming handhelds, and laptop prototypes, the company showed off a full gamut of new hardware.\n\nLuca Rossi, Lenovo's Executive Vice President and President of Intelligent Devices Group, hosted the IFA keynote speech before sitting down in a roundtable discussion at which I was present.\n\nThe topic? AI and AI PCs, of course.\n\nDespite growing concerns about AI causing an explosive market bubble, the fact that only about 5% of AI pilot projects make it beyond an incubation stage, or that AI is stealing jobs from young professionals at an alarming rate, Lenovo's senior leadership believes AI PCs are primed to completely take over the market.\n\nAll PCs will be AI PCs within five years — here's how that happens\n\nLenovo's new ThinkPad X9 is a big step away from the traditional ThinkPad aesthetic; yes, it's an AI PC. (Image credit: Future)\n\nPutting Lenovo's AI PC progress into perspective, so far in 2025, global AI PC penetration has hit roughly 5%. Lenovo's share of that is about 30%, and Rossi claims that the percentage will likely rise to 50% in a year or a year and a half.\n\nWhat comes after that? \"Every PC will be an AI PC in four, maximum five years\" is Rossi's prediction.\n\nIt's easy to assume that it's the killer AI features and apps that are driving that growth. Unfortunately, those don't yet exist. And if they did exist, Rossi doesn't believe that the vast majority of consumers would actually grasp and seek out AI capabilties.\n\nI think there is a relatively modest percentage of users that fully understand and fully embrace their AI. [...] I will not give you a percentage, but I would say it's not a large majority of users. Luca Rossi, Lenovo\n\nRight now, the AI PC market is largely being driven by hardware.\n\nAI PCs \"are typically very sleek, very nice with 12 hour battery life,\" explains Rossi, \"so they are very compelling, even if you take out the AI element.\" I can't argue with that, and the 2025 ASUS Zenbook A14 — one of the best Windows laptops we've ever tested even without considering the AI aspect — is proof.\n\nThere's also the matter of Windows 10's end-of-life fiasco that is forcing many users to upgrade PCs prematurely. Nevertheless, Rossi believes that AI PC growth will continue after the Windows 11 upgrade wave settles, even if that growth is slower than expert predictions.\n\nPC hardware is ready for AI; now the software must catch up\n\nA look at Microsoft's new Copilot Mode for the Edge browser. (Image credit: Future | Daniel Rubino)\n\nAI PCs only really arrived in 2024, making a big splash as Microsoft announced Copilot+ laptops with AI features unique to Windows 11.\n\nAt launch, only Qualcomm's Snapdragon X Systems-on-Chip (SoC) had a Neural Processing Unit (NPU) powerful enough to run the Copilot+ features. Intel and AMD were quick to catch up, and you can now easily find Copilot+ PCs with all three brands of CPU inside.\n\nRossi aptly brands 2024 as the year that the groundwork for AI hardware was established. 2025 can be seen as the year where that hardware matured, with stronger NPUs more capable of running AI locally without tapping the cloud.\n\nThe near future, says Rossi, is now the software's time to come into its own. He names Microsoft and Adobe as being leaders in this area, but many of Lenovo's Independent Software Vendors (ISVs) are also clamoring to make use of local AI hardware.\n\nThis is the part where the industry is not yet there in terms of software, but based on our understanding and our conversations with ISVs, there are at least 80 to 100 ISVs that are now porting their applications to have the ability to use the NPU in the CPU and get the workload done. Luca Rossi, Lenovo\n\nWhen pressed about one \"must-have\" AI app that becomes the main selling point of an AI PC, Rossi says that's still to come.\n\nRossi's argument is that NPUs are a relatively new innovation that have only been on the market for a couple of years. The software hasn't had time to mature. Rossi compares the AI software situation to that of the early days of phone app stores, when it was hard to find that one app that really made a difference.\n\n👉 Related: Best AI laptops in 2025\n\nCompare that to now, and there are countless hundreds of apps that we all rely on to function in the modern world.\n\nReturning to Copilot+ PCs, despite all of the marketing around Microsoft's initiative, it has failed to capture the attention of the masses. My colleague, Richard Devine, recently expressed his opinion about Copilot+, stating that he still doesn't care about it after a year of availability.\n\nThe future of AI computing is intent-based\n\nLenovo believes the future of AI computing is intent-based. (Image credit: Getty Images)\n\nWhile we're still waiting on the AI app that makes AI PCs a must-have, Rossi explains that he foresees computing moving toward an \"intent-based world.\"\n\nThe operating systems for which Lenovo currently builds hardware, including Windows and Android, aren't going anywhere. At least not yet. But Rossi imagines a form of advanced assistant called \"super agent\" that blends brands and ecosystems, all the while delivering that intent-based future.\n\nThat means the machine or the agent will anticipate your needs and will trigger the application or the task you need autonomously over time. That means there will be a layer, which is the agent or super agent. Luca Rossi, Lenovo\n\nRossi explains that super agents are already a reality in China, where AI seamlessly blends AI across desktops, laptops, wearables, and phones.\n\nWith Lenovo's dual-ecosystem OEM role and its CPU partnerships, Rossi believes Lenovo is in a unique position to pioneer this future of AI computing.\n\nHow will this new approach affect hardware design? It will be a slow progression of change, says Rossi. We'll still have the notebooks we know and love, but voice, gesture, and contextual awareness will begin to take over for keyboards and mice.\n\nRossi believes that wearables, like AR glasses, have the most potential for AI integration. Humans are already used to eyeglasses, they're comfortable to wear, and they could deliver AI directly within our field of view.\n\nOf course, hurdles like compute power, battery life, and lens technology refinement must be taken into consideration.\n\nIt's all gas and no brakes for Lenovo's AI ambitions\n\nIf Lenovo's forecasts are correct, the AI PC market will eventually consume the PC market as we know it today. Super agents will seamlessly blend platforms and devices, and AI software will be too good to not be using.\n\nAre you excited about that future, or are you skeptical of the envisioned AI future? Let me know in the comments section below!",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/lenovo/lenovo-ai-pc-predictions-luca-rossi-ifa-2025",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Spectre haunts CPUs again: VMSCAPE vulnerability leaks cloud secrets",
      "content": "If you thought the world was done with side-channel CPU attacks, think again. ETH Zurich has identified yet another Spectre-based transient execution vulnerability that affects AMD Zen CPUs and Intel Coffee Lake processors by breaking virtualization boundaries.\n\nThe attack, dubbed VMSCAPE (CVE-2025-40300), is said to be the first Spectre-based exploit that allows a malicious guest user in a cloud environment to leak secrets from the hypervisor in the host domain without code changes – injected Return-oriented programming gadgets – and in default configuration.\n\nThe technique is described in a paper [PDF] published on Thursday, \"VMSCAPE: Exposing and Exploiting Incomplete Branch Predictor Isolation in Cloud Environments,\" by Jean-Claude Graf, Sandro Rüegge, Ali Hajiabadi, and Kaveh Razavi. The paper is set to be presented at the 47th IEEE Symposium on Security and Privacy.\n\nCloud computing depends upon virtualization to securely partition physical computing resources into virtual ones, managed by a hypervisor. VMSCAPE targets the Kernel Virtual Machine (KVM) and QEMU (Quick Emulator), as the hypervisor and as the userspace component of the hypervisor in the host.\n\n\"VMSCAPE can leak the memory of the QEMU process at the rate of 32 B/s on AMD Zen 4,\" the authors state in their paper. \"We use VMSCAPE to find the location of secret data and leak the secret data, all within 772 s, extracting the cryptographic key used for disk encryption/decryption as an example.\"\n\nAMD Zen 1-5 processors are affected, as are Intel Coffee Lake processors, which debuted in 2017. Hardware fixes aren't feasible, the authors say, so Linux maintainers have addressed the issue in software. This comes at a cost, however, in terms of performance overhead.\n\nSpectre, a set of vulnerabilities based on processor microarchitecture, has allowed attackers to access sensitive host memory to varying degrees since its disclosure in 2018, alongside another flaw known as Meltdown.\n\nOne of these is known as Spectre v2 or Branch Target Injection, a way to abuse CPU indirect branch predictors, which control speculative execution – executing predicted instructions before they're called for in code, in order to improve performance.\n\nVarious mitigations have been developed and deployed to defend against Spectre-based attacks, generally at the cost of performance. These include: Indirect Branch Restricted Speculation (IBRS), Enhanced IBRS (eIBRS), Automatic IBRS (AutoIBRS), Indirect Branch Prediction Barrier (IBPB), and Single Threaded Indirect Branch Predictor (STIBP).\n\nBut, to date, Spectre v2 attacks have not had much impact because, as the authors note, they assume the attacker has the ability to run local code on the user's system.\n\nThe ETH Zurich boffins took a look at the way AMD and Intel processors handle host-guest boundaries and found the separation isn't sufficient on AMD Zen CPUs and older Intel CPUs. The branch target buffer (BTB) entries between host and guest are not isolated, so the branch predictor mingles predictions across host and guest domains. VMSCAPE exploits this with the help of a set of new attack primitives that the researchers call vBTI (virtualization Branch Target Injection).\n\nAn AMD spokesperson told The Register that a Security Brief will be issued that acknowledges the potential vulnerability. But the fix will be in software.\n\nIn a statement provided to The Register, an Intel spokesperson said, \"Existing mitigations on Intel processors can be used to mitigate this issue. Intel has previously provided guidance for Branch Target Injection (BTI), Branch History Injection (BHI), and Indirect Target Selection (ITS), and Intel engineers are working with Linux to ensure that the appropriate mitigations for these issues as described in these guidance documents are applied to Linux userspace hypervisor software. Linux mitigations are expected to be available on the VMSCAPE public disclosure date, and a CVE for this issue will be assigned by Linux.\"\n\nThe Linux patch, we're told, will be ported to various Linux distributions after its release.\n\nThe authors proposed a mitigation called \"IBPB-on-VMExit\" that Linux developers have optimized under the name \"IBPB before exit to userspace.\" According to the researchers, the overhead depends on the workload and the frequency of userspace exits.\n\n\"For emulated devices (default for QEMU), userspace exits are much more frequent than for virtualized devices (commonly used in enterprise systems),\" the authors observe in a summary note. \"Our benchmarking indicates an overhead of ~10 percent when using an emulated device.\"\n\nWith Zen 4, the authors' benchmark testing suggests \"a marginal 1 percent overhead\" post-patch.\n\nThe Linux mitigation is said to be active for all affected systems, including Zen 5 and even recent Intel CPUs that were not exploitable such as Lunar Lake and Granite Rapids. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/11/vmscape_spectre_vulnerability/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "'No asterisk generation' : AMD promises its MI450 AI GPU will be faster than ANYTHING Nvidia has, yes, that includes even Rubin Ultra",
      "content": "AMD positions MI450 as its no asterisk generation aimed at AI leadership\n\nCompany compares future GPU launch to 2021 Milan CPUs breaking Intel’s dominance\n\nNvidia remains overwhelmingly ahead with Rubin set to challenge MI450 in 2026\n\nAMD has made a startlingly confident claim regarding its upcoming Instinct MI450 GPUs.\n\nSpeaking at a recent investor conference, data center chief Forrest Norrod declared the firm’s new chips will outperform any rival hardware, including Nvidia’s Rubin Ultra.\n\nHe described the product as the company’s “no asterisk generation,” aimed at delivering leadership in both AI training and inference.\n\nMilan moment\n\nNorrod compared the launch to AMD’s 2021 “Milan moment,” when its EPYC server CPUs helped the company break Intel’s dominance in the server market.\n\n“MI450 is perhaps akin to our Milan moment for people that are familiar with our EPYC roadmap,” he said. “It will be, we believe, and we are planning for it to be the best training, inference, distributed inference, reinforcement learning solution available on the market.”\n\nThe MI450 will follow the current MI355, which is intended to strengthen training capabilities after earlier models were primarily optimized for inference.\n\nAMD says that the new generation has been designed with both silicon and software improvements in mind, alongside full system-level support.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nNorrod stressed that the hardware and software roadmap had been carefully staged to deliver competitiveness at every step.\n\nAt present, Nvidia utterly dominates the AI accelerator market, with estimates placing its share between 70 and 95 percent.\n\nAMD’s most advanced GPU today, the MI355X, still lags behind Nvidia’s Blackwell Ultra, although it shows clear progress over its predecessor.\n\nThe MI450 is expected to launch in 2026, arriving as Nvidia readies Rubin, which is forecast to deliver up to triple the performance of Blackwell Ultra. That will set up a direct test of AMD’s claims.\n\nAlthough the chip giant is describing the future launch as a turning point, history suggests customer adoption will depend not just on raw speed but also on software ecosystem maturity and data center integration.\n\nThis is something AMD is preparing for, as it has already said that the MI450 will ship with rack-level solutions designed for compatibility with existing infrastructure.\n\nAcknowledging Nvidia's current dominance, Norrod said, \"Nvidia is a fantastic company. They’ve done a fantastic job, and they were well ahead. We had to catch up.\"\n\nHe added, \"We decided, with this multigenerational roadmap, to put the objective in place of, okay, when we get to 450, we’re going to be there the same time as when Vera Rubin was intended to be there, and we’re going to be there with that part that’s fully performant, the software stack that’s fully there, at least for the 80% of the market that’s constituted by the top 20% or so customers. We’ve focused on getting there in the 450 so that for training, there’s no excuses, and there’s no impediment, there’s no hesitation of, hey, if I’m training, I’ll be behind in this generation if I go with AMD. That’s been the learning for us, and that’s been the realization.\"",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/no-asterisk-generation-amd-promises-its-mi450-ai-gpu-will-be-faster-than-anything-nvidia-has-yes-that-includes-even-rubin-ultra",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Nvidia's RTX 5000 Super GPUs might not arrive until CES 2026 – and that could be great news for AMD",
      "content": "Nvidia's rumored RTX 5000 Super GPU launch is reportedly delayed\n\nCES 2026 now seems the more likely time for a reveal\n\nAMD could capitalize on this if it can push out the rumored RX 9080 XT GPU\n\nNvidia's RTX 5000 series GPU line-up is set to receive a major update with rumored Super models, and it was thought that these could be close on the horizon - but apparently that isn't the case.\n\nAccording to a reputable hardware leaker, Hongxing2020 on X, Nvidia's RTX 5000 Super refreshes have been delayed. Although technically, they've not even been confirmed yet, so talk of a 'delay' presumably refers to rescheduling of launch timeframes by Nvidia.\n\nRumors have been floating around that the Super refreshes could launch in Q4 of this year, but as VideoCardz reports, according to graphics card makers, the expectation is for a CES 2026 reveal from Nvidia.\n\nIndeed, it seems a more realistic prospect that Nvidia might want to wait for a big event to showcase new RTX 5000 Super graphics cards, rather than pushing them out at the end of 2025.\n\nIt's also worth noting that recent speculation from multiple sources has implied that prices for these Super GPU models could turn out relatively reasonable, and that these boards will feature more VRAM. The RTX 5080 Super could get a boost to 24GB of VRAM over the current model's 16GB, and the RTX 5070 Ti Super may also run with 24GB.\n\n(Image credit: Future)\n\nAnalysis: AMD has a chance to capitalize here\n\nIf we take this rumor at face value, and Nvidia has indeed pushed back its launch plans here, this gives AMD more breathing room for a potential launch of its rumored Radeon RX 9080 XT. That is purportedly set to be a high-end GPU that could rival the RTX 5080.\n\nOn top of that, Intel has another rumored more powerful GPU - the Arc B770 - in the pipeline, with the packaging for that Battlemage graphics card seemingly in the works (as also reported by VideoCardz).\n\nGet daily insight, inspiration and deals in your inbox Sign up for breaking news, reviews, opinion, top tech deals, and more. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAll of these remain rumors, of course, as does Nvidia's Super refresh itself. But if AMD does have an RX 9080 XT GPU in the works, and Nvidia is now focused on launching its RTX 5000 Super series in Q1 2026, I'd love for Team Red to act between now and the end of 2025 with a reveal of a more powerful current-gen graphics card. Ideally, AMD shouldn't wait around if it has a chance to overshadow its rival here.\n\nHowever, a CES 2026 reveal for the rumored RX 9080 XT seems more likely. It's an ideal stage to reveal a new high-end GPU, after all, and CEO Lisa Su is confirmed as giving AMD's keynote.\n\nWe can talk about launch timing all we want, but the real key to the success of these purported GPUs will be pricing. We can hope that competition between these rumored launches could help keep price tags relatively competitive - but GPU inflation and real world pressures may present a different story.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/computing/gpu/nvidias-rtx-5000-super-gpus-might-not-arrive-until-ces-2026-and-thatd-be-great-news-for-amd",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "I finally tried OpenAI's 120 billion parameter open-source LLM — and without needing thousands of dollars worth of hardware",
      "content": "I'll admit that until an email dropped into my inbox, I wasn't even aware DuckDuckGo had an AI chatbot akin to ChatGPT on the go. But now I do, and per said email, it's now able to run OpenAI's gpt-oss:120b LLM.\n\nTraditionally an open source model such as this is one you would run locally through a tool such as Ollama or LMStudio, but thanks to DuckDuckGo anyone can use it, use it privately, and for free.\n\nWhy does this matter? If you were to download gpt-oss:120b in all of its 120 billion parameter glory to use at its best in Ollama, you would need more VRAM than you would get from a pair of RTX 5090s.\n\nIt's 65GB in size, so unless you have some monstrous GPU power in your rack, or something like an AMD Strix Halo-powered PC with all that lovely unified memory, it's pretty tough to run on consumer hardware.\n\nEspecially tough to run well.\n\nFast, free, private access to a sizable open-source LLM. (Image credit: Windows Central)\n\nWhat Duck.ai is providing is free access to this model, but using their servers, not your own machine. As it's provided by DuckDuckGo, a company well known for its commitment to privacy, it's probably as trustworthy as you'll get from an online tool of this kind.\n\nDuckDuckGo even flat out states that all chats are anonymized, and like other free-to-use models, you don't have to have an account. No sign-ups, no email address, just open the web page and start prompting your behind off.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nSo, how is it? It's fast. As if it wouldn't be when it's being powered by some massive cluster of hardware somewhere that isn't your home. In my limited time playing with it so far, it seems at least as quick at generating responses as the 20b model does on my RTX 5090 — Duck.ai doesn't show the tokens per second figure — but with one difference I'm not sure how I feel about yet.\n\nUsing gpt-oss:120b in Duck.ai, you don't see the content of the thinking that's done, it just throws out the response. The more I've been using gpt-oss on my own machine, the more I've started to appreciate being able to see this information.\n\nUsing thinking models such as gpt-oss locally with Ollama, you can see the thought process that delivers your response. Duck.ai doesn't have this. (Image credit: Windows Central)\n\nMaybe it's just me, but it's always interesting, and sometimes enlightening, seeing how the model created the output that it serves. In some cases this is how I've learned where mistakes have been made, and I feel like it's valuable information. I'd love it if Duck.ai even offered it as an option in settings to either show it or not.\n\nYou also can't upload your own files to use with the model. Some of the other options have image upload support, but as far as I can tell, none allow you to upload other files such as documents or examples of code. This is perhaps part of the privacy angle, but it does add a limitation to how you may want to use it.\n\nIt's generally really good, though, and since it's built inside a web app that feels a lot like ChatGPT or Google Gemini, it's welcoming and easy to use. It saves your recent chats in the sidebar, and the settings on hand to tweak how you want your responses are pretty thorough. These all apply, of course, to any of the models you use on Duck.ai, not just gpt-oss:120b.\n\nI might have found a new gem in my own AI arsenal here, but to decide on that, I'll have to play with it some more. For now, I'm just happy I can try gpt-oss:120b without having to have a GPU farm. Or an NVIDIA Blackwell Pro.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/artificial-intelligence/i-finally-tried-openais-120-billion-parameter-open-source-llm-and-without-needing-thousands-of-dollars-worth-of-hardware",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Slimbook Evo Linux laptops now available with AMD Ryzen AI 9 365 Strix Point",
      "content": "The Slimbook Evo 14 and Slimbook 15 Evo are thin and light laptops with high-resolution, 120 Hz displays, and support for up to 128GB of RAM and 16TB of storage. Slimbook recently announced updated models powered by Ryzen AI 9 365 Strix Point processors, and they’re now available for €1077 ($1265) and up.\n\nWhat makes these laptops a little different from most is that those starting prices include free installation of your choice of GNU/Linux distro. Options include Ubuntu, Debian, Fedora, Manjaro, and others. You can also have Windows installed, but you’ll have to pay a little more for a license.\n\nSlimbook also offers plenty of configuration options. Each model has two SODIMM slots for DDR5-5600 memory and two M.2 2280 slots for PCIe 4.0 NVMe SSDs.\n\nThe base price will get you a laptop with 16GB of RAM (two 8GB SODIMMS) and a single 500GB SSD plus a WiFi 6 card. But you can pay extra for systems with up to 128GB of total RAM and 8TB of total storage. There’s also a WiFi 7 card available for purchase, but Slimbook notes that it “currently” works as a WiFi card when running Linux, so you may need to wait for a driver update or install Windows to get the most use out of that upgrade.\n\nEach version of the laptop has AMD’s Ryzen AI 9 365 processor, which features a 10-core, 20-thread CPU, Radeon 880M 12-core integrated graphics, and a 50 TOPS Ryzen AI NPU.\n\nThe Slimbook Evo 14 has a 14 inch, 2880 x 1800 pixel IPS LCD display with a 120 Hz refresh rate and up to 500 nits brightness, an 80 Wh battery, and an aluminum body that measures 16.9mm (0.67 inches) thick and weighs 1.4kg (3.1 pounds).\n\nSlimbook’s Evo 15, meanwhile, has a 15.3 inch, 2560 x 1600 pixel, 120 Hz IPS LCD display that tops out at 400 nits brightness. The larger model also has a larger 99 Wh battery. This model also has a numeric keypad on the right side of the keyboard, but at 18.1mm (0.71 inches) thick and 1.6 kg (3.5 pounds), the Slimbook Evo 15 is a little thicker and heavier than its 14 inch sibling.\n\nBoth laptops feature dual fans for active cooling, and both feature 1080p webcams with IR cameras, dual microphones, stereo speakers, and white LED backlit keyboards. Ports include:\n\n1 x USB4 (40 Gbps w/DP 1.4 and 100W USB-PD)\n\n1 x USB 3.2 Gen 2 Type-C (10 Gbps w/DP 1.4 and 100W USB-PD)\n\n2 x USB 3.2 Gen 1 Type-A (5 Gbps)\n\n1 x USB 2.0 Type-A (480 Mbps)\n\n1 x SDXC card reader (SD 7.0, up to 985MB/s)\n\n1 x HDMI 2.1\n\n1 x Gigabit Ethernet\n\n1 x 3.5mm audio\n\nvia 9to5Google\n\nSupport Liliputing Liliputing's primary sources of revenue are advertising and affiliate links (if you click the \"Shop\" button at the top of the page and buy something on Amazon, for example, we'll get a small commission). But there are several ways you can support the site directly even if you're using an ad blocker* and hate online shopping. Contribute to our Patreon campaign or... Contribute via PayPal * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a guide that may help you disable it.",
      "source": "Liliputing",
      "url": "https://liliputing.com/slimbook-evo-linux-laptops-now-available-with-amd-ryzen-ai-9-365-strix-point/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Apple downgraded, Nvidia upgraded: Wall Street's top analyst calls",
      "content": "The most talked about and market moving research calls around Wall Street are now in one place. Here are today's research calls that investors need to know, as compiled by The Fly.\n\n\n\nTop 5 Upgrades:\n\n\n\nDA Davidson upgraded Nvidia (NVDA) to Buy from Neutral with a price target of $210, up from $195, citing the belief the growth in AI compute demand will drive enough demand to sustain growth into next year and likely beyond.\n\nDeutsche Bank upgraded Chewy (CHWY) to Buy from Hold with a price target of $45, up from $38, post the fiscal Q2 report. The company's growth investments in the second half of 2025 will drive earnings estimate cuts, but buy-side expectations are \"now in a better place,\" the firm tells investors in a research note. Seaport Research also upgraded Chewy to Buy from Neutral with a $47 price target.\n\nBarclays upgraded Thermo Fisher (TMO) to Overweight from Equal Weight with a price target of $550, up from $490. The company's valuation, both on an absolute and relative basis, is now at attractive levels, the firm tells investors in a research note.\n\nWolfe Research upgraded Bill (BILL) to Outperform from Peer Perform with a $70 price target. The shares are down 37% year-to-date and the company faces better prospects into fiscal 2026, the firm tells investors in a research note.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/apple-downgraded-nvidia-upgraded-wall-134736182.html",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "This ultra slim mini PC is essentially a Core i9 laptop with an RTX 5070 laptop GPU, but sans a battery, keyboard, and screen",
      "content": "Minisforum G7 Pro delivers laptop-level performance in a compact Mini PC chassis\n\nNVIDIA RTX 5070 Laptop GPU powers desktop-class graphics in a small device\n\nDual-channel DDR5 RAM and two M.2 PCIe 4.0 slots support heavy workloads\n\nAt IFA 2025, Minisforum unveiled a series of mini PCs, including the G7 Pro, which uses an Intel Raptor Lake-HX CPU and condenses high-end business laptop performance into a compact device.\n\nThe G7 Pro is a small-form-factor (SFF) gaming mini PC featuring an Intel Core i9-14900HX processor with 24 cores and 32 threads, reaching up to 5.8GHz.\n\nIts graphics are powered by an Nvidia GeForce RTX 5070 Laptop GPU, providing desktop-class performance.\n\nPowerful memory, fast storage, and versatile connectivity\n\nThis mini PC supports up to 96GB of dual-channel DDR5 RAM and offers storage via two M.2 PCIe 4.0 SSD slots.\n\nConnectivity options include HDMI 2.1, USB4, multiple USB-A and USB-C ports, RJ45 Ethernet, Wi-Fi 7, Bluetooth 5.4, and an SD card reader.\n\nThe chassis features an ultra-slim design with a mode toggle button for flexible operation.\n\nThis makes it suitable for workspaces with limited room, while still delivering desktop-level performance.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe absence of a built-in display or keyboard allows users to select peripherals that fit their needs.\n\nTechnically, this device is a laptop stripped of its battery, display, and keyboard.\n\nYet, it still delivers full Core i9 performance, making it both a portable option and a capable workstation for professional or gaming applications.\n\nThe absence of a battery means that this device is powered directly via an AC power connection using an external power adapter, similar to a desktop PC.\n\nHowever, this can be highly inconvenient for people without a stable power supply.\n\nThe price information for the G7 Pro remains unknown at the time of writing.\n\nThis will be important in determining whether users can afford to purchase it along with a separate keyboard and monitor, otherwise, a laptop might be a more convenient option.\n\nIn addition to the G7 Pro, Minisforum also presented three additional systems at IFA 2025.\n\nThe G1 Pro, powered by Ryzen 9 8945HX and an RTX 5060 desktop GPU, targets gamers who prefer a console-style mini PC.\n\nThe MS-S1 MAX is positioned as an AI workstation supporting up to 128GB of LPDDR5X memory and USB4 v2.\n\nThe NS Pro focuses on NAS use cases, with AMD Strix Point processors and high-speed storage connectivity.\n\nVia Videocardz",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/this-ultra-slim-mini-pc-is-essentially-a-core-i9-laptop-with-an-rtx-5070-laptop-gpu-but-sans-a-battery-keyboard-and-screen",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Top China silicon figure calls on country to stop using Nvidia GPUs for AI — says current AI development model could become 'lethal' if not addressed",
      "content": "Wei Shaojun, vice president of China Semiconductor Industry Association, and a senior Chinese academic and government adviser, has called on China and other Asian countries to ditch using Nvidia GPUs for AI training and inference. At a forum in Singapore, he warned that reliance on U.S.-origin hardware poses long-term risks for China and its regional peers, reports Bloomberg.\n\nWei criticized the current AI development model across Asia, which closely mirrors the American path of using compute GPUs from Nvidia or AMD for training large language models such as ChatGPT and DeepSeek. He argued that this imitation limits regional autonomy and could become 'lethal' if not addressed. According to Wei, Asia's strategy must diverge from the U.S. template, particularly in foundational areas like algorithm design and computing infrastructure.\n\nAfter the U.S. government imposed restrictions on the performance of AI and HPC processors that could be shipped to China in 2023, it created significant hardware bottlenecks in the People's Republic, which slowed down the training of leading-edge AI models. Despite these challenges, Wei pointed to examples such as the rise of DeepSeek as evidence that Chinese companies are capable of making significant algorithmic advances even without cutting-edge hardware.\n\nHe also noted Beijing's stance against using Nvidia's H20 chip as a sign of the country’s push for true independence in AI infrastructure. At the same time, he acknowledged that while China's semiconductor industry has made progress, it is still years behind America and Taiwan, so the chances that China-based companies will be able to build AI accelerators that offer performance comparable to that of Nvidia's high-end offerings are thin.\n\nWei proposed that China should develop a new class of processors tailored specifically for large language model training, rather than continuing to rely on GPU architectures, as they were originally aimed at graphics processing. While he did not outline a concrete design, his remarks are a call for domestic innovation at the silicon level to support China’s AI ambitions. However, he did not point out how China plans to catch up with Taiwan and the U.S. in the semiconductor production race.\n\nHe concluded on a confident note, stating that China remains well-funded and determined to continue building its semiconductor ecosystem despite years of export controls and political pressure from the U.S. The overall message was clear: China must stop following and start leading by developing unique solutions suited to its own technological and strategic needs.\n\nNvidia GPUs became dominant in AI because their massively parallel architecture was ideal for accelerating matrix-heavy operations in deep learning, offering far greater efficiency than CPUs. Also, the CUDA software stack introduced in 2006 enabled developers to write general-purpose code for GPUs, paving the way for deep learning frameworks like TensorFlow and PyTorch to standardize on Nvidia hardware.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nOver time, Nvidia reinforced its lead with specialized hardware (Tensor Cores, mixed-precision formats), tight software integration, and widespread cloud and OEM support, making its GPUs the default compute backbone for AI training and inference. Nvidia's modern architectures like Blackwell for data centers have plenty of optimizations for AI training and inference and have almost nothing to do with graphics. By contrast, special-purpose ASICs — which are advocated by Wei Shaojun — are yet to gain traction for either training or inference.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/artificial-intelligence/top-china-silicon-figure-calls-on-country-to-stop-using-nvidia-gpus-for-ai-says-current-ai-development-model-could-become-lethal-if-not-addressed",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Cramer Flags Oracle Rally As 'Strange,' Says Nvidia And AMD Aren't Getting Any Love",
      "content": "Benzinga and Yahoo Finance LLC may earn commission or revenue on some items through the links below.\n\nOracle Corp. (NYSE:ORCL) may be one of Wall Street's hottest AI bets, but CNBC's Jim Cramer says something isn't adding up. Despite Oracle's stock strength, chipmakers that would logically benefit from the company's data center growth, like Nvidia Corp. (NASDAQ:NVDA) and Advanced Micro Devices Inc. (NASDAQ:AMD), are barely moving.\n\n\"It's almost as if nobody believes anyone benefits besides Oracle,\" Cramer wrote on X, calling the divergence \"all very strange,\" he posted on X.\n\nOracle's AI Momentum Hits An Odd Speed Bump\n\nOracle has emerged as a surprise winner in the AI race, with investors betting on its cloud infrastructure to challenge leaders like Amazon.com Inc‘s (NASDAQ:AMZN) Amazon Web Services and Microsoft Corp‘s (NASDAQ:MSFT) Azure.\n\nTrending: The same firms that backed Uber, Venmo and eBay are investing in this pre-IPO company disrupting a $1.8T market — and you can too at just $2.90/share.\n\nORCL stock is up over 100% YTD, and was trading higher by over 40% at the time of publication on Wednesday, despite the company reporting a miss as it reported second quarter earnings on Tuesday. The company's recent surge reflects optimism about partnerships and AI-driven workloads that could expand its market share.\n\nTypically, such optimism would also fuel gains for semiconductor giants, as AI adoption drives demand for GPUs and chips to power data centers.\n\nChipmakers Sit Out The Rally\n\nYet Nvidia, the market's AI bellwether, and AMD, a rising competitor, are showing little movement alongside Oracle's momentum. This divergence may reflect skepticism that Oracle's growth translates into meaningful chip orders, especially given supply constraints and existing backlogs at Nvidia.\n\nSemiconductor valuations are also near record highs after a multi-quarter AI-fueled rally, leaving little room for sympathy trades without fresh catalysts.\n\nSee Also: If there was a new fund backed by Jeff Bezos offering a 7-9% target yield with monthly dividends would you invest in it?\n\nInvestor Caution Creeps In\n\nCramer's comment highlights a broader caution creeping into AI-related trades. Investors appear selective, rewarding Oracle for its narrative but reluctant to extend enthusiasm across the supply chain. Whether this signals overbought conditions in chip stocks or doubts about Oracle's ability to sustain its momentum, the divergence is a rare crack in the AI trade's usual correlations.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/cramer-flags-oracle-rally-strange-033102051.html",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "AMD Ryzen(TM) プロセッサー、GeForce RTX(TM) 5000シリーズ搭載Acer Nitroから量販店モデル4機種を一挙登場！",
      "content": "日本エイサー株式会社（本社：東京都新宿区、代表取締役社長：ボブ・セン）は、カジュアルゲーマーからコアゲーマーまで幅広いユーザーに向けたゲーミングブランド Nitro（ニトロ） より、16インチゲーミングノートPC 新製品 「Nitro 16S AI」 の2機種「AN16S-61-A76Z57T/E」「AN16S-61-N76Z56/E」と、「Nitro V 16S AI」 の2機種「ANV16S-41-A76Y56/E」「 ANV16S-41-A76Y55/E」の計4機種を、本日9月11日よりヨドバシカメラ、ビックカメラグループ、またその他量販店ECサイトにて順次発売いたします。\n\n「AN16S-61-A76Z57T/E」「AN16S-61-N76Z56/E」は、4機種の中でも上位モデルに位置づけられます。「ANV16S-41-A76Y56/E」「 ANV16S-41-A76Y55/E」との主な違いは、以下の4点です。\n\nCPU： AMD Ryzen™ AI 7 350 プロセッサーを採用 メモリ：32GBを搭載 ストレージ：1TB SSDを搭載 液晶パネル：NVIDIA® G-SYNC® に対応した WQXGA（2560×1600）解像度パネル を搭載\n\nNitro 16S AI（AN16S-61-A76Z57T/E、AN16S-61-N76Z56/E）\n\nいずれもAMD Ryzen™ AI 7 350 プロセッサー を搭載し、32GBメモリー と 大容量1TB（1024GB）SSD を標準装備。4K HDRストリーミング、ゲーミング、クリエイティブワークなど幅広い用途で高いパフォーマンスを発揮します。また高効率なマルチコア構成と AMD同時マルチスレッディングテクノロジー により、ゲームプレイ時の処理やマルチタスク時でもスムーズな操作を実現します。\n\nさらに、最大 50TOPS の処理能力を誇る AMD Ryzen AI NPU が、背景ぼかしや音声ノイズ除去などの機能を強化。Copilot+ PC による、プロンプトからのコンテンツ生成といったAI体験が、創造性と生産性を飛躍的に高めます。また電力効率の最適化により、長時間の使用でも発熱や騒音を抑制し、バッテリー駆動も効率化。ゲーミングPCとしての高性能と日常使いの柔軟性を兼ね備えた次世代AI PC です。\n\nNitro V 16S AI（ANV16S-41-A76Y56/E、ANV16S-41-A76Y55/E）\n\nAMD Ryzen™ 7 260 プロセッサー、16GBメモリー、512GB SSD を搭載。ゲーム、配信、クリエイティブワークなど、幅広い用途で安定したパフォーマンスを発揮します。高効率なマルチコア構成と AMD同時マルチ・スレッディング・テクノロジー により、ゲームプレイに必要な処理速度と、同時アプリ利用時の軽快な操作感を両立。複数のアプリ利用でもゲームがスムーズに動作し、画面切り替えや並行作業も軽快に行えます。\n\nさらに、AMD Ryzen AI（最大16 TOPS NPU） により、背景ぼかしや音声ノイズ除去などのAIサポート機能を強化。ゲーム配信やオンライン通話をより快適にし、新しいAIアプリケーションにも対応します。電力効率にも優れ、長時間の使用でも発熱や騒音を抑えた安定動作を実現。ゲーミングPCとしての性能と、日常使いの柔軟性を兼ね備えたバランスの取れた一台です。\n\n最新 GPU による圧倒的グラフィックス性能\n\n最上位機種「AN16S-61-A76Z57T/E」には NVIDIA® GeForce RTX™ 5070 Ti Laptop GPU を搭載。「AN16S-61-N76Z56/E」「ANV16S-41-A76Y56/E」には GeForce RTX™ 5060 Laptop GPU を、「AN16S-61-N76Z56/E」には GeForce RTX™ 5050 Laptop GPU をそれぞれ採用しています。また最新の NVIDIA Blackwell アーキテクチャと RTX Tensor コアにより、Nitro シリーズは表現力をさらに進化。消費電力を抑えつつ、前世代の RTX 40 シリーズから着実に性能を向上しています。さらに、AI 処理・生成 AI・映像制作など 150 以上の最適化アプリケーションに対応し、プロフェッショナルからクリエイターまで幅広いユーザーのワークフローを快適にサポート。DLSS 4 とリアルタイム Ray Tracing によるニューラルレンダリング技術が、圧倒的な美しさとスピードを両立した次世代の映像体験を提供します。\n\n目に優しく色彩と没入かんを極めたゲーミングディスプレイ\n\n「AN16S-61-A76Z57T/E」「AN16S-61-N76Z56/E」にはNVIDIA® G-SYNC® 対応の16インチ WQXGA（2560×1600）を、「ANV16S-41-A76Y56/E」「 ANV16S-41-A76Y55/E」には16インチWUXGA（1920×1200）を搭載し、いずれも解像度16:10 アスペクト比の IPS パネルを採用しています。\n\nノングレア（非光沢）仕様により、長時間のプレイでも目に優しく、外光の映り込みを抑えてクリアな視認性を確保。さらに、180Hz の高リフレッシュレートがティアリングやカクつきを防ぎ、素早いモーションも滑らかに描き出します。瞬時の操作を正確に反映することがｆ、FPSやアクションゲームにおける優位性を発揮することができるのです。\n\n加えて、sRGB 100% の広色域により深みのある色彩表現を実現。暗所での敵の動きや質感までも鮮やかに映し出し、集中力を高めながら、かつてない臨場感あふれるゲーム体験を提供します。\n\n長時間プレイでも安心の冷却性能\n\n高負荷なゲームプレイでもパフォーマンスを損なわない冷却性能を備えています。最新のサーマル設計により、デュアルファンとクアッド吸排気システムが冷却性能を飛躍的に向上。上部のキーボード面とボタンカバーの両方から取り込んだ冷気を、2つのファンが連動して強力に循環させ、システムの両側面と背面に配置された通気口から効率的に熱を排出します。この高性能な冷却構造が、CPUとGPUの性能を最大限に引き出し、長時間のプレイでも熱によるパフォーマンス低下を抑制。安定性と冷却効率を兼ね備え、ゲームが白熱してもPCは常にクールに保たれます。磨き抜かれた熱設計が、限界を超えるゲーミング体験を支えます。\n\nさらに、「AN16S-61-A76Z57T/E」「AN16S-61-N76Z56/E」には、液体金属熱グリスを採用。従来の熱グリスと比べ熱容量が14.5%※向上し、熱の蓄積を抑えます。\n\n※同じ条件下で液体金属熱グリスと従来の熱グリスを比較した Acer 社内テストに基づく性能向上。実際の性能は、システム、使用方法、環境によって異なる場合があります。\n\n美しさと堅牢性を兼ね備えたデザイン\n\n厚さ約19.9mm※のスリムなボディに、スタイルとパフォーマンスを凝縮。メタルケースに収められた洗練されたデザインは、モダンな美しさと堅牢さを兼ね備え、エレガンスとパワーを完璧に融合します。印象的なRGBライティングロゴや4ゾーンRGBライティング対応キーボードは、鮮やかな発光パターンをカスタマイズ可能。直感的な操作でゲームの没入感を高め、ワークスペースにも個性を演出します。\n\n※GeForce RTX™ 5070 Tiを搭載した最上位機種「AN16S-61-A93Z57T/E」のみ厚さ約21mmとなります。\n\n立体音響と AI 機能で進化する音と映像\n\nDTS:X® Ultraによる立体音響が、敵の気配を捉え、ゲームの世界を隅々までリアルに再現。足音、銃声、環境音が空間的に広がり、瞬時の判断力を研ぎ澄ませます。さらに、Acer PurifiedVoice™ のAIノイズリダクション機能が、プレイヤーの声をクリアに届け、仲間からの声も鮮明に表現。戦術的なコミュニケーションを妨げません。WebカメラにはAcer PurifiedView™ を搭載。背景ぼかしや視線補正、自動フレーミングなどのAI機能で、ビデオ通話や配信でも自然で鮮明な印象を実現します。音と映像の両面から支えるスマートなテクノロジーです。\n\nAI 機能を一元管理できる NitroSense\n\nNitroSense™ は、ゲーミングPCのパフォーマンスを直感的にコントロールできる専用アプリケーションです。独立した NitroSense キーを押すだけで起動し、システム温度、電力設定、使用状況をリアルタイムで監視可能。さらに、4つの動作モード（静音・バランス・パフォーマンス・エコ）を切り替えることで、使用シーンに応じた最適な冷却・静音・省電力環境を実現します。また、Experience Zone では AI 関連機能をひとつに集約。ゲームプレイから日常作業まで役立つスマートな機能に簡単にアクセスできます。Acer PurifiedVoice™ による AI ノイズリダクションや、PurifiedView™ の自動映像補正もここから一括管理可能。快適で効率的なユーザー体験を提供します。\n\nさらに、Wi-Fi 6EとBluetooth 5.2により、安定性と応答性に優れたワイヤレス接続を実現。ラグの少ないオンライン対戦やスムーズなストリーミング体験を可能にします。USB4®ポート（Type-C、最大40Gbps、映像出力対応）は、高速データ転送と高解像度映像出力を両立し、外部モニターやストレージ接続もスピーディに完了。作業もゲームも思いのままに加速します。\n\nインターフェース\n\n各モデルには、用途に応じた豊富なインターフェースを搭載しています。\n\nNitro 16S AI（AN16S-61-A76Z57T/E、AN16S-61-N76Z56/E）\n\nUSB4 ポート×1（Type-C、最大40Gbps、映像出力対応）（リア）、USB 3.2ポート×1（Type-C、Gen 2、最大10Gbps、映像出力対応）（リア）、USB 2.0ポート×1（レフト）、USB 3.2ポート×2（Type-A、Gen 2、最大10Gbps、うち1ポートは電源オフUSB充電機能付き）、ヘッドセット/スピーカー・ジャック×1、HDMI出力ポート×1、DCジャック×1\n\nNitro V 16S AIシリーズ（ANV16S-41-A76Y56/E、 ANV16S-41-A76Y55/E）\n\nUSB4 ポート×1（Type-C、最大40Gbps、映像出力対応）（リア）、USB 3.2ポート×1（Type-A、Gen 1、最大5Gbps）、USB 3.2ポート×2（Type-A、Gen 2、最大10Gbps、うち1ポートは電源オフUSB充電機能付き）、ヘッドセット/スピーカー・ジャック×1、HDMI出力ポート×1、DCジャック×1\n\n製品公式ページ 「Nitro 16S AI」:\n\nhttps://www.acer.com/jp-ja/laptops/nitro/nitro-16s-ai-amd\n\n製品公式ページ 「Nitro V 16S AI」:\n\nhttps://www.acer.com/jp-ja/laptops/nitro/nitro-v-16s-ai-amd\n\nプレスリリースページ\n\nhttps://www.acer.com/jp-ja/about/news/20250911\n\nAcerについて\n\nAcer は世界160か国以上で事業を展開するグローバルICTカンパニーです。1976年の創業以来、人々の生活を豊かにするパソコン、モニター、プロジェクター、タブレットなどのハードウェアやソフトウェア、サービスを提供しています。Acerは現在、全世界約7,500人の従業員とともに、“Breaking barriers between people and technology（人とテクノロジーの垣根を壊す）”のミッションのもと、製品の研究、デザイン、マーケティングおよび販売とサポートを行っています。\n\n日本エイサー株式会社について\n\n社名 ：日本エイサー株式会社\n\n所在地：東京都新宿区西新宿6-24-1 西新宿三井ビルディング 18F\n\n代表者：代表取締役社長 詹 國良（ボブ・セン）\n\n公式サイト： https://www.acer.com/\n\n公式facebook： https://www.facebook.com/AcerJapan\n\n公式X ： https://www.twitter.com/AcerJapan\n\nGaming公式X: https://twitter.com/PredatorJPN\n\n公式Instagram： https://www.instagram.com/acer_japan/\n\nGaming公式Instagram： https://www.instagram.com/predatorgamingjapan/\n\n公式YouTube： https://www.youtube.com/user/AcerJapanChannel\n\n© 2024 Acer Inc. All rights reserved. AcerとAcerロゴはAcer Inc.の登録商標です。その他商標、登録商標、サービスマーク等の著作物の著作権は、帰属表明の有無に関わらず、それぞれの権利者に帰属します。発表内容は予告なしに変更または削除されることがありますのであらかじめご了承ください。\n\n© 2024 Acer Inc. All rights reserved. Acer and the Acer logo are registered trademarks of Acer Inc. Other trademarks, registered trademarks, and/or service marks, indicated or otherwise, are the property of their respective owners. All offers subject to change without notice or obligation and may not be available through all sales channels.",
      "source": "Prtimes.jp",
      "url": "https://prtimes.jp/main/html/rd/p/000001031.000000640.html",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Borderlands 4 Dev Gearbox Asks PC Gamers to Keep Playing for at Least 15 Minutes After They Tweak Settings to See How Performance Has Changed, as Negative Steam Reviews Pile Up",
      "content": "Borderlands 4 has launched on Steam to big concurrent player numbers, but the release was marred by complaints about PC performance that have resulted in a ‘mixed’ user review rating on Valve’s platform.\n\nBorderlands 4 peaked at 207,479 concurrent player numbers on Steam yesterday, September 11, which was significantly higher than any previous Borderlands before it. However, the game launched to ‘mostly negative’ Steam reviews over performance issues and crashing, before recovering overnight to ‘mixed.’\n\nThe complaints revolve around poor performance even on high powered PCs, with some affected by crashing that makes the game difficult to even start.\n\n“Terrible optimization. Another Unreal Engine 5 casualty. Not worth buying in its current state unless you have a NASA PC,” said one person in a negative review.\n\n“Terrible, terrible performance. Worst I've ever seen. Turned it down to Low graphics presets and couldn't hit 60 FPS, even with FSR upscaling on my RX 6900 XT,” said another.\n\nIn response, Gearbox posted a Borderlands 4 Nvidia Optimization guide on Steam, advising players how to optimize their graphics settings for “better performance and framerates” on PC with the Nvidia app.\n\n“As PC gamers begin their Vault-hunting journeys in Borderlands 4, we've seen early feedback from the community surrounding graphics settings and how to achieve optimal performance,” Gearbox said, before outlining the “expected results” for the Borderlands 4 PC specs:\n\nMinimum PC specs - 1080p @ 30FPS with Low Preset settings\n\nRecommended PC specs - 1440p @ 60FPS with Medium Preset settings\n\nGearbox then issued a piece of advice to PC gamers that to me reads like an effort to prevent players from making knee-jerk reactions to the game's performance as soon as they’ve changed their settings: “Please note that any time you change any of your graphics settings, your shaders will need to recompile. Please keep playing for at least 15 minutes to see how your PC's performance has changed.”\n\nGearbox went on to show the “Optimal Settings” charts provided by Nvidia with suggestions for which graphics settings may work best for your combination of GPU and desired display resolution. Meanwhile, it recommended using the Nvidia app to download and install Nvidia’s newest Game Ready Driver (581.29) and “optimize for your system.” If all else fails, “please contact 2K Support for direct assistance.”\n\nBorderlands 4 Review Screenshots View 159 Images\n\nGearbox and publisher 2K Games will be keen to address the performance complaints early, given the impact negative reviews on Steam can have on a video game’s success. Ahead of launch, Gearbox development chief Randy Pitchford had said the Borderlands 4 Day 1 patch “does a lot,” amid concern about the performance of the looter shooter. Pitchford had responded to concern about Borderlands 4’s pre-release performance on PC from some users on X / Twitter.\n\nDespite the Day 1 patch, playing Borderlands 4 on older hardware won't miraculously unlock \"buttery smooth performance,\" Pitchford added. It should be expected that Borderlands 4 is “unplayable” if you’re trying to use a PC below min-spec, he said, and, generally, playing new AAA games on older hardware won't achieve impressive results.\n\nHere’s Pitchford's comment in full:\n\nThe Day 1 patch does a lot! That said, the expectation for using a below min-spec machine should be that the game is unplayable. That the game runs at all on your system is a miracle. That you can get 55 - 60 fps out of heavy combat is actually incredible given how the engine and what's going on under the hood. Your specification doesn't indicate if you're on SDD or HDD, but that could also explain some of the hitching. It's a big, bold, new, seamless world and I'm sorry to say that older hardware may not provide buttery smooth performance for the latest gen AAA games, as has always been the case since the dawn of PC gaming.\n\nAs a reminder, here are Borderlands 4’s PC specs:\n\nBorderlands 4 System Requirements:\n\nMinimum:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-9700 / AMD Ryzen 7 2700X\n\nMemory: 16 GB RAM\n\nGraphics: NVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. Requires 8 CPU Cores for processor. Requires 8 GB VRAM for graphics. SSD storage required\n\nRecommended:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nMemory: 32 GB RAM\n\nGraphics: NVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. SSD storage required\n\nIf you are delving into Borderlands 4 don't go without our updated hourly SHiFT codes list. We've also got a huge interactive map ready to go and a badass Borderlands 4 planner tool courtesy of our buds at Maxroll. Plus check out our expert players' choices for which character to choose (no one agreed).\n\nWesley is Director, News at IGN. Find him on Twitter at @wyp100. You can reach Wesley at wesley_yinpoole@ign.com or confidentially at wyp100@proton.me.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/borderlands-4-dev-gearbox-asks-pc-gamers-to-keep-playing-for-at-least-15-minutes-after-they-tweak-settings-to-see-how-performance-has-changed-as-negative-steam-reviews-pile-up",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "PowerColor AMD Radeon RX 9060 XT Reaper Dual Fan 16GB GDDR6 PCIe 5.0 Graphics Card $350 + Free Store Pickup",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18600991-powercolor-amd-radeon-rx-9060-xt-reaper-16gb-gddr6-pcie-5-0-graphics-card-350-free-store-pickup",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "GIGABYTE B650E AORUS ELITE X AX ICE AM5 ATX Mobo + 120mm Montech AX 120 ARGB Fan $107.90 + Free Shipping",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired BeigeRoad455 posted Item 1 of 2 Item 1 of 2 expired BeigeRoad455 posted GIGABYTE B650E AORUS ELITE X AX ICE AM5 ATX Mobo + 120mm Montech AX 120 ARGB Fan + Free Shipping $108 $263 58% off Newegg 37 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 8,356 Views Visit Newegg Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18601741-gigabyte-b650e-aorus-elite-x-ax-ice-am5-atx-mobo-120mm-montech-ax-120-argb-fan-107-90-free-shipping",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "New Spectre-based CPU vulnerability allows guests to steal sensitive data from the cloud",
      "content": "ETH Zurich researchers found a new Spectre-BTI attack called VMSCAPE that lets a VM steal host data\n\nIt affects cloud setups using KVM/QEMU on AMD and Intel CPUs, bypassing existing defenses\n\nThey propose flushing the branch predictor on VMEXIT as a low-cost fix\n\nIf Ghostbusters taught us anything, it’s that spectres are notoriously difficult to get rid of.\n\nSecurity researchers from the Swiss public university, ETH Zurich, recently discovered a new Spectre-BTI (Branch Target Injection) attack that allows a malicious virtual machine (VM) to leak sensitive data from the host system, without modifying host software.\n\nThe research team - Jean-Claude Graf, Sandro Rüegge, Ali Hajiabadi, and Kaveh Razavi - conducted a systematic analysis of branch predictor isolation, targeting environments using KVM/QEMU virtualization on AMD Zen 4 and Zen 5 CPUs.\n\nFixing the flaw\n\nIn early June, they developed an exploit and named it VMSCAPE.\n\nAccording to the research paper published earlier this week, VMSCAPE is proof that default mitigations (hardware and software defenses that were previously considered sufficient for speculative execution attacks such as Spectre) are not enough to prevent speculative execution attacks across VM boundaries, and that secrets like disk encryption keys can be leaked in real-world cloud setups.\n\nAll cloud providers running virtualized workloads on vulnerable CPUs using KVM/QEMU are affected by the bug, the researchers further explained, which includes AMD Zen 1-5, and Intel’s Coffee Lake chips. KVM/QEMU is a powerful virtualization stack commonly used in Linux-based cloud environments.\n\nThe bug is now tracked as CVE-2025-40300, but the severity score has not yet been determined.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nChipmakers are already on the move, as well. An AMD spokesperson told The Register that the company is preparing a security brief, as well as a software fix.\n\nAn Intel representative told the same publication that existing mitigations can be used to address this flaw. “Linux mitigations are expected to be available on the VMSCAPE public disclosure date, and a CVE for this issue will be assigned by Linux,\" they added.\n\nThe paper’s authors propose flushing the CPU’s branch predictor using IBPB on VMEXIT as a mitigation for VMSCAPE, as this prevents a malicious guest VM from influencing speculative execution paths in the host. They also stressed that the tests showed negligible performance overhead, and that the fix was practical for deployment.\n\nVia The Register",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/security/new-spectre-based-cpu-vulnerability-allows-guests-to-steal-sensitive-data-from-the-cloud",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Intel Talent Bleed Continues",
      "content": "Intel's long-time Xeon chief architect Ronak Singhal is leaving the company after nearly 30 years , marking yet another high-profile departure amid Intel's leadership churn and intensifying competition from AMD and Arm-based cloud CPUs. The Register reports:",
      "source": "Slashdot.org",
      "url": "https://slashdot.org/story/25/09/12/2136201/intel-talent-bleed-continues",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "How AMD, Nvidia, Broadcom Can Ride Oracle’s $455B Cloud Surge",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/12/how-amd-nvidia-broadcom-can-ride-oracles-455b-cloud-surge/",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Get this Ryzen 7 mini PC with 32GB RAM for a crazy low $339",
      "content": "Nowadays, your home or office setup can feature a mini PC without issue because these things aren’t just powerful, but also affordable. The Beelink SER5 Max mini PC is only $339 right now, which is 24 percent off its MSRP at Amazon.\n\nThis tiny device runs on an AMD Ryzen 7 6800H CPU and an amazing 32GB LPDDR5 RAM, which means this thing’ll be uber fast, handling all the tasks you need to get done throughout the day. The 1TB SSD will add plenty of storage space for apps and files, while also booting your system in a blink.\n\nThis Beelink SER5 Max mini PC also supports triple 4K monitors, so you get to multitask like never before.\n\nIf you want a different configuration, there are plenty of mini PCs on sale these days. Here are some alternatives:\n\nFor $319 (20% off) , you can get the Beelink EQi12 with an Intel i5 CPU, 16GB DDR4, a 500GB SSD, and dual screen support.\n\n, you can get the Beelink EQi12 with an Intel i5 CPU, 16GB DDR4, a 500GB SSD, and dual screen support. If you’d rather get a Ryzen system, the Acemagic K1 is down to $315 (28% off) , featuring an AMD Ryzen 7 CPU, 32GB DDR4, a 1TB SSD, and triple display support.\n\n, featuring an AMD Ryzen 7 CPU, 32GB DDR4, a 1TB SSD, and triple display support. If you want something even cheaper, the Acemagic V1 is down to $188.1 (41% off) , featuring an Intel Twin Lake N150 CPU, 16GB DDR4 RAM, and 1TB SSD, as well as dual display support.\n\n, featuring an Intel Twin Lake N150 CPU, 16GB DDR4 RAM, and 1TB SSD, as well as dual display support. The Kamrui GK3Plus is another good option, featuring an Alder Lake N95 CPU, 16GB RAM, and a 512GB SSD, as well as triple-screen support. This one’s only $160, which is 20% under its MSRP, but its CPU will be significantly slower than the Ryzen found in the Beelink SER5 Max.\n\nAll of these are good options, but it does depend on what type of system you prefer and just how much power you’ll need to get your tasks done.\n\nThe Beelink SER5 Max has a fantastic discount, and getting this speedy configuration for $339 is a great deal.\n\nGet a powerful mini PC for $339",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2898428/get-this-ryzen-7-mini-pc-with-32gb-ram-for-a-crazy-low-339.html",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Linux 6.17 Fix Lands To Address Regression With \"Serious Breakage\" In Hibernation",
      "content": "\"Commit 12ffc3b1513e (\"PM: Restrict swap use to later in the suspend sequence\") incorrectly removed a pm_restrict_gfp_mask() call from hibernation_snapshot(), so memory allocations involving swap are not prevented from being carried out in this code path any more which may lead to serious breakage.\n\n\n\nThe symptoms of such breakage have become visible after adding a shrink_shmem_memory() call to hibernation_snapshot() in commit 2640e819474f (\"PM: hibernate: shrink shmem pages after dev_pm_ops.prepare()\") which caused this problem to be much more likely to manifest itself.\n\n\n\nHowever, since commit 2640e819474f was initially present in the DRM tree that did not include commit 12ffc3b1513e, the symptoms of this issue were not visible until merge commit 260f6f4fda93 (\"Merge tag 'drm-next-2025-07-30' of https://gitlab.freedesktop.org/drm/kernel\") that exposed it through an entirely reasonable merge conflict resolution.\"\n\n\"The issue here is that as of 6.17.0-rc1, running hibernate (disk) more than 7 times causes instability on most machines. The hibernate can be run with /sys/power/disk set to any value. The issue is the hibernate image itself becoming corrupted. The instability appears in user space as the timeout and failure of any or all of these commands:\n\n\n\nsudo systemctl is-active systemd-journald\n\nsudo shutdown\n\nsudo reboot\n\nsudo -i exit\n\n\n\nThe system cannot be soft shutdown or rebooted, it has to be power cycled. I believe the init process memory itself is corrupted and thus anything that goes through the init process times out.\"\n\nThis week's round of power management fixes for the in-development Linux 6.17 kernel are on the more notable side with fixes for both AMD and Intel P-State drivers plus addressing a system hibernation issue that could lead to \"serious breakage\" and stems from a Linux 6.16 regression.Intel engineer and power management subsystem maintainer Rafael Wysocki kicked off this week's power management pull request by noting a fix for a \"nasty hibernation regression introduced during the 6.16 cycle.\" The fix elaborates on that nasty regression and ends up being a one-liner to resolve. Wysocki explained in that commit:The issue was brought to light a few days ago in a bug report In addition to fixing that hibernation regression, there are also a few fixes too for the Intel and AMD P-State CPU frequency scaling drivers:- Fix setting of CPPC.min_perf in the active mode with performance governor in the amd-pstate driver to restore its expected behavior changed recently (Gautham Shenoy)- Avoid mistakenly setting EPP to 0 in the amd-pstate driver after system resume as a result of recent code changes (Mario Limonciello)\"Those fixes in the pull request were merged on Thursday ahead of the Linux 6.17-rc6 release coming on Sunday.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.17-PM-Hibernation-FIxes",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "China’s souring on Nvidia. Here’s why",
      "content": "Beijing is souring on Nvidia.\n\nChina, which used to be one of Nvidia’s largest markets, seems largely conflicted about reaccepting Nvidia’s lower-tech H20 chips that Trump administration finally allowed to resume sales of in July. The Chinese tech industry might be excited about the Nvidia chip flow resuming, but the government is allegedly not.\n\nChinese authorities have discouraged local tech companies from purchasing Nvidia chips citing national security concerns, and even questioned industry titans like Tencent over their purchases of Nvidia chips, according to Reuters.\n\nIn response, tech giants like Alibaba and Baidu have begun using their own chips to train smaller AI models, the Information reported on Thursday, but they will reportedly continue to use some Nvidia chips.\n\n“The competition has undeniably arrived,” an Nvidia spokesperson told Gizmodo. “Customers will choose the best technology stack for running the world’s most popular commercial applications and open-source models. We’ll continue to work to earn the trust and support of mainstream developers everywhere.”\n\nChinese development is ramping up. China chip stocks have experienced a major boom so big that the Beijing-based company Cambricon had to warn investors recently. Tech giants like Huawei and Alibaba are leading the push, but smaller companies are also making strides.\n\nShanghai-based tech company MetaX told the Wall Street Journal last month that it’s preparing to start mass production of a new chip that has bigger memory than Nvidia’s H20.\n\nStill, largely no chip offering so far has been considered completely up to par with Nvidia’s best offerings. Reuters reported last week that top Chinese tech firms like Alibaba and ByteDance are still very keen to get their hands on Nvidia chips. That’s despite the fact that the Nvidia chips that are being sold to China are downgraded versions of existing models, developed to abide by U.S. exports restrictions.\n\nThe chips saga\n\nSome experts in Washington think any supply of American tech to China has sizable national security risks attached to it. They also claim the chips can assist China in outpacing American AI innovation.\n\nThe Biden administration was first to enforce export restrictions on Nvidia chips sold to China, in an effort to curb the entry of high-tech chips into China off of those fears.\n\nBeijing landed a particularly big blow to domestic AI confidence earlier this year with Deepseek’s R1, an AI model that rivaled the best of American companies offerings using lower cost chips, inadvertently showing Americans that Chinese innovation did not require the top Nvidia chips.\n\nThat fueled the blanket ban decision which turned out to be less effective than expected when a Financial Times report found that Nvidia’s highest tech chips were being smuggled into China in the absence of the lower tech H20s.\n\nThe decision was also a big hit to Nvidia: executives shared in a May earnings call that they had to revise revenue expectations down for the quarter by about $8 billion due to the restrictions.\n\nAfter an intense lobbying effort by Nvidia CEO Jensen Huang, Trump reversed his decision in July, allowing H20 chips sales to China. In exchange, Trump demanded that Nvidia, and fellow American chipmaker AMD, both give the U.S. government a 15% cut of all of their chips revenue in China.\n\nJust when Nvidia thought all was finally well, Beijing started raising concerns about the new Nvidia chips coming into China having kill switches and backdoors, urging Chinese companies to not use them. Nvidia has denied the claim.\n\nThe remaining political uncertainty has continued to cast a shadow on Nvidia’s performance in China. The company conceded in its latest earnings call that they were facing disappointing numbers from the region still and were yet to begin H20 shipments.\n\nWhy did Beijing change its mind?\n\nChina has a long relationship with Nvidia. The downturn in that relationship began after the first export restrictions went into effect, ramped up after an antitrust probe in December and has developed a life of its own under Trump’s trade war.\n\nChinese officials have voiced security concerns related to the latest round of chips set to enter the country, but this attitude change has less to do with Nvidia itself and more about China’s own chip industry.\n\nChinese AI industry is currently dependent on American chipmakers like Nvidia, and that gives Americans an edge. In the absence of Nvidia chips, China will have to develop their own high-tech chips that can rival and even surpass the quality of Nvidia chips. If that happens, the United States can be at jeopardy to lose its hold on the global chips demand, and China is the runner-up.\n\nThe country is making a big bet on AI, announcing an $8.2 billion AI-investment fund earlier this year, in an effort to spur innovation and reach independence.\n\n“It’s unfortunate to see that we in Asia, including China, are emulating the U.S. when it comes to developing algorithms and large models,” Wei Shaojun, an adviser to senior Chinese government officials and a professor at top Beijing university Tsinghua University told a forum in Singapore on Thursday. He warned that staying on this path of dependence could be “lethal” for the region, according to Bloomberg.\n\nAlong with the chips push, the country has increasingly emphasized global cooperation in AI, and center to that initiative is Beijing’s desire to cement itself at the center of the global AI trade.\n\nIt seems China is coming to terms with the fact that aspiration won’t be achievable as long as the industry is dependent on the U.S. for chips, especially when Washington has demonstrated that its trade policy decisions are volatile.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/chinas-souring-on-nvidia-heres-why-2000657632",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "ASUS Introduces the Most Powerful ProArt P16 Yet With New OLED Display and RTX 5090 GPU",
      "content": null,
      "source": "Fstoppers",
      "url": "https://fstoppers.com/gear/asus-introduces-most-powerful-proart-p16-yet-new-oled-display-and-rtx-5090-gpu-711392",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "AMD's RDNA4 GPU Architecture at Hot Chips 2025",
      "content": "RDNA4 is AMD’s latest graphics-focused architecture, and fills out their RX 9000 line of discrete GPUs. AMD noted that creating a good gaming GPU requires understanding both current workloads, as well as taking into account what workloads might look like five years in the future. Thus AMD has been trying to improve efficiency across rasterization, compute, and raytracing. Machine learning has gained importance including in games, so AMD’s new GPU architecture caters to ML workloads as well.\n\nFrom AMD’s perspective, RDNA4 represents a large efficiency leap in raytracing and machine learning, while also improving on the rasterization front. Improved compression helps keep the graphics architecture fed. Outside of the GPU’s core graphics acceleration responsibility, RDNA4 brings improved media and display capabilities to round out the package.\n\nMedia Engine\n\nThe Media Engine provides hardware accelerated video encode and decode for a wide range of codecs. High end RDNA4 parts like the RX 9070XT have two media engines. RDNA4’s media engines feature faster decoding speed, helping save power during video playback by racing to idle. For video encoding, AMD targeted better quality in H.264, H.265, and AV1, especially in low latency encoding.\n\nLow latency encoder modes are mostly beneficial for streaming, where delays caused by the media engine ultimately translate to a delayed stream. Reducing latency can make quality optimizations more challenging. Video codecs strive to encode differences between frames to economize storage. Buffering up more frames gives the encoder more opportunities to look for similar content across frames, and lets it allocate more bitrate budget for difficult sequences. But buffering up frames introduces latency. Another challenge is some popular streaming platforms mainly use H.264, an older codec that’s less efficient than AV1. Newer codecs are being tested, so the situation may start to change as the next few decades fly by. But for now, H.264 remains important due to its wide support.\n\nTesting with an old gameplay clip from Elder Scrolls Online shows a clear advantage for RDNA4’s media engine when testing with the latency-constrained VBR mode and encoder tuned for low latency encoding (-usage lowlatency -rc vbr_latency). Netflix’s VMAF video quality metric gives higher scores for RDNA4 throughout the bitrate range. Closer inspection generally agrees with the VMAF metric.\n\nRDNA4 does a better job preserving high contrast outlines. Differences are especially visible around text, which RDNA4 handles better than its predecessor while using a lower bitrate. Neither result looks great with such a close look, with blurred text on both examples and fine detail crushed in video encoding artifacts. But it’s worth remembering that the latency-constrained VBR mode uses a VBV buffer of up to three frames, while higher latency modes can use VBV buffer sizes covering multiple seconds of video. Encoding speed has improved slightly as well, jumping from ~190 to ~200 FPS from RDNA3.5 to RDNA4.\n\nDisplay Engine\n\nThe display engine fetches on-screen frame data from memory, composites it into a final image, and drives it to the display outputs. It’s a basic task that most people take for granted, but the display engine is also a good place to perform various image enhancements. A traditional example is using a lookup table to apply color correction. Enhancements at the display engine are invisible to user software, and are typically carried out in hardware with minimal power cost. On RDNA4, AMD added a “Radeon Image Sharpening” filter, letting the display engine sharpen the final image. Using dedicated hardware at the display engine instead of the GPU’s programmable shaders means that the sharpening filter won’t impact performance and can be carried out with better power efficiency. And, AMD doesn’t need to rely on game developers to implement the effect. Sharpening can even apply to the desktop, though I’m not sure why anyone would want that.\n\nPower consumption is another important optimization area for display engines. Traditionally that’s been more of a concern for mobile products, where maximizing battery life under low load is a top priority. But RDNA4 has taken aim at multi-monitor idle power with its newer display engine. AMD’s presentation stated that they took advantage of variable refresh rates on FreeSync displays. They didn’t go into more detail, but it’s easy to imagine what AMD might be doing. High resolution and high refresh rate displays translate to high pixel rates. That in turn drives higher memory bandwidth demands. Dynamically lowering refresh rates could let RDNA4’s memory subsystem enter a low power state while still meeting refresh deadlines.\n\nPower and GDDR6 data rates for various refresh rate combinations. AMD’s monitoring software (and others) read out extremely low memory clocks when the memory bus is able to idle, so those readings aren’t listed.\n\nI have a RX 9070 hooked up to a Viotek GN24CW 1080P display via HDMI, and a MSI MAG271QX 1440P capable of refresh rates up to 360 Hz. The latter is connected via DisplayPort. The RX 9070 manages to keep memory at idle clocks even at high refresh rate settings. Moving the mouse causes the card to ramp up memory clocks and consume more power, hinting that RDNA4 is lowering refresh rates when screen contents don’t change. Additionally, RDNA4 gets an intermediate GDDR6 power state that lets it handle the 1080P 60 Hz + 1440P 240 Hz combination without going to maximum memory clocks. On RDNA2, it’s more of an all or nothing situation. The older card is more prone to ramping up memory clocks to handle high pixel rates, and power consumption remains high even when screen contents don’t change.\n\nCompute Changes\n\nRDNA4’s Workgroup Processor retains the same high level layout as prior RDNA generations. However, it gets major improvements targeted towards raytracing, like improved raytracing units and wider BVH nodes, a dynamic register allocation mode, and a scheduler that no longer suffers false memory dependencies between waves. I covered those in previous articles. Besides those improvements, AMD’s presentation went over a couple other details worth discussing.\n\nScalar Floating Point Instructions\n\nAMD has a long history of using a scalar unit to offload operations that are constant across a wave. Scalar offload saves power by avoiding redundant computation, and frees up the vector unit to increase performance in compute-bound sequences. RDNA4’s scalar unit gains a few floating point instructions, expanding scalar offload opportunities. This capability debuted on RDNA3.5, but RDNA4 brings it to discrete GPUs.\n\nWhile not discussed in AMD’s presentation, scalar offload can bring additional performance benefits because scalar instructions sometimes have lower latency than their vector counterparts. Most basic vector instructions on RDNA4 have 5 cycle latency. FP32 adds and multiples on the scalar unit have 4 cycle latency. The biggest latency benefits still come from offloading integer operations though.\n\nSplit Barriers\n\nGPUs use barriers to synchronize threads and enforce memory ordering. For example, a s_barrier instruction on older AMD GPUs would cause a thread to wait until all of its peers in the workgroup also reached the s_barrier instruction. Barriers degrade performance because any thread that happened to reach the barrier faster would have to stall until its peers catch up.\n\nRDNA4 splits the barrier into separate “signal” and “wait” actions. Instead of s_barrier, RDNA4 has s_barrier_signal and s_barrier_wait. A thread can “signal” the barrier once it produces data that other threads might need. It can then do independent work, and only wait on the barrier once it needs to use data produced by other threads. The s_barrier_wait will then stall the thread until all other threads in the workgroup have signalled the barrier.\n\nMemory Subsystem\n\nThe largest RDNA4 variants have a 8 MB L2 cache, representing a substantial L2 capacity increase compared to prior RDNA generations. RDNA3 and RDNA2 maxed out at 6 MB and 4 MB L2 capacities, respectively. AMD found that difficult workloads like raytracing benefit from the larger L2. Raytracing involves pointer chasing during BVH traversal, and it’s not surprising that it’s more sensitive to accesses getting serviced from the slower Infinity Cache as opposed to L2. In the initial scene in 3DMark’s DXR feature test, run in Explorer Mode, RDNA4 dramatically cuts down the amount of data that has to be fetched from beyond L2.\n\nRDNA2 still does a good job of keeping data in L2 in absolute terms. But it’s worth noting that hitting Infinity Cache on both platforms adds more than 50 ns of extra latency over a L2 hit. That’s well north of 100 cycles because both RDNA2 and RDNA4 run above 2 GHz. While AMD’s graphics strategy has shifted towards making the faster caches bigger, it still contrasts with Nvidia’s strategy of putting way more eggs in the L2 basket. Blackwell’s L2 cache serves the functions of both AMD’s L2 and Infinity Cache, and has latency between those two cache levels. Nvidia also has a flexible L1/shared memory allocation scheme that can give them more low latency caching capacity in front of L2, depending on a workload’s requested local storage (shared memory) capacity.\n\nA mid-level L1 cache was a familiar fixture on prior RDNA generations. It’s conspicuously missing from RDNA4, as well as AMD’s presentation. One possibility is that L1 cache hitrate wasn’t high enough to justify the complexity of an extra cache level. Perhaps AMD felt its area and transistor budget was better allocated towards increasing L2 capacity. To support this theory, L1 hitrate on RDNA1 was often below 50%. At the same time, the RDNA series always enjoyed a high bandwidth and low latency L2. Putting more pressure on L2 in exchange for reducing L2 misses may have been an enticing tradeoff. Another possibility is that AMD ran into validation issues with the L1 cache and decided to skip it for this generation. There’s no way to verify either possibility of course, but I think the former reasons make more sense.\n\nBeyond tweaking the cache hierarchy, RDNA4 brings improvements to transparent compression. AMD emphasized that they’re using compression throughout the SoC, including at points like the display engine and media engine. Compressed data can be stored in caches, and decompressed before being written back to memory. Compression cuts down on data transfer, which reduces bandwidth requirements and improves power efficiency.\n\nTransparent compression is not a new feature. It has a long history of being one tool in the GPU toolbox for reducing memory bandwidth usage, and it would be difficult to find any modern GPU without compression features of some sort. Even compression in other blocks like the display engine have precedent. Intel’s display engines for example use Framebuffer Compression (FBC), which can write a compressed copy of frame data and keep fetching the compressed copy to reduce data transfer power usage as long as the data doesn’t change. Prior RDNA generations had compression features too, and AMD’sdocumentation summarizes some compression targets. While AMD didn’t talk about compression efficiency, I tried to take similar frame captures using RGP on both RDNA1 and RDNA4 to see if there’s a large difference in memory access per frame. It didn’t quite work out the way I expected, but I’ll put them here anyway and discuss why evaluating compression efficacy is challenging.\n\nThe first challenge is that both architectures satisfy most memory requests from L0 or L1. AMD slides on RDNA1 suggest the L0 and L1 only hold decompressed data, at least for delta color compression. Compression does apply to L2. For RDNA4, AMD’s slides indicate it applies to the Infinity Cache too. However, focusing on data transfer to and from the L2 wouldn’t work due the large cache hierarchy differences between those RDNA generations.\n\nDCC, or delta color compression, is not the only form of compression. But this slide shows one example of compression/decompression happening in front of L2\n\nAnother issue is, it’s easy to imagine a compression scheme that doesn’t change the number of cache requests involved. For example, data might be compressed to only take up part of a cacheline. A request only causes a subset of the cacheline to be read out, which a decompressor module expands to the full 128B. Older RDNA1 slides are ambiguous about this, indicating that DCC operates on 256B granularity (two cachelines) without providing further details.\n\nIn any case, compression may be a contributing factor in RDNA4 being able to achieve better performance while using a smaller Infinity Cache than prior generations, despite only having a 256-bit GDDR6 DRAM setup.\n\nSoC Features\n\nAMD went over RAS, or reliability, availability, and serviceability features in RDNA4. Modern chips use parity and ECC to detect errors and correct them, and evidently RDNA4 does the same. Unrecoverable errors are handled with driver intervention, by “re-initializing the relevant portion of the SoC, thus preventing the platform from shutting down”. There’s two ways to interpret that statement. One is that the GPU can be re-initialized to recover from hardware errors, obviously affecting any software relying on GPU acceleration. Another is that some parts of the GPU can be re-initialized while the GPU continues handling work. I think the former is more likely, though I can imagine the latter being possible in limited forms too. For example, an unrecoverable error reading from GDDR6 can hypothetically be fixed if that data is backed by a duplicate in system memory. The driver could transfer known-good data from the host to replace the corrupted copy. But errors with modified data would be difficult to recover from, because there might not be an up-to-date copy elsewhere in the system.\n\nOn the security front, microprocessors get private buses to “critical blocks” and protected register access mechanisms. Security here targets HDCP and other DRM features, which I don’t find particularly amusing. But terminology shown on the slide is interesting, because MP0 and MP1 are also covered in AMD’s CPU-side documentation. On the CPU side, MP0 (microprocessor 0) handles some Secure Encrypted Virtualization (SEV) features. It’s sometimes called the Platform Security Processor (PSP) too. MP1 on CPUs is called the System Management Unit (SMU), which covers power control functions. Curiously AMD’s slide labels MP1 and the SMU separately on RDNA4. MP0/MP1 could have completely different functions on GPUs of course. But the common terminology raises the possibility that there’s a lot of shared work between CPU and GPU SoC design. RAS is also a very traditional CPU feature, though GPUs have picked up RAS features over time as GPU compute picked up steam.\n\nInfinity Fabric\n\nOne of the most obvious examples of shared effort between the CPU and GPU sides is Infinity Fabric making its way to graphics designs. This started years ago with Vega, though back then using Infinity Fabric was more of an implementation detail. But years later, Infinity Fabric components provided an elegant way to implement a large last level cache, or multi-socket coherent systems with gigantic iGPUs (like MI300A).\n\nSlide from Hot Chips 29, covering Infinity Fabric used in AMD’s older Vega GPU\n\nThe Infinity Fabric memory-side subsystem on RDNA4 consists of 16 CS (Coherent Station) blocks, each paired with a Unified Memory Controller (UMC). Coherent Stations receive requests coming off the graphics L2 and other clients. They ensure coherent memory access by either getting data from a UMC, or by sending a probe if another block has a more up-to-date copy of the requested cacheline. The CS is a logical place to implement a memory side cache, and each CS instance has 4 MB of cache in RDNA4.\n\nTo save power, Infinity Fabric supports DVFS (dynamic voltage and frequency scaling) to save power, and clocks between 1.5 and 2.5 GHz. Infinity Fabric bandwidth is 1024 bytes per clock, which suggests the Infinity Cache can provide 2.5 TB/s of theoretical bandwidth. That roughly lines up with results from Nemes’s Vulkan-based GPU cache and memory bandwidth microbenchmark.\n\nAMD also went over their ability to disable various SoC components to harvest dies and create different SKUs. Shader Engines, WGPs, and memory controller channels can be disabled. AMD and other manufacturers have used similar harvesting capabilities in the past. I’m not sure what’s new here. Likely, AMD wants to re-emphasize their harvesting options.\n\nFinally, AMD mentioned that they chose a monolithic design for RDNA4 because it made sense for a graphics engine of its size. They looked at performance goals, package assembly and turnaround time, and cost. After evaluating those factors, they decided a monolithic design was the right option. It’s not a surprise. After all, AMD used monolithic designs for lower end RDNA3 products with smaller graphics engines, and only used chiplets for the largest SKUs. Rather, it’s a reminder that there’s no one size fits all solution. Whether a monolithic or chiplet-based design makes more sense depends heavily on design goals.\n\nFinal Words\n\nRDNA4 brings a lot of exciting improvements to the table, while breaking away from any attempt to tackle the top end performance segment. Rather than going for maximum performance, RDNA4 looks optimized to improve efficiency over prior generations. The RX 9070 offers similar performance to the RX 7900XT in rasterization workloads despite having a lower power budget, less memory bandwidth, and a smaller last level cache. Techspot also shows the RX 9070 leading with raytracing workloads, which aligns with AMD's goal of enhancing raytracing performance.\n\nSlide from RDNA4’s Launch Presentation not Hot Chips 2025\n\nAMD achieves this efficiency using compression, better raytracing structures, and a larger L2 cache. As a result, RDNA4 can pack its performance into a relatively small 356.5 mm² die and use a modest 256-bit GDDR6 memory setup. Display and media engine improvements are welcome too. Multi-monitor idle power feels like a neglected area for discrete GPUs, even though I know many people use multiple monitors for productivity. Lowering idle power in those setups is much appreciated. On the media engine side, AMD’s video encoding capabilities have often lagged behind the competition. RDNA4’s progress at least prevents AMD from falling as far behind as they have before.\n\nIf you like the content then consider heading over to the Patreon or PayPal if you want to toss a few bucks to Chips and Cheese. Also consider joining the Discord.",
      "source": "Chipsandcheese.com",
      "url": "https://chipsandcheese.com/p/amds-rdna4-gpu-architecture-at-hot",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "5 reasons you need to be more careful with RAM on Ryzen",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/ryzen-memory-compatibility-stinks-but-so-does-arrow-lake/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Linux's New \"Sheaves\" Per-CPU Caching Layer Showing Massive Wins For AMD Performance",
      "content": "\"I ported this patch series on top of v6.17 and ran some benchmarks: will-it-scale, hackbench, redis, unixbench and kernbench. I ran the benchmarks on Intel Granite Rapids (480 cores), AMD Turin (512 cores) and ARM (80 cores)\n\n\n\nSummary of the results:\n\n\n\n- Significant change (meaning >10% difference between base and experiment) on will-it-scale tests in AMD.\n\n- No significant change on other benchmarks ran.\"\n\nEarlier this week I wrote about Sheaves as an opt-in, per-CPU array-based caching layer likely coming for Linux 6.18. The sheaves patches have been queued into the \"slab/for-next\" Git branch ahead of the Linux 6.18 kernel merge window. Patches posted now by Google are showing the Linux Sheaves code having a massive beneficial impact for large AMD systems.Google engineer Sudarsan Mahendran posted some benchmarks of the SLUB per-CPU Sheaves patches on Friday. The patches were applied to a Linux 6.17 base and tested across AMD, Intel, and ARM servers. For the AMD EPYC Turin server the Sheaves work ended up being a massive win for performance on a number of benchmarks but also some regressions.Sudarsan Mahendran commented on the mailing list:Going over his benchmarks on that LKML thread were exciting when seeing \"+28.58%\" mean improvements to get started, but also some 13~20% regressions... But when getting to the higher process counts for these scalability benchmarks was when it was getting really wild with +70.59%, +126.89%, +112.89%, and other massive wins. See all of the Google engineer's data in this thread It will be exciting to see how the Sheaves patches play out in more real-world workloads. Once these patches hit the mainline kernel presumably for Linux 6.18, I'll be firing up a number of benchmarks on my own hardware and thankfully have a lot of AMD EPYC Turin hardware and more for some exciting benchmarks ahead.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-Sheaves-AMD-Performance",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Another vendor launches an AMD Radeon RX7600M XT external GPU - and this one even comes with Thunderbolt 5",
      "content": "OneXGPU Lite RX 7600M XT offers 2,048 stream processors with 8GB GDDR6\n\nInfinity Cache is limited to 32 MB, restricting bandwidth efficiency gains\n\nDelivers 120 W power draw and up to 65 W power output for connected external devices\n\nExternal GPUs are often marketed as a way to extend the capabilities of thin laptops, and the OneXGPU Lite follows that trend.\n\nThis new device, which weighs 500g and can clip into a handbag, is built around the AMD Radeon RX 7600M XT, a mobile RDNA3 chip with 2,048 stream processors, 8GB of GDDR6 memory, and 32MB of Infinity Cache.\n\nIt is rated for 120W power draw and can provide up to 65W to connected devices, although it still relies on a separate 240W power brick.\n\nHardware and connection standards\n\nThe graphics dock supports HDMI 2.1 and DisplayPort 2.0, with advertised output up to 4K at 120Hz.\n\nFor connectivity, the product description repeatedly mentions “USB 5.0” and “USB-C 5.0,” even though such standards do not exist.\n\nIt is more likely the device supports USB4 v2 or Thunderbolt 5, both of which deliver 80Gbps in each direction but cap PCIe bandwidth at 64Gbps.\n\nThe company itself uses the Thunderbolt 5 label, although proper certification details have not been shared.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nGiven this uncertainty, the practical value of such a device depends on how well it translates into real-world use.\n\nA laptop that once struggled with layered editing projects could, in theory, become serviceable as a photo editing PC.\n\nLikewise, high-resolution rendering timelines in software packages may run more smoothly, making the same system workable as a video editing PC.\n\nThe catch, as always, is that bandwidth limits and thermal constraints reduce efficiency compared with a desktop solution.\n\nThe OneXGPU Lite is priced at 3,899 RMB, around $535, with shipping expected from September 25.\n\nThat cost is comparable to standalone midrange cards, although those cards would typically be installed in full desktops with access to the best GPU performance in the segment.\n\nHere, the buyer is paying for portability and compatibility rather than raw speed, but the package also includes a proprietary USB 5.0 cable, listed at a $27 value.\n\nVia Videocardz",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/another-vendor-launches-an-amd-radeon-rx7600m-xt-external-gpu-and-this-one-even-comes-with-thunderbolt-5",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "HSBC: Wall Street Underestimating Advanced Micro Devices Inc. (AMD)’s AI GPU Business",
      "content": "Advanced Micro Devices, Inc. (NASDAQ:AMD) is one of the best tech stocks to buy for the long term. On September 9, HSBC reiterated a ‘Buy’ rating on the stock but cut its price target to $185 from $200. The price target cut comes amid concerns about the average selling price of the company’s M1355 chip.\n\nHSBC: Wall Street Underestimating Advanced Micro Devices Inc. (AMD)'s AI GPU Business\n\nPosonskyi Andrey/Shutterstock.com\n\nAccording to HSBC, the price target cut was necessitated by the fact that the average selling price of AMD’s M1355 chip would be $23,000, down from the previous $25,000 per unit. The lower average selling price has prompted HSBC to lower its 2026 AI GPU revenue from $15.1 billion to $13.9 billion.\n\nDespite the reduced AI GPU revenue estimate due to a lower average selling price, it is still 20% above consensus estimates. Likewise, HSBC insists Wall Street is underestimating AMD’s AI GPU business despite the slight price revision.\n\nAdditionally, HSBC anticipates that AMD will benefit from major cloud service providers, including Meta, Microsoft, and Oracle, as they begin testing its M1400 rack solution. The push is expected to diversify the company’s revenue base.\n\nAdvanced Micro Devices Inc. (NASDAQ:AMD) is a semiconductor company that designs and develops high-performance computing and visualization products, including CPUs, GPUs, and adaptive computing solutions. Its technologies are used in PCs, gaming, data centers, and embedded systems to advance markets such as artificial intelligence (AI), cloud computing, and others.\n\nWhile we acknowledge the potential of AMD as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 12 Best Consumer Goods Stocks Billionaires Are Quietly Buying and Goldman Sachs Penny Stocks: Top 12 Stock Picks.\n\nDisclosure: None. This article is originally published at Insider Monkey.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/hsbc-wall-street-underestimating-advanced-135320942.html",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "GIGABYTE B650 AORUS Elite AX Motherboard $169.99 + Free Shipping",
      "content": "Deal History includes data from multiple reputable stores, such as Best Buy, Target, and Walmart. The lowest price among stores for a given day is selected as the \"Sale Price\".\n\n\n\nSale Price does not include sale prices at Amazon unless a deal was posted by a community member.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18603382-gigabyte-b650-aorus-elite-ax-motherboard-169-99-free-shipping",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "HP OmniBook 7 Laptop Computer 13.3\" WQXGA AMD Ryzen AI 7 32 GB memory;2 TB SSD $862.39 EPP EDU",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired N3RD_01 posted Item 1 of 2 Item 1 of 2 expired N3RD_01 posted HP OmniBook 7 Laptop Computer 13.3\" WQXGA AMD Ryzen AI 7 32 GB memory;2 TB SSD $862.39 EPP EDU $862 $1,300 33% off HP Small & Medium Business 11 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 5,982 Views Visit Retailer Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details\n\nProcessor: AMD Ryzen™ AI 7 350 (up to 5.0 GHz max boost clock, 16 MB L3 cache, 8 cores, 16 threads)\n\nStorage: 2 TB PCIe® Gen4 NVMe™ TLC M.2 SSD\n\nMemory: 32 GB LPDDR5x-7500 MT/s (onboard)\n\nGraphics: Integrated: AMD Radeon™ 860M Graphics\n\nDisplay: 13.3\" diagonal, WQXGA (2560 x 1600), IPS, micro-edge, anti-glare, 400 nits, 100% sRGB\n\n\n\nHP EPP/ EDU accounts $862.39\n\n\n\nhttps://www.hp.com/us-en/shop/pdp...t3f0ua-aba HP OmniBook 7 Laptop Computer 13.3\" WQXGA AMD Ryzen AI 7 32 GB memory;2 TB SSDProcessor: AMD Ryzen™ AI 7 350 (up to 5.0 GHz max boost clock, 16 MB L3 cache, 8 cores, 16 threads)Storage: 2 TB PCIe® Gen4 NVMe™ TLC M.2 SSDMemory: 32 GB LPDDR5x-7500 MT/s (onboard)Graphics: Integrated: AMD Radeon™ 860M GraphicsDisplay: 13.3\" diagonal, WQXGA (2560 x 1600), IPS, micro-edge, anti-glare, 400 nits, 100% sRGBHP EPP/ EDU accounts Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster N3RD_01 Follow Give Rep Message 753 Deal Posts 1,191 Comments Posts 974 Reputation Points 918 Votes Submitted Deal Details Community Notes About the Poster\n\nProcessor: AMD Ryzen™ AI 7 350 (up to 5.0 GHz max boost clock, 16 MB L3 cache, 8 cores, 16 threads)\n\nStorage: 2 TB PCIe® Gen4 NVMe™ TLC M.2 SSD\n\nMemory: 32 GB LPDDR5x-7500 MT/s (onboard)\n\nGraphics: Integrated: AMD Radeon™ 860M Graphics\n\nDisplay: 13.3\" diagonal, WQXGA (2560 x 1600), IPS, micro-edge, anti-glare, 400 nits, 100% sRGB\n\n\n\nHP EPP/ EDU accounts $862.39\n\n\n\nhttps://www.hp.com/us-en/shop/pdp...t3f0ua-aba HP OmniBook 7 Laptop Computer 13.3\" WQXGA AMD Ryzen AI 7 32 GB memory;2 TB SSDProcessor: AMD Ryzen™ AI 7 350 (up to 5.0 GHz max boost clock, 16 MB L3 cache, 8 cores, 16 threads)Storage: 2 TB PCIe® Gen4 NVMe™ TLC M.2 SSDMemory: 32 GB LPDDR5x-7500 MT/s (onboard)Graphics: Integrated: AMD Radeon™ 860M GraphicsDisplay: 13.3\" diagonal, WQXGA (2560 x 1600), IPS, micro-edge, anti-glare, 400 nits, 100% sRGBHP EPP/ EDU accounts",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18602317-hp-omnibook-7-laptop-computer-13-3-wqxga-amd-ryzen-ai-7-32-gb-memory-2-tb-ssd-862-39-epp-edu",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "AI-driven search engine running inside a laundry room aims to rival Google, and you can try it yourself — programmer harnesses old server parts and AI to deliver quality results",
      "content": "A programmer wants to take on Google Search, starting with two PCs that sit in his laundry room. Ryan Pearce, who worked in both enterprise software and game development roles, was curious about what it takes to build a search engine. According to Fast Company, Pearce built two search engines: Searcha Page and its incognito variant, Seek Ninja. These two engines both have a database with over 2 billion entries. Although it’s less than half a percent of Google’s 400-billion-strong search index, it’s still a considerable number, and he expects to double it in the next six months or so.\n\nThis self-hosted search engine sits in Pearce’s home — but instead of going with a low-powered Raspberry Pi or a mini-PC that most people use when self-hosting, he opted for a used 32-core AMD EPYC 7532, which was one of the best workstation CPUs when it launched in 2020. After all, if you want to create a massive search engine, you’d need something punchier than an entry-level CPU. Nevertheless, since that processor is already five years old at the time of writing, you can now easily get a used copy for less than $200. “I could have gotten another chip for the same price, which would have had twice as many threads, but it would have produced too much heat,” the programmer told Fast Company.\n\nIt’s for this reason that the two servers sit inside his laundry room. Pearce initially had them installed in his bedroom, but the heat generated by the system prevented him from sleeping comfortably. So, he moved them to his utility room, with one device sitting on a ledge, and the other supporting unit propped on a couple of small stools. The two devices are plugged into an extension cord, and the network cable that connects them to the internet is routed through a hole he drilled into the wall. There was also a makeshift vent that allowed the heat generated by the machines to escape from his home. “The heat hasn’t been absolutely terrible,” Pearce said to the publication. “But if the door is closed for too long, it is a problem.”\n\nThe secret to how one programmer can run a massive search engine is AI — but it’s not the kind of AI that most people would think of. Pearce does not employ front-facing AI tools that summarize search results and do the thinking for you. Instead, he uses machine learning algorithms to expand the keywords used in the query and help understand the user's context. This enables search engines to deliver relevant results with a fraction of the resources that Google has.\n\nPearce said that he’s building his search engine piece by piece, and that he’s already written around 150,000 lines of code. However, he says that he’s done so much more than that, and that he has iterated over 500,000 lines of code. Most of these changes were made to reduce the code’s reliance on large language models and make it work without relying on AI. This technique enabled him to create a complex system and then lock in modules that work by removing the variable of AI.\n\nRyan said that he’s considering moving the search engine out of his home and into a data center-like facility. However, since he dislikes cloud services, it will likely be at a location near his house, where he can easily access the servers and work on them on-site as necessary. But, in the meantime, Pearce said that he’s doing affiliate-style advertising to help him achieve that goal.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/software/search-engines/ai-driven-search-engine-running-inside-a-laundry-room-aims-to-rival-google-and-you-can-try-it-yourself-programmer-harnesses-old-server-parts-and-ai-to-deliver-quality-results",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Podcast #836 – Intel & AMD CPU News, NVIDIA GPU Marketshare, Sapphire B850, SK hynix and Samsung SSD Reviews, Ubisoft kills games + MORE!",
      "content": "After a week off – Join us as we battle illness to bring you the pithy, erudite commentary you crave. That you deserve even. Start with software designed cores, mix in some Nvidia domination, season with the largest DDoS attack EVaR, then Ubisoft kills games and finish with fast SSDs. What an evening you are in for.\n\nOh, and we’re taking next week off too. So much stacked up vacation we need to use by EOY!\n\nWe must thank our Patreon members, because without you … we would be gone. New folks and current ones that are bumping their patronage are greatly appreciated.\n\nThis show cannot go on without you – you know who you are, please consider helping our efforts. It most definitely helps keep us on the air. And helps Josh buy burgers. Thank you!",
      "source": "PC Perspective",
      "url": "https://pcper.com/2025/09/podcast-836/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Supermicro (SMCI): Evaluating Valuation Following Launch of Blackwell Ultra AI Data Center Solutions",
      "content": "Super Micro Computer (SMCI) has just started shipping its highly anticipated NVIDIA Blackwell Ultra solutions worldwide, a move that is capturing plenty of investor attention. These new systems represent more than incremental upgrades. They promise to deliver rapid deployment and enhanced performance for some of the most demanding AI data center projects. With pre-validated racks, plug-and-play installation, and cutting-edge cooling innovations, Super Micro is making a bold play to lead the next wave of AI infrastructure.\n\nThis launch arrives at a pivotal moment for Super Micro. After a stretch of volatility, the stock jumped 4% on the news of these volume shipments, signaling a renewed sense of optimism in the company’s growth story. Over the past year, SMCI shares have wavered with a small year-over-year dip, but momentum has started building again in 2025, helped along by AI-driven product expansions and major partnerships. While there has been a near 50% year-to-date gain, recent months have seen some pullback, reminding investors that expectations remain high but not assured.\n\nAfter a big announcement and a sharp move, the big question remains. Is Super Micro ready for another leg up, or is the market already factoring in all that future growth?\n\nMost Popular Narrative: 39.6% Undervalued\n\nAccording to the most popular narrative, Super Micro Computer is considered significantly undervalued. The argument hinges on robust projected growth and strong positioning in the AI infrastructure market.\n\nPartnerships with NVDA, AMD, xAI and Intel position them as one of the most attractive providers of GPU data center infrastructure. They are also profiting from growth in other related industries such as Cloud, 5G and Storage. Using the SWS Fair Value tool and management guidance of $23bn for 2025 and $40bn for 2026, I decided to use a revenue growth rate of 50% to reach an estimated revenue of $50bn for 2028, which I consider conservative.\n\nCurious about what drives this bold undervaluation call? The key lies in aggressive growth assumptions and a premium multiple historically reserved for industry giants. Want to see how these strategic forecasts transform into a game-changing price target and why this narrative is gaining traction? The most intriguing projections are just one click away.\n\nResult: Fair Value of $74.53 (UNDERVALUED)\n\nHave a read of the narrative in full and understand what's behind the forecasts.\n\nHowever, risks remain, including potential regulatory hurdles and execution missteps. Either of these factors could challenge even the most optimistic projections for Super Micro.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/supermicro-smci-evaluating-valuation-following-125543430.html",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Sony PlayStation 6 Leak: Here’s What We Know About The Specs",
      "content": "Reputed hardware leaker ‘Moore’s Law Is Dead’ just dropped another bombshell, and this time the claims about Sony’s next-generation console are so outrageous they almost sound like wishful thinking from a PlayStation fanboy’s fever dream. The latest leak suggests the PS6 could pack hardware that rivals Nvidia’s upcoming RTX 5090, which would be absolutely bonkers for a console launching around 2027. But before we get carried away, let’s dig into what’s actually being claimed and whether any of this makes sense.\n\nThe headline grabber here is the claim that Sony’s next console could pack an AMD “Orion” APU with up to 10 Zen 6 cores and a GPU sporting 52-54 compute units of RDNA 5 architecture. We’re talking about 34-40 teraflops of raw computing power, with ray tracing performance supposedly matching Nvidia’s upcoming RTX 5090. For context, that’s a graphics card that’ll likely cost more than an entire console when it launches.\n\nNow, before you start planning your 2027 gaming setup, let’s pump the brakes a bit. Console manufacturers are masters of creative accounting when it comes to performance claims, and these numbers feel aggressively optimistic. Sure, AMD will have advanced their architecture significantly by the time the PS6 launches, likely in late 2027, but matching flagship PC hardware while maintaining console pricing is a tall order.\n\nWhat feels more realistic is the continued evolution of Sony’s custom silicon approach. The PS5 already showed us how specialized chips like the Tempest audio processor can punch above their weight. Adding dedicated AI acceleration for upscaling and background tasks makes perfect sense, especially as technologies like FSR and DLSS become gaming staples.\n\nThe more mundane rumors actually carry more weight. Multiple sources suggest the PS6 will stick with the detachable disc drive model introduced with the PS5 Slim, acknowledging that physical media isn’t dead but isn’t exactly thriving either. There’s also chatter about a companion handheld device, which would be Sony’s second attempt at portable gaming after the Vita’s mixed reception.\n\nPricing speculation suggests Sony might be targeting aggressive numbers to compete with Microsoft’s next Xbox, which some leakers claim could cost significantly more. If true, that competitive pressure could force both companies to eat larger losses on hardware to win market share.\n\nThe reality check here is simple: we’re still years away from any official announcement, and development priorities can shift dramatically. These leaks paint a picture of Sony aiming for a generational leap that goes beyond typical console upgrades, but the gap between engineering ambition and manufacturing reality often tells a different story. Still, if even half of these claims pan out, PlayStation fans have plenty to get excited about.",
      "source": "Yanko Design",
      "url": "https://www.yankodesign.com/2025/09/14/sony-playstation-6-leak-heres-what-we-know-about-the-specs/",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "NVIDIA and OpenAI CEOs accompanying President Trump's UK state visit — major AI projects on the agenda",
      "content": "U.S. President Donald Trump is about to do something none of his predecessors have — make a second full state visit to the UK. Ordinarily, a President in a second term of office visits, meets with the monarch, but doesn't get a second full state visit.\n\nOn this one it seems he'll be accompanied by two of the biggest faces in the ever-growing AI race; OpenAI CEO, Sam Altman, and NVIDIA CEO, Jensen Huang.\n\nThis is according to a report by the Financial Times, which claims that the two are accompanying President Trump to announce a \"large artificial intelligence infrastructure deal.\"\n\nThe deal is said to support a number of data center projects in the UK, another deal towards developing \"sovereign\" AI for another of the United States' allies.\n\nThe report claims that the two CEOs will announce the deal during the Trump state visit, and will see OpenAI supply the technology, and NVIDIA the hardware. The UK will supply all the energy required, which is handy for the two companies involved.\n\nUK energy is some of the most expensive in the world (one reason I'm trying to use my gaming PC with an RTX 5090 a lot less!)\n\nThe exact makeup of the deal is still unknown, and, naturally, neither the U.S. nor UK governments have said anything at this point.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAI has helped push NVIDIA to the lofty height of being the world's most valuable company. (Image credit: Getty Images | Kevin Dietsch)\n\nThe UK government, like many others, has openly announced its plans to invest in AI. As the next frontier for tech, you either get on board or you get left behind. And President Trump has made no secret of his desires to ensure the U.S. is a world leader.\n\nOpenAI isn't the only company that could provide the software side, but it is the most established. While Microsoft may be looking towards a future where it is less reliant on the tech behind ChatGPT for its own AI ambitions, it makes total sense that organizations around the world would be looking to OpenAI.\n\nNVIDIA, meanwhile, continues to be the runaway leader on the hardware front. We've seen recently that AMD is planning to keep pushing forward, and a recent Chinese model has reportedly been built to run specifically without NVIDIA GPUs.\n\nBut for now, everything runs best on NVIDIA, and as long as it can keep churning out enough GPUs to fill these data centers, it will continue to print money.\n\nThe state visit is scheduled to begin on Wednesday, September 17, so I'll be keeping a close eye out for when this AI deal gets announced.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/artificial-intelligence/nvidia-and-openai-ceos-accompanying-president-trumps-uk-state-visit-major-ai-projects-on-the-agenda",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Linux 6.17-rc6 Released With VMSCAPE Mitigation, FLYDIGI APEX 5 Support & Fixes",
      "content": "The newest weekly test release of Linux 6.17 is now available as we work toward the stable kernel release around the end of September.Linux 6.17-rc6 was just released by Linus Torvalds. Pulled into Linux 6.17-rc6 is a fix to address some \"serious breakage\" around system hibernation support as a regression introduced in Linux 6.16. Fixes to both the Intel and AMD P-State drivers also landed this week as part of the Linux 6.16-rc7 material.Some new material for Linux 6.17-rc6 since it just amounts to new device/vendor IDs is FLYDIGI APEX 5 gaming controller support for those expensive game controller options.This week also saw the public announcement of VMSCAPE as a new CPU security vulnerability issue affecting both AMD and Intel processors . VMSCAPE mitigation support was merged to Linux Git upon embargo lift and also since back-ported to the stable Linux kernel series. Linux 6.17-rc6 has the mitigation if you aren't a daily Git rider.\n\n\"Things remain pretty calm, and for some reason this release seems to just not have a ton of problems. Hopefully I'm not jinxing it.\n\n\n\nIt might just have been people being on vacation in August (read: Europe) which has caused this release to be nice and calm, but whatever the reason I'm certainly not complaining.\n\n\n\nSomewhat unusually, almost a third of the patch is from filesystem fixes, but that seems to be pure coincidence: not because there are any particularly large fixes, but because we just happened to independently have fixes in several different filesystems (ceph, smb client, nfs, erofs, btrfs). So just random timing.\n\n\n\nAnother third is driver fixes (gpu being half of it, the rest being other random drivers), and the final third is just \"misc other stuff\": core networking, another CPU speculation mitigation, somedocumentation fixes, some selftest updates, and minor noise elsewhere.\n\n\n\nBut really, none of it is very large. So everything seems slated for a normal release in two weeks.\"\n\nLinus Torvalds wrote with the 6.17-rc6 announcement There are a lot of great features and improvements in Linux 6.17 with this stable kernel version hopefully coming out two weeks from today on 28 September.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.17-rc6-Released",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Select Qualcomm X Elite Laptops Seeing IRIS Video Acceleration On Linux",
      "content": "Adding to the list of feature caveats around the different Qualcomm Snapdragon X Elite laptops and the varying Linux state is video acceleration support. But patches were posted this week by a Linaro engineer enabling hardware accelerated video playback for two X Elite laptop models.Linaro engineer Stephan Gerhold posted the patches enabling IRIS video acceleration decoding for the X1 Elite Compute Reference Design (CRD) and the Lenovo ThinkPad T14s. The CRD support isn't too useful for consumers themselves. The Lenovo ThinkPad T14s continues to benefit as one of the best supported X Elite laptops under Linux with even having firmware files upstream in linux-firmware.git.The patches posted on Thursday add the IRIS video acceleration code for the DeviceTree used on the Qualcomm reference board as well as the Lenovo ThinkPad T14s. Besides the DT support, there is also an IRIS firmware requirement.These new patches for those having either X1E platform can find them on the LKML . In time hopefully the other popular X Elite laptop models will also see this support in place.It was back in Linux 6.15 earlier this year that the Qualcomm IRIS video decode driver was upstreamed . In initial form a V4L2 video driver with H.264 decode.\n\nIn case you missed it for more details on the recent X Elite Linux experience, see the recent tests in Qualcomm Snapdragon X Elite Linux Performance Improving But Short Of AMD Ryzen & Intel Core Ultra",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Qualcomm-X-Elite-IRIS-Video",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "HSBC Trims AMD Target Amid Revised Pricing Assumptions",
      "content": "Advanced Micro Devices, Inc. (NASDAQ:AMD) is one of the AI Stocks on Wall Street’s Radar. On September 9, HSBC analyst Frank Lee lowered the price target on the stock to $185.00 (from $200.00) while maintaining a Buy rating.\n\nThe lower price target comes after the firm revised its assumptions regarding AMD’s MI355 chip average selling price (ASP). The firm now estimates the price to be $23,000 rather than $25,000 per unit, calling it a more “prudent assumption given differential pricing for different customers.”\n\nThe firm’s revenue estimates are still above consensus estimates, it noted, stating that it continues to believe that the street is underestimating the pricing potential.\n\n“In our 10 July upgrade note Back in the AI game with a bang, we had highlighted that the pricing power of the MI355 might surprise the market and drive the upside potential in 2026e. The management also acknowledged a significant pricing uplift from MI325 in its latest earnings call. We slightly revise down our ASP estimates from USD25k to USD23k as we believe that it is a more prudent assumption given differential pricing for different customers.\"\n\n\"Driven by our revised ASP assumptions, we lower our 2026e AI GPU revenue estimates from USD15.1bn to USD13.9bn, still 20% above consensus estimates as we continue to believe that the street is still underestimating the pricing potential. Additionally, we expect most CSPs including Meta, Microsoft, Oracle, and xAI are starting to enter the testing phase with the MI400 rack solution, with results potentially by 4Q25 or early 1Q26. Hence, we expect to see better order visibility emerging by 1Q26 regarding MI400 revenue potential.”\n\nAdvanced Micro Devices, Inc. (NASDAQ:AMD) develops and sells semiconductors, processors, and GPUs for data centers, gaming, AI, and embedded applications.\n\nWhile we acknowledge the potential of AMD as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 10 AI Stocks In The Spotlight For Investors and 10 AI Stocks on Wall Street’s Radar.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/hsbc-trims-amd-target-amid-000337435.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Enthusiast builds entire PC setup with Lego-style bricks — Includes desktop terminal-style OLED monitor & keyboard, with an iPhone 6-powered desk clock",
      "content": "We all start somewhere in our PC building journey, but seldom does an opportunity present itself to make our first system as unique as u/OkDebate6649. That's exactly what happened with the aforementioned Reddit user who built his computer literally brick-by-brick using Lego. Known as \"Choi,\" our resident enthusiast took Lego-style bricks and made not only a full PC case, but also a monitor featuring an OLED panel, along with a mechanical keyboard — desktop terminal style.\n\nOne of the best parts is that this was Choi's first-ever custom PC, as he's only used pre-builts before this. You might think that he's some sort of Lego master builder, but he has no prior experience in that department either. In fact, the only reason he even got his hands on Lego in the first place was to hit the minimum requirement for a discount while shopping online. Once he got the bricks, though, he quickly figured this would make for a fun experiment and got to work.\n\nChoi worked on the case, the monitor and the keyboard separately. Speaking to PC Gamer, he described how everything was constructed with modularity in mind. The monitor, which uses a 1080p OLED panel from AliExpress, is enclosed inside a custom body fully built from Lego. That frame can then attach to a similar keyboard housing and form a desktop terminal, akin to the Apple II. Not only that, but the case itself can be connected below the monitor.\n\nImage credit: u/OkDebate6649 on Reddit Image credit: u/OkDebate6649 on Reddit\n\nChoi has posted his escapades across different subreddits; we embedded the most detailed post above where he showcases the build from the inside. As you can see, there's no dedicated GPU in there — the PC is powered by a Ryzen 5 5600G because Choi is sacrilegiously a PlayStation gamer and only needs this PC for office work. That 5600G is paired with equally-modest hardware like 16GB of memory, a basic ITX motherboard, and an AMD stock cooler. The build has two 120mm fans mounted externally for air intake.\n\nImage credit: u/OkDebate6649 on Reddit Image credit: u/OkDebate6649 on Reddit Image credit: u/OkDebate6649 on Reddit\n\nNow, what if the transforming desktop terminal and the PC case were to get together and have a baby? Thankfully, our curious tinkerer has thought ahead and already made a \"retro Commodore-style monitor case.\" Details on this project are scarce, but Choi has used a 4:3 monitor and put it inside a custom Lego housing that can also fit an entire PC in there. There's a USB hub up front, too, for quick access. Unlike the 5600G build, though, this one has space for a dedicated GPU, but Choi is only using it as a secondary monitor for now.\n\nThe DIY madness doesn't stop here, either. Clearly, Choi loved the Lego theme and ran with it even further, building projects like a desk clock powered by an iPhone 6, an audio deck made to look like an old radio, and also a Lego mouse that we spotted in the pictures, which Choi never mentioned in the text. Everything is neatly placed in the corner of a room, encapsulating the perfect Lego setup. Sure, there's no high-end hardware powering this stuff, but the ingenuity behind this is far beyond anything extra money alone could buy.\n\nImage 1 of 3 (Image credit: u/OkDebate6649 on Reddit) (Image credit: u/OkDebate6649 on Reddit) (Image credit: u/OkDebate6649 on Reddit)\n\nChoi had no prior experience with custom PCs or Lego, yet he somehow ended up combining the best of both worlds to create something truly unique. It's a testament to the creative child that lives within all of us, and how easily that spark can surface when we let go of preconceived notions about what’s “too difficult.\" What starts as a fun diversion can turn into something special very quickly. If you're interested in DIY creations like this, make sure to check out these Joycon-style Steam Deck controllers, or the time someone made their entire PC out of cardboard.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/desktops/pc-building/enthusiast-builds-entire-pc-setup-with-lego-style-bricks-includes-desktop-terminal-style-oled-monitor-and-keyboard-with-an-iphone-6-powered-desk-clock",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Dave & Buster's (PLAY) Q2 Earnings: What To Expect",
      "content": "Arcade company Dave & Buster’s (NASDAQ:PLAY) will be announcing earnings results this Monday afternoon. Here’s what you need to know.\n\nDave & Buster's met analysts’ revenue expectations last quarter, reporting revenues of $567.7 million, down 3.5% year on year. It was a slower quarter for the company, with a significant miss of analysts’ EPS estimates and a slight miss of analysts’ same-store sales estimates.\n\nIs Dave & Buster's a buy or sell going into earnings? Read our full analysis here, it’s free.\n\nThis quarter, analysts are expecting Dave & Buster’s revenue to grow 1% year on year to $562.7 million, slowing from the 2.8% increase it recorded in the same quarter last year. Adjusted earnings are expected to come in at $0.92 per share.\n\nDave & Buster's Total Revenue\n\nHeading into earnings, analysts covering the company have grown increasingly bearish with revenue estimates seeing 3 downward revisions over the last 30 days (we track 9 analysts).\n\nLooking at Dave & Buster’s peers in the leisure facilities segment, some have already reported their Q2 results, giving us a hint as to what we can expect. AMC Entertainment delivered year-on-year revenue growth of 35.6%, beating analysts’ expectations by 3.1%, and Live Nation reported revenues up 16.3%, topping estimates by 3.4%. AMC Entertainment traded up 4.6% following the results while Live Nation was also up 3%.\n\nRead our full analysis of AMC Entertainment’s results here and Live Nation’s results here.\n\nThere has been positive sentiment among investors in the leisure facilities segment, with share prices up 7.6% on average over the last month. Dave & Buster's is down 7.4% during the same time and is heading into earnings with an average analyst price target of $32.71 (compared to the current share price of $23.70).\n\nUnless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.\n\nStockStory is growing and hiring equity analyst and marketing roles. Are you a 0 to 1 builder passionate about the markets and AI? See the open roles here.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/dave-busters-play-q2-earnings-030056656.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "【ゲーム】『ドラクエ7』リメイク発表！　おれ6がダントツで好きなんだけど異端扱いされるんだよな",
      "content": "異端といえば9じゃない？\n\n批判されてるのは転職システムと特技みたいなゲーム的な部分\n\n大丈夫俺もドラクエの中だけじゃなく全てのゲームの中でドラクエ６が一番好きだから\n\n丁寧につくってさすがドラクエとは思ったけどそれだけやな、\n\n1 名前：muffin ★[] 投稿日：2025/09/13(土) 02:35:45.85 ID:kBTir7eb9.net9/12(金) 22:36任天堂は12日、ゲームの新情報を発表する番組『Nintendo Direct』（ニンテンドーダイレクト）をYouTubeなどで配信した。Nintendo Switch、Switch2ソフトとなる『ドラゴンクエスト7』のリメイク『ドラゴンクエストVII Reimagined』が発表され、来年2月5日に発売される。『ドラクエ7』は、2000年8月26日にプレイステーションで発売され、その斬新な世界観や圧倒的なボリュームのストーリーが話題となった『ドラゴンクエストVII エデンの戦士たち』が原作。ニンテンドー3DSでも、その後発売された人気タイトルになっている。物語のはじまりは、世界にたったひとつしかない島「エスタード島」から。この島で暮らす主人公とその友達・キーファの日課となっていた島での探検がきっかけとなり、冒険の舞台は誰も見たことがない“新たな世界”へと一気に広がっていく。たどり着いた異世界では、エスタード島にはいなかった存在、モンスターの姿が。さらに、冒険で行きつく先ではさまざまな人物やダンジョン、そして強敵たちが主人公たちを待ち受けている。リメイク版『ドラゴンクエストVII Reimagined』は、グラフィックだけではなく、シナリオ、バトル、寄り道要素、システム面、すべて一から再構築。バトルの要となるのが職業システムも、各職業に固有の「職業とくせい」があり、バトル中にバーストチャージという状態になると、「職業とくせい」を発動させることができる。冒険をすすめると職業の「かけもち」が解放され、同時にふたつの職業につけるように。呪文や特技、職業とくせいもふたつ分に増えるので、パーティの戦力も大幅にアップしていく。動画ドラゴンクエストVII Reimagined [Nintendo Direct 2025.9.12]https://www.youtube.com/watch?v=NV70S9CI91chttps://newsatcl-pctr.c.yimg.jp/t/amd-img/20250912-00052276-famitsu-000-2-view.jpghttps://newsatcl-pctr.c.yimg.jp/t/amd-img/20250912-00000034-impgmw-000-2-view.jpg他記事「石板探しは楽になっていますよ」堀井雄二氏がリメイク『ドラクエ7』について語る。人形を3Dスキャンして制作、シナリオを再編し新エピソード追加もhttps://www.famitsu.com/article/202509/52327https://cimg.kgl-systems.io/camion/files/52327/thumbnail_ACsb.jpg98 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 03:53:43.65 ID:qu1H82kB0.netおれ6がダントツで好きなんだけど異端扱いされるんだよな1番面白いしキャラもストーリーもいいと思うけど101 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 03:59:16.10 ID:auwNNk1N0.net>>98俺も面白いと思ったけど、何故かまたやりたいみたいな気持ちにならなかった3とか4はまたやりたくなる何かがあった103 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 04:00:38.67 ID:jrFVYJsf0.net [3/3]>>98108 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 04:03:55.29 ID:IeNa05wo0.net [3/5]>>98特技が強すぎてイオナズンの出番がなかった記憶109 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 04:05:49.71 ID:NJX0vcyu0.net [5/7]>>98キャラもストーリーもいいけど142 名前：名無しさん＠恐縮です[sage] 投稿日：2025/09/13(土) 04:49:45.28 ID:LGMzNh9n0.net [1/3]>>98250 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 06:03:47.80 ID:0IbAWgx/0.net [3/3]>>98333 名前：名無しさん＠恐縮です[sage] 投稿日：2025/09/13(土) 06:54:36.23 ID:jorSawUN0.net [2/11]>>98９と10以外はみんな面白さがあるからランキングする必要もないちょっとしたゲームバランスの差でしかない",
      "source": "Livedoor.biz",
      "url": "https://honwaka2ch.livedoor.biz/archives/10926150.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Has Nvidia Lost Sight of the Core Consumer?",
      "content": "As seen in the above, datacenters made up a significantly smaller portion of NVDA's revenue prior to 2021 and the focus was on their core consumer grade gaming segment. However, with the popularization of generative AI tools like DALL-E and Chat-GPT by OpenAI in 2021 which sparked a race among the top tech companies to invest in and create the best generative models as a result we saw a more than 3x surge in AI investment market-wide between 2019 and 2021 which has since come to a plateau following a huge spike in 2021, after many of these companies including Microsoft and Google announced that they would be slowing down on their AI related spending and/or exploring in-house solutions to save on CapEx.\n\nBut today, It's all about AI and enterprise contracts. The headlines out of their most recent CES keynote weren't about consumer-grade GPUs or gaming, they were about new datacenter products and AI reasoning models with names like Nemotron and Llama in focus rather than the standard consumer power focused terms like CUDA and RTX. The everyday consumer will have minimal to no practical use for these AI reasoning models displayed by NVDA yet this was the focus of the showcase and really put things into perspective for me that NVDA seems to be abandoning its core consumer base in favor of satisfying its newly found AI enterprise markets. It was not so long ago that gaming was NVDA's top revenue source as detailed here in their 2021 Annual 10k filing;\n\nIn the past, NVIDIA events were all about Productivity, Games, GPUs, and Raw graphics horsepower aimed at consumer interests like pushing frames per second higher, powering better visuals, improving encoding performance, power efficiency, and exciting the consumer base by which Nvidia's $4 trillion foundation was built upon.\n\nVery little attention was given to the Next-gen consumer focused RTX-50 series graphics cards during the showcase. I found this to be disappointing because this was at an annual event meant to showcase Consumer Electronics, yet Nvidia consumers essentially took a backseat to all of these more Enterprise focused AI products/concepts.\n\nAt the start of 2025, there was a lot of optimistic chatter about what Nvidia's stock might do during this year's Central Electronics Showcase. Thinking back to this timeline it almost seemed as if every headline, every social media post, and the majority of online commentary surrounding Nvidia's CES press conference focused on Nvidia forwarding their growth in AI markets ranging from: AI PCs built for developers to more efficiently run LLMs, AI powered Robotics platforms, and their partnerships with various players within the Autonomous Automobile industry such as Toyota and Tesla.\n\nStory Continues\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Quid & Stanford University: 2025 AI Index\n\nThis AI investment surge has been congruent with the recent trend in NVDA's datacenter segment overtaking their gaming segment by an exponentially wide margin as seen a more recent 10k filing:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nIt is worth noting however that the corporate investments into AI only began to plateau in 2021-present, during this time we saw the top companies in the industry collectively aim to reduce their AI CapEx spend was also in alignment with the start of a sharp continuous decline in US Consumer Sentiment as released by the University of Michigan:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nFurthermore, this decline in consumer sentiment has not only been observed in the US but China as well as China Consumer Sentiment has nose-dived to and even further extent during the same period;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Organization for Economic Co-operation and Development via FRED\n\nThis sudden decline in the consumer sentiment has led to the pulling of investment capital not just in AI as detailed earlier, but also in adjacent industries like EVs;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: IEA\n\nI have referenced the chart above in a previous article, which delves into my concerns revolving around a recent slowdown in TSLA Cash Flows. If TSLA keeps going on the path that it currently is, their Non-adjusted Free Cash Flows will once again turn negative. Given that TSLA is one of NVDA's top B2B customers, I see this as a worrying trend as this has all aligned with the drop in consumer sentiment starting in 2021.\n\nEven as big tech investment into AI pulls back and the consumer sentiment declines, we can still see an exponential growth in the amount of newly funded Generative AI companies popping up on the frontend.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Quid & Stanford University: 2025 AI Index\n\nThese newfound startups could find themselves entering into what was a booming industry, now entering a cooldown period, if that's the case these companies will be unlikely to find success in chasing the Gen-AI trend now as the CapEx liquidity once provided to this industry by big tech players dries up.\n\nConcerningly, when evaluating NVDA's 2025 annual 10k filing it can be seen that 34% of this newfound revenue came from only three of their direct enterprise customers;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nThough Nvidia did not name their customers directly, it can be inferred through Omida Research's Q32023 report of H100 Shipments that NVDA's top customers were Microsoft, Meta, Google, and Amazon with notable business from TSLA, Oracle, Tiktok, and CoreWeave.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nGiven that many of these customers are the same companies that have begun to cut back on external AI CapEx spending, likely in alignment with the fall of the consumer, it is very likely that NVDA sees an exceptionally greater direct hit in not only their profit margins but also their total revenue as these companies seek internal solutions and competition from potentially more balanced companies such as Intel enters the fray.\n\nThe goal of many of these companies are to balance capex spend with their revenues and right now they are focusing on creating the best product for their core consumer base to fall back on, as these companies reduce spending, develop in-house solutions, or find better and most likely cheaper competitors to NVDA, we will see more and more of NVDA's overly focused B2B model dwindle. In times like these it would be great for NVDA to not only have a functioning B2B base but to also maintain its base consumer as a foundation to fall back on in hard times just some of NVDA's most successful corporate customers do, but in the effort to chase a growing AI trend NVDA has lost sight of that foundation and is leaving itself open to a massive pull of liquidity. The time may soon be coming when a company such as NVDA would want to have a strong consumer base to fall back on because as of now when reading into NVDA's QoQ Net Margins, a peak can already be observed, rounding down since the start of 2024 with a declines being experienced the in Q2, 2025.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MicroTrends.net\n\nThe last time we experienced any such decline in margins like this was at the start of 2022 which proceeded a 62% drop from $28.95 a share to $10.81 near the 89-month EMA all within the same year. If things were to go similarly this time around we could experience a similar 60-70% decline to around $50 per share aligning with the 89-month EMA in white.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: TradingView\n\nNVDA currently trades at a 57x multiple with a $3.15 EPS, I'd suspect that NVDA has the capacity to correct down to around a 15-20x multiple If it experienced a severe repricing due to its AI endeavors being priced out by the market and there's even the risk of EPS going down due to falling margins. If EPS drops significantly to $1.15, setting it back a year a 20x multiple of that would align with NVDA trading down to $23 a share in the coming months.\n\nIntel: Back to the consumer\n\nIntel, is taking the opposite approach of Nvidia.\n\nAt CES 2025, Intel rolled out its Core Ultra 200 series processors. These cover everything from thin-and-light laptops to high-performance desktops. Unlike Nvidia's corporate-heavy pitch, Intel's message was simple: more power, less energy, and prices that make sense for consumers.\n\nThe Core Ultra 200HX and H series aims to bring serious improvements to creators and gamers, better multi-thread performance, integrated Arc graphics, and even built-in NPUs for AI acceleration. The 200U series targets mainstream laptops, while the 200S series brings efficient yet power a high 16-20+ core count 125-watt chips to desktops.\n\nIntel is also targeting the mobile and notebook space directly, going up against Qualcomm and ARM and unlike Nvidia, Intel manufacture the majority of its chips in the United States. This puts them ad a great advantage when it comes to managing the ongoing tariffs and is likely to Nvidia heavy reliance on TSMC for production and Samsung for memory chips, which puts Nvidia in the crosshairs of these tariffs in which U.S based and sourced companies such as Intel and Micron could greatly benefit.\n\nAs NVDA has shifted its focus away from the consumer INTC has been aggressive in building its product lineup in the favor of the consumer and it really shows when looking at the chart of the historic video card market share:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: PassMark\n\nThe data here shows that NVDA's consumer video card market share dropped from 61.8% in 2022, to 54.2% in 2025, AMD remained stagnant, and during the same period, Intel's share rose from 16.1% to 21%.\n\nObserving the chart, it would appear that NVDA's market share is on a downwards trajectory with more declines likely as competition, mainly the now pro-consumer focused Intel continues to gain ground within NVDA's lost, yet core industry as Intel's product lineup right now puts the core consumer base first and remains easily accessible. Unlike NVDA, INTC is not talking about abstract AI models with gimmicky names that sound like they were ripped out of some sci-fi film; they're instead talking about battery life, power efficiency, security features, and real improvements that everyday people will notice when they buy their next laptop or desktop.\n\nA familiar trap?\n\nIn many ways, this is reminiscent to when Microsoft fumbled with the new generations of Xbox with the Kinect. Microsoft had a winning product in the Xbox 360 but got distracted by the gimmicks introduced with the Kinect, focusing on getting rid of the traditional controller in favor of motion controls, becoming an all in one media hub, and enforcing always online requirements for Xbox One with Kinect; a practice none of the consumers ever approved of yet Microsoft pushed it for years. It seems likely that Microsoft's obsession with motion controls came from their desire to chase after the success of the Nintendo Wii, which released in 2006, introduced motion controls to the masses, and ended up being the best-selling seventh generation console of that generation by far.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nBut by the time the eighth generation rolled in, the novelty of motion controls had long played it course and that was made very apparent with the fall in the Nintendo Wii's yearly sales as well as to complete failure of the Wii U.\n\nDuring the start of the eighth generation in 2013, we would see Sony, with its PS4 release, focus on games and gamer alike, showcasing pro-consumer features such as game sharing along with the ability to play games without the need of an internet connection; all backed by a strong lineup of game releases to boot. Sony did all of this and even took direct jabs at Microsoft, their competition, who was not then concerned with these pro-consumer moves at the time. Despite these open jabs from Sony, Microsoft would carry on with its anti-consumer practices in favor of the Kinect as it continued to push the all-in-one media hub features which was likely an attempt to compete with the then trending streaming markets, as well as pushing the motion controls which was a dying fad. As a result, a new trend would emerge of yearly PS4 sales consistently being double that of Xbox One sales;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nOne year later the CEO of Microsoft would appoint Phil Spencer as the new head of Xbox who then would undo the anti-consumer practices set in motion by the previous head, Don Mattrick, starting with the unbundling of the kinect and a more consumer friendly approach to gamer by offering backwards compatibility, and reverting back to the brand's roots; Unfortunately it was too late as the previous leadership had already sullied the brand's relationship with its core customer base and many of those that might have considered coming back to Xbox were already comfortably on PlayStation and later on, thanks to a much improved marketing campaign, Nintendo Switch; the result of Xbox's previous years of not focusing on the core consumer and even antagonizing the consumer at times made it very tough to take back market share against Nintendo and Sony, which remained, focused on their core gaming audience throughout.\n\nEven all these years later in the ninth generation of consoles, as Microsoft has spent the last 13 years reversing course on all of these anti-consumer practices, they remain significantly behind Nintendo and Sony generations later as the consumer base has already settled within their perspective ecosystems and winning them back has proven to be very hard for Microsoft to do with PS5 sales now being triple that of Xbox Series X/S.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nNvidia risks falling into the same trap: chasing enterprise AI hype while forgetting about the consumer market that made it a household name in the first place and in time of economic slowdown Nvidia will need to lean back on this core base but by the time they do another competitor would have likely scooped up a significant portion of this core base and just like Microsoft with the Xbox, it could take years before Nvidia can rebuild all of that lost consumer trust.\n\nValuation Overview:\n\nWhen taking in account NVDA's slowdown in profit margins mainly attributed to the slowdown in enterprise revenue paired with their loss in market share to INTC within the consumer base, it makes sense to consider INTC as the alternative investment to NVDA. Despite INTC's recent shaky history of EPS misses, it is worth considering the fact that the stock price trades at a very low price to sales multiple of 1.98x:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nThis low price to sales value contrasts with NVDA's which currently trades at a 25.95x multiple to its sales;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nThis in my opinion is a massive oversight in the market that shows speculative growth being priced into NVDA while ignoring the current actual contraction NVDA is currently facing, as a result, the comparison of these ratios tells us that sales growth is failing to keep up with the high speculative valuations of the current market.\n\nMeanwhile the market has severely undervalued INTC, not taking into consideration the fact that it is currently gaining a significant core market share against NVDA and AMD alike in a trend that seems likely to continue.\n\nLooking into other valuation data we can also see that INTC trades at a 1.01x book value which ultimately confirms that despite INTC's recent growth, the stock market still hasn't priced in any growth at all within the company which means that the stock is currently at its fairest value right now.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nMeanwhile when looking at NVDA's price to book we can see that in spite of recent contractions, the market is still valuing NVDA's stock at a 42.33x multiple to its book value.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nTaking in the totality of the data it would be in my opinion a valuable opportunity to capitalize on the arbitrage between NVDA and INTC's valuation and performance by investing long term into INTC rather it be shares or Long Call LEAPS (1 year or more of theta), while reducing share allocation or even buying some longer dated 300+ DTE OTM puts in NVDA or at least hedging current long positions in NVDA more aggressively with covered calls. As this arbitrage closes, I would anticipate NVDA's market cap valuation to contract while INTC's expands, narrowing the current spread between NVDA's $4.4T and INTC's $100B market cap valuations.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-lost-sight-core-consumer-185126232.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "GIGABYTE X870 Eagle WIFI7 AMD AM5 LGA 1718 Motherboard $199.99 + Free Shipping (1 replies)",
      "content": "Deal History includes data from multiple reputable stores, such as Best Buy, Target, and Walmart. The lowest price among stores for a given day is selected as the \"Sale Price\".\n\n\n\nSale Price does not include sale prices at Amazon unless a deal was posted by a community member.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18603412-gigabyte-x870-eagle-wifi7-amd-am5-lga-1718-motherboard-199-99-free-shipping",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "SoundHound AI (SOUN) Stock Trades Up, Here Is Why",
      "content": "What Happened?\n\nShares of voice AI technology company SoundHound AI (NASDAQ:SOUN) jumped 2.1% in the afternoon session after it received continued positive commentary from Wall Street analysts.\n\nThe move follows several bullish actions, including DA Davidson analyst Gil Luria maintaining a \"Strong Buy\" rating and increasing the price target from $15 to $17 on September 10. Additionally, Wedbush's Daniel Ives reiterated a \"Buy\" rating on September 11. This optimistic analyst sentiment is supported by the company's strong performance, with a recent report noting that SoundHound AI's revenue tripled in the second quarter compared to the previous year. The company's voice AI platform has now surpassed 1 billion queries per month, positioning it to capitalize on the growing use of AI in devices, cars, and homes.\n\nAfter the initial pop the shares cooled down to $14.37, up 1.8% from previous close.\n\nIs now the time to buy SoundHound AI? Access our full analysis report here, it’s free.\n\nWhat Is The Market Telling Us\n\nSoundHound AI’s shares are extremely volatile and have had 92 moves greater than 5% over the last year. In that context, today’s move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.\n\nThe previous big move we wrote about was 5 days ago when the stock dropped 4.9% on the news that markets pulled back, reversing early gains, as investor sentiment remained cautious despite a softer-than-expected inflation reading.\n\nStocks rose in the morning session after an unexpected drop in the Producer Price Index (PPI) for August signaled easing inflation and raised expectations for a potential Federal Reserve interest rate cut. The U.S. Bureau of Labor Statistics reported that the PPI, which measures wholesale prices, edged down 0.1% last month, contrary to analyst expectations for a 0.3% rise. This data gives the Federal Reserve more flexibility to consider lowering interest rates to stimulate the economy.\n\nSoundHound AI is down 28.7% since the beginning of the year, and at $14.37 per share, it is trading 40.7% below its 52-week high of $24.23 from December 2024. Investors who bought $1,000 worth of SoundHound AI’s shares at the IPO in April 2022 would now be looking at an investment worth $1,915.\n\nUnless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/soundhound-ai-soun-stock-trades-183609103.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "\"Some need to learn how their PCs work\" — Borderlands 4 head fires back as optimal settings for 68 GPUs released",
      "content": "Borderlands 4, the latest looter-shooter in the beloved series from Gearbox Software, launched on September 11, 2025. Less than a week later, it's sitting at a \"Mixed\" review score on Steam with more than 16,500 entries. The prevailing issue forcing the review score down? Dreadful PC optimization.\n\nThe game's developer has now released a couple of lengthy PC optimization guides for both NVIDIA and AMD GPUs (via Videocardz). There are 68 different GPUs listed, with optimal settings for 1080p, 1440p, and 4K resolutions. NVIDIA's cards range from the RTX 2070 to the mighty RTX 5090, while AMD's cards range from the RX 5700 XT to the RX 9070 XT.\n\nUnless you're using an RTX 3060 Ti or newer, you can expect about 30 FPS at 1080p. For 1440p, you'll want at least an RTX 3070 Ti to run the game at 30 FPS. Want to play at 4K? You'll want at least an RTX 3090 Ti to hit 60 FPS.\n\nBorderlands 4's poor PC performance doesn't sit well with gamers\n\nA look at recommended NVIDIA GPU settings for playing Borderlands 4 at 1440p. (Image credit: 2K Games)\n\nMy current GPU, NVIDIA's RTX 5070 Ti, is listed under the 4K section. In order to achieve 60+ FPS, I'll need DLSS 4's Multi Frame Generation cranked up to 4x with texture quality set to Medium (and many other settings dropped to Low).\n\nIf I want to hit 60+ FPS at 1440p, I'll still need DLSS MFG 4x, though textures and other quality can be cranked up a bit. I think perhaps I'll wait a bit longer before trying the game to see if any more performance updates are released.\n\nDespite knowing months ahead of launch that Borderlands 4's PC specs were very demanding — more than 50% of Steam users may need an upgrade to play the game, at least judging by Steam's frequent hardware surveys — players are trashing the game for its brutal performance.\n\nPoor optimization and PC performance were topics of our Borderlands 4 review.\n\nDespite playing the game on an NVIDIA RTX 3080 and AMD Ryzen 9 5900X — older hardware that should nevertheless be relevant today — our reviewer experienced some brutal performance woes that mostly continued after a patch.\n\nTerrible, terrible performance. Worst I've ever seen. Turned it down to Low graphics preset and couldn't hit 60 FPS, even with FSR upscaling on my RX 6900 XT. Steam user \"Etiko\"\n\nRandy Pitchford, CEO of Gearbox Software, hasn't been shy about stating his case for Borderlands 4's performance. The game, which runs on the controversial Unreal Engine 5, is demanding, and Pitchford says gamers need to come to terms with lowering the resolution or in-game settings to achieve stability.\n\n\"Borderlands 4 is a premium game made for premium gamers,\" said Pitchford in an X reply to a gamer struggling to play on older hardware.\n\nThe minimum and recommended specs are published. The most common hardware is a four year old cell phone. Borderlands 4 is a premium game made for premium gamers. Just as Borderlands 4 cannot run on a PlayStation 4, it cannot be expected to run on too-old PC hardware. Unlike on…September 13, 2025\n\nConsidering NVIDIA's RTX 3060 and RTX 4060 GPUs continue to hold the top spots on Steam's GPU survey list, many players are struggling to come to terms with how a AAA game can launch at a $70 price tag and run so poorly.\n\nOn the other side of the hardware fence, console players have bemoaned the lack of an FOV slider and a motion blur toggle. Considering that both of these common settings can directly contribute to motion sickness, it's not a good look for Gearbox.\n\nIf you are indeed one of Borderlands 4's launch adopters, I recommend giving the recommended GPU specs laid out by Gearbox a shot. At this point, any extra frames are appreciated.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/gaming/pc-gaming/borderlands-4-official-amd-nvidia-gpu-settings",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "AMD Continues Enhancing AMDGPU/AMDKFD Drivers For Checkpoint/Restore",
      "content": "CRIU is for Checkpoint/Restore in Userspace to be able to freeze a running container or app, preserve its state to disk, and later restore said running workload. A few years ago we saw AMD working on being able to checkpoint/restore running ROCm workloads . As seemingly the first work in a while on the matter by the AMDGPU/AMDKFD kernel drivers, there are some new CRIU elements coming for Linux 6.18.Last week's AMDGPU pull request of additional material for Linux 6.18 adds CRIU support for GEM memory management objects. CRIU support for GEM objects is also added to the AMDKFD compute kernel driver.As part of the CRIU support for GEM objects to AMDGPU and AMDKFD drivers, there is a new user-space API for handling it. Over in user-space is this pending CRIU pull request for DMA-BUF IPC support on AMDGPU.\n\nIn addition to this new AMD CRIU activity, this pull request brings UVD and DPM fixes for aging Southern Islands graphics cards. That work for the aging AMD Southern Islands GPUs is important as part of enhancing the GCN 1.0 and GCN 1.1 support on the AMDGPU driver as an alternative to the default Radeon DRM driver.Plus this pull request has more updates for Cyan Skillfish, continued user-queue \"UserQ\" work, exposing the vBIOS build number to user-space via sysfs, eDP updates, and various other fixes.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/AMDGPU-CRIU-Linux-6.18",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "The best \"Steam Deck killer\" launched months ago, but you still can't buy this Windows 11 handheld — are tariffs to blame for another fumbled competitor?",
      "content": "A new trend in PC gaming was popularized by Valve's excellent Steam Deck, a handheld option that brought console-style convenience to the masses who wanted to play titles locked to the platform, whether that's via Steam or any other storefront. I have my own, and it remains a huge part of my almost-daily gaming routine, but its Linux-based presentation is starting to be overshadowed by Windows-based alternatives.\n\nFirst, the ASUS ROG Ally showed promising signs of supporting Microsoft's operating system in a package that could challenge Valve's leading handheld. It was even one-upped internally by its bigger brother, the highly praised ROG Ally X. However, the original, with its AMD Ryzen Z1 Extreme processor, stuck with me for months as a viable Steam Deck alternative. That is, at least, until I got my hands on the MSI Claw 8 AI+ and fell in love with it.\n\nMSI dared to pass on AMD's offerings as it already enjoyed total domination, its earlier chips appearing in the Steam Deck, and Ryzen Z1 variants appearing in Lenovo's 'Nintendo Switch-esque' Legion Go. Instead, the Claw would use Intel's mobile chips, starting with codenamed Meteor Lake processors in the previous generation Claw 7 A1M and refreshed with Lunar Lake versions in the Claw 8 AI+. It all sounds fantastic, but there's a glaring issue — you'll hardly ever find the thing in stock.\n\nRunning fast and cool, the MSI Claw 8 AI+ proved that Intel Arc graphics are more than capable, if expensive. (Image credit: Rebecca Spear / Windows Central)\n\nIt's an axe I'll grind down to the handle, because it'll always frustrate me. The high-scoring MSI Claw 8 AI+ should have seen a few price-reducing deals by now, bringing it to a more realistic cost that resembles the post-$100 savings that ASUS has previously bestowed upon the ROG Ally X — but that's not the case — in fact, it's much worse than that.\n\nEvery week, I'll check on the MSI Claw 8 AI+ at Best Buy to see that its $999.99 price tag hasn't budged. Not only that, but the availability tracker sticks with an unmoving \"Sold Out\" message despite a handful of user reviews that suggest people have been lucky enough to bag one from this prominent retailer in the past, and they seem similarly happy with it.\n\nMSI Claw 8 AI+ $999 at Amazon Check Walmart It's the best Windows-based PC gaming handheld I've ever tested, but the Claw 8 AI+ is so consistently out of stock that it's almost impossible to recommend.\n\nThen again, if you pay over the odds, Walmart might hook you up for a Claw 8 AI+ at $1,249, but it's via a third-party seller, not the store itself. It's the same story at Amazon US; either it's stocked with an inflated price by a third-party seller, or it's completely invisible. Even a $999.99 listing at the official MSI US digital store can offer to notify you of restocks, but it can't sell you a Claw 8 AI+ today. At this point, it's a struggle to recommend it.\n\nNow, sometimes you might see something in stock alongside the elusive Claw 8 AI+, and it might seem like my complaints are unnecessary when you see it. However, the \"MSI Claw 8 AI+ A2VM Polar Tempest Edition\" (yes, it's a mouthful) is little more than a white recolor with a higher price tag. It was supposed to launch with a 2TB variant for more game storage, but at least for now, it's just a $25 price hike to replace the unique \"Sandstorm\" shade of the original.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe Polar Tempest Edition should have offered a 2TB SSD, but I've yet to see one in stock. (Image credit: MSI)\n\nPrice and availability problems keep coming back to the topic of tariffs, which has probably been the hottest topic in tech throughout 2025. We already saw the MSI Claw 8 AI+ and the Claw 7 AI+ increasing their price by $100 back in April this year, and neither has dropped back to their previous MSRP listings since. Raising the price is one thing, but if it isn't paired with any solutions for issues surrounding supply and demand, then what's the point? Even if the Claw returned to its previous price, there's no guarantee that any stock would follow.\n\nRaising the price is one thing, but if it isn't paired with any solutions for issues surrounding supply and demand, then what's the point?\n\nIt's mostly frustrating because I see a lot of generic, boilerplate responses from brands when inquiring about sudden component changes or reductions in their hardware categories, never wanting to point the blame directly at import/export tariffs. That, and I have to temper my expectations for modern-day gamers who are constantly mocked by gaming hardware that bloats its prices far above any intended MSRP, particularly with GPUs. The MSI Claw 8 AI+ is not a budget handheld gaming PC by any stretch of the imagination.\n\nThe MSI Claw 8 AI+ still deserves its 'best' award, even if you might never find one. (Image credit: Windows Central | Rebecca Spear)\n\nOn the other hand, the Claw 8 AI+ is the best Windows handheld I've ever used. It ran everything; I couldn't find anything in my Steam library (or GOG, Epic Games Store, etc) that it wouldn't shred. That, and it did it all without raising the fan noise, an ode to Intel's success with Lunar Lake's much-professed efficiency bump for its mobile processors.\n\nSure, it had its downsides, mostly related to software gripes and other issues that could be fixed with patches, but none of them detracted from my gaming enjoyment.\n\nI could spend all day praising MSI and Intel's partnership, but again, if you can't buy the thing, then who cares? I wanted to see Lunar Lake devices thrive, and some may have, but it still feels like the Claw 8 AI+ redeemed all of its predecessors' missteps for ultimately no reason. These days, I'm more eagerly awaiting the AMD-based ROG Xbox Ally X and its (presumably) similarly premium price point — which is fine, but it's still a shame to see a competitor fall off.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/handheld-gaming-pc/the-best-steam-deck-killer-launched-months-ago-but-you-still-cant-buy-it",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "\"NVIDIA violated the anti-monopoly law\" — China's ongoing investigation digs up antitrust violations as trade tensions mount",
      "content": "NVIDIA, the US company supplying most of the world with GPUs built specifically for powering AI, finds itself once again at odds with Chinese authorities.\n\nFollowing a preliminary investigation into the matter, Chinese antimonopoly regulators claim that NVIDIA broke antitrust laws (via Business Insider) in connection with the acquisition of Israeli chip design company Mellanox.\n\nNVIDIA announced it had reached a $6.9 billion deal with Mellanox in March 2019. China, shortly after the announcement, stated it had conditionally approved the deal.\n\nHowever, the antitrust investigation was initiated in December 2024 by China's State Administration for Market Regulation (SAMR). The investigation remains ongoing, say SAMR officials in the press release.\n\n[...] the State Administration for Market Regulation decided to conduct further investigation in accordance with the law.\n\nThe SAMR dropped the antitrust news at the same time that Chinese and US officials are attempting to negotiate trade intricacies in Madrid. Trade tensions have been on the rise for most of 2024 and 2025, with both sides making some bold claims regarding AI GPUs and how they're being used.\n\nA brief history of US, China, and NVIDIA trade tensions\n\nTwo cargo ships, one with a Chinese flag and the other with an American flag. (Image credit: Getty Images | Yaorusheng)\n\nA lot of recent trade tension between the US and China has NVIDIA sitting in the center. The GPU company's H20 AI chip, created specifically for the Chinese market as a less-powerful alternative to US AI chips, is highly sought after by China's AI firms.\n\nHowever, the NVIDIA chip was fully banned from being sold to China in April 2025 by the Trump administration. The cause of the ban centered on concerns that China was using the H20 chips to bolster its military and to develop further domestic AI models that could challenge US firms.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe ban was walked back in July, when NVIDIA CEO Jensen Huang reached a deal with President Trump following a White House visit. Huang's argument? It's better to have all AI models running on US technology.\n\nIt didn't take long for Huang to announce that NVIDIA was ordering 300,000 more H20 AI chips from TSMC in order to meet Chinese demand. And that was on top of the 600,000 to 700,000 H20 chips already stockpiled and awaiting buyers.\n\nAs a final part of the deal with the US government, NVIDIA and AMD agreed to pay a 15% chip tax for the export licenses needed to sell to China. The unprecedented deal remains informally approved. While Chinese AI firms clambered to place orders for the unbanned H20 AI GPUs, state officials began pressuring the firms to avoid the US hardware over fears of tracking devices, spyware, and other hidden back doors.\n\nNVIDIA responded by firmly stating that it wasn't placing any sort of trackers or malware in its AI GPUs.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/nvidia/nvidia-violated-anti-monopoly-laws-chinese-officials",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Open source Cloud Hypervisor adds (maybe futile) no-AI-code policy",
      "content": "The Cloud Hypervisor project has introduced a No AI code policy.\n\nCloud Hypervisor started life in 2018 as a joint effort between Google, Intel, Amazon, and Red Hat – all of which wanted to share their work on virtualization components to speed their respective efforts to create virtual machine monitors and hypervisors. The participants decided that work was best undertaken using Rust and the rust-vmm project is the result.\n\nIntel took the project in a slightly different direction and led to the creation of Cloud Hypervisor, a Virtual Machine Monitor for cloud workloads. The Linux Foundation took on the project in 2021, when Alibaba, ARM, ByteDance, and Microsoft were also part of the project, alongside Intel.\n\nAMD, Ampere, Germany’s Cyberus Technology and China’s Tencent Cloud have since become supporters, and the project now describes itself as “an open source Virtual Machine Monitor that runs on top of the KVM hypervisor and the Microsoft Hypervisor.” It’s mostly used by public clouds as the hypervisor in their IaaS services, and is customized to work with the hardware they buy in bulk.\n\nThe project delivered version 48 last week, complete with the new policy to “decline any contributions known to contain contents generated or derived from using Large Language Models.”\n\nAs detailed in the project’s documentation for contributors, the reasons for the ban are “… to avoid ambiguity in license compliance and optimize the use of limited project resources, especially for code review and maintenance.”\n\nThat wording suggests Cloud Hypervisor’s maintainers fear legal complications and/or contributions comprised of AI slop.\n\nAI coding tools are almost certainly trained on open source code, but it’s hard for developers to know if the LLMs helping them to write software also snarfed copyrighted code or projects published under restrictive licenses. All of Cloud Hypervisor’s contributors are likely targets for lawsuits, so politely declining to accept AI makes sense.\n\nEven though the project’s participants know it’s probably a futile gesture.\n\nIn a thread debating the policy, Cyberus Technology’s Philipp Schuster expressed concern “that this policy will basically be violated starting from day 0 after being merged. We never can ensure code is not at least enhanced with/from LLM.”\n\nIn response, a contributor named Bo Chen suggested “we need a procedure to make sure the policy is explicitly acknowledged. One option is to add a pull request template that includes a mandatory checkbox, requiring contributors to affirm they have read and agree to our contribution guide.”\n\nA notable inclusion in version 48 is documentation on how to run Windows 11 guests, which should help those creating cloudy desktop-as-a-service products.\n\nOther additions that may interest include:\n\nLifting the maximum number of supported vCPUs on x86_64 hosts using KVM from 254 to a whopping 8192;\n\nRemoving support for Intel’s Software Guard Extensions (SGX);\n\nAdding support for inter-VM shared memory;\n\nFaster pausing for VMs that run on many vCPUs.\n\n®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/15/cloud_hypervisor_no_ai_policy/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "China's entry-level GPU with AMD RX 550-level of performance is ready for tapeout — Loongson 9A1000 is finally off the drawing board and headed to fabs",
      "content": "Having started its development in 2023, Loongson Technology's 9A1000 graphics card is one step closer to the finishing line. According to Chinese media outlet ITHome, the development of the 9A1000 has been completed, and the graphics card will begin tapeout in the third quarter of this year.\n\nThe 9A1000 is Loongson's first graphics card, marking a significant milestone for the Chinese manufacturer, which had previously focused mainly on processors. The company positions the 9A1000 as an entry-level graphics card that supports AI acceleration. Therefore, it doesn't compete in the same segment as the Lisuan G100, another Chinese graphics card, that allegedly rivals the GeForce RTX 4060.\n\nAlthough we've been aware of the 9A1000 for some time, we still don't know its exact specifications. Loongson has kept details under wraps, only hinting that it offers performance similar to the Radeon RX 550, a card that was released eight years ago. However, it's too early to call it a win for Loongson, since the manufacturer still has to evaluate the 9A1000 after the tapeout.\n\nThe latest update on the 9A1000 indicates that Loongson has apparently reduced the area of the stream processor by 20%. The manufacturer also claims that it has increased the 9A1000's operating frequency by 25%, while optimizing power consumption during light loads by 70%. In terms of feature set, the 9A1000 supports OpenGL 4.0 and OpenCL ES 3.2 APIs.\n\nAccording to Looongson, the 9A1000 is up to 4X faster than the LG200, the integrated graphics unit inside the 2K3000 processor. The 9A1000 also provides up to 40 TOPS of AI computing power, which is slightly below that of AMD's XDNA 2 NPU inside the Ryzen AI Max+ (codenamed Strix Halo) chips, which deliver up to 50 TOPS.\n\nThe 9A1000 isn't the only graphics card on Loongson's plate. The company is also working on the 9A2000, which it claims is up to 10X faster than the 9A1000, with performance levels comparable to those of the GeForce RTX 2080. There are also plans for a 9A3000, a follow-up to the 9A2000, but no known specifications are available yet.\n\nAlthough it may not be immediately apparent, numerous Chinese corporations and startups have entered the graphics card industry. However, many of these entities fail and subsequently cease operations. Therefore, we only hear news about the more prominent firms, such as Biren, Moore Threads, and, in recent years, Loongson and Lisuan Technology.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/gpus/chinas-entry-level-gpu-with-amd-rx-550-level-of-performance-is-ready-for-tapeout-loongson-9a1000-is-finally-off-the-drawing-board-and-headed-to-fabs",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Condor Technology to Fly \"Cuzco\" RISC-V CPU into the Datacenter",
      "content": "Once a hyperscaler or a cloud builder gets big enough, it can afford to design custom compute engines that more precisely match its needs. It is not clear that the companies that make custom CPUs and XPUs are saving money, but they are certainly gaining control and that is worth something.\n\nArm made a push based on the power-efficient nature its architecture, and Nvidia has become a key player in AI with its powerful GPUs and now its “Grace” Arm server CPUs. A reinvigorated AMD has given system makers an x86 alternative to an Intel that is still trying to find its footing after a few years of missteps and missed deadlines. And now, the community for RISC-V, the open, modular, and highly customizable architecture overseen by the RISC-V International collective, is looking to make inroads into datacenters.\n\nIt is still early days for RISC-V, much as it was for Arm in the datacenter back in 2010, but the RISC-V architecture is being embraced by a range of well-known tech vendors, from Intel, Western Digital, Google, Nvidia, Meta Platforms, and Qualcomm, and a growing number of pure-plays and startups, such as Andes Technology, SiFive, Microchip Technology, Ventana, and Lattice Semiconductor.\n\nThere also is money backing the effort. Most recently, the European Union continued its on-again, off-again courting of RISC-V for supercomputers and other HPC systems in the region with the launch in March of DARE – Digital Autonomy with RISC-V in Europe – to oversee a six-year, $260 million effort.\n\nCondor Takes Flight\n\nAndes is two decades old and, despite its name, is based in Taiwan, not in Colombia, Chile, Peru, or Argentina where the mountain range of that name is located on the western coast of South America. The company is a founding member of RISC-V International and a maker of efficient and low-power processor cores based on the architecture.\n\nMark Evans, director of business development at Andes and now its Condor Computing subsidiary that was established in Austin, Texas to get indigenous to the United States, gave an overview of the company in a session at the AI Infra Summit in Santa Clara last week. The week before that Ty Garibay, Condor’s founder and president, and Shashank Nemawarkar, Condor’s director of architecture, walked everyone through the “Cuzco” core that the company has created to begin its assault on the datacenter in earnest.\n\nEvans says that Andes has shipped its intellectual property in over 17 billion RISC-V chips since 2005, and further that it has been growing sales at a compound annual growth rate of 29 percent between 2018 and now. Evans put some numbers on it, saying that Andes had $42 million in sales in 2024, and that its IP was present in 30 percent of RISC-V SoCs that were shipped last year.\n\nThe Andes customer base is pretty broad across various industry sectors, including MediaTek and Novatek in mobile devices, Phison in storage, and Meta Platforms and SK Telecom in AI compute engines.\n\nEvans says that 39 percent of the revenue that Andes had in 2024 came from the AI sector, significantly including the MTIA v1 and MTIA v2 coprocessors from Meta.\n\nThat brings us to the “Cuzco” RISC-V core that Condor was showing off at the Hot Chips 2025 conference.\n\nIn July, Condor successfully did full hardware emulation of the Cuzco core, booting multiple operating systems, including Linux, with the first users expected to get the processor sometime in the last quarter. This high-performance RISC-V core has microarchitectural tweaks, including the way it issues instructions and organizes execution units, all with the aim of creating what Garibay said will be “the world’s highest performance licensable RISC-V CPU IP,” with a broad range of use cases.\n\n“We’re entirely focused on bringing an innovative new microarchitecture to the RISC-V CPU market,” Garibay said during a presentation at Hot Chips. “We intend to demonstrate that RISC-V can be competitive in any high-performance computing application, from datacenters to handsets to automotive. … Our goal is to provide much better performance than other high-performance, licensable CPUs while operating at a similar power envelope.”\n\nCuzco is based on the latest RISC-V profile for datacenter computing – RVA-23 – so ensure high software compatibility, can support up to eight cores with up to 8 MB private L2 cache in a coherent cluster with a shared 256 MB L3 cache, and a 12-stage pipeline. There are functional units that execute through a pool after the eight-instruction dispatch. The CPU itself is standard, with fetch, instruction queue, and instruction decode, he said.\n\nBelow is a more detailed block diagram of the Cuzco core:\n\nHere is the cache memory architecture:\n\nAnd here is the socket architecture:\n\nThe structure of the core is what is really interesting with Cuzco, so we are going to spend our time there.\n\nOne area Condor focused on was the structure of the execution units, which Garibay said are pair into two pipelines called a “slice,” with each of the four slices being identical and each having its own pipelines and resources.\n\n“Each slice fully implements RISC-V compatibility,” he said. “The machine is scalable, in theory, down to one slice or pair of pipelines, although. practically probably, only anyone would ever implement is two slices. As a minimum machine, the overhead becomes unwieldy at that point. But it is scalable to six pipelines, three slices by default – eight pipelines, four slices – and then we will extend this architecture into the future, with added features as we grow the slice count.\n\nThe intent, he said, “was to ease the implementation of this in high-performance processes.”\n\nThen comes the time-based architecture for instruction sequencing. The chip starts out with what Nemawarkar called “a standard pipeline for the out-of-order machines. Typically, this is a 12-log stage pipeline. The instruction fetch, nothing different than most of it you have seen.”\n\nChanges come from the point of where instruction decode happens, Nemawarkar said. That’s where the time-based issuing logic kicks in. Most chips use Tomasulo’s algorithm, a process for the out-of-order scheduling of instructions. In these cases, the chips use content-addressable memories (CAMs) to point to instructions to send downstream. CAMs can eat up a lot of power, given the match-line switching and precharge cycles needed.\n\nCuzco uses its register scoreboard to record the write time of an instruction to a register, which then becomes the read time. The scoreboard says when the instruction is available for execution and tracks the future of write time of instructions. The chip’s time resource metrix (TRM) records the use of resources like arithmetic logic units (ALUs), buses, and load and store queues to help predict ahead of time what resource will be available, which enables predictive scheduling. Instructions can be issued with an understand of exact future cycles for operands and resources, according to Andes.\n\nIt also does away with the power-hungry CAMs.\n\n“The reasoning behind that is this allows us to reduce the complexity, which typically happens in the global scheduling or a local scheduling or combination of that, when the machines start to become wider and wider,” Nemawarkar said. “Everybody knows that being a huge problem. Then essentially, with each execution unit, you need to start looking at which instructions are ready, how do I execute based on the priority for which instruction to be given, etc.”\n\nIt’s something that other implementations haven’t tried before, according to Garibay.\n\n“It is a departure, and it’s a good departure in that we’re looking to reduce the overall power and area of what has become the most power-and-area-hungry part of these wide, out-of-order machines – instruction scheduling,” Garibay added.\n\nEnterprises and HCP centers will be able to put Cuzco to the test by the end of the year so see how the new execution units and out-of-order instruction scheduling will work for them.",
      "source": "The Next Platform",
      "url": "https://www.nextplatform.com/2025/09/15/condor-technology-to-fly-cuzco-risc-v-cpu-into-the-datacenter/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Intel Is Losing Ground in the High-End CPU Segment. Can the US Government Save the Legacy Company?",
      "content": "Key takeaways: AMD dominates the high-end CPU market with its Ryzen 9000 and X3D chips, reducing Intel’s premium market share even though Intel still leads in total unit sales.\n\nwith its Ryzen 9000 and X3D chips, reducing Intel’s premium market share even though Intel still leads in total unit sales. Intel’s decline is partly self-inflicted , marked by missed mobile and AI revolutions, fab delays, $2.9B quarterly losses, and 24,000 layoffs that threaten to hollow out critical talent.\n\n, marked by missed mobile and AI revolutions, fab delays, $2.9B quarterly losses, and 24,000 layoffs that threaten to hollow out critical talent. The US government and Nvidia have stepped in with Washington investing $8.9B and Nvidia contributing $5B, providing Intel with fresh capital, political support, and the integration of RTX GPU chiplets into future CPUs.\n\nwith Washington investing $8.9B and Nvidia contributing $5B, providing Intel with fresh capital, political support, and the integration of RTX GPU chiplets into future CPUs. Intel’s survival might come at the expense of its independence: it now has credibility and room to breathe but risks becoming a junior partner to Nvidia and relying on U.S. policy rather than leading innovation itself.\n\nFor decades, Intel was the undisputed leader in the CPU market: a company so dominant that its name became a synonym for computing power. Today, that reputation has diminished.\n\nOnce dominated by Intel, the high-end consumer and professional CPU markets are now shifting toward AMD. This shift is well justified: AMD’s Ryzen 9000 and X3D chips consistently outperform Intel’s flagship models in benchmarks, efficiency, stability, and long-term platform support.\n\nMeanwhile, Nvidia has surged to a market capitalization of over $4.2 trillion, riding the AI wave and becoming the most valuable company in history.\n\nIntel, by contrast, has lost its lead. The company reported a $2.9 billion loss in Q2 2025, announced plans to cut 24,000 jobs, and shelved multi-billion-dollar European projects.\n\nIts CEO even admitted in July that Intel no longer ranks among the world’s top ten semiconductor companies: an admission that would have been unexpected just a decade ago.\n\nBut Intel’s story isn’t just about its decline: two influential supporters have now stepped in. The US government bought a 10% stake in Intel this August, investing $8.9 billion in the company’s vital role in domestic chip production.\n\nAnd this week, Nvidia announced a $5B investment in Intel, promising to incorporate its RTX GPU technology into upcoming Intel processors.\n\nThe stakes couldn’t be higher. Could this new influx of capital signal the start of Intel’s recovery, or is it just life support for a fading giant?\n\nIntel’s Market Position Under Siege\n\nIntel’s biggest challenge isn’t just internal mistakes; it’s the ongoing decline of its market standing in high-end consumer CPUs. Intel was known for high performance for years, but AMD has changed that narrative.\n\nPowered by the Ryzen 9000 series and its innovative X3D chips, AMD has shifted from underdog to leader in benchmarks, efficiency, and value. The numbers reveal a change redefining the power balance in the CPU market.\n\nAMD’s High-End Dominance\n\nAlthough Intel still leads in overall CPU sales, AMD has consistently gained ground in the high-end market where performance and profit margins are key.\n\nIn Q2 2025, Intel accounted for about 75% of consumer CPU unit sales, but AMD’s revenue share increased to 27.8%, nearly 10% higher year-over-year. The key point: Intel sells more chips overall, but AMD is gaining ground with higher-value models.\n\nThe desktop CPU market is experiencing an even more significant shift. AMD’s revenue share increased by 20.5% year-over-year to 39.3%, with unit sales reaching 32.2%.\n\nThe surge is driven by the Ryzen 9000 series and X3D chips, praised for gaming performance, energy efficiency, and extended support through the AM5 socket (supported until at least 2027).\n\nBenchmarks highlight this imbalance. According to PassMark, AMD occupies all top 30 slots for professional workloads: a clean sweep that underscores how far Intel’s top-tier CPUs have slipped.\n\nAlt: Table showing PassMark’s top-end CPU list with Intel CPUs only making an appearance at #31.\n\nThe trend over time reveals the stakes. In 2016, Intel outsold AMD by 9:1. By 2023, it was 4:1. Now, in 2025, it’s just 2:1. If momentum continues, AMD could outsell Intel outright within five years: a scenario once hard to imagine.\n\nAlt: Market share line chart showing Intel’s waning lead over AMD.\n\nAMD has genuinely earned its users’ trust over time. Its chips regularly offer better real-world performance and use less power, while Intel has faced issues with stability and reliability in recent releases. AMD is becoming the more reliable choice for gamers, creators, and enterprise buyers alike.\n\nIntel may still lead in volume, but losing the high-end halo segment risks more than just revenue. Premium chips shape brand identity and influence future innovation. And once that perception shifts — as it now has toward AMD — reclaiming it becomes a much taller challenge.\n\nIntel’s Self-Inflicted Wounds\n\nMuch of Intel’s struggles comes from fierce competition, but some of its decline has been self-inflicted.\n\nOver the past decade, the company has repeatedly failed at crucial moments. It missed the mobile revolution by ceding smartphones to ARM-based processors and then missed the AI boom, while competitors like Nvidia built their fortunes around GPU-accelerated machine learning.\n\nEven Intel’s highly anticipated foundry expansion has fallen behind schedule, causing the US to remain dependent on Taiwan’s TSMC for advanced manufacturing.\n\nThe company’s own leadership has acknowledged this reality. In July 2025, CEO Lip-Bu Tan admitted bluntly:\n\n“We are not in the top 10 semiconductor companies,” – a stunning confession from a firm that once set the industry’s pace.\n\nFinancially, the impact has been substantial. Intel reported a $2.9 billion loss in Q2 2025 and announced it would lay off 24,000 employees, reducing its workforce from nearly 100,000 to about 75,000.\n\nAlong with the layoffs, Intel canceled plans for huge fabs in Germany and Poland and closed its automotive division, wiping out years of investment in those sectors.\n\nAnalysts warn that these cuts could further weaken Intel. Unless Washington facilitates talent-sharing or supply chain guarantees with Nvidia, AMD, and TSMC, Intel risks depleting the workforce needed to develop competitive chips in the next decade.\n\nAlt: Timeline showing Intel’s missteps over the past decade\n\nCPU Performance and Reliability Crisis\n\nIntel once set the standard in the high-end consumer market. However, its latest flagship has fallen short. The $600 Core i9-12900K consistently trails behind AMD’s Ryzen 9 7950X across key benchmarks.\n\nIndependent testing shows Ryzen delivering 34% higher FPS (194.8 vs. 144.9), significantly more L3 cache (144MB vs. 76MB), and lower power consumption. AMD’s AM5 platform also guarantees support until 2027, appealing to buyers who want to future-proof their builds.\n\nBut raw performance isn’t the only issue. Intel’s latest chips have encountered widespread stability and reliability problems.\n\nLinux developer Michael Stapelberg, a long-time Intel user, reported his 285K system failing twice in months despite normal thermal conditions.\n\nLong-running workloads caused crashes and unresponsiveness, forcing him to switch from Intel to AMD. Similar complaints have spread across forums and retailer reviews, indicating high RMA rates and instability in real-world use.\n\nThese issues directly undermine Intel’s value proposition. Enthusiasts might accept quirks, but enterprises executing AI-intensive workloads cannot afford unreliable hardware.\n\nAt a time when computing reliability is more critical than ever, Intel’s flagship CPUs seem slower than AMD’s and less trustworthy: a risky combination in the competition for high-end market share.\n\nIntel’s Political and Financial Lifelines\n\nIntel’s struggle is no longer just a corporate issue; it’s clearly a national concern. Over the past year, the U.S. government and Nvidia have stepped in to provide Intel with unmatched support.\n\nThese interventions emphasize how vital Intel is to America’s technological sovereignty, even as its commercial competitiveness declines.\n\nThe U.S. Government’s $8.9B Stake\n\nIn August 2025, the Trump administration made headlines by acquiring a 9.9% stake in Intel for $8.9 billion, effectively labeling the chipmaker as “too big to fail.”\n\nUnlike the 2008 auto industry bailouts, this move wasn’t mainly about saving jobs; it was about geopolitics.\n\nThe US remains heavily dependent on Taiwan Semiconductor Manufacturing Company (TSMC), which controls 64% of the global foundry market and supplies about 44% of US logic chip imports as of 2021. Given China’s ongoing claims over Taiwan, Washington views this reliance as a strategic vulnerability.\n\nThe CHIPS Act of 2022 allotted $52B to support domestic semiconductor manufacturing, but progress is slow, and building advanced fabs takes years.\n\nConversely, Trump’s direct investment in Intel provided immediate political influence and capital, positioning Intel as the “national champion” of US chipmaking.\n\nStill, risks persist. Intel has found it challenging to attract outside customers to its foundry business, and concerns remain about whether Washington can compel AMD, Nvidia, or others to use Intel-manufactured chips if performance falls short of TSMC. Without competitive products, political support alone may not be sufficient.\n\nAlt: Graphic of the US Capitol dome with the Intel logo in the foreground\n\nNvidia’s $5B Lifeline\n\nIf the US stake was the first political lifeline, then Nvidia’s $5B investment in September was the second. Announced at a high-profile press conference, the deal involves Nvidia purchasing common stock in Intel and partnering on both consumer CPUs and AI-focused data center products.\n\nThe most striking feature is the plan to incorporate RTX GPU chiplets into upcoming Intel CPUs, effectively providing an alternative to AMD’s popular Ryzen APUs.\n\nThis could be a game-changer for thin laptops, handhelds, and small-form PCs by adding real gaming capabilities and AI acceleration to Intel-powered devices.\n\nOn the data center side, the alliance could reshape the x86 ecosystem. Nvidia already dominates AI servers through its GPUs and proprietary NVLink interconnects.\n\nBy partnering with Intel’s CPUs, Nvidia broadens its influence while giving Intel access to fast-growing AI markets it has largely overlooked. Nvidia CEO Jensen Huang estimates the partnership could target a $50B market opportunity.\n\nThe market reaction to this news was swift:\n\nIntel stock surged nearly 30% , the biggest one-day gain in years.\n\n, the biggest one-day gain in years. Nvidia rose 3% , adding $120B in market cap: more than 20 times its actual investment.\n\n, adding $120B in market cap: more than 20 times its actual investment. AMD fell 4%, a sign that investors fear it could be boxed out of future datacenter and consumer markets.\n\nAlt: Price chart showing Intel (INTC) surging nearly 30% premarket following news of Nvidia’s investment.\n\nPolitically, the deal benefits U.S. strategic interests. Nvidia CEO Jensen Huang said the White House had no direct involvement, though Commerce Secretary Howard Lutnick was “very supportive.”\n\nAnalysts widely believe Washington encouraged Nvidia to support Intel, playing its part to ensure that America’s legacy chipmaker wouldn’t collapse just as AI reshapes the global economy.\n\nFor Intel, the partnership restores much-needed credibility. For Nvidia, it gains goodwill in Washington while keeping options open to shift manufacturing away from TSMC if geopolitics require it.\n\nThe Future of Intel’s Technology\n\nIntel’s $8.9B US government lifeline and Nvidia’s $5B partnership have bought the company valuable time, but its survival depends on execution.\n\nThe immediate concern is whether these alliances enhance or weaken Intel’s technology roadmap, making the company a junior partner in its own industry.\n\nWhat About Intel GPUs?\n\nNvidia’s $5B investment raises one of the biggest questions about what it means for Intel’s GPU ambitions.\n\nOn paper, Intel is committed to continuing its Arc discrete graphics and Xe architecture roadmaps. An Intel spokesperson told PCWorld that the Nvidia partnership is “complementary to Intel’s roadmap” and does not replace its GPU efforts.\n\nBut it’s reasonable to be skeptical of this. Intel’s discrete GPUs have struggled to gain traction, with Nvidia controlling around 94% of the GPU market as of Q2 this year. If future Intel CPUs start integrating Nvidia’s RTX chiplets, what incentive remains to develop Arc further?\n\nAlt: Roadmap graphic showing Xe3 Celestial potentially integrating RTX chiplets\n\nThere’s also a historical reason for skepticism. Intel previously tried a hybrid design in Kaby Lake-G, which combined Intel CPUs with AMD Radeon GPUs. The product failed, hindered by driver problems and a short lifespan. Nova Lake-AX, Intel’s next SoC platform, might revisit this concept: but this time, with Nvidia GPUs instead of AMD’s.\n\nIntel maintains it will keep developing its own GPUs, but the new partnership looms large. Over time, Intel risks relying on Nvidia’s graphics dominance instead of fighting directly.\n\nRisks and Rewards of the Intel–Nvidia Alliance\n\nThe Nvidia deal is being hailed as a “historic collaboration” by both companies, but its implications are double-edged.\n\nOpportunities\n\nTechnical lift : Nvidia’s GPU chiplets could make Intel CPUs competitive in thin-and-light gaming laptops and mini-PCs, where AMD’s APUs have held the edge.\n\n\n\n: Nvidia’s GPU chiplets could make Intel CPUs competitive in thin-and-light gaming laptops and mini-PCs, where AMD’s APUs have held the edge. Datacenter dominance: Nvidia extends its AI ecosystem by pairing its GPUs with Intel’s x86 CPUs, creating a powerful rival to AMD’s EPYC processors.\n\nInvestor confidence: Intel stock surged 30% after the announcement, while Nvidia added around $120B to its market cap.\n\nRisks\n\nJunior partner status : Intel may become a vessel for Nvidia’s strategy rather than an innovator in its own right.\n\n\n\n: Intel may become a vessel for Nvidia’s strategy rather than an innovator in its own right. GPU ambitions sidelined : Intel’s Arc and Xe families risk irrelevance if Nvidia becomes the preferred GPU inside Intel chips.\n\n\n\n: Intel’s Arc and Xe families risk irrelevance if Nvidia becomes the preferred GPU inside Intel chips. Geopolitical uncertainty: Both companies remain dependent on TSMC for manufacturing despite US backing. Nvidia CEO Jensen Huang himself emphasized that “you just can’t overstate the magic that is TSMC.”\n\nThe big picture is clear: Intel now relies on two key supporters, Washington and Nvidia. Together, they provide Intel with breathing room and market credibility.\n\nIn return, however, Intel might have to sacrifice some of its independence, acting less like a global leader and more like a US-backed ecosystem partner. said, this won’t happen in the blink of an eye. It will take time and precious resources, which is precisely why the US government decided to get involved.\n\nCan Intel Really Be Saved?\n\nIntel’s unchecked-dominance arc of its story is firmly in the past; now, its focus is on survival. Once the symbol of US chip supremacy, the company is now at the nexus of government policy and private partnership.\n\nThe $8.9B US stake confirms that Intel is too strategic to fail, while Nvidia’s $5B investment adds both credibility and technical driving force.\n\nIn the short term, these moves have steadied the ship. Intel’s stock surged 30% on the Nvidia news, investors regained confidence, and the company now has a clearer roadmap for consumer PCs and data centers. Make no mistake: this is a much-needed early win for new CEO Lip-Bu Tan.\n\nBut the long-term challenges are very real. Intel must prove it can deliver reliable high-end CPUs, compete with AMD’s performance edge, and carve out space in AI: a sector already dominated by Nvidia. Worse still, it risks becoming a junior partner, leaning on others’ innovation instead of forging its own path.\n\nSo now, the question is no longer whether Intel can survive. With both Washington and Nvidia invested, it almost certainly will. The real question is whether Intel can reclaim its role as a global leader, or whether its future will be defined as a dependent ally in a new semiconductor world order. As they say, time will tell.\n\nMonica is a tech journalist and content writer with over a decade of professional experience and more than 3,000 published articles. Her work spans PC hardware, gaming, cybersecurity, consumer tech, fintech, SaaS, and digital entrepreneurship, blending deep technical insight with an accessible, reader-first approach. Her writing has appeared in Digital Trends, TechRadar, PC Gamer, Laptop Mag, SlashGear, Tom’s Hardware, The Escapist, WePC, and other major tech publications. Outside of tech, she's also covered digital marketing and fintech for brands like Whop and Pay.com. Whether she’s explaining the intricacies of GPU architecture, warning readers about phishing scams, or testing a liquid-cooled gaming PC, Monica focuses on making complex topics engaging, clear, and useful. She’s written everything from deep-dive explainers and product reviews to privacy guides and e-commerce strategy breakdowns. Monica holds a BA in English Language and Linguistics and a Master’s in Global Media Industries from King’s College London. Her background in language and storytelling helps her craft content that’s not just informative, but genuinely helpful—and a little bit fun, too. When she’s not elbow-deep in her PC case or neck-deep in a Google Doc file, she's probably gaming until the early hours or spending time with her spoiled-rotten dog. View all articles by Monica J. White\n\nRelated Articles",
      "source": "Techreport.com",
      "url": "https://techreport.com/news/intel-losing-high-end-cpu-segment-can-us-govt-save-it/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "These portable operating systems are so light you don’t even need to install them",
      "content": null,
      "source": "MakeUseOf",
      "url": "https://www.makeuseof.com/these-portable-operating-systems-light-dont-need-to-install/",
      "timestamp": "2025-09-15"
    }
  ],
  "Intel": [
    {
      "headline": "US Tech Companies Enabled the Surveillance and Detention of Hundreds of Thousands in China",
      "content": "An Associated Press investigation based on tens of thousands of leaked documents revealed Tuesday that American technology companies designed and built core components of China's surveillance apparatus over the past 25 years, selling billions of dollars in equipment to Chinese police and government agencies despite warnings about human rights abuses.IBM partnered with Chinese defense contractor Huadi in 2009 to develop predictive policing systems for the \"Golden Shield\" project, AP reports, citing classified government blueprints. The technology enabled mass detentions in Xinjiang, where administrators assigned 100-point risk scores to Uyghurs with deductions for growing beards or being aged 15-55. Dell promoted a laptop with \"all-race recognition\" capabilities on its WeChat account in 2019. Thermo Fisher Scientific marketed DNA kits as \"designed\" for ethnic minorities including Uyghurs and Tibetans until August 2024.Oracle, Microsoft, HP, Cisco, Intel, NVIDIA, and VMware sold geographic mapping software, facial recognition systems, and cloud infrastructure to Chinese police through the 2010s. The surveillance network tracks \"key persons\" whose movements are restricted and monitored, with one estimate suggesting 55,000 to 110,000 people were placed under residential surveillance in the past decade. China now has more surveillance cameras than the rest of the world combined.",
      "source": "Slashdot.org",
      "url": "https://news.slashdot.org/story/25/09/09/1124247/us-tech-companies-enabled-the-surveillance-and-detention-of-hundreds-of-thousands-in-china",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel's crown as the best choice for gamers may be slipping as pros complain about its performance vs. AMD",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/intels-crown-slipping-pros-complain-performance-vs-amd/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Exit, rebuild, repeat — Intel’s new era begins without Holthaus",
      "content": "The Intel logo is displayed during the 2018 CeBIT technology trade fair\n\nIntel has announced major leadership changes as CEO Lip-Bu Tan pushes ahead with efforts to transform the struggling chipmaker. The most notable departure is Michelle Johnston Holthaus, whose career at Intel has spanned more than 30 years.\n\nThe shake-up comes just as Intel admitted its Arrow Lake processors failed to live up to expectations. All eyes are now on the upcoming Nova Lake architecture, which it hopes will restore competitiveness against AMD. This rivalry continues to gain ground with users and across the industry.\n\nHolthaus’s departure after 30 years at Intel\n\nHolthaus joined Intel in 1996, a year before I was even born, which makes me feel old. Anyway, starting as a program manager in the OEM Platform Solutions Division. Holthaus went from there, and she moved steadily through leadership roles in sales, marketing, and product development.\n\nBetween 2013 and 2017, she managed Intel’s partnership with Microsoft, coordinating sales, product roadmaps, and technical support. This role kept Intel’s CPUs and Microsoft’s platforms closely aligned across Windows, Surface, Xbox, and cloud services.\n\nIn late 2024, Holthaus stepped into the spotlight as interim co-CEO alongside CFO David Zinsner following Pat Gelsinger’s departure. She was later appointed CEO of Intel Products but held the position for only 9 months before resigning. Intel said the decision was due to “a material reduction in her duties, responsibilities, salary, and target annual bonus,” which matched the “Good Reason” clause in her contract.\n\nThanks to this clause, Holthaus will receive full severance benefits and remain with Intel in a non-executive advisory role until March 1, 2026.\n\nNew leadership team takes shape\n\nKevork Kechichian has joined Intel from Arm as Executive Vice President and General Manager of the Data Center Group. He brings more than 30 years of semiconductor experience and previously managed Snapdragon SoC teams at Qualcomm.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAnother addition is Jim Johnson, a 40-year Intel veteran, who has been confirmed as Senior Vice President and General Manager of the Client Computing Group. Over his long career, Johnson has worked across Intel’s Technology and Manufacturing Group, Networking and Communications, and global operations.\n\nIntel has also formed a new division in 2025, the Central Engineering Group, which will be led by Srinivasan “Srini” Iyengar. This team will focus on custom silicon design for external customers. Iyengar, who spent over 25 years at Cadence Design Systems, brings deep expertise in silicon engineering and design automation.\n\nLastly, Dr. Naga Chandrasekaran’s responsibilities have been expanded to include Foundry Services, alongside his existing role as Executive Vice President and Chief Technology and Operations Officer of Intel Foundry. Before joining Intel, he spent 16 years at Micron, where he led advanced memory technology development.\n\nTogether, these appointments show Tan’s push to blend long-time Intel leaders with external expertise from companies like Arm, Cadence, and Micron. It may take time before the results are clear, but the changes highlight Intel’s willingness to act boldly as it struggles to compete.\n\nTan’s strategy and vision for Intel’s future\n\nLip-Bu Tan, chief executive officer of Intel Corp (Image credit: Getty Images | Bloomberg)\n\nTan is aiming to cut back on bureaucracy by eliminating redundant management layers and creating a flatter, more focused structure. The goal is to speed up decision-making and bring more direct accountability. A clear example is that Holthaus’s position will not be replaced, with key groups now reporting directly to Lip-Bu Tan.\n\nHe is also pivoting Intel toward custom silicon and foundry services, areas where the company hopes to become a leader. The newly formed Central Engineering Group is central to this effort, with a focus on building chips for external customers instead of just Intel’s own products.\n\nOf course, no turnaround story in 2025 would be complete without AI, and Tan’s plans touch on that too. Still, the real test will be whether this strategy helps Intel compete with rivals like AMD. Rebuilding trust with users and partners will take time, but Nova Lake may give us the first glimpse of what Tan’s reshaped Intel can deliver.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/intel/exit-rebuild-repeat-intels-new-era-begins-without-holthaus",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "TikTok's parent company ByteDance is valuing itself at $330 billion. One big investor thinks it's worth even more.",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nByteDance believes it is worth more than Chevron, General Electric, and Coca-Cola. One of the world's biggest investors thinks it's even more valuable than that.\n\nFidelity, which invested in TikTok's parent company in 2020 through its massive Contrafund, valued the company at more than $385 billion at the end of July, filings show. That is nearly 17% more than ByteDance's self-valuation of $330 billion.\n\nAccording to reports in late August, ByteDance is offering a share buyback program for employees looking for liquidity and valued itself at more than $330 billion, a 5.5% increase from earlier this year, when the company marked itself at $315 billion.\n\nIt's a lofty valuation for a company that struggles to make profits despite tens of billions of dollars in quarterly revenues. But for $6.4 trillion Fidelity, the Chinese company's valuation of itself is low. Fidelity's valuation of the company considers ByteDance more valuable than public companies such as defense tech firm Palantir and Wall Street staple Bank of America.\n\nFidelity declined to comment. ByteDance did not immediately respond to a request for comment.\n\nThere are plenty of reasons why the company might depress its valuation when offering buybacks to employees, primarily to accumulate its own equity at a discount in case it is needed for fundraising down the line.\n\nThe company has a looming deadline that would materially change its standing. President Donald Trump's June executive order postponed the date by which ByteDance would need to sell its US TikTok operations to September 17, though he has hinted at that deadline being extended.\n\nThe app briefly went dark in the US in January to comply with the original divest-or-sell deadline before Trump directed his Attorney General not to enforce the law, which was passed by the Senate. The White House made its own TikTok account last month, when Trump said he was a fan of the app.\n\nHe floated the government taking a 50% stake in TikTok, similar to the deal the government struck to take 10% of Intel, though he did not give additional details on what the joint venture would look like.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/fidelity-valuation-tiktok-parent-bytedance-2025-9",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Weird CPU architectures, the MOV only CPU (2020)",
      "content": "I like CPU architectures, especially weird, interesting and unusual ones. For example, the Intel iAPX 432 is still something I would love to play around with. Recently, I realized that a working CPU can be made with just a simple Move instruction. For this to work, everything needs to be memory mapped. The ALU, program counter, everything.\n\nOf course, this idea is nothing new and this idea is called the Transport Triggered Architecture. I decided to have a look into this, how it works and make a simple TTA CPU.\n\nHow does a TTA CPU work\n\nBefore I can make a CPU, let’s look into what is so different in a TTA CPU. In most CPU’s, calculations are done using registers and some arithmetic logic unit. For example, to add 2 numbers, the assembly code could be:\n\nLOAD VARIABLE1, REGISTER0 LOAD VARIABLE2, REGISTER1 ADD REGISTER0, REGISTER1, REGISTER2 STORE REGISTER2, VARIABLE3\n\nIn a TTA CPU, there is no ALU or registers in the CPU itself. Instead, they exist somewhere in memory. In order to add 2 numbers, they are moved from memory or registers, to the ALU. The ALU result is then moved back to memory/registers. Or in code:\n\nMOVE VARIABLE1, ALU_A MOVE VARIABLE2, ALU_B MOVE ALU_ADD_RESULT, VARIABLE3\n\nIn the simplest form, the CPU in a TTA CPU only needs to move data from one memory address to another. All calculations are done as a result of data being moved around. If you think, how would you jump to a different section of code, it’s easy. If the program counter is also in memory, a jump is as simple as moving a new address to the program counter.\n\nA few TTA computers have been made, and even commercially sold. But in general, it’s a niche architecture that never has gotten popular. So let’s build one :D\n\nBuilding a simple TTA computer\n\nI decided to build the computer in Digital, a simulator for digital logic that is based on Logisim but much improved. Just the name is a bit too common when googling :)\n\nIn order to make a simple TTA computer, a few things are needed.\n\nA CPU capable of moving data A program counter An ALU A branch block\n\nI want the CPU to be a von Neumann type of CPU, meaning that there is one memory bus with code to execute and RAM. To have a useable amount of memory, a 16 bit address, in order to address 64KB of RAM, is probably nice. Let’s just make it a 16 bit CPU when we are busy.\n\nAs there is just a single instruction, MOVE data from A to B, every instruction is 32 bits. First 16 bits with the address A, then 16 bits with the address B.\n\nThe CPU\n\nThe CPU can be surprisingly easy, after some consideration I came to the realization it just has to 4 things:\n\nFetch the first 16 bits of the instruction for the source address Fetch the second 16 bits of the instruction for the destination address Read the data from the source address Write that data to the destination address\n\nTo build the entire CPU, a block to turn one clock signal into 4 is needed for the 4 steps. This means 1 instruction takes 4 clocks, but that is not too uncommon for a simple CPU.\n\nThe program counter is needed to select the right instruction, and a few latches or registers to store the addresses and data.\n\nOne simple CPU\n\nTo simplify things, I created a 16 bit bus driver, 16 bit latch and 16 bit register building block. The 1 to 4 CLK modules is made using a 74_161 counter and a 74_139 2 to 4 decoder.\n\nThe program counter only sees a clock when fetching the instruction, when the CPU reads and writes to the fetched addresses, the program counter is not incremented.\n\nThe program counter\n\nWithout the program counter, the CPU won’t do much. To make a 16 bit program counter, a total of 4 of the 74_161 counters are needed. The program counter is, of course, memory mapped. In order to change it, a write to a specific address is used. This means a comparator is required to check if the address is correct. The output of the comparator AND the read/write signal are connected to the Load pins of the 74_161 in order to load a new value.\n\nAll in all, a fairly simple program counter.\n\nThe ALU\n\nWith the CPU done, let’s hook up some things to it, like the ALU\n\nTo keep part count down, a common option is to use the 74_181 4 bit ALU. With 4 of those, a 16 bit ALU can be made. Additionally, 2 registers are needed for the 2 inputs, and a bus driver in order to only output a value when needed.\n\nSome logic is also required for address decoding. The lowest 5 bits select the instruction, as the 74_181 has 32 possible instructions. The 6th bit selects in which register to store the data for the input.\n\nThe full schematic is as follows\n\nEach alu_slice just contains a 74_181, but connected in a way that I can work with busses. And even then it’s a bit of a messy schematic.\n\nThe flow control block\n\nBy lack of better name, the flow control block. Some form of program flow control is needed in order to implement something like an if() statement. In this case, a block with 4 registers and one output. 2 registers contain addresses, 2 contain variables. When read, if the variables are equal, address 1 will be returned, else address 2. And just like that, a simple flow control is implemented\n\nA comparator, 2 to 4 decoder, some registers and addressing logic and that’s all. By now one downside of this type of CPU slowly pops up, having registers in all memory mapped peripherals like the ALU and flow control slowly make a small CPU fairly big.\n\nWith that all in order, the complete CPU looks like this:\n\nI added a GPIO block that just stores the value written to it to make debugging easier.\n\nLet’s calculate some Fibonacci numbers\n\nWhat to do with a simple CPU that does show it functions as a CPU? Calculate some Fibonacci numbers seems like a good idea. It’s simple, but does show some flow control and calculation abilities.\n\nLet’s start with the code needed in C, or at least, pseudo-C, to calculate the first 10 Fibonacci numbers\n\nint T1 = 0; int T2 = 1; int nextTerm = 0; for(int i = 0; i < 10; ++i) { nextTerm = T1 + T2; T1 = T2; T2 = nextterm; }\n\nNow, let’s translate that to a bunch of MOV instuctions. A big bunch of them. First, a memory map.\n\n0x0000 to 0x7FFF is the instruction memory\n\n0x8000 to 0xBFFF is the RAM\n\n0xC000 to 0xC03F is the ALU\n\n0xC100 to 0xC103 is the flow control block\n\n0xFE00 is the GPIO block\n\n0xFFFF is the program counter\n\n//one time setup MOV 0x64 0xC102 MOV 10, compareB MOV 0x65 0xC101 MOV addrdone, Compare_addr2 MOV 0x66 0xC100 MOV 6, Compare_addr1 MOV 0x67 0x8001 MOV 1, T2 //Fibonacci calculation MOV 0x8000 0xc000 MOV T1, ALU1 MOV 0x8001 0xc020 MOV T2, ALU2 MOV 0x8001 0x8000 MOV T2, T1 MOV 0xC012 0x8001 MOV ALU_O, T2 MOV 0x8001 0xfe00 MOV T2, GPIO //handling the for loop MOV 0x8002 0xC000 MOV CNT, ALU1 MOV 0x0067 0xC020 MOV 1, ALU2 MOV 0xC012 0x8002 MOV ALU_O, CNT MOV 0x8002 0xC103 MOV CNT, CompareA MOV 0xC100 0xFFFF MOV Compare_O, PC MOV 0x0065 0xFFFF MOV addrdone, PC //just a loop\n\nWow, that’s a lot of code. Let’s try and unwrap that a bit. As the CPU can only move data, numbers have to be stored in memory. This means that the “int T2 = 1” C instruction is done by moving the value 1 stored in flash (in address 0x67) to variable T2 in RAM (address 0x8002)\n\nThe Fibonacci calculation itself is fairly easy, move T1 and T2 to the ALU, replace T1’s value with T2, move the result from the ALU back to T2. T2 is moved to the GPIO for a nice indication.\n\nThe for loop is handled by increasing a variable by 1 and comparing it to a set value, 10 (stored in address 0x64) for 10 loops. If they are not equal, the PC is set to the start of the Fibonacci calculation, else it’s set to an address containing an infinite loop.\n\nConclusion\n\nAnd with all of that, it calculates.\n\nFibonacci result in the top right under GPIO\n\nThere is a small bug caused by the RAM being infinite fast and asynchronous, sometimes a value is written to address 0x8012, caused by the 0xC012 address of the ALU. Apart from that, the CPU happily runs along.\n\nThis was an interesting way of making a CPU, but it’s not the most efficient or fast CPU. It can be made pretty small however. All in all, a fun exercise in a quirky and niche CPU architecture.\n\nAll the source files can be found here, and if you enjoyed this post, you can buy me a coffee.",
      "source": "Justanotherelectronicsblog.com",
      "url": "https://justanotherelectronicsblog.com/?p=771",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "How Republicans Plan to Use AI for 2026 (Even If It’s Too Woke)",
      "content": "Conservatives in California descended on Orange County over the weekend for the Republican Party’s Fall 2025 Convention and Leadership Summit. Some of the sessions at the three-day event focused on artificial intelligence, providing a peek at how the party of Donald Trump plans to use AI in the 2026 midterm elections and beyond.\n\nBrent Lowder, the California director of a right-wing nonprofit called the Leadership Institute, gave well-attended talks at the convention about how Republicans should use AI in a rapidly evolving environment. Lowder’s talks emphasized the need for conservatives to embrace new technology as quickly as possible or risk getting walloped by Democratic opponents who use AI.\n\n“AI’s just this kind of new technology, and I don’t wanna see conservatives be slow to adopt it, like we’ve done so much before. That’s why it’s so important for us,” Lowder told the audience.\n\nIn 2008, presidential hopeful Barack Obama promised to announce his VP candidate (Joe Biden) via text, which allowed his campaign to collect a massive number of phone numbers from people who wanted to be the first to know. And in 2012, President Obama’s campaign embraced social media in ways that his competitor, Mitt Romney, did not.\n\nThe 51-year-old Lowder, who previously ran a political action committee that helped elect Trump to his first term in 2016, understands Republicans can’t get caught flat-footed technologically.\n\nThat kind of fear about missing out seemed to drive much of the discussion. But Lowder also touted the increased efficiency he saw in using AI. Lowder told the audience to think of AI as “super interns.” He said that AI makes mistakes, and it’s important not to just use whatever the AI produces as a final product. And he repeatedly reminded the audience that AI will just make things up and produce errors. It was a tool, he told the crowds. And it was interesting to hear him downplay the capabilities while remaining optimistic, a contrast to the hype of AI CEOs who insist tools like ChatGPT are like having PhD experts in any field.\n\nLowder also stressed that you could really get some interesting ideas by prompting tools like ChatGPT to pretend as though it were a conservative operative, using that exact kind of wording when asking for an analysis of poll results.\n\nLowder played videos of Steve Jobs giving a speech at Leeds University in 1985 that seem incredibly prescient 40 years later. Jobs predicted that one day, people might be able to have a conversation with Aristotle. The audience was audibly impressed by the late Apple co-founder’s predictions, instantly making the connection to tools like OpenAI’s ChatGPT.\n\nLowder told the audience about different kinds of AI tools they could use beyond ChatGPT, including Grok, which he noted was run by Elon Musk, “so it’s a little bit crazy and wild-eyed, and also a lot of fun.” He told the audience that his favorite tools were Perplexity, because of how it cited sources, and NotebookLM, because of the customization options.\n\nHe also recommended that anyone who needed to use sensitive documents download something like Jan.ai to run a model locally. Privacy can obviously be a major concern for political campaigns, and even the most green convention attendees seemed to understand that.\n\nOne man from the audience asked if he could ask ChatGPT about any secret information that may have been uploaded by Democrats. Lowder told him that wasn’t going to work, but noted that Republicans shouldn’t upload anything sensitive.\n\nLowder said that AI could make people nervous because they consider it creepy, especially given how it’s now being portrayed in popular media. And while he understood where that unease was coming from, it was vital for the conservative movement to embrace it if they wanted to win elections.\n\nLowder had AI write some social media posts, generating bullet points about innovation and the free market. One of the examples that came back was, “Let’s keep those incentives flowing to watch innovation as it transforms our world.” Lowder then showed how he asked the bot to punch up the language to make it “shorter” and more “edgy” but it spit out something that was too over the top: “We’re here to dominate, innovate, and conquer in the free market. In the free market jungle.”\n\n“So I was like, ‘Eh, I don’t know if I want my candidate to say we’re here to dominate that.’ You know, Trump can say that, but maybe not everybody, right?” Lowder said, to a laugh from the audience.\n\nEven though Lowder is clearly all-in on Trump and Trumpism, it was interesting to hear him talk in what might be considered more old-school Republican language. When Lowder was asked about the biases that may be present in the major AI chatbots, he talked about the notorious example when Google’s Gemini generated images of American founding fathers as Black in early 2024. But Lowder was quick to note that all of the big tech companies just want to make a product that works as they seek to dominate the space.\n\nThe problem with so many AI chatbots, as Lowder sees it, is that they’re trained on the internet, which apparently has a liberal bias. “I would guess it probably leans left. The reality is all these models were trained basically on the internet, right? And the internet leans left,” Lowder said. But he insisted that the free market would sort it all out. That’s not quite how Trump sees the world these days, as he gobbles up 10% of Intel.\n\nLowder also showed off how AI image tools could be used to clean up campaign photographs, using a failed local politician, former Republican Rep. Michelle Steel, as an example in his slides. Lowder said that if you took a photo for a campaign and wanted to remove a tattoo, that was something AI could help you with, showing the audience before and after photos of the “unwanted tattoo.”\n\nDuring the 2024 race, Steel lost to her opponent, Democrat Derek Tran, by an extremely close margin in Orange County. How close? Just 653 votes. Steel had compared Tran to Mao Zedong and used hammer and sickle imagery in mailers. Tran is the son of Vietnamese refugees who fled the Communist country, making her attack particularly weird. But it’s unclear if she actually used AI to remove any tattoos from her own campaign mailers. That may have just been a hypothetical on Lowder’s part, who insisted he didn’t actually have anything against tattoos.\n\nLowder came across as knowledgeable and reasonable when it came to the possibilities and limits of AI, but he did show the limits of his knowledge at times, including when he suggested that he could tell when something was written by AI just because it used an em dash. Or, as he called it, a long hyphen.\n\n“We all laugh at each other when we can see somebody send us an email or a leftist candidate puts a quote in that we can tell is generated by GPT,” Lowder told the audience. “You know how you can tell it’s GPT? GPT loves really big hyphens. So if you see really big hyphens, and they use them a lot, it’s definitely a GPT thing, I guarantee you.”\n\nAgain, they’re called em dashes. And the reason that AI chatbots like to use em dashes is because 30- and 40-somethings love to use em dashes. People jokingly refer to them on social media as “millennial em dashes” for a reason. In fact, President Donald Trump sometimes uses em dashes in his Truth Social posts. But that’s not because Trump is using AI. It’s almost certainly because Trump often dictates his posts to a person, and during the 2024 presidential campaign, that person was Natalie Harp, his 34-year-old assistant. Is it possible that Trump uses AI? Sure. But the more likely explanation is that his millennial assistant is just showing her love for millennial em dashes.\n\nLowder clearly believes that AI is a powerful tool. And any Republican who resists embracing platforms like Perplexity, ChatGPT, and NotebookLM is bound to be left in the dust.\n\n“The bottom line is we have to get over that nervousness and we have to engage with the technology because if we don’t, there’s gonna be consequences, right?” Lowder said. “It’s not going anywhere.”\n\nAnd however you feel about AI personally, Lowder’s perspective is one shared by just about every political operative across the spectrum right now. You may like AI, you may hate it. But even if the AI bubble were to burst tomorrow, it really feels like a technology that will be around in some form for many years to come. The question is just how Lowder and his opponents decide to get with it.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/republican-plan-to-use-ai-in-2026-2000655153",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Why I stopped overclocking my CPU after years of enthusiasm",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/cpu-overclocking-is-mostly-dead/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "macOS Tahoe RC Now Available With New Features For Mac Users",
      "content": "After the iPhone 17 event, Apple made the Release Candidate version of macOS Tahoe available. With that, the company is days away from launching one of the biggest macOS releases since Big Sur. At that time, the company was about to unveil the first M1 Macs. Now, it's preparing to stop supporting Intel computers, as the focus will shift completely to Macs with its own processors.\n\nHowever, more than just offering a final glimpse of the future of macOS to Intel Mac users, Apple designed software that's more integrated with iOS and iPadOS than ever before. After all, macOS Tahoe features the new Liquid Glass design, which is also available on the other operating systems. Additionally, Apple is adding new apps to the Mac, including Phone, Journal, and Preview.\n\nThat said, not only is Apple making the transition between hardware more seamless, but also better integrated. For example, iPhone Mirroring expands Live Activities to the Mac, so you can see when an Instagram post has been uploaded, when your Uber driver is arriving, or how your team is performing in a big game, all from your Mac's display.",
      "source": "BGR",
      "url": "https://www.bgr.com/1963608/macos-tahoe-rc-download-now-available/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "This Dell Inspiron laptop with Intel Core 7 is a steal for only $600",
      "content": "Finding an everyday laptop that’s good enough to get you through your days without costing a fortune can be tough—unless you let us do the hard work for you. I just found this Dell Inspiron 14 laptop that’s perfect as a daily driver, and it’s extremely affordable right now with this sale: Dell is selling it for $599.99 via its online shop (was $899.99).\n\nThis isn’t some weak configuration either. You’re looking at a more-than-decent 2024-era Intel Core 7 150U processor with 10 cores, plus 16GB of speedy DDR5 RAM, plus a spacious 1TB SSD that’s plenty for all your apps, files, photos, and even videos. This config will comfortably run Windows 11 Home (which comes pre-installed) without choking or slowing to a crawl, making sure it doesn’t impact your productivity.\n\nIt’s relatively compact for a laptop, with a 14-inch IPS screen at a crisp 2.2K resolution (that’s 2240×1400), a reasonable weight of 3.44 pounds, and an okay thickness of 0.74 inches. You should be able to lug this around without breaking a sweat, and that display should be adequate (though not great) with 300 nits of brightness.\n\nThis laptop lacks a dedicated graphics card so don’t expect to game much on it. It’s also rather light on connectivity, with just two USB-A ports and a USB-C video port with power delivery, plus an HDMI 1.4 port (only goes up to 1080p@60Hz) and a 3.5mm headset jack.\n\nIt’s far from the greatest machine ever, but it’s a darn good value now that it’s $300 off. Grab it for just $599.99 before this deal expires!\n\nSave $300 on this Dell Inspiron laptop with Intel Core 7 processor",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2903058/this-dell-inspiron-laptop-with-intel-core-7-is-a-steal-for-only-600.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "New Intel executive reshuffle sees products chief Holthaus leave after 30 years",
      "content": "Intel’s Michelle Johnston Holthaus leaves the company after 30+ years\n\nFurther leadership roles appointed, including a new hire\n\nCEO Lip-Bu Tan wants to flatten company leadership\n\nSenior Intel exec Michelle Johnston Holthaus will be departing the company after more than three decades, including a short stint as interim co-CEO with David Zinsner after ex-CEO Pat Gelsinger’s departure.\n\nHolthaus’ most recent role as Chief Exec of Products comes to a close after 10 months, and the company will not be rehiring for this role.\n\nAcknowledging Holthaus’ transformational impacts, new CEO Lip-Bu Tan noted: “She has made a lasting impact on our company and inspired so many of us with her leadership.”\n\nIntel announces major leadership shakeups\n\nThe company also announced the appointment of Kevork Kechichian as EVP & GM of Data Center Group, bringing more than 30 years’ chip industry experience from Arm, NXP Semiconductor, Qualcomm and more.\n\nJim Johnson becomes SVP & GM of Client Computing Group after around four decades at Intel, Srinivasan Iyengar becomes the head of a new Central Engineering Group, and Naga Chandrasekaran steps up at EVP & CTO of Intel Foundry to oversee development, manufacturing and go-to-market.\n\nThe changes come amid Intel’s ongoing efforts to flatten its hierarchical structure, resulting in more leaders reporting directly to Tan. By streamlining operations, cutting jobs and rebuilding its engineering culture, Tan hopes Intel can reposition itself to succeed going forward.\n\nThe news comes a couple of weeks after Intel reached an agreement with President Trump, whereby the US Government would invest $8.9 billion in Intel to help strengthen its position and bolster domestic American manufacturing.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nA move that has drawn its fair share of public scrutiny, including remarks made by Intel itself about the potential implications of having such political backing.\n\nIntel shares are up 21% this year to date, but the company’s market cap ($113.87 billion) falls far behind that of Nvidia ($4.097 trillion), now ranked as the world’s most valuable company.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/new-intel-executive-reshuffle-sees-products-chief-holthaus-leave-after-30-years",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel ousts CEO of Products as part of the latest executive shake-up, ending 30-year career — company also establishes new custom chip design unit",
      "content": "Intel has removed its chief executive officer of products, Michelle Johnston Holthaus, as part of a major shake-up of the executive branch of the embattled chip firm, according to Reuters. This is part of new CEO Lip-Bu Tan's plan to reshape the company under his leadership, flattening the leadership structure so he makes more of the important decisions about day-to-day operation.\n\nSince joining Intel in March this year, CEO Lip-Bu Tan has been a controversial figure. He's presided over mass firings and had to walk a fine line with shareholders, executives, and the U.S. administration, after his ties to Chinese businesses came to light. But in his short time at Intel he's made sweeping changes, laying off hundreds of engineers and chip designers, killing Intel's automotive division, and cutting middle management in chip fabrication teams.\n\nHolthaus is the latest high-profile figure at Intel to get the axe, ending a 30-year career at Intel, but a mere 10 months in her CEO of products role, and a temporary position as co-CEO after the previous CEO, Pat Gelsinger, suddenly left in 2024.\n\n\"Throughout her incredible career, Michelle has transformed major businesses, built high-performing teams and worked to delight our customers,\" Tan said in a statement. \"She has made a lasting impact on our company and inspired so many of us with her leadership. We are grateful for all Michelle has given Intel and wish her the best.\"\n\nIntel has said Holthaus will remain with the company in an advisory role, but her position will not be filled by anyone else.\n\nWhat Intel is doing, though, is bringing in executives from elsewhere, including one who worked at Tan's previous endeavour, Cadence. Srinivasan Iyengar joined the company in June and will take on the role of head of a new central engineering division.\n\nThis group will focus on developing a new custom silicon business for external customers. Although Intel's fabrication business has been one of its worst-performing in recent years, and there are still talks of it selling large portions of it, it's found a new lease of life following U.S. government investment and Bu Tan's leadership.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nWith Iyengar's new role, though, it's possible we'll see Intel designing chips for customers, rather than merely producing them. That could see it compete against the likes of Broadcom and Marvell. With Tan pushing for a faster, leaner business overall, Iyengar will report directly to him in his new role.\n\nIntel also announced that it had acquired the services of former executive vice president of solutions engineering at Arm, Kevork Kechichian. He'll begin heading Intel's datacenter group, and brings years of experience at ARM, NXP Semiconductor, and Qualcomm.\n\nAll of this comes at a both turbulent and rather bizarre time for the company. It has recently secured swifter funding as part of the CHIPS Act under the Trump administration's restructuring of how that fund works. But to get it, Intel had to agree to give the government a 10% stake in the company.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/intel-ousts-ceo-of-products-as-part-of-the-latest-executive-shake-up-ending-30-year-career-company-also-establishes-new-custom-chip-design-unit",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Acer unveils superlight Travelmate X4 14 AI laptop with an OLED display and Wi-Fi 7 connectivity",
      "content": "Acer TravelMate X4 14 AI unveiled at IFA 2025 with Intel Core Ultra processors\n\nWeighs 1.27kg, offers up to 32GB memory, 1TB storage, and OLED display option\n\nFeatures Wi-Fi 7, Thunderbolt 4 ports, and 65Wh battery rated 12 hours\n\nAcer has taken the wraps off a number of new products at IFA 2025, including the TravelMate X4 14 AI, lightweight Windows 11 Pro laptop aimed at small and medium businesses.\n\nThe Copilot+ PC (model TMX414-51) is powered by Intel’s Core Ultra Series 2 processors, with options ranging up to the Core Ultra 7 258V, and can reach up to 115 TOPS of overall performance.\n\nGraphics come from integrated Intel Arc, with configurations including Arc 130V and Arc 140V.\n\nAdvanced hardware and modern processors\n\n“As AI is becoming increasingly important in modern business workflows, small and medium businesses need devices that integrate intelligent tools, robust security, and mobility,” said James Lin, General Manager, Notebooks, Acer.\n\n“The TravelMate X14 AI was designed to deliver just that, powered by the latest Intel Core Ultra processors and Copilot+ PC experiences, offering professionals a lightweight yet durable solution crafted to accelerate productivity and collaboration from anywhere.”\n\nThe business laptop weighs 1.27kg and measures 15.9mm thick. It meets MIL-STD 810H testing standards covering vibration, humidity, and temperature extremes.\n\nThe system is available with up to 32GB of LPDDR5X memory and up to 1TB of PCIe Gen4 SSD storage.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe 14-inch screen is available in two versions. Buyers can choose an IPS WUXGA display with 120Hz refresh and 100% sRGB coverage, or an OLED WUXGA display with 120Hz refresh, 500 nits peak brightness, 100% DCI-P3 color, and VESA DisplayHDR True Black 500 certification.\n\nBoth panels use a 16:10 aspect ratio. An FHD webcam with IR support is included, paired with a built-in shutter for privacy.\n\nAcer has also included UserSensing 2.0, which dims and locks the screen when the user steps away. Other security features include a discrete TPM, Acer ProShield Plus, and support for a Kensington Nano lock. The laptop also carries TCO and EPEAT compliance.\n\nMark Linton, Vice President, Windows + Devices at Microsoft, said, “The Acer TravelMate X14 AI demonstrates what’s possible when advanced hardware and modern processors come together. With powerful performance, enhanced security, and unique AI experiences, it’s an ideal choice for today’s professionals looking to upgrade to a PC that prioritizes portability and performance.”\n\nConnectivity includes Wi-Fi 7, Bluetooth 5.4, two Thunderbolt 4 ports, two USB-A ports, HDMI 2.1, an audio jack, and a Gigabit Ethernet jack.\n\nThe 65Wh battery supports fast charging and is rated at up to 12 hours of use under MobileMark 2025 testing.\n\nThe laptop also integrates Acer PurifiedView 2.0 for improved video calls, along with PurifiedVoice 2.0, DTS:X Ultra Audio speakers, and a triple microphone array.\n\nThere's no word on pricing or availability yet - but we should know more soon.\n\nAcer TravelMate X4 14 AI | Boost SMB with AI Performance | Acer - YouTube Watch On",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/acer-unveils-superlight-travelmate-x4-14-ai-laptop-with-an-oled-display-and-wi-fi-7-connectivity",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel reshuffle puts engineering and 'a new custom silicon business' in the spotlight but also ends a 30-year career at Intel for Product CEO Michelle Johnston Holthaus",
      "content": "Things are, once again, all shake-up at Intel. After a new CEO, tons of layoffs, an increased focus on the Foundry side of the business, and other changes, Intel is sticking on-brand and making even more changes, this time to executive leadership. And while the biggest news for many might be that Intel Products CEO Michelle Johnston Holthaus is leaving, what's particularly interesting is the company is starting a new group that will focus on a new custom silicon business.\n\nIn addition to these two things, Intel also announced that Jim Johnson will lead the Client Computing Group (CCG), Kevork Kechichian from Arm will join to lead Intel's Data Center Group (DCG), and Intel Foundry CTOO Naga Chandrasekaran will also cover Foundry Services.\n\nThe custom silicon business that's perhaps of most interest is to be headed up by senior VP and Fellow Srini Iyengar. Iyengar joined Intel earlier in the year after being a Fellow at Cadence Design Systems, which is of note because Intel CEO Lip-Bu Tan was previously CEO of Cadence until 2021.\n\nThe new group will apparently be looking towards serving external customers: \"Intel is also establishing a new Central Engineering Group led by Srinivasan (Srini) Iyengar, a senior vice president and Fellow. In his expanded role, Iyengar will lead horizontal engineering functions and build a new custom silicon business to serve a broad range of external customers.\"\n\nIf it pans it, this could certainly be a good move for Intel. Hearing the words \"custom silicon\" for \"external customers\" in 2025 triggers obvious thoughts of AI, as well as chasing down TSMC's foundry dollar. Data centres are increasingly gobbling up AI workloads and thus far Nvidia has been the company to reap the bulk of the rewards from that.\n\nIntel CEO Lip-Bu Tan conducting a keynote address. (Image credit: Intel)\n\nFrom his very first earnings call, Tan made it clear that Intel is going to look to cement itself in the AI market, although there's been no definite word over what exactly that means. Now, there's some reason to suppose that will mean custom AI silicon for data centers. Intel Foundry could certainly do with something of the sort to stake a bold new claim to after the past few years and especially months of troubled waters. But it really needs customers onboard.\n\nNo doubt extra incentive to push into Intel Foundry comes from the recent 10% buy-in from the US government, which is under the stipulation that Intel must own at least 51% of its Foundry for five years. In other words, there can be no back-up plan to scarper and sell.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAs far as we're concerned as PC gamers, it could be good news, too. Emphasis on \"could\" there, but a push into AI accelerators, for instance, would presumably give Intel a lot of R&D as well as actual GPU silicon to trickle down into its gaming division. Just like Nvidia with Blackwell and the RTX 50-series. Though I suppose that analogy should show us such a development might not necessarily spell any improvements for GPU prices. At any rate, changes are afoot.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/graphics-cards/intel-reshuffle-puts-engineering-and-a-new-custom-silicon-business-in-the-spotlight-but-also-ends-a-30-year-career-at-intel-for-product-ceo-michelle-johnston-holthaus/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Qualcomm Snapdragon X Elite Linux Performance Improving But Short Of AMD Ryzen & Intel Core Ultra",
      "content": "Back in May we provided an initial look at the Qualcomm Snapdragon X Elite laptop performance on Ubuntu Linux with the upstream support for the Qualcomm Snapdragon X1E maturing, more laptops becoming supported, and the Ubuntu X1E \"Concept\" ISOs enhancing the end-user experience. The performance was okay but short of expectations. Months later we are revisiting the Qualcomm Snapdragon X Elite Linux performance on the newest Ubuntu Concept ISOs and newer firmware that is providing a much better experience albeit still not as competitive as the newest AMD Ryzen AI 300 series and Intel Core Ultra laptops under Linux.\n\nSince the May testing, the Qualcomm Snapdragon X Elite Linux testing was experiencing a hiatus... Newer Ubuntu X1E Concept ISOs were failing to properly work on the Acer Swift AI 14 laptop that I had purchased to carry out these Linux tests. Repeatedly the new refreshed media for several months failed to boot properly on the laptop due to Device Tree issues and/or other problems over time. Fortunately, the newest Ubuntu X1E Concept ISOs from late August fixed those problems. So I have been able to carry out clean, working installs of Ubuntu again on this Acer Swift 14 AI laptop powered by an X1 Elite SoC.\n\nThe \"plucky-desktop-arm64+x1e-20250827.iso\" as the newest as of testing now has everything in place so the laptop I have been using for testing works out. Though caveats still apply like you will want to keep around the Microsoft Windows 11 on ARM installation in order to run qcom-firmware-extract for extracting the necessary firmware from the Windows partitions. Most Snapdragon X laptops still do not have any firmware permitted for redistribution in upstream linux-firmware.git and thus the workaround of needing to fetch it from a Windows partition is needed for getting features like GPU acceleration and other functionality working.\n\nKeeping the Windows 11 installation is also important for easily applying system firmware updates to the device itself. While working through these Ubuntu Linux woes on the Acer Swift 14 AI, a system firmware update came down and was applied that ended up being very important for multi-core performance as I'll be showing in this article.\n\nIt's far from a pleasant out-of-the-box experience but at least an easier route than the likes of Apple Silicon on Linux.\n\nFor today's benchmarking is a look at how the Qualcomm Snapdragon X Elite performance has evolved since the tests earlier this year and then followed by a comparison of the Acer Swift 14 AI up against an assortment of other Intel Core and AMD Ryzen laptops tested over the summer, all on Ubuntu 25.04 and tested within the Phoronix lab.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/review/snapdragon-x1e-september",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Repost: Make your development environment portable and reproducible",
      "content": "Getting Genetics Done, and kindly contributed to Want to share your content on R-bloggers? [This article was first published on, and kindly contributed to R-bloggers ]. (You can report issue about the content on this page here Want to share your content on R-bloggers? click here if you have a blog, or here if you don't.\n\nReposted from the original at https://blog.stephenturner.us/p/development-environment-portable-reproducible.\n\nYou upgrade your old Intel Macbook Pro for a new M4 MBP. You’re setting up a new cloud VM on AWS after migrating away from GCP. You get an account on your institution’s new HPC. You have everything just so in your development environment, and now you have to remember how to set everything up again.\n\nI just started a new position, and I’m doing this right now.\n\nSetting up a reproducible and portable development environment that works seamlessly across different machines and cloud platforms can save you time and headaches. These are a few of the strategies I use to quickly reproduce my development environment across machines.\n\nDotfiles in a GitHub repo New VM setup script in a GitHub repo R “verse” package on GitHub Dev containers in VS Code\n\nKeep your dotfiles in a private GitHub repo\n\nDotfiles are the hidden configuration files in your home directory. Examples include .vimrc for Vim, .tmux.conf for tmux, or .bashrc for your shell environment. I have a long list of aliases and little bash functions in a .aliases.sh file that my .bashrc sources. I also have a .dircolors , global .gitignore , a .gitconfig , and a minimal .Rprofile .\n\nKeeping these files in a GitHub repository makes it easy to quickly reproduce your development environment on another machine. If you search GitHub for “dotfiles” or look at the awesome-dotfiles repo, you’ll see many people keep their dotfiles in a public repo. I use a private repo, because I’m too scared I might accidentally commit secrets, such as API tokens in my .Renviron or PyPI credentials in .pypirc .\n\nWhenever you get a new machine or VM, getting things set up is easy:\n\n# Your private dotfiles repo git clone https://github.com/<yourusername>/dotfiles cd ~/dotfiles # A script to symlink things to your home ./install.sh\n\nKeep a fresh cloud VM setup script\n\nI started playing with computers in the 1990s. I’ve experienced enough hard drive failures, random BSODs, and other critical failures, that I treat my computer as if it could spontaneously combust at any moment and I could immediately lose all of my unsaved, un-backed-up work at any moment. I treat my cloud VMs the same way, as if they’re disposable (many times they are disposable, by design).\n\nImagine you launch a new cloud VM starting from a clean Ubuntu image. Now you need all the tools you use every day on this machine – vim, tmux, RStudio, conda, Docker, gcloud/gsutil, etc. Additionally, while I use conda to create virtual environments for installing tools for specific tasks, there are some domain-specific tools I use so often every day for exploratory analysis that I actually prefer having a local installation on the machine — things like bedtools, seqtk, samtools, bcftools, fastp, Nextflow, and a few others — instead of having to load a conda environment or use Docker every time I want to do something simple.\n\nI keep a script on GitHub that will install all the software I need on a fresh VM. Here’s an example setup script I use as a GitHub gist.\n\nI know this isn’t completely Reproducible™ in the sense that a Docker container might be, because I’m not controlling the version of every tool and library I’m installing, but it’s good enough to get me up and running for development and interactive data analysis and exploration.\n\nR: Custom “verse” package on GitHub\n\nThe tidyverse is probably the best known meta-package that installs lots of other packages for data science. Take a look at the tidyverse package DESCRIPTION file. When you run install.packages(\"tidyverse\") , it will install all the packages listed in the Imports field, including dplyr, tidyr, purrr, ggplot2, and others.\n\nYou can use this pattern to create your own “verse” package that installs all your favorite packages. This is helpful for setting up a new machine, or re-installing all the R packages you use whenever you upgrade to a new major version of R.\n\nTake a look at my Tverse package on GitHub at github.com/stephenturner/Tverse, specifically at the DESCRIPTION file. In the Imports field I include all the packages I know I’ll use routinely. Note that this also includes several Bioconductor packages (which requires including the biocViews: directive in the DESCRIPTION), as well as one of my favorite packages, breakerofchains, that is only available from GitHub (requiring the Remotes: entry).\n\nOnce this package is pushed to GitHub I can easily install all those packages and their dependencies:\n\ndevtools::install(\"stephenturner/Tverse\")\n\nDev containers in VS Code\n\nDevelopment containers (dev containers) allow you to create and use consistent development environments using Docker containers. It allows you to open any folder inside (or mounted into) a container and take advantage of Visual Studio Code’s full feature set. This is particularly useful when working with teams or switching between projects with different dependencies.\n\nThe dev container docs and tutorial are both good places to start. You’ll need to have Docker running, and install the Dev Containers VS Code extension.\n\nFrom Microsoft’s documentation:\n\nWorkspace files are mounted from the local file system or copied or cloned into the container. Extensions are installed and run inside the container, where they have full access to the tools, platform, and file system. This means that you can seamlessly switch your entire development environment just by connecting to a different container.\n\nFrom Microsoft’s dev containers documentation .\n\nUsing a dev container template\n\nYou can use any pre-built dev container templates available on registries like Docker Hub or Microsoft’s container registry. Here’s an example using Rocker with R version 4.4.1, and adds a few extensions to VS Code running in the container. You could also create your own container for development, put that on Docker Hub, then use that image.\n\n{ \"image\": \"rocker/r-ver:4.4.1\", \"customizations\": { \"vscode\": { \"extensions\": [ \"REditorSupport.r\", \"ms-vscode-remote.remote-containers\" ] } } }\n\nUsing a custom Dockerfile\n\nYou can use a custom Dockerfile to create your dev container. First, create a .devcontainer/ directory in your project with a Dockerfile and a devcontainer.json file. Define your development environment in the Dockerfile (base image, installed packages and configuration). In the JSON replace the image property with build and dockerfile properties:\n\n{ \"build\": { \"dockerfile\": \"Dockerfile\" } }\n\nStart VS Code running the container\n\nAfter you create your devcontainer.json file (either from a template or completely custom), open the folder in the container using the command palette:\n\nAnd prove to yourself that your VS Code environment is indeed using the container (I’m using rocker R 4.4.1 here). Running whoami shows I’m root inside the container (not my own username), and I’m indeed running R version 4.4.1.",
      "source": "R-bloggers.com",
      "url": "https://www.r-bloggers.com/2025/09/repost-make-your-development-environment-portable-and-reproducible/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Reorg Puts 40-Year Vet in Charge of PC Group",
      "content": "Intel announced a corporate reorganization that puts Jim Johnson, a 40-year veteran of the company, in charge of the Client Computing Group responsible for its x86-based chip designs for PCs. He was previously serving in this role in an interim basis.\n\n“Jim’s steady leadership and trusted relationships across the computing industry are driving continued progress in our client business as we prepare to launch a new generation of products,” Intel CEO Lip-Bu Tan said.\n\nThurrott.com readers may recognize Johnson as the face of “Lunar Lake,” the controversial—and, I would argue, unsuccessful—attempt to quickly scale Intel’s x86 silicon to battery compete with more efficient Arm-based designs. He anchored the Intel announcement event for Lunar Lake at last year’s IFA in Berlin, Germany. And then he appeared at the Lenovo Innovation World press conference at this year’s show, which was held last week.\n\nHis appearance at Lenovo Innovation World was, to put it mildly, awkward, though he gets an A for confidence and staying on-message.\n\n“With Core Ultra Series 2 [Lunar Lake], we re-engineered the CPU, the GPU, and the NPU and delivered faster compute, improved AI experience, and busted the myth that x86 can’t be power efficient,” Johnson said at the event, which is available for rewatching on YouTube. Here, he paused, presumably for applause.\n\nIt never came. As most in the audience understood, and as my unpredictable and mostly lackluster experiences with Lunar Lake-based PCs show, this isn’t the home run that Johnson promoted. Lunar Lake is more efficient than previous Intel chips, but it’s also incredibly unreliable and unpredictable. Indeed, Lunar Lake is such a disaster that Intel will never make a chip design like it again, and it loses money on every unit sold. Subsequent Core Ultra Series 2 designs have all used different architectures.\n\nTo be clear, this is no one person’s fault in the sense that a cascading series of strategic mistakes over a decade or more led to Intel’s problems today. The company was forced to rush Lunar Lake to market so it could have a Copilot+ PC-compatible chip to compete with more efficient designs from AMD and Qualcomm.\n\nAnd Johnson wasn’t in charge of Intel’s Client Computing Group at that time. Michelle Johnston Holthaus was. And as it turns out, she’s leaving Intel as Johnson is elevated into her former role. She had become CEO of Intel products briefly, after Pat Gelsinger, the previous Intel CEO, left the company.\n\n“Throughout her incredible career, Michelle has transformed major businesses, built high-performing teams, and worked to delight our customers,” Tan said. “She has made a lasting impact on our company and inspired so many of us with her leadership. We are grateful for all Michelle has given Intel and wish her the best.”\n\nAs part of the reorg, Intel also revealed that Naga Chandrasekaran, the executive vice president and chief technology and operations officer of Intel Foundry, will expand his role to include Foundry Services. He joined Intel last year after a stint at Micron.\n\nIntel is also creating a new Central Engineering Group that will “build a new custom silicon business to serve a broad range of external customers.” This will be led by Srini Iyengar, who joined Intel this past June. And former Arm executive Kevork Kechichian has joined Intel as executive vice president and general manager of the Data Center Group (DCG).\n\nChandrasekaran was already reporting directly to the Intel CEO, and now Johnson, Kechichian, and Iyengar will as well, Intel says.",
      "source": "Thurrott.com",
      "url": "https://www.thurrott.com/hardware/326233/intel-reorg-puts-40-year-vet-in-charge-of-pc-group",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "What I learned while optimizing my RAM timings for better PC performance",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/improve-your-ram-timings/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel CFO talks 14A production, says US stake removes CHIPS grant ‘handcuffs’",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_58f88a00-b09b-4ae4-84d0-2a0527c07026",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 \"Battlemage\" Nears Launch as Intel Prepares Packaging",
      "content": "Intel plans to complete its Arc \"Battlemage\" lineup with the highest-performing B770 SKU. Thanks to @Haze2K1 on X, we found shipping manifests dated June 11, 2025, which list BMG-G31 GPU dies packed in boxes with dimensions matching those used before the Arc B580 launch. Last time with B580, the launch happened 2.5 months after these shipping manifests appeared. The current rumor mill suggests that the card will utilize 32 Xe2 cores with 16 GB of memory on a 256-bit bus, providing it with a clear capacity edge over many 8 GB rivals from AMD and NVIDIA, like the RTX 5060 Ti and RX 9060. The BMG-G31 die is bigger than the BMG-G21 used in the B580, B570, and Arc Pro parts, which explains the larger crates. Extra silicon could enable higher clocks, stronger ray tracing, and a wider memory interface, though thermal management and power draw will matter. Early samples and firmware checks will set the final timing and availability soon.Timing will determine how much impact the Arc B770 can have, because AMD and NVIDIA already control much of the upper mid-range and high-end segments. NVIDIA \"SUPER\" refreshes of the current \"Blackwell\" only raise the pressure on Intel to be both performance competitive and well priced. Battlemage has already shifted pricing expectations in the market before, compelling rivals to rethink memory configurations and price points. Intel has also shown steady improvement in its driver updates and software support, which has narrowed historical gaps in user experience. Rumors pointing to a Q4 2025 debut would put the card into the usual holiday buying window, but to convert gamer's interest into real market share, Intel will need an aggressive pricing strategy and solid supply.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340802/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "QNAP’s new NAS hardware features Intel N150 or Core 3 N355 inside",
      "content": "QNAP may be one of the biggest names in the network-attached storage business, but many of the company’s consumer-grade products tend to ship with years-old processors that can hamper performance.\n\nSo it’s nice to see that QNAP has finally introduced new systems powered by Intel Alder Lake-N/Twin Lake processors. The new QNAP Qu405, Qu605, and Qu805 feature between four and 8 bays for hard drives and come with a choice of Intel N150 quad-core or Core 3 N355 octa-core processors.\n\nWhile these are technically new chips based on Intel Twin Lake architecture, there’s virtually no real difference between Twin Lake and Alder Lake-N, which means that even these processors are starting to show their age a bit – they’re basically 12th-gen Intel Core processors that were first released in early 2023 featuring four or more Efficiency cores and no Performance cores.\n\nBut they’re still a pretty good fit for network-attached storage devices that are meant for 24/7 stable operation thanks to a combination of low-power consumption and respectable performance. And they should bring pretty significant gains in CPU and graphics performance over the Intel Jasper Lake chips used in earlier models from QNAP.\n\nSo far QNAP has only introduced its new models with Twin Lake chips for the Chinese market, so it’s possible some specs or features could be different if and when these (or similar) systems become available in other regions.\n\nBut it looks like all of the new QNAP QuX05 series models announced in China will have a set of features that includes::\n\n1 x SODIMM slot for up to 16GB of DDR5 memory\n\n8GB of eMMC NAND flash storage\n\n4, 6 or 8 bays for 3.5 inch SATA HDDs (or 2.5″ drives with adapters)\n\n2 x M.2 2280 slots for PCIe Gen 3 SSDs (SSD cache acceleration is supported)\n\n2 x 2.5 Gb Ethernet ports\n\n1 x USB 3.2 Gen 2 Type-C port\n\n2 x USB 3.2 Gen 2 Type-A port\n\n1 x HDMI 2.1 port\n\nLike most NAS hardware, these new models typically ship without any hard drives or SSDs, but QNAP will at least four processor/memory configurations for each model:\n\nIntel N150 + 8GB\n\nIntel N150 + 16GB\n\nIntel Core 3 N355 + 8GB\n\nIntel Core 3 N355 + 16GB\n\nWithout knowing the global pricing for the new models, it’s hard to say how competitive they’ll be at a time when a growing number of companies are entering the NAS space with systems featuring decent hardware and affordable price tags. But it is nice to see an established brand like QNAP catching up in terms of hardware capabilities.\n\nvia TechPowerUp and NASCompares\n\nSupport Liliputing Liliputing's primary sources of revenue are advertising and affiliate links (if you click the \"Shop\" button at the top of the page and buy something on Amazon, for example, we'll get a small commission). But there are several ways you can support the site directly even if you're using an ad blocker* and hate online shopping. Contribute to our Patreon campaign or... Contribute via PayPal * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a guide that may help you disable it.",
      "source": "Liliputing",
      "url": "https://liliputing.com/qnaps-new-nas-hardware-features-intel-n150-or-core-3-n355-inside/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "(PR) Intel Announces Key Leadership Changes to Data Center and Client Computing Group",
      "content": "Intel Corporation today announced a series of senior leadership appointments that support the company's strategy to strengthen its core product business, build a trusted foundry, and foster a culture of engineering across the business.Kevork Kechichian has joined Intel as executive vice president and general manager of the Data Center Group (DCG). In this role, he will lead Intel's data center business across cloud and enterprise, including the Intel Xeon processor family.Kechichian brings more than 30 years of industry experience, and joins Intel from Arm, where he most recently served as executive vice president of engineering. At Arm, he led technology development with ecosystem partners and managed the company's transformation from IP licensing to delivering full-stack solutions. His previous leadership roles include senior engineering positions at NXP Semiconductors and Qualcomm.\"Kevork brings a powerful combination of strategic vision, technical depth, and operational rigor that will help us seize growth opportunities across the data center market,\" said Lip-Bu Tan, CEO of Intel.Jim Johnson has been appointed senior vice president and general manager of Intel's Client Computing Group (CCG), after successfully serving in the role on an interim basis. He will lead Intel's efforts to deliver innovative computing solutions and foster growth across the global PC and edge ecosystems.A 40-year Intel veteran, Johnson has held various engineering and leadership roles across the company, including in the Technology and Manufacturing Group, the Networking and Communications Group, and general manager of several global businesses and manufacturing plants.\"Jim's steady leadership and trusted relationships across the computing industry are driving continued progress in our client business as we prepare to launch a new generation of products,\" Tan said.Intel is also establishing a new Central Engineering Group led by Srinivasan (Srini) Iyengar, a senior vice president and Fellow. In his expanded role, Iyengar will lead horizontal engineering functions and build a new custom silicon business to serve a broad range of external customers.Iyengar joined Intel in June from Cadence Design Systems, where he led global silicon engineering. He brings deep technical expertise in custom silicon development and has worked closely with hyperscale data center customers to optimize solutions for key workloads.\"With Srini leading Central Engineering, we're aligning innovation and execution more tightly in service to customers,\" Tan said. \"We are laser-focused on delivering world-class products and empowering our engineering teams to move faster and execute with excellence. Kevork, Jim, and Srini are exceptional leaders whose deep technical acumen and industry relationships will be instrumental as we continue building a new Intel.\"Kechichian, Johnson, and Iyengar will report directly to CEO Lip-Bu Tan.Naga Chandrasekaran, executive vice president and chief technology and operations officer of Intel Foundry, will expand his role to include Foundry Services. This will create a more integrated structure spanning technology development, manufacturing and go-to-market to better serve customers. Intel consolidated technology development and manufacturing under Chandrasekaran's leadership earlier this year.Chandrasekaran joined Intel in 2024 from Micron, where he served as senior vice president for technology development. He brings decades of experience spanning the breadth of semiconductor manufacturing and R&D.\"Naga's strong leadership, combined with a more integrated foundry operating model, will help us enhance the quality of execution, collaboration and customer service across our foundry business,\" Tan said.Chandrasekaran will continue reporting to Tan. Kevin O'Buckley, continues as senior vice president and general manager of Foundry Services, reporting to Chandrasekaran.Additionally, Intel announced that Michelle Johnston Holthaus, chief executive of Intel Products, will depart after more than three decades with the company. Holthaus held numerous senior leadership roles, including interim co-CEO, executive vice president and general manager of CCG, and chief revenue officer. She will remain a strategic advisor over the coming months to ensure a seamless transition.\"Throughout her incredible career, Michelle has transformed major businesses, built high-performing teams and worked to delight our customers,\" Tan said. \"She has made a lasting impact on our company and inspired so many of us with her leadership. We are grateful for all Michelle has given Intel and wish her the best.\"",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340800/intel-announces-key-leadership-changes-to-data-center-and-client-computing-group",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 “Battlemage” Nears Launch as Intel Prepares Packaging",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "ACEMAGIC Kron Mini K1 review – Quite a capable mini PC",
      "content": "MetryGrow 48W LED Plant Grow Light review – makes sure your indoor plants get what they need",
      "source": "The Gadgeteer",
      "url": "https://the-gadgeteer.com/2025/09/09/acemagic-kron-mini-k1-review-quite-a-capable-mini-pc/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel announces leadership changes to strengthen execution and accelerate innovation",
      "content": "Intel announces leadership changes to strengthen execution and accelerate innovation\n\nIntel has announced a series of senior leadership appointments aimed at advancing its core product business, scaling its foundry operations, and reinforcing engineering capabilities across the company. The moves, which include new hires and expanded responsibilities for key executives, come as Intel continues its efforts to improve execution and sharpen competitiveness in the semiconductor industry.\n\nAccording to a press release, Kevork Kechichian has been named executive vice president and general manager of the Data Center Group, overseeing Intel's data center business spanning cloud and enterprise solutions, including the Xeon processor line. Kechichian joins from Arm, where he was executive vice president of engineering and led the company's transition from IP licensing to full-stack solutions. He previously held leadership roles at NXP Semiconductors and Qualcomm. Intel CEO Lip-Bu Tan said Kechichian brings a blend of \"strategic vision, technical depth, and operational rigor\" to the role.\n\nIn the Client Computing Group, Jim Johnson has been confirmed as senior vice president and general manager, following an interim tenure. A 40-year Intel veteran, Johnson has held engineering and management positions across multiple business units. Tan credited him with providing \"steady leadership\" as Intel prepares to launch a new generation of client computing products.\n\nIntel is also creating a Central Engineering Group led by Srinivasan (Srini) Iyengar, who joined the company earlier this year from Cadence Design Systems. Iyengar will oversee horizontal engineering functions and establish a custom silicon business serving external customers, particularly in the hyperscale data center market.\n\nIn its foundry operations, Intel said Naga Chandrasekaran, executive vice president and chief technology and operations officer, will expand his role to include Foundry Services. The change consolidates technology development, manufacturing, and go-to-market functions under a single leadership structure. Chandrasekaran, who joined Intel in 2024 from Micron, will continue reporting to Tan, while Kevin O'Buckley remains senior vice president and general manager of Foundry Services, reporting to Chandrasekaran.\n\nAlongside these appointments, Intel announced that Michelle Johnston Holthaus, chief executive of Intel Products, will depart after more than 30 years at the company. Holthaus held several senior leadership roles, including interim co-CEO, General Manager of the Client Computing Group, and Chief Revenue Officer. She will serve as a strategic advisor during the transition period. Tan praised her for transforming key businesses and inspiring teams across the company.\n\nMajor corporate restructuring continues\n\nIn March 2025, Intel named Lip-Bu Tan as its new CEO. Under his leadership, the company has embarked on a significant restructuring aimed at accelerating decision-making and bolstering technological leadership.\n\nTan's restructuring efforts have resulted in a flattened organizational hierarchy. Key business units, such as the Data Center and AI Group and the Client Computing Group, now report directly to the CEO. This change is intended to streamline the company's decision-making processes, enabling a more agile response to market demands in the highly competitive semiconductor industry.\n\nAdditionally, Intel appointed Sachin Katti as Chief Technology and AI Officer. Katti's responsibilities include overseeing the company's AI strategy and product roadmap as well as managing operations within the networking and edge computing division. This appointment reflects Intel's emphasis on expanding its AI capabilities and integrating advanced technologies across multiple sectors.\n\nChanges to the company's board have also been implemented. Three board members retired, reducing the total board size to 11. To reinforce its industry expertise, Intel added Eric Meurice, formerly the CEO of ASML, and Steve Sanghi, interim CEO of Microchip Technology, to its board. Both new members bring extensive experience in the chip manufacturing sector, which Intel aims to leverage in its ongoing transformation.\n\nArticle edited by Jack Wu",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250909VL202/intel-management-personnel-business.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Watch The PC Gamer Streamer Showdown live today on Twitch",
      "content": "Are you ready?\n\nThe PC Gamer Streamer Showdown kicks off today, a three-day triathalon of gaming competition between eight talented streamers. Watch live on twitch.tv/pcgamer beginning at 12 noon ET / 9 AM PT / 5 PM BST or on the streams of any of our eight competitors.\n\nWins in these three games aren't the only thing that our streamers are fighting for, they're also vying for \"Cool Points\" that add to their overall tournament performance, earned by completing special challenges within matches like registering a perfect round in Street Fighter 6 or finding the Bugle of Friendship in Peak. For more details read here.\n\nHere's a breakdown of the match schedule for September 9, 10, and 12.\n\nThe weeklong schedule of competition. (Image credit: PC Gamer)\n\nThe lineup of competitors is a talented set of variety streamers:\n\nBarefootTasha twitch.tv/barefoottasha\n\nKingGothalion twitch.tv/kinggothalion\n\nAplFisher twitch.tv/aplfisher\n\nRIPMika twitch.tv/ripmika\n\nAsh IV twitch.tv/ashiv_\n\nElainaExe twitch.tv/elainaexe\n\nDish twitch.tv/dish\n\nunCAGEDgamez twitch.tv/uncagedgamez\n\nOur brave contestants. (Image credit: Future)\n\nThe PC Gamer Streamer Showdown is powered by OMEN. Watch all week long for a chance to win an OMEN Max 16 laptop, valued at more than $3000! On the final day of the tournament, a viewer of the winning streamer will be randomly selected to win.\n\nLaptop specs and features include:\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n(Image credit: OMEN)",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/games/pc-gamer-streamer-showdown/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Delta Force Reveals New Operator Raptor Ahead Of Next Season",
      "content": null,
      "source": "Bleeding Cool News",
      "url": "https://bleedingcool.com/games/delta-force-reveals-new-operator-raptor-ahead-of-next-season/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "What to know about the Trump administration's Intel investment",
      "content": null,
      "source": "Quartz India",
      "url": "https://qz.com/federal-government-investing-semiconductor-business-intel",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Synopsys reports quarterly revenue below estimates, shares fall",
      "content": "(Reuters) -Chip design software provider Synopsys (SNPS) missed Wall Street estimates for third-quarter revenue on Tuesday, hurt by weakness in its Design IP business, sending shares down 20% in premarket trading on Wednesday.\n\nThe segment includes Synopsys' interface, security and embedded processor intellectual property, along with IP implementation services.\n\nThe underperformance in the segment was caused by deals that did not materialize, largely due to new export restrictions disrupting design starts in China and challenges at a major foundry customer, CEO Sassine Ghazi said on a post-earnings call.\n\nIn early July, the United States lifted restrictions on exports to China for chip design software developers, which had been imposed in late May.\n\nSynopsys had made significant investments in building out IP for the foundry customer, with expectations for returns in the second half of 2025, Ghazi said on the call. However, the customer pulled out due to market and client-related reasons.\n\nSynopsys, which counts companies such as Nvidia, Intel and Qualcomm among its partners, provides software and hardware used to design advanced processors.\n\nSunnyvale, California-based Synopsys completed its $35 billion cash-and-stock acquisition of engineering design firm Ansys in July, after receiving conditional approval from China's market regulator. The deal, announced early last year, faced intense antitrust scrutiny in markets including Britain.\n\nThe company reported revenue of $1.74 billion for the third quarter ended July 31, missing analysts' estimates of $1.77 billion, according to data compiled by LSEG.\n\nOn an adjusted basis, Synopsys reported a profit of $3.39 per share, also below estimates of $3.74 per share.\n\nSynopsys projected current-quarter revenue between $2.23 billion and $2.26 billion, while analysts expect $2.09 billion.\n\nRival Cadence Design Systems raised its annual sales and profit forecast in July.\n\n(Reporting by Juby Babu in Mexico City; Editing by Mohammed Safi Shamsi)",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/synopsys-reports-quarterly-revenue-below-233110633.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Shipped \"Panther Lake\" Processors to Samsung for Galaxy Book Laptops",
      "content": "According to the NBD shipment manifests, Intel has shipped its upcoming \"Panther Lake\" processor family to Samsung for its Galaxy Book laptops as early as May this year. This indicates that the final integration of Intel's latest design is complete and that Samsung has already incorporated these processors into its Galaxy Book line. The leaked shipping manifests show a BGA2540 processor, which corresponds to Panther Lake and is described as an integrated chip for a Samsung laptop. This confirms that the Galaxy Book is set to receive a Panther Lake update. However, the specific SKUs that will power the Samsung Galaxy Book laptops remain unknown for now.The low-power PTL-U models are designed for a 15 W TDP and are expected to come in 6-core and 8-core versions. Some SKUs will feature four high-performance P-cores paired with four LPE-cores, while others will have only two LPE-cores complementing four P-cores. Both families will utilize Xe3-based integrated graphics, with entry models featuring four GPU cores. The more powerful PTL-H line will scale up to around 16 CPU cores, comprising four P-Cores, eight E-cores, and four LPE-cores. Some H-series parts might include up to 12 GPU cores for integrated graphics, but the final configurations will be revealed when Intel officially launches the Panther Lake product family. At IFA 2025 in Berlin, Acer was the only OEM to showcase a Panther Lake-powered laptop, the Swift 16 AI . We will have to wait for Samsung's official announcement to learn more about the remaining specifications, such as SKU choices, screen, memory, and storage configurations.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340805/intel-shipped-panther-lake-processors-to-samsung-for-galaxy-book-laptops",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "QNAP Intros QuNAS Series with Intel Core 3 N355 Twin Lake CPUs",
      "content": "QNAP has unveiled its new QuNAS series of network-attached storage systems featuring Intel's latest Twin Lake architecture processors launched in January this year. The lineup centers around the Intel Core 3 N355 CPU , an 8-core, 8-thread processor with a 15 W TDP that can boost up to 3.9 GHz. The series flagship QNAP Qu805-N355 model measures 165 × 217 × 285 mm and can hold eight 3.5-inch SATA drives with hot-swap capability, supporting both 2.5-inch SATA SSDs. Memory configurations include 8 GB or 16 GB DDR5 SODIMM options, with 8 GB eMMC NAND flash for boot storage. Two M.2 2280 slots support NVMe PCIe Gen 3 x1 SSDs for additional storage expansion. Connectivity features dual 2.5 Gigabit Ethernet ports, three USB 3.2 Gen 2 ports including one Type-C connector, and HDMI 2.1 output capable of 4K resolution at 60 Hz. The system draws 102.78 W during typical operation from a 150 W external adapter.The series is complemented with six-bay (Qu605, 165 × 217 × 226 mm, 84.42 W) and four-bay (Qu405, 165 × 217 × 168 mm, 62.69 W) models. QNAP also offers Lite variants powered by the Intel N150 quad-core processor running at 3.6 GHz while maintaining similar feature sets. Exact pricing and availability are yet to be known since the series is currently listed only on the QNAP Chinese official website.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340809/qnap-intros-qunas-series-with-intel-core-3-n355-twin-lake-cpus",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Announces Key Leadership Changes to Data Center and Client Computing Group",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/intel-announces-key-leadership-changes-to-data-center-and-client-computing-group/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Steve Bannon Rages: Young Republicans Want Nationalized Health Care",
      "content": "Real America's Voice Steve Bannon was livid that young Republicans have so many liberal and socialist views when it comes to healthcare, wealth and industry.\n\nMedicare for all looks good, right young MAGA's?\n\nA new Rasmussen poll couldn't appease Bannon's annoyance with the reults\n\nRasmussen usually are the most pro-Trump polls in America\n\nMITCHELL: Well, here's a really good example. This is an 18 to 39 year old likely voter survey.\n\nI have to thank the folks at Stopping Socialism, Justin Haskins, the Heartland Institute for sponsoring this. It's free. People can go to RasmussenReports.com, download the cross tabs, because there's a lot of stuff in here.\n\nBut here's one example. This is a sample that we weighted to a Trump minus four recalled vote.\n\nThis is how it looked in November. Do you agree or disagree with this statement?\n\nMajor industries like healthcare, energy, and big tech should be nationalized to give more control and equity to the people.\n\nIf the Zoomers were really based, that number should be a pretty low number, but it's not. 76% of 18 to 39 year olds at least somewhat agree with that.\n\nAlmost 40% strongly agree, but here's the problem. It's not just the Democrats. 78% of self-ID'd Republican young people who want major industries like healthcare and tech nationalized.\n\nThat's absolutely insane.\n\nAnd it's a vast majority of Trump 2024 voters. So people did not vote for Trump because they're conservative. Yes, 79% of Trump 2024 voters want to nationalize major industries. We have 57% of Trump 2024 voters wanting excess wealth confiscation.\n\nThese people are not just going to be happy with, you know, let's cut a few regulations.\n\n--\n\nBANNON: If that's the way, and I keep telling, if that's the system you want, you're going to get Luigi on one end or you get Mondami on the other.\n\nOkay.\n\nYou've brought this on yourself.\n\nI don't know.\n\nI back these kids in that they don't know the details of change, but it has to change.\n\nDo we have to nationalize tech or big health?",
      "source": "Crooksandliars.com",
      "url": "https://crooksandliars.com/2025/09/steve-bannon-flips-young-republicans-healthcare",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Detailed findings from AP investigation into how US tech firms enabled China's digital police state",
      "content": "BEIJING (AP) — American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warningsfrom the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nThe AP investigation was based on tens of thousands of leaked emails and databases from a Chinese surveillance company; thousands of pages of confidential corporate and government documents; public Chinese language marketing material; and thousands of procurements, many provided by ChinaFile, a digital magazine published by the non-profit Asia Society. The AP also drew from dozens of open record requests and interviews with more than 100 current and former Chinese and American engineers, executives, experts, officials, administrators, and police officers.\n\nAmerican tech firms were by far the biggest suppliers, but German, Japanese, and Korean firms also had a role. Here are some examples:\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nMILITARY ACCESS: A Chinese military contractor worked with Armonk, New York-based IBM in 2009 to design national intelligence systems, including a counterterrorism system, according to classified Chinese government documents. These systems were used by China’s secret police, the Ministry of State Security, and the Chinese military. IBM referred to any such deals as “old, stale interactions”: “ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.”\n\nANTI-TERROR ANALYSIS: IBM agents in China sold IBM’s i2 policing analysis software to the Xinjiang police, China’s Ministry of State Security, and other Chinese police units throughout the 2010s, leaked emails show. i2 software was subsequently copied and deployed by one former IBM agent, Landasoft, as the basis for a predictive policing platform that tagged hundreds of thousands of people as potential terrorists during a brutal crackdown in China’s far west Xinjiang region. IBM says it ceased relations with Landasoft in 2014, prohibited sales to police in Xinjiang and Tibet since 2015, and has no record of any sales of i2 software to the Public Security Bureau in Xinjiang.\n\nETHNIC REPRESSION: Dell and then-subsidiary VMWare sold cloud software and storage devices to police and entities providing data to police in Tibet and Xinjiang, even as late as 2022 after ethnic repression there was widely known. Dell addressed race in its marketing: In 2019, Dell said on WeChat it had teamed up with surveillance firm Yitu to sell a “military-grade” AI-powered laptop for Chinese police with “all-race recognition.” Dell, based in Round Rock, Texas, told AP it conducts “rigorous due diligence” to ensure compliance with U.S. export controls. Chinese policing systems, including in Xinjiang, also used software from Oracle, based in Austin, Texas, and from Microsoft, based in Seattle, according to procurements and a leaked database obtained by AP.\n\nFINGERPRINT RECOGNITION: Chinese defense contractor Huadi worked with IBM to construct China’s national fingerprint database; IBM said it never sold “fingerprinting-specific” products to the Chinese government and that any possible misuse “for fingerprinting purposes” was done without its knowledge or assistance. HP and VMWare sold technology used for fingerprint comparison by Chinese police. Intel said in 2019 marketing material that it partnered with Hisign, a Chinese fingerprinting company that sold to Xinjiang police, to make their fingerprint readers more effective, and that the new reader was “fully tested in an actual application scenario” with a municipal police bureau. Hisign was still an Intel partner as of last year, according to Chinese media reports. California-based Intel said it has not had any technical engagement with Hisign since 2024, and told AP it would “act swiftly” if it became aware of any “credible misuse.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAI CAMERAS: IBM, Dell, Tokyo-based Hitachi, and VMWare promoted facial recognition for use by Chinese police. Japanese electronics giant Sony said on its official WeChat account that it wired a Chinese prison with “intelligent” cameras, saying it was widely trusted for “surveillance projects.” California chip giant Nvidia and Intel partnered with China’s three biggest surveillance companies to add AI capabilities to camera systems used for video surveillance across China, including in Xinjiang and Tibet, until sanctions were imposed. Relations with other Chinese surveillance companies continued more recently: Nvidia posted on its WeChat social media account in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk. Nvidia told AP those relationships no longer continue.\n\nSURVEILLANCE RESEARCH: Nvidia, IBM, and Hitachi staff collaborated with Chinese police researchers and companies on surveillance technology. Nvidia said in a post dating to 2013 or later that a Chinese police institute used its chips for surveillance technology research. Nvidia said it doesn’t currently work with Chinese police but did not address the past. And in 2021, an IBM and a U.S. Army researcher coauthored an AI video study with a Chinese police researcher working at a sanctioned company, according to a paper unearthed by IPVM, a surveillance research publication. The U.S. Army told AP the Chinese police researcher only worked on the paper after the Army researcher’s work had concluded.\n\nDNA: Chinese police DNA labs bought Dell and Microsoft software and equipment to save genetic data on police databases. In 2021, Hitachi advertised DNA sequencers to Chinese police, and police labs bought pipettes from German biotech firm Eppendorf last year. And until contacted by AP in August, Massachusetts-based biotech firm Thermo Fisher Scientific‘s website stated that its kits are made for China’s national DNA database and “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans,” and featured the work of a Chinese police researcher who discussed using Thermo Fisher kits to identify ethnic Uyghur and Manchu populations at a 2016 conference. Thermo Fisher stopped sales in Xinjiang in 2021 and in Tibet in 2024, but still promotes kits to police elsewhere in China, including at a police trade show earlier this year. In a statement to AP, Thermo Fisher said its kits “are designed to be effective across diverse global populations” but “do not have the capability to distinguish among specific ethnic groups.”\n\nINTERNET POLICE: In 2014, VMWare said internet police in cities across China used its software, and in 2016, Dell said on its WeChat account that its services assisted the Chinese internet police in “cracking down on rumormongers” — essentially promoting censorship. An undated IBM marketing presentation said that internet police in Shanghai and Guangzhou used its i2 software, with metadata suggesting it was from 2018. IBM held a conference in Beijing promoting i2 in 2018, according to its official WeChat account.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nENCRYPTION TECHNOLOGY: Leaked government blueprints show Illinois-based Motorola provided encrypted radio communications technology to the Chinese police for handling “sudden and mass events in Beijing.” Motorola did not respond to requests for comment.\n\nAI DRIVES: Californian hard disk giants Seagate and Western Digital and Tokyo-based Toshiba sell hard drives specialized for AI video systems for use by Chinese police. In 2022, Toshiba wrote about how its surveillance hard drives can help police monitor communities to “identify and control suspicious” or “blacklisted” individuals. “They’re optimized and adapted for security systems,” Toshiba sales director Feng Hao told AP. Last year, Western Digital touted its partnership with Chinese surveillance company Uniview at a policing trade expo, months before Uniview was sanctioned over complicity in rights abuses. And Seagate said on WeChat in 2022 that it sells hard drives “tailor made” for AI video systems in China for use by police to help them ”control key persons,” and promoted their drives to police at a security trade association in China this year.\n\nMAPPING SOFTWARE: Blueprints show that in 2009, IBM, Oracle, and Esri, the creator of ArcGIS based in California, sold hundreds of thousands of dollars’ worth of software to build China’s Police Geographic Information System, and in 2013, HP said it sold “digital fencing” solutions to Chinese police. Such systems alert Chinese police even today when Uyghurs, Tibetans or dissidents stray out of provinces, counties or even villages. The U.S. curbed exports of such mapping software to China in 2020. But the restrictions are narrow in scope, and Esri maintains a research center in Beijing that marketed to police and other Chinese clients. Esri denied involvement.\n\nPOLICE GEAR: Chinese police patrol the streets equipped with foreign technology. Officers stroll the streets of Beijing with Motorola walkie-talkies, for example, while Korean electronics giant Samsung sells microSD cards for police body cameras, advertising them at Chinese police trade shows in 2023 and 2024. And in WeChat posts, Chinese state-owned company Jinghua said it cooperated with German electronics giant Philips on China’s first ”AI-powered 5G” police body camera and advertised Philips-branded recorders and cameras to Chinese police. In a statement, Philips said it had no partnership with Jinghua, did not authorize sales of Philips-branded body cameras in China, and would be contacting Jinghua over the posts.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nIBM, Dell, California network seller Cisco, Seattle-based Amazon Web Services, Seagate, Intel, Thermo Fisher and Western Digital all said they adhere to relevant export controls, laws and regulations where they operate. Eppendorf, Sony, and Hitachi declined to describe their business relationships in China but said they respected human rights.\n\nOracle, Hewlett Packard Enterprise, and California tech conglomerate Broadcom, which acquired VMWare in 2023, did not comment on the record. HP, Motorola, Samsung, Toshiba, Huadi, and Landasoft did not respond. Microsoft said it did not knowingly provide software for updates to China’s main policing system.\n\nThe Xinjiang government said in a statement that it uses surveillance technologies to “prevent and combat terrorist and criminal activity” and does not target any particular ethnicity. The statement said Western countries also use such technology, calling the U.S. “a true surveillance state.” Other government agencies did not respond to a request for comment.\n\n__\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/detailed-findings-ap-investigation-us-043012321.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel 14A Node Expected to Cost More Than 18A, Driven by High-NA EUV",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/intel-14a-node-expected-to-cost-more-than-18a-driven-by-high-na-euv/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Belarusian spy network uncovered by Eurojust operation, Moldovan ex-intel chief arrested",
      "content": null,
      "source": "EURACTIV",
      "url": "https://www.euractiv.com/section/politics/news/belarusian-spy-network-uncovered-by-eurojust-operation-moldovan-ex-intel-chief-arrested/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "HP EliteBook 8 G1a 16 AI laptop review: Redesigned inside and out",
      "content": "The business-centric EliteBook 8 series directly replaces the outgoing EliteBook 800 series. The new naming convention makes it easier to identify the price category, generation, and type of processor. In this case, the EliteBook 8 G1a 16 in review is an entry-level (8) first generation (G1) model powered by an AMD (a) processor. Higher-end EliteBook models sport the \"X\" or \"Ultra\" name instead of the \"8\".\n\nOur test configuration is a costlier SKU with the Zen 5 Ryzen AI 7 PRO 350 CPU, 32 GB of RAM, and 1200p IPS display for approximately $1900 USD. Lower-end options start with the Zen 4 Ryzen 5 Pro 230 while the 1200p native resolution is fixed across the board.\n\nAlternatives to the 16-inch EliteBook 8 G1a include other entry-level to midrange business or office laptops like the Asus ExpertBook B5, Lenovo ThinkPad L16, or Dell Latitude 5000 to 7000 series. A 14-inch version of this model is also available called the EliteBook 8 G1a 14. For Intel fans, SKUs with Core Ultra CPUs are aptly named the EliteBook 8 G1i 16.\n\nMore HP reviews:",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/HP-EliteBook-8-G1a-16-AI-laptop-review-Redesigned-inside-and-out.1103659.0.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Appoints Jim Johnson As CCG Head, Kevork Kechichian As DCG Head & Naga Chandrasekaran As IFS Head, Michelle Johnston Departs After More Than 3 Decades",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/intel-appoints-jim-johnson-ccg-head-kevork-kechichian-dcg-head-naga-chandrasekaran-ifs-head-michelle-johnston-departs/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia Announces Rubin CPX GPU To Speed Long-Context AI",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/karlfreund/2025/09/09/nvidia-announces-rubin-cpx-gpu-to-speed-long-context-ai/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Apple、Liquid Glassデザインを採用した「macOS 26 Tahoe」や「iOS/iPadOS 26」、「watchOS 26」、「visionOS 26」、「tvOS 26」を日本時間9月16日にリリースすると発表。",
      "content": "AppleがLiquid Glassデザインを採用した「macOS 26 Tahoe」と「iOS 26」、「watchOS 26」「visionOS 26」を9月16日に正式リリースすると発表しています。詳細は以下から。\n\n\n\n\n\nAppleは日本時間2025年09月10日 午前2時より、スペシャルイベント「Awe dropping. (言葉にできない。)」を開催し、A19チップを搭載した「iPhone 17/Air/Pro」、「AirPods Pro 3」、「Apple Watch Series 11」などを発表しましたが、\n\n更新されたAppleのプレビューページによると、Appleは06月からBeta版を公開し開発を進めてきたLiquid Glassデザインシステム採用の「macOS 26 Tahoe」や「iOS/iPadOS 26」、「watchOS 26」、「visionOS 26」、「tvOS 26」を現地時間2025年09月15日、日本時間の16日に正式リリースすると発表しています。\n\nシステム要件\n\nmacOS 26 TahoeやiOS/iPadOS 26はガラス調のLiquid Glassデザインシステムが全Apple OSで採用される一方、Macでは最後のIntel Mac miniとなっている「Mac mini (2018)」や、Intelチップを搭載した最後のMacBook Air「MacBook Air (Retina, 13-inch, 2020)」、プロユーザー向けにIntel Xeonを搭載した「iMac Pro (2017)」、そして2018~2019年製造のMacBook Pro、iMacがmacOS 26 Tahoeのサポートから外されており、\n\niPhone/iPadでは、2018年に発売されたApple A12 Bionicチップ搭載の「iPhone XR/XS」シリーズ、2019年に発売されたA10 Fusionチップ搭載の「iPad (第7世代)」がシステム要件から外れるので、ユーザーの方は注意してください。\n\nmacOSのシステム要件\n\nmacOS 14\n\nSonoma macOS 15\n\nSequoia macOS 26\n\nTahoe MacBook Air 2018以降 2020以降 2020以降のApple Siliconモデルのみ MacBook Pro 2018以降 2020以降のApple Siliconモデル\n\nMacBook Pro (16‑inch, 2019)\n\nMacBook Pro (13‑inch, 2020, Four Thunderbolt 3 ports) Mac mini 2018以降 2020以降のApple Siliconモデル iMac 2019以降 2020以降 iMac Pro 2017以降 終了 Mac Studio 2022以降 Mac Pro 2019以降",
      "source": "Applech2.com",
      "url": "https://applech2.com/archives/20250910-macos-26-tahoe-and-ios-26-available-9-15.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Media Encoder 2025 v25.4.1",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-media-encoder-2025-v25-4-1-2/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Lenovo Legion Pro 7i: 16\" QHD+ 240Hz OLED, RTX 5090, Intel Ultra 9 275HX, 64GB DDR5, 2TB SSD $2999.99",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18593518-lenovo-legion-pro-7i-16-qhd-240hz-oled-rtx-5090-intel-ultra-9-275hx-64gb-ddr5-2tb-ssd-2999-99",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Dell 14 Plus: 14\" QHD+ 90Hz, Intel Ultra 9 288V, 32GB LPDDR5, 1TB SSD $899.99",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired Dr.W posted Item 1 of 2 Item 1 of 2 expired Dr.W posted Dell 14 Plus: 14\" QHD+ 90Hz, Intel Ultra 9 288V, 32GB LPDDR5, 1TB SSD $899.99 $900 $1,390 35% off Micro Center 9 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 5,929 Views Visit Micro Center Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details Lowest price ever and cheaper than the previous popular\n\n\n\nAvailable In-store Only; In stock at all stores (except for CA, TX) when posting.\n\n\n\nSPECS: 14\" 2.5K/QHD+ (2560x1600, WQXGA+) 16:10, 90Hz, 300-nits, 100% sRGB, Anti-Glare, WVA/IPS Display\n\nIntel Core Ultra 9 288V (48 TOPS NPU, 8 cores, up to 5.1 GHz)\n\n32GB, LPDDR5X, 8533MT/s, Memory on Package, onboard\n\n1TB M.2 PCIe NVMe Solid State Drive\n\nIntel Arc Graphics\n\nIntel Wi-Fi 7 BE201, 2x2, 802.11be, Bluetooth wireless card\n\n1080p at 30 fps FHD camera\n\nEnglish Backlit Copilot key keyboard, no numeric keypad\n\n4-Cell Battery, 64WHr (Integrated)\n\n4.42 lbs. (2.00 kg)\n\nExterior chassis materials: LCD Cover/Base: Aluminium Bezel/Palmrest: Plastic\n\nPorts: 1x USB 3.2 Gen 1 (5 Gbps) port 1x USB 3.2 Gen 2 (10 Gbps) Type-C port with DisplayPort 1.4 and Power Delivery 1x Thunderbolt 4 port with DisplayPort 2.1 and Power Delivery 1x HDMI 2.1 port 1x Universal Audio jack\n\n\n\n\n\nhttps://www.microcenter .com/produ...r-ice-blue and cheaper than the previous popular FP deal In stock at all stores (except for CA, TX) when posting. Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster Dr.W Follow Give Rep Message 8,032 Deal Posts 11,542 Comments Posts 16,996 Reputation Points 10,806 Votes Submitted Deal Details Community Notes About the Poster Lowest price ever and cheaper than the previous popular\n\n\n\nAvailable In-store Only; In stock at all stores (except for CA, TX) when posting.\n\n\n\nSPECS: 14\" 2.5K/QHD+ (2560x1600, WQXGA+) 16:10, 90Hz, 300-nits, 100% sRGB, Anti-Glare, WVA/IPS Display\n\nIntel Core Ultra 9 288V (48 TOPS NPU, 8 cores, up to 5.1 GHz)\n\n32GB, LPDDR5X, 8533MT/s, Memory on Package, onboard\n\n1TB M.2 PCIe NVMe Solid State Drive\n\nIntel Arc Graphics\n\nIntel Wi-Fi 7 BE201, 2x2, 802.11be, Bluetooth wireless card\n\n1080p at 30 fps FHD camera\n\nEnglish Backlit Copilot key keyboard, no numeric keypad\n\n4-Cell Battery, 64WHr (Integrated)\n\n4.42 lbs. (2.00 kg)\n\nExterior chassis materials: LCD Cover/Base: Aluminium Bezel/Palmrest: Plastic\n\nPorts: 1x USB 3.2 Gen 1 (5 Gbps) port 1x USB 3.2 Gen 2 (10 Gbps) Type-C port with DisplayPort 1.4 and Power Delivery 1x Thunderbolt 4 port with DisplayPort 2.1 and Power Delivery 1x HDMI 2.1 port 1x Universal Audio jack\n\n\n\n\n\nhttps://www.microcenter .com/produ...r-ice-blue and cheaper than the previous popular FP deal In stock at all stores (except for CA, TX) when posting.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18593587-dell-14-plus-14-qhd-90hz-intel-ultra-9-288v-32gb-lpddr5-1tb-ssd-899-99",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Patch Tuesday Arrives with New Features for Windows 11",
      "content": "It’s Patch Tuesday, and those on Windows 11 can look forward to a long list of new features. You know, once Microsoft gets around to delivering them on your PC, as most of them are being rolled out gradually.\n\nCumulative update KB5065426 is available for PCs running Windows 11 version 23H2. And cumulative update KB5065426 is available now for PCs running Windows 11 version 24H2. Both builds include numerous new features that were first previewed two weeks ago.\n\nKey new features include:\n\nRecall improvements (Copilot+ PCs only). Recall provides a new homepage experience with shortcuts for your recent activity, most-used apps, and most-visited websites. There are new controls for filtering the apps and websites that Recall shouldn’t record, plus a new navigation bar on the left with links to Home, Timeline, Feedback, and Settings.\n\nClick to Do improvements (Copilot+ PCs only). Click to Do now provides an interactive tutorial when you first launch it, and you can access it later by navigating to More options (“…”) > Start tutorial.\n\nAgent in Settings (Copilot+ PCs only). Previously available on Snapdragon X-based Copilot+ PCs, the new Agent in Settings is now available to those with AMD- and Intel-based Copilot+ PCs too. But it’s still limited to English, which must be configured as your primary display language.\n\nSearch improvements. When you initiate Search from the Taskbar item, a new grid view is used for image results so you can more easily find what you’re looking for. The Search window will now display a status pane if Windows 11 is still indexing your search locations. And search results will clearly differentiate between local and cloud-stored files.\n\nLarger clock option in Notification center. As was the case in Windows 10, you can now enable a larger clock with settings in the Date and Calendar window that appears when you display the Notification center. (To do so, open Settings, navigate to Time & language > Date & time, and enable the option “Show time in the Notification Center.”)\n\nSystem dialog improvements. System dialogs now appear modally over the rest of the Desktop, which is dimmed to give emphasis to the dialog.\n\nLock screen widgets improvements. You can now add, remove, and rearrange Lock screen widgets. And these widgets now support a new small sizing option.\n\nFile Explorer improvements. Microsoft has made minor visual changes to the context menu that appears when you right-click in File Explorer.\n\nWindows Hello improvements. The Windows Hello user experience is completely redesigned with more modern visuals. It’s nicer looking but, truth be told, slower and more tedious to use now. But it does let you switch between available authentication options such as passkeys or connected devices.\n\nGenerative AI privacy and security settings. A new page in the Settings app, found at Privacy & security > Text and Image Generation, displays which third-party apps have recently used generative AI models built into Windows. You can also manage which apps can use these features, and then disable those you don’t want.\n\nWidgets improvements. You can now configure multiple dashboards in the Widgets board, and there’s a new navigation bar on the left for switching between the widget dashboards and other views like the Discover feed, which is “more organized, personalized, and engaging.”\n\nTask Manager improvements. Task Manager has been updated to more accurately display CPU usage across all views. The Details view now has an optional CPU Utility column, as per the Processes view.\n\nFixes. As you might imagine, these builds also deliver multiple security and bug fixes across ReFS, the Chinese (Simplified) Input Method Editor (IME), Arm64 performance, and more.\n\nYes, you will need to reboot as usual.",
      "source": "Thurrott.com",
      "url": "https://www.thurrott.com/windows/windows-11/326263/patch-tuesday-arrives-with-new-features-for-windows-11",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Takeaways from AP's investigation into how US tech companies enabled China's digital police state",
      "content": "BEIJING (AP) — Across China, tens of thousands of people tagged as troublemakers are trapped in a digital cage, barred from leaving their province and sometimes even their homes by the world’s largest digital surveillance apparatus. Most of this technology came from companies in a country that has long claimed to support freedoms worldwide: the United States.\n\nOver the past quarter century, American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warnings from the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nMost of the companies that responded said they fully complied with all laws, sanctions and U.S. export controls governing business in China, past and present. Here are key findings:\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAmerica brought ‘predicative policing’ to China\n\nU.S. companies introduced systems that mine a vast array of information — texts, calls, payments, flights, video, DNA swabs, mail deliveries, the internet, even water and power use — to unearth individuals deemed suspicious and predict their movements. But this technology also allows Chinese police to threaten friends and family and preemptively detain people for crimes they have not even committed. The AP found a Chinese defense contractor, Huadi, worked with IBM in 2009 to design the main policing system for Beijing to censor the internet and crack down on alleged terrorists, the Falun Gong religious sect, and even villagers deemed troublesome. IBM referred to any possible relationship it may have had with Chinese government agencies as “old, stale interactions”: “ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.” Huadi did not respond.\n\nUS tech enabled the Xinjiang crackdown\n\nAmerican surveillance technologies allowed a brutal mass detention campaign in the far west region of Xinjiang — targeting, tracking and grading virtually the entire native Uyghur population to forcibly assimilate and subdue them. IBM agents in China sold its i2 software to the Xinjiang police, China’s Ministry of State Security, and many other Chinese police units throughout the 2010s, leaked emails show. One agent, Landasoft, subsequently copied and deployed it as the basis for a predictive policing platform that tagged hundreds of thousands of people as potential terrorists. IBM said it has no record of its i2 software ever being sold to the Public Security Bureau in Xinjiang, was not aware of any interaction between Landasoft and that bureau and cut ties with Landasoft in 2014. Landasoft did not respond.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome tech companies even specifically addressed race in their marketing. Dell and a Chinese surveillance firm promoted a “military-grade” AI-powered laptop with “all-race recognition” on its official WeChat account in 2019. And until contacted by AP in August, biotech giant Thermo Fisher Scientific’s website marketed DNA kits to the Chinese police as “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans.” The Xinjiang government said that it uses surveillance technologies to prevent terrorism, and that Western countries also use such technology, calling the U.S. “a true surveillance state.”\n\nCompanies pitched tech to control citizens\n\nThough the companies often claim they aren’t responsible for how their products are used, some directly pitched their tech as tools for Chinese police to control citizens, marketing materials from IBM, Dell, Cisco, and Seagate show. Their sales pitches — made both publicly and privately — cited Communist Party catchphrases on crushing protest, including “stability maintenance,” “key persons,” and “abnormal gatherings,” and named programs that stifle dissent, such as “Internet Police,” “Sharp Eyes” and the “Golden Shield.” IBM, Dell, Cisco and Seagate said they adhere to all relevant laws.\n\nAmerican tech laid the foundation for Chinese surveillance\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAmerican technology laid the foundation for China’s surveillance apparatus that Chinese companies have since built on and in some cases replaced. Intel and Nvidia helped China’s three biggest surveillance companies make their camera systems AI-powered. Contracts to maintain existing IBM, Dell, HP, Cisco, Oracle, and Microsoft software and gear remain ubiquitous, often with third parties. And to this day, concerns remain over where technology sold to China will end up, with former U.S. officials and national security experts criticizing a deal struck this summer for Nvidia to sell chips used in artificial intelligence to China, saying the technology would fall into the hands of the Chinese military and intelligence. Nvidia said in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk, but told the AP those relationships no longer continue. Nvidia said it does not make surveillance systems or software, does not work with police in China and has not designed the H20 chips for police surveillance, and the White House and Department of Commerce did not respond to requests for comment.\n\nBig loopholes in sanctions remain\n\nSome U.S. companies ended contracts in China over rights concerns and after sanctions. IBM said it has prohibited sales to Tibet and Xinjiang police since 2015, and suspended business relations with defense contractor Huadi in 2019. Nvidia and Intel also ended partnerships with China’s top two surveillance companies in 2019. However, sanctions experts noted that the laws have significant loopholes and often lag behind new developments. For example, a ban on military and policing gear to China after the 1989 Tiananmen massacre does not take into account newer technologies or general-use products that can be applied in policing. They also noted that the law around export controls is complicated.\n\nA cautionary tale\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nWhat started in China more than a decade ago could be seen as a cautionary tale for other countries at a time when the use of surveillance technology worldwide is rising sharply, including in the United States. Emboldened by the Trump administration, U.S. tech companies are more powerful than ever, and President Donald Trump has rolled back a Biden-era executive order meant to safeguard civil rights from new surveillance technologies. As the capacity and sophistication of such technologies has grown, so has their reach. Surveillance technologies now include AI systems that help track and detain migrants in the U.S. and identify people to kill in the Israel-Hamas war. China, in the meantime, has used what it learned from the U.S. to turn itself into a surveillance superpower, selling technologies to countries like Iran and Russia.\n\n“Because of this technology … we have no freedom at all,” said Yang Caiying, now in exile in Japan, whose family has been trapped in an increasingly tight noose of surveillance for the past 16 years. “At the moment, it’s us Chinese that are suffering the consequences, but sooner or later, Americans and others, too, will lose their freedoms.”\n\n__\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/takeaways-aps-investigation-us-tech-043117960.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Perfectly Clear WorkBench 4.8.0.2849",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/perfectly-clear-workbench-4-8-0-2849-2/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe After Effects 2025 v25.4.0",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-after-effects-2025-v25-4-0/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "US tech companies enabled the surveillance and detention of hundreds of thousands in China",
      "content": "BEIJING (AP) — The body camera hung from the top of the IV drip, recording the slightest twitch made by Yang Guoliang as he lay bloody and paralyzed in a hospital bed after a police beating with bricks.\n\nBy then, surveillance was nothing new for the Yang family in rural China, snared in an intricate network based on U.S. technology that spies on them and predicts what they’ll do.\n\nTheir train tickets, hotel bookings, purchases, text messages and phone calls are forwarded to the government. Their house is ringed with more than a dozen cameras. They’ve tried to go to Beijing 20 times in the past few years, but masked men show up and grab them, often before they depart. And last year, Yang’s wife and younger daughter were detained and now face trial for disrupting the work of the Chinese state — a crime carrying a sentence of up to a decade in prison.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nYet the Yangs say they are not criminals. They are simply farmers trying to beg Beijing to stop local officials from seizing their 1 1/2 acres of land in China’s eastern Jiangsu province.\n\n“Every move in my own home is monitored,” Yang said, sitting behind black curtains that block him from the glare of police lights trained straight at his house. “Their surveillance makes me feel unsafe all the time, everywhere.”\n\nAcross China, tens of thousands of people tagged as troublemakers like the Yangs are trapped in a digital cage, barred from leaving their province and sometimes even their homes by the world’s largest digital surveillance apparatus. Most of this technology came from companies in a country that has long claimed to support freedoms worldwide: the United States.\n\nOver the past quarter century, American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warningsfrom the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nCritically, American surveillance technologies allowed a brutal mass detention campaign in the far west region of Xinjiang — targeting, tracking and grading virtually the entire native Uyghur population to forcibly assimilate and subdue them.\n\nU.S. companies did this by bringing “predictive policing” to China — technology that sucks in and analyzes data to prevent crime, protests, or terror attacks before they happen. Such systems mine a vast array of information — texts, calls, payments, flights, video, DNA swabs, mail deliveries, the internet, even water and power use — to unearth individuals deemed suspicious and predict their behavior. But they also allow Chinese police to threaten friends and family and preemptively detain people for crimes they have not even committed.\n\nFor example, the AP found a Chinese defense contractor, Huadi, worked with IBM to design the main policing system known as the “Golden Shield” for Beijing to censor the internet and crack down on alleged terrorists, the Falun Gong religious sect, and even villagers deemed troublesome, according to thousands of pages of classified government blueprints taken out of China by a whistleblower, verified by AP and revealed here for the first time. IBM and other companies that responded said they fully complied with all laws, sanctions and U.S. export controls governing business in China, past and present.\n\nAcross China, surveillance systems track blacklisted “key persons,” whose movements are restricted and monitored. In Xinjiang, administrators logged people as high, medium, or low risk, often according to 100-point scores with deductions for factors like growing a beard, being 15 to 55 years old, or just being Uyghur.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome tech companies even specifically addressed race in their marketing. Dell and a Chinese surveillance firm promoted a “military-grade” AI-powered laptop with “all-race recognition” on Dell's official WeChat account in 2019. And until contacted by AP in August, biotech giant Thermo Fisher Scientific’s website marketed DNA kits to the Chinese police as “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans.”\n\nWhile the flood of American technology slowed considerably starting in 2019 after outrage and sanctions over atrocities in Xinjiang, it laid the foundation for China’s surveillance apparatus that Chinese companies have since built on and in some cases replaced. To this day, concerns remain over where technology sold to China will end up.\n\nFor example, 20 former U.S. officials and national security experts wrote a letter in late July criticizing a deal for Nvidia to sell H20 chips used in artificial intelligence to China, with 15% of revenues going to the U.S. government. They said no matter who the chip is sold to, it will fall into the hands of Chinese military and intelligence services.\n\nNvidia said it does not make surveillance systems or software, does not work with police in China and has not designed the H20 for police surveillance. Nvidia posted on its WeChat social media account in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk, but told the AP those relationships no longer continue. The White House and Department of Commerce did not respond to requests for comment.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nThermo Fisher and hard drive maker Seagate promoted their products to Chinese police at conferences and trade shows this year, according to online posts. Officers stroll the streets of Beijing with Motorola walkie talkies. Nvidia and Intel chips remain critical for Chinese policing systems, procurements show. And contracts to maintain existing IBM, Dell, HP, Cisco, Oracle, and Microsoft software and gear remain ubiquitous, often with third parties.\n\nWhat started in China more than a decade ago could be seen as a cautionary tale for other countries at a time when the use of surveillance technology worldwide is rising sharply, including in the United States. Emboldened by the Trump administration, U.S. tech companies are more powerful than ever, and President Donald Trump has rolled back a Biden-era executive order meant to safeguard civil rights from new surveillance technologies.\n\nAs the capacity and sophistication of such technologies has grown, so has their reach. Surveillance technologies now include AI systems that help track and detain migrants in the U.S. and identify people to kill in the Israel-Hamas war. China, in the meantime, has used what it learned from the U.S. to turn itself into a surveillance superpower, selling technologies to countries like Iran and Russia.\n\nThe AP investigation was based on tens of thousands of leaked emails and databases from a Chinese surveillance company; tens of thousands of pages of confidential corporate and government documents; public Chinese language marketing material; and thousands of procurements, many provided by ChinaFile, a digital magazine published by the non-profit Asia Society. The AP also drew from dozens of open record requests and interviews with more than 100 current and former Chinese and American engineers, executives, experts, officials, administrators, and police officers.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nThough the companies often claim they aren’t responsible for how their products are used, some directly pitched their tech as tools for Chinese police to control citizens, marketing material from IBM, Dell, Cisco, and Seagate show. Their sales pitches — made both publicly and privately — cited Communist Party catchphrases on crushing protest, including “stability maintenance,” “key persons,” and “abnormal gatherings,” and named programs that stifle dissent, such as “Internet Police,” “Sharp Eyes” and the “Golden Shield.”\n\nOther companies, like Intel, Nvidia, Oracle, Thermo Fisher, Motorola, Amazon Web Services, Microsoft, Western Digital, creator of mapping software ArcGIS Esri, and what was then Hewlett Packard, or HP, also sold technology or services knowingly to Chinese police or surveillance companies. Four practicing lawyers said sales like those uncovered by AP could potentially go against at least the spirit, if not the letter, of U.S. export laws at the time, which the companies denied.\n\nAmerican technology made up nearly every part of China’s surveillance apparatus, AP found:\n\nMILITARY AND POLICE: In 2009, Chinese defense contractor Huadi worked with IBM to build national intelligence systems, including a counterterrorism system, used by the Chinese military and China’s secret police, the Ministry of State Security. Chinese agents sold IBM’s i2 police surveillance analysis software to the same ministry and to Chinese police, including in Xinjiang, through the 2010s, leaked emails and marketing posts show. IBM said it has no record of its i2 software ever having been sold to the Public Security Bureau in Xinjiang.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSURVEILLANCE: Nvidia and Intel partnered with China’s three biggest surveillance companies to add AI capabilities to camera systems used for video surveillance across China, including Xinjiang and Tibet, until sanctions were imposed. Nvidia said in a post dating to 2013 or later that a Chinese police institute used its chips for surveillance technology research.\n\nETHNIC REPRESSION: IBM, Oracle, HP, and ArcGIS developer Esri sold hundreds of thousands of dollars’ worth of geographic and mapping software to Chinese police that allows officers to detect when blacklisted Uyghurs, Tibetans or dissidents stray out of provinces or villages. As late as 2019, with detentions in Xinjiang well underway, Dell hosted an industry summit in its capital. Dell and then-subsidiary VMWare sold cloud software and storage devices to police and entities providing data to police in Tibet and Xinjiang, even in 2022 after abuses there became widely known.\n\nIDENTIFICATION: Huadi worked with IBM to construct China’s national fingerprint database; IBM told AP it never sold “fingerprinting-specific product or technology” to the Chinese government “in violation of US law.” HP and VMWare sold technology used for fingerprint comparison by Chinese police, while Intel partnered with a Chinese fingerprinting company to make their devices more effective. IBM, Dell, and VMWare also promoted facial recognition to Chinese police. China’s police and police DNA labs bought Dell and Microsoft software and equipment to save genetic data on police databases.\n\nCENSORSHIP AND CONTROL: In 2016, Dell boasted on its WeChat account that its services assisted the Chinese internet police in “cracking down on rumormongers.” Seagate said on WeChat in 2022 that it sells hard drives “tailor made” for AI video systems in China for use by police to help them ”control key persons,” despite facing backlash for selling drives in Xinjiang.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nFor extended findings, click here.\n\n“Everything was built on American tech,” said Valentin Weber, a researcher at the German Council on Foreign Relations who studied the use of U.S. tech by Chinese police. “China’s capability was close to zero.”\n\nIBM, Dell, Cisco, Intel, Thermo Fisher and Amazon Web Services all said they adhere to export control policies. Seagate and Western Digital said they adhere to all relevant laws and regulations where they operate.\n\nOracle, Hewlett Packard Enterprise, and tech conglomerate Broadcom, which acquired VMWare and cloud company Pivotal in 2023, did not comment on the record; HP, Motorola and Huadi did not respond, and Esri denied involvement but did not reply to examples. Microsoft told AP it found no evidence that it “knowingly sold technology to the military or police” as part of updates to the “Golden Shield.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome U.S. companies ended contracts in China over rights concerns and after sanctions. For example, IBM said it has prohibited sales to Tibet and Xinjiang police since 2015, and suspended business relations with defense contractor Huadi in 2019.\n\nHowever, sanctions experts noted that the laws have significant loopholes and often lag behind new developments. For example, a ban on military and policing gear to China after the 1989 Tiananmen massacre does not take into account newer technologies or general-use products that can be applied in policing.\n\nThey also noted that the law around export controls is complicated. Raj Bhala, an expert in international trade law at the University of Kansas, said the issues the AP described fell into “the kind of gray area that we put in exams.”\n\n“It would raise concerns about possible inconsistencies, possible violations,” said Bhala, who emphasized he was speaking generally and not about any specific company. “But I really stress ‘possible.’ We need to know more facts.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nWhile German, Japanese and Korean firms also played a role, American tech firms were by far the biggest suppliers.\n\nThe Xinjiang government said in a statement that it uses surveillance technologies to “prevent and combat terrorist and criminal activity,” that it respects citizens’ privacy and legal rights and that it does not target any particular ethnicity. The statement said Western countries also use such technology, calling the U.S. “a true surveillance state.” Other government agencies did not respond to a request for comment, including China’s police and authorities in the Yangs’ province.\n\nThis technology still powers the police database that controls the Yangs and other ordinary people. An estimate based on Chinese government statistics found at least 55,000 to 110,000 were put under residential surveillance in the past decade, and vast numbers are restricted from travel in Xinjiang and Tibet. China’s cities, roads and villages are now studded with more cameras than the rest of the world combined, analysts say — one for every two people.\n\n“Because of this technology … we have no freedom at all,” said Yang Guoliang’s elder daughter, Yang Caiying, now in exile in Japan. “At the moment, it’s us Chinese that are suffering the consequences, but sooner or later, Americans and others, too, will lose their freedoms.”\n\nSelling surveillance superpowers\n\nBack when China was emerging from the chaotic violence of the Cultural Revolution in 1976, three in four Chinese were farmers, including the Yangs. They lived in a three-room home of tiles and pounded earth nestled among the lush, humid fields of the Yangtze River delta.\n\nAfter Chairman Mao Zedong’s death that year, Beijing’s new leaders opened China to the world, and American tech firms like HP and IBM rushed in. But there were hard limits on how much change the government would accept. In 1989, the Tiananmen pro-democracy protests rattled Beijing, which sent tanks and troops to shoot students.\n\nSoon after, Beijing began planning the “Golden Shield,” aimed at digitizing China’s police force.\n\nIn 2001, the 9/11 al-Qaida attacks turbocharged interest in surveillance technology. One researcher claimed authorities could have foiled the attack by unearthing connections between hijackers through public information in databases.\n\nAmerican companies cashed in, selling the U.S. billions of dollars in surveillance technologies they said could prevent crime and terror attacks.\n\nThey spotted the same sales opportunity in China. Researchers warned surveillance technologies would be “instruments of repression” in the hands of authoritarian states. Yet IBM, Cisco, Oracle, and other American companies clinched orders to supply Beijing’s “Golden Shield.”\n\n“China didn’t have this kind of thing before,” said Wang, a former Chinese police official in Xinjiang who asked to be identified only by last name for fear of retaliation. “These concepts all came from the West.”\n\nSoon, disturbing stories emerged. Chinese police blocked sensitive news, pinpointing dissidents with unnerving precision. They stalked adherents of the Falun Gong sect banned by authorities. Congress demanded explanations from tech companies.\n\nIn 2008, documents leaked to the press showed Cisco saw the “Golden Shield” as a sales opportunity, quoting a Chinese official calling the Falun Gong an “evil cult.” A Cisco presentation reviewed by AP from the same year said its products could identify over 90% of Falun Gong material on the web. Followers sued Cisco, which is now petitioning the U.S. Supreme Court to throw out the lower court ruling that allowed the lawsuit.\n\nAt a human rights conference in February, then-Cisco lawyer Katie Shay said companies had a responsibility to understand how customers might misuse their technology for “surveillance and censorship.”\n\n“A lot of people have suffered at the hands of their government, and I want to acknowledge that pain,” said Shay, who left Cisco in June. “I also will say that Cisco disputes the allegations of Cisco’s involvement.”\n\nCisco told the AP it is committed to human rights, but the court allegations may “open the floodgates for suits against U.S. corporations merely for legal exports of off-the-shelf goods and services.”\n\nAs Cisco was summoned before Congress, IBM partnered with a Chinese defense contractor on Phase Two of China’s “Golden Shield.”\n\nClassified government blueprints obtained by AP show that in 2009, IBM worked with Huadi, the state-owned subsidiary of China’s biggest missile military contractor spun off from China’s Ministry of Defense, to build out predictive policing.\n\n“Consolidate Communist Party rule,” read the Huadi blueprint, which showed the databases would track hundreds of thousands of people online.\n\nIn response to AP’s questions, IBM referred to any possible relationship it may have had with Chinese government agencies as “old, stale interactions”:\n\n“ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.”\n\nBack in 2009, Beijing needed the technology urgently to quash critics bonding online. Among them were the Yangs.\n\nIn April that year, local authorities ordered the Yangs and more than 300 other families in their village off their land. Developers coveted their prime lakefront property for “Western-style” apartments and villas, with fountains, football fields and shopping centers.\n\nThe Yangs had no idea police were installing systems that could target families like theirs. They just knew their land was being seized — in return for just a unit in a five-floor walk-up, too many stairs for their elderly mother to climb.\n\nThe Yangs and other farmers across China filed complaints.\n\n“I discovered the way the government took our land was illegal,” Yang Caiying said. “They cheated us.”\n\nPredict and prevent\n\nIn July 2009, three months after the Yang land was seized, riots erupted on the other side of the country in Xinjiang. Gory images of a Uyghur lynched at a toy factory spread online, angry Uyghurs took to the streets, and hundreds were killed.\n\nOnce again, American firms pitched their technology as the solution.\n\nThe government sent troops and cut Xinjiang’s phone and internet connections. In secret meetings, officials concluded that police had failed to spot the danger signs because they couldn’t identify Uyghurs deemed separatists, terrorists, and religious extremists, three engineers then working for the Xinjiang government told AP.\n\nAt the time, Xinjiang police and data systems were already running on American technology including IBM, Cisco, Oracle, and Microsoft, the engineers said, which AP verified by reviewing government contracts. But the databases were unconnected.\n\nSo Xinjiang launched an ambitious initiative to fuse data from all available sources, including banks, railways, and phone companies, into a central database. Officials demanded complete information on all suspicious individuals and their relatives going back three generations, according to the engineers, who described specific meetings in which they participated. Two asked to remain anonymous, fearing for their family in China; the third, Nureli Abliz, is now in Germany.\n\nSoon, lucrative contracts went up for bidding. Among those seeking to profit was IBM.\n\n“Prevent problems before they happen,” IBM promised Chinese officials. In an August 2009 pamphlet, IBM cited the Xinjiang riots and said its technology could help the government “ensure urban safety and stability.”\n\nIBM executives fanned out across the country to court Chinese officials. In December 2009, they set up a new “IBM Institute for Electronic Governance Innovation” in Beijing. In 2011, IBM acquired i2, a software program designed to prevent “terrorist threats.” IBM touted i2’s ability to analyze Chinese social media and licensed a Shanghai-based firm called Landasoft to sell it to China’s police, corporate records show.\n\nChinese police purchased tens of millions of dollars’ worth of products from companies like IBM, Cisco, Oracle, and Microsoft to upgrade the “Golden Shield” policing systems, a leaked accounting ledger acquired by AP from a whistleblower shows.\n\nIn the confrontation between the Chinese state and its critics, American technology tipped the scales of power.\n\nIn 2011, thieves ransacked the Yangs’ house, hunting for their property deed. They didn’t find it.\n\nTwo years later, bald men with tattoos and gold chains smashed down their door, shattered windows and flipped furniture to bully them out of their home anyway. Yang’s mother dropped to the floor in terror. Doctors diagnosed a heart attack, but the Yangs didn’t have money for a pacemaker.\n\nFurious, the Yangs sued local police. In June 2015, a judge ruled their land had been seized illegally. The Yangs celebrated.\n\nBut just weeks after the ruling, officers identified human rights lawyers through the “Golden Shield” technology, cuffed hundreds of them and pressed them into police vans across China. One lawyer later recalled how police monitored his messages on human rights in WeChat before they grabbed him, shackled him to a chair, and tortured him.\n\nOvernight, China’s budding rights-defense movement was dealt a fatal blow — and with it, the Yangs’ case. The Yangs were called in and curtly told the judgment was being overturned, their lawsuit dismissed without trial.\n\n“We really had too much faith in the law, you know?” Yang Guoliang said, his hands clenched in fists. “It turned out to be worthless.”\n\nTechnologies of terror\n\nIn the meantime, Beijing was transforming Xinjiang into the most heavily surveilled place on earth, sweeping around a million people into camps and prisons.\n\nWhen bombs tore through a train station in Xinjiang’s capital hours after a visit by leader Xi Jinping in 2014, Xi demanded a crackdown.\n\n“He was super angry,” said Abliz, one of the engineers with the Xinjiang government. “They concluded they weren’t surveilling Uyghurs closely enough.”\n\nThe next year, in April 2015, Abliz attended a closed-door exposition in Xinjiang. A booth ran by Landasoft, the former IBM partner, caught his eye.\n\nAfter years as a vendor of IBM’s i2 police surveillance analysis software to Xinjiang police, Landasoft had struck out on its own, touting i2-like software it said could detain extremists before they caused trouble. The similarity was no coincidence: Landasoft’s software was copied from i2, according to leaked emails and records.\n\n“The platform is developed based on i2,” a Landasoft project manager wrote in an email.\n\nIt used a proprietary data visualization system developed by i2. The software powered what was called the Integrated Joint Operations Platform, or IJOP, with the authority to trigger arrests.\n\nAbliz went numb.\n\n“I thought then that this was the end of humanity,” he said.\n\nLandasoft did not respond to repeated requests for comment. IBM said it cut ties with Landasoft in 2014 and was not aware of any interaction between Landasoft and the Public Security Bureau in Xinjiang.\n\nIn the autumn of 2015, months after the Xinjiang expo, Landasoft signed contracts with Xinjiang police, emails show. Workers installed millions of cameras and wired over 7,000 police outposts, often built just hundreds of meters apart. Nearly 100,000 officers were recruited to pound on doors and collect names, addresses, fingerprints and face-scans.\n\nThough Chinese hardware was favored, foreign software was irreplaceable for its performance and compatibility with China’s American-built systems, engineers told AP. That included server and database software from Oracle and Microsoft and cloud software from VMWare, which Dell acquired in 2016.\n\nIn late 2016, the crackdown began. Internal documents, a leaked copy of the Landasoft software and interviews with 16 former Xinjiang police officers, officials and engineers reveal how the system worked.\n\nLandasoft’s software combined data fed into a central police database to compile a dossier on vast swaths of Xinjiang’s population, tagging them with categories like “went on pilgrimage” or “studied abroad.” Administrators then questioned them, computed risk scores and decided who to detain.\n\nHundreds of thousands of people were tagged “untrustworthy”, leaked messages show. Leaked documents show the IJOP flagged 24,412 people as “suspicious” in just one week in 2017, leading to most being detained.\n\n“They thought it better to grab thousands of innocents than let a single criminal slip free,” Abliz said.\n\nThe technology was crude and flawed. Landasoft emails show engineers frantically fixing a software bug to release hundreds of people categorized as high-risk. And surveillance cameras often misidentified people, a former Xinjiang police officer found when he checked their ID cards.\n\nYet officers were told “computers cannot lie” and that the IJOP’s listed targets were “absolutely correct,” Abliz said. The software’s orders were often obeyed fearfully, unquestioningly.\n\n“The tech companies told the government their software is perfect,” Abliz said. “It’s all a myth.”\n\nMinority report\n\nThe all-encompassing surveillance forced total compliance: Officers arrested colleagues, neighbors informed on each other.\n\nIn May 2017, Kalbinur Sidik, a teacher now in the Netherlands, was summoned to her district government office in a yellow brick apartment building in Xinjiang’s capital. A young Uyghur woman, fresh from college, rose and introduced herself as a local official. Sidik, the woman explained, was being appointed as the head of her building, responsible for collecting information on neighbors.\n\n“What’s this data going to be used for?” Sidik asked.\n\nThe woman looked at a computer, with a Landasoft program running and lists of names and tags: “Goes out at night,” “Overseas phone,” “unemployed.” One button stood out: “Push Alert.”\n\nThe woman clicked it, and the screen filled with names. These people, the woman explained, would be detained and interrogated for suspected ties to terrorism. Sidik’s eyes widened.\n\n“I hated her for what she was doing,” Sidik said. “I knew those people would disappear.”\n\nXinjiang officials issued arrest quotas, Sidik and five other former officers and administrators said. Sidik watched with horror as the number of people who attended her compound’s weekly mandatory flag-raising ceremony shrank, from 400 to just over 100, as residents were arrested.\n\nAt the district office, she observed the logos popping up on screens: Oracle, Microsoft, Intel. The AP found evidence of products from all three companies used in Xinjiang’s policing and data systems during the crackdown, along with Esri, Seagate, Western Digital, Nvidia, Thermo Fisher, and VMWare, then owned by Dell, which advertised cooperation with Xinjiang authorities on its website.\n\nSidik asked her neighborhood official where it all came from.\n\n“We’ve spent a lot of money to import foreign technology,” she recalls the official telling her.\n\nAmong those caught in the digital dragnet was Parida Qabylqai, an ethnic Kazakh pharmacist at a military hospital in Xinjiang.\n\nIn February 2018, Qabylqai was flagged by the IJOP for visiting her parents in Kazakhstan. At first, her boss thought it was a mistake.\n\n“You’re a good person, you shouldn’t be listed,” she recalled him saying. Then he checked the IJOP and spotted her name.\n\n“It’s really serious! You’re going to end up in the camps,” he blurted out in shock.\n\nAn officer pressed a confession into her hands.\n\n“What did I do wrong?” Qabylqai asked.\n\n“Just sign!” the officer shouted.\n\nQabylqai was cuffed, hooded, and whisked to a camp, where cameras watched her day and night, even peering at her naked body in the toilet. Guards barking over speakers ordered her not to speak or even to move.\n\n“They did things to us that no human being should ever have to experience,” she said. “But they said my name was listed by the IJOP, so they didn’t need to explain anything.”\n\nEven enforcers of the system weren’t spared.\n\nIn 2018, Liu Yuliang, a civil servant in Xinjiang, was ordered to the home of a young police officer in his village. He and dozens of others stood, silent, as the officer embraced his sobbing, pregnant wife.\n\nThe officer had forced many people into the camps. Then he himself was flagged for detention.\n\nToo fearful to resist, Liu went along with the arrest, just as the young officer had done before him.\n\nLandasoft software alerted police when flagged people did anything labeled suspicious, like going out at night or logging on the internet repeatedly. Liu was sent to knock on doors, questioning residents whose “eyes filled with fear.”\n\nAs police swept Xinjiang, Landasoft purchased software from Pivotal, a cloud company later acquired by Broadcom, emails show. And Landasoft registered accounts on both Amazon Web Services and Microsoft Azure in 2018, seeking to expand cloud offerings to police clients, emails show.\n\nAWS said Landasoft “consumed very limited cloud services for a brief period” and not for software in the Xinjiang crackdown. Microsoft said Landasoft used Azure services through a self-service portal retired in 2021, and that any Landasoft data was deleted.\n\nThe Xinjiang government told the AP: “There is absolutely no such thing as ‘large-scale human rights violations.’”\n\nLiu eventually resigned and returned to his hometown in eastern China, trying to forget what he had seen and done. But he noted with unease the new cameras and checkpoints being installed around his home.\n\nFour days later, state security called and summoned him for questioning. The all-seeing surveillance apparatus had followed him home.\n\n“The Xinjiang model is being copied everywhere, in every city in China,” Liu said.\n\nIn 2024, Liu left China, ignoring an airport officer who warned that wherever he went, he would be watched.\n\n“This technology has no emotions,” Liu said. “But in the hands of a government that doesn’t respect the law, it becomes a tool for evil.”\n\nAutomated autocracy\n\nThe Yangs are still trapped by U.S. technology. IBM, Dell, HP, Cisco, and Seagate servers, switches and drives power police systems targeting them, maintenance contracts dating to this year show. Intel and Nvidia chips process data. Oracle and VMWare software run the database.\n\nBut the harder the Yangs push, the harder the system pushes back.\n\nIn February 2023, they went to the National Public Complaints Administration in Beijing with a letter. Two days later, police grabbed them from their hotel and drove them home.\n\nThe Yangs persisted, trying to plead their case to Beijing. In the following months, they were seized at bus and train stations, beaten at a hospital and abducted by ambulance.\n\nLast July, Yang’s mother tried again. She carried a letter for Chinese leader Xi Jinping:\n\n“They’re using violence and kidnapping to bar me from petitioning and seeking medical treatment ... We beg you, General Secretary, to save us.”\n\nOutside Beijing’s leadership compound, burly men in black tackled Yang’s mother to the ground. She was jailed for over a month, questioned, strip-searched, force-fed medication and deprived of food and water. In October, she and Yang’s sister disappeared.\n\nThe Yangs’ house is now the last left standing. The father lives alone.\n\nHis relatives have cut contact, unnerved by the flock of police that tail him. Thousands of pages of documents stashed in drawers, stuffed in bags, and piled in boxes in a bathtub chronicle every step of their 16-year quest for justice.\n\nIn April, Yang was sent criminal charges showing how much police had spent to stop the family’s “abnormal petitioning.”\n\nThe cost: About $37,000.\n\n__\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/us-tech-companies-enabled-surveillance-040441040.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel’s chief executive of products departs among other leadership changes",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/dee0bcafc675be2b",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel and Dell announce key leadership exits",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/12b96d116a22c7f3",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Bridge 2025 v15.1.1",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-bridge-2025-v15-1-1/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Lightroom Classic 2025 v14.5.1",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-lightroom-classic-2025-v14-5-1-3/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Core Ultra 3 205 Reportedly Delivers Up To 48% Higher Multi-Core Performance Vs Core i3 14100",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/intel-core-ultra-3-205-reportedly-delivers-up-to-48-higher-multi-core-performance-vs-core-i3-14100/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "High Potential Cast on What You Need to Know Heading Into Season 2",
      "content": null,
      "source": "Bleeding Cool News",
      "url": "https://bleedingcool.com/tv/high-potential-cast-on-what-you-need-to-know-heading-into-season-2/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Blue City Mayor Tells CNN Just How Far He’s Gone To Interfere With ICE",
      "content": "Democratic Mayor Daniel Biss of Evanston, Illinois, told CNN host Erin Burnett on Monday that his city turned off certain public safety tools in an effort to thwart United States Immigration and Customs Enforcement (ICE).\n\nPresident Donald Trump hinted at stepped-up federal enforcement efforts in Chicago in an Aug. 25 post on Truth Social, following it up with a meme based on a famous character from the “Apocalypse Now” posted Saturday, which included a reference to the quote “I love the smell of napalm in the morning” from the Francis Ford Coppola-directed film. Biss, a Democratic candidate for Congress, told Burnett that he’d ordered license-plate cameras to be turned off. (RELATED: Dems Are Losing Their Minds Over Trump’s ‘Smell Of Deportations In The Morning’ Post)\n\n“The reason that we communicated with our residents this morning is that I got information from a senior state official last night indicating that they had good intel, that they thought it was likely that ICE would be coming to Evanston today and in the coming days, and we just felt that we had a responsibility to let our residents know so they could work to protect themselves,” Biss claimed.\n\nWATCH:\n\n\n\n“We’ve been doing everything we can to protect our residents from before Donald Trump took office, passing strong sanctuary laws to make sure our police are not cooperating with federal civil immigration enforcement,” Biss continued. “Protecting our data, switching off our license plate cameras when we learned that that data was being shared. But we also need to make sure our residents know as much as possible so they can take the steps they need to protect themselves.”\n\nLicense-plate cameras help police with parking enforcement, monitoring traffic flow and to combat auto theft, according to SecurityCameraKing.com. Biss also announced his intention to emulate a stunt pulled by Democratic Mayor Karen Bass of Los Angeles.\n\n“I got trained in rapid response,” Biss told Burnett later in the interview. “So now when ICE comes to town, I get a text. I’m able to go immediately to the location, share rights that individuals have with them, and inform them of their rights. Videotape, bear witness, hold ICE officials accountable.”\n\nResistance to ICE operations to arrest illegal immigrants also included a Milwaukee judge who allegedly helped an illegal briefly evade ICE agents in April and Democratic Mayor Freddie O’Connell of Nashville, who released the names of ICE agents involved in a crackdown on illegal immigrants in the city in May. (RELATED: Jonathan Turley Explains Why Trump Will ‘Win Either Way’ In Chicago Crime Fight)\n\nIn New York City, ICE agents arrested Democratic mayoral candidate Brad Lander on June 18 after he allegedly interfered with an ICE operation in a Manhattan court. Democratic Rep. LaMonica McIver of New Jersey was charged with assaulting an ICE agent after a May incident at an ICE facility in Newark.\n\nIn Texas, there were two incidents where shots were fired at ICE or Border Patrol facilities since July 4, with ten people being charged with attempted murder in connection with the former incident. In another incident, one person fired at the ICE agents with a pistol when ICE raided two California marijuana farms in July after obtaining a warrant, with the FBI offering a $50,000 reward for information leading to the suspect’s identification, arrest and conviction.\n\nAll content created by the Daily Caller News Foundation, an independent and nonpartisan newswire service, is available without charge to any legitimate news publisher that can provide a large audience. All republished articles must include our logo, our reporter’s byline and their DCNF affiliation. For any questions about our guidelines or partnering with us, please contact licensing@dailycallernewsfoundation.org.",
      "source": "The Daily Caller",
      "url": "https://dailycaller.com/2025/09/09/blue-city-mayor-tells-cnn-just-how-far-hes-gone-to-interfere-with-ice/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Corporation $INTC Position Boosted by Advisors Asset Management Inc.",
      "content": "Advisors Asset Management Inc. increased its holdings in Intel Corporation (NASDAQ:INTC – Free Report) by 124.3% in the first quarter, according to its most recent 13F filing with the Securities and Exchange Commission (SEC). The institutional investor owned 50,247 shares of the chip maker’s stock after buying an additional 27,842 shares during the quarter. Advisors Asset Management Inc.’s holdings in Intel were worth $1,141,000 at the end of the most recent reporting period.\n\nA number of other institutional investors and hedge funds have also added to or reduced their stakes in the business. Vanguard Group Inc. grew its holdings in Intel by 2.2% in the 1st quarter. Vanguard Group Inc. now owns 377,390,437 shares of the chip maker’s stock worth $8,570,537,000 after buying an additional 8,291,233 shares in the last quarter. UBS AM a distinct business unit of UBS ASSET MANAGEMENT AMERICAS LLC grew its holdings in Intel by 8.2% in the 4th quarter. UBS AM a distinct business unit of UBS ASSET MANAGEMENT AMERICAS LLC now owns 63,263,339 shares of the chip maker’s stock worth $1,268,430,000 after buying an additional 4,793,927 shares in the last quarter. Northern Trust Corp grew its holdings in Intel by 0.3% in the 1st quarter. Northern Trust Corp now owns 45,969,843 shares of the chip maker’s stock worth $1,043,975,000 after buying an additional 158,288 shares in the last quarter. Invesco Ltd. grew its holdings in Intel by 1.3% in the 1st quarter. Invesco Ltd. now owns 43,651,076 shares of the chip maker’s stock worth $991,316,000 after buying an additional 562,246 shares in the last quarter. Finally, Amundi grew its holdings in Intel by 22.0% in the 1st quarter. Amundi now owns 37,878,097 shares of the chip maker’s stock worth $849,606,000 after buying an additional 6,829,690 shares in the last quarter. 64.53% of the stock is owned by institutional investors.\n\nGet Intel alerts:\n\nAnalysts Set New Price Targets\n\nA number of equities analysts recently issued reports on INTC shares. Rosenblatt Securities reissued a “sell” rating and issued a $14.00 price objective on shares of Intel in a report on Friday, July 25th. Benchmark reaffirmed a “hold” rating on shares of Intel in a research note on Friday, July 25th. Stifel Nicolaus increased their price target on Intel from $21.00 to $24.50 and gave the company a “hold” rating in a research note on Monday, July 21st. Deutsche Bank Aktiengesellschaft began coverage on Intel in a research note on Wednesday, May 21st. They set a “hold” rating and a $23.00 price target for the company. Finally, Citigroup reaffirmed a “hold” rating on shares of Intel in a research note on Tuesday, July 8th. One investment analyst has rated the stock with a Buy rating, twenty-two have assigned a Hold rating and five have assigned a Sell rating to the company’s stock. According to MarketBeat, the company presently has a consensus rating of “Reduce” and a consensus price target of $22.17.\n\nIntel Price Performance\n\nShares of NASDAQ:INTC opened at $24.48 on Tuesday. Intel Corporation has a one year low of $17.67 and a one year high of $27.55. The stock has a fifty day moving average of $22.75 and a 200-day moving average of $21.81. The company has a market capitalization of $107.15 billion, a PE ratio of -5.13 and a beta of 1.23. The company has a debt-to-equity ratio of 0.42, a quick ratio of 0.92 and a current ratio of 1.24.\n\nIntel (NASDAQ:INTC – Get Free Report) last announced its quarterly earnings data on Thursday, July 24th. The chip maker reported ($0.10) EPS for the quarter, missing analysts’ consensus estimates of $0.01 by ($0.11). Intel had a negative net margin of 38.64% and a negative return on equity of 3.78%. The company had revenue of $12.86 billion for the quarter, compared to analyst estimates of $11.88 billion. During the same quarter last year, the company posted $0.02 EPS. Intel’s revenue was up .5% on a year-over-year basis. Intel has set its Q3 2025 guidance at 0.000-0.000 EPS. As a group, equities analysts anticipate that Intel Corporation will post -0.11 EPS for the current fiscal year.\n\nIntel Company Profile\n\n(Free Report)\n\nIntel Corporation designs, develops, manufactures, markets, and sells computing and related products and services worldwide. It operates through Client Computing Group, Data Center and AI, Network and Edge, Mobileye, and Intel Foundry Services segments. The company's products portfolio comprises central processing units and chipsets, system-on-chips (SoCs), and multichip packages; mobile and desktop processors; hardware products comprising graphics processing units (GPUs), domain-specific accelerators, and field programmable gate arrays (FPGAs); and memory and storage, connectivity and networking, and other semiconductor products.\n\nFeatured Articles\n\nWant to see what other hedge funds are holding INTC? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for Intel Corporation (NASDAQ:INTC – Free Report).\n\nReceive News & Ratings for Intel Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Intel and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/09/intel-corporation-intc-position-boosted-by-advisors-asset-management-inc/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel shuffles executive deckchairs, tosses 30-year veteran chief overboard",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/bc8de5fbfbdd9420",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Says Former Co-CEO Johnston Holthaus to Depart",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/57028fb1747c2d28",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Illustrator 2025 v29.7.1",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-illustrator-2025-v29-7-1-3/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel’s top Oregon executive, most senior female leader, is leaving the company",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/444eea5fee24237f",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "What to know about the Trump administration's Intel investment",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/a9f519346b5f2b49",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "(PR) Other World Computing (OWC) Launches Thunderbolt 5 Dual 10GbE Network Dock",
      "content": "\"Our goal has always been to remove the friction that slows professionals down, or gets in the way of their doing their work,\" said Larry O'Connor, Founder and CEO, Other World Computing (OWC). \"With the Thunderbolt 5 Dual 10GbE Network Dock, we're giving creatives, IT teams, and power users a smarter, faster, and cleaner way to connect everything they need, without the mess of extra adapters or compromises in speed.\"\n\n\"We can run a live show with 11 cameras on an isolated NDI network, pull footage through the second 10-gig NIC connected to our NAS, plus hook up a second Thunderbolt display—all through a single Thunderbolt 5 cable while keeping the front 2.5GbE port available to run Dante,\" said Guy Cochran, a respected video production consultant with decades of hands-on experience, trusted by creators and major networks such as ESPN and Disney.\n\nMulti-Network Versatility: Dual, fully independent 10 Gb/s Ethernet ports and a front-facing 2.5 Gb/s Ethernet port let you connect up to three separate networks and/or high-speed network devices simultaneously\n\nExtreme Throughput: Bond the 10GbE ports with link aggregation and access your NAS at up to 20 Gb/s from your notebook computer.\n\nOne Simple Solution: Easily handle complex multi-network workflows, unlock high-bandwidth network storage connectivity, and expand your connectivity possibilities with this dock and included Thunderbolt 5 cable.\n\nTransformative: Experience workstation/server-class networking from your notebook and enable workflows that were previously cumbersome or impossible.\n\nConvenient Connectivity: Three Thunderbolt 5 and four USB 10 Gb/s ports give you the flexibility to use both cutting-edge devices and legacy gear.\n\nMore Devices: Create three separate daisy chains of devices - even bus-powered - and remove devices from one chain without affecting the other chains.\n\nGreater Visual Clarity: Enhance your efficiency with sharper details by connecting up to three 8K displays.\n\nSilently Cool: Fanless aluminium enclosure for quiet and cool operation.\n\n\"Thunderbolt 5 opens up entirely new possibilities for creative and production workflows, and OWC's new dock really showcases that. By combining downstream Thunderbolt 5 ports with additional USB connectivity, it gives pros the flexibility to connect everything they need without compromise,\" said Ben Hacker, General Manager, Client Connectivity Division, Intel. \"And for teams working with high-performance NAS solutions like the OWC Jellyfish, this is a game-changer—unlocking the bandwidth and responsiveness they've been waiting for in video and collaborative workflows.\"\n\nOther World Computing (OWC), a trusted leader in high-performance storage, memory, connectivity, software, and accessories that empower creative and business professionals to maximize performance, enhance reliability, and streamline workflows, today announced the launch of its new OWC Thunderbolt 5 Dual 10GbE Network Dock. This powerful dock enables users to connect to multiple high-speed networks, access blazing-fast network-attached storage (NAS), and expand device setups via a single Thunderbolt cable. It is built for pros who need serious speed and flexibility.Creative and IT pros know the struggle—juggling adapters, dealing with too few ports, and waiting on slow network speeds just to get through the day. The OWC Thunderbolt 5 Dual 10GbE Network Dock changes that. With one powerful Thunderbolt connection, you get two 10GbE ports, a 2.5GbE port, three Thunderbolt 5 ports, and four USB ports—all designed to simplify your setup and supercharge your workflow. It's built to handle the demands of media, IT, and production work, whether you are accessing NAS storage at blazing 20 Gb/s speeds or managing multiple networks. Think of it as desktop-class power and flexibility, now available anywhere your Mac or PC takes you.The OWC Thunderbolt 5 Dual 10GbE Network Dock enables:The OWC Thunderbolt 5 Dual 10GbE Network Dock is immediately available and priced at $499.00.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340813/other-world-computing-owc-launches-thunderbolt-5-dual-10gbe-network-dock",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "neural-compressor-pt 3.5",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/neural-compressor-pt/3.5/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "neural-compressor-tf 3.5",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/neural-compressor-tf/3.5/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "UK internet user helps stop teenager launching deadly attack on Ukrainian school",
      "content": "A UK internet user helped police stop a teenager from unleashing a deadly attack on his school in Ukraine, the Metropolitan Police has said.\n\nThe anonymous referral was made to the Met's Counter Terrorism Internet Referral Unit on 4 September, according to the force.\n\nIt warned of an \"imminent attack being planned by an individual in Ukraine\" and was immediately passed to Europol to help alert local police.\n\nA day later, a 15-year-old boy was arrested at a school in Zakarpattia, western Ukraine, the country's ministry for internal affairs confirmed in a post on X.\n\nBe the first to get Breaking News Install the Sky News app for free\n\nThe boy was a student at the school and was arrested with a knife in his backpack while he was livestreaming the incident online, the post revealed.\n\nIt was accompanied by an image of the knife, phone, and rucksack seized by police at the scene.\n\nGet Sky News on WhatsApp Follow our channel and never miss an update Tap here to follow\n\nRead more from Sky News\n\nOnline conspiracies over deaths of 16 election candidates\n\nIsrael launches strikes on Hamas in Qatar\n\nSix killed in rush hour bus shooting\n\nCommander Dominic Murphy, of the Met's Counter Terrorism Command, described the intel and subsequent response as a \"truly remarkable piece of work\".\n\n\"The swift actions by our officers alerting Ukrainian counterparts have helped to avert what could have been a potentially devastating attack at a school in Ukraine,\" he said.\n\n\"It's all the more remarkable when you consider the incredible difficulties those in Ukraine are facing while fighting a war, but thanks to our collective efforts, lives have almost certainly been saved.\"\n\nHe urged people in the UK to report anything suspicious they see online to the Met's internet unit so they can work with international partners to thwart other potential incidents.",
      "source": "Sky.com",
      "url": "https://news.sky.com/story/uk-internet-user-helps-stop-teenager-launching-deadly-attack-on-ukrainian-school-13427703",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "PDF Expert 3.10.19 fix",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/pdf-expert-3-10-19-fix/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Embedded Systems Market Report 2025-2029 and 2034 | Competitive Analysis of Key Players - Samsung, Sony Semiconductor Solutions, Siemens, Intel, Qualcomm Technologies",
      "content": "Dublin, Sept. 09, 2025 (GLOBE NEWSWIRE) -- The \"Embedded Systems Market Report 2025\" report has been added to ResearchAndMarkets.com's offering.\n\n\n\nThis Embedded Systems market report provides a comprehensive analysis of the market's characteristics, size, and growth, including segmentation, regional and country-level breakdowns, competitive landscape, market shares, trends, and strategies. It also tracks historical and forecasted market growth across various geographies.\n\n\n\n\n\n\n\nThe embedded systems market size has grown strongly in recent years. It will grow from $110.89 billion in 2024 to $121.55 billion in 2025 at a compound annual growth rate (CAGR) of 9.6%. The growth in the historic period can be attributed to establishment of standards and certifications ensured the reliability and safety of embedded systems, increasing focus on cybersecurity led to the development of secure embedded systems to protect against vulnerabilities, expansion of global manufacturing capabilities provided cost-effective production of embedded systems, growing consumer demand and energy efficiency.\n\nThe embedded systems market size is expected to see strong growth in the next few years. It will grow to $173.8 billion in 2029 at a compound annual growth rate (CAGR) of 9.4%. The growth in the forecast period can be attributed to demand for systems capable of real-time data processing, decreasing costs of embedded system components, growth in demand for tailored embedded solutions, expansion of embedded systems in developing countries and implementation in solar, wind, and other renewable energy solutions. Major trends in the forecast period include advanced embedded systems for military applications, increasing integration with cloud platforms, growth of Industry 4.0, expansion of telematics services and use of blockchain technology.\n\n\n\nThe growing emphasis on energy efficiency and sustainability is anticipated to drive the growth of the embedded systems market in the future. Energy efficiency and sustainability involve using less energy to perform the same tasks, thereby reducing energy waste, and employing methods and technologies that fulfill current needs without compromising the ability of future generations to meet their own needs. These concepts are increasingly important due to rising concerns about environmental degradation, resource depletion, and climate change\n\n. Embedded systems support energy efficiency and sustainability by optimizing energy usage, integrating renewable energy sources, and enabling intelligent grid technologies. For example, in May 2023, according to the International Energy Agency (IEA), global energy investment increased to $1.74 trillion in 2023 from $1.61 trillion in 2022. In 2023, about USD 2.8 trillion will be invested in energy, with over USD 1.7 trillion allocated to clean energy initiatives, including renewable power, nuclear, grids, storage, low-emission fuels, efficiency enhancements, end-use renewables, and electrification. Therefore, the rising focus on energy efficiency and sustainability is driving the growth of the embedded systems market.\n\n\n\nMajor companies in the embedded systems market are developing security solutions to protect embedded devices and systems from cyber threats. These security solutions implement measures such as encryption, authentication, and secure boot mechanisms to safeguard embedded devices and systems.\n\n\n\nNorth America was the largest region in the embedded systems market in 2024. Asia-Pacific is expected to be the fastest-growing region in the forecast period. The regions covered in the embedded systems market report are Asia-Pacific, Western Europe, Eastern Europe, North America, South America, Middle East, Africa. The countries covered in the embedded systems market report are Australia, Brazil, China, France, Germany, India, Indonesia, Japan, Russia, South Korea, UK, USA, Canada, Italy, Spain.\n\n\n\nKey Attributes:\n\n\n\n\n\nReport Attribute Details No. of Pages 200 Forecast Period 2025 - 2029 Estimated Market Value (USD) in 2025 $121.55 Billion Forecasted Market Value (USD) by 2029 $173.8 Billion Compound Annual Growth Rate 9.4% Regions Covered Global\n\n\n\n\n\nKey Topics Covered:\n\n\n\n1. Executive Summary\n\n\n\n2. Embedded Systems Market Characteristics\n\n\n\n3. Embedded Systems Market Trends and Strategies\n\n\n\n4. Embedded Systems Market - Macro Economic Scenario Including the Impact of Interest Rates, Inflation, Geopolitics, and the Recovery from COVID-19 on the Market\n\n\n\n5. Global Embedded Systems Growth Analysis and Strategic Analysis Framework\n\n5.1. Global Embedded Systems PESTEL Analysis (Political, Social, Technological, Environmental and Legal Factors, Drivers and Restraints)\n\n5.2. Analysis of End Use Industries\n\n5.3. Global Embedded Systems Market Growth Rate Analysis\n\n5.4. Global Embedded Systems Historic Market Size and Growth, 2019-2024, Value ($ Billion)\n\n5.5. Global Embedded Systems Forecast Market Size and Growth, 2024-2029, 2034F, Value ($ Billion)\n\n5.6. Global Embedded Systems Total Addressable Market (TAM)\n\n\n\n6. Embedded Systems Market Segmentation\n\n6.1. Global Embedded Systems Market, Segmentation by Component, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nHardware\n\nSoftware\n\nServices\n\n6.2. Global Embedded Systems Market, Segmentation by Function, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nReal-Time\n\nStandalone\n\nMobile\n\nNetworked\n\n6.3. Global Embedded Systems Market, Segmentation by System Size, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nSmall Size\n\nMedium Size\n\nLarge Size\n\n6.4. Global Embedded Systems Market, Segmentation by End-Use Industry, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nAutomotive\n\nConsumer Electronics\n\nAerospace and Defense\n\nHealthcare\n\nTelecommunication\n\nIndustrial\n\nOther End-Use Industries\n\n6.5. Global Embedded Systems Market, Sub-Segmentation of Hardware, by Type, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nMicrocontrollers (MCUs)\n\nMicroprocessors (MPUs)\n\nDigital Signal Processors (DSPs)\n\nApplication-Specific Integrated Circuits (ASICs)\n\nField-Programmable Gate Arrays (FPGAs)\n\nSensors\n\nPower Management ICs\n\n6.6. Global Embedded Systems Market, Sub-Segmentation of Software, by Type, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nReal-Time Operating Systems (RTOS)\n\nEmbedded Software Development Tools\n\nMiddleware\n\nFirmware\n\n6.7. Global Embedded Systems Market, Sub-Segmentation of Services, by Type, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nDesign and Development Services\n\nConsulting Services\n\nMaintenance and Support Services\n\n7. Embedded Systems Market Regional and Country Analysis\n\n7.1. Global Embedded Systems Market, Split by Region, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\n7.2. Global Embedded Systems Market, Split by Country, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nEmbedded Systems Market Competitive Landscape and Company Profiles\n\nEmbedded Systems Market Competitive Landscape\n\nEmbedded Systems Market Company Profiles\n\nSamsung Electronics Overview, Products and Services, Strategy and Financial Analysis\n\nSony Semiconductor Solutions Corporation Overview, Products and Services, Strategy and Financial Analysis\n\nSiemens AG Overview, Products and Services, Strategy and Financial Analysis\n\nIntel Corporation Overview, Products and Services, Strategy and Financial Analysis\n\nQualcomm Technologies Inc. Overview, Products and Services, Strategy and Financial Analysis\n\nEmbedded Systems Market Other Major and Innovative Companies\n\nHoneywell International Inc.\n\nBroadcom Inc.\n\nNvidia Corporation\n\nAdvanced Micro Devices Inc.\n\nTexas Instruments\n\nSTMicroelectronics\n\nInfineon Technologies AG\n\nNXP Semiconductors\n\nAnalog Devices Inc.\n\nRenesas Electronics Corporation\n\nON Semiconductor\n\nMicrochip Technology Inc.\n\nMarvell\n\nVishay Intertechnology Inc.\n\nArm Limited\n\nFor more information about this report visit https://www.researchandmarkets.com/r/xho2gi\n\nAbout ResearchAndMarkets.com\n\nResearchAndMarkets.com is the world's leading source for international market research reports and market data. We provide you with the latest data on international and regional markets, key industries, the top companies, new products and the latest trends.\n\nAttachment",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/09/3146621/28124/en/Embedded-Systems-Market-Report-2025-2029-and-2034-Competitive-Analysis-of-Key-Players-Samsung-Sony-Semiconductor-Solutions-Siemens-Intel-Qualcomm-Technologies.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Belarusian spy network uncovered by Eurojust operation, Moldovan ex-intel chief arrested",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/654d3912b9e089d6",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "ROOKE: Democrats Just Gave Their Dumbest Members Ample Opportunity To Embarrass Their Party",
      "content": "House Republicans formed a new subcommittee to investigate January 6, and Democrats took the bait, sending their loudest mouthpieces to represent them.\n\nHouse Speaker Mike Johnson initially announced plans for the new Republican-led Select Subcommittee to Continue Investigation of the Events Surrounding January 6 shortly after the start of the 119th Congress. Still, the formal vote and authorization occurred Sept. 3.\n\nThe subcommittee operates under the House Judiciary Committee, chaired by Republican Ohio Rep. Jim Jordan, with Republican Georgia Rep. Barry Loudermilk leading the Jan. 6-specific efforts. The panel has subpoena power and is tasked with a comprehensive review, with a final report due by Dec. 31, 2026. Republicans hope to build on their earlier investigations, including an interim report released in December 2024 by a previous subcommittee under the House Administration Committee.\n\nRepublicans argue that the original bipartisan select committee formed in 2021 was politically biased against President Donald Trump, selectively presenting evidence and ignoring alternative perspectives. Democrats, including Minority Leader Hakeem Jeffries, have criticized it as an attempt to “whitewash” the attack.\n\nHowever, if Jeffries really felt like this committee was going to change the narrative they crafted surrounding Jan. 6, why on earth would he send Texas Rep. Jasmine Crockett and California Rep. Eric Swalwell to represent the Democratic Party?\n\n🚨BREAKING: Hakeem Jeffries has tapped Eric Swalwell to be the top Democrat on the new GOP-led J6 subcommittee. pic.twitter.com/RWR3Pn90F1 — Daily Caller (@DailyCaller) September 8, 2025\n\nOne can only conclude their inclusion is to turn the subcommittee into a clown show for extra attention. (Sign up for Mary Rooke’s weekly newsletter here!)\n\nSwalwell isn’t known for his decision-making abilities, nor his strong camera presence. He was removed from the House Intelligence Committee in 2023 due to allegations that he had a sexual relationship with a suspected Chinese spy, Christine Fang (Fang Fang), from 2014 to 2015.\n\nDemocrat Rep. Jasmine Crockett thinks Eric Swalwell — who was removed from the House Intel Committee over his relationship with a Chinese spy — is someone people should “really feel inspired by” 🤡 pic.twitter.com/bsl2vlKoVx — RNC Research (@RNCResearch) April 7, 2024\n\nSince Swalwell was seen as enough of a national security risk to make him unfit for sensitive intelligence, it begs the question of why his leadership thinks he should hold any committee roles, much less take part in investigations like that of January 6. This move opens the door to dismissing anything Swalwell says as unqualified or a distraction, despite the House Ethics Committee clearing him of wrongdoing regarding the relationship with Fang Fang.\n\nHis biased, false, or misleading attacks on Republicans and Trump are well-documented, including being a key figure in promoting the Democrat-led Russian collusion hoax as a member of the House Permanent Select Committee on Intelligence (HPSCI) and a ranking member of its CIA Subcommittee. Swalwell actively participated in the committee’s investigation into alleged Russian interference in the 2016 election and potential ties to the Trump campaign. Swalwell’s statements were often cited in post-Mueller analyses as examples of unsubstantiated claims that fueled the false narrative, which led to Trump’s first impeachment trial.\n\n(And let’s not forget that while promoting the Russian collusion hoax, Swalwell appeared to fart during a live TV interview while discussing Trump’s impeachment on MSNBC’s “Hardball with Chris Matthews” in 2019.)\n\n🚨 WATCH: Hakeem Jeffries gets TRIGGERED by question about Rep. Swalwell comparing J6 to 9/11 and Pearl Harbor@AndiNapier https://t.co/GJGyvBzHQ4 https://t.co/6zmFTDAmTP pic.twitter.com/jnzJyQvjYe — Daily Caller (@DailyCaller) September 8, 2025\n\nSimilarly, Crockett isn’t known for being the Democrats’ best and brightest. While she has a knack for driving headlines, it’s not always in the best interest of her party for her to be front-facing.\n\nI’m honored to serve on the new January 6th subcommittee alongside @RepSwalwell and @RepMoskowitz. Together, we will defend the Constitution, protect the truth, and make sure the American people never forget who was responsible for the defilement of the Capitol. pic.twitter.com/gH9JFUYCGy — Congresswoman Jasmine Crockett (@RepJasmine) September 8, 2025\n\nCrockett often exhibits characteristics of being overly partisan, unserious, and lacking intellectual depth, with fiery rhetoric that is easily perceived as imbecilic. She somehow managed to turn the devastating Texas floods into a story about herself. Crockett has also wildly claimed that Republicans would willingly “enslave her.”\n\n🚨NEW: Jasmine Crockett *laughs and claps* as she jokes Trump’s “HAND LOOK LIKE IT’S ABOUT TO FALL OFF”🚨@DailyCaller pic.twitter.com/h06XWEGVRB — Jason Cohen 🇺🇸 (@JasonJournoDC) September 5, 2025\n\nAnd, in July, Crockett tried to shut down an Atlantic magazine profile on her after a reporter reached out to other House Democrats. The profile portrayed Crockett as a power-hungry narcissist who acts foolishly to appeal to certain voters, as is evident in her constant change in speech patterns depending on the audience. But, more importantly, it exposed that her colleagues don’t even seem to like her. The reporter reached out to 20 other House Democrats, and all of them either ignored the request for comment or declined to comment on the record.\n\nSome interesting details from The Atlantic’s profile of Rep. Jasmine Crockett: 1. Her phone’s lock screen is a photo of herself\n\n2. She thought she deserved to be the top Dem on Oversight because she has the largest social media following\n\n3. She tried to shut down the profile… pic.twitter.com/CvRlFtRNkd — Amber Duke (@ambermarieduke) July 28, 2025\n\nJanuary 6 has become a special event to Crockett, who often uses it as a cudgel to beat Trump and Republicans. On the event’s anniversary, shortly before Trump’s inauguration, Crockett claimed that Trump “premeditated and planned” the riot months in advance, despite there being no evidence to back up her claims. (ROOKE: Democrats Would Rather Die Than Eat The Low-Hanging Fruit)\n\nIncluding Swalwell and Crockett seems to be a self-sabotaging move by Democrats. While they successfully chose their top Trump resisters willing to go on any media outlet that will have them to denounce Trump and Republicans, their inclusion makes the Democratic effort appear like a partisan farce rather than a credible counter to the Republican investigation.\n\nFollow Mary Rooke on X: @MaryRooke\n\nSign up for Mary Rooke’s weekly newsletter here!",
      "source": "The Daily Caller",
      "url": "https://dailycaller.com/2025/09/09/rooke-democrats-trump-jasmine-crockett-eric-swalwell-january-6-committee/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel, Now Backed By Trump Administration, Announces Major Leadership Reshuffle: 30-Year Products Veteran To Step Down",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/a46a58324eab2719",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The GAIN AI Act Looks More Like Protectionism Than National Security",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b46e3827ffda946c",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Windows 11 Pro, Intel i7, 2TB SSD, 64GB RAM: HP Slashes $2600 From Its 5/5 Rated Laptop",
      "content": "September is the best month to score amazing laptop deals, thanks to the back-to-school season. Unlike Prime Day in July, which barely had any laptop discounts, Amazon is really stepping up this time: They’re offering a huge $2,600 off this HP business laptop (Intel 13th Gen i7-1355U, Intel Iris Xe Graphics, FHD Touch Screen, 64 GB DDR4, 2 TB SSD) that’s getting perfect 5-star reviews. It’s now available for $1,099 down from $3,699. Plus, you also get some handy extras included like a wireless mouse, a USB-C hub, and a 128GB flash drive.\n\nSee at Amazon\n\nSupercharged HP Laptop\n\nThis HP laptop comes with the latest Intel 13th Gen i7-1355U processor (reaching up to 5.0GHz) and with 10 cores and 12 threads. That simply means it can keep pace with everything you do. It’s paired with Intel Iris Xe Graphics so the visuals are sharp and silky.\n\nWith 64GB of DDR4 RAM and a spacious 2TB SSD, you’ll never be held back by this laptop no matter how many programs you have running or how much data you’re storing.\n\nWhat’s more, the laptop is only 3.5 pounds and 0.73 inches thick so it won’t smother your bag or take up too much space. The 15.6-inch touchscreen screen is also very comfortable and bright with full HD resolution (1920 by 1080 pixels) and 300 nits of brightness: everything will stand out and look alive.\n\nWhen it comes to staying in touch, this laptop has it all covered: It has Wi-Fi 6, which keeps the internet fast and consistent, and Bluetooth 5.3 for rapid pairing with your wireless devices. The camera is excellent for work meetings or online lessons, thanks to HP’s True Vision HD Camera that features a Privacy Guard for keeping things safe. The audio system is optimized for crisp and well-balanced sound so calls and video are clear without the use of headphones.\n\nOne of the standout features is the new Copilot key that launches Microsoft’s AI assistant. You can get help summarizing reports, pulling out insights or automating tedious tasks – all at the touch of a button. Based on Windows 11 Pro, this laptop comes with enhanced security features and tools that business users will appreciate.\n\nDo not delay—September’s the time when it is worth grabbing it before it goes up in price again.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/windows-11-pro-intel-i7-2tb-ssd-64gb-ram-hp-slashes-2600-from-its-5-5-rated-laptop-2000624604",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "HP’s 2025 Laptop Bundle Crashes to Nearly 80% Off, Likely Triggered by Apple’s Latest Launch",
      "content": "Fall is here which means school is back in sessions. If you’re still in need of a laptop for the new semester, first of all, what are you doing? Classes started weeks ago. Thankfully, you’re not out of luck just yet. Multiple retailers still have their back-to-school deals live and many opportunities to save on a new computer can still be found. Take this HP everyday laptop for example. This 2025 model is designed for students and businesses and it comes bundled with a bunch of goodies including a year of Microsoft Office 365. Amazon normally has it listed for $1,500, but for a limited time, the price is down 76% which brings it to just $360.\n\nThis 2025 HP 14 laptop is working with an Intel N150 processor capable of up to 3.4Hz and uses an integrated Intel UHD graphics card. It comes with 16GB of RAM and 128GB of internal storage. It comes pre-installed with Windows 11 Pro and Microsoft Copilot.\n\nSee at Amazon\n\nThe HP 14 is super light, weighing in at only 3.24 lbs. It only 0.71 inches thin. These together make the laptop highly portable as they should have no issue slipping into most backpacks. Great for schlepping back and forth between classes.\n\nBattery life is solid. You’ll get up to 11 hours of use on a single charge. When it dies, it only takes 45 minutes of charging to bring it back over 50%. You can comfortably bring it to your classes without worrying about packing the charger every day.\n\nFree Gifts Included\n\nAlrighty, let’s get to the freebies. With this HP laptop, you’ll get a handful of accessories that will help you on campus. You get a wireless mouse, some dust plugs to keep your ports dust free, a pack of webcam covers to maintain your privacy, and a 256GB microSD card to expand your storage even further.\n\nMost notably, the bundle includes a one year subscription to Microsoft 365. With this, you’ll gain access Microsoft’s full suite of apps such as Word, PowerPoint, Excel, and more — all things you’ll likely be regularly using for your classwork depending on your major.\n\nYou also will have OneDrive storage. This is great for being able to access all your files from a number of devices. Forgot to submit a homework assignment, but now you’ve already left the dorm? Just pull it up on your phone and send it to your professor from there. Easy peasy.\n\nFor a limited time, you can score this HP 14 laptop for students at the discounted price of just $360.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/hps-2025-laptop-bundle-crashes-to-nearly-80-off-likely-triggered-by-apples-latest-launch-2000624470",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Intel promises 'leadership across the board on desktop' when its next-gen Nova Lake CPU launches in late 2026",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_ba3b95fc-670d-4cb4-a6fc-5ad2e715a1e5",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "iPhone 17 Pro Hands-On: The Most Un-Jony Ive iPhones Apple Has Ever Made",
      "content": "I felt a sense of déjà vu as I picked up the iPhone 17 Pro and 17 Pro Max—in Cosmic Orange, of course—at the “Awe Dropping” Apple Event and tried to pin down what about these new Apple smartphones felt so familiar. Then it hit me as I left the Steve Jobs Theater in a tired daze last night: the iPhone 17 Pros remind me of the MacBook Pros with M1 Pro and M1 Max chips.\n\nLike those first “pro” MacBooks, the iPhone 17 Pros are actually built for pros. It’s not just “pro” for marketing. The iPhone 17 Pros are slightly thicker and heavier, have the longest-lasting batteries of any iPhones ever, the best cameras, and are a whole lot more powerful than the iPhone 16 Pros. You feel all the pro-ness as soon as the brick slabs are in your hands. Everything, including the large camera bump or plateau, screams “professional,” just like those 2021 MacBook Pros. And they should because Apple finally prioritized function over form, just like those MacBook Pros, which brought back the SD card slot and MagSafe charging charging. Pro users want an uncompromised gadget—or at least the closest to it—and Apple delivers it this year.\n\nSee iPhone 17 Series at Apple\n\nSee iPhone 17 Series at Best Buy\n\nUnlike the iPhone Air that I couldn’t help but ogle with my jaw on the floor, the iPhone 17 Pros elicited less awe from me. In every way, they are beefed-up versions of the iPhone Pros that came before them. The aluminum unibody design has a Ceramic Shield cutout on the backside for wireless charging, and the camera plateau stretches across the whole top third. It’s not the most beautiful iPhone design (that award still goes to the iPhone 4 or iPhone X, in my opinion), but it’s functional. I even noticed that the antenna lines that cut into the side of the frames now bleed around the camera plateau. It’s very similar to the antenna lines that wrap around the display on the Apple Watch Ultras. Again, functional design first—this supposedly improves cellular and wireless connectivity, according to Apple.\n\nI have touched the Cosmic Orange iPhone 17 Pro. Here’s your first look #AppleEvent pic.twitter.com/HUiB8dxC8l — Ray Wong (@raywongy) September 9, 2025\n\nEven with a heftier design, the iPhone 17 Pros don’t feel bulky. In fact, the iPhone 17 Pro Max—the Pro Max model has always been too big and heavy for me—felt lighter and thinner than it actually is. For the first time ever, I felt I could use the iPhone 17 Pro Max daily and my hands wouldn’t hurt from gripping it like an old Game Boy. The curved metal frame definitely helps to make the iPhone 17 Pros feel thinner than they really are. Its size still isn’t great if you care about pocketability, though.\n\nJust like I said in my iPhone Air hands-on, I’ll have to test the iPhone 17 Pros to see how well the performance and battery life are, and how good the cameras are. That being said, the thicker designs also meant Apple was able to improve the thermals for sustained performance when the A19 Pro chip is pushed hard for 3D mobile gaming and GPU-intensive tasks like capturing RAW photos and videos (and editing them). If that’s not prioritizing function first over form, I don’t know what is. Who remembers the dark days when the thermals on Intel-equipped MacBook Pros were so bad? Apple, post-Jony Ive, seems to give a sh*t about this now, and I’m all for it.\n\nThe Center Stage camera is easily my new favorite camera feature. The ability to hold the iPhone 17 Pros vertically and take horizontal selfies (works for video, too) is a game-changer if you ask me. No more contorting my hand into a claw to hold my iPhone sideways to shoot a selfie or vlog. I also really liked the “Dual Capture” feature, which lets you record video from both the rear and front cameras. The front camera appears as a picture-in-picture box that you can move to any corner of the screen. It’s going to be great for reaction videos.\n\nI also did a table wobble test. Here’s how that went:\n\niPhone 17 Pro table wobble test! Does it pass? Let’s find out! #AppleEvent pic.twitter.com/jhUv1zxR3K — Ray Wong (@raywongy) September 9, 2025\n\niPhone 17 hands-on\n\nThe iPhone 17 was the least exciting model for me, and I spent the least amount of time playing with it. It’s a straightforward update with an A19 chip, a larger 6.3-inch 120Hz display, a new dual-camera system with twin 48-megapixel main and ultrawide lenses, and some new colors. The Sage green colorway is my favorite of the new bunch, but they also lack the vibrancy of the colors from the iPhone 16 series.\n\nThere’s really not much to say about the iPhone 17… it feels like an iPhone 16 Pro, with the same size screen, but with an aluminum frame. It’s lightweight, but not the thinnest or thinnest in the iPhone lineup. It’s the everyperson’s iPhone, and I don’t foresee that changing.\n\nThe best part is probably that the iPhone 17 still starts at $799, now with 256GB of storage.\n\nSee iPhone 17 Series at Apple\n\nSee iPhone 17 Series at Best Buy",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/iphone-17-pro-hands-on-the-most-un-jony-ive-iphones-apple-has-ever-made-2000655964",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Despite cutting the gags, Borderlands 4's PC specs say it still needs 100GB of SSD space",
      "content": "Two days before launch, Borderlands 4 has its PC system requirements. They’re generally on the higher side without teetering over into full-on tech demo lunacy – the RTX 2070 is a minimum-spec graphics card, for instance – though anyone with a smaller SSD will need to make room for the looty FPS sequel’s bumper-size 100GB storage requirement.\n\nI have mixed feelings about this. On the one hand, gargantuan install sizes are kind of obnoxious (even the infamously bloated Call of Duty agrees), and are partly caused by merely visual, high-resolution textures that we increasingly need madly expensive GPUs to even enable. Or at least, to enable without simultaneously committing framerateicide.\n\nOn the other hand, 100 is a very round and satisfying number. Just look at it. Way better than 112 or some garbage. I do wonder if anyone working in Gearbox’s gigabyte dieting department saw it was possible to compress it down to 99GB, potentially avoiding the shock of entering the triple digits, but left it at 100GB just because it’s vaguely nicer. I suspect I’d do the same.\n\nAnyway, here’s the hardware:\n\nBorderlands 4 minimum PC specs\n\nOS: Windows 10 / 11\n\nWindows 10 / 11 CPU: Intel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum)\n\nIntel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum) RAM: 16GB\n\n16GB GPU: Nvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum)\n\nNvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum) Storage: 100GB (SSD required)\n\nBorderlands 4 recommended PC specs\n\nOS: Windows 10 / Windows 11\n\nWindows 10 / Windows 11 CPU: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nIntel Core i7-12700 / AMD Ryzen 7 5800X RAM: 32GB\n\n32GB GPU: Nvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nNvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580 Storage: 100GB (SSD required)\n\nSolid state hungriness aside, it’s a bit strange seeing the Arc B580 in the recommended tier, alongside the RTX 3080 and RX 6800 XT – it’s a good little budget card but not on the same level as those two older, yet bonafide high-end GPUs. Though maybe that means Borderlands 4 performs better-than-recommended on this Nvidia/AMD kit?\n\nAlso, 2K’s post doesn’t mention it specifically, but DLSS 4 Multi Frame Generation is supported as well. This needs a GeForce RTX 50 series card to operate at full pelt, with RTX 40 models making do with DLSS 3-style 2x frame gen.\n\nI’m generally in the 'wait and see how it is' camp on Fourderlands, with its new planet and its many billions of randomly generated firearms, having previously been interested enough to mulch through Borderlands 3 with mates but jointly concluding it wasn’t worth our time. This new one is something of a reset, with its lead writer Taylor Clark claiming it won’t have as many jokes. Which is, at once, likely an improvement and also a weird thing to make a selling point of. B4's out on September 12th.",
      "source": "Rock Paper Shotgun",
      "url": "https://www.rockpapershotgun.com/despite-cutting-the-gags-borderlands-4s-pc-specs-say-it-still-needs-100gb-of-ssd-space",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Advanced Micro Devices, Inc. (AMD) Becomes the Most Under-Owned U.S. Semiconductor Stock",
      "content": "Advanced Micro Devices, Inc. (NASDAQ:AMD) is included in our list of the 14 Tech Stocks to Sell Now According to Ken Fisher.\n\nAdvanced Micro Devices, Inc. (AMD) Becomes the Most Under-Owned U.S. Semiconductor Stock\n\nClose-up of Silicon Die are being Extracted from Semiconductor Wafer and Attached to Substrate by Pick and Place Machine. Computer Chip Manufacturing at Fab. Semiconductor Packaging Process.\n\nBank of America reported on September 3, 2025, that Advanced Micro Devices, Inc. (NASDAQ:AMD), despite being an outperformer in the sector, has become the most under-owned U.S. semiconductor stock among active managers. Active ownership fell to 20% in August from 23% in May and 39% a year earlier.\n\nMeanwhile, Advanced Micro Devices, Inc. (NASDAQ:AMD)’s relative weighting has gone down by 80% year-over-year compared to the S&P 500. This is in line with consensus forecasts, which project 22% sales growth and AMD’s continued gains over the Philadelphia Semiconductor Index. At the same time, the investment firm reiterated its ‘Buy’ rating on AMD, thanks to strong tailwinds from rising artificial intelligence adoption and the company’s sustained market share gains against Intel.\n\nAdvanced Micro Devices, Inc. (NASDAQ:AMD) focuses on designing and developing semiconductors, offering CPUs, GPUs, AI accelerators, and embedded solutions. It serves data centers, client computing, gaming, and specialized applications globally.\n\nWhile we acknowledge the potential of AMD as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 15 Stocks That Will Benefit From AI and 10 Must-Buy Canadian Stocks to Invest in.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/advanced-micro-devices-inc-amd-085831164.html",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "CHILLYHELL macOS Backdoor and ZynorRAT RAT Threaten macOS, Windows, and Linux Systems",
      "content": "Cybersecurity researchers have discovered two new malware families, including a modular Apple macOS backdoor called CHILLYHELL and a Go-based remote access trojan (RAT) named ZynorRAT that can target both Windows and Linux systems.\n\nAccording to an analysis from Jamf Threat Labs, ChillyHell is written in C++ and is developed for Intel architectures.\n\nCHILLYHELL is the name assigned to a malware that's attributed to an uncategorized threat cluster dubbed UNC4487. The hacking group is assessed to have been active since at least October 2022.\n\nAccording to threat intelligence shared by Google Mandiant, UNC4487 is a suspected espionage actor that has been observed compromising the websites of Ukrainian government entities to redirect and socially engineer targets to execute Matanbuchus or CHILLYHELL malware.\n\nThe Apple device management company said it discovered a new CHILLYHELL sample uploaded to the VirusTotal malware scanning platform on May 2, 2025. The artifact, notarized by Apple back in 2021, is said to have been publicly hosted on Dropbox since then. Apple has since revoked the developer certificates linked to the malware.\n\nOnce executed, the malware extensively profiles the compromised host and establishes persistence using three different methods, following which it initializes command-and-control (C2) communication with a hard-coded server (93.88.75[.]252 or 148.72.172[.]53) over HTTP or DNS, and enters into a command loop to receive further instructions from its operators.\n\nTo set up persistence, CHILLYHELL either installs itself as a LaunchAgent or a system LaunchDaemon. As a backup mechanism, it alters the user's shell profile (.zshrc, .bash_profile, or .profile) to inject a launch command into the configuration file.\n\nA noteworthy tactic adopted by the malware is its use of timestomping to modify the timestamps of created artifacts to avoid raising red flags.\n\n\"If it does not have sufficient permission to update the timestamps by means of a direct system call, it will fall back to using shell commands touch -c -a -t and touch -c -m -t respectively, each with a formatted string representing a date from the past as an argument included at the end of the command,\" Jamf researchers Ferdous Saljooki and Maggie Zirnhelt said.\n\nCHILLYHELL supports a wide range of commands that allow it to launch a reverse shell to the C2 IP address, download a new version of the malware, fetch additional payloads, run a module named ModuleSUBF to enumerate user accounts from \"/etc/passwd\" and conduct brute-force attacks using a pre-defined password list retrieved from the C2 server.\n\n\"Between its multiple persistence mechanisms, ability to communicate over different protocols and modular structure, ChillyHell is extraordinarily flexible,\" Jamf said. \"Capabilities such as timestomping and password cracking make this sample an unusual find in the current macOS threat landscape.\"\n\n\"Notably, ChillyHell was notarized and serves as an important reminder that not all malicious code comes unsigned.\"\n\nThe findings dovetail with the discovery of ZynorRAT, a RAT that uses a Telegram bot called @lraterrorsbot (aka lrat) to commandeer infected Windows and Linux hosts. Evidence shows that the malware was first submitted to VirusTotal on July 8, 2025. It does not share any overlaps with other known malware families.\n\nCompiled with Go, the Linux version supports a wide range of functions to enable file exfiltration, system enumeration, screenshot capture, persistence through systemd services, and arbitrary command execution -\n\n/fs_list, to enumerate directories\n\n/fs_get, to exfiltrate files from the host\n\n/metrics, to perform system profiling\n\n/proc_list, to run the \"ps\" Linux command\n\n/proc_kill, to kill a specific process by passing the PID as input\n\n/capture_display, to take screenshots\n\n/persist, to establish persistence\n\nZynorRAT's Windows version is near-identical to its Linux counterpart, while still resorting to Linux-based persistence mechanisms. This likely indicates that development of the Windows variant is a work in progress.\n\n\"Its main purpose is to serve as a collection, exfiltration, and remote access tool, which is centrally managed through a Telegram bot,\" Sysdig researcher Alessandra Rizzo said. \"Telegram serves as the main C2 infrastructure through which the malware receives further commands once deployed on a victim machine.\"\n\nFurther analysis of screenshots leaked via the Telegram bot has revealed that the payloads are distributed via a file-sharing service known as Dosya.co, and that the malware author may have \"infected\" their own machines to test out the functionality.\n\nZynorRAT is believed to be the work of a lone actor possibly of Turkish origin, given the language used in Telegram chats.\n\n\"Although the malware ecosystem has no shortage of RATs, malware developers are still dedicating their time to creating them from scratch,\" Rizzo said. \"ZynorRAT's customization and automated controls underline the evolving sophistication of modern malware, even within their earliest stages.\"",
      "source": "Internet",
      "url": "https://thehackernews.com/2025/09/chillyhell-macos-backdoor-and-zynorrat.html",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "A former manager says a 5-month job hunt has her eyeing a pivot: 'I'm starting to get excited about not managing people'",
      "content": "Karen Del'Olio has struggled to find work since being furloughed from her research program manager role in April.\n\nKaren Del'Olio has struggled to find work since being furloughed from her research program manager role in April. Karen Del'Olio\n\nKaren Del'Olio has struggled to find work since being furloughed from her research program manager role in April. Karen Del'Olio\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nAfter years in management, a frustrating job search has Karen Del'Olio rethinking what she wants next.\n\nIn April, the 59-year-old was furloughed from her role as a research program manager at an academic institution in Massachusetts after a sponsor pulled funding from the project she led. Despite beginning her search in April and applying to dozens of jobs, she said she didn't land any interviews beyond an initial recruiter call during the first four months of her search. While she's since secured two interviews past the recruiter stage, she's still looking for an offer.\n\n\"I just get recruiters who say they're going to send the résumé on, and then I never hear back — I get ghosted,\" she said.\n\nHer furlough is set to end in October, and Del'Olio said she doesn't expect to be rehired — in part because of recent funding cuts from the National Institutes of Health. She was raised to keep a rainy-day fund, and for now, those savings have helped her cover expenses. But she's burning through them quickly, and if her job search stretches much longer, she worries her financial situation could become unstable. While she applied for unemployment benefits in May, she said she wasn't approved until August — at which point she received retroactive payments.\n\nFinancial concerns are one reason she's begun exploring roles outside the management positions she initially targeted. And as her search continues, she's starting to believe the shift might be for the best — that the downsides of management may outweigh the benefits, even with the higher pay.\n\n\"It doesn't have to be in management; though, preferably, that's the pay scale that I'm looking for,\" she said of her next job. \"I'm starting to get excited about not managing people.\"\n\nDel'Olio's experience reflects a broader shift in the US labor market that's made it challenging for workers in managerial positions to find jobs. Several major corporations, including Microsoft, Google, Intel, and Walmart, have cut manager roles in recent years.\n\nIt's not just big businesses. Gusto, a payroll and benefits platform for small and midsize businesses, found that manager firings and layoffs by businesses on the platform had risen 66% between January 2022 and September 2024 for those ages 45 to 54 — and more than 400% for those ages 35 to 44.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nThis trend, dubbed the Great Flattening, reflects a broader push to reduce costs and bureaucracy, moves business leaders say will make their organizations more efficient. But for some laid-off managers, finding new employment has been difficult. Amid economic uncertainty, including tariffs and the early impacts of AI adoption, US businesses are hiring at nearly the slowest pace in more than a decade.\n\nThe pros and cons of management positions\n\nDel'Olio believes she's part of a generation of workers in their 50s and early 60s who are often overlooked in today's job market. She feels they're caught in a gap — not old enough to retire but navigating a workplace that's rapidly evolving, especially with the rise of AI.\n\nShe worries that many job seekers in this age group — many of whom are targeting management roles — may be at a disadvantage as companies prioritize younger, lower-cost workers perceived as more tech-savvy. In addition to needing jobs to continue building retirement savings, many also rely on employment for medical insurance, since Medicare coverage typically doesn't begin until age 65.\n\nGiven these circumstances, Del'Olio said she's torn between focusing her job search on higher-paying manager-level jobs that match her experience and pursuing lower-level roles she may enjoy more — and that could be easier to land.\n\nDel'Olio said she appreciated many aspects of being a manager. She liked establishing strategies, aligning teams toward a shared vision, mentoring others, and designing systems and programs. Her role also gave her broad visibility and allowed her to collaborate across departments. In her job search, she's applied to several clinical research and program management roles in the healthcare sector that she believes would build on her past leadership experience.\n\nBut there were also downsides that have made her reconsider management. Administrative tasks — such as performance reviews and handling team turnover — were time-consuming. She also found it difficult to juggle competing priorities and navigate interpersonal conflicts among coworkers, all while staying accountable for her team's performance. She added that she sometimes wished she could spend less time \"putting out fires\" and working to keep team morale positive.\n\nIn recent months, Del'Olio has spent more time exploring non-managerial roles that allow for more creativity, innovation, and work-life balance — without the day-to-day demands of managing a team. She said she's especially drawn to roles related to health communications, marketing and branding, content development, digital health, and quality improvement.\n\n\"I feel I can be more creative and innovative in non-managerial positions,\" she said. \"I'd rather connect people and build relationships and not manage their tasks.\"\n\nTrying to stay a step ahead of a changing job market\n\nDel'Olio said her job search strategies have included customizing her résumé for each position and reaching out to recruiters on LinkedIn. She's also used ChatGPT to help revise her résumé, hoping it will suggest \"modern\" terms that are more likely to be recognized by applicant tracking systems. She also tries to include relevant language from the job description in her résumé.\n\n\"If you don't match the language specifically, you may get a low score through that AI-powered screening process,\" she said. \"I've even gotten an automatic decline within an hour.\"\n\nDel'Olio said she's also concerned that her age may be working against her. Even if she doesn't list her birth date in an application, she suspects AI hiring systems can estimate her age based on the length of her work history, which could be hurting her chances. To try to counter this, she's removed the dates from her degrees and some of her past jobs.\n\nIn the coming months, Del'Olio plans to learn more about data management and AI technologies to make herself more marketable to employers. She said she intends to join some AI-focused groups on LinkedIn and pursue some online AI certifications.\n\n\"If you can't beat 'em, join 'em,\" she said, referencing the potential for AI to negatively impact employment in certain sectors.\n\nIf her search continues to stall, Del'Olio said she may have to expand it even further — to any role that simply offers a paycheck. In the meantime, she's trying to keep up with a job market that feels like it's constantly shifting.\n\n\"I think the entire world of work has changed,\" she said. \"The way that we hire; the way that we manage; the way that we promote.\"",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/former-manager-cant-find-job-looking-roles-outside-management-2025-9",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Hedgehog-like mini PC doesn't have a fan - silent Mele Cyber X1 is designed to run 24/7 and is cooled by hundreds of metal spikes",
      "content": "MeLe Cyber X1 UHD Graphics supports 4K playback and handles productivity tasks efficiently\n\nHundreds of metal spikes replace fans to achieve completely silent operation\n\nIntel N150 processor delivers modest performance with four cores\n\nThe MeLe Cyber X1 is the latest addition to MeLe’s series of compact mini PCs, following the trend set by the previous Quieter series.\n\nThis mini PC relies on a dense metal fin heatsink made up of hundreds of tightly packed metal spikes covering its top panel.\n\nThis design disperses heat without the need for fans, allowing silent operation even during continuous 24/7 use.\n\nSilent design but with entry-level Intel performance\n\nThe system is powered by the Intel N150, a 12th-gen Twin Lake-N processor with four cores, four threads, and speeds up to 3.6GHz.\n\nThe MeLe Cyber X1 integrates Intel UHD Graphics, which handles video playback, light gaming, and common productivity tasks, with codec support for AV1, VP9, and h.265 up to 4K at 60 frames per second.\n\nWhile it is not intended to rival high-performance systems, the configuration is adequate for Windows 11 Pro, general browsing, office work, and low-demand design applications.\n\nThe unit comes with 16GB of LPDDR5 memory running at 4800MHz, permanently soldered onto the motherboard, making upgrades impossible.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nStorage is provided through a 512GB SSD, complemented by a microSD slot supporting up to 2TB expansion.\n\nFor display and external device support, the MeLe Cyber X1 offers two HDMI 2.0a ports and a USB Type-C 3.2 Gen2 connection capable of video output via DisplayPort 1.4 as well as 10Gbps data transfer and PD 3.0 power delivery.\n\nAdditional connectivity comes from a mix of USB-A 3.2 Gen1, USB-A 3.2 Gen2, USB 2.0, and a 3.5mm audio jack.\n\nNetwork options include Gigabit Ethernet, Wi-Fi 5, and Bluetooth 5.1, although these are not the most recent standards available.\n\nThe package includes a VESA mount and a Kensington lock slot for security, but the absence of newer wireless standards raises questions about long-term suitability for demanding business networks.\n\nThe Cyber X1 is available for €299.99, which is not unreasonable but puts it in competition with systems offering faster processors or more flexible upgrade paths.\n\nIt may not be the best workstation or business PC for power users, but it could find its place as a silent mini PC for offices, digital signage, or continuous low-power tasks.\n\nUltimately, it seems designed less for versatility and more for specialized use where silence and 24/7 reliability matter more than raw performance or expandability.\n\nVia Android PC (originally in Spanish)",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/hedgehog-like-mini-pc-doesnt-have-any-fan-silent-mele-cyber-x1-is-designed-to-run-24-7-and-is-cooled-by-hundreds-of-metal-spikes",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Intel confirms Arrow Lake refresh set for 2026, Nova Lake later that year — company admits there are 'holes to fill on the desktop front,' says it is 'confident in the roadmap'",
      "content": "Intel confirmed at a recent Goldman Sachs Technology conference that it plans to launch a refresh of its Arrow Lake processors \"next year,\" with its true next-generation Nova Lake designs to follow along before the end of 2026, as per a transcript of the presentation. Although this likely means at least another year of AMD's Ryzen 9000 CPUs holding the gaming performance crown, Intel maintains that it's \"confident in the road map,\" as it stands.\n\nThe statement came from Intel's Corporate Vice President, Investor Relations, John Pitzer. He said: \"We've got a couple of holes we've got to fill on the desktop front. But quite frankly, we feel confident in the road map [...] We'll have a refresh of Arrow Lake next year, which will help start the process on the desktop side, and then we'll conclude that with Nova Lake when we launch late next year into 2027.\"\n\nWe've been hearing hints about a refresh of the Core Ultra 200 generation of CPUs for some time now, with various rumors about what it might involve. Improved binning and clock speed tweaks should result in a higher boost clock for CPUs involved in the refresh, though that may be limited to just K and KF-series models if some rumors are to be believed.\n\nThere was some talk about Intel introducing a newer, more capable neural processing unit (NPU) for AI workloads, but the most recent reports suggest that this is no longer happening, or was never officially planned.\n\nThe upgraded Core Ultra 200 CPUs are expected to maintain the same core counts, though we may see increased power limits in some models.\n\nA 2026 launch for such a refresh, though, feels quite late. By the middle of 2026, Intel's Arrow Lake generation will be almost two years old, and AMD will likely be well on its way to launching its next-generation Zen 6 CPUs. Although some recent rumors suggest mobile Zen 6 CPUs might not launch until 2027, giving Intel some breathing room to launch Nova Lake, the desktop versions should arrive before the end of the year. AMD will release more concrete roadmap details this November, giving us a clearer outline of what to expect over the next 18 months.\n\nWhether Zen 6 and Nova Lake debut before the end of 2026 or just after, though, that's not a huge lead time for any Arrow Lake refresh processors to gain much ground. They'd need to be notably faster than existing Core Ultra 200 CPUs to be particularly relevant, so far from the original launch date, and pricing would need to be exceedingly favorable to attract buyers who can see so many shiny next-generation CPUs just over the horizon. Especially since Nova Lake is expected to use an entirely new socket, severely limiting upgrade paths for Arrow Lake buyers.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/intel-confirms-arrow-lake-refresh-set-for-2026-nova-lake-later-that-year-company-admits-there-are-holes-to-fill-on-the-desktop-front-says-it-is-confident-in-the-roadmap",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "4-bit Single Board Computer Based on the Intel 4004 Microprocessor",
      "content": "[Scott Baker] is at it again and this time he has built a 4-bit single board computer based on the Intel 4004 microprocessor.\n\nIn the board design [Scott] covers the CPU (both the Intel 4004 and 4040 are supported), and its support chips: the 4201A clock-generator, its crystal, and the 4289 Standard Memory Interface. The 4289 irons out the 4-bit interface for use with 8-bit ROMs. Included is a ATF22V10 PLD for miscellaneous logic, a 74HCT138 for chip-select, and a bunch of inverters for TTL compatibility (the 4004 itself uses 15 V logic with +5 V Vss and -10 V Vdd).\n\n[Scott] goes on to discuss the power supply, ROM and page mapper, the serial interface, the RC2014 bus interface, RAM, and the multimodule interface. Then comes the implementation, a very tidy custom PCB populated with a bunch of integrated circuits, some passive components, a handful of LEDs, and a few I/O ports. [Scott] credits Jim Loo’s Intel 4004 SBC project as the genesis of his own build.\n\nIf you’re interested in seeing this board put to work check out the video embedded below. If you’d like to know more about the 4004 be sure to check out Supersize Your Intel 4004 By Over 10 Times, The 4004 Upgrade You’ve Been Waiting For, and Calculating Pi On The 4004 CPU, Intel’s First Microprocessor.",
      "source": "Hackaday",
      "url": "https://hackaday.com/2025/09/11/4-bit-single-board-computer-based-on-the-intel-4004-microprocessor/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "This Elite-Level HP Laptop Bundle (64GB RAM, 2TB SSD) Drops Again Overnight, 72% Off and Likely as Low as It Gets",
      "content": "Amazon is not messing around with this new laptop deal, which is only fitting because it’s on a laptop that also does not mess around. You can get a fully loaded 17-inch HP Business Laptop with a 12-core Intel Ultra 7 255U processor, supercharged AI power, and 2TB of storage for a 72%-off price of $1,119 — that’s a savings of over $2,800.\n\nAlong with this enormously powerful HP touchscreen laptop comes a $200 accessories package including a wireless mouse, USB hub, 128GB flash drive, and 7-in-1 cleaning kit. For additional value, Windows 11 Pro is preinstalled, and the 12 TOPS (Trillions of Operations Per Second) of AI computational power combined with Microsoft Copilot creates a peak AI device.\n\nSee at Amazon\n\nTerrific Touchscreen\n\nThe generously proportioned 17.3-inch touchscreen of this business laptop is not only a perfect interactive device giving the user a rapid-reaction tablet-like experience, but it’s a vivid HD+ (1600 x 900 resolution) display with anti-glare treatment and 250 nits of brightness. The keyboard is also backlit for better accessibility, and the Copilot key is present for one-touch deployment of the powerful AI features.\n\nWhatever you have on that high-performing screen — anything from multiple windows of complex spreadsheets to whatever TV show or movie you’re streaming — will come through without any hesitation or glitching. That’s because the 12-core Intel Ultra 7 255U processor is an absolute beast, able to hit speeds of up to 5.2GHz and bolstered by a maxed-out 64GB of RAM. The huge 2TB SSD reads and writes data with impressive speed, and the huge amount of storage and memory combined with the elite processor makes this HP laptop virtually future-proofed.\n\nAll the Connections\n\nThe Wi-Fi 6 and Bluetooth 5.4 hookups are just the tip of the connectivity spear. This HP laptop has a 720p HD webcam with a privacy shutter built in, and there are two USB-A, one USB-C, and an HDMI 1.4b port at the ready should you want to connect parallel accessories, including the 128GB USB flash drive and 7-in-1 USB hub that come free with this laptop. The pre-tuned stereo speakers complete this truly impressive package.\n\nWhile the $4,000 retail price for this 17.3-inch HP Business Laptop with Windows 11 Pro and accessories bundle is a little bloated, to say the least, the huge 72% Amazon price cut lands it at an exceptionally competitive $1,119. With the powerful Intel processor, huge cache of memory and storage, and hypercharged AI engine, this will be your everyday productivity laptop for years to come.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/this-elite-level-hp-laptop-bundle-64gb-ram-2tb-ssd-drops-again-overnight-72-off-and-likely-as-low-as-it-gets-2000624810",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Spectre haunts CPUs again: VMSCAPE vulnerability leaks cloud secrets",
      "content": "If you thought the world was done with side-channel CPU attacks, think again. ETH Zurich has identified yet another Spectre-based transient execution vulnerability that affects AMD Zen CPUs and Intel Coffee Lake processors by breaking virtualization boundaries.\n\nThe attack, dubbed VMSCAPE (CVE-2025-40300), is said to be the first Spectre-based exploit that allows a malicious guest user in a cloud environment to leak secrets from the hypervisor in the host domain without code changes – injected Return-oriented programming gadgets – and in default configuration.\n\nThe technique is described in a paper [PDF] published on Thursday, \"VMSCAPE: Exposing and Exploiting Incomplete Branch Predictor Isolation in Cloud Environments,\" by Jean-Claude Graf, Sandro Rüegge, Ali Hajiabadi, and Kaveh Razavi. The paper is set to be presented at the 47th IEEE Symposium on Security and Privacy.\n\nCloud computing depends upon virtualization to securely partition physical computing resources into virtual ones, managed by a hypervisor. VMSCAPE targets the Kernel Virtual Machine (KVM) and QEMU (Quick Emulator), as the hypervisor and as the userspace component of the hypervisor in the host.\n\n\"VMSCAPE can leak the memory of the QEMU process at the rate of 32 B/s on AMD Zen 4,\" the authors state in their paper. \"We use VMSCAPE to find the location of secret data and leak the secret data, all within 772 s, extracting the cryptographic key used for disk encryption/decryption as an example.\"\n\nAMD Zen 1-5 processors are affected, as are Intel Coffee Lake processors, which debuted in 2017. Hardware fixes aren't feasible, the authors say, so Linux maintainers have addressed the issue in software. This comes at a cost, however, in terms of performance overhead.\n\nSpectre, a set of vulnerabilities based on processor microarchitecture, has allowed attackers to access sensitive host memory to varying degrees since its disclosure in 2018, alongside another flaw known as Meltdown.\n\nOne of these is known as Spectre v2 or Branch Target Injection, a way to abuse CPU indirect branch predictors, which control speculative execution – executing predicted instructions before they're called for in code, in order to improve performance.\n\nVarious mitigations have been developed and deployed to defend against Spectre-based attacks, generally at the cost of performance. These include: Indirect Branch Restricted Speculation (IBRS), Enhanced IBRS (eIBRS), Automatic IBRS (AutoIBRS), Indirect Branch Prediction Barrier (IBPB), and Single Threaded Indirect Branch Predictor (STIBP).\n\nBut, to date, Spectre v2 attacks have not had much impact because, as the authors note, they assume the attacker has the ability to run local code on the user's system.\n\nThe ETH Zurich boffins took a look at the way AMD and Intel processors handle host-guest boundaries and found the separation isn't sufficient on AMD Zen CPUs and older Intel CPUs. The branch target buffer (BTB) entries between host and guest are not isolated, so the branch predictor mingles predictions across host and guest domains. VMSCAPE exploits this with the help of a set of new attack primitives that the researchers call vBTI (virtualization Branch Target Injection).\n\nAn AMD spokesperson told The Register that a Security Brief will be issued that acknowledges the potential vulnerability. But the fix will be in software.\n\nIn a statement provided to The Register, an Intel spokesperson said, \"Existing mitigations on Intel processors can be used to mitigate this issue. Intel has previously provided guidance for Branch Target Injection (BTI), Branch History Injection (BHI), and Indirect Target Selection (ITS), and Intel engineers are working with Linux to ensure that the appropriate mitigations for these issues as described in these guidance documents are applied to Linux userspace hypervisor software. Linux mitigations are expected to be available on the VMSCAPE public disclosure date, and a CVE for this issue will be assigned by Linux.\"\n\nThe Linux patch, we're told, will be ported to various Linux distributions after its release.\n\nThe authors proposed a mitigation called \"IBPB-on-VMExit\" that Linux developers have optimized under the name \"IBPB before exit to userspace.\" According to the researchers, the overhead depends on the workload and the frequency of userspace exits.\n\n\"For emulated devices (default for QEMU), userspace exits are much more frequent than for virtualized devices (commonly used in enterprise systems),\" the authors observe in a summary note. \"Our benchmarking indicates an overhead of ~10 percent when using an emulated device.\"\n\nWith Zen 4, the authors' benchmark testing suggests \"a marginal 1 percent overhead\" post-patch.\n\nThe Linux mitigation is said to be active for all affected systems, including Zen 5 and even recent Intel CPUs that were not exploitable such as Lunar Lake and Granite Rapids. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/11/vmscape_spectre_vulnerability/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "An Interview with Dan Kim About Intel, Nvidia, and the U.S. Government",
      "content": "Subscribe to Stratechery Plus for full access. Already subscribed? Log in $15 / month or $150 / year\n\nWith Stratechery Plus you get access to the subscriber-only Stratechery Update and Stratechery Interviews, and the Sharp Tech, Sharp China, Dithering, Greatest of All Talk, and Asianometry podcasts.\n\nStratechery Update\n\nSubstantial analysis of the news of the day delivered via three weekly emails or podcasts. Stratechery Interviews\n\nInterviews with leading public CEOs, private company founders, and discussions with fellow analysts. Dithering\n\nA twice-weekly podcast from John Gruber and myself: 15 minutes an episode, not a minute less, not a minute more. Sharp Tech\n\nAndrew Sharp and myself discuss how technology works and the ways it impacts our lives. Sharp China\n\nA weekly podcast from Andrew Sharp and Sinocism’s Bill Bishop about understanding China and how China impacts the world. Greatest Of All Talk\n\nA twice-weekly podcast from Andrew Sharp and Ben Golliver about the NBA, life, and national parks. Asianometry\n\nAudio and transcripts of the Asianometry YouTube channel, the best source for learning about how tech works.\n\nStratechery Updates are also available via SMS, RSS, or on this site. Please see the Stratechery Update Schedule for more details about delivery times and planned days-off. Please note that all subscriptions auto-renew monthly/annually (but can be cancelled at any time). If you are interested in ordering and managing multiple subscriptions for your team or company, please fill in the form here.\n\nFrequently-Asked Questions\n\nHow do I subscribe to the Stratechery Podcast? Once you are subscribed, please visit your Delivery Preferences where you will find easy-to-follow instructions for adding Stratechery Podcasts to your favorite podcast player.\n\nCan I read Stratechery via RSS? Yes! Create a Stratechery Passport account, go to Delivery Preferences, and add your personalized RSS feed. Free accounts will have access to Weekly Articles, while subscribers will have access to the Daily Update as well.\n\nCan I share a Stratechery Update subscription with a friend? No, the Stratechery Update and Stratechery Podcast are intended for one subscriber only. Sharing emails, using shared inboxes, or sharing RSS feeds is a violation of Stratechery’s Terms of Service, and your account may be suspended or your RSS feed reset. Of course occasional forwarding of the Stratechery Update to interested friends or colleagues is totally fine.\n\nCan I buy a subscription for my team? Yes! You can purchase a team subscription here.\n\nCan I switch to an annual plan? Yes! Just go to your account page, choose the ‘Subscriptions’ tab, and click the Annual upgrade button. You will be charged immediately, with a prorated discount applied for the remainder of your current monthly plan.\n\nDo you offer a student discount? Stratechery is purposely kept at a low price — thousands of dollars less than other analyst reports or newsletters — to ensure it is accessible to everyone, including students.\n\nCan you create a custom invoice that meets my government/company requirements? I am happy to create an invoice to your specification for annual subscribers; however, it is simply not viable for me to offer this service to monthly subscribers. Therefore, if you need a custom invoice please subscribe or switch to an annual subscription and contact Stratechery. June 1, 2021 Update: We are hoping to add native support for custom invoices to Passport; you can subscribe to Passport Updates to be notified when it is available.",
      "source": "Stratechery.com",
      "url": "https://stratechery.com/2025/an-interview-with-dan-kim-about-intel-nvidia-and-the-u-s-government/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Hijacker helper VoidProxy boosts Google, Microsoft accounts on demand",
      "content": "Multiple attackers using a new phishing service dubbed VoidProxy to target organizations' Microsoft and Google accounts have successfully stolen users' credentials, multi-factor authentication codes, and session tokens in real time, according to security researchers.\n\nOkta Threat Intelligence uncovered the ongoing attacks, and told The Register that several different criminals and cybercrime gangs are using VoidProxy. The company has issued a detailed report on its findings.\n\n\"We have observed the targeting of multiple industries across multiple geographies, each of which reflects the priorities of the individual customer\" of the phishing-as-a-service operation, the threat hunters said via email, in response to The Register's questions.\n\nThe phishes target any Google and Microsoft accounts, from small businesses to large enterprises, we're told. And while Okta didn't have a confirmed victim count, \"we have observed high-confidence account takeovers in multiple entities,\" the threat intel team told us. \"By extension, we expect Microsoft and Google will have observed a larger number of ATO events, given that VoidProxy proxies non-federated users directly with Microsoft and Google servers.\"\n\n“We regularly see new phishing campaigns like this pop up, which is why we design durable protections to keep users safe from these types of attacks, including defenses against domain spoofing, phishing links, and compromised senders,” a Google spokesperson told The Register. “We also agree with the report’s recommendation that users adopt passkeys as a strong protection against phishing.”\n\nGoogle declined to answer The Register's specific questions, including how many account takeovers it had seen. Microsoft declined to comment.\n\nWhile Okta observed the attacks as beginning around January, the researchers said that they have linked these phishing campaigns to VoidProxy ads on the dark web from as far back as August 2024.\n\nWe have observed high-confidence account takeovers in multiple entities\n\n\"The activity is ongoing,\" the threat intel team said via email. \"We are detecting new infrastructure and generating alerts for customers on a daily basis.\"\n\nHere's how the attacks work. First, the criminals send phishing lures from legitimate, albeit compromised, email accounts from providers including Constant Contact, ActiveCampaign (Postmark app), NotifyVisitors, and others.\n\nThese emails have a link to a URL shortening service (like TinyUrl) embedded within the communication, and the malicious link redirects the victim several times before they land on the first-stage phishing site. The phishing websites are hosted on low-cost domains such as .icu, .sbs, .cfd, .xyz, .top, and .home, and placed behind Cloudflare, which hides the real IP address and makes it more difficult for network defenders to take down the host.\n\nAfter completing a Cloudflare CAPTCHA challenge, thus ensuring the victim is a human and not a bot, the user is sent to the phishing site, which looks exactly like a Google or Microsoft account sign-in page. This service also redirects accounts protected by third-party single sign-on (SSO) providers like Okta.\n\nAttacker-in-the-Middle\n\nThe page looks completely legit to the user, who likely then enters their login credentials. But instead of signing on to their actual Microsoft or Google account, this info is sent to the VoidProxy's attacker-in-the-middle (AiTM) proxy server, where the AiTM attack plays out.\n\n\"It's here that the sophisticated, multi-layered nature of VoidProxy comes into play,\" the report says.\n\nAiTM attacks happen when criminals secretly position themselves between two parties - such as a user and a website - to intercept login and banking credentials, or to listen in on communications and manipulate data flowing between them.\n\nIn this stage of the attacks, the core proxy server, which is hosted on ephemeral infrastructure, captures and relays sensitive information like usernames, passwords, and MFA responses to legitimate Microsoft, Google, and Okta services. These legit services validate and authenticate the users' information and then issue a session cookie, which is also intercepted by the proxy server.\n\n\"A copy of the cookie is exfiltrated and made available to the attacker via their admin panel,\" the report says. \"The attacker is now in possession of a valid session cookie and can access the victim's account.\"\n\nAnd all of these features are offered for sale to other criminals via VoidProxy's phishing-as-a-service operation.\n\nCustomers (aka criminals) receive a full-featured administrative panel that allows them to manage and monitor their phishing campaigns, and a dashboard for each campaign tracks how many credentials and cookies have been stolen on a daily basis. These campaigns and stolen data are also displayed by region with maps of each country showing the victim count.\n\nOkta recommends enrolling in strong authenticators such as Okta FastPass, using FIDO2 WebAuthn (passkeys and security keys), and enforcing phishing-resistance in policy to avoid falling victim to VoidProxy attacks.\n\nThe report authors also tell us that they encourage industry partners - like Microsoft and Google - \"to continue to support and advocate for industry standards like Interoperability Profile for Secure Identity in the Enterprise (IPSIE).\n\n\"A consistent adherence to these standards could, for example, ensure impacted parties can sign a user out of both their device and all their browser apps in real-time whenever a user interacts with known malicious infrastructure,\" the threat intel team told The Register. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/11/voidproxy_phishing_service/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Adaptables Media Timer – An open-source media player for creative code",
      "content": "The Adaptables Media Timer is an open-source media player designed to make complex multimedia scheduling simple and accessible. It supports all the standard audio-visual formats while also being capable of running dynamic formats like web applications and generative coding outputs.\n\nThe Media Timer was developed after noticing that existing media playback devices weren’t very suitable for modern media requirements. Too often, people were stuck with restrictive, basic scheduling limitations or had to convert rich interactive work into simplified video formats. The Media Timer offers a more flexible approach for exhibitions and installations.\n\nThe open-source software lets you easily synchronise your media across an unlimited number of schedules for each day of the week, accepting a much broader range of file types including Processing and Pure Data executables, P5.JS sketches and Python scripts. Built from refurbished hardware, the Media Timers help reduce tech waste while utilising the low power capabilities of single board computers to offer a carbon efficient, environmentally friendly alternative.\n\nThe Media Timer’s custom operating system “AdaptableOS” is built on Debian Linux. The configuration and initialisation software are built using Rust and offer accurate scheduling of media to the second (~10ms). The Media Timer software relies on systemd as the service manager. Acceptable media formats are audio, video, image, slideshow, web applications and executables. Getting started and technical example guides can be found here.\n\nProject Page | Instagram\n\nEco Standard #1 Standard #2 Pro Processor: Intel Atom x5 Z-8350, 1.44GHz\n\nStorage: 8GB/16GB\n\nRAM: 2GB\n\nResolution: 2560 x 1600 32-bit colour\n\nVideo: Display Port (x2)\n\nNetwork: 10/100/1000\n\nUSB: 3×2.0, 1×3.0\n\nPower: 4W/5W Processor: Intel Pentium Silver J5005, 1.5GHz-2.8GHz\n\nStorage: 16GB\n\nRAM: 4GB\n\nGraphics: Intel UHD 600/605\n\nResolution: 2 @ 3840×2160@60Hz, 1 @ 2560×1600@60Hz\n\nVideo: 3 x Display Port\n\nNetwork: 10/100/1000\n\nUSB: 3×2.0, 6×3.2, 1×3.2 type C\n\nPower: 4W/7W Processor: Intel Celeron J4105, 1.5GHz-2.5GHz\n\nStorage: 16GB\n\nRAM: 4GB\n\nGraphics: Intel UHD 600/605\n\nResolution: 2 @ 2560×1600@60Hz\n\nVideo: 2 x Display Port\n\nNetwork: 10/100/1000\n\nUSB: 3×2.0, 6×3.2, 1×3.2 type C\n\nPower: 4W/7W Coming Soon\n\nAll Adaptables kits are made by hand in Glasgow, UK. Our small team crafts each element of every Media Timer, developing our custom operating system and open source software, refurbishing devices and creating multifunctional recyclable cases and packaging.",
      "source": "Creativeapplications.net",
      "url": "https://www.creativeapplications.net/member/adaptables-media-timer-an-open-source-media-player-for-creative-code/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Dynabook just launched a trio of laptops each weighing 849g - and I can't believe that's barely heavier than two cans of Coke",
      "content": "Dynabook launches three ultraportable laptops weighing only 849g\n\nG8, G6, and GS share 13.3-inch displays, long battery life, and slim design\n\nPort selection includes Thunderbolt 4, HDMI, microSD, and Ethernet\n\nDynabook has launched a trio of laptops in Japan, all weighing just 849g (about 1.87 pounds). The new lineup includes the G8, G6, and GS series, each of which are slightly different but share the same ultra-portability.\n\nThe G8 series is the flagship option and is powered by Intel’s Core Ultra 7 or Ultra 5 processors, paired with 16GB of memory and a 512GB SSD.\n\nThis model comes with a 13.3-inch WUXGA non-glare display, promising wide viewing angles and high color reproduction.\n\nSame, but different\n\nSecurity features include facial recognition, along with a TPM chip and password protection.\n\nThe G6 comes with Intel’s Core Ultra 5 processor. Like the G8, it has 16GB of memory and a 512GB SSD, plus the same 13.3-inch screen.\n\nThe G6 also includes facial recognition and a similar port layout, keeping the weight to the same 849g.\n\nThe GS series, introduced as the standard model, uses Intel’s Core Ultra 5 with 16GB of memory but pairs it with a smaller 256GB SSD.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nWhile it shares the same 13.3-inch WUXGA panel and 849g weight, the GS replaces facial recognition with a fingerprint sensor.\n\nBattery performance is consistent across the range, with about 11 hours during video playback and up to 28 hours when idle.\n\nAll three models share the same port layout. On the right side, users get a microSD card slot, two USB 3.2 Gen1 Type-A connectors, two Thunderbolt 4 USB-C ports with power delivery, a LAN port, and a security lock slot.\n\nOn the left side, there’s another Thunderbolt 4 USB-C port, a microphone and headphone combo jack, an HDMI output, and a third USB 3.2 Gen1 Type-A port.\n\nAll three models support Wi-Fi 6E and Bluetooth 5.3 and come with a 2MP webcam featuring a physical shutter for privacy.\n\nBundled software includes Microsoft 365 Basic and Office Home & Business 2024. The systems are offered in Nebula Black and Celeste Blue finishes.\n\nNo word on pricing but they are set to go on sale in Japan in the coming months.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/dynabook-just-launched-a-trio-of-laptops-each-weighing-849g-and-i-cant-believe-thats-barely-heavier-than-two-cans-of-coke",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Intel's 14nm+++ desktop CPUs are making a comeback — chipmaker inexplicably resurrects Comet Lake from five years ago with 'new' Core i5-110",
      "content": "It appears that Intel is experiencing a sense of nostalgia, as the chipmaker (via momomo_us) has introduced the Core i5-110 processor, based on Comet Lake. Comet Lake is a stroll down memory lane for many of us, as these 14nm+++ chips were introduced around half a decade ago.\n\nWhile the Core i5-110 is clearly a Comet Lake part, Intel markets the new chip under the Core Series 1 moniker. The Core Series 1 mainly comprises mobile and embedded Raptor Lake chips. However, Intel has used the series to mask some of its rebadged processors, such as the Core 5 120, which the chipmaker also silently launched. Therefore, the Core i5-110 is the second desktop chip (that we know of) that Intel has added to the Core Series 1 family.\n\nThe Core i5-110, launched in the third quarter of this year, features a six-core, 12-thread configuration with a maximum of 12MB of L3 cache. It features a base clock speed of 2.9 GHz, with a turbo boost clock speed that reaches up to 4.3 GHz. Comet Lake is built on the Skylake microarchitecture, and these processors are produced using Intel's 14nm+++ process technology.\n\nIntel Core i5-110 Specifications\n\nSwipe to scroll horizontally Processor Cores / Threads Base / Boost Clock (GHz) L3 Cache (MB) TDP (W) MSRP Core i5-110 6 / 12 2.9 / 4.3 12 65 $200 Core i5-10400 6 / 12 2.9 / 4.3 12 65 $200 - $210\n\nThe Core i5-110 is a rebadge of the previous Core i5-10400, launched in 2020. The specifications are identical for the two 14nm+++ chips in every way. Both are 65W processors with an Intel UHD Graphics 630 engine that operates between 350 MHz and 1.1 GHz, supporting up to 128GB of DDR4-2666 memory.\n\nThe Core i5-110 is a desktop processor, meaning it is compatible with an LGA1200 socket and either an Intel 400-series or 500-series motherboard. However, Intel has introduced two new sockets since LGA1200, so it's a mystery just how many consumers still have a LGA1200 motherboard that can accommodate the Core i5-110.\n\nDespite the Core i5-110 being a blatant rebrand, Intel is still charging the same price for the chip as it was when it launched five years ago. The RCP (Recommended Customer Price) for the Core i5-110 is $200, which falls within the same range as the Core i5-10400's $200 to $210. It's an insane price considering that 14nm+++ chips should be dirt cheap to produce by now.\n\nAt $200, the Core i5-110 is supposed to be a value processor, but it's hard to see the value in it.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/intels-14nm-desktop-cpus-are-making-a-comeback-chipmaker-inexplicably-resurrects-comet-lake-from-five-years-ago-with-new-core-i5-110",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Battlefield 6 Battle Royale details released — shaping up to be EA’s most ambitious mode yet",
      "content": "Battlefield 6 is getting a Battle Royale mode, and the first details have been released.\n\nBattlefield 6 ended its beta on a high note, drawing thousands of eager players who even queued in menus before matches went live. It went on to break 500,000 concurrent players on Steam alone — a clear sign that Battlefield is back in a big way.\n\nBut no competitive shooter launches these days, it seems, without a Battle Royale mode. Like it or not, Battlefield 6 has one, and it’s aiming to be different. I’ll personally be hoping it avoids the missteps of Splitgate 2, whose underwhelming Battle Royale pushed the game back into beta.\n\nA brutal new take on the shrinking ring\n\nBattlefield 6 will be adding a Battle Royale mode with a zero tolerance zone. (Image credit: Michael Hoglund)\n\nUnlike most Battle Royale games where the zone slowly chips away at your health, Battlefield 6 takes a far harsher approach. Traditionally, players can heal through the damage or pull off clutch plays while stuck in the zone, leading to plenty of tense moments and highlight clips. None of that will be possible here; if you touch the zone, you’re instantly eliminated.\n\nIt’s a drastic change, and honestly, I’m here for it. This approach should push players into fights faster and keep matches from dragging, solving the slow starts that often plague the genre. Call of Duty: Warzone has long struggled with players abusing the zone to win, even after multiple balance tweaks. With no way to exploit it in Battlefield 6, it’ll be fun to see just how chaotic things get.\n\nSquad-focused chaos on a massive scale\n\nLarge map combat is a staple of Battlefield already, and its Battle Royale doesn't sound like a mere clone of other popular titles. (Image credit: Electronic Arts)\n\nLike most Battle Royale games, Battlefield 6 will feature 100 players split into 25 squads of four, which is a familiar setup for the genre. What sets it apart is the return of Battlefield’s class system. Players can mix classes to build a balanced squad, or all choose the same class, but once you lock in your choice, it can’t be changed mid-match.\n\nYou won’t start empty-handed, either. Each class begins with two gadgets, and as the match progresses, you can earn XP by eliminating players or completing missions. This XP contributes to both your personal level, unlocking new traits that enhance your chosen class mid-match.\n\nOne example given is the Assault class gaining faster armor plate equip speed, giving them a slight edge in fights. There’s also Intel cases to look out for, which provide XP to whole of your squad.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe map, progression, loot and second changes…\n\nBattlefield 6 has really captured an audience so far, and it's not even out yet. (Image credit: Electronic Arts)\n\nIn true Battlefield 6 fashion, there’s a brand-new map built entirely around destruction, allowing its layout to shift and change between matches. Vehicles also return, ranging from fast transport options to heavily armored powerhouses that can swing the momentum of a fight.\n\nPlayers can choose from four classes — Assault, Engineer, Support, and Recon — each with distinct roles and gadgets. A training path system lets squads earn XP during matches, unlocking new traits and one-time abilities as they level up their chosen classes.\n\nThe loot system includes five weapon tiers alongside attachments, throwables, gadgets, and strike packages, which are powerful tactical rewards like air strikes that can turn the tide of battle. There’s also a second chance system, with the Support class able to revive teammates and a redeploy feature that lets players return after being eliminated or caught in the zone.\n\nLeaks, launch hopes, and lessons from the past\n\nThe Battle Royale test will be under NDA, but it shouldn't be too long before we see more from it. (Image credit: Electronic Arts)\n\nBattlefield Labs is currently testing the mode, though it’s all under NDA, and some early leaks have already surfaced — something EA is no doubt unhappy about.\n\nThere aren’t many official details yet, and I’ve tried to highlight the most important ones here, but you can find more information in EA's blog post.\n\nThe mode sounds like a genuine breath of fresh air for the genre, and I’m hoping it launches alongside Battlefield 6 in October 2025. It’s still unclear whether it will be bundled with the main game or released as a free-to-play standalone, but hopefully it avoids the fate of Battlefield V and Battlefield 2042, whose Battle Royale attempts were poorly received and quickly abandoned.\n\nI have high hopes for Battlefield, and I want Call of Duty to finally have real competition again. My only concern is that the mode could become the main focus, pulling attention away from the traditional multiplayer experience that made the series great in the first place.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/gaming/battlefield-6-battle-royale-details-released-shaping-up-to-be-eas-most-ambitious-mode-yet",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "This Lenovo Thinkpad laptop is farming pure boardroom aura",
      "content": "The Lenovo Thinkpad X9 Aura Edition is a reinvention of a line going back three decades, and one which is carried out with aplomb. It has enough power for most tasks, a great display, a brilliant keyboard and can be carried anywhere. Plus, it has the battery to make it through a full day of work. But for a better port selection, it would be a slam dunk. If you need a machine to satisfy all of your office needs, you should look no further.\n\nWhy you can trust Creative Bloq Our expert reviewers spend hours testing and comparing products and services so you can choose the best for you. Find out more about how we test.\n\n(Image credit: Future/Sean Cameron)\n\nThe laptop as a form factor has been bound by two dreams: one for power, the other for portability. Neither of them is mutually exclusive, but typically a machine can’t be one and also the other.\n\nAs a designer, one’s job isn’t to pursue philosophical ideals, however, but to render into reality what will best sell to a certain audience. And if we consider the audience as a busy, on-the-go business professional, portability will be the possibility that becomes a priority.\n\nThere are plenty of examples of machines which achieve a light weight, but that isn’t enough to be premium. Vision is needed, and more, a certain je ne sais quoi, without getting too arty farty. Enter the Thinkpad X9 Aura edition, the latest entry by Lenovo in the venerable line of business machines, which looks to make productivity sexy.\n\nIt comes with an all-metal build, a fancy OLED display, advanced biometrics, a new Intel processor, a touted keyboard and more. Perhaps most importantly, distressingly for some, there’s no trackpad nub, no hallmark to laptops from 30 years ago, a sign of a machine with its eyes firmly on the future.\n\nBut as ever, the competition in this space is tight, does the X9 Aura do enough to stand out among, say, laptops for Photoshop?\n\nRead on for our full review.\n\nSwipe to scroll horizontally Specs CPU: Intel Core Ultra 7 258V vPro NPU: Intel NPU Graphics: Intel Arc 140V GPU Memory: 32GB Storage: 1TB SSD Screen size: 14 inch Screen type: OLED Resolution: 2880 x 1800 Refresh rate: 120Hz Colour gamut (measured): 100% DCI-P3 Brightness (measured): 500 nits Ports: 2x Thunderbolt 4 USB-C, 1x HDMI 2.1, Audio Combo Jack Wireless connectivity: Wi-Fi 7, Bluetooth 5.4 Dimensions: 311.2 × 216.7 × 17.95 mm Weight: 1.141kg\n\n(Image credit: Future/Sean Cameron)\n\nDesign, build and display\n\n• Thin and light\n\n• Brilliant 3K display\n\nGet the Creative Bloq Newsletter Daily design news, reviews, how-tos and more, as picked by the editors. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nWith editing, the old maxim is that you know you’re done when there’s nothing left to take away. When it comes to design, things aren’t so straightforward; weight needs to be kept to a minimum, but that can’t come at too much of a sacrifice to power or function.\n\nThat mission in mind, the engineers at Lenovo have clearly been busy, as the X9 Aura makes for a great first impression. The grey colourway might not be designed to set pulses racing, but it catches the eye and is definitely office appropriate; this is one meant to be wielded by executives.\n\nAt 17mm, it is thin, and weighing 1.1kg, it can easily be lifted with one hand. In a backpack, it feels as though it is barely there at all. If you are a student or someone who commutes with their laptop regularly, this should definitely be on your list.\n\nThat’s not least because it also sports MIL standard protection, as has become common for the ThinkPad line. This isn’t to say that it can survive a nuclear explosion, but at a time when most laptops come without sturdiness certifications, the fact that this one can handle a little rough-housing is a differentiating factor.\n\nThe screen can be raised one-handed, and when you do, you’ll see there’s a notch, but not the kind you’ll find on a MacBook. Where those eat up screen space, this one extends into the air above the display, housing the necessary infrared sensors for Windows Hello. It also holds a slightly above-average quality webcam, in all, a sensible use of space.\n\nContinuing to the keyboard, here we find the typical ThinkPad brilliance. Though there’s no trackpad nub in the centre, this is a supremely well-considered option. There’s a nice amount of travel, the keys are well-sized and spaced, and it was easy to build up to a comfortable, fast typing speed with relatively little lead-in time. Truly, it’s a class act of a keyboard.\n\nThankfully, the display is just the same. At over 3K in resolution, everything is pin-sharp given the relatively dinky dimensions of the panel, and it supports full HDR and is Dolby Vision certified. It’s a very nice option for watching video, and the 120Hz refresh rate keeps the interface feeling smooth and fresh.\n\nPeak brightness was also just about enough to battle sunlight, high praise for a laptop, though the slightly glossy nature of the panel means that reflections were sometimes an issue.\n\nWith 100% coverage of the DCI-P3 colour space, it will also suffice for photo work for some, though as ever, if you have specific needs in this area, you’ll be best with a calibrated external monitor.\n\nOne slight sore point, though to be expected on a thin and light, there’s not the best port selection. There are two USB-C slots with support for Thunderbolt 4, a 3.5mm headphone jack and an HDMI port. If you have specific needs, a dongle will be a necessity.\n\nDesign score: 5/5\n\nFeatures\n\n• Bluetooth 5.4 and WiFi 7\n\n• AI inclusions of questionable utility\n\nAs it is 2025, and AI is a mandatory inclusion with every product release, here we can see that it is a headlining ‘feature’ of the X9.\n\nSo there’s a host of inclusions to burnish the ‘AI’ credentials of the ThinkPad. You’ll find camera enhancements to blur your background, intelligent noise suppression for video calls and more. These are typically built into the likes of Teams, but having them more widely across the system could prove to be useful for some.\n\nThere are security optimisations too, which may prove to be useful in a pinch but will be ignored by most. And that sums up the inclusion of AI features on this device. Occasionally, you’ll find something that will prove to be momentarily useful, then the novelty wears off, and its existence is forgotten.\n\nBeyond that, we can see a bevvy of future-proof connectivity options included, such as WiFi 7 and Bluetooth 5.4, which is always a positive. And lastly, there are two speakers tucked into the hinge of the screen, producing a sound which isn’t quite room-filling but certainly good enough for jamming out to while typing up a storm.\n\nFeatures score: 3/5\n\n(Image credit: Future/Sean Cameron)\n\nBenchmark scoring\n\nWe test every one of our laptops using the same benchmarking software suite to give you a thorough overview of its suitability for creatives of all disciplines and levels. This includes:\n\n• Geekbench: Tests the CPU for single-core and multi-core power, and the GPU for the system's potential for gaming, image processing, or video editing. Geekbench AI tests the CPU and GPU on a variety of AI-powered and AI-boosted tasks.\n\n• Cinebench: Tests the CPU and GPU's ability to run 3D software such as Cinema 4D and Redshift.\n\n• UL Procyon: Uses UL Solutions' Procyon software suite to test the system's ability for AI image generation in Stable Diffusion, its Microsoft Office performance and its battery life in a looping video test.\n\n• Topaz Video AI: We use Topaz Video AI to test the system's ability to upscale video and convert video to slow-motion.\n\n• PugetBench for Creators: We use the PugetBench for Creators benchmarking suite to test the system's ability to run several key tasks in Photoshop and Adobe Premiere Pro, as well as its performance when encoding/transcoding video.\n\n• ON1 Resize AI: Tests the system's ability to resize 5 photos to 200% in a batch process. We take the total time taken to resize the images and divide by 5.\n\nPerformance\n\nIf the main benefit of a lighter laptop is portability, the main drawback is power. The smaller the chipset, the smaller the power draw, and the less the power, is the usual calculation applied. But some, especially from the ARM side, have tried hard to counter that narrative, and now Intel has joined the bandwagon. The X9 Aura comes running the latest Core 7 Ultra chip, which promises power efficiency, near instant wake-up and enough oomph to run powerful and demanding programmes. It comes with 32GB of RAM by default and a 1TB SSD to boot, so how does it fare in practice?\n\nAs you might expect, basic tasks like navigating through the slightly infuriating Windows 11 are carried out without a hitch. As is everything from word processing to browsing. There’s not quite the blazing single-core performance of Apple chips, but you’ll certainly not notice any slowdowns.\n\nThe picture then begins to turn when switching to more demanding applications.\n\nStarting with a game, on the Cyberpunk 2077 benchmark, with medium presets, the machine achieved a stable 18fps framerate. As might be expected, this means that if you want to play the latest games, you would be best to look elsewhere.\n\nIt handled lower to medium intensity games and older titles with aplomb, however. And a benefit of the Intel chip is the X86 architecture, meaning that over the Snapdragon competition, there were no compatibility issues.\n\nIn the likes of Geekbench 6, this is borne out, with a single-core score of 2684, keeping up with the likes of more powerful, and power-hungry, H series chips from Intel, though definitely not coming close in multi-core configurations.\n\nWith a score of 6015 overall in Pugetbench Photoshop, we can see that for more CPU-intensive work, the Aura copes well. It’s when the work relies on the GPU, an integrated effort, that things become more complex. While the Aura is capable of tasks such as video editing, it takes a while to do so and gets hot in the process. Lastly, coming to AI workloads, it works surprisingly well, but again, it won’t match a device running a dedicated GPU.\n\nPerformance score: 4/5\n\nPrice\n\nThe X9 Aura is priced starting at £1,300, which gets you a 3K display and all the mod cons, including 32GB of RAM. That puts it right up against several options from Apple and stands it in relatively good stead.\n\n(Image credit: Future/Sean Cameron)\n\nWho is it for?\n\nIf you travel regularly, or have the general need to be mobile, the Lenovo Thinkpad X9 Aura Edition will be of great interest to you. With brilliant ergonomics, a nice display, a great keyboard and plenty of power, it will be able to meet the needs of most professionals. If you want a potent blend of power and portability, this is your bag.\n\nSwipe to scroll horizontally Attributes Comment Rating Design Svelte, comfortable and stylish 5/5 Features Lacks ports but good wireless connectivity options 4/5 Performance Surprisingly powerful 4/5 Value Well priced against MacBook competition 4/5\n\nAlso consider\n\n(Image credit: Apple)\n\nApple MacBook Pro 14 (M4, 2024)\n\nThe MacBook Pro 14 has a few advantages over the Lenovo. It has a longer period of support, an OS that some prefer, better battery life and improved GPU performance. However the Aura holds its own with a pleasant display, still good battery life and a more robust design.\n\n(Image credit: Apple)\n\nMacBook Air 13 (2024)\n\nThe MacBook Air presents an interesting option. In its cheapest configuration it costs nearly £300 less than the Aura, and offers a lot of the same features, along with a competitive RAM allocation. Whether it appeals to you will largely be a matter of whether you need to complete video work, in which case the Mac might be more competitive, and of course where you sit on MacOS vs Windows.\n\n(Image credit: Future)\n\nAsus ProArt PX13\n\nMaybe you need power and mobility, should that be the case then maybe the Asus ProArt PX13 is the machine for you. At 13 inches it may be small, but that also means it is easy to lug around. It’s also possessed of a GeForce RTX 4070 so can game, and make short work of many creative tasks. It can bend too, boasting a tent mode, and with prices on sale starting at £1,899.99, it is at least worth a look in. It is a lot more expensive, but with that spend comes extra flexibility.\n\nFull verdict\n\nThe Lenovo Thinkpad X9 14 Aura Edition is a well-honed laptop clearly targeted at the business professional. It has a great display, a wonderful keyboard, is eminently portable and will fit into almost any workflow, provided said workflow doesn’t also require a GPU. It’s about as close an answer Windows has to the MacBook Air, which is no small praise.",
      "source": "Creative Bloq",
      "url": "https://www.creativebloq.com/tech/laptops/this-lenovo-thinkpad-laptop-is-farming-pure-boardroom-aura",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Intel Talent Bleed Continues",
      "content": "Intel's long-time Xeon chief architect Ronak Singhal is leaving the company after nearly 30 years , marking yet another high-profile departure amid Intel's leadership churn and intensifying competition from AMD and Arm-based cloud CPUs. The Register reports:",
      "source": "Slashdot.org",
      "url": "https://slashdot.org/story/25/09/12/2136201/intel-talent-bleed-continues",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Borderlands 4 Dev Gearbox Asks PC Gamers to Keep Playing for at Least 15 Minutes After They Tweak Settings to See How Performance Has Changed, as Negative Steam Reviews Pile Up",
      "content": "Borderlands 4 has launched on Steam to big concurrent player numbers, but the release was marred by complaints about PC performance that have resulted in a ‘mixed’ user review rating on Valve’s platform.\n\nBorderlands 4 peaked at 207,479 concurrent player numbers on Steam yesterday, September 11, which was significantly higher than any previous Borderlands before it. However, the game launched to ‘mostly negative’ Steam reviews over performance issues and crashing, before recovering overnight to ‘mixed.’\n\nThe complaints revolve around poor performance even on high powered PCs, with some affected by crashing that makes the game difficult to even start.\n\n“Terrible optimization. Another Unreal Engine 5 casualty. Not worth buying in its current state unless you have a NASA PC,” said one person in a negative review.\n\n“Terrible, terrible performance. Worst I've ever seen. Turned it down to Low graphics presets and couldn't hit 60 FPS, even with FSR upscaling on my RX 6900 XT,” said another.\n\nIn response, Gearbox posted a Borderlands 4 Nvidia Optimization guide on Steam, advising players how to optimize their graphics settings for “better performance and framerates” on PC with the Nvidia app.\n\n“As PC gamers begin their Vault-hunting journeys in Borderlands 4, we've seen early feedback from the community surrounding graphics settings and how to achieve optimal performance,” Gearbox said, before outlining the “expected results” for the Borderlands 4 PC specs:\n\nMinimum PC specs - 1080p @ 30FPS with Low Preset settings\n\nRecommended PC specs - 1440p @ 60FPS with Medium Preset settings\n\nGearbox then issued a piece of advice to PC gamers that to me reads like an effort to prevent players from making knee-jerk reactions to the game's performance as soon as they’ve changed their settings: “Please note that any time you change any of your graphics settings, your shaders will need to recompile. Please keep playing for at least 15 minutes to see how your PC's performance has changed.”\n\nGearbox went on to show the “Optimal Settings” charts provided by Nvidia with suggestions for which graphics settings may work best for your combination of GPU and desired display resolution. Meanwhile, it recommended using the Nvidia app to download and install Nvidia’s newest Game Ready Driver (581.29) and “optimize for your system.” If all else fails, “please contact 2K Support for direct assistance.”\n\nBorderlands 4 Review Screenshots View 159 Images\n\nGearbox and publisher 2K Games will be keen to address the performance complaints early, given the impact negative reviews on Steam can have on a video game’s success. Ahead of launch, Gearbox development chief Randy Pitchford had said the Borderlands 4 Day 1 patch “does a lot,” amid concern about the performance of the looter shooter. Pitchford had responded to concern about Borderlands 4’s pre-release performance on PC from some users on X / Twitter.\n\nDespite the Day 1 patch, playing Borderlands 4 on older hardware won't miraculously unlock \"buttery smooth performance,\" Pitchford added. It should be expected that Borderlands 4 is “unplayable” if you’re trying to use a PC below min-spec, he said, and, generally, playing new AAA games on older hardware won't achieve impressive results.\n\nHere’s Pitchford's comment in full:\n\nThe Day 1 patch does a lot! That said, the expectation for using a below min-spec machine should be that the game is unplayable. That the game runs at all on your system is a miracle. That you can get 55 - 60 fps out of heavy combat is actually incredible given how the engine and what's going on under the hood. Your specification doesn't indicate if you're on SDD or HDD, but that could also explain some of the hitching. It's a big, bold, new, seamless world and I'm sorry to say that older hardware may not provide buttery smooth performance for the latest gen AAA games, as has always been the case since the dawn of PC gaming.\n\nAs a reminder, here are Borderlands 4’s PC specs:\n\nBorderlands 4 System Requirements:\n\nMinimum:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-9700 / AMD Ryzen 7 2700X\n\nMemory: 16 GB RAM\n\nGraphics: NVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. Requires 8 CPU Cores for processor. Requires 8 GB VRAM for graphics. SSD storage required\n\nRecommended:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nMemory: 32 GB RAM\n\nGraphics: NVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. SSD storage required\n\nIf you are delving into Borderlands 4 don't go without our updated hourly SHiFT codes list. We've also got a huge interactive map ready to go and a badass Borderlands 4 planner tool courtesy of our buds at Maxroll. Plus check out our expert players' choices for which character to choose (no one agreed).\n\nWesley is Director, News at IGN. Find him on Twitter at @wyp100. You can reach Wesley at wesley_yinpoole@ign.com or confidentially at wyp100@proton.me.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/borderlands-4-dev-gearbox-asks-pc-gamers-to-keep-playing-for-at-least-15-minutes-after-they-tweak-settings-to-see-how-performance-has-changed-as-negative-steam-reviews-pile-up",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "HP 17.3″ Laptop Bundle (32GB RAM, 1TB SSD) Is Almost 80% Off, Now Way Cheaper Than iPad Pro M4 With Less Storage",
      "content": "The Fall semester has already started for college students, so why haven’t you gotten yourself a laptop yet? You may not need it for Syllabus week, but soon you’ll be sent home with more homework than you can imagine. Get a computer that can handle it without completely depleting your monthly budget. Right now, this HP student laptop is down 77% at Amazon. It’s list price is $2,800, but the deal is bringing the price to just $645. That’s a difference of $2,154.\n\nOkay, hey now. That over two thousand dollar discount can’t be real right? Well, kind of. If we take a look at the price history of this item, we’ll see it’s only existed on Amazon since June of this year. After a couple weeks, it immediately shot down in price by roughly as much as it has now (mostly around $800). Since then, it’s been back and forth from a crazy discount like this and its full price, but never back up for more than several days at a time.\n\nSee at Amazon\n\nLooking at the specs, the laptop is pretty good—but not nearly-three-thousand-dollars-good. It’s rocking an Intel Core i3 processor, which is fine. It does come with 32GB of RAM and 1TB of internal storage which is really good, but not pushing the starting price up that much.\n\nSo what gives? I’ll tell you. Some Amazon sellers will try to give the illusion you’re getting a better deal than you are. That starting price is just made up. The discounted rate is the real value of the laptop. But now if we’re looking at that, this laptop had spent most of the Summer at around $800. Now that school has started, it’s come down to its new lowest price of $646. For this reason, really we can say this HP laptop is on sale for $154 off. That’s not bad!\n\nThe HP laptop has a nice and large 17.3-inch display. This is great not just for getting schoolwork done, but if you’re in the dorms, you might end up watching a lot of your shows and movies from it too. Good to have a sizeable screen for that. Of course, you can always connect it to a TV or larger display using the HDMI 1.4 port.\n\nWhat Else Your Getting\n\nOther ports include two USB-A slots, one USB-C, and a good ol’ headphone/mic jack. The HP laptop also supports Wi-Fi 6 as well as Bluetooth 5.0 to easily pair wirelessly to some of your accessories.\n\nSpeaking of accessories, the laptop comes with a number of them as a bonus. You get a wireless mouse, and external CD/DVD drive, a full 1TB external hard drive, along with some webcam covers, dust plugs, and a cleaning cloth. All that plus an HP laptop that comes preinstalled with Windows 11 Pro for $646? Sounds like a pretty good deal after all.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/hp-17-3-laptop-bundle-32gb-ram-1tb-ssd-is-almost-80-off-now-way-cheaper-than-ipad-pro-m4-with-less-storage-2000624999",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Intel resurrects ancient 10th-gen processor for ‘new’ Core i5",
      "content": "Intel would like you to know about a new processor it’s selling. It’s a 6-core, 12-thread, 14-nanometer design that draws 65 watts and runs at 2.9Ghz, called the Core i5-110. If you watch Intel processors like a hawk, that might sound familiar: The specs appear to be identical to the Core i5-10400, a Comet Lake CPU that first debuted in 2020.\n\nIn product terms this is what’s known as a “rebadge,” and it’s hardly unprecedented for both regular chips and other designs. But given the pace of CPU tech, and the issues Intel is facing at the moment, this particular example might rub consumers the wrong way. Assuming they notice, of course — the entire point of a rebadge is getting products out there without making much of a splash. The new listing was spotted by Twitter poster @momomo_US.\n\nDisney/Intel\n\nIntel is calling this a “Core™ processors (Series 1)” though in its defense, it does identify it as “products formerly Comet Lake in the listing. One thing that hasn’t changed is the price. At $200 USD, the i5-110 costs exactly the same as the Core i5-10400 did five years ago. Even if you think that’s a good deal (it’s pretty milquetoast), tracking down the DDR4 RAM to go with it in 2025 might just cancel out any budget plans.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2907842/intel-resurrects-ancient-10th-gen-processor-for-new-core-i5.html",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "New Spectre-based CPU vulnerability allows guests to steal sensitive data from the cloud",
      "content": "ETH Zurich researchers found a new Spectre-BTI attack called VMSCAPE that lets a VM steal host data\n\nIt affects cloud setups using KVM/QEMU on AMD and Intel CPUs, bypassing existing defenses\n\nThey propose flushing the branch predictor on VMEXIT as a low-cost fix\n\nIf Ghostbusters taught us anything, it’s that spectres are notoriously difficult to get rid of.\n\nSecurity researchers from the Swiss public university, ETH Zurich, recently discovered a new Spectre-BTI (Branch Target Injection) attack that allows a malicious virtual machine (VM) to leak sensitive data from the host system, without modifying host software.\n\nThe research team - Jean-Claude Graf, Sandro Rüegge, Ali Hajiabadi, and Kaveh Razavi - conducted a systematic analysis of branch predictor isolation, targeting environments using KVM/QEMU virtualization on AMD Zen 4 and Zen 5 CPUs.\n\nFixing the flaw\n\nIn early June, they developed an exploit and named it VMSCAPE.\n\nAccording to the research paper published earlier this week, VMSCAPE is proof that default mitigations (hardware and software defenses that were previously considered sufficient for speculative execution attacks such as Spectre) are not enough to prevent speculative execution attacks across VM boundaries, and that secrets like disk encryption keys can be leaked in real-world cloud setups.\n\nAll cloud providers running virtualized workloads on vulnerable CPUs using KVM/QEMU are affected by the bug, the researchers further explained, which includes AMD Zen 1-5, and Intel’s Coffee Lake chips. KVM/QEMU is a powerful virtualization stack commonly used in Linux-based cloud environments.\n\nThe bug is now tracked as CVE-2025-40300, but the severity score has not yet been determined.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nChipmakers are already on the move, as well. An AMD spokesperson told The Register that the company is preparing a security brief, as well as a software fix.\n\nAn Intel representative told the same publication that existing mitigations can be used to address this flaw. “Linux mitigations are expected to be available on the VMSCAPE public disclosure date, and a CVE for this issue will be assigned by Linux,\" they added.\n\nThe paper’s authors propose flushing the CPU’s branch predictor using IBPB on VMEXIT as a mitigation for VMSCAPE, as this prevents a malicious guest VM from influencing speculative execution paths in the host. They also stressed that the tests showed negligible performance overhead, and that the fix was practical for deployment.\n\nVia The Register",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/security/new-spectre-based-cpu-vulnerability-allows-guests-to-steal-sensitive-data-from-the-cloud",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Intel Xeon chief architect leaves just 8 months after appointment — Ronak Singhal latest departure in ongoing shakeup",
      "content": "Ronak Singhal, Intel senior fellow and chief architect of Xeon products, will leave the company by the end of the month, as first reported by CRN and confirmed to Tom's Hardware. Singhal appears to be the second chief architect of Xeon products to depart the company in less than a year. His departure emphasizes the deep restructuring under chief executive Lip-Bu Tan, though it remains to be seen who will be responsible for defining the future of Xeon CPUs.\n\nSinghal's departure from Intel just eight months after he succeeded Sailesh Kottapalli as chief architect of Xeon products highlights the turmoil at Intel in general and the company's Data Center Group in particular. Sailesh Kottapalli left in January to join Qualcomm's renewed server CPU initiative, whereas Justin Hotard, general manager of DCG, left the company to become chief executive of Nokia in February. Hotard succeeded Sandra Riviera in early 2024 as Riviera chose to become chief executive of Altera, which was spun off later that year (Riviera was replaced this August). A few days ago, Intel appointed Kevork Kechichian as the head of DCG.\n\nRonak Singhal joined Intel in 1997, right after graduating from Carnegie Mellon University. His most recent role included responsibility for overall Xeon CPU strategy, roadmap execution, and platform-level integration. This included not only chip design but also adjacent technologies such as memory systems, platform security features, and AI acceleration. Singhal was the second chief architect of Xeon products (after Kottapalli) in Intel's history. It is unclear whether he has influenced Intel's Xeon roadmap significantly.\n\nThroughout his 28 years at Intel, Singhal has shaped the architectural direction of several critical product generations. In the late 1990s, he was involved in Pentium 4 validation, and then he led performance optimization for Nehalem and Westmere. He also oversaw the development of Haswell and Broadwell server CPUs. In general, he was quite a cross-disciplinary architect deeply embedded in Intel products as his technical oversight extended beyond cores to encompass CPU microarchitecture, memory systems, platform security, and eventually AI acceleration. Singhal has been granted 30 patents covering CPU architectures.\n\nThe leadership transition aligns with Lip-Bu Tan's strategy to revamp the whole company and Intel's Data Center Group. To accelerate changes, Tan appointed former Arm executive Kevork Kechichian as executive VP and GM of the group. He also shifted accelerators development to a Sachin Katti-led AI subdivision, making CPUs the primary focus within the data center unit.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/intel-xeon-chief-architect-leaves-just-8-months-after-appointment-ronak-singhal-latest-departure-in-ongoing-shakeup",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Get this Ryzen 7 mini PC with 32GB RAM for a crazy low $339",
      "content": "Nowadays, your home or office setup can feature a mini PC without issue because these things aren’t just powerful, but also affordable. The Beelink SER5 Max mini PC is only $339 right now, which is 24 percent off its MSRP at Amazon.\n\nThis tiny device runs on an AMD Ryzen 7 6800H CPU and an amazing 32GB LPDDR5 RAM, which means this thing’ll be uber fast, handling all the tasks you need to get done throughout the day. The 1TB SSD will add plenty of storage space for apps and files, while also booting your system in a blink.\n\nThis Beelink SER5 Max mini PC also supports triple 4K monitors, so you get to multitask like never before.\n\nIf you want a different configuration, there are plenty of mini PCs on sale these days. Here are some alternatives:\n\nFor $319 (20% off) , you can get the Beelink EQi12 with an Intel i5 CPU, 16GB DDR4, a 500GB SSD, and dual screen support.\n\n, you can get the Beelink EQi12 with an Intel i5 CPU, 16GB DDR4, a 500GB SSD, and dual screen support. If you’d rather get a Ryzen system, the Acemagic K1 is down to $315 (28% off) , featuring an AMD Ryzen 7 CPU, 32GB DDR4, a 1TB SSD, and triple display support.\n\n, featuring an AMD Ryzen 7 CPU, 32GB DDR4, a 1TB SSD, and triple display support. If you want something even cheaper, the Acemagic V1 is down to $188.1 (41% off) , featuring an Intel Twin Lake N150 CPU, 16GB DDR4 RAM, and 1TB SSD, as well as dual display support.\n\n, featuring an Intel Twin Lake N150 CPU, 16GB DDR4 RAM, and 1TB SSD, as well as dual display support. The Kamrui GK3Plus is another good option, featuring an Alder Lake N95 CPU, 16GB RAM, and a 512GB SSD, as well as triple-screen support. This one’s only $160, which is 20% under its MSRP, but its CPU will be significantly slower than the Ryzen found in the Beelink SER5 Max.\n\nAll of these are good options, but it does depend on what type of system you prefer and just how much power you’ll need to get your tasks done.\n\nThe Beelink SER5 Max has a fantastic discount, and getting this speedy configuration for $339 is a great deal.\n\nGet a powerful mini PC for $339",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2898428/get-this-ryzen-7-mini-pc-with-32gb-ram-for-a-crazy-low-339.html",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Linux 6.17 Fix Lands To Address Regression With \"Serious Breakage\" In Hibernation",
      "content": "\"Commit 12ffc3b1513e (\"PM: Restrict swap use to later in the suspend sequence\") incorrectly removed a pm_restrict_gfp_mask() call from hibernation_snapshot(), so memory allocations involving swap are not prevented from being carried out in this code path any more which may lead to serious breakage.\n\n\n\nThe symptoms of such breakage have become visible after adding a shrink_shmem_memory() call to hibernation_snapshot() in commit 2640e819474f (\"PM: hibernate: shrink shmem pages after dev_pm_ops.prepare()\") which caused this problem to be much more likely to manifest itself.\n\n\n\nHowever, since commit 2640e819474f was initially present in the DRM tree that did not include commit 12ffc3b1513e, the symptoms of this issue were not visible until merge commit 260f6f4fda93 (\"Merge tag 'drm-next-2025-07-30' of https://gitlab.freedesktop.org/drm/kernel\") that exposed it through an entirely reasonable merge conflict resolution.\"\n\n\"The issue here is that as of 6.17.0-rc1, running hibernate (disk) more than 7 times causes instability on most machines. The hibernate can be run with /sys/power/disk set to any value. The issue is the hibernate image itself becoming corrupted. The instability appears in user space as the timeout and failure of any or all of these commands:\n\n\n\nsudo systemctl is-active systemd-journald\n\nsudo shutdown\n\nsudo reboot\n\nsudo -i exit\n\n\n\nThe system cannot be soft shutdown or rebooted, it has to be power cycled. I believe the init process memory itself is corrupted and thus anything that goes through the init process times out.\"\n\nThis week's round of power management fixes for the in-development Linux 6.17 kernel are on the more notable side with fixes for both AMD and Intel P-State drivers plus addressing a system hibernation issue that could lead to \"serious breakage\" and stems from a Linux 6.16 regression.Intel engineer and power management subsystem maintainer Rafael Wysocki kicked off this week's power management pull request by noting a fix for a \"nasty hibernation regression introduced during the 6.16 cycle.\" The fix elaborates on that nasty regression and ends up being a one-liner to resolve. Wysocki explained in that commit:The issue was brought to light a few days ago in a bug report In addition to fixing that hibernation regression, there are also a few fixes too for the Intel and AMD P-State CPU frequency scaling drivers:- Fix setting of CPPC.min_perf in the active mode with performance governor in the amd-pstate driver to restore its expected behavior changed recently (Gautham Shenoy)- Avoid mistakenly setting EPP to 0 in the amd-pstate driver after system resume as a result of recent code changes (Mario Limonciello)\"Those fixes in the pull request were merged on Thursday ahead of the Linux 6.17-rc6 release coming on Sunday.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.17-PM-Hibernation-FIxes",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Intel has rebranded the dusty old Core i5 10400 as the Core i5 110, presumably because it found a bunch of them tucked down the back of the couch",
      "content": "Ah, you know how it is. You start looking for a pen, or a sticky note, or maybe some spare change, and suddenly you start finding things you lost years ago. In Intel's case, that appears to be a load of Comet Lake-era Core i5 10400 CPUs, but not to worry—it's simply rebranded them as Core i5 110 CPUs, to sync up with its relentlessly-confusing modern chip naming schemes. Oh, and under code name, it's listed as \"products formerly known as Comet Lake.\" How very Prince.\n\nYes, you too could be the proud owner of a five-year-old six-core, 12-thread CPU with a max boost clock of 4.3 GHz and 12 whole MB of L3 cache—albeit with a fancy new name (via Tom's Hardware). To be honest, it's probably still a reasonably decent CPU in many scenarios, but you can't deny that this sort of rebranding makes things even more complicated for your average user trying to decide on their next upgrade.\n\nThat's not to mention that the Core i5 110 is an LGA 1200 socket chip, which is a whole two generations behind. You can still pick up the odd LGA 1200 motherboard if you trawl the listings, but if you ask me it's a pretty damning indictment of both how old this chip seems in 2025, and how Intel hasn't exactly made it easy for would-be upgraders with its socket-switching since 2020, when this chip was first released.\n\nYou'll be pairing it with DDR4, of course, as that's the fastest memory it supports, and you'll be paying $200 according to the MSRP—although the original Core i5 10400 is currently retailing for $130 at Amazon.\n\nYep, that sure is a significant amount of cash for a chip that's been thoroughly outclassed by more recent (and sometimes cheaper) offerings, like the Core i5 13400F. I suppose those of you looking for an upgrade on the LGA 1200 socket might be interested, but for that sort of cash I'd seriously suggest saving up for a more recent motherboard and CPU bundle instead.\n\n(Image credit: Future)\n\nOr taking a look at the used market, for that matter, where Comet Lake-era chips are often found for very sensible cash. Regardless, Intel's naming scheme these days is confusing enough that even we on the PC Gamer hardware team find ourselves occasionally stumped as to which chip architecture falls under which brand.\n\nSay you buy one of Intel's Series 2 chips, what does that get you? It could be Intel Core Ultra 9 285K, a desktop chip forged out of the Arrow Lake architecture. Or the Intel Core Ultra 9 285HX, an Arrow Lake mobile chip. Or the entirely different Intel Core Ultra 288V, a Lunar Lake mobile chip. Or even an Intel Core 210H, a Raptor Lake rehash for laptops. And you still have some Series 1 chips hanging around, as this latest Comet Lake drop shows, though Series 1 could also mean Meteor Lake or even Raptor Lake chips. The differences in age/ability/power/price between all of these chips is potentially huge.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nI think. I'll be honest, I still consult Jacob's chart in this article from time to time when I get confused, and I still have to look up individual chips to figure out which architecture they're using on the regular. And I do this for a living. As a consumer? All I'll say is check, double check, and check again to make sure you're buying the correct chip for your setup.\n\nHonestly, I need a lie down. To be fair to Intel, it's biggest competitor, AMD, also has very confusing naming schemes and the odd bit of dodgy branding, ala the debacle with the Ryzen 5000 XT-series. Anyone got a decoder wheel I could use? All this is giving me a serious headache.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/processors/intel-has-rebranded-the-dusty-old-core-i5-10400-as-the-core-i5-110-presumably-because-it-found-a-bunch-of-them-tucked-down-the-back-of-the-couch/",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "When it comes to Borderlands 4 and its '8 cores or equivalent' requirement, it's actually core quality, not core count, that matters the most",
      "content": "In case you didn't know, because you've been living on Pluto these past few days, Borderlands 4 has launched. It's not exactly been smooth sailing for 2K Games and Gearbox Software, the publishers and developers, as the game's overall performance is rougher than the Drake Passage.\n\nTo help matters (or make things worse, depending on your point of view), 2K produced a detailed chart of what settings Nvidia GPU owners should use to get the best performance. However, most of this just involved enabling upscaling and frame generation. Borderlands 4 is just plain hard on your hardware.\n\nEspecially the CPU, it would seem, because the minimum system requirements demand an '8 core (or equivalent)' processor, citing an Intel Core i7 9700 as an example. Yesterday, I tested a very similar chip, the 9700K, in a rig with a Radeon RX 5700 XT and 1080p Low quality, and the CPU was frequently hitting 100% utilisation in the open world (see below).\n\nBut what if your gaming PC has a processor with fewer cores, a Core i5 or a Ryzen 5 chip, for example? Does that mean you're going to be in trouble? To find out, I've spent the day running a series of tests on two gaming PCs, where I've decreased the number of cores and/or threads active in the BIOS.\n\nStarting with an Intel Core Ultra 9 285K, with 48 GB of Corsair DDR5-8400 and a GeForce RTX 5080, I ran Borderlands 4 at 1080p with DLSS Performance enabled to minimise the impact of the GPU on the results. However, I did enable the Badass quality preset to ensure that the CPU was pushed as hard as possible.\n\nAs you can see, the unpopular 285K is pretty consistent, irrespective of what P- or E-cores are enabled. To be honest, the fact that the game runs as well as it does on just four P-cores (so four threads, as Arrow Lake doesn't support HyperThreading) is absolutely remarkable. Sure, the 1% low frame rate isn't great, and the game does stutter a bit more than normal, but overall not a bad showing.\n\nAs to why the performance just doesn't consistently decrease with the core count, the answer is two-fold. One, Borderlands 4 distributes its workload across a whole host of threads, and none of them are especially heavy on a single core.\n\nI used PIX on Windows to analyse the threads the game generates, and there are an awful lot of background worker threads to handle asset loading, the precompiled PSO pool, Bink (video compression), etc.\n\nIntel's Arrow Lake architecture is quite complex, as unlike previous designs, which comprised a block of P-cores topped by a block of E-core clusters, the distribution of cores in the 285K is such that disabling a couple of P- or E-cores leads to some odd behaviour on the ring bus that handles all the data traffic.\n\nBut what about a more traditional CPU design, where it's just a block of identical cores that can handle two threads apiece? To answer this question, I used an AMD Ryzen 7 9800X3D with 32 GB of DDR5-6000, and the same RTX 5080 graphics card.\n\nWell, shiver me timbers, just look at those four little cores go! Much better than four Arrow Lake P-cores, that's for sure, but don't forget that the 9800X3D houses an almighty wodge of fast L3 cache, so a handful of Zen 5 cores aren't going to be waiting much for data. What's really remarkable, though, is how little difference there is between using just four cores, four threads and eight cores, 16 threads.\n\nObviously, both CPUs are sporting the very latest architectures from AMD and Intel, and I dare say that I'd get very different results using processors from five or six years ago.\n\nI'm a bit disappointed to have not got to the bottom of why Borderlands 4 is so demanding on older CPUs, but I've not given up, and I plan to use PIX across more platforms to see just what's going on. It could simply be a case that older chips don't play ball as nicely as the latest ones do with Windows 11's thread scheduler, or it could be something that's symptomatic of Unreal Engine 5.\n\nEither way, though, where 2K Games is telling you that eight CPU cores is the minimum, I can tell you now that this is not the case, as long as you're using a relatively new six-core processor. Hurrah for small mercies, however they come.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/when-it-comes-to-borderlands-4-and-its-8-cores-or-equivalent-requirement-its-actually-core-quality-not-core-count-that-matters-the-most/",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "5 reasons you need to be more careful with RAM on Ryzen",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/ryzen-memory-compatibility-stinks-but-so-does-arrow-lake/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Bring back your old Mac: 5 ways to refresh the OS on elderly Apples",
      "content": "Any day now, a new version of Apple's macOS is due to launch, and it will exclude the bulk of the Intel-powered models the company has ever sold. However, there are multiple ways to breathe new life into Macs that go back as far as 10 or even 15 years.\n\nThe Reg FOSS desk has two older Intel Macs in daily use that can't run any currently-supported version of macOS, though. Recently, we've been exploring our available options, and we've found that there are multiple potential routes to keep an old-time Mac productive.\n\nmacOS 26 \"Tahoe\" is due in a few days, and there are a whole four Intel Macs that will be able to run it: the 2019 MacBook Pro and Mac Pro, and the 2020 MacBook Pro and iMac. Those are the official models, anyway. As we covered back in 2023, the OpenCore Legacy Patcher project offers a free tool that lets you create a custom-modified macOS installer that will let you install newer versions of macOS onto Macs too old to officially support them. We reckon there's a good chance that a future update to OCLP will make more older models able to run macOS 26.\n\n\"Tahoe\" is officially the last-ever macOS for Intel hardware, though. The switch to Arm-based Apple Silicon processors is permanently closing the door on the \"Hackintosh\" world, and the world of Arm devices is so wildly heterogeneous that there's basically zero prospect of running Arm macOS on anything else. That's why there's the special Armbian distro just to make the current Linux available on Arm kit.\n\nBefore we tried to upgrade one of our daily drivers with OCLP, though, we wanted to test drive upgrading to an unsupported macOS. To this end, we recently pulled a retired MacBook out of storage. It's a 2010 13-inch MacBook Pro. The last supported macOS for this model is 10.13 \"High Sierra\", and the newest mainstream web browser for this is Firefox 115, which is the ESR release from 2023. When its successor Firefox 128 appeared, Mozilla said it would keep updating version 115 for as long as possible. As The Register reported last week, that currently means March 2026. To get to the subsequent Firefox ESR, we needed at least macOS 10.15 \"Catalina\".\n\nThis shouldn't work, but it does: macOS 10.15 running happily on a MacBook Pro from two years before Apple's cut-off - Click to enlarge\n\nThat poses a slight snag. The 2010 MBP is the only Core 2 Duo machine we've encountered that refuses memory that's faster than the 1066 MHz DDR3 SDRAM for which it's specified. It wants at least one PC3-8500 SO-DIMM, and it won't start with PC3-10600, let alone even faster. (We blame the Nvidia GeForce 320M GPU for this fussiness.) As a result, our MBP only has 6 GB of RAM. That's a snag.\n\nThe current release of OCLP is version 2.4.1 and the oldest macOS it supports is macOS 11 \"Big Sur\". Officially, this will run in 4 GB, but we suspect it might be rather sluggish. However, OCLP doesn't support Catalina.\n\nEnter the DOS dude\n\nHelp is at hand from Collin Mistr, AKA dosdude1. Among other apps, he offers a tool called macOS Catalina Patcher. It's a just-over-200-MB download, although obviously you will need a copy of macOS Catalina as well. Apple has a helpful downloads page for every version from 10.7 to 15 (oddly, except 10.9 Mavericks, which was the first release the company distributed for free).\n\nCatalina Patcher offers three different ways to install, including an in-place upgrade. - Click to enlarge\n\nThe \"Install macOS Catalina.app\" file is an 8.26 GB download, so we didn't download a fresh copy: we copied it from our iMac onto a Mac-formatted USB key, and then onto the MBP. Then we downloaded Mistr's patcher and ran it. (Unsurprisingly, this is not an authorized app, as it does something Apple doesn't want to support, so don't double-click it; right-click it and pick Open.) It offers the choice of creating an installer USB, installing onto the machine it's running on, or creating an ISO file.\n\nSince this is a sacrificial testbed machine – it was replaced by a Core i7 Dell Latitude running ChromeOS Flex a couple of years ago – we just told it to install in place. It creates a modified installer in the /tmp folder, then launches that. First this converted our HFS+ SSD into the newer APFS format, then started the upgrade. Apple's time estimate was just under half an hour, but it took longer. Once the process finished, our 2010 MacBook Pro was running the 2020 version of macOS, even though it officially only supports models from 2012 onwards. On its own, macOS found an update for Safari, downloaded and installed it, and we were done.\n\nThere are no giveaways that this is an unofficial OS. The About this Mac dialog box still identifies the correct model, its GPU, its RAM slots, everything. On first launch, Firefox 115 automatically updated itself to version 128, and we then manually upgraded that to the latest 142. It runs fine – not blazingly fast, but pretty well for a 15-year-old computer based on a CPU launched in 2007.\n\nOur primary objective was successfully accomplished: to get a current, supported web browser. A few applets automatically updated themselves, such as the Rectangle window-tiling tool. We had to manually download Chrome from Google's Other Platforms page, and version 128 is the latest for this old OS, but it works.\n\nEvery silver lining has a cloud\n\nThere are some drawbacks to the upgrade, though. The machine is a little more sluggish than before. Although 10.15 was the first all-64-bit version of macOS, it has multiple new features to offset the removal of the 32-bit subsystems: the APFS filesystem, built-in Siri, several separate apps in place of iTunes, and so on. Our ancient but perfectly serviceable copy of Microsoft Office 2011 was 32-bit only so it no longer works. We grabbed the latest LibreOffice 25.8, which does work, but it's not exactly snappy. Now we have dark mode. Woohoo.\n\nTo be honest, just as Office 2011 did everything we wanted and a very great deal more besides, so did High Sierra. As The Register said in 2017:\n\nAll High Sierra's most interesting features are at the deep system level. 10.13 has no new apps and (almost) no new user-facing features at all. Apple has even resisted to give a cosmetic makeover to what's already there.\n\nIn this, it reminds us of the classic Mac OS X 10.6 \"Snow Leopard\", of which the same writer said:\n\nWhat greeted me was familiar: Snow Leopard starts like Leopard, down to the pixel. Apple promises that Snow Leopard frees about 7 GB from a comparable Leopard installation… there's some serious shrinkage going on. Safari's public beta on Leopard weighs in at 45 MB, but the Snow Leopard Safari at just 14 MB. The Address Book shrinks from 58 MB to 15 MB. Mail is now 77.5 MB.\n\nThat's the kind of upgrade we like. These days, 10.6 is hailed as one of the best-ever releases. Perhaps we should say liked, because High Sierra was the last time Apple managed a new version that looked and worked the same, but tightened everything up under the hood.\n\nNostalgia for old OS releases‽\n\nPart of the reason for this dramatic shrinkage was that Mac OS X 10.5 \"Leopard\" was the last ever PowerPC version. 10.6 removed all the PowerPC code, leaving only Rosetta, licensed from Transitive – which also sold it as QuickTransit to HP and Novell before IBM acquired it in 2008.\n\nOfficially, Snow Leopard is Intel only. That hasn't stopped the hardcore PowerMac enthusiasts, though, who have managed to custom-compile and put out a pre-release version.\n\nSome Mac fans miss old versions, just as some Windows fans do. We've written about running the translucent glories of Windows 7 in 2025, as we did about running Windows XP in 2023.\n\nAlthough it still looks sleek, Snow Leopard is so long in the tooth now that it's more of a Smilodon. This vulture ran it for years on a homemade Hackintosh, but we don't want to go back that far.\n\nWe recently discovered the website of Jonathan \"Wowfunhappy\" Alland, a discerning vintage-macOS aficionado who runs Mavericks Forever, and on it, he explains in detail why he chose this particular version; for instance, it was the first OS X to support memory compression, so it runs well on low-memory machines, and it was one of the last versions to retain the Aqua appearance. He also has a meticulously curated Mavericks App Library.\n\nNow that we've upgraded our elderly MacBook Pro, we're considering maxing out its memory and seeing how far we can upgrade it, but we might end up going backwards instead. However, on the same trip when we retrieved the MBP, we also collected an even older MacBook: a 2008 white MacBook. Sadly, this machine really is maxed out. As far as we can find out, OS X 10.7 \"Lion\" really is the last version of OS X it can run.\n\nLeopards and Lions … why not revenant Foxes, and shiny shiny Chromium?\n\nBut some of the hints on Mavericks Forever made us wonder if we could make Lion a little more useful. Before COVID-19, we had installed Firefox Legacy on the machine. It's based on Firefox 68, but although it's not maintained anymore, it still works and can open most contemporary websites. The Mavericks page told us about Firefox Dynasty. This is a port of the current Firefox for older versions of Mac OS X, back to version 10.8 \"Mountain Lion\".\n\nUnfortunately, it's on GitHub, and Firefox Legacy can't open GitHub's JavaScript-riddled Releases page. But we did recently discover another browser that can: Chromium Legacy. The latest version is from May 2024, based on Chromium 127, but it unzips and runs fine on \"Lion\", and in turn, it enabled us to download Firefox Dynasty.\n\nAnd this definitely shouldn't work, but here's the current Firefox (and Chromium 124) on OS X 10.7. - Click to enlarge\n\nResult: the latest Firefox 142, complete with vertical tab bar, running happily on the version of OS X El Reg reviewed in 2011. And, for any websites that won't work right in Firefox, we have a fairly recent version of Chromium as well. Suddenly, that makes this ancient OS a much more viable proposition.\n\nOne limitation of Chromium Legacy is that it can't check for updates – if there ever will be any more – and you may have difficulties fetching it from GitHub using a very old Firefox. Never fear: Wowfunhappy's Chromium Legacy Downloader is here, and he also offers the corresponding Firefox Dynasty Downloader PrefPane.\n\nSomewhere, we think we have a spare 4 GB DDR2 SO-DIMM lying around. We will try to max out the MacBook's RAM at a massive 6 GB, give the creaky old thing a small SSD, and take it out on the road for a run. With two modern browsers, we should be able to handle most things, and fifteen or twenty-year-old writing tools are still absolutely perfect. Maybe we can dig out a copy of Word from before the \"fluent interface\" and its wretched Ribbon were dreamed up.\n\nBootnote\n\nAs we've seen, a community of dedicated and determined enthusiasts is getting more recent OSes and modern browsers working on ancient Intel Macs and PowerMacs.\n\nBut it's not limited to getting newer OSes running on older kit. The counterpart is Mac OS 9 Lives, which has versions of the real original macOS that have been tweaked to run on some later PowerPC G4 hardware, released after Apple started amending the machines' firmware to compel users to switch to the fancy new Mac OS X.\n\nFor instance, there's a build of Mac OS 9.2.2 for iBook G4, and another one for the Mac mini G4. Somewhere, we have both of those machines, and once we can find them, we plan to try this out. They are both rather underpowered for Mac OS X, but they represent the fastest hardware ever made for Mac OS 9.\n\nOur G4 mini was a gift from the late DJ Walker Morgan, who some Register readers may remember for his Unix column in Personal Computer World under the pseudonym of David Evnull. (\"D. Evnull\" – /dev/null – geddit?) Ave, atque, vale. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/13/refresh_an_old_mac/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Intel Loses Another Prominent Linux Engineer - Now Going To NVIDIA",
      "content": "In the past few months at Intel between layoffs / corporate reorganizations and some deciding to pursue job opportunities elsewhere, there have been unfortunate impacts to their Linux engineering resources. Intel over the summer lost some prominent Linux engineering talent and in turn has even led to upstream Linux drivers being orphaned along with other driver maintainers departing and various other staffing changes . Unfortunate for Intel, another notable Linux name has left the company.Colin Ian King announced today that it was his last day at Intel. Colin King had just been employed by Intel for nearly four years but is well known prior to then. Prior to joining Intel, Colin was a kernel engineer at Canonical where he worked on Ubuntu Linux for over 13 years. Colin King was well known for his Ubuntu Linux work and has contributed more than four thousand patches to the upstream Linux kernel over the years. At Intel, Colin continued his kernel contributions with performance optimizations and more.If his name doesn't ring a bell, perhaps you know it from Stress-NG with Colin being the lead developer of those kernel micro-benchmarks. Colin has made incredible contributions to the upstream Linux kernel community over the past many years.Colin announced his departure from Intel today on LinkedIn:\n\nIn there he also announced he will now apparently be working for NVIDIA. For the benefit of the upstream Linux kernel community, hopefully he will be continuing to focus on upstream Linux kernel activity at NVIDIA... Especially given their increasing open-source GPU driver activity as well as growing kernel activity elsewhere from their networking products to other data center offerings and also needing to ensure the Linux kernel is performing effectively for showcasing the power of their products for AI and more.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Colin-King-Leaving-Intel",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "One of our favorite mini PC vendors has launched a ridiculously light laptop with an Intel Core Ultra CPU and a 5-megapixel OLED display",
      "content": "Geekom GeekBook X14 Pro OLED panel delivers 2880×1800 resolution with DCI-P3 coverage.\n\nIntel Core Ultra 200H processors drive performance with integrated Arc graphics.\n\n70 Wh battery promises extended productivity without frequent charging.\n\nGeekom, a company best known for its mini PC range, has stepped into a more competitive space with its first thin-and-light notebooks.\n\nThe GeekBook X14 Pro is only 16.9mm thick, weighs just 999g, and uses a durable aluminum alloy chassis with a 135° hinge.\n\nIts standout feature is a 14-inch OLED screen at 2880 x 1800 resolution and DCI-P3 100% coverage, which roughly equates to a 5-megapixel pixel count.\n\nNot bad for a first attempt\n\nUnder the hood, the X14 Pro features Intel’s Core Ultra 200H “Arrow Lake-H” processors paired with integrated Arc graphics.\n\nThese chips combine Lion Cove and Skymont CPU cores but omit Lunar Lake Xe2 graphics.\n\nThis raises doubts about whether Geekom has chosen the best CPU configuration for sustained performance.\n\nHowever, since this is the company's first attempt, it is probably testing the waters with a modest CPU.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThis device's power draw peaks at 35W, which is typical for lightweight systems but could limit demanding tasks.\n\nMemory is soldered LPDDR5 running at 7500MHz, with up to 32GB capacity, which means there is no opportunity to upgrade.\n\nHowever, there is a single M.2 2280 NVMe SSD slot that provides storage, which may be restrictive for users expecting multiple drives.\n\nThe laptop is powered by a 70Wh battery, which is a relatively high capacity for a device weighing under one kilogram.\n\nIn theory, this battery can support long hours of typical productivity tasks before needing a recharge.\n\nThe battery is paired with a 65W USB-C GaN charger, chosen for its efficiency and small form factor.\n\nFor connectivity, this device comes with HDMI 2.0, a 40Gbps USB-C, a 5Gbps USB-A, and a headphone jack.\n\nWireless support includes Wi-Fi 6E and Bluetooth 5.4, while integrated DTS:X Ultra speakers suggest attention to audio quality.\n\nThis device also includes a backlit 78-key keyboard, and a power-key fingerprint reader rounds out the input options.\n\nAt the time of writing, Geekom has not announced pricing or release dates, making it difficult to judge the X14 Pro’s competitiveness against established brands.\n\nAt the same event, Geekom also revealed the GeekBook X16 Pro. This larger option uses a 16-inch 2560 x 1600 IPS panel, carries a 75Wh battery, offers dual SSD slots, and weighs 1299g.\n\nTogether, these two devices show Geekom is aiming beyond mini PC products, but their ultimate value depends on competitive pricing and reviews.\n\nVia Notebookcheck (originally in German)",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/one-of-our-favorite-mini-pc-vendors-has-launched-a-ridiculously-light-laptop-with-an-intel-core-ultra-cpu-and-a-5-megapixel-oled-display",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Cloud Hypervisor Will Block AI Generated Code, Raises x86_64 VM Limit To 8,192 vCPUs",
      "content": "Cloud Hypervisor 48.0 is now available for this Intel-started, open-source and Rust-based VMM focused on modern cloud workloads. Cloud Hypervisor continues to tailor to Windows and Linux guests while emphasizing security and cloud-native workloads.Cloud Hypervisor 48 introduces experimental \"fw_cfg\" device support for being able to pass configuration data and files like VM boot configurations from the host to the guest. There is also experimental support for Inter-VM Shared Memory \"ivshmem\" as another new feature.Cloud Hypervisor 48 also brings firmware boot support on RISC-V 64-bit, improved block performance when dealing with 16KB block sizes and smaller, faster VM pause operation especially with larger vCPU counts, and raises the x86_64 KVM vCPU limit. Up to this point Cloud Hypervisor could only handle up to 254 vCPUs with x86_64/KVM while now can handle up to 8,192 vCPUs.Cloud Hypervisor 48 also has removed Intel SGX support after previously deprecating the feature.Another notable change for the Cloud Hypervisor open-source project is they have established a policy against AI-generated code. Cloud Hypervisor will decline any contributions known to contain code generated or derived from Large Language Models.\n\nMore details on all of the Cloud Hypervisor 48 changes and downloads via GitHub",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Cloud-Hypervisor-48",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "AI Will Not Make You Rich",
      "content": null,
      "source": "Joincolossus.com",
      "url": "https://joincolossus.com/article/ai-will-not-make-you-rich/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Linux's New \"Sheaves\" Per-CPU Caching Layer Showing Massive Wins For AMD Performance",
      "content": "\"I ported this patch series on top of v6.17 and ran some benchmarks: will-it-scale, hackbench, redis, unixbench and kernbench. I ran the benchmarks on Intel Granite Rapids (480 cores), AMD Turin (512 cores) and ARM (80 cores)\n\n\n\nSummary of the results:\n\n\n\n- Significant change (meaning >10% difference between base and experiment) on will-it-scale tests in AMD.\n\n- No significant change on other benchmarks ran.\"\n\nEarlier this week I wrote about Sheaves as an opt-in, per-CPU array-based caching layer likely coming for Linux 6.18. The sheaves patches have been queued into the \"slab/for-next\" Git branch ahead of the Linux 6.18 kernel merge window. Patches posted now by Google are showing the Linux Sheaves code having a massive beneficial impact for large AMD systems.Google engineer Sudarsan Mahendran posted some benchmarks of the SLUB per-CPU Sheaves patches on Friday. The patches were applied to a Linux 6.17 base and tested across AMD, Intel, and ARM servers. For the AMD EPYC Turin server the Sheaves work ended up being a massive win for performance on a number of benchmarks but also some regressions.Sudarsan Mahendran commented on the mailing list:Going over his benchmarks on that LKML thread were exciting when seeing \"+28.58%\" mean improvements to get started, but also some 13~20% regressions... But when getting to the higher process counts for these scalability benchmarks was when it was getting really wild with +70.59%, +126.89%, +112.89%, and other massive wins. See all of the Google engineer's data in this thread It will be exciting to see how the Sheaves patches play out in more real-world workloads. Once these patches hit the mainline kernel presumably for Linux 6.18, I'll be firing up a number of benchmarks on my own hardware and thankfully have a lot of AMD EPYC Turin hardware and more for some exciting benchmarks ahead.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-Sheaves-AMD-Performance",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Monster Hunter Stories 3: Twisted Reflection gets a release date — we're also getting a new Monstie that I've been longing to ride since the first game, but everyone else will hate",
      "content": "What new Monsties will you discover in Monster Hunter Stories 3: Twisted Reflection?\n\nThe Nintendo Direct September 2025 event has come and gone, revealing a mountain of new games and more information on already announced titles heading for Xbox and PC.\n\nOne such title that has received new intel is Monster Hunter Stories 3: Twisted Reflection, the latest entry in Monster Hunter's spin-off Monster Hunter Stories series.\n\nDuring the Nintendo Direct, Monster Hunter Stories 3: Twisted Reflection got a new trailer revealing more of its story, playable Monsties, turn-based combat, and most importantly – its release date.\n\nWe know that Monster Hunter Stories 3: Twisted Reflection will be launching on March 13, 2026, for Xbox Series X|S, PlayStation 5, Nintendo Switch 2, and PC via Steam.\n\nHere's everything we know about Monster Hunter Stories 3: Twisted Reflection from the Nintendo Direct and another trailer released shortly afterwards by Capcom.\n\nMonster Hunter Stories 3: Twisted Reflection - Release Date Trailer - YouTube Watch On\n\nThe trailer begins with a recap of the game's premise. Monster Hunter Stories 3 takes place in a world where Rathalos have been driven to extinction.\n\nOne day, however, an egg birthed a pair of Rathalos bearing the mark of the world-ending Skyscale Rathalos. To protect their world from this doomed prophecy, the kingdom of Azuria put one of the baby Rathalos to death.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nMany years later, a horrible plague has begun spreading throughout the land, encasing everything in crystals and making the local monsters turn feral.\n\nYou play as the heir of Azuria, who has been tasked by the kingdom along with the surviving twin, Rathalos, to investigate and find a cure for this crystal plague.\n\nTo make things worse, war is on the horizon as the trailer shows footage of Azuria engulfed in battle with the kingdom of Vermeil, whose armies are led by a warrior riding the other twin Rathalos, which was presumed to be dead for years.\n\nYou can now switch between riding Monsties on the fly without needing to dismount. (Image credit: Capcom)\n\nThe trailer then showcases a montage of Monster Hunter Stories 3: Twisted Reflection's gameplay, which looks to be a full-blown evolution of the Monster Hunter Stories formula compared to the previous game, Monster Hunter Stories 2: Wings of Ruin.\n\nFor starters, while riding your Monsties (which are monsters that a player can tame and control) out in the open world, you can switch which Monstie to ride without dismounting.\n\nFor example, you can jump off a cliff and hover while riding a Tobi-Kadachi, then switch immediately to riding a Rathalos in midair, without needing to dismount from Tobi-Kadachi and plant your feet on the ground to call a Rathalos first.\n\nThis will no doubt make exploring the world go by way faster and potentially allow for some cool platforming tricks where you can jump and forth between multiple Monsties while traversing precarious areas.\n\nCo-ordinate your attacks with Monsties to take out challenging bosses like the explosive Magnamalo. (Image credit: Capcom)\n\nNext, the trailer gives us brief glimpses of Monster Hunter Stories 3: Twisted Reflection's turn-based combat system, which looks to be the same as in previous games.\n\nHuman party members take turns using their weapons to attack enemy monsters or command their pet Monsties to sic them. Combat is waged by employing attacks with either Power, Technical, or Speed tags to overpower opponents in Rock-Paper-Scissors style clashes.\n\nWhat's new about the combat system thus far is that we're getting a new weapon type for the player character to use in battle, the Longsword.\n\nAdditionally, enemy monsters now have a special gauge meter below their health bar that decreases whenever they take damage, which they never had before in previous games.\n\nCould this be a damage mitigation shield counter like Clair Obscur: Expedition 33, or an 'Enrage' meter that causes an enemy monster to instantly perform a devastating attack when the meter is empty? We'll have to wait for more info from Capcom to find out.\n\nAt long last, I can finally ride Plesioth and make everyone's lives miserable in Monster Hunter Stories\n\nMonsters from Monster Hunter Wilds are joining the hunt. (Image credit: Capcom)\n\nPerhaps the most exciting announcement from the trailer is that we'll be getting several new monsters to hunt and potential new Monsties to tame.\n\nThus far, we know that Paolumu, Rathalos, Velocidrome, Tobi-Kadachi, Nerscylla, Yian Kut-Ku, and Anjaneth will return as Monsties from previous games.\n\nGlavenus and Legiana are also potentially returning Monsties, as we see them being ridden in cutscenes but not during gameplay yet.\n\nAs for new monsters, we see a feral Chatacabra and a tease for Rey Dau from Monster Hunter Wilds at the end of the trailer.\n\nDread it, run from it, the hip-check always arrives. (Image credit: Capcom)\n\nBy far the most exciting addition for me personally is that Plesioth is finally going to be a Monstie after being only an enemy for many years in previous games.\n\nFor those who don't know, Plesioth is one of the most reviled and hated monsters in the entire Monster Hunter franchise. It's gigantic, hits like a truck, it can shoot steel-cutting water beams, and it has a venomous bite that puts players to sleep.\n\nWorst of it, Plesioth repeatedly uses an infamous attack now referred to by Monster Hunter Stories 2 as the 'Hyperspace Tackle', which can hit players a million miles away despite not looking like it hit them due to its massive, invisible range.\n\nI've always wanted to have a Monstie version of Plesioth ever since Monster Hunter Stories 1, so I could give enemy Plesioths a taste of their own medicine and prank players in online PVP multiplayer matches.\n\nI'm so happy to finally see my wish come true, along with all the new, exciting monsters and gameplay features Monster Hunter Stories 3: Twisted Reflection is bringing.\n\nI know for a fact that I wasn't expecting to see monsters from Monster Hunter Wilds' monster roster so soon.\n\nHere's hoping we get to see Arkveld, Rey Dau, and Nu Udra as tameable Monsties when Monster Hunter Stories 3: Twisted Reflection launches on Xbox, PlayStation, Nintendo Switch 2, and PC on March 13, 2025.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/gaming/monster-hunter-stories-3-twisted-reflection-gets-a-release-date-were-also-getting-a-new-monstie-that-ive-been-longing-to-ride-since-the-first-game-but-everyone-else-will-hate",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Western intel funds Serbian unrest - Vucic",
      "content": "https://sputnikglobe.com/20250913/western-intel-funds-serbian-unrest---vucic-1122776022.html\n\nWestern Intel Funds Serbian Unrest - Vucic\n\nWestern Intel Funds Serbian Unrest - Vucic\n\nSputnik International\n\nEfforts to overthrow the government in Serbia have so far cost the organizers from outside $4 billion, Serbian President Aleksandar Vucic said.\n\n2025-09-13T05:28+0000\n\n2025-09-13T05:28+0000\n\n2025-09-13T08:47+0000\n\nworld\n\naleksandar vucic\n\nserbia\n\neurope\n\nprotest\n\nriots\n\ncolor revolutions\n\nhttps://cdn1.img.sputnikglobe.com/img/07e9/08/0f/1122614220_0:0:3072:1728_1920x0_80_0_0_d188aeb6eb283dabe454854d36293679.jpg\n\n\"A total of $4 billion has been invested in the destruction of Serbia. Who are our opponents? The main organizers are from outside, they created a network and gathered people, a network of students and children, which frightens and destroys the basic values ​​of our society. These are employees of various intelligence services of several countries. We know that three countries have particularly used their intelligence networks,\" Vucic said on TV Informer overnight to Saturday, adding that he can't name these countries so as not to complicate Serbia's position. At the end of 2024, he spoke about 2 billion euros ($2.3 billion) invested by the organizers in mass protests in Serbia, at the beginning of 2025 - about 3 billion euros. Student and opposition protests began in Serbia after the canopy collapsed at a train station in Novi Sad on November 1, 2024, killing 16 people. The situation in Serbian cities escalated in mid-August. Protesters stepped up their actions, clashing with the police in the evening and at night, blocking roads.\n\nhttps://sputnikglobe.com/20250826/vucic-compelled-to-take-hard-stance-on-riots-in-serbia-1122674457.html\n\nserbia\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\n2025\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\nNews\n\nen_EN\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\n1920 1080 true\n\n1920 1440 true\n\n1920 1920 true\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\nSputnik International\n\nserbia protests, serbia protests funding, color revolution in serbia,",
      "source": "Sputnikglobe.com",
      "url": "https://sputnikglobe.com/20250913/western-intel-funds-serbian-unrest---vucic-1122776022.html",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Fist of the North Star: New \"Hokuto No Ken\" Trailer, Visuals Released",
      "content": null,
      "source": "Bleeding Cool News",
      "url": "https://bleedingcool.com/tv/fist-of-the-north-star-new-hokuto-no-ken-trailer-visuals-released/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "This refurbished MacBook Air is cheaper than most tablets right now",
      "content": "If you’re looking for a dependable, portable, and budget-conscious laptop for day-to-day tasks, look no further. This pre-loved MacBook Air hits the sweet spot—and it’s only $189.97 (reg. $999) with free shipping for a little while longer.\n\nWith a 1.8GHz Intel Core i5 processor, this machine is fast enough for tasks such as email, Google Docs, light streaming, and Zoom calls. It’s not here to replace your gaming rig or your creative workstation, but for the average user who just needs something that works without the drama, this MacBook is a total win.\n\nAt just under 3 pounds, it’s a dream for travel. Toss it in your tote or backpack and you’re good to go—whether you’re hopping on a plane or just working from the library. And thanks to the 12-hour battery, you can leave the charger at home more often than not.\n\nThe 128GB SSD keeps boot-up times snappy and gives you plenty of space for documents, photos, and those videos you swore you’d organize one day. Plus, the 13.3-inch widescreen display delivers a crisp viewing experience, even if you’re just catching up on YouTube.\n\nSure, it’s not brand new—this is a Grade “A” or “B” refurbished device, meaning you might see a minor scuff here or there. But under the hood, it’s fully functional, professionally inspected, and even comes with a 90-day aftermarket parts and labor warranty, just in case.\n\nAt just $189.97 with free shipping, this deal is hard to beat. Grab your own 13.3-inch MacBook Air now before units sell out for good.\n\nApple MacBook Air 13.3″ (2017) 1.8GHz i5 8GB RAM 128GB SSD Silver (Refurbished)See Deal\n\nStackSocial prices subject to change.",
      "source": "Macworld",
      "url": "https://www.macworld.com/article/2905647/this-refurbished-macbook-air-is-cheaper-than-most-tablets-right-now.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "A major AI video editor now has a lifetime subscription for $25",
      "content": "Editing videos used to be time-consuming, incredibly frustrating, and pretty difficult. AI has changed that. Macxvideo AI is part of a new generation of tools designed to make video work faster, simpler, and more accessible, especially for Mac users. A lifetime subscription to Macxvideo is usually $69.95, but right now, it’s only $24.99.\n\nThis all-in-one video toolkit combines more than 20 functions into a single desktop app. You can enhance video quality, upscale to 4K or 8K, convert formats, compress files, record your screen, and make edits without switching between programs. It runs entirely offline and uses GPU acceleration to boost performance, which is helpful when you’re working with high-resolution media.\n\nThe AI models in Macxvideo are trained to handle common issues like motion blur, low resolution, or poor lighting. It includes tools for frame interpolation, face recovery, colorization, and background noise removal. You can also convert videos to GIFs, apply watermarks, and correct fisheye distortion.\n\nMacxvideo is designed specifically for macOS and works on both Intel and Apple Silicon Macs running macOS 10.15 or later. It supports a wide range of formats and settings, so it can handle quick fixes as well as more involved projects.\n\nThis is a one-time purchase with no recurring costs.\n\nRight now, you can get a Macxvideo Lifetime Subscription for only $25.\n\nMacxvideo AI: Lifetime SubscriptionSee Deal\n\nStackSocial prices subject to change.",
      "source": "Macworld",
      "url": "https://www.macworld.com/article/2902398/a-major-ai-video-editor-now-has-a-lifetime-subscription-for-25.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Select Qualcomm X Elite Laptops Seeing IRIS Video Acceleration On Linux",
      "content": "Adding to the list of feature caveats around the different Qualcomm Snapdragon X Elite laptops and the varying Linux state is video acceleration support. But patches were posted this week by a Linaro engineer enabling hardware accelerated video playback for two X Elite laptop models.Linaro engineer Stephan Gerhold posted the patches enabling IRIS video acceleration decoding for the X1 Elite Compute Reference Design (CRD) and the Lenovo ThinkPad T14s. The CRD support isn't too useful for consumers themselves. The Lenovo ThinkPad T14s continues to benefit as one of the best supported X Elite laptops under Linux with even having firmware files upstream in linux-firmware.git.The patches posted on Thursday add the IRIS video acceleration code for the DeviceTree used on the Qualcomm reference board as well as the Lenovo ThinkPad T14s. Besides the DT support, there is also an IRIS firmware requirement.These new patches for those having either X1E platform can find them on the LKML . In time hopefully the other popular X Elite laptop models will also see this support in place.It was back in Linux 6.15 earlier this year that the Qualcomm IRIS video decode driver was upstreamed . In initial form a V4L2 video driver with H.264 decode.\n\nIn case you missed it for more details on the recent X Elite Linux experience, see the recent tests in Qualcomm Snapdragon X Elite Linux Performance Improving But Short Of AMD Ryzen & Intel Core Ultra",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Qualcomm-X-Elite-IRIS-Video",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Linux 6.17-rc6 Released With VMSCAPE Mitigation, FLYDIGI APEX 5 Support & Fixes",
      "content": "The newest weekly test release of Linux 6.17 is now available as we work toward the stable kernel release around the end of September.Linux 6.17-rc6 was just released by Linus Torvalds. Pulled into Linux 6.17-rc6 is a fix to address some \"serious breakage\" around system hibernation support as a regression introduced in Linux 6.16. Fixes to both the Intel and AMD P-State drivers also landed this week as part of the Linux 6.16-rc7 material.Some new material for Linux 6.17-rc6 since it just amounts to new device/vendor IDs is FLYDIGI APEX 5 gaming controller support for those expensive game controller options.This week also saw the public announcement of VMSCAPE as a new CPU security vulnerability issue affecting both AMD and Intel processors . VMSCAPE mitigation support was merged to Linux Git upon embargo lift and also since back-ported to the stable Linux kernel series. Linux 6.17-rc6 has the mitigation if you aren't a daily Git rider.\n\n\"Things remain pretty calm, and for some reason this release seems to just not have a ton of problems. Hopefully I'm not jinxing it.\n\n\n\nIt might just have been people being on vacation in August (read: Europe) which has caused this release to be nice and calm, but whatever the reason I'm certainly not complaining.\n\n\n\nSomewhat unusually, almost a third of the patch is from filesystem fixes, but that seems to be pure coincidence: not because there are any particularly large fixes, but because we just happened to independently have fixes in several different filesystems (ceph, smb client, nfs, erofs, btrfs). So just random timing.\n\n\n\nAnother third is driver fixes (gpu being half of it, the rest being other random drivers), and the final third is just \"misc other stuff\": core networking, another CPU speculation mitigation, somedocumentation fixes, some selftest updates, and minor noise elsewhere.\n\n\n\nBut really, none of it is very large. So everything seems slated for a normal release in two weeks.\"\n\nLinus Torvalds wrote with the 6.17-rc6 announcement There are a lot of great features and improvements in Linux 6.17 with this stable kernel version hopefully coming out two weeks from today on 28 September.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.17-rc6-Released",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Breer: Polk's ‘football character' played role in Patriots-Saints trade",
      "content": "There's no question about it: The Patriots whiffed on Ja'Lynn Polk.\n\nNew England traded Polk to the New Orleans Saints on Saturday. The Patriots acquired a 2027 sixth-round pick in exchange for Polk and a 2028 seventh-round pick, according to The Athletic's Dianna Russini. Terms of the trade were not confirmed by the team.\n\nThe second-year wide receiver was selected 37th overall in the 2024 NFL Draft.\n\nSubscribe to NBC Sports Boston's podcast network to hear our Insiders bring you the latest insights on your favorite teams! PODCASTS\n\n\"It's about as small a return as you can get, and this is really just a flat miss,\" Sports Illustrated's Albert Breer said on Patriots Pregame Live before a Week 2 matchup against the Dolphins on Sunday.\n\nPatriots head coach Mike Vrabel told radio broadcaster Scott Zolak the franchise felt it was best to give Polk a fresh start. Polk was placed on season-ending injured reserve and thus was not eligible to play for the Patriots this season.\n\nBreer's insights aligned with Vrabel's comments, and also included noteworthy detail.\n\n\"This just got to the point where they were hopeful that he would come back in a better place than he had been in 2024, and they still saw a backup player out there on the practice field even before he got hurt,\" Breer said.\n\n\"I think where they feel like they really missed -- this isn't a bad guy, so it's not a personal character thing. I want to make sure I emphasize that,\" Breer continued. \"But the football character wasn't exactly what they thought it would be.\"\n\nThe University of Washington product bragged about having \"the best hands in the league\" during his rookie season. He finished the year catching 12 of the 33 passes thrown his way for a mere 87 yards and two touchdowns in 15 games. When Polk stepped to the microphone in training camp this summer, he said he didn't learn anything from his rookie season and instead was putting it in the rearview.\n\n\"He didn't dig himself out of that hole,\" Breer said. \"They started to view him as more of a backup and then the question became, 'Do we just cut bait now or do we keep chasing a mistake and maybe create a situation where you're not giving other players some opportunity?' And, of course, that issue is exacerbated by the fact that they missed on another receiver in Javon Baker.\"\n\nBaker initially made New England's 53-man roster, but was one of the ensuing cuts after the Patriots claimed a few players off waivers. Baker signed with the Eagles practice squad after being released.\n\nBreer dropped a Baker-related nugget of information, as well.\n\nThe Patriots entered Day 3 of the 2024 NFL Draft planning to draft wide receiver Troy Franklin out of Oregon, Breer said. New England had the third pick in the fourth round. However, the Broncos traded in front of the Patriots and selected Franklin right in front of New England. The Patriots drafted offensive lineman Layden Robinson with their initial fourth-round pick (No. 103) and circled back at wide receiver and selected Baker later in the fourth round (No. 110).\n\nNeither Robinson nor Baker remain in New England while Franklin is a starting wide receiver in Denver.\n\nAnother aspect that makes matters worse for the Patriots is the fact two of Polk's college teammates are flourishing in the league. The Bears selected Rome Odunze with the No. 9 pick and the Buccaneers drafted Jalen McMillan with the 92nd overall pick. The Patriots bypassed McMillan, as well as others like Chargers star Ladd McConkey, and instead drafted Polk.\n\n\"A lot of people in the NFL viewed Ja'Lynn Polk the same way he Patriots did -- tough, smart, high football IQ, a guy that maybe doesn't have the highest ceiling in the world but was going to be able to play right way and be a role player for a long, long time to come in the NFL,\" Breer said. \"Obviously, it did not play out that way.\"\n\nAfter trading Polk, only two members (Drake Maye, Caedan Wallace) of the 2024 eight-player draft class are on New England's active roster.",
      "source": "Nbcsportsboston.com",
      "url": "https://www.nbcsportsboston.com/nfl/new-england-patriots/jalynn-polk-saints-trade-reaction/731243/",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Intel outlines 2026 PC roadmap: Arrow Lake refresh to hold the line before Nova Lake overhaul",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250911PD244/intel-arrow-pc-2026-roadmap.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Beelink ME Mini Review: The mini PC maker’s first NAS supports 6 NVMe SSDs",
      "content": "Over the past few years we’ve seen a bunch of Chinese PC and accessory makers launch affordable network-attached storage (NAS) systems with Intel Alder Lake-N or Twin Lake processors and support for PCIe NVMe SSDs. But the Beelink ME Mini is one of the first to support up to six NVMe drives. Most other models, including the GMK NucBox G9, Maiyunda M1S, and TerraMaster F4 SSD only support four.\n\nThe Beelink ME Mini also features a new design for an NVMe-based NAS: it’s a small cube-shaped computer that measures 99 x 99 x 99mm (3.9″ x 3.9″ x 3.9″). Lift the top cover and you’ll find six M.2 2280 slots and a built-in power supply positioned vertically around a central cooling core.\n\nThe computer features the popular Intel N150 mobile processor, which is a 6-watt processor with low power consumption, but is also a quad-core chip that offers decent performance-per-watt. The integrated Intel Graphics GPU features 24 execution units and support for 4K video at 60 Hz as well as Intel Quick Sync hardware-accelerated video decoding.\n\nFor networking, the ME Mini offers both twin 2.5 Gb Ethernet ports, WiFi 6, and Bluetooth 5.2.\n\nFirst introduced earlier this year, the Beelink ME Mini is available from Amazon or the Beelink website with prices starting at $209 for a basic model with 12GB of LPDDR5-4800 memory and 64GB of eMMC storage. There’s also a $329 for a version that also comes with a 2TB Crucial P3 Plus SSD and Windows 11 Pro license.\n\nBeelink provided Liliputing with an ME Mini unit which included a 2 TB Crucial SSD for free, with no requirement that the computer be returned upon completion of the review. But this review is not sponsored by Beelink, and the company did not modify or approve the content of this article in any way.\n\nPhysical Design\n\nThe ME Mini is available in three colours: pearl white, midnight gray (grey) and peacock blue, which is best described as a dark turquoise or blueish-green (see also the ‘Case Colours’ section below).\n\nEssentially, the device is a small plastic cube with rounded corners, cut-outs for ports, a power button, and ventilation. It sits on two semi-circular rubber feet.\n\nThe front has a symmetrical layout based around a central on/off button. Either side of which are two pin hole indicator lights: the left shows white when it is running whilst the right shows orange when it is sleeping. Then on either side on the front are USB 3.2 Gen 2×1 (10 Gbps) ports. The far left being Type-C, and the far right is a Type-A port.\n\nOn the back are the remaining ports. Over on the left is the power port which takes the included IEC C7 (Figure Eight) power lead. Next comes a vertical USB 2.0 port. Then there are two side-by-side 2.5 Gb (Intel I266-V) Ethernet ports. Finally, on the far right is a vertical HDMI port.\n\nBoth sides have a series of ventilation holes across the bottom and are otherwise plain.\n\nThe top looks like it contains a dial which is full of ventilation holes. However, this is just design aesthetics as it doesn’t rotate because it is in fact glued in.\n\nThe centre of the base has a slightly protruding circular section which is surrounded by ventilation holes for air expulsion. It also has the rubber feet that together lift the ME Mini fractionally off the surface to allow airflow.\n\nNot shown in the picture are tiny rubber plugs located in each corner that conceal the four screws fixing the top to the bottom of the device. There is also a tiny hole between the two feet at the bottom, which enables access, using a paperclip or similar, to the clear CMOS button inside the device.\n\nGetting to the internals like the NVMe drives, is rather awkwardly hindered by these little rubber plugs, as first they have to be prised out before undoing the screws.\n\nTo easily understand the internal layout, Beelink’s website has a great overall view of the ME Mini’s design which shows the device’s basic structure.\n\nEverything orientates around a large heatsink. It has a central core that covers the processor at the bottom of the heatsink, and then runs to the top of the device where it is covered by a 60 mm, 5 volt fan.\n\nOff this core are six struts that run from the bottom to top, and are connected to the outer walls of the heatsink which is square in shape.\n\nThe cooling is based on a reverse-chimney design where colder outside air is pulled into the device from the top and then pushed downwards before being exhausted through the sides and, to a lesser extent, the base. This air movement cools not only the metal heatsink but everything else, as all the components are attached to it.\n\nOn the outside of the heatsink where the NVMe drives are to be located, are thermal pads. Each NVMe drive is then attached by a screw to the heatsink. This ensures that the drives hottest part, its controller, comes into contact with the thermal pad.\n\nAnother notable design feature is that the 45 watt power supply is internal to the device and is embedded within the heatsink.\n\nThis design serves a dual purpose as not only does it take care of incorporating the power supply without increasing the size of the device, but it also allows the heat generating component to face the heatsink, and therefore the heat is wicked away.\n\nOn the other side of the heatsink is the WiFi module and CMOS battery. There’s an M.2 E-Key slot on the left that Beelink uses for an Intel AX101 Wi-Fi 6 (802.11ax) 2230 card. Its two aerials are mounted above on foam pads, the left being the main antenna and the right for the aux or diversity antenna.\n\nBut you can also remove that wireless card and replace it with something else. In the picture above you’ll notice that I’ve replaced the Intel AX101 module with an M.2 adapter to provide additional storage. I’ll cover this in more detail below.\n\nThe plastic base of the ME Mini is attached to the motherboard by four small screws which can only be accessed once the top cover is removed.\n\nOnce removed, this exposes the rear side of the motherboard and the mountings for the heatsink which covers the CPU on the other side.\n\nFinally, inside the box you get your country specific power cable, a HDMI cable and a user manual.\n\nHardware: Storage, memory and networking\n\nWhat makes the ME Mini so interesting to me from a hardware perspective, is how it manages to provide six NVMe slots.\n\nMost NAS mini PCs with Intel Alder Lake or Twin Lake processors have faced the restrictions defined in the Intel Processor and Intel Core i3 and Intel Core 3 N-Series Datasheet. This is a document produced by Intel which is specifically intended for Original Equipment Manufacturers (OEMs), Original Design Manufacturers (ODM) and BIOS vendors creating products based on the N series processors.\n\nThe section relevant to designing a NAS is the PCI Express Port Support Feature Details as this stipulates how many PCIe lanes are provided by the processors and how they can be configured.\n\nOf particular interest is Note 7 that states:\n\nThe PCIe* Lanes can be configured independently from one another but the max number of configured Root Ports (Devices) must not be exceeded\n\nA maximum of 5 PCIe* Root Ports (or devices) can be enabled\n\n\n\nOther manufacturers have built products within this restriction by making use of PCIe express packet switches like the ASM1182e and ASM2806 to switch PCIe lanes and allow more ports to be connected. However, Beelink seem to have simply enabled more Root Ports.\n\nBy looking at the PCIe Root Port assignments when running Ubuntu on the ME Mini, we see that eight PCIe Root Ports are enabled, with two allocated to the two 2.5 GbE ports and the remaining six allocated to NVMe slots.\n\nFive of these NVMe allocations get a single lane of PCIe 3.0.\n\nAnd specifically the fourth NVMe slot, gets two lanes of PCIe 3.0.\n\nAlthough the NVMe slots are PCIe 3.0, they will still work with PCIe 4.0 drives as these drives are backward compatible. The impact from a lower PCIe generation and number of allocated lanes, only affects the speed of the NVMe.\n\nFor example, the included Crucial P3 Plus is a Gen 4.0 drive capable of reaching 5,000 MB/s for sequential read and 4,200 for sequential write when used in a computer with a 4-lane PCIe Gen 4.0 slot.\n\nObviously performance will be lower in systems like the Beelink ME Mini, given it allocates fewer PCIe lanes which are from the previous generation The best performance can be obtained when the SSD is inserted in the fourth NVMe slot where it will get the benefit of two PCIe Gen 3 lanes.\n\nCrystalDiskMark showed the sequential read speed was 1741 MB/s and the sequential write speed was 1692 MB/s. In contrast, all the other NVMe slots are single lane and so technically half the speed.\n\nI can demonstrate by testing with some Lexar NQ790 4TB M.2 2280 PCIe Gen4 NVMe drives in slot 4 and in slot 1. The faster two-lane, slot 4 shown on the left, gave a sequential read speed of 1776 MB/s with a sequential write speed of 1709 MB/s. The single-lane slot 1 shown on the right, only provided a sequential read speed of 891 MB/s and a sequential write speed of 868 MB/s.\n\nThe ME Mini also comes with eMMC storage which is a soldered down HS400 Enhanced strobe MMC card which has a maximum bandwidth of 400 MB/s. When tested I saw a sequential read speed of 310 MB/s and a sequential write speed of 221 MB/s.\n\nWhile it might seem like the computer’s 1 and 2-lane PCIe Gen 3.0 connections will keep you from getting the full benefit of solid state storage by limiting the read/write speeds, it’s actually the Ethernet ports that will be the bottleneck for users who plan to access the NAS over a network.\n\nThe theoretical maximum throughput of 2.5 Gb Ethernet (2.5GbE) is 313 MB/s. When I tested the ports using iperf3 I got slightly less at 294 MB/s for both upload and download.\n\nWhen accessed remotely, the NAS was showing a sequential read speed just under 300 MB/s and a sequential write speed of around 250 MB/s. See the ‘Networking Performance’ section below for further details.\n\nSo any NVMe drives used with this computer will actually be able to transfer data to and from storage faster than it can be accessed over a network connection.\n\nThat doesn’t mean it’s pointless to use SSDs for this NAS instead of hard drives. The solid state drives take up less physical space than hard drives, allowing you to fit as many as six drives into a computer that’s too small to hold a single 3.5 inch hard drive. SSDs also consume less energy and have no moving parts, which means they don’t make noise and aren’t as likely to break. They are, however, more expensive than hard drives. So while the Beelink ME Mini itself is priced competitively with NAS systems that support four or eight hard drives, the costs of storage for an SSD-only device like this can be pretty high.\n\nFinally, another consideration when using a NAS is how much memory is available. Some filesystems, such as ZFS, are known to be memory-intensive and require sufficient memory to work efficiently.\n\nUnfortunately, the ME Mini has soldered down memory which is not user upgradeable. But it does come with 12 GB of LPDDR5, which is more than you get from many other NAS systems in the same price range. Beelink could have included more memory though. Officially Intel says the Intel N150 processor supports up to a maximum of 16 GB of RAM, but it’s been well documented that computers with this processor can support 32 GB or more.\n\nOne further, but untested restriction, is that the Maximum Memory Speed is 4800 MT/s, and this is the speed the ME Mini is configured to run at even though the installed LPDDR5 memory is capable of 6400 MT/s.\n\nWindows Performance\n\nThe ME Mini review unit came with Windows 11 Pro pre-installed on the Crucial P3 Plus NVMe drive.\n\nThe first observation to note is that both Power Limit 1 and 2 are set to 15 watts. This means that the CPU is provided with constant power, and is not provided with extra power to boost its frequency during heavy workloads. In contract, previous N100 mini PCs I’ve reviewed in the past, such as the GEEKOM Mini Air12 has its Power Limit 2 set to 25 watts and the Beelink EQ12 had a higher PL1 value of 20 watts and the same higher PL2 of 25 watts.\n\nSo, the CPU performance of the ME Mini will be slightly degraded compared to other mini PCs with similar processors in order to keep the temperature of the processor lower and more consistent. Given the only difference between the N100 and N150 is that the latter has a slightly higher turbo frequency (3.4 GHz vs 3.6 GHz), no real performance difference is going to be seen with the current power limit settings.\n\nIf you were solely using the ME Mini as a Windows mini PC just with a lot of storage, you might notice this performance impact as the Intel N150 is not a super powerful processor in the first place.\n\nI did run a few benchmarks just for comparison purposes.\n\nFirst let’s look at comparing Geekbench’s CPU results with a couple of arguably equivalent mini PCs which both has an N100 CPU, the GEEKOM Mini Air12 and the Beelink EQ12.\n\nThe single core score achieved by the ME Mini was 1147 and this compares with 1226 and 1199 so minimal impact. However, the multi core score was only 2143, whereas Mini Air12 scored 3249 and the EQ12 scored 3186. Ouch.\n\nAnother CPU benchmark I ran was Cinebench R23. The single core results saw the ME Mini getting 945 pts against 933 for the Mini Air12 and 946 for the EQ12. For multi core, the outcome was better than the Geekbench results, with the ME Mini only slightly lower at 2861 pts vs 3008 for the Mini Air12 and 2947 for the EQ12.\n\nIt is worth noting that these two benchmarks are very different. Geekbench consists of a series of tests and favours the ability to boost, whereas Cinebench is more of a continuous test where the longer it takes to complete the test, the less impact the initial boost has on the result.\n\nThe final benchmark I ran was Performance Test’s Passmark. This is a good benchmark to see how components like the CPU, Memory and Storage perform both individually and all together.\n\nComparing scores between devices will obviously be heavily affected by “what and how much” was installed for each component. Nevertheless, the Passmark score does reflect the overall performance you will get when using the configuration. When running each of the devices with their “as sold” configurations, without any UEFI/BIOS tweaking etc., the ME Mini scored 1549.9, the Mini Air12 scored 2457.6 and the EQ12 scored 2216.8. The ME Mini’s CPU (PL1/2 15W), Disk (PCIe Gen 3 x2) and Memory (12 GB) all play a significant part in affecting this overall score.\n\nHowever, even though customers who purchase a ME Mini with a 2TB SSD will get a system with Windows pre-installed, the computer is marketed as a NAS rather than a general-purpose mini PC. So I wanted to see how it performed as a network-attached storage device.\n\nMy first challenge was how to set up the ME Mini to test as a NAS running Windows. I didn’t want to lose an entire NVMe slot just because it had Windows sitting on a 2 TB drive, as I planned to test the maximum storage configuration the ME Mini supports of using six 4 TB drives.\n\nI first “moved” Windows from the Crucial P3 Plus drive to the eMMC storage. I did this by removing the NVMe drive and then running the Windows reset feature to effectively perform a clean installation of Windows to the eMMC drive. I did find I was missing some drivers, but they are available from Beelink’s support page.\n\nMy initial concern was whether running Windows from the slower eMMC drive would affect performance. So, I reran the earlier benchmarks:\n\n\n\n\n\n\n\n\n\nAs can be seen, all the results are within the margin of testing error with the exception of Passmark, which is singularly affected by the slower Disk mark (16123.0 vs 1692.2).\n\nReassured, I installed six Lexar NQ790 4TB M.2 2280 PCIe Gen4 NVMe drives. The next step was to consider how to set up the NAS storage using these six drives.\n\nWindows 11 includes Storage Spaces which, as they admit, is conceptually similar to redundant array of independent disks (RAID). And as ZFS and Btrfs are not supported by Windows my choice of file system was going to be limited to NTFS.\n\nWhen considering a ZFS configuration for six drives, one of the more frequently suggested options is to create two separate three-wide RAIDZ1 vdevs in the same zpool.\n\nTrying to break this down into [Windows] terminology, I want two RAIDZ1 (parity i.e. RAID 5) virtual disks consisting of three physical drives, combined (stripped i.e. RAID 0) in the same zpool (virtual volume). Simply put, I want RAID 50 (RAID 5+0) using six drives.\n\nI found I couldn’t do all of this using the Storage Spaces GUI so I ended up writing a PowerShell script so I could easily recreate the storage configuration during testing.\n\nFirst, I created two storage pools each consisting of three NVMe drives with parity resilience.\n\nI then striped the resultant two virtual disks to create a single virtual volume I could use as my NAS.\n\nUsing HWiNFO, I set the NVMe temperature sensor for each drive to display on the right of the taskbar. Running CrystalDiskMark gave a sequential read speed of 3538.51 MB/s and a sequential write speed of 657.38 and the maximum drive temperature seen was 50 °C which is perfectly acceptable.\n\nNext, I installed Docker Desktop and located both the installation directory and the docker data directory on my NAS ‘N’ drive to save space on the Windows system drive.\n\nI then created a Jellyfin container with its media on the NAS, so I could further test the performance impact and further monitor the drive temperatures.\n\nLooking at the statistics while Jellyfin was playing music showed plenty of CPU headroom as it created minimal load.\n\nAll six of the drives remained at a safe temperature, showing only a minor degree of a two degree increase from when idle. During this usage the fan remaining whisper quiet.\n\nUbuntu Performance\n\nWhile Windows was pre-installed on the unit Beelink sent me, the ME Mini should support a wide range of different operating systems. Beelink lists some of the more commonly encountered NAS OS that the device supports on their webpage including Proxmox, Unraid, TrueNAS and FNOS, the latter being a new closed-source but free NAS OS specifically for users in China.\n\nI decided to use Ubuntu for the review and set up my NAS manually, so that I had the flexibility of configuring RAID and file systems of my choice, purely for ease of testing.\n\nAs Windows 11 minimum storage requirement is 64 GB or larger, and given the eMMC is only 64 GB, it means that I couldn’t just dual boot Ubuntu from eMMC by creating an additional partition.\n\nTypically, when there is a user-replaceable WiFi card in an M.2 2230 slot, I can just use Key-E to Key-M adapter and use a 2230 NVMe drive at PCIe Gen 3 x1 since the computer can use an Ethernet cable for a wired network connection.\n\nHowever, the installed Intel AX101 card is CNVi and not PCIe. Sometimes, depending on the design, a M.2 may support both the CNVi and standard M.2 Key-E wireless module. I tested with an adapter and confirmed that it is definitely not supported.\n\nHowever, I also tried a Key-E to micro SD card adapter which contained a Sandisk Extreme PRO 256 GB card, and this was recognised both in Windows and Ubuntu.\n\nAs can be seen, the adapter is recognised as USB storage and only runs as USB 2.0.\n\nIt doesn’t matter too much how fast the micro SD card is, as it will be capped at USB 2.0 speeds. Testing gave a sequential read speed of 20.32 MB/s and a sequential write speed of 27.64 MB/s.\n\nWhilst this is not particularly fast, I’ve found that running Ubuntu from an adapter like this is totally fine for a NAS. In fact, the Unraid operating system, which is designed specifically for NAS systems, must be run from a USB drive, which means that it’s often running off a slow storage device.\n\nIf you do want quicker read/write speeds, you could install Ubuntu with separate partitions, and then for quicker write speeds on /var and /tmp for example, they can be moved or bound to directories/partitions on the NAS once configured.\n\nHowever, most users who choose a different operating system to Windows, will likely use the eMMC for OS storage, or install the OS on the NAS. Basically, there is a lot of flexibility available.\n\nSo, my testing setup on the ME-Mini consisted of an installation of Ubuntu 25.04 with ZFS, Docker Desktop, Portainer and Cockpit on the micro SD card. I also removed Snaps to improve performance as this frees up some memory.\n\nI configured each RAID such that it was accessible as ‘/ME-Mini’ and had three sub-directories called ‘media’, ‘linuxium’ and ‘nas’, each of which was made available through SMB. I also created a Jellyfin container that used media from ‘/ME-Mini/media’.\n\nThe first RAID I created had the same storage configuration I used in Windows but implemented using ZFS. As a reminder, this was to create two RAIDZ1 vdevs each with three NVMe drives, in the same zpool which I called ME-Mini.\n\nRunning ldiskmark, which is my Ubuntu implementation of CrystalDiskMark using ‘fio’, I saw a sequential read speed of 1614.8 MB/s and a sequential write speed of 827.0 MB/s. This compares to Windows where the sequential read speed was 3538.51 MB/s and the sequential write speed was 657.38 MB/s.\n\nWhen the Jellyfin container was running and playing music, there was little impact on the drive temperatures, similar to Windows. Using sensors showed that all the temperatures were under 45 °C.\n\nThere was also little load of the CPU, however, due to the filesystem using ZFS, the memory usage was very high at 82 %.\n\nThis RAID configuration is arguably storage-expensive as it uses two drives for parity yet only protects for a single drive failure. Having installed 24 TB of disk space, the available space is only just over 14 TB.\n\nGiven the cost of the drives, a more space-to-cost configuration would be to just create a RAID5 configuration using all six drives, or in ZFS terms, create a zpool of all six drives as RAIDZ1.\n\nThis increases the storage by 4 TB and the RAID’s sequential read and write speeds are similar to before. However, there is an increased risk of data loss during a rebuild as this puts a lot of work on the remaining drives which may cause another one to fail.\n\nBut one thing it doesn’t change is the high demand for memory that ZFS makes.\n\nSo as a final example, I’ve created a RAID50 configuration using ext4 for the filesystem.\n\nThe RAID performance was very much improved for sequential reads at 3027.8 MB/s whilst there was a slight degradation in sequential write speeds to 804.2 MB/s however this still exceeds the available network throughput.\n\nPerformance whilst running Jellyfin was just as good as when running on ZFS.\n\nMoving the filesystem to ext4 also didn’t increase the drive temperatures. If anything, the NVMe temperatures dropped slightly.\n\nBut the main gain, as expected, was the lower memory usage. It dropped from 84% usage with ZFS to 34% with ext4.\n\nAnd just on the point of using ext4, if LVM is also used and ‘md0’ is initialised using ‘pvcreate’ so that the NAS storage is created as a logical volume, then ‘lvcreate–snapshot’ can be used to create snapshots, which is one of the benefits from using ZFS.\n\nWhen running these configurations, neither the CPU nor NVMe drives got hot, resulting in a fan that even though was running, was still too quiet to hear.\n\nNetworking Performance\n\nAs mentioned earlier, given the typical NVMe speeds in the ME Mini, the 2.5 Gb Ethernet ports are a performance bottleneck when accessing the NAS over a network.\n\nIn terms of performance, there is nothing wrong with the 2.5 Gb Ethernet ports. During testing I was getting 2.35 Gbits/sec both up and down which is about the best speed you can get.\n\nWhen accessing the NAS remotely over a network, I was getting a sequential read speed just under 300 MB/s and a sequential write speed of around 250 MB/s.\n\nIn theory, it would have been possible to include a 10 Gigabit Ethernet port in the design of the ME Mini. For example, Beelink could have swapped one of the existing 2.5 GbE ports for an NVMe slot. This would allow PCIe Root Port 4, which currently has two PCIe lanes allocated to it, for a 10 Gb Ethernet port.\n\nAnd whilst there are other combinations that could be used, none will alleviate the two key problems of a 10 GbE port. The first is heat. All of the 10 GbE controllers I’ve used run very hot and require proper cooling for them to work efficiently. The second issue is cost. It would likely add another 50% to the price and by doing so, change the ME Mini’s market position as being a very cheap yet storage-rich NAS device.\n\nHowever, there is a low-cost solution to improving network throughput. The front left port is a 10 Gbps USB 3.2 Gen 2×1 Type-C port giving you the option of using a 5 Gbps USB Ethernet adapter.\n\nI connected a Wavlink WL-NWU340G USB C to 5 Gbps Ethernet Adapter which uses the Realtek RTL8157 controller and has drivers available from Realtek for both Windows and Linux.\n\nUsing this 5 Gb Ethernet adapter, I was getting at least 4.71 Gbits/sec for both upload and download, which is double the speed of the ME Mini’s Ethernet ports.\n\nObviously, this makes accessing the NAS remotely much faster, and I saw sequential read speeds at just under 600 MB/s and a sequential write speed of around 560 MB/s.\n\nFinally, I also checked whether the faster write speeds would create any issue with the NVMe’s temperatures. Transferring a 100 GB file remotely to the ME Mini saw the continuous write speed drop down to around 450 MB/s, and all the drive temperatures still showed under 50 °C indicating no thermal issues or throttling.\n\nCase colours\n\nAs mentioned, the ME Mini is available in three colours: white, grey and dark turquoise.\n\nKnowing that sometimes, colour choices can be regretted or change over time, I’ve arranged with Beelink, for anyone who owns a ME Mini, the option of purchasing just the case in a different colour for only USD 15.\n\nAll you need to do is email their support at [email protected] to request a different case.\n\nThe case actually comprises of several components: an outer shell, perforated top, base, on/off button, on/off spring, rubber feet and rubber screw-covers. Fortunately, the case you receive will have the top and on/off button installed, meaning all you have to do is swap your existing case and base, and then stick on the rubber accessories.\n\nOn a personal note, I wish the case came in a black option as that would better colour-match some routers, switches and PC cases.\n\nIssues and Limitations\n\nI’ve not found any issues with the ME Mini whilst testing it for this review. There are some “but it doesn’t have” type statements that could be claimed, like “no ECC memory support” or “only 12 GB soldered down memory”, but it’s easy to forgive these omissions given the low price of the hardware.\n\nThe only practical limitation I think is worth highlighting is that the Intel N150 processor is not a very powerful CPU, and it only has four cores without hyperthreading. So, whilst running a few containers will be fine, it is not really suitable for multiple VMs, gaming or other demanding tasks. But the processor is suitable for powering the ME Mini for more basic network attached storage applications.\n\nHighlights\n\nWhat you get for your money is very good value. The ME Mini excels as a low cost, low power, low noise, multi NVMe capacity small footprint NAS.\n\nThe ME Mini is available as barebones for $209 or can be purchased with a 2TB Crucial P3 Plus NVMe drive that additionally includes a Windows 11 Pro license for just $329. Different coloured cases for existing owners are available for $15 by emailing Beelink’s support at [email protected].\n\nI’d like to thank Beelink for providing the review unit.\n\nSupport Liliputing Liliputing's primary sources of revenue are advertising and affiliate links (if you click the \"Shop\" button at the top of the page and buy something on Amazon, for example, we'll get a small commission). But there are several ways you can support the site directly even if you're using an ad blocker* and hate online shopping. Contribute to our Patreon campaign or... Contribute via PayPal * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a guide that may help you disable it.",
      "source": "Liliputing",
      "url": "https://liliputing.com/beelink-me-mini-review-the-mini-pc-makers-first-nas-supports-6-nvme-ssds/",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Refurb Weekend: Silicon Graphics Indigo² Impact 10000",
      "content": "My general vintage computing projects, mostly microcomputers, 6502, PalmOS, 68K/Power Mac and Unix workstations, but that's not all you'll see. While over the decades I've written for publications likeand, these articles are all original and just for you. My promise: No AI-generated article text, ever. All em-dashes are intentional and inserted by hand. Be kind, REWIND and PLAY.Old VCR is advertisement- and donation-funded, and what I get goes to maintaining the hardware here at Floodgap. I don't drink coffee, but the Mr Pibb doesn't buy itself. :-) Thanks for reading.",
      "source": "Blogspot.com",
      "url": "http://oldvcr.blogspot.com/2025/09/refurb-weekend-silicon-graphics-indigo.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "HEARS Perfection from Brainworx",
      "content": "Personalised EQ curves for hearing correction\n\nBrainworx have announced the release of HEARS Perfection. The software applies personalised EQ correction based on a short listening test, and is designed to be used to compensate for natural hearing differences, age-related changes, or fatigue that can affect accurate monitoring.\n\nUnlike room calibration tools which are designed to help balance speakers or headphones, HEARS Perfection focuses on the listener and their individual hearing ability. Users undertake a built-in listening test lasting around five minutes, which identifies frequency dips in the critical mid and high ranges and creates a personalised corrective EQ curve. Users can scale the compensation amount for dialling in more natural results, and the plug-in’s low CPU footprint makes it suitable for permanent use on the master bus.\n\nAdditional features include channel solo options (L, R, mid, or side) for precision listening, a bypass safety reminder to avoid accidental exports with correction active, and a redesigned modern interface with improved stability.\n\nVideo of HEARS Perfection - Quick Overview | Plugin Alliance\n\nThe plug-in supports VST3, AU, and AAX formats, running on macOS (Intel & Apple Silicon) and Windows 10/11.\n\nPricing & Availability\n\nHEARS Perfection is available now via Plugin Alliance at an introductory price of $79.99 (regular price $129).\n\nwww.plugin-alliance.com/en/products/hears_perfection.html",
      "source": "Soundonsound.com",
      "url": "https://www.soundonsound.com/news/hears-perfection-brainworx",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Intel loses key Ohio fab lobbyist and Xeon architect as delays mount",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250912PD239/intel-ceo-xeon-fab-business.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Apple releases macOS Tahoe 26 with more powerful Spotlight search and its own Phone app",
      "content": "is a senior reporter who’s been covering and reviewing the latest gadgets and tech since 2006, but has loved all things electronic since he was a kid.\n\nPosts from this author will be added to your daily email digest and your homepage feed.\n\nmacOS Tahoe 26 is now available to everyone using compatible MacBooks and Mac desktops. It was first announced last June at WWDC 25 and made available for testing through developer and public betas released over the past three months. This will be the last major macOS update for older Intel-based Macs – specifically those featuring Apple’s T2 Security Chip.\n\nVarious UI elements on Tahoe will have a glossy transparent appearance, revealing what’s beneath them. Image: Apple\n\nThe most notable update with Tahoe will also be its most obvious. It includes a major UI overhaul based on Apple’s new Liquid Glass design language that will feature an extensive use of transparent effects on windows, buttons, and notifications. Tahoe’s menu bar will also be completely transparent, making displays seem a bit larger.\n\nmacOS’ Spotlight search tool and launcher will be more useful with Tahoe, ranking search results intelligently based on relevance and allowing users to perform specific actions with apps like sending an email or creating a note without having to actually open those specific apps. If you like to keep your Mac immaculately organized you can now change the colors of folders or add an emoji to make them stand out.\n\nThe new Phone app can route calls from your iPhone to your desktop so you don’t need to reach for your smartphone to answer them. Image: Apple\n\nA new Phone app will mirror the functionality of the one on iOS and can relay calls from your iPhone through your computer. It will include access to recents and voicemails, as well as new iOS features like Call Screening that can answer calls from unknown numbers for you and Hold Assist that can stay on the line until a real person responds. Leveraging Apple Intelligence, Live Translation can translate text, audio during phone calls or FaceTime calls, and even chats in Messages.",
      "source": "The Verge",
      "url": "https://www.theverge.com/news/777521/apple-macos-tahoe-26-now-available-download-update",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Chinese Chipmaker Stocks Rally As U.S. Firms Face Fresh Beijing Scrutiny",
      "content": "This article first appeared on GuruFocus.\n\nSep 15 - China's latest trade move placed U.S. chipmakers in the spotlight after Beijing opened an anti-dumping probe into American semiconductors. The investigation, announced late last week, aims to protect China's domestic industry and support local firms.\n\nChinese chip stocks jumped on the news. SG Micro, Suzhou Novosense Microelectronics, and 3Peak each surged to their daily trading limit. Semiconductor Manufacturing International (SIUIF), the country's top contract chipmaker, gained 1.3% in Hong Kong, while Hua Hong Semiconductor (HHUSF) advanced 2.9%.\n\nThe probe came just one day after the U.S. Commerce Department placed GMC Semiconductor Technology (Wuxi) and Jicun Semiconductor Technology on its restricted trade list. Both firms were accused of acquiring American equipment for SMIC.\n\nInvestors also watched U.S.-listed chip giants. Nvidia (NASDAQ:NVDA), Advanced Micro Devices (NASDAQ:AMD), Broadcom (AVGO), Intel (INTC), Texas Instruments (TXN), Marvell Technology (NASDAQ:MRVL), QUALCOMM (NASDAQ:QCOM), Micron Technology (NASDAQ:MU), and Analog Devices (NASDAQ:ADI) all traded in focus as markets weighed potential fallout.\n\nThe recent moves highlight increasing technological fissure between Washington and Beijing, each of which is seeking to protect their national supply chains, but preserve their place in world chip manufacturing.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/chinese-chipmaker-stocks-rally-u-123058218.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Open source Cloud Hypervisor adds (maybe futile) no-AI-code policy",
      "content": "The Cloud Hypervisor project has introduced a No AI code policy.\n\nCloud Hypervisor started life in 2018 as a joint effort between Google, Intel, Amazon, and Red Hat – all of which wanted to share their work on virtualization components to speed their respective efforts to create virtual machine monitors and hypervisors. The participants decided that work was best undertaken using Rust and the rust-vmm project is the result.\n\nIntel took the project in a slightly different direction and led to the creation of Cloud Hypervisor, a Virtual Machine Monitor for cloud workloads. The Linux Foundation took on the project in 2021, when Alibaba, ARM, ByteDance, and Microsoft were also part of the project, alongside Intel.\n\nAMD, Ampere, Germany’s Cyberus Technology and China’s Tencent Cloud have since become supporters, and the project now describes itself as “an open source Virtual Machine Monitor that runs on top of the KVM hypervisor and the Microsoft Hypervisor.” It’s mostly used by public clouds as the hypervisor in their IaaS services, and is customized to work with the hardware they buy in bulk.\n\nThe project delivered version 48 last week, complete with the new policy to “decline any contributions known to contain contents generated or derived from using Large Language Models.”\n\nAs detailed in the project’s documentation for contributors, the reasons for the ban are “… to avoid ambiguity in license compliance and optimize the use of limited project resources, especially for code review and maintenance.”\n\nThat wording suggests Cloud Hypervisor’s maintainers fear legal complications and/or contributions comprised of AI slop.\n\nAI coding tools are almost certainly trained on open source code, but it’s hard for developers to know if the LLMs helping them to write software also snarfed copyrighted code or projects published under restrictive licenses. All of Cloud Hypervisor’s contributors are likely targets for lawsuits, so politely declining to accept AI makes sense.\n\nEven though the project’s participants know it’s probably a futile gesture.\n\nIn a thread debating the policy, Cyberus Technology’s Philipp Schuster expressed concern “that this policy will basically be violated starting from day 0 after being merged. We never can ensure code is not at least enhanced with/from LLM.”\n\nIn response, a contributor named Bo Chen suggested “we need a procedure to make sure the policy is explicitly acknowledged. One option is to add a pull request template that includes a mandatory checkbox, requiring contributors to affirm they have read and agree to our contribution guide.”\n\nA notable inclusion in version 48 is documentation on how to run Windows 11 guests, which should help those creating cloudy desktop-as-a-service products.\n\nOther additions that may interest include:\n\nLifting the maximum number of supported vCPUs on x86_64 hosts using KVM from 254 to a whopping 8192;\n\nRemoving support for Intel’s Software Guard Extensions (SGX);\n\nAdding support for inter-VM shared memory;\n\nFaster pausing for VMs that run on many vCPUs.\n\n®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/15/cloud_hypervisor_no_ai_policy/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Walmart is emerging as an AI powerhouse with one big advantage",
      "content": "lighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nAnalysts have characterized the recent strength in the stock market as an AI rally, but flying under the Magnificent Seven's radar is Walmart — a company so vast that it literally has its own weatherman.\n\nAnd as it turns out, the retail juggernaut's scale and reach are proving to be tremendous assets in the AI race.\n\nThat's because most top AI companies — like OpenAI, Microsoft, Anthropic, or Meta — operate in a primarily virtual space, processing unfathomably complex rivers of information into more digital information. AI-adjacent companies like Nvidia, Intel, and Oracle focus on providing the physical infrastructure upon which the AI machines function. Then there are the companies that are using digital intelligence to deliver physical results through automation and augmented experiences, like Tesla and Amazon.\n\nWalmart, by contrast, has a vast and complicated set of physical challenges to solve as the largest retailer in the US — and the world. Those include everything from cleaning up spills in the dairy aisle to stocking shelves.\n\n\"We move billions of items around every month, every year,\" Walmart US CEO John Furner said Tuesday at the Fortune Brainstorm Tech conference. He said the company has been developing machine learning tools and other automation projects since around 2015.\n\nFurner said that the company's AI models and supply chain automation help plan inventory to arrive at the right aisle at the right time, for example. One technique involves creating \"digital twins\" of each facility to model the movement of merchandise through the system on its way to customers.\n\nFurner also said store associates increasingly have an AI chatbot handy via their handheld devices to help them better set priorities and help customers.\n\n\"It's a combination of people being powered by technology. There's a lot of judgment to retail and decision-making. And we're in a very dynamic industry,\" he said. \"We think this next phase of physical AI in combination with Gen AI is going to be really helpful.\"\n\nThe company's head of e-commerce, David Guggina, told the Goldman Sachs Communicopia and Tech conference last week how AI is helping his team run experiments and fulfill orders at an increasingly rapid rate.\n\nGuggina said his team is now able to work at breathtaking speed behind the scenes, too.\n\n\"What took a data scientist days or weeks before can now be done in minutes,\" he said.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nAI also helps ensure that each of the company's 4,700 stores has the kinds of products best suited to their local markets, slashing delivery times to minutes after a customer places an order.\n\n\"We've just completed the third inning,\" he said by way of the classic baseball game analogy. \"So we're still early with regard to our automation journey in the fulfillment network.\"\n\nThese digital-to-physical uses of AI are also complemented by a myriad of \"micro agents\" that handle tasks like tracking local event calendars or monitoring inventory levels.\n\nWalmart, of course, is still fine-tuning its AI approach, and there have been hiccups.\n\nThe proliferation of bespoke Walmart-made AI agents eventually started to confuse users, the company told the Wall Street Journal.\n\nThe company has rolled many of those micro agents into four \"super agents\" designed to assist shoppers, merchandisers, programmers, and third-party marketplace sellers.\n\nStill, because Walmart's 20,000-strong global tech team builds so many of these digital and physical solutions in-house, the company is emerging as an unexpected AI powerhouse.\n\nThe company snagged former Instacart exec Daniel Danker in July to accelerate its AI efforts.\n\nIt's also deepening its partnership this month with OpenAI via a new training program for associates and enterprise access to ChatGPT tools for frontline Sam's Club employees to help operate their warehouse stores more smoothly.\n\nAfter all, while chatbots might sometimes hallucinate answers, there's no faking a cold gallon of milk on your doorstep.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/why-walmart-is-emerging-as-an-ai-powerhouse-2025-9",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "AOMedia Announces Year-End Launch of Next-Gen Video Codec AV2",
      "content": "The Future of Innovation Is Open: AOMedia Member Survey Highlights Adoption Trends\n\nWakefield, Mass. — Sept. 15, 2025 — The Alliance for Open Media (AOMedia), a global collaboration of innovators working together to define and deploy open standards that power the next generation of media experiences, today announced the upcoming launch of the next evolution in open video coding: AV2. Set for a year-end release, AV2 is not only an upgrade to the widely adopted AV1 but also a foundational piece of AOMedia’s future tech stack.\n\nAV2, a generation leap in open video coding and the answer to the world’s growing streaming demands, delivers significantly better compression performance than AV1. AV2 provides enhanced support for AR/VR applications, split-screen delivery of multiple programs, improved handling of screen content, and an ability to operate over a wider visual quality range. AV2 marks a milestone on the path to an open, innovative future of media experiences.\n\n“At AOMedia, we believe innovation thrives when it’s open,” said Dr. Pierre-Anthony Lemieux, Executive Director of AOMedia. “Our standards benefit from input from innovators worldwide and are developed under a royalty-free patent policy, bringing next-generation media experiences to more people, faster. We’re excited to share AV2 with the world, as we continue to lead the way in shaping the future of media through open collaboration.”\n\nSurvey Findings: Widespread Support of AV1 and Planned Adoption of AV2\n\nIn conjunction with its 10th anniversary, AOMedia released new member survey findings that underscore strong industry-wide support for its open innovation model and the widespread adoption of its technologies.\n\nThe survey found that 88% of members ranked AV1 as either “extremely critical” or “important” to their current or future product roadmaps. AOMedia’s Adoption Showcase illustrates the real-world benefits members are achieving through AV1 deployment. Looking ahead, 53% of AOMedia members surveyed plan to adopt AV2 within 12 months upon its finalization later this year, with 88% expecting to implement it within the next two years.\n\nJoin the Future of Open Media Innovation\n\nAOMedia invites new members to help shape the future of open, high-performance media standards. To learn more about membership opportunities, contact membership@aomedia.org.\n\nAbout AOMedia\n\nLaunched in 2015, the Alliance for Open Media (AOMedia) develops open standards for media — spanning video, audio, still images, and immersive technologies. AOMedia brings together 49 global innovators — including tech leaders with decades of media tech experience and some of the world’s largest patent holders — to support this mission. Its steering committee consists of Amazon, Apple, Cisco, Google, Intel, Meta, Microsoft, Mozilla, Netflix, NVIDIA, Samsung Electronics, and Tencent. Learn more at www.aomedia.org.\n\nMedia Contact\n\nMelissa Bednar\n\nAOMedia Public Relations\n\nmbednar@virtualinc.com\n\n781.876.8962",
      "source": "Aomedia.org",
      "url": "https://aomedia.org/press%20releases/AOMedia-Announces-Year-End-Launch-of-Next-Generation-Video-Codec-AV2-on-10th-Anniversary/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "How next-gen laptops use NPUs for massive power savings",
      "content": "Current laptops with Intel Core Ultra Series 2 processors rely on a hybrid chip design that is specifically geared towards energy efficiency. The Neural Processing Unit (NPU), used for the first time in consumer systems, plays a central role here. This dedicated computing unit for AI tasks relieves the CPU and GPU of inference-based processes such as image recognition, language processing, or modelling.\n\nWhile the CPU had to take on many of these tasks in conventional systems, the NPU enables a significantly more differentiated load distribution. This lowers the average system load and noticeably reduces energy requirements. As many NPU calculations can be carried out at a low clock frequency and in parallel, the energy balance is significantly improved compared to purely CPU- or GPU-based architectures.\n\nEnergy-saving components in Intel Core Ultra\n\nThe Intel Core Ultra V models in particular combine four performance cores with four efficiency cores and a dedicated NPU to form a tiered computing unit. The P-cores take over performance-critical tasks, while the E-cores and NPU remain continuously active in the background and run routine processes and AI functions with low power requirements.\n\nMark Hachman / IDG\n\nThe integrated Intel Arc Graphics also plays a role in this context: it enables hardware-accelerated video decoding and graphics-intensive display without an additional dedicated GPU, which relieves the cooling system and reduces the overall power consumption. The NPU delivers up to 48 TOPS of computing power with minimal power consumption. This benefits AI applications and AI functions as well as users, as the energy requirements of notebooks can be significantly minimised.\n\nIntel\n\nMicrosoft’s energy-saving mechanisms under Windows 11\n\nParallel to the hardware platform, new energy-saving strategies have been implemented with Windows 11. The “User Interaction-Aware CPU Power Management” analyzes user activity in real time. If no interaction via keyboard, mouse, or touchpad is detected, the system automatically throttles CPU performance without interrupting active media playback or presentations. In addition, the “Adaptive Energy Saver” function also activates the energy-saving mode regardless of the battery status, provided the system load and usage scenario allow this.\n\nSam Singleton\n\nIn both cases, the NPU can ensure that AI-supported functions remain active in the background without negatively impacting the energy balance. The AI also balances priorities in the background, for example by delaying cloud synchronization or adaptive process rest.\n\nHP Omnibook and other Copilot models in comparison\n\nDevices such as the HP’s Omnibook X line already integrate these technologies system-wide. In combination with an Intel Core Ultra 7 258V and an Intel Arc 140V GPU, the NPU enables locally executed features such as Windows Studio Effects or AI functions in HP AI Companion without noticeably draining the battery. Many other models also achieve battery runtimes of over 24 hours in mixed operation thanks to the use of NPUs. Models such as the Surface Laptop 6 or the Surface Pro 10 integrate a dedicated NPU directly into the Intel Core Ultra SoC, supplemented by high-performance CPU cores and integrated graphics.\n\nOther compatible devices also rely on the Copilot concept, which combines powerful NPUs with intelligent energy management. Devices such as the Galaxy Book with RTX 4050/4070 or the Surface Pro 10 with Intel Core Ultra 7 demonstrate these possibilities. In practice, this means that even when language translation, background blurring or real-time image optimization are actively used, power consumption remains low.\n\nSoftware-based optimization and AI offloading\n\nA significant contribution to energy savings is made by shifting compute-intensive workloads to the NPU on the software side. Applications such as Zoom, Adobe Premiere Pro or Amuse are increasingly using native ONNX runtime-based interfaces to offload AI processes such as image generation, object tracking or audio filters to the NPU.\n\nAdobe\n\nThis reduces the energy requirements of the CPU, which is particularly noticeable during long periods of use in video conferences or creative applications. The NPU is accessed via standardized interfaces such as DirectML and Intel and AMD platforms, which have native integration into the ONNX runtime. The resulting reduction in load on the main processors makes a decisive contribution to more even load distribution and therefore longer battery life.\n\nInteraction of CPU, GPU, and NPU in practice\n\nIn modern notebooks, the CPU, GPU, and NPU work as a dynamic processing trio. While the CPU continues to control the operating system and general applications, the GPU takes over graphics-intensive tasks or parallelized computing operations. The NPU concentrates on dedicated AI processes and enables continuous processing with low energy consumption. Windows 11 assigns these tasks specifically, and continuously evaluates which unit is most efficient for execution.\n\nIDG / Mark Hachman\n\nThis means that recurring tasks such as speech transcription, person recognition, or background noise filters can be processed directly on the NPU. This not only lowers power consumption, but also reduces the system temperature, which enables lighter cooling systems and therefore more compact and lighter notebook designs overall.\n\nLocal processing instead of cloud offloading\n\nThe local execution of AI workloads on the NPU replaces the usual cloud access in many cases. This means that image analyses, language models, or layout suggestions no longer have to be calculated online, but run entirely on the device. This not only reduces latencies, but also avoids unnecessary network activity. This is another factor that reduces power consumption.\n\nAt the same time, the availability of these functions is increased even without a network connection, for example on the train or when travelling. Battery life then benefits in two ways: through lower computing load on the CPU and GPU and through reduced Wi-Fi or LTE/5G activity.\n\nWindows 11 shows NPU utilization in Task Manager for the first time\n\nMicrosoft has expanded the Task Manager for control and transparency of this new architecture. In addition to CPU, GPU, and RAM, NPU utilization is now also displayed as a separate measured value. This allows users to understand how much their AI applications are actually benefiting from the dedicated hardware.\n\nFor developers, the ONNX runtime in combination with the Windows Performance Analyzer also offers detailed diagnostic functions that can be used to specifically analyze inference times, operator load, and load curves. This enables fine-tuned optimization for maximum energy gain and minimum runtime delay.\n\nSam Singleton\n\nBattery life as the new benchmark for AI PCs\n\nWhile attention has long focused on computing power and model size, there is now a paradigm shift. The actual runtime of a device is increasingly becoming the most important quality criterion for AI-optimized notebooks. Modern AI notebooks achieve video playback times of over 26 hours under realistic conditions, a value that would be almost impossible to realize without NPU-supported power distribution.\n\nAt the same time, the combination of an adaptive energy-saving mode, local AI offloading, and intelligent load controls opens up new possibilities for mobile applications where the power supply is not always guaranteed.\n\nConclusion: Saving energy with specialized AI hardware\n\nThe integration of NPUs into current notebook platforms not only marks a technological advance in terms of AI performance, but also enables a sustainable reduction in energy consumption through intelligent task sharing for the first time. In combination with the new energy-saving functions of Windows 11, the result is a platform that not only works faster in everyday use, but also noticeably more efficiently. For users, this means longer battery life, less waste heat, quieter systems, and an overall better balance between performance and mobility, without sacrificing modern AI functions.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2888029/how-next-gen-laptops-use-npus-for-massive-power-savings.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "iOS 26, iPadOS 26, macOS Tahoe, watchOS 26, tvOS 26, And visionOS 26 Are Now Available",
      "content": "After three long months of beta testing, Apple has made iOS 26, iPadOS 26, macOS Tahoe, watchOS 26, tvOS 26, and visionOS 26 available to all users. If you have compatible devices, you can download Apple's latest software by going to Settings > General > Software Update.\n\nAll of these software updates feature the new Liquid Glass design. While it's going to be more noticeable on iOS, iPadOS, and macOS, Apple also tweaked the UI of watchOS, tvOS, and visionOS. With this redesign, Apple users can take advantage of new Clear icons, redesigned Control Center, new looks for the apps, and finally having the names of all the updates match.\n\nFor iPadOS 26, Apple is getting more serious about multitasking and productivity features, as the company now offers a new window tiling system, a Preview app for signing documents and sketching, and improved Apple Intelligence features powered by ChatGPT. macOS Tahoe brings improved Continuity functionalities, a revamped Spotlight search, and it also marks the last major OS update for Intel Macs. Apple says macOS 27 will be only available to Apple Silicon computers.",
      "source": "BGR",
      "url": "https://www.bgr.com/1968552/ios-26-ipados-26-macos-tahoe-watchos-26-tvos-26-visionos-26-download-now-available/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Condor Technology to Fly \"Cuzco\" RISC-V CPU into the Datacenter",
      "content": "Once a hyperscaler or a cloud builder gets big enough, it can afford to design custom compute engines that more precisely match its needs. It is not clear that the companies that make custom CPUs and XPUs are saving money, but they are certainly gaining control and that is worth something.\n\nArm made a push based on the power-efficient nature its architecture, and Nvidia has become a key player in AI with its powerful GPUs and now its “Grace” Arm server CPUs. A reinvigorated AMD has given system makers an x86 alternative to an Intel that is still trying to find its footing after a few years of missteps and missed deadlines. And now, the community for RISC-V, the open, modular, and highly customizable architecture overseen by the RISC-V International collective, is looking to make inroads into datacenters.\n\nIt is still early days for RISC-V, much as it was for Arm in the datacenter back in 2010, but the RISC-V architecture is being embraced by a range of well-known tech vendors, from Intel, Western Digital, Google, Nvidia, Meta Platforms, and Qualcomm, and a growing number of pure-plays and startups, such as Andes Technology, SiFive, Microchip Technology, Ventana, and Lattice Semiconductor.\n\nThere also is money backing the effort. Most recently, the European Union continued its on-again, off-again courting of RISC-V for supercomputers and other HPC systems in the region with the launch in March of DARE – Digital Autonomy with RISC-V in Europe – to oversee a six-year, $260 million effort.\n\nCondor Takes Flight\n\nAndes is two decades old and, despite its name, is based in Taiwan, not in Colombia, Chile, Peru, or Argentina where the mountain range of that name is located on the western coast of South America. The company is a founding member of RISC-V International and a maker of efficient and low-power processor cores based on the architecture.\n\nMark Evans, director of business development at Andes and now its Condor Computing subsidiary that was established in Austin, Texas to get indigenous to the United States, gave an overview of the company in a session at the AI Infra Summit in Santa Clara last week. The week before that Ty Garibay, Condor’s founder and president, and Shashank Nemawarkar, Condor’s director of architecture, walked everyone through the “Cuzco” core that the company has created to begin its assault on the datacenter in earnest.\n\nEvans says that Andes has shipped its intellectual property in over 17 billion RISC-V chips since 2005, and further that it has been growing sales at a compound annual growth rate of 29 percent between 2018 and now. Evans put some numbers on it, saying that Andes had $42 million in sales in 2024, and that its IP was present in 30 percent of RISC-V SoCs that were shipped last year.\n\nThe Andes customer base is pretty broad across various industry sectors, including MediaTek and Novatek in mobile devices, Phison in storage, and Meta Platforms and SK Telecom in AI compute engines.\n\nEvans says that 39 percent of the revenue that Andes had in 2024 came from the AI sector, significantly including the MTIA v1 and MTIA v2 coprocessors from Meta.\n\nThat brings us to the “Cuzco” RISC-V core that Condor was showing off at the Hot Chips 2025 conference.\n\nIn July, Condor successfully did full hardware emulation of the Cuzco core, booting multiple operating systems, including Linux, with the first users expected to get the processor sometime in the last quarter. This high-performance RISC-V core has microarchitectural tweaks, including the way it issues instructions and organizes execution units, all with the aim of creating what Garibay said will be “the world’s highest performance licensable RISC-V CPU IP,” with a broad range of use cases.\n\n“We’re entirely focused on bringing an innovative new microarchitecture to the RISC-V CPU market,” Garibay said during a presentation at Hot Chips. “We intend to demonstrate that RISC-V can be competitive in any high-performance computing application, from datacenters to handsets to automotive. … Our goal is to provide much better performance than other high-performance, licensable CPUs while operating at a similar power envelope.”\n\nCuzco is based on the latest RISC-V profile for datacenter computing – RVA-23 – so ensure high software compatibility, can support up to eight cores with up to 8 MB private L2 cache in a coherent cluster with a shared 256 MB L3 cache, and a 12-stage pipeline. There are functional units that execute through a pool after the eight-instruction dispatch. The CPU itself is standard, with fetch, instruction queue, and instruction decode, he said.\n\nBelow is a more detailed block diagram of the Cuzco core:\n\nHere is the cache memory architecture:\n\nAnd here is the socket architecture:\n\nThe structure of the core is what is really interesting with Cuzco, so we are going to spend our time there.\n\nOne area Condor focused on was the structure of the execution units, which Garibay said are pair into two pipelines called a “slice,” with each of the four slices being identical and each having its own pipelines and resources.\n\n“Each slice fully implements RISC-V compatibility,” he said. “The machine is scalable, in theory, down to one slice or pair of pipelines, although. practically probably, only anyone would ever implement is two slices. As a minimum machine, the overhead becomes unwieldy at that point. But it is scalable to six pipelines, three slices by default – eight pipelines, four slices – and then we will extend this architecture into the future, with added features as we grow the slice count.\n\nThe intent, he said, “was to ease the implementation of this in high-performance processes.”\n\nThen comes the time-based architecture for instruction sequencing. The chip starts out with what Nemawarkar called “a standard pipeline for the out-of-order machines. Typically, this is a 12-log stage pipeline. The instruction fetch, nothing different than most of it you have seen.”\n\nChanges come from the point of where instruction decode happens, Nemawarkar said. That’s where the time-based issuing logic kicks in. Most chips use Tomasulo’s algorithm, a process for the out-of-order scheduling of instructions. In these cases, the chips use content-addressable memories (CAMs) to point to instructions to send downstream. CAMs can eat up a lot of power, given the match-line switching and precharge cycles needed.\n\nCuzco uses its register scoreboard to record the write time of an instruction to a register, which then becomes the read time. The scoreboard says when the instruction is available for execution and tracks the future of write time of instructions. The chip’s time resource metrix (TRM) records the use of resources like arithmetic logic units (ALUs), buses, and load and store queues to help predict ahead of time what resource will be available, which enables predictive scheduling. Instructions can be issued with an understand of exact future cycles for operands and resources, according to Andes.\n\nIt also does away with the power-hungry CAMs.\n\n“The reasoning behind that is this allows us to reduce the complexity, which typically happens in the global scheduling or a local scheduling or combination of that, when the machines start to become wider and wider,” Nemawarkar said. “Everybody knows that being a huge problem. Then essentially, with each execution unit, you need to start looking at which instructions are ready, how do I execute based on the priority for which instruction to be given, etc.”\n\nIt’s something that other implementations haven’t tried before, according to Garibay.\n\n“It is a departure, and it’s a good departure in that we’re looking to reduce the overall power and area of what has become the most power-and-area-hungry part of these wide, out-of-order machines – instruction scheduling,” Garibay added.\n\nEnterprises and HCP centers will be able to put Cuzco to the test by the end of the year so see how the new execution units and out-of-order instruction scheduling will work for them.",
      "source": "The Next Platform",
      "url": "https://www.nextplatform.com/2025/09/15/condor-technology-to-fly-cuzco-risc-v-cpu-into-the-datacenter/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Intel trims full-year expense outlook following Altera stake sale",
      "content": "(Reuters) - Intel said on Monday it has lowered its full-year 2025 adjusted operating expense target to $16.8 billion, from $17 billion earlier, to reflect the deconsolidation of its programmable chip business, Altera.\n\nShares of the struggling chipmaker rose nearly 4% as the trimmed projected expenses provided investors with some respite after burgeoning costs left Intel with a strained balance sheet.\n\nThe company recorded an annual loss of $18.8 billion in 2024, its first such loss since 1986, after former CEO Pat Gelsinger poured billions into expanding its loss-making contract-manufacturing business.\n\nNew CEO Lip-Bu Tan is streamlining operations and making management changes to strengthen the company's finances.\n\nThis comes as the U.S. government has taken a 10% equity stake by converting Biden-era grants into shares.\n\nIn April, Intel agreed to sell 51% of Altera to private equity firm Silver Lake, valuing the unit at $8.75 billion, well below the nearly $17 billion Intel paid in 2015.\n\nIntel completed the transaction on September 12, with Silver Lake acquiring a majority stake in Altera for an equity value of about $3.3 billion, according to a regulatory filing, reflecting debt financing and cash for the business.\n\nAs an Intel segment in the first half of 2025, Altera reported a 55% gross margin on $816 million in revenue and $356 million in operating expenses.\n\nIntel kept its 2026 full-year operating expense target at $16 billion.\n\nThe company said in July it will end this year with a workforce more than a fifth smaller than last year. Tan has pledged tighter cost discipline and “no more blank checks.”\n\n(Reporting by Arsheeya Bajwa in Bengaluru; Editing by Tasim Zahid)",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/intel-lowers-full-expense-target-101915801.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Top Stock Movers Now: Tesla, Intel, Nvidia, and More",
      "content": "Key Takeaways U.S. equities mostly rose at midday on optimism about U.S.-China trade and TikTok's future.\n\nTesla CEO Elon Musk purchased about $1 billion in the electric vehicle maker's stock.\n\nChinese regulators are investigating U.S. chipmakers for alleged dumping of analog integrated circuit semiconductors.\n\nU.S. equities were higher at midday on positive comments about China trade and the future of TikTok from President Trump, as well as Tesla (TSLA) news. S&P 500 and Nasdaq gained, while the Dow Jones Industrial Average was little changed.\n\nTesla shares jumped as a regulatory filing showed CEO Elon Musk purchased 2.57 million shares of the electric vehicle's stock valued at about $1 billion.\n\nShares of Seagate Technology Holdings (STX) traded above $200 for the first time on continued excitement over the company's new hard disk drive for artificial intelligence data centers.\n\nIntel (INTC) shares climbed after the struggling semiconductor maker reduced its target for full-year non-GAAP operating expenses after completing the $3.3 billion sale of a majority stake in its Altera programmable chip business to private equity firm Silver Lake.\n\nAlphabet (GOOGL) shares were up for a third straight session, making the parent of Google the fourth company with a $3 trillion market capitalization.\n\nCorteva (CTVA) was among the worst-performing stocks in the S&P 500 following a report that the manufacturer of crop seeds and pesticides is looking into splitting itself into two separate companies.\n\nSome chipmakers, including Nvidia (NVDA) and Texas Instruments (TXN), fell as Chinese regulators were investigating potential dumping of analog integrated circuit semiconductors from the U.S.\n\nU.S.-listed shares of AstraZeneca (AZN) declined after a report the drugmaker had paused a planned $272 million investment in Britain, and received a downgrade from Europe's Handelsbanken.\n\nOil and gold futures rose. The yield on the 10-year Treasury note declined. The U.S. dollar lost ground to the euro, pound, and yen. Prices for most major cryptocurrencies dipped.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/top-stock-movers-now-tesla-intel-nvidia-and-more-11809916",
      "timestamp": "2025-09-15"
    }
  ]
}