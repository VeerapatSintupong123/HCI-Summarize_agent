{
  "Nvidia": [
    {
      "headline": "How China is challenging Nvidia's AI chip dominance",
      "content": "How China is challenging Nvidia's AI chip dominance\n\n9 hours ago Share Save Osmond Chia Business reporter Share Save\n\nGetty Images Jensen Huang, the boss of Silicon Valley-based Nvidia, has warned China is \"nanoseconds behind\" the US in chips\n\nThe US has dominated the global technology market for decades. But China wants to change that. The world's second largest economy is pouring huge amounts of money into artificial intelligence (AI) and robotics. Crucially, Beijing is also investing heavily to produce the high-end chips that power these cutting-edge technologies. Last month, Jensen Huang - the boss of Silicon Valley-based AI chip giant Nvidia - warned that China was just \"nanoseconds behind\" the US in chip development. So can Beijing match American technology and break its reliance on imported high-end chips?\n\nAfter DeepSeek\n\nChina's DeepSeek sent shockwaves through the tech world in 2024 when it launched a rival to OpenAI's ChatGPT. The announcement by a relatively unknown startup was impressive for a number of reasons, not least because the company said it cost much less to train than leading AI models. It was said to have been created using far fewer high-end chips than its rivals, and its launch temporarily sank Silicon Valley-based Nvidia's market value. And momentum in China's tech sector has continued. This year, some of the country's big tech firms have made it clear that they aim to take on Nvidia and become the main advanced chip suppliers for local companies. In September, Chinese state media said a new chip announced by Alibaba can match the performance of Nvidia's H20 semiconductors while using less energy. H20s are scaled-down processors made for the Chinese market under US export rules. Huawei also unveiled what it said were its most powerful chips ever, along with a three-year plan to challenge Nvidia's dominance of the AI market. The Chinese tech giant also said it would make its designs and computer programs available to the public in China in an effort to draw firms away from their reliance on US products.\n\nGetty Images DeepSeek stunned the tech world in 2024 when it launched an AI model to rival ChatGPT\n\nOther Chinese chip developers have also secured major contracts with big businesses in the country. MetaX is supplying advanced chips for the likes of state-owned telecoms operator, China Unicom. Another hotly-tipped potential challenger to Nvidia is Beijing-based Cambricon Technologies. Its Shanghai-listed shares have more than doubled in value over the last three months as investors bet that it will benefit from Beijing's push for Chinese firms to use locally produced high-end chips. Tencent, which owns the super app WeChat, is another notable tech giant that has heeded the government’s call to use Chinese chips. There has also been no shortage of state-backed trade shows, promoting Chinese technology companies in a bid to attract investors. \"The competition has undeniably arrived,\" a spokesperson for Nvidia told the BBC in response to queries about the recent progress made by Chinese chip firms. \"Customers will choose the best technology stack for running the world's most popular commercial applications and open-source models. We'll continue to work to earn the trust and support of mainstream developers everywhere.\" Yet some experts have cautioned that claims made by Chinese chipmakers should be taken with a pinch of salt due to a lack of publicly available data and consistent testing benchmarks. China's semiconductors perform similarly to the US in predictive AI but fall short in complex analytics, said computer scientist Jawad Haj-Yahya, who has tested both American and Chinese chips. \"The gap is clear and it is surely shrinking. But I don't think it's something they will catch up on in the short-term.\"\n\nWhere China leads - and lags\n\nOn the BG2 technology and business podcast in September, Nvidia's Jensen Huang highlighted the strengths of China's tech sector, crediting its hardworking and vast talent pool, intense domestic competition and progress in chipmaking. \"This is a vibrant entrepreneurial, high-tech, modern industry,\" he said, urging the US to compete \"for its survival\". His assessment is likely to be welcomed by officials in Beijing. The country has long vied to become a global leader in tech, partly to reduce its reliance on the West. For years, China has invested heavily in what President Xi Jinping calls \"high-quality development\", which covers industries from renewables to AI. Even before US President Donald Trump's return to the White House, China had spent tens of billions of dollars as part of its efforts to transform its vast economy from the \"world's factory\" for basic products to a home of cutting-edge industries. An ongoing tariffs war with Trump's America has only made that mission more urgent. Xi has vowed to make his country more self-reliant and not depend on \"anyone's gifts\".\n\nMr Huang has also warned that the US should trade freely with China or risk handing it the edge in the AI race. This comes against a backdrop of Beijing applying more pressure on Nvidia as it launched an anti-monopoly probe into the firm last month. But China's state-led approach can also be an obstacle to innovation if everyone in the sector only focuses on a \"shared goal\", said computing professor Chia-Lin Yang from the National Taiwan University. It can make it harder for disruptive ideas to break the mould, she added. China's chip industry has also yet to overcome criticism that its products can be less user-friendly than those of Western rivals like Nvidia. Prof Yang believes these issues can soon be solved by China's huge number of skilled tech industry workers. \"You cannot underestimate China's ability to catch up.\"\n\nGetty Images Chinese tech giant Huawei unveiled its plans to rival Nvidia's dominance in AI chips\n\n'Bargaining chip' for China",
      "source": "BBC News",
      "url": "https://www.bbc.com/news/articles/cgmz2vm3yv8o",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Meet Lisa Su: CEO and president of Advanced Micro Devices, the main competitor to Nvidia",
      "content": "Lisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion.\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nlighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nLisa Su is the engineer behind one of the most dramatic corporate turnarounds in the tech industry.\n\nThe Taiwanese American CEO is widely credited with transforming AMD from a struggling semiconductor firm on the brink of collapse into a global powerhouse competing head-to-head with Intel and Nvidia.\n\nWhen Su joined AMD in 2012, the company's market value was under $2 billion. Within a decade of her leadership, AMD's innovations in high-performance computing and graphics, especially the Ryzen CPUs and EPYC server processors, catapulted the company's value to roughly $270 billion as of October 2025.\n\nBut Su's leadership has not been without challenges. AMD's two largest competitors, Nvidia and Intel, are now working together in a strategic collaboration. Under the second Trump administration, export regulations related to China, one of AMD's largest markets, are also constantly changing.\n\nHere's a look at the timeline of Su's career, from her early life in New York City to her role as one of the most influential women in tech and innovation:",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/meet-lisa-su-ceo-and-president-of-advanced-micro-device",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Huawei Atlas 950 SuperPoD vs Nvidia DGX SuperPOD vs AMD Instinct Mega POD: How do they compare?",
      "content": "Huawei stacks thousands of NPUs to show brute-force supercomputing dominance\n\nNvidia delivers polish, balance, and proven AI performance that enterprises trust\n\nAMD teases radical networking fabrics to push scalability into new territory\n\nThe race to build the most powerful AI supercomputing systems is intensifying, and major brands now want a flagship cluster that proves it can handle the next generation of trillion-parameter models and data-heavy research.\n\nHuawei’s recently-announced Atlas 950 SuperPoD, Nvidia’s DGX SuperPOD, and AMD’s upcoming Instinct MegaPod each represent different approaches to solving the same problem.\n\nThey all aim to deliver massive compute, memory, and bandwidth in one scalable package, powering AI tools for generative models, drug discovery, autonomous systems, and data-driven science. But how do they compare?\n\nSwipe to scroll horizontally Huawei Ascend 950 vs Nvidia H200 vs AMD MI300 Instinct Category Huawei Ascend 950DT NVIDIA H200 AMD Radeon Instinct MI300 Chip Family / Name Ascend 950 series H200 (GH100, Hopper) Radeon Instinct MI300 (Aqua Vanjaram) Architecture Proprietary Huawei AI accelerator Hopper GPU architecture CDNA 3.0 Process / Foundry Not yet publicly confirmed 5 nm (TSMC) 5 nm (TSMC) Transistors Not specified 80 billion 153 billion Die Size Not specified 814 mm² 1017 mm² Optimization Decode-stage inference & model training General-purpose AI & HPC acceleration AI/HPC compute acceleration Supported Formats FP8, MXFP8, MXFP4, HiF8 FP16, FP32, FP64 (via Tensor/CUDA cores) FP16, FP32, FP64 Peak Performance 1 PFLOPS (FP8 / MXFP8 / HiF8), 2 PFLOPS (MXFP4) FP16: 241.3 TFLOPS, FP32: 60.3 TFLOPS, FP64: 30.2 TFLOPS FP16: 383 TFLOPS, FP32/FP64: 47.87 TFLOPS Vector Processing SIMD + SIMT hybrid, 128-byte memory access granularity SIMT with CUDA and Tensor cores SIMT + Matrix/Tensor cores Memory Type HiZQ 2.0 proprietary HBM (for decode & training variant) HBM3e HBM3 Memory Capacity 144 GB 141 GB 128 GB Memory Bandwidth 4 TB/s 4.89 TB/s 6.55 TB/s Memory Bus Width Not specified 6144-bit 8192-bit L2 Cache Not specified 50 MB Not specified Interconnect Bandwidth 2 TB/s Not specified Not specified Form Factors Cards, SuperPoD servers PCIe 5.0 x16 (server/HPC only) PCIe 5.0 x16 (compute card) Base / Boost Clock Not specified 1365 / 1785 MHz 1000 / 1700 MHz Cores / Shaders Not specified CUDA: 16,896, Tensor: 528 (4th Gen) 14,080 shaders, 220 CUs, 880 Tensor cores Power (TDP) Not specified 600 W 600 W Bus Interface Not specified PCIe 5.0 x16 PCIe 5.0 x16 Outputs None (server use) None (server/HPC only) None (compute card) Target Scenarios Large-scale training & decode inference (LLMs, generative AI) AI training, HPC, data centers AI/HPC compute acceleration Release / Availability Q4 2026 Nov 18, 2024 Jan 4, 2023\n\nThe philosophy behind each system\n\nWhat makes these systems fascinating is how they reflect the strategies of their makers.\n\nHuawei is leaning heavily on its Ascend 950 chips and a custom interconnect called UnifiedBus 2.0 - the emphasis is on building out compute density at an extraordinary scale, then networking it together seamlessly.\n\nNvidia has spent years refining its DGX line and now offers the DGX SuperPOD as a turnkey solution, integrating GPUs, CPUs, networking, and storage into a balanced environment for enterprises and research labs.\n\nAMD is preparing to join the conversation with the Instinct MegaPod, which aims to scale around its future MI500 accelerators and a brand-new networking fabric called UALink.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nWhile Huawei talks about exaFLOP levels of performance today, Nvidia highlights a stable, battle-tested platform, and AMD pitches itself as the challenger offering superior scalability down the road.\n\nAt the heart of these clusters are heavy-duty processors built to deliver immense computational power and handle data-intensive AI and HPC workloads.\n\nHuawei’s Atlas 950 SuperPoD is designed around 8,192 Ascend 950 NPUs, with reported peaks of 8 exaFLOPS in FP8 and 16 exaFLOPS in FP16 - so it is clearly aimed at handling both training and inference at an enormous scale.\n\nNvidia’s DGX SuperPOD, built on DGX A100 nodes, delivers a different flavor of performance - with 20 nodes containing a total of 160 A100 GPUs, it looks smaller in terms of chip count.\n\nHowever, each GPU is optimized for mixed precision AI tasks and paired with high-speed InfiniBand to keep latency low.\n\nAMD’s MegaPod is still on the horizon, but early details suggest it will pack 256 Instinct MI500 GPUs alongside 64 Zen 7 “Verano” CPUs.\n\nWhile its raw compute numbers are not yet published, AMD’s goal is to rival or exceed Nvidia’s efficiency and scale, especially as it uses next-generation PCIe Gen 6 and 3-nanometer networking ASICs.\n\nFeeding thousands of accelerators requires staggering amounts of memory and interconnect speed.\n\nHuawei claims the Atlas 950 SuperPoD carries more than a petabyte of memory, with a total system bandwidth of 16.3 petabytes per second.\n\nThis kind of throughput is designed to keep data moving without bottlenecks across its racks of NPUs.\n\nNvidia’s DGX SuperPOD does not attempt to match such headline numbers, instead relying on 52.5 terabytes of system memory and 49 terabytes of high-bandwidth GPU memory, coupled with InfiniBand links of up to 200Gbps per node.\n\nThe focus here is on predictable performance for workloads that enterprises already run.\n\nAMD, meanwhile, is targeting the bleeding edge with its Vulcano switch ASICs offering 102.4Tbps capacity and 800Gbps per tray external throughput.\n\nCombined with UALink and Ultra Ethernet, this suggests a system that will surpass current networking limits once it launches in 2027.\n\nOne of the biggest differences between the three contenders lies in how they are physically built.\n\nHuawei’s design allows for expansion from a single SuperPoD to half a million Ascend chips in a SuperCluster.\n\nThere are also claims that an Atlas 950 configuration could involve more than a hundred cabinets spread over a thousand square meters.\n\nNvidia’s DGX SuperPOD takes a more compact approach, with its 20 nodes integrated in a cluster style that enterprises can deploy without needing a stadium-sized data hall.\n\nAMD’s MegaPod splits the difference, with two racks of compute trays plus one dedicated networking rack, showing that its architecture is centered around a modular but powerful layout.\n\nIn terms of availability, Nvidia’s DGX SuperPOD is already on the market, Huawei’s Atlas 950 SuperPoD is expected in late 2026, and AMD’s MegaPod is planned for 2027.\n\nThat said, these chips are fighting very different battles under the same banner of AI supercomputing supremacy.\n\nHuawei’s Atlas 950 SuperPoD is a show of brute force, stacking thousands of NPUs and jaw-dropping bandwidth to dominate at scale, but its size and proprietary design may make it harder for outsiders to adopt.\n\nNvidia’s DGX SuperPOD looks smaller on paper, yet it wins on polish and reliability, offering a proven platform that enterprises and research labs can plug in today without waiting for promises.\n\nAMD’s MegaPod, still in development, has the makings of a disruptor, with its MI500 accelerators and radical new networking fabric that could tilt the balance once it arrives, but until then, it is a challenger talking big.\n\nVia Huawei, Nvidia, TechPowerUp",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/huawei-atlas-950-superpod-vs-nvidia-dgx-superpod-vs-amd-instinct-mega-pod-how-do-they-compare",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Analyst on NVIDIA (NVDA): ‘Eventually, We Will Hit a Wall’",
      "content": "We recently published 10 Stocks Wall Street is Watching Heading into October. NVIDIA Corporation (NASDAQ:NVDA) is one of the stocks Wall Street is watching.\n\nChris Rolland from Susquehanna said during a program on CNBC last month that Nvidia’s growth will eventually slow down and hit a “wall.” However, the analyst remains bullish on the stock and praised the company’s recent quarter numbers.\n\n“I think eventually we will hit some sort of a wall when it comes to this deceleration. I don’t know if it’s next year, but eventually we’re going to have a flat year and everyone’s going to freak out and think that the P multiple might even be too high. It’s been a meteoric rise. I’m not getting off the train just yet. There’s still a lot of growth here. Whether you’re talking about hyperscale capex, we’ve seen incredible improvement, but there’s probably still another 20 or 30% to go there over the next few years. We have sovereign ahead of us. We have China ahead of us. There’s still some opportunity here.”\n\nThe current AI boom cycle stems from spending by major tech companies, and Nvidia is the biggest beneficiary of this spending. In Q2 FY2026, three direct customers accounted for 23%, 19%, and 14% of NVDA’s accounts receivable. Almost all of the company's revenue comes from AI-related infrastructure spending. In the latest quarter, $41.3 billion of the $46.7 billion revenue came from these clients. The music could stop for Nvidia if these major companies decide to slow down their spending amid a lack of ROI. If investors sense a weakness in CapEx spending, and the market begins to waver, NVDA stock price would be the first to see its impact.\n\nBaird Chautauqua International and Global Growth Fund stated the following regarding NVIDIA Corporation (NASDAQ:NVDA) in its second quarter 2025 investor letter:\n\n“NVIDIA Corporation (NASDAQ:NVDA) reported first quarter results that were extremely solid. The company took a write-down on China-specific datacenter products and flushed out any future China contributions from their guidance, following the new export restrictions introduced in April. Demand commentary ex China was extremely encouraging—Nvidia is outgrowing expectations despite supply constraints and outgrowing competing ASIC products by a large margin. We have been underweight Nvidia relative to the benchmark, which was up 46% in the quarter, given our short-to medium-term concerns that the feverish AI datacenter build may be resulting in overcapacity, which has not come to bear.\n\nWhile we acknowledge the potential of NVDA as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/analyst-nvidia-nvda-eventually-hit-141543966.html",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Meet Lisa Su: CEO and president of Advanced Micro Devices, the main competitor to Nvidia",
      "content": "Lisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion.\n\nREUTERS/Steve Marcus\n\nAMD's CEO, Lisa Su, grew up in Queens and obtained three…\n\nThis story appeared on businessinsider.com , 2025-10-05 10:16:01.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/ccf28a26f3aecc1a",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Wall Street, crypto industry say tokenization will reshape global markets: 'It’s going to eat the entire financial system'",
      "content": "Wall Street, crypto industry say tokenization will reshape global markets: 'It’s going to eat the entire financial system'\n\nImagine a future where the biggest US stocks like Tesla (TSLA) or Nvidia (NVDA) can be traded around the clock, with the transactions settled in seconds.\n\nMomentum is…\n\nThis story appeared on finance.yahoo.com , 2025-10-05 13:30:05.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/ced34fe0aef65643",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Linux 6.18 DRM Pull Includes New Tyr & Rocket Drivers, More AMD & Intel GPU Enhancements",
      "content": "The Direct Rendering Manager \"DRM\" pull request ended up leading to Linus Torvalds complaining over text and Rust code formatting but in the end he pulled all of these kernel graphics driver updates and also the associated \"accel\" accelerator subsystem drivers too.With the Linux 6.18 DRM pull there is a lot of kernel graphics driver improvements across the board, including the new drivers of Tyr and the Rocket accelerator driver. For enhancing existing driver support, the AMD and Intel graphics drivers continue seeing a bulk of the activity. Plus ongoing Rust code work in the DRM subsystem and more.\n\nBelow is a look at the DRM kernel driver changes for Linux 6.18.- The \"Rocket\" accelerator driver is finally mainlined for enabling the NPU found on newer Rockchip SoCs. This is the open-source driver reverse-engineered and started by Tomeu Vizoso. The Rocket accel driver works with new user-space code in Mesa 25.3 for Rockchip NPUs.- The AMDGPU and AMDKFD Checkpoint and Resture \"CRIU\" support for GEM memory objects.- Expanded AMDGPU Video Core Next \"VCN\" engine reset support.- More AMD Cyan Skillfish updates.- The AMDXDNA accelerator driver now supports user-space allocated buffers, improved error reporting, and other enhancements.- A new Intel Xe driver interface for querying VMA count and memory attributes. The intel Intel SLPC \"power_profile\" sysfs interface for the Xe driver for power management tuning.- Intel Xe driver SR-IOV support for CCS surfaces on Xe2+. The SR-IOV PF mode is also now enabled by default on supported platforms. Intel has returned to working on the upstream Habana Labs accelerator driver . There still is no Gaudi 3 support but at least they are back to working on this code under a new set of maintainers.- Intel Xe driver support for madvise in GPU SVM (Shared Virtual Memory).- The Arm Mali Panthor DRM driver added support for Mali G710, G510, G310, Gx15, Gx20, Gx25 GPUs.- Continued work on Nova as the next-generation open-source NVIDIA Linux kernel driver written in Rust.- The initial code around Tyr as a new Rust driver for Arm Mali GPUs . It's not yet usable by end-users, similar to the Nova driver.- Various new Rust abstractions and other work toward making Rust DRM drivers more practical.See this pull for the full list of DRM feature patches this cycle.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-DRM",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "I cloned my voice with AI and it was unsettlingly good",
      "content": null,
      "source": "MakeUseOf",
      "url": "https://www.makeuseof.com/ai-voice-clone-chatterbox/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "How China is challenging Nvidia's AI chip dominance",
      "content": "How China is challenging Nvidia's AI chip dominance\n\n9 hours ago Share Save Osmond Chia Business reporter Share Save\n\nGetty Images Jensen Huang, the boss of Silicon Valley-based Nvidia, has warned China is \"nanoseconds behind\" the US in chips\n\nThe US has dominated the global technology market for decades. But China wants to change that. The world's second largest economy is pouring huge amounts of money into artificial intelligence (AI) and robotics. Crucially, Beijing is also investing heavily to produce the high-end chips that power these cutting-edge technologies. Last month, Jensen Huang - the boss of Silicon Valley-based AI chip giant Nvidia - warned that China was just \"nanoseconds behind\" the US in chip development. So can Beijing match American technology and break its reliance on imported high-end chips?\n\nAfter DeepSeek\n\nChina's DeepSeek sent shockwaves through the tech world in 2024 when it launched a rival to OpenAI's ChatGPT. The announcement by a relatively unknown startup was impressive for a number of reasons, not least because the company said it cost much less to train than leading AI models. It was said to have been created using far fewer high-end chips than its rivals, and its launch temporarily sank Silicon Valley-based Nvidia's market value. And momentum in China's tech sector has continued. This year, some of the country's big tech firms have made it clear that they aim to take on Nvidia and become the main advanced chip suppliers for local companies. In September, Chinese state media said a new chip announced by Alibaba can match the performance of Nvidia's H20 semiconductors while using less energy. H20s are scaled-down processors made for the Chinese market under US export rules. Huawei also unveiled what it said were its most powerful chips ever, along with a three-year plan to challenge Nvidia's dominance of the AI market. The Chinese tech giant also said it would make its designs and computer programs available to the public in China in an effort to draw firms away from their reliance on US products.\n\nGetty Images DeepSeek stunned the tech world in 2024 when it launched an AI model to rival ChatGPT\n\nOther Chinese chip developers have also secured major contracts with big businesses in the country. MetaX is supplying advanced chips for the likes of state-owned telecoms operator, China Unicom. Another hotly-tipped potential challenger to Nvidia is Beijing-based Cambricon Technologies. Its Shanghai-listed shares have more than doubled in value over the last three months as investors bet that it will benefit from Beijing's push for Chinese firms to use locally produced high-end chips. Tencent, which owns the super app WeChat, is another notable tech giant that has heeded the government’s call to use Chinese chips. There has also been no shortage of state-backed trade shows, promoting Chinese technology companies in a bid to attract investors. \"The competition has undeniably arrived,\" a spokesperson for Nvidia told the BBC in response to queries about the recent progress made by Chinese chip firms. \"Customers will choose the best technology stack for running the world's most popular commercial applications and open-source models. We'll continue to work to earn the trust and support of mainstream developers everywhere.\" Yet some experts have cautioned that claims made by Chinese chipmakers should be taken with a pinch of salt due to a lack of publicly available data and consistent testing benchmarks. China's semiconductors perform similarly to the US in predictive AI but fall short in complex analytics, said computer scientist Jawad Haj-Yahya, who has tested both American and Chinese chips. \"The gap is clear and it is surely shrinking. But I don't think it's something they will catch up on in the short-term.\"\n\nWhere China leads - and lags\n\nOn the BG2 technology and business podcast in September, Nvidia's Jensen Huang highlighted the strengths of China's tech sector, crediting its hardworking and vast talent pool, intense domestic competition and progress in chipmaking. \"This is a vibrant entrepreneurial, high-tech, modern industry,\" he said, urging the US to compete \"for its survival\". His assessment is likely to be welcomed by officials in Beijing. The country has long vied to become a global leader in tech, partly to reduce its reliance on the West. For years, China has invested heavily in what President Xi Jinping calls \"high-quality development\", which covers industries from renewables to AI. Even before US President Donald Trump's return to the White House, China had spent tens of billions of dollars as part of its efforts to transform its vast economy from the \"world's factory\" for basic products to a home of cutting-edge industries. An ongoing tariffs war with Trump's America has only made that mission more urgent. Xi has vowed to make his country more self-reliant and not depend on \"anyone's gifts\".\n\nMr Huang has also warned that the US should trade freely with China or risk handing it the edge in the AI race. This comes against a backdrop of Beijing applying more pressure on Nvidia as it launched an anti-monopoly probe into the firm last month. But China's state-led approach can also be an obstacle to innovation if everyone in the sector only focuses on a \"shared goal\", said computing professor Chia-Lin Yang from the National Taiwan University. It can make it harder for disruptive ideas to break the mould, she added. China's chip industry has also yet to overcome criticism that its products can be less user-friendly than those of Western rivals like Nvidia. Prof Yang believes these issues can soon be solved by China's huge number of skilled tech industry workers. \"You cannot underestimate China's ability to catch up.\"\n\nGetty Images Chinese tech giant Huawei unveiled its plans to rival Nvidia's dominance in AI chips\n\n'Bargaining chip' for China",
      "source": "BBC News",
      "url": "https://www.bbc.com/news/articles/cgmz2vm3yv8o?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Bheadline%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Nintendo Switch 2 supports two different types of Nvidia DLSS — A second, 'light' version for upscaling beyond 1080p, along with the standard, PC-like CNN model",
      "content": "The Nintendo Switch 2 is the only mainstream console that comes with Nvidia hardware inside, while Microsoft and Sony rely on AMD. Therefore, the Switch 2 supports Nvidia's proprietary DLSS technology that helps it upscale games to 1080p and beyond, which is crucial in a handheld with power constraints. It was long speculated that the version of DLSS present on the Switch 2 was unique and unlike the standard models available on PC, and Digital Foundry's latest testing has confirmed that.\n\nNintendo Switch 2 DLSS Image Quality Analysis: \"Tiny\" DLSS/Full-Fat DLSS Confirmed - YouTube Watch On\n\nWhile looking at a diverse selection of titles like Cyberpunk 2077, Street Fighter 6, Hogwarts Legacy, Star Wars Outlaws, The Touryst, and Fast Fusion; Digital Foundry observed that there are two different DLSS versions at work.\n\nFirst up, there's \"Fat DLSS\" that resembles the CNN-based model found on PC, and this can only upscale games to 1080p. It has a cleaner, sharper image in motion, less artifacting, better antialiasing, and smoother camera cuts. Objects move in and out of motion almost identically to how they would on PC — which is to say, gracefully.\n\nBut, as mentioned, it's limited to 1080p. To go past that resolution, Nvidia and Nintendo have developed a special \"DLSS Light\" which can upscale to greater resolutions (remember, Switch 2 is marketed for up to 4K when docked). This version looks better in stills, but looses sharpness as soon as you move because reconstruction techniques get temporarily disabled. It introduces artifacts where you can see unfiltered pixels, but at the benefit of half the frame-time cost, which allows it to scale way past just 1080p.\n\n(Image credit: Jeffrey Kampman/Tom's Hardware)\n\nThis goes to show just how demanding the original version of DLSS is; it doesn't make sense to run that on every game, especially in handheld mode. When you need to reach resolutions higher than 1080p, the light model should still be better, despite its inferior temporal performance. What remains to be seen, though, is whether the newer, more efficient Transformer-based model of DLSS can somehow make its way onto the Switch 2 in the future.\n\nDigital Foundry even reached out to an unnamed but respected developer familiar with DLSS on the Switch, who confirmed that two versions of the tech do indeed exist in the pipeline to choose from. The light version is newer, and more uniquely suited to the Switch 2's hardware capabilities. We haven't seen any first-party Nintendo game utilize DLSS so far either, so that's also something to keep an eye on, given how most Nintendo games focus on precise movement and controls.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/video-games/nintendo/nintendo-switch-2-supports-two-different-types-of-nvidia-dlss-a-second-light-version-for-upscaling-beyond-1080p-along-with-the-standard-pc-like-cnn-model",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Weekly Market Wrap: Intel, Nvidia and Electronic Arts made major news",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/markets/weekly-market-wrap-intel-nvidia-and-electronic-arts-made-the-most-news",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Best VPNs for multiple devices in 2025",
      "content": null,
      "source": "Android Police",
      "url": "https://www.androidpolice.com/best-vpn-for-multiple-devices/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Samsung will collaborate with OpenAI to develop floating data centers and power plants as Sam Altman rushes to compete with his firm's own partners",
      "content": "OpenAI and Samsung sign letter of intent for sweeping AI partnership\n\nAgreement includes memory supply, data centers, and floating power infrastructure\n\nOpenAI seeks independence from hyperscalers as rivals expand global infrastructure\n\nOpenAI and Samsung and have signed a letter of intent for a sweeping partnership that spans semiconductors, data centers, shipbuilding, cloud services, and maritime technologies.\n\nThe announcement was made at a ceremony in Seoul attended by senior leaders from across Samsung’s electronics, shipbuilding, construction, and IT services businesses.\n\nThe agreement states that Samsung Electronics will act as a strategic memory partner for OpenAI’s Project Stargate initiative, which aims to build out masses of new AI infrastructure.\n\nFloating data centers\n\nOpenAI has projected its memory demand could reach 900,000 DRAM wafers per month, and Samsung will supply high-performance, energy-efficient memory solutions to meet the requirement.\n\nSamsung SDS will work with OpenAI to design, develop, and operate AI data centers and provide enterprise AI services.\n\nIt will also act as a reseller of OpenAI’s ChatGPT Enterprise in Korea, supporting adoption by local businesses.\n\nSamsung Heavy Industries and Samsung C&T will collaborate with OpenAI on floating data centers, with possible expansion into floating power plants and control centers.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n“Floating data centers… can address land scarcity, lower cooling costs and reduce carbon emissions,” the companies said in their letter of intent.\n\nAs The Stack notes, floating data centers remain rare, but interest is growing. The Stockton project in California has been running since 2021, Japanese firms and Yokohama city are planning a solar- and battery-powered design, and in June 2025, the American Bureau of Shipping and Herbert Engineering proposed a nuclear-powered floating data center concept.\n\nThe announcement comes a matter of days after we revealed Nvidia had poured $100 billion into OpenAI (to spend on Nvidia’s own chips, naturally), and suggests the ChatGPT creator is looking to reduce its dependence on hyperscaler partners such as Microsoft.\n\nWith AI rivals like Meta and Google rapidly expanding their own infrastructure, there is growing pressure on OpenAI to establish itself as a large-scale operator in its own right.\n\nFollow TechRadar on Google News and add us as a preferred source to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!\n\nAnd of course you can also follow TechRadar on TikTok for news, reviews, unboxings in video form, and get regular updates from us on WhatsApp too.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/samsung-will-collaborate-with-openai-to-develop-floating-data-centers-and-power-plants-as-sam-altman-rushes-to-compete-with-his-firms-own-partners",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Skytech Eclipse Lite 2 Desktop: Ryzen 7 9800X3D, RTX 5080, 32GB RAM, 2TB SSD $2130.99",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18664246-skytech-eclipse-lite-2-desktop-ryzen-7-9800x3d-rtx-5080-32gb-ram-2tb-ssd-2130-99",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "How to watch Ipswich Town vs Norwich City: Free streams, TV channels and preview for East Anglian Derby",
      "content": "Kick off: 12 pm BST/ 7am ET, Sunday, October 5.\n\nWatch Ipswich vs Norwich for free on ITVX (UK restricted)\n\nOutside the UK? Use NordVPN to unblock your ITVX account\n\nOne of the Championship's most iconic derbies takes place this Sunday for the first time in over 500 days, and after a summer of treachery there's a reignited fire between these two clubs that is certain to make for a feisty fixture.\n\nSo far, life back in the Championship for Kieran McKenna's Ipswich has been turbulent to say the least. After a summer of chops and changes, the identity of McKenna's Ipswich is a little bit off the mark. The Tractor Boys sit 13th in the Championship with a game in hand after a bizarre abandonment of their fixture away at Blackburn Rovers.\n\nAcross the A140, in a season where fans were promised better quality football and a push for play-offs, Norwich seem to be falling short of expectations. The Canaries sit 19th in the Championship at the time of writing and have won just one game in their last seven league outings.\n\nIn a game which both fanbases look for instantaneously when the fixtures are released, neither Ipswich nor Norwich fans will be going into this one with full confidence and will be hoping that a win against their rivals can jumpstart their 2025/26 season.\n\nSo how can you watch the East Anglian derby on ITVX from anywhere in the world? Is ITVX available as a mobile app?\n\nHere's our guide on how to watch Ipswich vs Norwich for free.\n\nHow to watch Ipswich vs Norwich for free on ITVX\n\nITV's online streaming service, ITVX, will be broadcasting the East Anglian derby on Sunday, 5th October, for free.\n\nThe great thing about ITVX's coverage is that you don't even need an ITVX subscription to watch Ipswich vs Norwich, you just need a valid TV license and an email account and you're good to go.\n\nFirst time using ITVX? You can register for a free account or download the app on your mobile device.\n\nOutside the UK for the derby? You can use NordVPN to reliably unlock your ITVX stream of Ipswich vs Norwich from anywhere in the world.\n\nHow to watch the Ipswich vs Norwich on ITVX from anywhere\n\nITVX will only be broadcasting the East Anglian derby to residents of the UK.\n\nSoccer fans traveling or working outside the UK will need to use a VPN to access ITVX's free coverage of the East Anglian derby this Sunday.\n\nThere are lots of VPNs but NordVPN is the one you can rely on to unblock ITVX stream and watch Ipswich vs Norwich from anywhere in the world.\n\nIt's really simple to use a VPN to unblock your stream of this weekend's derby.\n\n1. Install the VPN of your choice. As we've said, NordVPN is our favorite.\n\n2. Choose the location you wish to connect to in the VPN app. For instance, if you're visiting the US and want to watch your free ITVX stream, you'd select 'UK'.\n\n3. Sit back and enjoy the action. Head to ITVX, sign in, and watch all the drama and chaos unfold in the derby this Sunday.\n\nWhat does ITVX's East Anglian derby coverage include?\n\n(Image credit: Getty Images- NurPhoto)\n\nITVX's coverage of Ipswich vs Norwich takes place on Sunday, October 5, and will include pre-match analysis, a full live stream and post match analysis.\n\nThe UK network's broadcast will be presented by Hugh Woozencroft with commentary provided by Seb Hutchinson and Lucy Ward. The punditry team will include Matt Holland and Dean Aston, providing expert insight and analysis. On the floor reporting will be provided by Aaron Paul, offering fans some player and manager reactions.\n\nFans can expect a tense atmosphere this Sunday at Portman Road as the two rivals battle it out for bragging rights. ITVX will be broadcasting all the drama and providing action replays, highlights and a full aftershow. As well as this, ITV will also be uploading highlights to their YouTube channel.\n\nWhat devices is ITVX available on?\n\nYou can use ITVX on all of the following devices and platforms:\n\nAmazon Fire (Tablets, Cube, Stick, TVs)\n\nAndroid TV (please note: some models aren’t supported)\n\nAndroid (Mobile & Tablet) - Android 7.0 and above\n\nApple TV (tvOS 14 or later)\n\nGoogle TV (Chromecast with Google TV and NVIDIA Shield)\n\nFreely\n\nFreesat (please note: some models aren’t supported)\n\nFreeview Play (TVs and set-top boxes) (please note: some models aren’t supported)\n\niOS (iPhone & iPad) - iOS 14 and above\n\nLG Smart TVs (2016-2024)\n\nNOW Smart Sticks and Boxes (minimum firmware v11.5.0)\n\nPlayStation (PS4 and PS5)\n\nRoku (Stick & Roku-OS powered TVs, minimum firmware v11.5.0)\n\nSamsung Smart TVs (2017 and above - 2016 models only offer on demand TV)\n\nSky Q, Sky Glass and Sky Stream puck\n\nVirgin Media (360, Stream, TiVo)\n\nYouView (BT, Humax, Sony, TalkTalk)\n\nXbox (One, Series X, Series S)\n\nIpswich vs Norwich Preview\n\nThe general consensus going into this Championship season was that Ipswich have one of, if not, the strongest team in the division, making their 13th place league position, a little underwhelming.\n\nHowever, Ipswich will be looking to kickstart their season after they've slowly been adjusting to their new-look squad. Now unbeaten in four league matches, Mckenna will be hoping that a win against rivals Norwich, will give his team the momentum they need to climb up the table.\n\nLiam Manning's latest defeat as Norwich boss came at the hands of West Bromwich Albion, where the visiting Baggies returned home with all three points thanks to a goal from striker, Josh Maja.\n\nHowever, Norwich will go into this fixture with some solace as they still hold a record of 16 years unbeaten in the East Anglian derby, a record that dates back to 2009. The Canaries will be hoping they can rely on key players such as Josh Sargent to protect that precious record this Sunday as they make the journey to Portman Road.\n\nStarting XI's:\n\nIpswich starting XI: Palmer, Furlong, O'Shea, Kipre, Davis, Matusiwa, Cajuste, Walle Egeli, Szmodics, Philogene, Hirst.\n\nIpswich bench: Walton, Young, Greaves, Taylor, Nunez, McAteer, Akpom, Clarke, Azon.\n\nNorwich starting XI: Kovacevic, Stacey, Darling, Cordoba, Fisher, McLean, Topic, Mattson, Schwartau, Crnac, Sargent.\n\nNorwich bench: Grimshaw, Medic, Mahovo, Schlupp, Wright, Gibbs, Marcondes, Jurasek, Makama.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/how-to-watch/football/ipswich-town-vs-norwich-city-efl-championship-2025-26free",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Gamers, don't wait for Windows 10's demise - it's time to upgrade to Windows 11 or even SteamOS",
      "content": "In case you somehow missed it, Microsoft is saying goodbye to Windows 10 on October 14, 2025, when support for security updates will come to an end. This means PC gamers who have been adamant about staying away from Windows 11 will be left with a few options.\n\nThe first is simply staying on Windows 10, and if doing so, I'd say it's compulsory to sign up for the Extended Security Updates (ESU) scheme to get another year of updates. (Do not try running an operating system without the latest security patches).\n\nAnother choice could be to finally upgrade to Windows 11 - assuming your PC meets the hardware requirements - or you could even switch to the bloatware-free Tiny11 spin on Microsoft's OS.\n\nOr you could leave the Microsoft ecosystem entirely and switch to Valve's SteamOS. If you've read any of my previous articles on this topic, you'll know that my favored recommendation is SteamOS, but there are pros and cons whichever choice you make.\n\nIn some respects, Valve's SteamOS (which is Linux-based) is a better bet for gamers than Microsoft's desktop OS - it clearly is for handhelds - boasting a streamlined game mode that essentially replicates a gaming console's user interface for couch play, and is designed to allow players to jump into games without much hassle. It's not all perfect in SteamOS, though, as there are compatibility wrinkles - notably several popular multiplayer games (like Call of Duty) use anti-cheat and won't run on the operating system. On top of that, using certain game mods can sometimes be a bit of a pain.\n\nWindows 11 is still a great operating system for gaming, and you won't run into any stumbling blocks in terms of incompatibility here. It's also generally easy to get to grips with and simple enough in terms of the nuts and bolts of files and folders (file systems can be more cumbersome in Linux, certainly for computing novices). Microsoft is also delivering a similar simple game mode experience to SteamOS, with the upcoming 'full-screen experience' launching on the Asus ROG Xbox Ally.\n\nWhere Windows 11 falls down is with some of the frustrating bugs that can occur with the monthly updates (which are forced onto your PC - at least with Windows 11 Home, where you can only briefly delay their installation). This was particularly evident with Windows 11 24H2 breaking games, alongside oft-voiced criticisms online around bloatware and background processes messing with gaming performance.\n\nGet daily insight, inspiration and deals in your inbox Sign up for breaking news, reviews, opinion, top tech deals, and more. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nIf you'd rather avoid Windows 11, and SteamOS isn't your bag either, so your preferred route is to stick with Windows 10 under the ESU scheme, there's one big drawback worth noting on the PC gaming front. Capcom recently announced that it will be dropping support for Monster Hunter games on Windows 10 - and other game publishers will surely follow in its footsteps.\n\nCapcom move spells bad news for other games on Windows 10\n\n(Image credit: Capcom)\n\nI've touched on this already, but Capcom's announcement is not to be taken lightly. Windows 10 gamers are at risk of facing hiccups - or perhaps major spanners in the works - in Monster Hunter games in the future due to support being cast aside.\n\nThis will surely affect new releases from Capcom, too. While I'm sure the highly anticipated Resident Evil Requiem will work fine on Windows 10, I won't be surprised if players start to face issues either at launch or later down the line. When future game updates aren't checked with Windows 10, problems may inevitably creep in - and the developer won't address them.\n\nYou may have ongoing security updates for Windows 10 with the ESU scheme, but if your games aren't being supported, that could become a big problem - and you can bet it won't just be Capcom doing this.\n\n(Image credit: Rockstar Games)\n\nIt's likely a long way down the road, but there's now no guarantee that Rockstar's GTA 6 will run well on Windows 10 - or even support it. I know, that sounds like a stretch, and it would be a surprise if it didn't support Windows 10 considering how accessible GTA 5 was. However, we're looking at possibly 2027 or 2028 for GTA 6's eventual launch on PC - the grand picture for Windows could look quite different then.\n\nIn my opinion, publishers dropping support for Windows 10 could affect so many other upcoming (or unannounced) games, that it might be best to save yourself the headache with all this and pick your upgrade path now.\n\nIf I were forced to choose, I'd pick SteamOS, but I have to recommend Windows 11 for those who can install it\n\n(Image credit: Future / John Loeffler)\n\nIn my eyes, SteamOS is the better operating system compared to Windows when it comes to ease of use for gaming, but Valve's OS isn't quite there just yet for most desktop PC users.\n\nFor handheld gaming PCs, SteamOS is an absolute no-brainer, and I'd recommend choosing it over Windows 11 every time, since it's no secret that Microsoft's OS isn't very handheld-friendly. Microsoft is introducing the full-screen experience game mode, though, which tames background processes and bloatware, and ultimately frees up more resources for games to use in Windows 11 – but I'm still not convinced it'll dethrone SteamOS for me.\n\nHowever, it's a rather different picture on desktop PCs, and that's where I would recommend Windows 11 (for now). Since there's no official support from Valve to install SteamOS on desktop PCs, you'd have to rely on its clone, Bazzite, which has much better support.\n\nEven then, unless you're using AMD hardware, you'll likely run into issues with Bazzite's Game Mode, specifically with Nvidia GPUs. Unless you plan on using the SteamOS desktop mode (which defeats the purpose of SteamOS), you'll run into issues with apps like Discord - this is one of the reasons why I haven't yet switched to Bazzite on my desktop PC - and you may also run into games with compatibility issues.\n\nFor some of you, these issues might not be deal-breakers, and if that's the case, then obviously you should go ahead and try Bazzite. Otherwise, it could be wise to upgrade to Windows 11 - the good thing about its latest update, version 25H2, is that it's not likely to be as problematic with bugs as 24H2 (given that 25H2 is only a very minor upgrade).\n\nFollow TechRadar on Google News and add us as a preferred source to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!\n\nAnd of course you can also follow TechRadar on TikTok for news, reviews, unboxings in video form, and get regular updates from us on WhatsApp too.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/computing/windows/gamers-dont-wait-for-windows-10s-demise-its-time-to-upgrade-to-windows-11-or-even-steamos",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "3 Ways AI Is Quietly Transforming Retirement Planning — and What It Means for Your Money",
      "content": "When you pictured the ways artificial intelligence would change the future, you might have imagined AI powering flying cars. Though we’re not quite there yet, AI has already transformed many areas of daily life — from how we access information to how we plan for retirement.\n\nFor You: Here’s Why You Might Want To Invest Your Retirement Savings in a Roth 401(k)\n\nLearn About: 3 Advanced Investing Moves Experts Use to Minimize Taxes and Help Boost Returns\n\nWorking on retirement planning with a professional financial advisor who is familiar with your situation and goals is always best. However, new AI-powered tools can supplement that guidance by helping you better define your objectives and gain insights into best practices.\n\nTo learn more about how AI is transforming retirement planning — and how it can impact your nest egg — GOBankingRates spoke with Vasant Dhar, professor of data science at the Leonard N. Stern School of Business at New York University and host of the “Brave New World” podcast. As a pioneer in AI, Dhar helped bring machine learning to Wall Street in the early 1990s. His book, “Thinking With Machines: The Brave New World of AI,” will be published this year.\n\nUnsurprisingly, Dhar had detailed insights into what people preparing for retirement today can expect from AI.\n\nAI Can Offer Personalization\n\nThough AI can’t match the human touch of sitting across from an advisor, Dhar says AI-powered financial planning tools like robo-advisors can offer a degree of personalization.\n\nUsing a robo-advisor, you’ll likely fill out an online questionnaire that touches on a few key areas:\n\nFinancial goals\n\nRisk tolerance\n\nTime horizon\n\nExternal financial data\n\nPersonal preferences\n\nOnce AI gathers this information, algorithms can generate suggestions for retirement plans or even manage a portfolio. Of course, these surveys can be superficial, and robo-advisors may offer limited suggestions without considering complex situations — or human emotions.\n\nStill, Dhar believes working with AI tools can help clarify your retirement goals and available resources.\n\n“Such tools can personalize retirement planning in several ways. They can help you clarify your objectives, which is one of the hardest problems in retirement planning,” he said.\n\nRead Next: I Help People Retire Every Day — Here’s the Most Common Retirement Mistake People Make\n\nRetirees Can Benefit From Faster Optimization and Risk Management\n\nFrom his work bringing AI to Wall Street, Dhar has seen how it has changed portfolio optimization, tax strategies and risk management in professional investing.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/3-ways-ai-quietly-transforming-162240565.html",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Circular Financing: Does Nvidia's $110B Bet Echo the Telecom Bubble?",
      "content": "When Nvidia announced a $100 billion investment commitment to OpenAI in September 2025 , analysts immediately drew comparisons to the telecom bubble. The concern : is this vendor financing , where a supplier lends money to customers so they can buy the supplier’s products , a harbinger of another spectacular collapse?\n\nAmerican tech companies will spend $300-400 billion on AI infrastructure in 2025, , exceeding any prior single-year corporate infrastructure investment in nominal dollars. David Cahn estimates the revenue gap has grown to $600 billion.\n\nI analyzed the numbers. The similarities are striking , but the differences matter.\n\nThe Lucent Playbook\n\nLucent’s revenue peaked at $37.92B in 1999 , crashed 69% to $11.80B by 2002 , never recovered. Merged with Alcatel in 2006.\n\nIn 1999 , Lucent Technologies reached $37.92 billion in revenue at the peak of the dot-com bubble. Lucent was the #1 North American telecommunications equipment manufacturer with 157,000 employees & dominated markets alongside Nortel Networks (combined 53% optical transport market share). Behind the scenes , equipment makers extended billions in vendor financing to telecom customers. Lucent committed $8.1B , Nortel extended $3.1B with $1.4B outstanding , & Cisco promised $2.4B in customer loans.\n\nThe strategy seemed brilliant : lend money to cash-strapped telecom companies so they could buy your equipment. Everyone wins—until the merry-go-round stops.\n\nWhen the bubble burst :\n\n47 Competitive Local Exchange Carriers (CLECs) bankrupted 2000-2003 , including Covad , Focal Communications , McLeod , Northpoint , Winstar , Why they failed : $60B overbuild 1996-2001 , market saturation from identical business models , sudden funding collapse (Jan 2001 : billions available , Apr 2001 : zero)\n\n33-80% of vendor loan portfolios went uncollected as customers failed & equipment became worthless\n\nFiber networks were using less than 0.002% of available capacity , with potential for 60,000x speed increases. It was just too early.\n\nNvidia’s Playbook\n\nFast forward to 2025. Nvidia’s vendor financing strategy totals $110 billion in direct investments plus another $15+ billion in GPU-backed debt. The largest commitment is $100B to OpenAI (September 2025), , structured as 10 tranches of $10B each tied to infrastructure deployment milestones. The first $10B was valued at a $500B OpenAI valuation , with subsequent tranches priced at prevailing valuations. Payment comes via lease arrangements , not upfront GPU purchases. OpenAI CFO Sarah Friar confirmed : “Most of the money will go back to Nvidia”\n\nBeyond OpenAI , Nvidia holds a $3B stake in CoreWeave , a company that has spent $7.5B on Nvidia GPUs , & $3.7B in other AI startup investments through NVentures.\n\nThe GPU-backed debt market adds another layer. CoreWeave alone carries $10.45B in debt using GPUs as collateral. An additional $10B+ in GPU-backed debt has emerged for “Neoclouds” including Lambda Labs ($500M GPU-backed loan),.\n\nLucent in 1999-2000 had vendor financing commitments of $8.1B (24% of $33.6B revenue). Nvidia’s direct investments total 67% of annual revenue ($110B against $165B LTM). Nvidia’s exposure is 2.8x larger relative to revenue than Lucent’s official outstanding loans , though Lucent’s off-balance-sheet guarantees masked the true exposure.\n\nThe Numbers Side-by-Side (2024 Dollars)\n\nMetric Lucent (FY2000, inflation-adj.) Nvidia (2025) Vendor financing $15B $110B Operating cash flow $304M $15.4B (Q2 FY26) Revenue $61B $165B (LTM) Top 2 Customers represent 23% 39%\n\nThe Reasons to be Wary\n\n1. The AI Customer Base is More Concentrated\n\nLucent’s top 2 customers—AT&T at 10% & Verizon at 13%—accounted for 23% of revenue in FY2000. The Regional Bell Operating Companies , or RBOCs , the seven “Baby Bells” created from AT&T’s 1984 breakup , were also major customers. Nvidia has 39% of revenue from just 2 customers & 46% from 4 customers , nearly double Lucent’s concentration. 88% of Nvidia’s revenue comes from data centers.\n\n2. GPU-Backed Debt Is New\n\nThe new $10B+ GPU-backed debt market is built on the assumption that GPUs will hold their value over 4-6 years. GPU-backed loans carry ~14% interest rates , triple investment-grade corporate debt.\n\nHow Depreciation Schedules Changed :\n\nCompany Pre-2020 2020-2021 2022-2023 2024-2025 Change Amazon 3 years 4 years (2020) → 5 years (2021) 5 years 6 years (2024) → 5 years (2025) First reversal Microsoft ~3 years 4 years 6 years 6 years +100% Google ~3 years 4 years 6 years 6 years +100% Meta ~3 years 4 years 4.5 years → 5 years 5.5 years +83% CoreWeave N/A N/A 4 years → 6 years (Jan 2023) 6 years +50% (GPUs) Nebius N/A N/A 4 years 4 years Industry standard\n\nAmazon’s 2025 reversal (6 → 5 years) is the first major pullback.\n\nCPUs historically have 5-10 years of useful life , while GPUs in AI datacenters last 1-3 years in practice , despite 6-year accounting assumptions., Evidence from Google architects shows GPUs at 60-70% utilization survive 1-2 years , with 3 years maximum. Meta’s Llama 3 training experienced 9% annual GPU failure rates , suggesting 27% failure over 3 years.\n\nCerno Capital raises the question : “Are these policies a reflection of genuine economic & technological realities? Or are these policies a lever by which hyperscalers are enhancing the optics of their investment programs amid rising investor concerns?”\n\n4. The Use of SPVs\n\nTech companies use Special Purpose Vehicles (SPVs) to finance AI datacenter construction. A hyperscaler like Meta partners with a private equity firm like Apollo , contributing capital to a separate legal entity that builds & owns the datacenter.\n\nAs investor Paul Kedrosky explains : “I have a stake in it as Meta. Some giant private debt provider has a stake in it. The datacenter is under my control. But I don’t own it, so you don’t get to roll it back into my balance sheet.”*\n\nThe Structure\n\nEntity Creation : Hyperscaler & PE firm form separate legal entity (SPV) Capital Structure : Typically 10-30% equity, 70-90% debt from private credit markets Lease Agreement : SPV leases capacity back to hyperscaler Balance Sheet Treatment : SPV debt doesn’t appear on hyperscaler’s balance sheet\n\nThe hyperscaler maintains operational control through long-term lease agreements. Because it doesn’t directly own the SPV , the debt remains off its balance sheet under current accounting standards.\n\nThe appeal is straightforward. “I don’t want the credit rating agencies to look at what I’m spending. I don’t want investors to roll it up into my income statement.”*\n\nMarket Scale\n\nAmerican tech companies are projected to spend $300-400 billion on AI infrastructure in 2025. Hyperscaler capital expenditures have reached approximately 50% of operating income, levels historically associated with government infrastructure buildouts rather than technology companies.\n\nWhere the Risk Sits\n\nDatacenter assets now represent 10-22% of major REIT portfolios , up from near zero two years ago. The thin equity layer (10-30%) means if datacenter utilization falls short of projections or if GPUs depreciate faster than projected , equity holders face losses before debt holders experience impairment.\n\n*Quotes lightly edited for clarity & brevity\n\n5. Custom Silicon Threat\n\nHyperscalers are building their own AI accelerators to reduce Nvidia dependence. Microsoft aims to use “mainly Microsoft silicon” , specifically Maia accelerators , in datacenters. Google deploys TPUs , Amazon builds Trainium & Inferentia chips , & Meta develops MTIA processors. If customers shift to in-house silicon , CoreWeave’s GPU collateral value & Nvidia’s vendor financing become exposure to customers building competitive alternatives.\n\nNvidia Isn’t Lucent & 2025 Isn’t 2000\n\nAccounting : Lucent manipulated $1.148B in revenue , SEC charged 10 executives with fraud ; Nvidia shows no evidence of manipulation , audited by PwC , Aa3 rated\n\n: Lucent manipulated $1.148B in revenue , SEC charged 10 executives with fraud ; Nvidia shows no evidence of manipulation , audited by PwC , Aa3 rated Cash flow : Lucent lent $8.1B while cash flow lagged profitability & receivables exploded $5.4B (1998-1999) ; Nvidia lends with $50B+ annual operating cash flow & $46.2B net cash\n\n: Lucent lent $8.1B while cash flow lagged profitability & receivables exploded $5.4B (1998-1999) ; Nvidia lends with $50B+ annual operating cash flow & $46.2B net cash Credit rating : Lucent downgraded to A3 (December 2000) ; Nvidia upgraded to Aa3 (March 2024)\n\n: Lucent downgraded to A3 (December 2000) ; Nvidia upgraded to Aa3 (March 2024) Customer base : Lucent’s customers were leveraged CLECs burning capital ; Nvidia’s top 4 customers generated $451B in operating cash flow in 2024 (Microsoft $119B , Alphabet $125B , Amazon $116B , Meta $91.3B)\n\n: Lucent’s customers were leveraged CLECs burning capital ; Nvidia’s top 4 customers generated $451B in operating cash flow in 2024 (Microsoft $119B , Alphabet $125B , Amazon $116B , Meta $91.3B) Capacity : Fiber networks used <0.002% of capacity in 2000 ; Microsoft & AWS report AI capacity constraints in 2025,\n\nWhat I’m Watching\n\nIs AI demand real (like cloud computing) or speculative (like dot-com fiber)?\n\nHere’s what I’m watching :\n\nGPU utilization rates : Are data centers actually using the chips or just stockpiling? OpenAI’s monetization : Can they generate enough revenue to justify the buildout? Debt defaults : Any cracks in the $15B GPU-backed debt market? AR trends : AR improved from 68% (FY24) to 30% (Q2 FY26) , but still watch for deterioration Customer adds : Are new customers emerging , or is Nvidia dependent on the same 2-4 hyperscalers? Custom silicon threat : Microsoft developing Maia accelerators , aiming to use “mainly Microsoft silicon in the data center.” If hyperscalers shift to in-house chips , Nvidia’s vendor financing becomes exposure to customers building competitive alternatives. Vendor consolidation : Many companies are in a period of experimentation trying 2-3 competing vendors. Those experimental budgets may thin with time , reducing overall spend.\n\nAI is already broadly deployed—40% of US employees used AI at work by September 2025 , double the 20% rate in 2023. Questions persist about effectiveness : the oft cited MIT study found 95% of AI pilots failed to deliver measurable P&L impact , primarily due to poor integration rather than technical failures.\n\nYet the pace of improvement is tremendous. Labor market data shows wages rising twice as fast in AI-exposed industries , & workers using AI boost performance up to 40%. Many of Nvidia’s customers are profitable & sophisticated hyperscalers—Microsoft , Google , Amazon , Meta—generating $451B in operating cash flow in 2024 , with tremendous pull from their own enterprise customers demanding AI. OpenAI is not profitable , reporting a $4.7B loss in H1 2025 on $4.3B revenue , though nearly half the loss is stock-based compensation.\n\nUnlike the telecom bubble , where demand was speculative & customers burned cash , this merry-go-round has paying riders.\n\nCoda : Lucent’s Accounting Fraud\n\nBehind the vendor financing disaster was systematic accounting fraud. The SEC charged Lucent with manipulating $1.148 billion in revenue & $470 million in pre-tax income during fiscal year 2000. The fraud involved multiple schemes :\n\nChannel Stuffing : Lucent sent $452 million in equipment to distributors but counted it as revenue before the distributors sold to end customers. This created phantom sales.\n\nSide Agreements : Lucent executives entered secret agreements with distributors granting them return rights & privileges beyond their distribution contracts , making it improper to recognize revenue. These side deals were hidden from auditors.\n\nReserve Manipulation : Lucent improperly established & maintained excess reserves to smooth earnings , violating GAAP.\n\nThe SEC charged 10 Lucent executives with securities fraud. The company paid a $25 million fine—the largest ever for failing to cooperate with an SEC investigation. The accounting manipulation masked deteriorating fundamentals until too late.\n\nThe WinStar Collapse : Lucent committed $2 billion in vendor financing to WinStar Communications , a CLEC. When WinStar struggled , Lucent refused a final $90 million loan extension. WinStar filed bankruptcy. Lucent wrote off $700 million in bad debts. This pattern repeated across customer defaults : Lucent made provisions for bad debts of $2.2 billion (2001) & $1.3 billion (2002)—a total of $3.5 billion in customer loan losses.\n\nReferences",
      "source": "Tomtunguz.com",
      "url": "https://tomtunguz.com/nvidia_nortel_vendor_financing_comparison/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Trump administration's $100,000 H-1B visa fee challenged in new lawsuit",
      "content": "President Donald Trump signed a proclamation in September that would implement a $100,000 fee for each H-1B visa application.\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nA coalition of unions, nonprofits, religious organizations, and a healthcare staffing firm, among others, is suing the Trump administration over its $100,000 H-1B visa fee, marking what appears to be the first major legal challenge against the proclamation to land in federal court.\n\nIn a lawsuit filed on Friday in the US District Court in Northern California, plaintiffs said President Donald Trump doesn't have the authority to \"unilaterally impose fees,\" calling it \"extortionate,\" \"draconian,\" and an impediment to innovation.\n\n\"Most fundamentally, the President has no authority to unilaterally impose fees, taxes or other mechanisms to generate revenue for the United States, nor to dictate how those funds are spent,\" the lawsuit said. \"The Constitution assigns the 'power of the purse' to Congress, as one of its most fundamental premises.\"\n\nThe lawsuit further argued that Trump framed the fee as a tax, considering what he said he'd do with the funds raised from the $100,000 requirement.\n\nOn September 19, Trump told reporters, \"We're going to take that money and we're going to reduce taxes, we're going to reduce debt.\"\n\nThe suit, led by a California-based healthcare recruiting firm called Global Nurse Force, is asking a federal court to declare Trump's proclamation unlawful and to prevent the government from enforcing the fee.\n\nThe H-1B visa program has long served as a pipeline for skilled foreign workers to enter the United States legally. Over the years, the tech and research fields have become among the top industries that utilize H-1B visa workers.\n\nHowever, the program has also been critical for manufacturing, health care, and education, among other industries. The lawsuit said that while many H-1B workers are in tech, \"more than a third of all H-1B workers are in other fields.\" Notably, the coalition of plaintiffs does not appear to include any tech-related organizations or representatives.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nIn implementing a $100,000 fee, Trump said the move seeks to discourage employers and companies from exploiting the program to replace American workers.\n\nWhite House spokesperson Abigail Jackson told Business Insider in an email that the administration's actions \"are lawful\" and that the new requirement will stop companies from \"spamming the system and driving down American wages, while providing certainty to employers who need to bring the best talent from overseas.\"\n\nThe introduction of the fee nearly two weeks ago initially sowed chaos and confusion in Silicon Valley, as employers rushed to warn any of their H-1B workers who were overseas at the time to return to the US immediately.\n\nAs more details trickled in, some major tech CEOs, including Nvidia CEO Jensen Huang, appeared to warm to the idea.\n\n\"Immigration is really important to our company and is really important to our nation's future, and I'm glad to see President Trump making the moves he's making,\" Huang said in an interview with CNBC.\n\nAttorneys for the plaintiffs did not immediately respond to a request for comment.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/h1b-visa-lawsuit-trump-administration-sued-2025-10",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Skytech Eclipse Lite 2 Desktop: Ryzen 7 9800X3D, RTX 5080, 32GB RAM, 2TB SSD $2181 + Free Shipping",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18661510-skytech-eclipse-lite-2-ryzen-7-9800x3d-rtx-5080-32gb-ddr5-2tb-ssd-2180-99",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "This is the world's smallest eGPU dock with a built-in 650W PSU - but I'm not sure I'd be comfortable with my $1,999 Geforce RTX 5090 GPU exposed to the elements",
      "content": "NXPort eGPU integrates 650W power in a small dock\n\nThunderbolt and USB4 connections may bottleneck even the most powerful GPUs\n\nOpen-frame design leaves components vulnerable to damage\n\nThe pursuit of transforming business laptops into desktop-grade powerhouses has long relied on external GPU enclosures.\n\nTraditional solutions have often been bulky, cumbersome, and required separate power supplies or complex assembly.\n\nNXPort claims to be the “world’s smallest eGPU dock,” promising 650W of integrated power in a palm-sized form factor measuring 169mm x 102mm x 82mm.\n\nCompact form, big questions\n\nThe central claim of NXPort is that it houses a built-in power supply within a tiny, open-frame chassis.\n\nOn paper, this allows compatibility with nearly all consumer-grade GPUs and simplifies connectivity by supporting Thunderbolt 3/4/5 or USB4.\n\nHowever, a compact, exposed design introduces concerns about heat management and physical protection.\n\nExpensive components, including GPUs like the $1,999 GeForce RTX 5090, would sit exposed to dust, accidental contact, and variable cooling conditions.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe device meets the ATX 3.1 spec for stable power delivery, but real-world performance under sustained load is unverified, leaving potential users cautious about long-term reliability.\n\nThe company presents NXPort as a plug-and-play solution that can greatly improve GPU performance.\n\nIn the company’s tests, pairing a budget laptop with an Nvidia RTX 4060 reportedly produced a “6X Gaming Benchmark” improvement.\n\nThe dock is also described as suitable for intensive creative workloads and AI model training, capable of handling tasks requiring “thousands of parallel operations.”\n\nYet, it is important to note that performance may be limited by the bandwidth of Thunderbolt or USB4 connections.\n\nThis could restrict the throughput of high-end graphics cards despite the dock’s internal power.\n\nThe dock also supports GPUs with various power connectors, including 12V-2x6, 8-pin, dual 8-pin, triple 8-pin, and quad 8-pin (12VHPWR).\n\nThis provides flexibility for future upgrades without enclosure limitations.\n\nAlthough NXPort claims to be the “world’s smallest eGPU dock,” its 1.3kg weight is well above that of the GDP G1, a former smallest, which weighs only 867g.\n\nThe company states that the device is budget-friendly, as an NXPort paired with an RTX 3050 costs $459 ($239 for the base dock + $220 for the GPU).\n\nCompared with $1,599 for a laptop featuring a similar RTX 4050 GPU, this offers a cost-efficient way to achieve desktop-level graphics without replacing the existing laptop.\n\nThe NXPort project is currently listed on Kickstarter, where it has raised $57,618 from 211 backers, surpassing its $3,856 goal.\n\nWith 21 days remaining in the campaign, the funding trajectory suggests strong early interest, although the final product has yet to reach backers for independent evaluation.\n\nDisclaimer: We do not recommend or endorse any crowdfunding project. All crowdfunding campaigns carry inherent risks, including the possibility of delays, changes, or non-delivery of products. Potential backers should carefully evaluate the details and proceed at their own discretion.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/this-is-the-worlds-smallest-egpu-dock-with-a-built-in-650w-psu-i-am-not-sure-that-id-be-comfortable-with-my-usd1-999-geforce-rtx-5090-gpu-exposed-to-the-elements",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "nvidia-nat-ragaai 1.3.0a20250930",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-ragaai/1.3.0a20250930/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "UiPath announces collaboration with Nvidia",
      "content": "We use cookies to improve user experience, and analyze website traffic.\n\nFor these reasons, we may share your site usage data with our analytics partners. By clicking \"Accept Cookies\" you consent to store on your device all the technologies described in our Cookie Policy.",
      "source": "Thefly.com",
      "url": "https://thefly.com/permalinks/entry.php/id4205203/PATH;NVDA-UiPath-announces-collaboration-with-Nvidia",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Nvidia (NVDA) Stock Trades Up, Here Is Why",
      "content": "What Happened?\n\nShares of leading designer of graphics chips Nvidia (NASDAQ:NVDA) jumped 2.3% in the afternoon session after several Wall Street firms raised their price targets on the stock and reports surfaced of a major deal involving its advanced AI systems.\n\nThe positive sentiment was fueled by a reported deal where cloud provider CoreWeave agreed to supply Meta Platforms with up to $14.2 billion in AI computing power using Nvidia's latest GB300 systems. This agreement highlighted the immense and sustained demand for AI infrastructure from major tech companies. Further boosting investor confidence, several financial firms, including KeyBanc, Barclays, and Citi, increased their price targets for Nvidia. Analysts pointed to an improving supply of key components and strong, continued spending in the AI sector as the primary reasons for their optimistic outlook, which helped push the stock to a record high.\n\nAfter the initial pop the shares cooled down to $186.21, up 2.4% from previous close.\n\nIs now the time to buy Nvidia? Access our full analysis report here, it’s free.\n\nWhat Is The Market Telling Us\n\nNvidia’s shares are quite volatile and have had 18 moves greater than 5% over the last year. In that context, today’s move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.\n\nThe previous big move we wrote about was 8 days ago when the stock gained 4.1% on the news that the company announced a partnership with OpenAI that included plans for a potential investment of up to $100 billion.\n\nThe deal aimed to supply OpenAI with advanced AI hardware for its next generation of AI models and the buildout of massive data centers. According to the announcement, the partnership involved deploying at least 10 gigawatts of Nvidia's systems for OpenAI's AI infrastructure. This news solidified Nvidia's central role in the future of artificial intelligence.\n\nNvidia is up 34.6% since the beginning of the year, and at $186.21 per share, has set a new 52-week high. Investors who bought $1,000 worth of Nvidia’s shares 5 years ago would now be looking at an investment worth $13,762.\n\nUnless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-nvda-stock-trades-why-185050056.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "NVIDIA Corporation (NVDA) and OpenAI Forge $100B Partnership to Power Next-Gen AI Systems",
      "content": "We recently compiled a list of the 12 Best Stocks to Own for Grandchildren. NVIDIA Corporation is one of them.\n\nNVIDIA Corporation (NASDAQ:NVDA) tops our list for being one of the best stocks to buy . It continues to dominate the AI and data center markets with groundbreaking developments in September 2025. The company posted second-quarter fiscal 2026 revenue of $46.7 billion, a 56% year-over-year increase, driven by strong demand for its Blackwell Data Center products, which grew 17% sequentially. CEO Jensen Huang described the Blackwell AI platform as a “generational leap” in infrastructure, with production scaling quickly to meet demand from advanced reasoning AI models.\n\nA major highlight this month is NVDA’s strategic partnership with OpenAI, involving up to $100 billion in investment and a commitment to supply advanced data center chips for next-generation AI systems. This alliance strengthens the firm’s central role in the AI ecosystem and significantly expands its long-term market potential. In addition, the company announced a $5 billion investment in Intel stock, with plans to co-develop custom AI infrastructure for data centers and PCs, aiming at a $50 billion market opportunity.\n\nNVIDIA Corporation (NVDA) and OpenAI Forge $100B Partnership to Power Next-Gen AI Systems\n\nNVIDIA Corporation (NASDAQ:NVDA) also introduced Rubin CPX, a new GPU designed to handle massive-context inference tasks, enabling million-token coding and generative video at unprecedented speed and efficiency. This innovation supports its vision of transforming data centers into fully integrated “AI factories.”\n\nWhile we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy NOW\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-corporation-nvda-openai-forge-164802201.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "nvidia-nat-phoenix 1.3.0a20250930",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-phoenix/1.3.0a20250930/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Analyst Highlights the Nvidia Link in Micron (MU) Business, Says It’s ‘The Most Important Takeaway’",
      "content": "We recently published 10 Buzzing Tech and AI Stocks Everyone’s Talking About. Micron Technology Inc. (NASDAQ:MU) is one of the stocks analysts were recently talking about.\n\nMehdi Hosseini, senior equity research analyst at Susquehanna, said in a latest program on CNBC that Nvidia “has to buy” from Micron, and this places the memory company in a strong position in terms of pricing power.\n\n“I think the most important takeaway here, which I don’t think Sanjay (Micron CEO) is going to elaborate on a live interview, is who is actually doing a lot of buying. Unlike prior cycles, which were driven by distributors and the OEMs and ODMs, this cycle it is Nvidia, it is AMD, it is Broadcom that are actually doing the buying. And when you look at the AI, what Nvidia charges, which is about 80% of the AI server, the majority of that is going towards memory. So it is Nvidia that has to buy from Micron Technology Inc (NASDAQ:MU), and this is what gives Sanjay pricing power. The future of AI compute requires advanced memory, and that’s where the premium comes in, which is why this cycle is sustainable throughout 2016 and may even sustain into 2027.”\n\nPhoto by L N on Unsplash\n\nParnassus Investments, an investment management firm that focuses on owning a concentrated portfolio of U.S. large-cap stocks, released its Parnassus Value Equity Fund second-quarter 2025 investor letter. Here is what they have to say about Micron Technology Inc. (NASDAQ:MU) in their investor letter:\n\n“Micron Technology Inc. (NASDAQ:MU) shares advanced due to the company’s strong position in the AI-driven memory market. Management noted robust demand in its latest quarter.”\n\nWhile we acknowledge the potential of MU as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/analyst-highlights-nvidia-micron-mu-120746683.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "nvidia-nat-weave 1.3.0rc1",
      "content": "For more information about the NVIDIA NeMo Agent toolkit, please visit the NeMo Agent toolkit GitHub Repo .\n\nThis is a subpackage for Weights and Biases Weave integration for observability.\n\nDownload files\n\nDownload the file for your platform. If you're not sure which to choose, learn more about installing packages.\n\nSource Distributions\n\nNo source distribution files available for this release.See tutorial on generating distribution archives\n\nBuilt Distribution\n\nFilter files by name, interpreter, ABI, and platform.\n\nIf you're not sure about the file name format, learn more about wheel file names.\n\nThe dropdown lists show the available interpreters, ABIs, and platforms. Enable javascript to be able to filter the list of wheel files.\n\nCopy a direct link to the current filters Copy",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-weave/1.3.0rc1/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "NVIDIA Releases Battlefield 6 GeForce Game Ready Driver",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/nvidia-releases-battlefield-6-geforce-game-ready-driver/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Why Nvidia-Backed CoreWeave's Stock Is Soaring Today",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_c5b65ded-72b7-44dd-b549-03674f027e35",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Jim Cramer Shares Very Important Analysis About Oracle Corporation (ORCL)",
      "content": "We recently published 15 Stocks Jim Cramer Mentioned As He Said Quantum Computing Worried Him. Oracle Corporation (NYSE:ORCL) is one of the stocks Jim Cramer recently discussed.\n\nOracle Corporation (NYSE:ORCL) has been the talk of the town recently after it revealed a whopping $455 billion in cloud backlog as part of its fiscal first quarter earnings release. In this episde, Cramer critically evaluated the announcement:\n\nJim Cramer Shares Very Important Analysis About Oracle Corporation (ORCL)\n\n“[On shares being down at open] Well Oracle is the fundament of what happened. That was the, that was the straw because everybody else had been self funding. You know because cash flow, Mark Zuckerberg had a cash flow, Google had a cash flow. And suddenly Oracle comes in. Where are they going to get all the money? Well they’re going to get it from OpenAI, but where’s OpenAI going to get all the money? They’re going to get it from NVIDIA. . .\n\nWhile we acknowledge the potential of ORCL as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/jim-cramer-shares-very-important-174234413.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Ambitious Wee Beastie Project Aims To Put Desktop NVIDIA RTX 4070 GPU Into 4.75 L Chassis",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/ambitious-wee-beastie-project-aims-to-put-desktop-nvidia-rtx-4070-gpu-into-4-75-l-chassis/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "AMD Dense Geometry Format (DGF) Aims to Increase Visual Detail with Future GPUs",
      "content": "Visible Noise Nine months after Nvidia ships a feature, AMD produces a paper about their equivalent, and btw it doesn’t work with any of their existing products. Looks like 90XX is a dead end product.\n\nVisible Noise Why are people so surprised and angry at Nvidia’s success?\n\nVisible Noise They literally have no competition. Nvidia is still delivering features years ahead of AMD.\n\nHecate91 As usual Nvidia fans whine that AMD cards don't have a proprietary to Nvidia feature, then whine anyways when AMD develops something similar because they've never bought an AMD and never have any intention to do anything but mindlessly bash the brand.\n\nAnyway unless the feature does something groundbreaking then it's just another optional feature, I wouldn't expect this to make RDNA4 cards obsolete, and perhaps it could be processed at a driver level or on existing hardware.\n\nNvidia shipped Ray Tracing, it wasn't supported on GTX cards. They shipped MFG, it's not supported on cards prior to RTX50. You don't consider GeForce a dead end lineup, do you ?Because Nvidia is using their success to push their agenda of making the entire planet dependent on their dogshit AI tech that nobody neither wants nor needs.100% AI generated raster ? Miss me with that shit.The latest AMD has been on an Nvidia feature is Ray Reconstruction/Redstone and they barely have a full year of latency on this.Also, I'd like to point out that if you read the article a little bit closer, AMD's tech seems to be better since hitting broader, not just RT perf.And since if could run on raster, it would be hardware agnostic instead of vendor locked.I noticed that so far, when AMD follows, they might be later on delivery, but they follow with better.I'm curious about that \"potential performance hit\" mentioned on the article, how much of a hit are we talking about ? How much variance in outcome can we expect ? How is it behaving at different resolutions and different tiers of details complexity ? Is it hardware agnostic ? How would it run on other brands of cards ?I gotta say, I'm looking forward to this, even if if looks to be hardware dependent to get the intended performance, it kinda sounds like a new \"FSR moment\" to me when they make something that just works for everyone and improves X or Y factor.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341494/amd-dense-geometry-format-dgf-aims-to-increase-visual-detail-with-future-gpus",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Microsoft Corporation (MSFT): A Bull Case Theory",
      "content": "We came across a bullish thesis on Microsoft Corporation on The Edge of Power’s Substack. In this article, we will summarize the bulls’ thesis on MSFT. Microsoft Corporation's share was trading at $507.03 as of September 25th. MSFT’s trailing and forward P/E were 37.17 and 32.79 respectively according to Yahoo Finance.\n\ndennizn/Shutterstock.com\n\nMicrosoft’s AI strategy is transforming it into a critical global infrastructure player, with investments and partnerships positioning it far beyond a conventional software vendor. The adoption of Microsoft Copilot by the U.S. House of Representatives illustrates this shift, as AI moves from a productivity tool to essential infrastructure capable of supporting state-scale operations. Globally, Microsoft is deploying more than $56 billion in AI-focused projects, including sovereign cloud regions and supercomputing hubs in the U.K., Norway, and the U.S., with total CapEx for fiscal 2025 expected to approach $80 billion.\n\nThese initiatives combine renewable energy, GPU clusters, and strategic partnerships, creating a distributed, resilient infrastructure network that spans continents and aligns with sovereign priorities. In the Middle East, alliances with G42 in the UAE and sovereign cloud regions in Saudi Arabia extend Microsoft’s influence into fast-growing AI markets, effectively tying its growth to politically aligned, capital-rich projects and providing a strategic counterweight to Chinese technology influence. Despite this scale, the market has largely overlooked Microsoft’s moves, favoring smaller, unprofitable AI players.\n\nThe company’s embedded presence in government, sovereign partnerships, and global cloud infrastructure provides durable pricing power and revenue visibility, supporting a potential stock valuation of $600 by year-end. Beyond commercial returns, Microsoft’s investments represent soft power, shaping AI adoption, digital infrastructure, and geopolitical influence, while enabling NVIDIA and other tech partners to thrive.\n\nWith unmatched scale, innovation leadership, and embeddedness across governments and enterprises, Microsoft is building the global rails of the AI economy, offering long-term, resilient upside for investors and anchoring portfolios in a way smaller startups cannot replicate. Its global AI infrastructure positions the company as a quasi-state actor, securing both technological and strategic advantage for decades.\n\nPreviously we covered a bullish thesis on Microsoft Corporation (MSFT) by Ray Myers in May 2025, which highlighted the company’s strong enterprise software position, cloud growth via Azure, gaming expansion, and AI integration. The stock has appreciated approximately 11.9% since our coverage. The thesis still stands as Microsoft’s fundamentals remain robust. The Edge of Power shares a similar view but emphasizes Microsoft’s global AI infrastructure and geopolitical influence.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/microsoft-corporation-msft-bull-case-144323663.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "New York firm faces China investigation over $17M advanced trading hardware smuggling — accused of installing customized processors and networking hardware at Shanghai Futures Exchange",
      "content": "Tower Research Capital, a New York-based high-frequency trading (HFT) firm, is under fire by Chinese authorities for allegedly smuggling high-tech hardware into the country for the purpose of using it in the Shanghai Futures Exchange (SHFE). The report comes by way of Financial Times, which notes the Chinese customs authorities are determining whether Tower installed illicit \"customized processors and networking hardware\" that didn't match its customs declaration.\n\nTower allegedly brought in $17 million worth of hardware into the country. Although the hardware hasn't been seized, the authority handling the case has instructed Tower not to remove any of it from the SHFE server room until the investigation is concluded. Should the allegations ring true, Tower could face \"significant fines\" and even criminal charges.\n\nHigh-frequency trading is automated and algorithm-based, and reliant on highly specialized FPGAs and ASICs to do millisecond-quick (or even sub-millisecond) trades. HFT firms go as far as designing their own network cards and software stacks, complementing the operating systems' functionality or bypassing it entirely.\n\nTaking the recent U.S. hardware export controls into context, it may seem odd that China itself would be raising an eyebrow against advanced hardware going into the country, but there's a logical reason. The Shanghai Futures Exchange reportedly only allows \"certified brokers\" to connect directly to its servers, therefore bypassing precious milliseconds in network latency if they were located farther away.\n\nIf Tower employed customized hardware that's faster than expected, that would be seen as a no-no by the SHFE, as the regulatory agency apparently wants an even playing field among all traders. This move comes after the Chinese market regulator announced \"comprehensive and systematic regulation\" after a big market sell-off in 2024.\n\nThe regulation makes sense in theory, but the Financial Times remarks that \"people familiar\" with the Chinese HFT market state that firms have been abusing a legal loophole by rolling their own custom servers and installing them under the name of approved Chinese brokers.\n\nThe report contains no information on exactly what type of hardware is involved in this story, but the recently introduced U.S. export controls cover not just high-end Nvidia GPUs, but all sorts of high-end FPGAs, ASICs, even HBM and standard Intel and AMD processors. It's not hard to imagine that $17 million worth of highly optimized servers have one, multiple, or all of the aforementioned bits of silicon.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/new-york-firm-faces-china-investigation-over-usd17m-advanced-trading-hardware-smuggling-accused-of-installing-customized-processors-and-networking-hardware-at-shanghai-futures-exchange",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Big Tech's AI Spending—and Borrowing—Will Be Even Higher Next Year, Says Citi",
      "content": "Key Takeaways Citigroup analysts on Tuesday forecast hyperscalers would spend even more on AI infrastructure next year than previously expected.\n\nThe AI data center buildout is increasingly being financed by debt rather than cash flows, an evolution that exposes the AI boom to new vulnerabilities like default and interest rate risk.\n\nOther financing methods, like the investment agreement announced by OpenAI and Nvidia last week, have worried some onlookers fearful of an AI bubble.\n\nAfter a series of big cloud computing deals this month, Citigroup analysts now expect AI spending to exceed their already eye-watering forecast.\n\nCiti analysts on Tuesday estimated that hyperscalers—including Microsoft (MSFT), Alphabet (GOOG), Amazon (AMZN), Oracle (ORCL), and CoreWeave (CRWV)—will spend $490 billion on infrastructure and other capital goods next year, up from a prior estimate of $420 billion. Citi’s forecasts are slightly above the Wall Street consensus.\n\nWhy This Matters To You The AI infrastructure boom has been a major force behind U.S. stock market gains and economic growth in recent years. If tech companies rely on debt to fund their massive AI investments, they could expose the AI buildout—and the broader economy—to greater risk.\n\nThe analysts pointed to an onslaught of announced partnerships, investments, and products in recent weeks as evidence of strong AI demand. They said their recent conversations with CIOs and CTOs at a range of companies “reflect a similar increase in urgency around adoption at the enterprise level.”\n\nCiti expects AI infrastructure providers like Nvidia (NVDA) to benefit from higher spending. As such, the firm’s analysts raised their price target on Nvidia shares to $210 from $200 on Tuesday.\n\n\n\nDebt, Not Cash Flows, May Fund Future Spending\n\nThe hyperscalers are among the world’s largest, most profitable companies, a fact that has enabled them to increase their infrastructure spending exponentially over the past few years. But not even hugely profitable tech giants can undertake this level of investment on their own.\n\n“It is notable that we have gone from the cash flow funded stage of this investment cycle to the debt funded stage, with the incremental risks that come with it,” Citi’s analysts wrote.\n\nOracle last week sold $18 billion of bonds in the second-largest U.S. debt deal this year, according to a Bloomberg report. Oracle, which has spent more than it's made in each of the last two quarters, is expected to use the debt to increase its cloud capacity so it can deliver on a five-year, $300 billion deal with OpenAI. Adding that much capacity will be expensive. Citi sees Oracle’s capital expenditures ballooning to $58 billion in fiscal year 2027, nearly three times what it spent in the fiscal year that ended in May.\n\nOpenAI, another company that will need to spend a lot to support its ambitions, took a different approach to raising money. Last week, the company struck a deal with Nvidia to deploy 10 GW of Nvidia systems over the next five years in exchange for an incremental $100 billion equity investment. OpenAI is reportedly discussing leasing—not buying—the chips from Nvidia, a novel arrangement that could cut its hardware costs by 10 to 15%, according to The Information.\n\nThe deal raised eyebrows on Wall Street, where some analysts and investors expressed concern about the “circularity” and concentration of the AI ecosystem. Some skeptics likened it to a bailout, with Nvidia stepping in as an investor of last resort to support a cash-starved OpenAI. It has also inspired comparisons to the Dotcom Bubble, when telecom equipment providers lent to and invested in their own customers, fueling speculative fervor.\n\nBut analysts see important differences between the 1990s and today. “The critical distinction, in our view, is the ‘off-ramp’ created by growing external demand for AI services driven by enterprise adoption,” write Citi analysts.\n\nCompanies like OpenAI and Meta (META), they say, are rolling out AI-driven applications and services with clear monetization prospects. And the rate of AI’s technological progress, they argue, is quickly expanding the scope of potential applications.",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/big-tech-s-ai-spending-and-borrowing-will-be-even-higher-next-year-says-citi-11821812",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "CoreWeave Extends Hot Streak With Meta's $14 Billion Cloud Deal",
      "content": "CoreWeave Inc. (NASDAQ:CRWV) surged after it disclosed in a regulatory filing that it has entered into a multibillion-dollar agreement with Meta Platforms Inc. (NASDAQ:META) for cloud computing capacity valued at up to $14.2 billion.\n\nAccording to an 8-K filing with the SEC, the agreement was executed on September 25 under the companies' existing Master Services Agreement, effective as of December 2023.\n\nMeta has committed to payments of approximately $14.2 billion through December 14, 2031, with the option to significantly expand the order through 2032.\n\nAlso Read: CoreWeave Expands Agreement With OpenAI To Train Next-Gen Models\n\nCoreWeave will provide reserved capacity orders, subject to delivery and service availability requirements. The agreement includes provisions for termination, indemnification, and limitations of liability.\n\nThe company determined that the Master Services Agreement qualifies as a material definitive agreement under SEC rules. It will remain effective until all orders are fulfilled, expired, or terminated in accordance with its terms.\n\nPart Of Larger Growth Push\n\nThe new contract builds on CoreWeave's rapid expansion in 2025 as demand for artificial intelligence infrastructure accelerates.\n\nEarlier this year, the company announced a $6.3 billion arrangement with Nvidia (NASDAQ:NVDA) to purchase unused cloud capacity through 2032.\n\nIt also expanded its agreement with OpenAI by up to $6.5 billion, in addition to an earlier $11.9 billion commitment.\n\nSince its March IPO, CoreWeave's shares have more than tripled, lifted by contracts with Microsoft (NASDAQ:MSFT), Nvidia, OpenAI, and now Meta. However, trading has been volatile.\n\nIn August, insiders sold shares as lock-up restrictions expired, even as institutional investors added positions. Analysts tracked by Benzinga list price forecasts ranging widely, from below current levels to as high as $200 per share, with consensus near $127.\n\nPrice Action: CRWV shares were trading higher by 15.20% to $141.14 at last check Tuesday. META was down 1.53%.\n\nRead Next:\n\nPhoto by T. Schneider via Shutterstock\n\nUp Next: Transform your trading with Benzinga Edge's one-of-a-kind market trade ideas and tools. Click now to access unique insights that can set you ahead in today's competitive market.\n\nGet the latest stock analysis from Benzinga?\n\nThis article CoreWeave Extends Hot Streak With Meta's $14 Billion Cloud Deal originally appeared on Benzinga.com\n\n© 2025 Benzinga.com. Benzinga does not provide investment advice. All rights reserved.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/coreweave-extends-hot-streak-metas-135527689.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Here's How IonQ is Paving its Profitability Path in the Quantum Race",
      "content": "IonQ’s IONQ path to profitability is anchored by both strong revenue performance and strategic capital allocation. In the last-reported second quarter of 2025, the company’s revenues surpassed the high end of the guidance by 15%, demonstrating the ability to accelerate project implementation with existing customers. Its substantial $1 billion equity investment, coupled with pro forma cash and investments of $1.6 billion, provides a solid financial foundation to fund ongoing research, acquisitions and global expansion without immediate pressure to achieve near-term profitability. These resources also enable IonQ to execute on its ambitious roadmap for scaling quantum computing capacity while maintaining operational flexibility.\n\nA primary pillar of IonQ’s profitability strategy is its accelerated technology roadmap, enhanced by acquisitions and strategic partnerships. The acquisitions of Oxford Ionics, Lightsynq and Capella position the company to achieve 800 logical qubits by 2027 and 80,000 logical qubits by 2030. These milestones, combined with Lightsynq’s photonic interconnect technology and Capella’s space-based quantum networking capabilities, allow IonQ to target scalable, cost-efficient quantum computing systems with low unit costs, providing a clear pathway to attractive unit economics once large-scale deployment is achieved.\n\nIonQ is also building a diversified commercial ecosystem to drive recurring revenue streams. Collaborations with global organizations, such as AstraZeneca, AWS, NVIDIA, Oak Ridge National Laboratory and the U.S. Department of Energy, highlight practical applications where IonQ’s quantum systems provide measurable advantages, including a 20x speed-up in drug development workflows. In addition, the development of production-grade Quantum Key Distribution (QKD) networks, used by governments, financial institutions and telecoms, establishes a parallel revenue engine from quantum networking.\n\nWith its vertical integration, experience in trapped-ion technology and a patent portfolio of over 1,000, IonQ is well-positioned to sustain competitive advantage as it scales its quantum and networking businesses worldwide.\n\nIONQ’s Peer Update\n\nRigetti RGTI: Technologically, Rigetti is advancing superconducting gate-based hardware via its chiplet architecture, with a 36-qubit system available and a 100+ qubit system at 99.5% two-qubit fidelity expected by year-end 2025. This leaves the company well-positioned to scale while retaining optionality for partnerships or acquisitions.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/heres-ionq-paving-profitability-path-133000725.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Nvidia gets a price target hike from Citi on AI infrastructure growth, OpenAI deal",
      "content": "Nvidia is poised for further upside as it ramps up initiatives to improve artificial intelligence infrastructure, including new products and partnerships, according to Citi. The investment bank, which has a buy rating on shares, raised its price target for Nvidia to $210 from $200,…\n\nThis story appeared on cnbc.com , 2025-09-30 18:21:37.273000.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/981a6324990c4c0b",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "(PR) Tight Upstream Supply and Restocking Drive 2024 DRAM Module Revenue Growth of 7%",
      "content": "TrendForce reports that following the completion of inventory digestion in the downstream consumer market concluded at the end of Q4 2023, DRAM suppliers shifted focus towards HBM and server DDR5 products, leading to tighter supply for other DRAM types. This increase in demand pushed overall DRAM prices higher, encouraging module manufacturers to replenish stocks and boost procurement. Consequently, the global DRAM module market achieved USD 13.3 billion in revenue in 2024, a 7% YoY increase that reversed the 28% decline experienced in 2023.In the latter half of 2024, demand momentum declined due to rising module prices. Module manufacturers struggled to transfer these high chip costs to distribution channels, limiting sales. To stay competitive, some aimed to enhance costs structure by increasing their purchase of cheaper server reball chips.TrendForce observes that, with the overall market recovering in 2024, most module manufacturers experienced year-over-year revenue growth. However, the extent of growth differed depending on target markets and operational strategies.In 2024, the leading five DRAM module manufacturers captured 81% of the total global revenue, with the top eight accounting for 83%. Kingston retained a strong 66% market share, maintaining its leading position. However, its revenue growth was slower compared to competitors, due to weaker demand in the consumer segment during the second half of 2024. Kingston remained focused on its high-end brand image, emphasizing profitability.ADATA utilized inexpensive inventory accumulated during the 2Q23-3Q23 rebound, aggressively increasing shipments in the first half of 2024. This approach contributed to a 20% rise in revenue, earning it the second spot in the global rankings.Kimtigo actively broadened its domestic and international channels, leveraging the 2H23 rebound to capitalize on recovery opportunities and projecting a 10% revenue increase in 2024.Team Group concentrated on the gaming market, increasing its presence in North American e-commerce and distributor channels, while also expanding its enterprise server DRAM projects. These initiatives resulted in a 59% revenue increase, elevating the company to fourth place.Patriot Memory utilized a diversified portfolio across consumer, gaming, and industrial control sectors, achieving a 12% YoY growth and securing the fifth position.Innodisk has solidified its position in the industrial sector and is actively growing its edge AI product offerings. By partnering with NVIDIA platforms, it has expanded into new markets, increasing revenue and climbing to sixth place.Apacer also concentrated on industrial markets and increased operational flexibility by outsourcing manufacturing to partners in India, leading to a modest recovery and securing seventh place.Agile Gear International (AGI) quickly expanded by entering Amazon Japan, boosting brand awareness and sales. It broke into the top eight globally and achieved the highest revenue growth rate among leading companies.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341491/tight-upstream-supply-and-restocking-drive-2024-dram-module-revenue-growth-of-7",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "GoodRx stock soars after CEO hints at potential TrumpRx partnership",
      "content": "Investing.com -- GoodRx Holdings (NASDAQ:GDRX) stock surged 18% Wednesday after CEO Wendy Barnes suggested the digital healthcare platform could potentially partner with the Trump administration on its new drug pricing initiative.\n\nIn an interview on Fox Business, Barnes revealed that GoodRx has been having \"conversations\" with the Trump administration regarding efforts to deliver more affordable drug pricing. She noted that the government’s TrumpRx proposal would complement GoodRx’s existing business model, adding that the company could \"perhaps partner\" with the administration on the initiative.\n\nThe stock climbed as much as 27% during intraday trading before settling at an 18% gain by market close.\n\nThe comments from Barnes came just one day after President Donald Trump announced a comprehensive plan aimed at reducing prescription drug costs in the United States. The president’s initiative includes the creation of a \"TrumpRx\" direct-to-consumer website where Americans would be able to purchase medications at discounted prices, as well as a broad agreement with Pfizer to lower prices on many of its products.\n\nGoodRx, which operates a platform helping consumers find discounted prices on prescription medications, appears well-positioned to potentially benefit from or collaborate with the administration’s new drug pricing efforts.\n\nRelated articles\n\nGoodRx stock soars after CEO hints at potential TrumpRx partnership\n\nEUR/USD Could Rebound as Bond-Driven US Dollar Strength Looks Overdone\n\nNatural Gas: Consolidation Could Set Stage for Breakout Above $3.20 Barrier",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/goodrx-stock-soars-ceo-hints-210736698.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Ridgewood Investments LLC Buys 1,097 Shares of NVIDIA Corporation $NVDA",
      "content": "Ridgewood Investments LLC boosted its position in NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 11.8% during the second quarter, HoldingsChannel reports. The fund owned 10,358 shares of the computer hardware maker’s stock after buying an additional 1,097 shares during the quarter. Ridgewood Investments LLC’s holdings in NVIDIA were worth $1,636,000 as of its most recent filing with the SEC.\n\nOther large investors also recently modified their holdings of the company. Kingstone Capital Partners Texas LLC raised its holdings in shares of NVIDIA by 267,959.7% during the second quarter. Kingstone Capital Partners Texas LLC now owns 382,373,765 shares of the computer hardware maker’s stock valued at $64,976,521,000 after acquiring an additional 382,231,120 shares in the last quarter. UBS AM A Distinct Business Unit of UBS Asset Management Americas LLC grew its stake in shares of NVIDIA by 2.9% during the 1st quarter. UBS AM A Distinct Business Unit of UBS Asset Management Americas LLC now owns 206,794,926 shares of the computer hardware maker’s stock valued at $22,412,434,000 after purchasing an additional 5,896,735 shares during the period. Goldman Sachs Group Inc. grew its stake in shares of NVIDIA by 123.5% during the 1st quarter. Goldman Sachs Group Inc. now owns 187,995,213 shares of the computer hardware maker’s stock valued at $20,374,921,000 after purchasing an additional 103,889,872 shares during the period. Nuveen LLC purchased a new position in NVIDIA in the 1st quarter worth approximately $15,089,414,000. Finally, Amundi raised its holdings in shares of NVIDIA by 16.0% during the 1st quarter. Amundi now owns 135,770,043 shares of the computer hardware maker’s stock worth $13,826,199,000 after acquiring an additional 18,733,431 shares in the last quarter. 65.27% of the stock is currently owned by institutional investors.\n\nGet NVIDIA alerts:\n\nAnalyst Ratings Changes\n\nA number of equities analysts have recently issued reports on NVDA shares. Needham & Company LLC reissued a “buy” rating and set a $200.00 price target on shares of NVIDIA in a research report on Thursday, August 28th. Craig Hallum lifted their price objective on NVIDIA from $195.00 to $245.00 and gave the stock a “buy” rating in a research report on Thursday, August 28th. UBS Group reissued a “buy” rating on shares of NVIDIA in a research note on Tuesday, September 23rd. KeyCorp reaffirmed an “overweight” rating and set a $250.00 price objective (up from $230.00) on shares of NVIDIA in a research note on Tuesday. Finally, Wall Street Zen upgraded NVIDIA from a “hold” rating to a “buy” rating in a report on Friday, September 5th. Four equities research analysts have rated the stock with a Strong Buy rating, thirty-six have issued a Buy rating, four have given a Hold rating and one has given a Sell rating to the company’s stock. Based on data from MarketBeat.com, the stock presently has a consensus rating of “Moderate Buy” and an average price target of $211.00.\n\nNVIDIA Price Performance\n\nNASDAQ NVDA opened at $186.44 on Wednesday. The stock has a market capitalization of $4.53 trillion, a P/E ratio of 53.12, a P/E/G ratio of 1.32 and a beta of 2.10. NVIDIA Corporation has a 1 year low of $86.62 and a 1 year high of $187.35. The business’s fifty day moving average is $177.20 and its two-hundred day moving average is $146.90. The company has a debt-to-equity ratio of 0.08, a quick ratio of 3.60 and a current ratio of 4.21.\n\nNVIDIA (NASDAQ:NVDA – Get Free Report) last posted its quarterly earnings results on Wednesday, August 27th. The computer hardware maker reported $1.05 EPS for the quarter, beating the consensus estimate of $1.01 by $0.04. NVIDIA had a net margin of 52.41% and a return on equity of 101.74%. The business had revenue of $46.74 billion for the quarter, compared to analysts’ expectations of $45.65 billion. During the same period in the previous year, the company posted $0.68 EPS. NVIDIA’s revenue was up 55.6% on a year-over-year basis. NVIDIA has set its Q3 2026 guidance at EPS. On average, research analysts forecast that NVIDIA Corporation will post 2.77 earnings per share for the current fiscal year.\n\nNVIDIA Dividend Announcement\n\nThe firm also recently disclosed a quarterly dividend, which will be paid on Thursday, October 2nd. Investors of record on Thursday, September 11th will be issued a $0.01 dividend. This represents a $0.04 annualized dividend and a yield of 0.0%. The ex-dividend date is Thursday, September 11th. NVIDIA’s dividend payout ratio is currently 1.14%.\n\nInsider Buying and Selling\n\nIn other NVIDIA news, Director Persis Drell sold 40,000 shares of the stock in a transaction on Friday, September 19th. The shares were sold at an average price of $177.65, for a total value of $7,106,000.00. Following the sale, the director directly owned 138,740 shares in the company, valued at approximately $24,647,161. This trade represents a 22.38% decrease in their ownership of the stock. The transaction was disclosed in a document filed with the SEC, which is accessible through the SEC website. Also, CFO Colette Kress sold 30,500 shares of the stock in a transaction on Friday, September 19th. The stock was sold at an average price of $176.40, for a total transaction of $5,380,200.00. Following the sale, the chief financial officer directly owned 2,883,402 shares of the company’s stock, valued at $508,632,112.80. This represents a 1.05% decrease in their position. The disclosure for this sale can be found here. In the last quarter, insiders sold 4,022,407 shares of company stock valued at $700,382,754. 4.17% of the stock is owned by company insiders.\n\nAbout NVIDIA\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nRead More\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/01/ridgewood-investments-llc-buys-1097-shares-of-nvidia-corporation-nvda/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Nvidia Becomes World's Largest Company, Hits $4.5 Trillion Market Cap",
      "content": "This article first appeared on GuruFocus.\n\nOct 1 - Nvidia (NASDAQ:NVDA) just set another record, becoming the first company to surpass a $4.53 trillion market cap after shares climbed 2.6% on September 30 to close at $186.58. The milestone comes only months after the chipmaker crossed $4 trillion in July, fueled by surging demand for its AI chips and infrastructure partnerships.\n\nThe stock has advanced 39% year-to-date, supported by major artificial intelligence projects. One of the largest involves a $100 billion commitment with Microsoft (NASDAQ:MSFT)-backed OpenAI, aimed at building AI infrastructure capable of supporting at least 10 gigawatts of compute power. OpenAI has also teamed up with Oracle (ORCL) to construct five new data centers designed for GPU-heavy workloads.\n\nThe momentum extends beyond Nvidia's direct deals. CoreWeave (NASDAQ:CRWV), a cloud provider backed by Nvidia, recently secured a $14.2 billion agreement to supply AI infrastructure to Meta Platforms (NASDAQ:META). At the same time, Alphabet's Google (NASDAQ:GOOGL), Apple (NASDAQ:AAPL), Microsoft (NASDAQ:MSFT), Broadcom (NASDAQ:AVGO), Advanced Micro Devices (NASDAQ:AMD), and Palantir Technologies (NASDAQ:PLTR) continue to expand spending on AI-related infrastructure.\n\nThe swift rise of Nvidia emphasizes not only that the company has been the top player in AI hardware but also that the market of computing power is redefining the industry due to the rapid growth of the requirements.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-becomes-worlds-largest-company-122555338.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "The Gaslit Asset Class",
      "content": "I'm David Rosenthal, and this is a place to discuss the work I'm doing in Digital Preservation.",
      "source": "Dshr.org",
      "url": "https://blog.dshr.org/2025/09/the-gaslit-asset-class.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "nvidia-nat-mcp 1.3.0a20251001",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-mcp/1.3.0a20251001/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "CoreWeave Stock To $250?",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/10/01/coreweave-stock-to-250/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "NVIDIA Corporation $NVDA Shares Purchased by McGlone Suttner Wealth Management Inc.",
      "content": "McGlone Suttner Wealth Management Inc. raised its stake in shares of NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 5.1% during the second quarter, according to the company in its most recent 13F filing with the SEC. The fund owned 33,041 shares of the computer hardware maker’s stock after buying an additional 1,603 shares during the quarter. NVIDIA comprises about 0.8% of McGlone Suttner Wealth Management Inc.’s investment portfolio, making the stock its 18th biggest position. McGlone Suttner Wealth Management Inc.’s holdings in NVIDIA were worth $5,220,000 as of its most recent filing with the SEC.\n\nA number of other large investors have also recently bought and sold shares of the stock. Kathleen S. Wright Associates Inc. grew its position in shares of NVIDIA by 169.3% in the first quarter. Kathleen S. Wright Associates Inc. now owns 404 shares of the computer hardware maker’s stock valued at $44,000 after purchasing an additional 254 shares during the period. Copia Wealth Management purchased a new stake in shares of NVIDIA in the fourth quarter valued at $50,000. Barnes Dennig Private Wealth Management LLC purchased a new stake in shares of NVIDIA in the first quarter valued at $51,000. Bruce G. Allen Investments LLC grew its position in shares of NVIDIA by 198.2% in the first quarter. Bruce G. Allen Investments LLC now owns 492 shares of the computer hardware maker’s stock valued at $53,000 after purchasing an additional 327 shares during the period. Finally, Campbell Capital Management Inc. grew its position in shares of NVIDIA by 5,900.0% in the first quarter. Campbell Capital Management Inc. now owns 600 shares of the computer hardware maker’s stock valued at $65,000 after purchasing an additional 590 shares during the period. Institutional investors and hedge funds own 65.27% of the company’s stock.\n\nGet NVIDIA alerts:\n\nNVIDIA Trading Up 2.5%\n\nNASDAQ:NVDA opened at $186.44 on Wednesday. The business’s 50-day moving average is $177.20 and its two-hundred day moving average is $146.90. The company has a debt-to-equity ratio of 0.08, a current ratio of 4.21 and a quick ratio of 3.60. NVIDIA Corporation has a 12 month low of $86.62 and a 12 month high of $187.35. The firm has a market capitalization of $4.53 trillion, a PE ratio of 53.12, a price-to-earnings-growth ratio of 1.32 and a beta of 2.10.\n\nNVIDIA Dividend Announcement\n\nNVIDIA ( NASDAQ:NVDA Get Free Report ) last announced its earnings results on Wednesday, August 27th. The computer hardware maker reported $1.05 earnings per share (EPS) for the quarter, topping analysts’ consensus estimates of $1.01 by $0.04. NVIDIA had a return on equity of 101.74% and a net margin of 52.41%.The business had revenue of $46.74 billion for the quarter, compared to analyst estimates of $45.65 billion. During the same period in the previous year, the company earned $0.68 earnings per share. The company’s revenue for the quarter was up 55.6% compared to the same quarter last year. NVIDIA has set its Q3 2026 guidance at EPS. Research analysts predict that NVIDIA Corporation will post 2.77 earnings per share for the current fiscal year.\n\nThe firm also recently announced a quarterly dividend, which will be paid on Thursday, October 2nd. Stockholders of record on Thursday, September 11th will be given a dividend of $0.01 per share. This represents a $0.04 dividend on an annualized basis and a dividend yield of 0.0%. The ex-dividend date of this dividend is Thursday, September 11th. NVIDIA’s payout ratio is presently 1.14%.\n\nAnalyst Ratings Changes\n\nA number of brokerages have recently commented on NVDA. Needham & Company LLC reaffirmed a “buy” rating and issued a $200.00 price objective on shares of NVIDIA in a research report on Thursday, August 28th. Cantor Fitzgerald reiterated an “overweight” rating and issued a $240.00 target price on shares of NVIDIA in a report on Thursday, August 28th. Morgan Stanley lifted their target price on NVIDIA from $206.00 to $210.00 and gave the company an “overweight” rating in a report on Thursday, August 28th. Robert W. Baird lifted their target price on NVIDIA from $195.00 to $225.00 and gave the company an “outperform” rating in a report on Monday, August 25th. Finally, Jefferies Financial Group reiterated a “buy” rating and issued a $220.00 target price (up previously from $205.00) on shares of NVIDIA in a report on Monday. Four analysts have rated the stock with a Strong Buy rating, thirty-six have given a Buy rating, four have assigned a Hold rating and one has issued a Sell rating to the stock. Based on data from MarketBeat.com, the company has an average rating of “Moderate Buy” and a consensus target price of $211.00.\n\nGet Our Latest Stock Analysis on NVIDIA\n\nInsider Buying and Selling at NVIDIA\n\nIn other news, CEO Jen Hsun Huang sold 75,000 shares of NVIDIA stock in a transaction dated Monday, September 29th. The stock was sold at an average price of $182.34, for a total transaction of $13,675,500.00. Following the sale, the chief executive officer directly owned 71,233,203 shares of the company’s stock, valued at approximately $12,988,662,235.02. The trade was a 0.11% decrease in their ownership of the stock. The sale was disclosed in a legal filing with the Securities & Exchange Commission, which can be accessed through this hyperlink. Also, CFO Colette Kress sold 30,500 shares of NVIDIA stock in a transaction dated Friday, September 19th. The stock was sold at an average price of $176.40, for a total value of $5,380,200.00. Following the sale, the chief financial officer directly owned 2,883,402 shares in the company, valued at approximately $508,632,112.80. The trade was a 1.05% decrease in their ownership of the stock. The disclosure for this sale can be found here. In the last 90 days, insiders sold 4,022,407 shares of company stock valued at $700,382,754. Company insiders own 4.17% of the company’s stock.\n\nAbout NVIDIA\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nFeatured Stories\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/01/nvidia-corporation-nvda-shares-purchased-by-mcglone-suttner-wealth-management-inc/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "These S&P 500 Stocks Stood Out in Q3 2025: Western Digital, Warner Bros Discovery, Seagate, Corning, Teradyne",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/markets/these-s-p-500-stocks-stood-out-in-q3-2025-western-digital-warner-bros-discovery-seagate-corning-teradyne",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Now Up 70% in 2025, Is Intel Stock a Buy, Sell, or Hold for Q4?",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/35169458/now-up-70-in-2025-is-intel-stock-a-buy-sell-or-hold-for-q4",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "US takes a stake in company operating one of world's largest lithium mines in Nevada",
      "content": "The U.S. government is taking a minority stake in Lithium Americas, a company that is developing one of the world’s largest lithium mines in northern Nevada.\n\nThe Department of Energy will take a 5% equity stake in the miner, which is based in Vancouver. It will also take a 5% stake in the Thacker Pass lithium mining project, a joint venture with General Motors.\n\nThacker Pass is considered crucial in reducing U.S. reliance on China for lithium, a critical material used to produce the high tech batteries used in cell phones, electric vehicles and renewable energy. Both Republicans and Democrats support the project and narrowing the production gap. China is the world’s largest lithium processor.\n\nU.S. Energy Secretary Chris Wright said in a statement that the deal with Lithium Americas “helps reduce our dependence on foreign adversaries for critical minerals by strengthening domestic supply chains and ensures better stewardship of American taxpayer dollars.”\n\nThacker Pass is expected to produce 40,000 metric tons of battery-quality lithium carbonate per year in its first phase, enough to help power 800,000 EVs.\n\nThe equity stake in Lithium Americas is the latest example of the direct intervention by the Trump administration with private companies. The government is getting a 10% stake in Intel through the conversion of billions in previously granted government funds and pledges. The administration spent $400 million of taxpayer money in July on MP Materials stock to make the U.S government the biggest owner in the Las Vegas rare earths miner. Trump also made a deal with Nvidia and AMD to give the U.S. government a 15% cut of revenue from selling certain chips to China.\n\nLithium Americas said Wednesday that it reached a non-binding agreement in principle with the DOE to advance the first draw of $435 million on the federal loan. The DOE has agreed to defer $182 million of debt service over the first five years of the loan.\n\nThe White House and Canada's Lithium Americas seemed to be moving forward with the deal late last month, as both parties agreed on changes to an approximately $2.3 billion federal loan that could allow the project to move forward to extract the silver-white metal used in electric vehicle batteries. GM has pledged more than $900 million to help develop Thacker Pass, which holds enough lithium to build 1 million electric vehicles annually.\n\nDan Ives, an analyst with Wedbush, called Thacker Pass is a “massive opportunity” for the U.S. to reduce its reliance on China and other foreign adversaries for lithium.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/us-takes-minority-stake-company-115743152.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Analyst Highlights Red Flags in Nvidia (NVDA)-OpenAI $100 Billion Deal – ‘Feature of Past Bubbles’",
      "content": "We recently published 10 Stocks to Watch as Investors Scramble to Pour Money into AI Trade. NVIDIA Corporation (NASDAQ:NVDA) is one of the stocks that caught analysts' attention.\n\nTom Hancock, GMO portfolio manager, recently talked about Nvidia’s $100 billion deal with OpenAI during an interview on CNBC. He believes the company is “losing” on the deal.\n\n“I think vendor financing has a pretty spotty history, frankly. It’s been a feature of past bubbles that we’ve seen. NVIDIA Corp (NASDAQ:NVDA) is basically giving hundreds of millions here. Roughly 35 million will go back into NVIDIA Corp (NASDAQ:NVDA) revenue down the road. It’ll look like revenue for NVIDIA Corp (NASDAQ:NVDA), but it’s not real cash they’re getting—they’re losing on the deal. Nvidia has also underwritten some of Coreweave’s investment. This is not to say it’s a bubble or anything fraudulent, but it demonstrates how much capital intensity there is in building out AI infrastructure at a time when monetization outside some in-house applications at companies like Meta or Alphabet is very unclear, given the scale of investment required.”\n\nPhoto by Kaleidico on Unsplash\n\nNvidia’s Hopper Infrastructure and now Blackwell form the core of AI infrastructure for LLM training and inference. But Nvidia’s growth is slowing compared to previous quarters amid competition and capex spending limitations from major companies. In the recently reported quarter, Nvidia’s annual revenue growth came in at 56%, compared with nearly 100% YoY growth in the past.\n\nWith its strong position in the data center market and rising demand, Nvidia is likely to keep growing, though not at the same pace it has in the past. Increasing competition from major companies like Broadcom is also expected to impact Nvidia’s margins in the long term.\n\nColumbia Threadneedle Global Technology Growth Strategy stated the following regarding NVIDIA Corporation (NASDAQ:NVDA) in its second quarter 2025 investor letter:",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/analyst-highlights-red-flags-nvidia-202807470.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Japan LDP election: Koizumi leads among party lawmakers, analysis shows",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/3db5cff00650bbbb",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Arm's CEO said he learned a key leadership lesson working under Jensen Huang",
      "content": "Arm's CEO, Rene Haas, said Jensen Huang has a \"set of characteristics of vision, speed, fearlessness, taking risk, and an ability to pivot very, very fast.\"\n\nArm's CEO, Rene Haas, said Jensen Huang has a \"set of characteristics of vision, speed, fearlessness, taking risk, and an ability to pivot very, very fast.\" Samantha Burkardt/SXSW Conference & Festivals via Getty Images\n\nArm's CEO, Rene Haas, said Jensen Huang has a \"set of characteristics of vision, speed, fearlessness, taking risk, and an ability to pivot very, very fast.\" Samantha Burkardt/SXSW Conference & Festivals via Getty Images\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nArm CEO Rene Haas said at Nvidia, he saw up close how bold leadership decisions can change a company's trajectory.\n\nThe CEO of the $150 billion chip design firm spoke about his seven years at Nvidia working on computing products at the All-In Summit 2025 in September, in a conversation posted Wednesday.\n\nHaas said he saw how Jensen Huang built the company by taking bold risks and pivoting quickly.\n\nHaas said Huang changed strategy at an off-site meeting meant to review business roadmaps. \"We're abolishing this product line. We're going to move 2,000 engineers off of project X onto project Y,\" said Haas, adding that the company had only about 6,000 people at the time.\n\nThat abrupt shift — away from making support chips for Intel's processors — proved decisive. Instead of trying to keep up with Intel in PCs, Huang redirected thousands of engineers to focus on Arm-based designs and graphics chips. That move reshaped the company's future, said Haas, who left Nvidia in 2013 to join Arm.\n\n\"You have this amazing set of characteristics of vision, speed, fearlessness, taking risk, and an ability to pivot very, very fast,\" Haas said of Huang, adding that he has \"learned so much\" from working with him.\n\nNvidia is one of Arm's flagship customers — its latest AI chips combine Arm-based CPUs with its own powerful GPUs.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nIn 2020, Nvidia tried to acquire Arm in a $40 billion deal that fell through because of regulatory hurdles. Haas told Business Insider in 2022 that Arm wasn't dwelling on the failed sale and was instead focused on expanding in industries like cloud, networking, automotive, and the Internet of Things.\n\n\"I'm not going to say Jensen is my competitor today,\" Haas said at the All-In Summit.\n\nBut when asked if Arm might eventually make its own chips and go head-to-head with Nvidia, he added: \"I'm not going to say that today, but could we do that? I hinted in the last conference call that we're looking at going a little bit further than we do today.\"\n\nArm and a Nvidia spokesperson declined to comment.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/arm-ceo-rene-haas-leadership-lesson-nvidia-jensen-huang-2025-10",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Summary of reading: July - September 2025",
      "content": null,
      "source": "Thegreenplace.net",
      "url": "https://eli.thegreenplace.net/2025/summary-of-reading-july-september-2025/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "California AI Bill Sends Shock Waves Through The Industry",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/paulocarvao/2025/10/01/california-ai-bill-sends-shock-waves-through-the-industry/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Goldman Sachs Warns Wall Street's 'Goldilocks' Economy Could Soon Meet Three Big 'Bears' — And Investors Aren't Ready For The Shock",
      "content": "Benzinga and Yahoo Finance LLC may earn commission or revenue on some items through the links below.\n\nThe global investment banking giant Goldman Sachs Group Inc. has raised concerns about a potential market shock that could disrupt the current ‘Goldilocks’ economy.\n\nGoldilocks Economy Holds, But Growth And Rate Risks Loom\n\nThe term ‘Goldilocks’ economy refers to a balanced economic scenario, not too hot to cause inflation or too cold to slow growth. The S&P 500 index is currently near its all-time high, and investors are in high spirits.\n\nTrending: If there was a new fund backed by Jeff Bezos offering a 7-9% target yield with monthly dividends would you invest in it?\n\nHowever, Goldman Sachs’ chief global equity strategist, Mueller-Glissmann, and his team have identified three potential ‘bears’ that could disrupt this equilibrium. A growth shock, which could result from increased unemployment or disappointments in AI. Secondly, a rate shock, in case the Federal Reserve doesn’t implement further rate cuts. Lastly, a new dollar bear, leading to a 10% devaluation of the dollar, which could deter foreign investors from the U.S. market, Fortune reported.\n\n\"There is a risk that Goldilocks meets one of the three bears,\" Mueller-Glissmann says.\n\nMueller-Glissmann noted that, despite these potential shocks, none have materialized yet, though the risk of growth and interest rate shocks persists as year-end approaches. Cleveland Fed President Beth Hammack shared a similar view, indicating she does not anticipate any major market downturn in the near term.\n\nSee Also: An EA Co-Founder Shapes This VC Backed Marketplace—Now You Can Invest in Gaming's Next Big Platform\n\nAI Boom Surges As S&P Faces Potential Market Bubble\n\nThe warning from Goldman Sachs comes amid ongoing discussions about a potential AI stock market bubble. The AI sector has been defying gravity, with companies like NVIDIA Corporation (NASDAQ:NVDA) at the center of this boom. Despite concerns about overvaluation, the AI market continues to grow, raising questions about the sustainability of this trend.\n\nEarlier in September, Bank of America strategist Michael Hartnett also sounded the alarm on a potential AI stock market bubble, citing historic valuation metrics. The S&P 500’s price-to-book ratio hit a record high, surpassing levels seen during the dot-com bubble in 2000.\n\nDespite these warnings, the S&P 500 entered the historically strong fourth quarter with a warning sign for investors. While the fourth quarter typically delivers the best average returns, a strong year-to-date performance through September often leads to a flat or negative October, creating uncertainty for Wall Street.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/goldman-sachs-warns-wall-streets-104607169.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "The AI boom could burst like a bubble if tech companies miss their growth forecasts, top economist Steve Hanke says",
      "content": "lighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nInvestors should buckle up as the AI boom could ultimately collapse like the dot-com bubble, veteran trader and economist Steve Hanke has said.\n\n\"As money pours into AI, it's hard to know whether the market's exuberance is rational or irrational,\" Hanke, a professor of applied economics at Johns Hopkins University, said by email.\n\nFederal Reserve Chair Alan Greenspan coined the term \"irrational exuberance\" in his famous description of the market mood as US stocks surged 13-fold between 1982 and 1999, fueled by immense excitement about technology and the internet.\n\nHanke, who was the president of Toronto Trust Argentina when it was the world's best-performing market mutual fund in 1995, said that dot-com euphoria eventually hit irrational levels and \"ended when the bubble popped.\"\n\nThe tech-heavy Nasdaq index plummeted nearly 80% from its peak in March 2000 to its trough in October 2002, while the benchmark S&P 500 plunged around 45% over the same period.\n\nHanke, who was also economic advisor to President Ronald Reagan in the 1980s, said that the answer to whether the market is rational or irrational this time will \"largely depend on whether the AI firms' spectacular revenue forecasts hold water.\"\n\nHere are some of the key growth projections he was referring to:",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/steve-hanke-ai-boom-dotcom-bubble-tech-stocks-growth-forecasts-2025-10",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Lakeshore Financial Planning Inc. Acquires 1,934 Shares of NVIDIA Corporation $NVDA",
      "content": "Lakeshore Financial Planning Inc. boosted its position in shares of NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 52.0% in the 2nd quarter, according to its most recent filing with the Securities & Exchange Commission. The fund owned 5,650 shares of the computer hardware maker’s stock after purchasing an additional 1,934 shares during the period. NVIDIA comprises about 0.4% of Lakeshore Financial Planning Inc.’s investment portfolio, making the stock its 24th biggest position. Lakeshore Financial Planning Inc.’s holdings in NVIDIA were worth $893,000 at the end of the most recent reporting period.\n\nSeveral other institutional investors have also recently added to or reduced their stakes in the company. Brighton Jones LLC increased its position in NVIDIA by 12.4% in the 4th quarter. Brighton Jones LLC now owns 324,901 shares of the computer hardware maker’s stock valued at $43,631,000 after acquiring an additional 35,815 shares in the last quarter. Bank Pictet & Cie Europe AG increased its position in NVIDIA by 1.0% in the 4th quarter. Bank Pictet & Cie Europe AG now owns 2,346,417 shares of the computer hardware maker’s stock valued at $315,100,000 after acquiring an additional 22,929 shares in the last quarter. Highview Capital Management LLC DE increased its position in NVIDIA by 6.7% in the 4th quarter. Highview Capital Management LLC DE now owns 58,396 shares of the computer hardware maker’s stock valued at $7,842,000 after acquiring an additional 3,653 shares in the last quarter. Hudson Value Partners LLC increased its position in NVIDIA by 30.7% in the 4th quarter. Hudson Value Partners LLC now owns 50,658 shares of the computer hardware maker’s stock valued at $6,805,000 after acquiring an additional 11,900 shares in the last quarter. Finally, Forum Financial Management LP increased its position in NVIDIA by 28.2% in the 4th quarter. Forum Financial Management LP now owns 189,998 shares of the computer hardware maker’s stock valued at $25,515,000 after acquiring an additional 41,757 shares in the last quarter. 65.27% of the stock is owned by institutional investors.\n\nGet NVIDIA alerts:\n\nAnalysts Set New Price Targets\n\nNVDA has been the subject of several analyst reports. KeyCorp reiterated an “overweight” rating and set a $250.00 price target (up previously from $230.00) on shares of NVIDIA in a research report on Tuesday. Wall Street Zen upgraded shares of NVIDIA from a “hold” rating to a “buy” rating in a research report on Friday, September 5th. Wedbush reiterated an “outperform” rating and set a $210.00 price target on shares of NVIDIA in a research report on Thursday, August 28th. Rosenblatt Securities reiterated a “buy” rating and set a $215.00 price target on shares of NVIDIA in a research report on Tuesday, September 23rd. Finally, Stifel Nicolaus lifted their price objective on shares of NVIDIA from $202.00 to $212.00 and gave the stock a “buy” rating in a research note on Monday, August 25th. Four equities research analysts have rated the stock with a Strong Buy rating, thirty-six have given a Buy rating, four have given a Hold rating and one has assigned a Sell rating to the company. According to data from MarketBeat, NVIDIA currently has an average rating of “Moderate Buy” and a consensus target price of $211.00.\n\nInsider Transactions at NVIDIA\n\nIn other news, Director Harvey C. Jones sold 250,000 shares of the stock in a transaction dated Thursday, September 18th. The shares were sold at an average price of $176.21, for a total value of $44,052,500.00. Following the completion of the transaction, the director owned 7,183,280 shares of the company’s stock, valued at approximately $1,265,765,768.80. This represents a 3.36% decrease in their ownership of the stock. The transaction was disclosed in a legal filing with the Securities & Exchange Commission, which can be accessed through the SEC website. Also, Director Mark A. Stevens sold 350,000 shares of the company’s stock in a transaction that occurred on Friday, September 19th. The shares were sold at an average price of $176.39, for a total value of $61,736,500.00. Following the completion of the transaction, the director directly owned 7,399,803 shares of the company’s stock, valued at $1,305,251,251.17. This represents a 4.52% decrease in their position. The disclosure for this sale can be found here. Over the last 90 days, insiders sold 4,022,407 shares of company stock valued at $700,382,754. 4.17% of the stock is currently owned by insiders.\n\nNVIDIA Price Performance\n\nNASDAQ:NVDA opened at $186.44 on Wednesday. NVIDIA Corporation has a one year low of $86.62 and a one year high of $187.35. The company has a market cap of $4.53 trillion, a P/E ratio of 53.12, a P/E/G ratio of 1.32 and a beta of 2.10. The firm’s fifty day moving average price is $177.20 and its two-hundred day moving average price is $146.90. The company has a debt-to-equity ratio of 0.08, a current ratio of 4.21 and a quick ratio of 3.60.\n\nNVIDIA (NASDAQ:NVDA – Get Free Report) last announced its earnings results on Wednesday, August 27th. The computer hardware maker reported $1.05 earnings per share (EPS) for the quarter, beating analysts’ consensus estimates of $1.01 by $0.04. The company had revenue of $46.74 billion during the quarter, compared to analysts’ expectations of $45.65 billion. NVIDIA had a net margin of 52.41% and a return on equity of 101.74%. NVIDIA’s quarterly revenue was up 55.6% on a year-over-year basis. During the same quarter in the previous year, the business posted $0.68 earnings per share. NVIDIA has set its Q3 2026 guidance at EPS. Equities analysts expect that NVIDIA Corporation will post 2.77 earnings per share for the current year.\n\nNVIDIA Dividend Announcement\n\nThe business also recently announced a quarterly dividend, which will be paid on Thursday, October 2nd. Stockholders of record on Thursday, September 11th will be issued a $0.01 dividend. The ex-dividend date of this dividend is Thursday, September 11th. This represents a $0.04 dividend on an annualized basis and a dividend yield of 0.0%. NVIDIA’s dividend payout ratio is 1.14%.\n\nAbout NVIDIA\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nSee Also\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/01/lakeshore-financial-planning-inc-acquires-1934-shares-of-nvidia-corporation-nvda/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Samsung, SK Hynix set to supply chips to OpenAI's Stargate project",
      "content": "By Heekyong Yang and Hyunjoo Jin\n\nSEOUL (Reuters) -Samsung Electronics and SK Hynix have signed letters of intent to supply memory chips for OpenAI's data centers, as South Korean chipmakers join forces with the ChatGPT maker to meet rising demand from its Stargate project.\n\nThe announcements were made on Wednesday after OpenAI CEO Sam Altman met South Korean President Lee Jae Myung and the chairmen of Samsung Electronics and SK Hynix at the presidential office in central Seoul.\n\nU.S. President Donald Trump unveiled the $500 billion Stargate project in January, charging OpenAI and partners including SoftBank and Oracle with ensuring the U.S. remains a leader in artificial intelligence.\n\nExpanding chip availability was one of the key ideas of the project, and Nvidia said last week it would invest up to $100 billion in OpenAI and supply it with data center chips.\n\nPLAN TO BUILD TWO DATA CENTERS IN SOUTH KOREA\n\nSouth Korea's top presidential adviser, Kim Yong-beom, said OpenAI was seeking to order 900,000 semiconductor wafers in 2029, and planned to set up joint ventures with Samsung and SK Hynix to build two data centers in South Korea with an initial capacity of 20 megawatts.\n\nThe adviser said South Korea was open to participating in financing for the Stargate project if needed.\n\n“The significant part of the Stargate project would be impossible without memory chips from the two companies,” Kim told a press briefing.\n\nThe president's office said the partnership would give South Korean chipmakers an early foothold in the world's largest AI infrastructure project, providing a growth opportunity for the domestic chip industry.\n\nSamsung and SK Hynix together hold about 70% of the global Dynamic Random Access Memory chip market and nearly 80% of the HBM market.\n\nHBM - a type of DRAM standard first produced in 2013 - involves stacking chips vertically to save space and reduce power consumption, helping to process the large volumes of data generated by complex AI applications.\n\nOpenAI this year set up its first office in Seoul as South Korean demand for its ChatGPT service surged. The country has the largest number of paying ChatGPT subscribers after the United States, according to OpenAI.\n\nAlongside the chip supply agreements, Samsung Electronics' affiliate Samsung SDS signed a partnership with OpenAI to develop, build and operate AI data centers under the Stargate project, while also expanding enterprise AI services.\n\nShipbuilder Samsung Heavy Industries and construction unit Samsung C&T will jointly work with OpenAI to develop floating offshore data centers to cut cooling costs and carbon emissions.\n\n(Reporting by Heekyong Yang and Hyunjoo Jin. Editing by Mark Potter and Jan Harvey)",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/samsung-sk-hynix-set-supply-112215713.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "No, Deus Ex Remastered, I simply do not believe you need an RTX 2080 to run at recommended settings",
      "content": "We've done a lot of eye-widening on this website about the lofty requests of certain games’ system requirements, but it’s the recommended specs of Deus Ex Remastered that might just send my brow surging through the ceiling and into the fuselage of a passing Airbus, killing everyone on board. You’ve seen it. You’ve seen how it only adds, at most, five years’ worth of graphical nous to the 2000 classic. So, per Steam: a Core i7, 16GB of RAM, and an Nvidia GeForce RT-goddamn-X 2080? No. I’m sorry. No way.\n\nAs noted on Xitter by Mab, developer of fellow imsim ETOS, that’s more than what Deus Ex: Mankind Divided was asking for its own recommended hardware. And while that was nine years ago, it’s still quite clearly a more proficient user of visual whiz-bang tech than Deus Ex Remastered is. At no point, for instance, does Adam Jensen ever resemble a haunted bottle of children’s shampoo:\n\nImage credit: Aspyr\n\nAlso, they spelt 'Nvidia' as 'Nvida'.\n\nYou must think us fools, Aspyr. Fools! To believe that a graphics card which cost 699 Ameridollars at launch could possibly be necessary to render the remaster’s meagre, sometimes actively vibes-quelling graphics changes. The original can run on a netbook, assuming any working ones still exist. There’s just no way. You’re lying. You must be. Oh god. Oh god what if they’re not lying.\n\nWhat if you actually need, in 2025, high-end components to comfortably run a game built around something released a quarter-century ago? What if we’ve been played, and the past three years of stuttering, fan-torturing Unreal Engine 5 performance disasters were just a distraction from the true threat of questionable Blair-era remakes? What if ray tracing did nothing wrong and Randy Pitchford was only trying to warn us? That’s a reality I’m not sure I can face.\n\nY’know what, maybe some things are better left unbenchmarked. Sadly, there doesn’t seem to be much else for starving Deus Ex fans (hello) to look forward to instead, with a Mankind Divided sequel cancelled last year and Jensen VA Elias Toufexis vocally doubting the series’ future. With that cancellation came 100 staff layoffs at developers Eidos Montreal, a studio that cut jobs further earlier this year.",
      "source": "Rock Paper Shotgun",
      "url": "https://www.rockpapershotgun.com/no-deus-ex-remastered-i-simply-do-not-believe-you-need-an-rtx-2080-to-run-at-recommended-settings",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "TSMC Stock Rises as Taiwan Rejects Trump's 50-50 Chip Plan",
      "content": "This article first appeared on GuruFocus.\n\nOct 2 - Taiwan Semiconductor Manufacturing (TSMC) shares advanced on Wednesday after Taiwan's government said it would not adopt a U.S. proposal requiring American firms to split semiconductor sourcing evenly between domestic and foreign suppliers.\n\nVice Premier Cheng Li-chiun stated the so-called 50-50 plan was not part of recent negotiations with Washington, though Taiwan continues to seek deeper high-tech cooperation with the United States. The plan, floated by Trump administration officials, would have pushed U.S. companies to buy half of their chips locally and half from overseas partners such as TSMC.\n\nTSMC stock rose about 2% to $292 in early U.S. trading, extending a 3% gain from the prior session. The company, which produces more than 90% of the world's most advanced semiconductors, supplies major American tech firms including Apple (NASDAQ:AAPL) and Nvidia (NVDA).\n\nThe United States currently manufactures around 12% of global semiconductors, according to the Semiconductor Industry Association. Washington has outlined goals to increase production capacity to as much as 40%, though analysts estimate this could require investment exceeding $500 billion.\n\nTaiwan has emphasized it will maintain its core chip manufacturing base on the island while also expanding production abroad. TSMC is investing in new facilities in Arizona and recently committed roughly $165 billion to U.S. projects as part of its long-term global expansion strategy.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/tsmc-stock-rises-taiwan-rejects-134018538.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "nvidia-nat-langchain 1.3.0a20251002",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-langchain/1.3.0a20251002/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Nvidia Stock Just Touched a New All-Time High. Here Is Where Options Data Says NVDA Could Be Headed Next",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/35193963/nvidia-stock-just-touched-a-new-all-time-high-here-is-where-options-data-says-nvda-could-be-headed-next",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "S&P 500, Nasdaq Hits Record High As Investors Ignore Washington Shutdown Drama",
      "content": "This article first appeared on GuruFocus.\n\nOct 2 - The S&P 500 pushed to a fresh record Thursday, climbing 0.1% despite the ongoing U.S. government shutdown.\n\nThe Nasdaq Composite rose 0.3% to notch a new intraday high, while the Dow Jones Industrial Average gained 78 points, or 0.2%.\n\nTraders largely ignored Washington's gridlock, with momentum instead coming from strength in megacap tech and corporate updates.\n\nNvidia (NVDA) advanced 1% and reached an all-time high, extending the AI-driven rally that has dominated markets this year. Tesla (TSLA) also stood out, with shares up 3% in premarket trading after the automaker reported 497,099 third-quarter deliveries, topping estimates of 447,600.\n\nDespite the shutdown's economic risks, investors focused on earnings optimism, Fed rate cut expectations, and AI momentum, factors that continue to outweigh near-term policy turbulence.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/p-500-nasdaq-hits-record-175311327.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Optimum Inks Multi-Year Agreement for Amdocs Ltd (DOX) AI Suite",
      "content": "Amdocs Ltd (NASDAQ:DOX) is one of the cheap AI stocks to buy right now. On September 10, Optimum, a provider of fiber internet, mobile, and TV services, reached an agreement to continue using the company’s AI offerings.\n\nOptimum Inks Multi-Year Agreement for Amdocs Ltd (DOX) AI Suite\n\nEvgeniiAnd/Shutterstock.com\n\nOptimum is to leverage Amdocs amAlz Suite; a telco-grade AI platform to implement new solutions, including AI-powered Bill Presenter and Gen AI Care Agent. The integration will enable the company to modernize its billing infrastructure and resolve issues with its legacy system.\n\nAccording to Anthony Goonetilleke, Group President of Technology and Head of Strategy at Amdocs, the deal underscores the growing demand for the company’s solutions amid an increasing need for smart, scalable operations.\n\n“Our collaboration with Optimum underscores the growing need for smart, scalable operations that go beyond traditional IT services,” said Goonetilleke. “With our AI-powered solutions, we’re empowering Optimum to simplify complexity, accelerate innovation, and unlock long-term business value.”\n\nAmdocs Ltd (NASDAQ:DOX) is a technology company that uses AI to help telecommunications companies transform customer experiences, automate operations, and optimize decision-making. It has partnered with NVIDIA to develop and deploy these AI solutions, using NVIDIA’s infrastructure and models to build advanced AI agents.\n\nWhile we acknowledge the potential of DOX as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 10 Best Performing ASX Stocks in 2025 and Conservative Stock Portfolio: 11 Best Stocks to Buy Now.\n\nDisclosure: None. This article is originally published at Insider Monkey.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/optimum-inks-multi-agreement-amdocs-053602889.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "GeForce NOW to Add Battlefield 6, ARC Raiders, Bloodlines 2, and More in October",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/geforce-now-to-add-battlefield-6-arc-raiders-bloodlines-2-and-more-in-october/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Seascape Capital Management Lowers Stake in NVIDIA Corporation $NVDA",
      "content": "Seascape Capital Management cut its position in NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 2.0% during the second quarter, according to the company in its most recent disclosure with the Securities & Exchange Commission. The institutional investor owned 44,237 shares of the computer hardware maker’s stock after selling 890 shares during the period. NVIDIA accounts for about 2.2% of Seascape Capital Management’s investment portfolio, making the stock its 8th biggest position. Seascape Capital Management’s holdings in NVIDIA were worth $6,989,000 at the end of the most recent reporting period.\n\nA number of other institutional investors and hedge funds have also recently added to or reduced their stakes in NVDA. Pachira Investments Inc. lifted its holdings in NVIDIA by 1.0% in the second quarter. Pachira Investments Inc. now owns 6,450 shares of the computer hardware maker’s stock valued at $1,019,000 after buying an additional 63 shares during the period. HFG Wealth Management LLC grew its position in NVIDIA by 3.4% in the second quarter. HFG Wealth Management LLC now owns 2,075 shares of the computer hardware maker’s stock valued at $328,000 after purchasing an additional 68 shares in the last quarter. Burkett Financial Services LLC grew its position in NVIDIA by 1.3% in the second quarter. Burkett Financial Services LLC now owns 5,450 shares of the computer hardware maker’s stock valued at $861,000 after purchasing an additional 70 shares in the last quarter. Guided Capital Wealth Management LLC lifted its stake in shares of NVIDIA by 0.3% during the 2nd quarter. Guided Capital Wealth Management LLC now owns 27,858 shares of the computer hardware maker’s stock worth $4,401,000 after buying an additional 70 shares during the last quarter. Finally, Luts & Greenleigh Group Inc. increased its position in NVIDIA by 0.4% during the 2nd quarter. Luts & Greenleigh Group Inc. now owns 19,894 shares of the computer hardware maker’s stock worth $3,143,000 after purchasing an additional 76 shares in the last quarter. 65.27% of the stock is currently owned by institutional investors and hedge funds.\n\nGet NVIDIA alerts:\n\nNVIDIA Stock Up 0.4%\n\nShares of NVDA opened at $187.24 on Thursday. The business’s 50 day simple moving average is $177.52 and its 200-day simple moving average is $147.17. NVIDIA Corporation has a 1 year low of $86.62 and a 1 year high of $188.14. The stock has a market capitalization of $4.55 trillion, a price-to-earnings ratio of 53.34, a price-to-earnings-growth ratio of 1.35 and a beta of 2.12. The company has a debt-to-equity ratio of 0.08, a current ratio of 4.21 and a quick ratio of 3.60.\n\nNVIDIA Dividend Announcement\n\nNVIDIA ( NASDAQ:NVDA Get Free Report ) last released its quarterly earnings results on Wednesday, August 27th. The computer hardware maker reported $1.05 earnings per share for the quarter, beating the consensus estimate of $1.01 by $0.04. NVIDIA had a return on equity of 101.74% and a net margin of 52.41%.The company had revenue of $46.74 billion for the quarter, compared to analyst estimates of $45.65 billion. During the same quarter in the prior year, the firm posted $0.68 EPS. NVIDIA’s quarterly revenue was up 55.6% compared to the same quarter last year. NVIDIA has set its Q3 2026 guidance at EPS. As a group, equities analysts expect that NVIDIA Corporation will post 2.77 earnings per share for the current fiscal year.\n\nThe company also recently declared a quarterly dividend, which will be paid on Thursday, October 2nd. Stockholders of record on Thursday, September 11th will be given a dividend of $0.01 per share. The ex-dividend date of this dividend is Thursday, September 11th. This represents a $0.04 dividend on an annualized basis and a dividend yield of 0.0%. NVIDIA’s dividend payout ratio is presently 1.14%.\n\nInsider Transactions at NVIDIA\n\nIn related news, Director Harvey C. Jones sold 250,000 shares of the firm’s stock in a transaction dated Thursday, September 18th. The stock was sold at an average price of $176.21, for a total transaction of $44,052,500.00. Following the sale, the director owned 7,183,280 shares of the company’s stock, valued at $1,265,765,768.80. This trade represents a 3.36% decrease in their ownership of the stock. The sale was disclosed in a document filed with the Securities & Exchange Commission, which is available through this link. Also, Director Mark A. Stevens sold 350,000 shares of the firm’s stock in a transaction dated Friday, September 19th. The shares were sold at an average price of $176.39, for a total value of $61,736,500.00. Following the sale, the director directly owned 7,399,803 shares in the company, valued at approximately $1,305,251,251.17. The trade was a 4.52% decrease in their position. The disclosure for this sale can be found here. In the last 90 days, insiders have sold 4,022,407 shares of company stock valued at $700,382,754. 4.17% of the stock is currently owned by corporate insiders.\n\nWall Street Analysts Forecast Growth\n\nA number of research firms have recently commented on NVDA. Phillip Securities raised shares of NVIDIA from a “moderate buy” rating to a “strong-buy” rating in a research note on Monday, July 14th. Wolfe Research increased their target price on shares of NVIDIA from $220.00 to $230.00 in a research report on Tuesday, September 23rd. Sanford C. Bernstein reaffirmed a “buy” rating on shares of NVIDIA in a research note on Tuesday, September 23rd. TD Cowen lifted their price target on shares of NVIDIA from $140.00 to $235.00 and gave the company a “buy” rating in a report on Tuesday, August 19th. Finally, Craig Hallum lifted their price target on NVIDIA from $195.00 to $245.00 and gave the stock a “buy” rating in a research report on Thursday, August 28th. Four analysts have rated the stock with a Strong Buy rating, thirty-six have given a Buy rating, four have given a Hold rating and one has issued a Sell rating to the company. According to data from MarketBeat, NVIDIA currently has an average rating of “Moderate Buy” and a consensus price target of $211.00.\n\nRead Our Latest Stock Analysis on NVDA\n\nAbout NVIDIA\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nFeatured Articles\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/02/seascape-capital-management-lowers-stake-in-nvidia-corporation-nvda/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "OpenAI Valuation Soars To $500 Bn In Private Share Sale: Reports",
      "content": null,
      "source": "International Business Times",
      "url": "https://www.ibtimes.com/openai-valuation-soars-500-bn-private-share-sale-reports-3785198",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "S&P 500 Gains & Losses Today: Buffett's Berkshire Buys; Fair Isaac Soars, Equifax Falls",
      "content": "Key Takeaways Shares of credit score Fair Isaac soared on Thursday, Oct. 2, 2025, as it said it would provide data more directly to lenders. Shares of competing credit bureaus lost ground.\n\n\n\nAn increase in cryptocurrency prices helped lift shares of crypto exchange operator Coinbase.\n\nShares of Occidental Petroleum fell as the company confirmed a deal to sell part of its business to Warren Buffett's Berkshire Hathaway.\n\nShares of a data analytics firm took off after the company said it would provide its consumer credit scores directly to firms that give credit reports to mortgage lenders. The move pressured the credit bureaus that also evaluate potential borrowers.\n\nMajor U.S. equities indexes ticked higher Thursday. Outperformance from materials and technology stocks offset declines in most sectors as investors continued to weigh the implications of a government shutdown. The S&P 500 added less than 0.1%, while the Dow and the Nasdaq were up 0.2% and 0.4%, respectively. See here to read Investopedia's full coverage of the day's trading.\n\nWarren Buffet's Berkshire Hathaway (BRK.A, BRK.B) confirmed a nearly $10 billion deal to acquire the petrochemical division of Occidental Petroleum (OXY). The transaction marks Berkshire's largest deal since 2022. Shares of Occidental Petroleum fell 7.3%, while Berkshire Hathaway shares posted fractional losses.\n\nFair Isaac (FICO) shares surged 18%, notching the top performance in the S&P 500, after the data analytics company said it would offer its FICO consumer credit scores directly to firms that sell consolidated credit reports to mortgage providers. The data provider said the move would reduce the reliance on the three nationwide credit bureaus, and shares of the credit bureaus moved lower. Equifax (EFX) shares were down 8.5%, falling the most of any S&P 500 stock, while TransUnion (TRU) shares dropped nearly 11%.\n\nThe prices of bitcoin (BTCUSD) and other major cryptocurrencies extended their recent revival. Shares of Coinbase Global (COIN), operator of the largest U.S. crypto exchange, jumped 7.5%, while of online brokerage Robinhood Markets (HOOD), which also offers crypto trading, added 4.1%. Robinhood CEO Vlad Tenev at a conference predicted that the \"tokenization\" of real-world assets, including stocks, would have a major impact on global financial markets.\n\nIntel (INTC) shares gained 3.8% in the wake of recent reports that Advanced Micro Devices (AMD) is in early talks to become a customer of Intel's foundry business. Intel stock has doubled in value since reaching its year-to-date low in April, boosted by a series of high-profile investments from Nvidia (NVDA), SoftBank (SFTBY), and the U.S. government.\n\nShares of the renewable energy provider AES Corp. (AES) sank 7%. The downturn reversed some of the gains posted in the previous session amid reports that Global Infrastructure Partners, owned by BlackRock (BLK), was in advanced negotiations about a potential acquisition of AES, which has signed deals with several tech firms to power artificial intelligence data centers.",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/s-and-p-500-gains-and-losses-today-buffett-s-berkshire-buys-fair-isaac-soars-equifax-falls-11823467",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Microsoft Bets $33 Billion on Neoclouds like Nebius to Ease AI Crunch",
      "content": "Microsoft Corp.’s deal with neocloud company Nebius Group NV will provide computing power to internal teams creating large language models and a consumer AI assistant, according to people familiar with the situation.\n\nThe arrangement, which is worth as much as $19.4 billion, sparked a rally in Nebius shares when it was outlined Sept. 8, but the announcement was short on specifics. As part of the deal, Microsoft will get access to more than 100,000 of Nvidia Corp.’s latest GB300 chips, said the people, who requested anonymity to discuss an internal matter.\n\nMost Read from Bloomberg\n\nThe strategy is aimed at coping with a shortage of AI data center capacity and letting Microsoft free up its own server farms to provide lucrative AI services to customers.\n\nThis is just one of a string of deals Microsoft has struck with so-called neoclouds — a new category of small infrastructure providers that lease out AI-focused computing power. Microsoft has inked more than $33 billion in commitments to such providers, including Nebius, CoreWeave Inc., Nscale and Lambda. The deals demonstrate the company’s growing willingness to use relative newcomers for important infrastructure.\n\nCloud vendors have generally operated their own data centers, but Microsoft is struggling to bring sufficient computing capacity online. Renting access to servers from neoclouds speeds things up since they have already solved logistical challenges including obtaining sufficient power and chips.\n\n“We are in very much land-grab mode in the AI space,” said Scott Guthrie, who leads Microsoft’s cloud efforts. “We’ve made the decision that we don’t want to be constrained in terms of capacity.”\n\nNebius shares were up about 5.5% at 10:17 a.m. in New York, while Microsoft was mostly unchanged. Nebius and the other neocloud firms declined to comment.\n\nThe advent of power-guzzling generative AI has put enormous strain on data center infrastructure. So Microsoft is freeing up capacity in its own data centers for cloud clients by running some computing for internal and OpenAI work at neocloud facilities, Guthrie said.\n\nFor example, the first foundation AI models built under consumer AI chief Mustafa Suleyman were trained at a CoreWeave data center near Portland, Oregon, according to people familiar with the work.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/microsoft-bets-33-billion-neoclouds-100000431.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "AI stock rally: OpenAI valuation lifts Nvidia, AMD, Intel & more",
      "content": "00:00 Speaker A\n\nAnd Brooke, I want to start with you on just the gains that we're seeing in the AI trade. What's the biggest sectors, the biggest names that are really bouncing off of this open AI news?\n\n00:10 Brooke\n\nYeah, now that we heard more about open AI's valuation, we are seeing this renewed optimism when it comes to the AI tech trade that we saw really over the summer. Following AI announcing this this valuation, or rather, you know, we're getting this report. We are seeing on the flip side, Samsung electronics as well as SK Heynex, also seeing those stocks move higher this morning, as you could see right now.\n\n00:32 Brooke\n\nThey both signed letters of intent to really supply memory chips for open AI's data centers. So once again, this renewed optimism around what exactly open AI could bring to the table. Of course, it is still a private company, but we see both of these, these letter of intense really causing both socks to rally this morning.\n\n00:46 Brooke\n\nIn addition to that, we have other news around AI, really driving some momentum behind trades we haven't seen in a while. Speaking of AMD's a top trending ticker on Yahoo Finance's platform this morning, and that's basically because Intel is in talks to add AMD as a customer. So we are seeing some momentum there this morning, up about 3% in extended hours trading.\n\n01:06 Brooke\n\nUm, you know, and also too, I do want to point out that Qualcomm, they shifted their chips to Arm holding after a litigation with Arm. We now are seeing some momentum there. In addition to that, Nvidia, there was some skepticism about that 100 billion dollar deal in open AI and the and the circular nature of it. But now based upon this fact that we are getting this higher valuation than expected around open AI. We are seeing Nvidia move higher yet again this morning. And so all of these are really driving momentum behind that AI trade that we haven't seen in some quite some time.\n\n01:39 Speaker A\n\nAnd clearly investors are optimistic here. We have stocks at record highs. You were just running through some of those tech names. But we do have some Wall Street watchers that are warning of frothiness, of overexuberance. What is the street saying? Are these valuations justified?\n\n01:55 Brooke\n\nYeah, what we're hearing right now is there's a few different factors going into what could lead the momentum to those record S&P 500 targets by year end. You know, we did see the S&P 500 cross that 6700 mark just yesterday at market close. But now what we're hearing, particularly from a UBS strategist, sort of saying, look beyond AI technologies, look into autonomous systems, look into humanoids, think beyond the AI picture.\n\n02:20 Brooke\n\nas really what this is all going to come down to is what exactly we see these Q3 earnings report, you know, come out essentially to be. If they do yet again beat Wall Street's expectations. On top of that, you have to take into consideration that there's now nearly 100% chance that the Fed will cut interest rates especially amid this backdrop where we do have the shutdown and limited data going into the October 29th meeting.\n\n02:44 Brooke\n\nAnd all of this in addition, when we are seeing potentially higher yields getting attention there, that could drive investors out of the equity market and into yields. And so there's multiple different factors at play, but we have heard from multiple firms over the past month that they did raise their S&P 500 target for year end.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/ai-stock-rally-openai-valuation-133157224.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Boom Or Bubble: How Long Can The AI Investment Craze Last?",
      "content": null,
      "source": "International Business Times",
      "url": "https://www.ibtimes.com/boom-bubble-how-long-can-ai-investment-craze-last-3785275",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "People Are Making AI Videos of Sam Altman Stealing Content on Sora 2",
      "content": "A new feature on OpenAI’s video generator Sora 2 called ‘Cameo’ is allowing users to make videos of CEO Sam Altman stealing content and GPUs.\n\nThe Cameo feature allows users to insert themselves or others into AI-generated videos. However, the person wanting to appear in the video must first verify that they are granting their likeness by uploading a short video and audio recording of themselves to OpenAI.\n\nCEO Sam Altman — who appeared prominently in the marketing for Sora 2 — has perhaps unwisely allowed his likeness to be used by anyone on the app. That has given users the chance to make embarrassing videos of Altman.\n\nI love Sora 2 Sam Altman must love this too pic.twitter.com/YexwVEoBKQ — Adyseus (@Adyseku) October 1, 2025\n\nSome of them, such as the above video of Altman pretending to be a cat, are fairly innocuous and good-natured. However, others allude to what many people see as OpenAI’s practice of illegally appropriating content to build its AI models.\n\ni have the most liked video on sora 2 right now, i will be enjoying this short moment while it lasts cctv footage of sam stealing gpus at target for sora inference pic.twitter.com/B86qzUGlMq — gabriel (@GabrielPeterss4) September 30, 2025\n\nA bunch of videos showing Altman stealing GPUs appeared immediately on the new Sora app. Sora developer Gabriel Petersson says that he has the “most liked video on Sora 2” for his AI-generated CCTV footage showing Altman shoplifting GPUs at Target.\n\nLmao, Sam Altman stealing art from Miyazaki in the Studio Ghibli HQ. Sora 2 is wilddddddd. pic.twitter.com/qzhfMs0A2t — PJ Ace (@PJaccetturo) October 1, 2025\n\nHowever, a video showing Altman “stealing art from [Hayao] Miyazaki in the Studio Ghibli HQ” is more pertinent to IP creators. OpenAI has long been accused of infringing the rights of artists to build its AI models, a practice it says is fair use.\n\nMiyazaki, co-founder of Studio Ghibli, famously had a strong distaste for AI-generated content. When he was first shown the technology, he said he was “utterly disgusted,” echoing the sentiments of many photographers and artists.\n\n“I would never wish to incorporate this technology in my work at all. I strongly feel this is an insult to life itself,” Miyazaki said.\n\nSo when ChatGPT’s AI image generator sparked a trend that saw people turn their photos into Studio Ghibli-style images, Miyazaki must have been appalled.",
      "source": "PetaPixel",
      "url": "https://petapixel.com/2025/10/02/people-are-making-ai-videos-of-sam-altman-stealing-content-on-sora-2/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Job losses might be likely due to AI but Nvidia's CEO says the booming billion-dollar industry will always need more plumbers and electricians",
      "content": "The explosion of generative AI over the last few years signals a change in the job market alongside it, and this brings with it worries of job instability and losses. With big players like Nvidia, Meta, X, and the governments worldwide further committing to AI, questions are posed to those at the very top.\n\nIn a recent interview with the British news channel, Channel 4, Nvidia's CEO Jensun Huang, gave his thoughts on what's next. He says, \"If you're an electrician, if you're a plumber, if you're a carpenter, we're going to need hundreds of thousands of them. To build all of these factories.\"\n\nHuang argues, \"The skilled craft segment of every economy is going to boom\".\n\n\"You're going to have to build. You're going to keep doubling and doubling… every single year.\"\n\nJust last week, Nvidia shared plans to spend $100 billion on OpenAI. This cash is intended to go towards greater supplies of data centre chips, to further train upcoming AI models. Just weeks before that, Nvidia's earnings report showed it made almost 10 times more from AI than gaming. Nvidia's stock price is also at an all-time high, over 10 times what it was half a decade ago.\n\n@c4news CEO of US chip giant Nvidia, Jensen Huang, tells Channel 4 News, that ‘electricians and plumbers’ will be the big winners in the AI race as the skilled craft segment of every economy is going to see a 'boom'. #Tech #AI #Nvidia #Economy #C4News ♬ original sound - Channel 4 News\n\nOpenAI's spending has also skyrocketed, alongside ChatGPT's popularity, and the US government is firmly behind cementing \"US dominance in artificial intelligence\". From a PC gaming perspective, we've even seen brands like Razer jump on the AI bandwagon. This is all to say AI doesn't appear to be going away, and it has backing in the hundreds of billions.\n\n(Image credit: Nvidia)\n\nWhen asked what could happen if the UK doesn't 'grasp this opportunity', Huang says, \"just as the last industrial revolution, the reason why it came about was because you needed it. And so the industrial revolution that started here in the UK came out of need. You need it now, too.\"\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nEarlier this year, the UK's Department for Science, Innovation and Technology signed an agreement with OpenAI to push the chatbot into the public sector in a further bid to make the UK an AI powerhouse.\n\nThough highlighting future employment seems relevant to current fears around the job market, this doesn't address those who have degrees and experience in fields being replaced. Senator Bernie Sanders argued in June that \"Artificial intelligence is going to displace millions and millions of workers\". A month after this, OpenAI's Sam Altman shared that he thinks some jobs will be \"totally, totally gone\" due to AI. A former Google executive in August argued AI will lead to a \"short-term dystopia\" because it will struggle to create new jobs for those it is replacing.\n\nHuang tells reporters, \"You're going to be building out AI infrastructure here in the UK for a decade,\" but it's not clear what the plan is for workers after that.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/job-losses-might-be-likely-due-to-ai-but-nvidias-ceo-says-the-booming-billion-dollar-industry-will-always-need-more-plumbers-and-electricians/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "OpenAI Is World's Top Startup With $500B Valuation After Employee Share Sale",
      "content": "KEY TAKEAWAYS OpenAI has reportedly finalized a secondary share sale that values the artificial intelligence company at $500 billion.\n\nAt that level, OpenAI's valuation overtakes that of SpaceX, Elon Musk's rocket and satellite-internet company.\n\n\n\nOpenAI has reportedly finalized a secondary share sale that values the artificial intelligence company at $500 billion, making the ChatGPT owner the world's most valuable startup ever.\n\nThe share sale, which allows employees to cash out, comes just months after OpenAI CEO Sam Altman said that Meta Platforms (META) was poaching the company's AI staff with signing bonuses as high as $100 million.\n\nWhy This Matters OpenAI's sky-high valuation suggests investor demand for AI plays, which has helped propel the major U.S. equities indexes to record highs, remains strong.\n\nAccording to Bloomberg, OpenAI's current and former employees sold about $6.6 billion in stock in a deal that has has vaulted the company past Elon Musk’s SpaceX to become the world’s largest startup. OpenAI had a $300 billion valuation earlier this year. Rocket company SpaceX is valued at $400 billion, Bloomberg said.\n\nInvestors that bought into the secondary share sale—where investors buy from other investors rather than the company—included Japan's SoftBank, which put forth $30 billion in a funding round earlier this year. Thrive Capital, Dragoneer Investment Group, Abu Dhabi’s MGX, and T. Rowe Price also snapped up shares, the report said.\n\nOpenAI, which is backed by Microsoft (MSFT), is the latest of a string of AI startups to have seen valuations soar as investors are eager for exposure ahead of potential market entries. Nvidia (NVDA) also said last month that it plans to invest up to $100 billion in OpenAI to build out AI data centers. Nvidia, the chipmaker at the heart of the AI boom, has a market capitalization of well over $4 trillion, making it the world's most valuable publicly listed company.\n\nOpenAI didn't immediately respond to an Investopedia request for comment.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/openai-is-worlds-top-startup-with-500b-valuation-after-employee-share-sale-11822885",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "OpenAI Secures Samsung and SK Partnership for Stargate Data Centers",
      "content": "When we think of AI data centers, we think of the chips powering these machines. Now, companies like NVIDIA are a huge supplier when it comes to AI, but we shouldn’t forget that in a computer, there’s more to it than just the CPU or GPU. Components like RAM play a crucial role too. In an announcement on the OpenAI website, the company has revealed a new partnership with Samsung and SK for memory chips.\n\nOpenAI partners with Samsung and SK for memory chips\n\nAccording to OpenAI, the partnership will focus on ramping up production of advanced memory chips for the Stargate project. If you’re not familiar, Stargate is OpenAI’s $500 billion AI infrastructure initiative that involves building massive data centers. The deal came together after OpenAI CEO Sam Altman met with South Korean President Lee Jae Myung and executives from Samsung and SK in Seoul.\n\nSamsung and SK Hynix are planning to produce up to 900,000 DRAM wafers per month specifically for Stargate and AI data centers. If that sounds like a lot, it is because it is. For context, that’s more than double what the industry currently produces in high-bandwidth memory chips. Some reports suggest this could eat up roughly 40% of total global DRAM output.\n\nGiven OpenAI’s growing popularity, it has managed to attract more than its fair share of big names in tech. Recently, NVIDIA said it would invest a whopping $100 billion into the company. It also plans to give them access to over 10 gigawatts of compute capacity. Oracle also signed a deal worth $300 billion in compute capacity to OpenAI over the next five years.\n\nBut OpenAI’s ambitions don’t stop there\n\nIn addition to working with Samsung and SK, there was a recent report that suggests OpenAI wants to work with TSMC and Foxconn. The report claims that OpenAI is interested in developing its own AI chips. This means that instead of relying on third-party companies, OpenAI wants to do it themselves.\n\nIt’s a smart play. Developing its own chips gives OpenAI greater control over both hardware and software. It’s a similar play we’re seeing from both Apple and Google. Both companies have developed their own software and hardware for their phones, allowing them to develop specific features while optimizing for both.",
      "source": "Android Headlines",
      "url": "https://www.androidheadlines.com/2025/10/openai-secures-samsung-and-sk-partnership-for-stargate-data-centers.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Telegram Wallet to Offer Tokenized US Stocks via Kraken and Backed Partnership",
      "content": null,
      "source": "Cryptonews",
      "url": "https://cryptonews.com/news/telegram-wallet-to-offer-tokenized-us-stocks-via-kraken-and-backed-partnership/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Why Google rebranded to Alphabet - and why it paid dividends",
      "content": "When Google rebranded to Alphabet on October 1, 2015, it was to make the sprawling array of Google-related ventures “cleaner and more accountable,” according to founders Sergey Brin and Larry Page.\n\nThe launch of the new holding company aimed to restructure the organisation and distinguish between distinct areas of the business - partly for investors, but also for customers.\n\n“As Sergey and I wrote in the original founders’ letter 11 years ago, ‘Google is not a conventional company. We do not intend to become one’,” Page wrote in a blog post at the time.\n\n“As part of that, we also said that you could expect us to make ‘smaller bets in areas that might seem very speculative or even strange when compared to our current businesses.’ From the start, we’ve always strived to do more, and to do important and meaningful things with the resources we have,” he added.\n\nWhy Alphabet?\n\nSo why ‘Alphabet’ of all names? According to Page, the name was chosen because it represented a “collection of letters that represent language, one of humanity’s most important innovations, and is at the core of how the index with Google Search”.\n\nBy this point, Google itself had indeed become a “collection” of companies operating under one umbrella – but it was less an alphabet and more of a cacophony of disparate enterprises.\n\nFrom its search and advertising business to YouTube or ventures like Waymo and DeepMind, it was becoming difficult to pin down exactly what the company did.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nMoreover, it’s grown since the rebranding, bringing on cybersecurity firm Mandiant and data analytics startup, Looker.\n\nUltimately, the rebrand enabled “more management scale,” Page noted back in 2015. In pursuing this approach, each individual cog in the expanding machine would remain well-oiled and maintained.\n\nAt the time of the rebrand, Alphabet was to be run by Page, Brin, and CFO Ruth Porat. Google, which included the search, YouTube, Chrome, and Android segments, was run by Sundar Pichai. Every other subsidiary also had its own chief executive.\n\nIn 2019, Pichai took the helm at Alphabet in addition to his role as chief executive at Google.\n\nA changing tech landscape\n\nLooking back, the rebrand not only shocked Silicon Valley, but also pointed toward the changing face of the global technology landscape. Google had its finger in an array of pies by this point, much like industry counterparts such as Microsoft.\n\nIt really wasn’t just Google anymore, and it was a move that certainly appears to have paid dividends. In the year prior to rebranding, the company was valued at $445 billion, with earnings reports showing it boasted revenues of $66 billion.\n\nBy September 2025, Alphabet had reached even loftier heights, joining the likes of Microsoft, Apple, and Nvidia with a valuation of over $3 trillion.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/why-google-rebranded-to-alphabet-and-why-it-paid-dividends",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "2 Monster Growth Stocks (1 Backed by Nvidia) to Buy Before They Soar 150% and 430%, According to a Wall Street Expert",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_752553fb-4790-457f-89cd-89a068ce0208",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Friday Financial Purchases 639 Shares of NVIDIA Corporation $NVDA",
      "content": "Friday Financial grew its position in NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 17.9% during the second quarter, according to the company in its most recent 13F filing with the SEC. The fund owned 4,211 shares of the computer hardware maker’s stock after purchasing an additional 639 shares during the quarter. Friday Financial’s holdings in NVIDIA were worth $665,000 as of its most recent filing with the SEC.\n\nOther institutional investors also recently modified their holdings of the company. Kingstone Capital Partners Texas LLC lifted its stake in shares of NVIDIA by 267,959.7% in the second quarter. Kingstone Capital Partners Texas LLC now owns 382,373,765 shares of the computer hardware maker’s stock valued at $64,976,521,000 after buying an additional 382,231,120 shares in the last quarter. Nuveen LLC purchased a new stake in shares of NVIDIA in the first quarter valued at about $15,089,414,000. Goldman Sachs Group Inc. raised its holdings in shares of NVIDIA by 123.5% in the first quarter. Goldman Sachs Group Inc. now owns 187,995,213 shares of the computer hardware maker’s stock valued at $20,374,921,000 after purchasing an additional 103,889,872 shares during the last quarter. GAMMA Investing LLC increased its holdings in NVIDIA by 12,173.2% during the first quarter. GAMMA Investing LLC now owns 48,837,781 shares of the computer hardware maker’s stock worth $5,293,039,000 after buying an additional 48,439,859 shares during the last quarter. Finally, Assenagon Asset Management S.A. increased its holdings in NVIDIA by 204.6% during the first quarter. Assenagon Asset Management S.A. now owns 35,652,571 shares of the computer hardware maker’s stock worth $3,864,026,000 after buying an additional 23,948,733 shares during the last quarter. 65.27% of the stock is owned by institutional investors.\n\nGet NVIDIA alerts:\n\nNVIDIA Trading Up 0.4%\n\nNVDA stock opened at $187.24 on Thursday. The company has a market capitalization of $4.55 trillion, a PE ratio of 53.34, a price-to-earnings-growth ratio of 1.35 and a beta of 2.12. NVIDIA Corporation has a one year low of $86.62 and a one year high of $188.14. The company’s 50 day moving average price is $177.52 and its two-hundred day moving average price is $147.17. The company has a debt-to-equity ratio of 0.08, a quick ratio of 3.60 and a current ratio of 4.21.\n\nNVIDIA Announces Dividend\n\nNVIDIA ( NASDAQ:NVDA Get Free Report ) last posted its quarterly earnings results on Wednesday, August 27th. The computer hardware maker reported $1.05 EPS for the quarter, topping the consensus estimate of $1.01 by $0.04. The firm had revenue of $46.74 billion for the quarter, compared to the consensus estimate of $45.65 billion. NVIDIA had a net margin of 52.41% and a return on equity of 101.74%. The business’s revenue was up 55.6% compared to the same quarter last year. During the same period last year, the firm posted $0.68 earnings per share. NVIDIA has set its Q3 2026 guidance at EPS. As a group, analysts predict that NVIDIA Corporation will post 2.77 earnings per share for the current fiscal year.\n\nThe firm also recently declared a quarterly dividend, which will be paid on Thursday, October 2nd. Shareholders of record on Thursday, September 11th will be paid a dividend of $0.01 per share. The ex-dividend date of this dividend is Thursday, September 11th. This represents a $0.04 annualized dividend and a dividend yield of 0.0%. NVIDIA’s dividend payout ratio (DPR) is 1.14%.\n\nInsiders Place Their Bets\n\nIn other NVIDIA news, Director Mark A. Stevens sold 350,000 shares of NVIDIA stock in a transaction that occurred on Friday, September 19th. The shares were sold at an average price of $176.39, for a total transaction of $61,736,500.00. Following the transaction, the director directly owned 7,399,803 shares of the company’s stock, valued at approximately $1,305,251,251.17. This trade represents a 4.52% decrease in their ownership of the stock. The transaction was disclosed in a legal filing with the SEC, which can be accessed through this hyperlink. Also, CEO Jen Hsun Huang sold 75,000 shares of NVIDIA stock in a transaction on Monday, July 14th. The stock was sold at an average price of $164.36, for a total transaction of $12,327,000.00. Following the completion of the transaction, the chief executive officer directly owned 74,648,225 shares in the company, valued at approximately $12,269,182,261. The trade was a 0.10% decrease in their ownership of the stock. The disclosure for this sale can be found here. Over the last ninety days, insiders have sold 4,022,407 shares of company stock valued at $700,382,754. 4.17% of the stock is currently owned by corporate insiders.\n\nAnalyst Ratings Changes\n\nA number of equities analysts have weighed in on NVDA shares. New Street Research increased their target price on shares of NVIDIA from $200.00 to $235.00 and gave the stock a “buy” rating in a research report on Friday, September 12th. Oppenheimer reiterated an “outperform” rating and set a $225.00 target price (up previously from $200.00) on shares of NVIDIA in a research report on Thursday, August 28th. Mizuho raised their price objective on shares of NVIDIA from $192.00 to $205.00 and gave the company an “outperform” rating in a research report on Thursday, August 14th. Jefferies Financial Group restated a “buy” rating and issued a $220.00 price objective (up from $205.00) on shares of NVIDIA in a research report on Monday. Finally, Wall Street Zen upgraded shares of NVIDIA from a “hold” rating to a “buy” rating in a research report on Friday, September 5th. Four equities research analysts have rated the stock with a Strong Buy rating, thirty-six have issued a Buy rating, four have assigned a Hold rating and one has assigned a Sell rating to the stock. According to MarketBeat, NVIDIA has an average rating of “Moderate Buy” and a consensus price target of $211.00.\n\nGet Our Latest Analysis on NVDA\n\nAbout NVIDIA\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nFeatured Articles\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/02/friday-financial-purchases-639-shares-of-nvidia-corporation-nvda/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Bitcoin Could Hit $1 Million Because 'Governments Keep Printing Money Like No Tomorrow', Telegram CEO Says",
      "content": "Benzinga and Yahoo Finance LLC may earn commission or revenue on some items through the links below.\n\nTelegram CEO Pavel Durov said Bitcoin (CRYPTO: BTC) could reach $1 million, pointing to fiat money printing and the cryptocurrency's fixed supply as BTC spiked to $116,500 on Wednesday morning.\n\nDurov's $1M Bitcoin Call\n\nIn an interview clip from a podcast with Lex Fridman shared on X, Durov reiterated his long-standing belief in Bitcoin, saying governments “keep printing money like no tomorrow” yet “nobody is printing Bitcoin.”\n\nHe added that the fixed issuance makes the asset the \"ultimate means of exchange\" because it cannot be censored or confiscated.\n\nBitcoin Breaks Resistance With Bulls Targeting $130,000\n\nBTC Price Dynamics (Source: TradingView)\n\nTrending: If there was a new fund backed by Jeff Bezos offering a 7-9% target yield with monthly dividends would you invest in it?\n\nBitcoin's daily chart shows a breakout above descending triangle resistance, with Fibonacci retracements at $113,900 and $116,900 now in focus.\n\nThe RSI has risen to 58.9, while all major EMAs (20, 50, 100, 200) are positioned below price between $112,000 and $113,500, creating a strong support cluster.\n\nNear-term resistance stands at $120,800 and $124,500, with scope for an extension toward $130,000–135,000 if momentum holds.\n\nOn the downside, failure to sustain above $114,000 would raise the risk of a retest at $110,000–108,000.\n\nDerivatives And On-Chain Flows Show Confidence\n\nBTC Derivative Analysis (Source: Coinglass)\n\nSee Also: 7 Million Gamers Already Trust Gameflip With Their Digital Assets — Now You Can Own a Stake in the Platform\n\nFutures open interest rose 5% to $84.3 billion alongside a 15.7% jump in trading volume, while Binance top traders' long/short ratio climbed to 1.53.\n\nLiquidations added fuel, with shorts losing $145 million in 24 hours compared to $20M from longs.\n\nBTC Netflows (Source: Coinglass)\n\nSpot flows also turned positive, with $190 million in net outflows on Sep. 30 as coins moved off exchanges into long-term storage.\n\nSmaller outflows today reflect consolidation, not reversal, keeping supply pressure tilted bullish.\n\nUptober History Backs Bitcoin's Rally Momentum\n\nOctober has historically been one of Bitcoin's strongest months, averaging +20% returns since 2013 with gains in nine of the last 12 years.\n\nCombined with positive technicals and renewed on-chain accumulation, the seasonal trend reinforces the current rally narrative.\n\nImage: Shutterstock\n\nTrending Now:",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/bitcoin-could-hit-1-million-033113682.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Recession Odds 'Not At 0%,' Says Economist As Small And Medium Businesses Drive Job Losses In ADP Report Amid BLS Shutdown",
      "content": "Benzinga and Yahoo Finance LLC may earn commission or revenue on some items through the links below.\n\nA surprisingly weak private-sector ADP Employment report, released during an ongoing government shutdown, has intensified fears of a looming economic downturn.\n\nEconomist Warns Recession Odds Are Not At 0% Level\n\nU.S. private payrolls unexpectedly shed 32,000 jobs in September, a stark reversal from consensus expectations of a 51,000 gain. The losses were driven entirely by small and medium-sized businesses, painting a troubling picture of the U.S. economy.\n\nTrending: If there was a new fund backed by Jeff Bezos offering a 7-9% target yield with monthly dividends would you invest in it?\n\nWith the Bureau of Labor Statistics (BLS) suspending its data releases, the ADP report has taken on “outsize influence,” according to Bill Adams, Chief Economist for Comerica Bank. The bleak numbers prompted economist David Rosenberg, the founder and president of Rosenberg Research & Associates Inc., to post on X that “recession odds are not at the 0% level that equity and credit markets have been discounting.”\n\n\n\n\n\nSmall And Medium-Sized Establishments Shed Jobs\n\nThe weakness was concentrated among smaller firms. According to the ADP report, small establishments (1-49 employees) lost 40,000 jobs, while medium-sized firms (50-499 employees) cut 20,000 positions. In contrast, large businesses with over 500 employees added 33,000 jobs, highlighting a growing divergence in the labor market.\n\nCompounding the negative outlook was a massive downward revision to the prior month’s data. August's figures were revised from a 54,000 job gain to a 3,000 job loss, a swing Rosenberg called a “huge downward revision.” After revisions, ADP’s data now shows that private sector employment has fallen in three of the last four months.\n\nSee Also: 7 Million Gamers Already Trust Gameflip With Their Digital Assets — Now You Can Own a Stake in the Platform\n\nFederal Reserve Could Continue The Rate-Cutting Cycle\n\nThe report is expected to put significant pressure on the Federal Reserve to ease monetary policy. Adams noted that the weak report “makes the Fed more likely to cut the federal funds target another quarter percent at their October meeting.”",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/recession-odds-not-0-says-013008131.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "NVIDIA’s ‘Ambitious’ Plans to Build a Taiwan HQ Reportedly Stalled by Political Disputes & Ownership Concerns",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/nvidia-ambitious-plans-to-develop-a-hq-in-taiwan-has-come-to-a-stall/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "NVIDIA Corporation $NVDA Shares Bought by CHICAGO TRUST Co NA",
      "content": "CHICAGO TRUST Co NA lifted its position in shares of NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 4.3% during the second quarter, HoldingsChannel reports. The fund owned 150,120 shares of the computer hardware maker’s stock after acquiring an additional 6,217 shares during the quarter. NVIDIA comprises 3.3% of CHICAGO TRUST Co NA’s holdings, making the stock its 5th biggest position. CHICAGO TRUST Co NA’s holdings in NVIDIA were worth $23,717,000 at the end of the most recent reporting period.\n\nOther hedge funds have also recently added to or reduced their stakes in the company. Kingstone Capital Partners Texas LLC lifted its position in shares of NVIDIA by 267,959.7% during the 2nd quarter. Kingstone Capital Partners Texas LLC now owns 382,373,765 shares of the computer hardware maker’s stock valued at $64,976,521,000 after acquiring an additional 382,231,120 shares during the period. Nuveen LLC purchased a new position in NVIDIA in the 1st quarter valued at approximately $15,089,414,000. Goldman Sachs Group Inc. raised its holdings in NVIDIA by 123.5% during the first quarter. Goldman Sachs Group Inc. now owns 187,995,213 shares of the computer hardware maker’s stock worth $20,374,921,000 after purchasing an additional 103,889,872 shares during the last quarter. GAMMA Investing LLC boosted its position in NVIDIA by 12,173.2% during the first quarter. GAMMA Investing LLC now owns 48,837,781 shares of the computer hardware maker’s stock worth $5,293,039,000 after purchasing an additional 48,439,859 shares in the last quarter. Finally, Assenagon Asset Management S.A. grew its holdings in NVIDIA by 204.6% in the first quarter. Assenagon Asset Management S.A. now owns 35,652,571 shares of the computer hardware maker’s stock valued at $3,864,026,000 after purchasing an additional 23,948,733 shares during the last quarter. Institutional investors and hedge funds own 65.27% of the company’s stock.\n\nGet NVIDIA alerts:\n\nNVIDIA Price Performance\n\nShares of NVIDIA stock opened at $188.89 on Friday. The business’s fifty day moving average price is $177.83 and its 200 day moving average price is $147.65. NVIDIA Corporation has a twelve month low of $86.62 and a twelve month high of $191.05. The company has a current ratio of 4.21, a quick ratio of 3.60 and a debt-to-equity ratio of 0.08. The stock has a market capitalization of $4.59 trillion, a P/E ratio of 53.81, a PEG ratio of 1.35 and a beta of 2.12.\n\nNVIDIA Dividend Announcement\n\nNVIDIA ( NASDAQ:NVDA Get Free Report ) last released its quarterly earnings data on Wednesday, August 27th. The computer hardware maker reported $1.05 earnings per share for the quarter, beating the consensus estimate of $1.01 by $0.04. NVIDIA had a return on equity of 101.74% and a net margin of 52.41%.The business had revenue of $46.74 billion for the quarter, compared to analyst estimates of $45.65 billion. During the same period in the previous year, the company posted $0.68 EPS. The company’s revenue was up 55.6% compared to the same quarter last year. NVIDIA has set its Q3 2026 guidance at EPS. As a group, research analysts anticipate that NVIDIA Corporation will post 2.77 earnings per share for the current year.\n\nThe firm also recently disclosed a quarterly dividend, which was paid on Thursday, October 2nd. Stockholders of record on Thursday, September 11th were given a $0.01 dividend. The ex-dividend date of this dividend was Thursday, September 11th. This represents a $0.04 annualized dividend and a dividend yield of 0.0%. NVIDIA’s dividend payout ratio is presently 1.14%.\n\nInsider Activity\n\nIn other NVIDIA news, Director Mark A. Stevens sold 350,000 shares of the business’s stock in a transaction dated Friday, September 19th. The stock was sold at an average price of $176.39, for a total transaction of $61,736,500.00. Following the transaction, the director owned 7,399,803 shares in the company, valued at $1,305,251,251.17. The trade was a 4.52% decrease in their ownership of the stock. The sale was disclosed in a document filed with the SEC, which is available through this hyperlink. Also, CEO Jen Hsun Huang sold 75,000 shares of the company’s stock in a transaction dated Monday, July 14th. The stock was sold at an average price of $164.36, for a total value of $12,327,000.00. Following the completion of the sale, the chief executive officer directly owned 74,648,225 shares of the company’s stock, valued at $12,269,182,261. The trade was a 0.10% decrease in their position. The disclosure for this sale can be found here. In the last 90 days, insiders have sold 4,097,407 shares of company stock valued at $714,378,504. Company insiders own 4.17% of the company’s stock.\n\nWall Street Analysts Forecast Growth\n\nSeveral research analysts have recently issued reports on the company. Wall Street Zen raised NVIDIA from a “hold” rating to a “buy” rating in a research note on Friday, September 5th. Wells Fargo & Company lifted their target price on shares of NVIDIA from $185.00 to $220.00 and gave the stock an “overweight” rating in a research report on Monday, August 11th. Loop Capital increased their price target on shares of NVIDIA from $175.00 to $250.00 and gave the company a “buy” rating in a research report on Wednesday, June 25th. Wolfe Research raised their price objective on shares of NVIDIA from $220.00 to $230.00 in a research note on Tuesday, September 23rd. Finally, Bank of America upped their target price on NVIDIA from $220.00 to $235.00 and gave the company a “buy” rating in a research note on Thursday, August 28th. Four analysts have rated the stock with a Strong Buy rating, thirty-six have given a Buy rating, four have given a Hold rating and one has given a Sell rating to the company. According to data from MarketBeat, NVIDIA presently has a consensus rating of “Moderate Buy” and an average price target of $211.00.\n\nGet Our Latest Research Report on NVIDIA\n\nNVIDIA Profile\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nFurther Reading\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/03/nvidia-corporation-nvda-shares-bought-by-chicago-trust-co-na/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Novice Investor’s Digest For Friday, October 3: Stock Prices Remain Strong",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/catherinebrock/2025/10/03/novice-investors-digest-for-friday-october-3-stock-prices-remain-strong/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Nvidia and Fujitsu agree to work together on AI robots and other technology",
      "content": "TOKYO (AP) — U.S. technology company Nvidia (NVDA) and Fujitsu (6702.T), a Japanese telecommunications and computer maker, agreed Friday to work together on artificial intelligence to deliver smart robots and a variety of other innovations using Nvidia's computer chips.\n\n“The AI industrial revolution has already begun. Building the infrastructure to power it is essential in Japan and around the world,” Nvidia Chief Executive Jensen Huang said, hugging his Fujitsu counterpart Takahito Tokita on stage.\n\nFujitsu stock closed 3% up on Friday.\n\n“Japan can lead the world in AI and robotics,” Huang told reporters at a Tokyo hotel.\n\nThe companies will work together on building what they called “an AI infrastructure,” or the system on which the various futuristic AI uses will be based, including health care, manufacturing, the environment, next-generation computing and customer services. The hope is to establish that AI infrastructure for Japan by 2030.\n\nIt initially will be tailored for the Japanese market, leveraging Fujitsu’s decades-long experience here, but may later expand globally, and will utilize Nvidia’s GPUs, or graphics processing units, which are essential for AI, according to both sides.\n\nThe two executives did not outline specific projects or give a monetary figure for planned investments. But exploring a collaboration in AI for robots with Yaskawa Electric Corp., a Japanese machinery and robot maker, was noted as a possible example. AI will be constantly evolving and learning, they said.\n\nFujitsu and Nvidia have been working together on AI, speeding up manufacturing with digital twins and robotics to tackle aging Japan’s labor shortages.\n\nTokita said the companies were taking a “humancentric” approach aimed at keeping Japan competitive.\n\n“Through our collaboration with Nvidia, we aim to create new, unprecedented technologies and contribute to solving even more serious social issues,” said Tokita.\n\nSign up for Yahoo Finance's Week in Tech Subscribe By subscribing, you are agreeing to Yahoo's Terms and Privacy Policy\n\n___\n\nYuri Kageyama is on Threads: https://www.threads.com/@yurikageyama",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-fujitsu-agree-together-ai-073114124.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "2025.40: The AI Slop Era Arrives",
      "content": "This Week in Stratechery\n\nWelcome back to This Week in Stratechery!\n\nAs a reminder, each week, every Friday, we’re sending out this overview of content in the Stratechery bundle; highlighted links are free for everyone. Additionally, you have complete control over what we send to you. If you don’t want to receive This Week in Stratechery emails (there is no podcast), please uncheck the box in your delivery settings.\n\nOn that note, here were a few of our favorites this week.\n\nThe AI Slop Era Arrives. I wrote about MetaAI Vibes on Monday, and Sora on Wednesday. DON’T READ EITHER OF THEM. Instead, listen to this week’s episode of Sharp Tech, where I dig deep to understand why my takes were wrong, and what that means for not just the future of AI (and OpenAI), but also the suddenly significant problems facing Meta. — Ben Thompson\n\n\n\n\n\nWhat “China Hawk” Really Means. This week’s episode of Sharp China is outside the paywall, dense with information and full of overlap with the tech world . Topics include the maddening details on the proposed TikTok sale, the launch of a Chinese visa program to attract foreign tech talent, a very interesting Xi rumor in advance of the fourth plenum later this month, and a new effort to target subsidiaries of companies that have been added to the entity list by the U.S. government. In addition to all that, we discussed recent comments from Jensen Huang on the US and China, in which the Nvidia CEO said the label “China Hawk” should be a “badge of shame.” For his part, Bill explained why Huang may come to regret those comments as bipartisan Nvidia resentment builds in Washington. And for mine, I found the comments strikingly out of step with the reality of who “China hawks” are, what they’re trying to achieve, and the proximate cause of alarm among folks with security clearances. — Andrew Sharp\n\n\n\nSteve Ballmer and the Clippers Catastrophe. Greatest of All Talk published its 600th episode this week and celebrated with an extended look at the Clippers, who have been stars (villains?) of the NBA offseason thanks to allegations that owner Steve Ballmer used a now-bankrupt green fintech company to circumvent the salary cap to pay superstar Kawhi Leonard. My co-host Ben Golliver was at Clippers media day in L.A. this week, where everyone involved stridently denied the allegations. That led to thoughts on the likely next steps in this farcical affair, along with big picture questions about the Clippers’ standing in the NBA and comps to Ballmer’s time at Microsoft. Come for that substance, and stay for another hour reveling in media days elsewhere in the NBA. Stratechery subscribers can access every episode of the GOAT (we’ve already recorded episode 601), and it’s going to be a great new season. — AS\n\nStratechery Articles and Updates\n\nDithering with Ben Thompson and Daring Fireball’s John Gruber\n\nAsianometry with Jon Yu\n\nSharp China with Andrew Sharp and Sinocism’s Bill Bishop\n\nGreatest of All Talk with Andrew Sharp and WaPo’s Ben Golliver\n\nSharp Tech with Andrew Sharp and Ben Thompson\n\nThis week’s Sharp Tech video is an instant reaction to the new Meta AI app.",
      "source": "Stratechery.com",
      "url": "https://stratechery.com/2025/the-ai-slop-era-arrives/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "$200 Billion Chip Frenzy: AI Mania Sends Stocks Into Overdrive",
      "content": "This article first appeared on GuruFocus.\n\nGlobal chipmakers have ignited a fresh wave of investor euphoria, with more than $200 billion added to their combined market value in just one session. The latest surge came as OpenAI secured a record $500 billion valuation through an employee share sale, alongside agreements with South Korean semiconductor producers. Reports that Intel (NASDAQ:INTC) may look to Advanced Micro Devices (NASDAQ:AMD) as a customer added further fuel, underscoring how deeply artificial intelligence has embedded itself into the sector's growth narrative. Investors continue to chase exposure to chip leaders such as Nvidia, SK Hynix, and Samsung, sending both the Philadelphia Semiconductor Index and Asia's chip benchmark toward historic highs.\n\nThe rally has been particularly striking in Asia and Europe. SK Hynix (HXSCL) shares soared 10% while Samsung Electronics advanced 3.5%, pushing South Korea's Kospi Index to record levels. In Europe, ASML gained nearly 5% on Thursday, extending a rebound that now totals almost 50% since August. Analysts suggest the current pace is being driven less by fundamentals and more by fear of missing out, with valuations reflecting the frenzyBloomberg's Asia chip gauge now trades at 19 times forward earnings while the SOX Index stands at 27 times, approaching peaks seen in 2024. Market strategists note that upcoming fourth-quarter results could act as a turning point, forcing investors to reassess whether the momentum can hold.\n\nChina has added its own layer of strength to the rally, with government support, Alibaba's (NYSE:BABA) stepped-up AI spending, and Huawei's three-year plan to erode Nvidia's (NASDAQ:NVDA) dominance all boosting sentiment. The Hang Seng Tech Index has surged nearly 50% year-to-date on the back of these developments. OpenAI's Sam Altman is expected in Taipei for meetings with Taiwan Semiconductor Manufacturing Co. (NYSE:TSM) and Hon Hai, lifting their shares further. While concerns linger that revenues have yet to catch up with the extraordinary capital deployed into AI infrastructure, many investors remain convinced that the sector's upside could extend into next year, with momentum still firmly in place.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/200-billion-chip-frenzy-ai-051826508.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Meet Moore Threads: how former Nvidia vice-president created a Chinese GPU star",
      "content": "Moore Threads Technology, a Chinese graphics processing unit (GPU) start-up founded by a veteran of Nvidia's China operations, has become one of the most closely watched semiconductor players in the country, as domestic AI chip designers race to displace the US chip giant.\n\nThe Beijing-based company last week received approval from the Shanghai Stock Exchange for an initial public offering (IPO). It took just 88 days from filing the application in June to receive approval, making it one of the fastest cases to get the green light to list on the Nasdaq-style Star Market.\n\nThe hastened timetable was the latest sign of how China is doubling down on efforts to achieve self-sufficiency in the chips that provide the computing power needed for the development of AI models, as the US-China tech war intensifies and casts a shadow over Nvidia's future sales in the country.\n\nDo you have questions about the biggest topics and trends from around the world? Get the answers with SCMP Knowledge, our new platform of curated content with explainers, FAQs, analyses and infographics brought to you by our award-winning team.\n\n\"Moore Threads' rapid IPO process reflects that the domestic GPU industry is entering a critical period,\" said Zhang Xinyuan, an analyst from Beijing-based think tank Kefangde.\n\nThe listing, in which Moore Threads expected to raise 8 billion yuan (US$1.12 billion), would significantly accelerate the large-scale commercialisation of the company's GPUs, Zhang added.\n\nMoore Threads displayed its MCCX D800 AI server at the World Artificial Intelligence Conference in Shanghai, July 5, 2024. Photo: SCMP alt=Moore Threads displayed its MCCX D800 AI server at the World Artificial Intelligence Conference in Shanghai, July 5, 2024. Photo: SCMP>\n\nBehind the Moore Threads' story is James Zhang Jianzhong, its founder and CEO, who previously spent 14 years working for Nvidia. He was vice-president at Nvidia and general manager of its China operations before leaving in 2020 to start his company.\n\nZhang, a computer science graduate from Nanjing University of Science and Technology, joined Nvidia in 2005 and was credited with helping it expand in the mainland market over the years. Before Nvidia, he worked for US tech companies including HP and Dell.\n\nZhang's pedigree also gave Moore Threads immediate credibility. Many of the start-up's early recruits came from Nvidia and its US rival Advanced Micro Devices. The company also attracted marquee investors including GGV, Sequoia China, ByteDance and Tencent Holdings.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/meet-moore-threads-former-nvidia-093000383.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Walmart turns to Google to solve longtime customer headache",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/retail/walmart-turns-to-google-to-solve-longtime-customer-headache",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Magnificence beyond the Magnificent 7? Here’s the next generation of AI winners powering the stock market.",
      "content": null,
      "source": "MarketWatch",
      "url": "https://www.marketwatch.com/story/magnificence-beyond-the-magnificent-7-heres-the-next-generation-of-ai-winners-powering-the-stock-market-c87e9e66",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "NVIDIA Corporation $NVDA Stake Boosted by Bfsg LLC",
      "content": "Bfsg LLC boosted its stake in NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 3.6% in the 2nd quarter, HoldingsChannel.com reports. The institutional investor owned 177,533 shares of the computer hardware maker’s stock after buying an additional 6,192 shares during the quarter. NVIDIA comprises 3.1% of Bfsg LLC’s holdings, making the stock its 3rd largest holding. Bfsg LLC’s holdings in NVIDIA were worth $28,048,000 at the end of the most recent reporting period.\n\nSeveral other large investors have also bought and sold shares of NVDA. Kathleen S. Wright Associates Inc. grew its position in shares of NVIDIA by 169.3% in the 1st quarter. Kathleen S. Wright Associates Inc. now owns 404 shares of the computer hardware maker’s stock worth $44,000 after buying an additional 254 shares during the period. Copia Wealth Management bought a new stake in NVIDIA during the fourth quarter worth about $50,000. Barnes Dennig Private Wealth Management LLC purchased a new stake in NVIDIA in the first quarter worth about $51,000. Bruce G. Allen Investments LLC increased its stake in shares of NVIDIA by 198.2% during the first quarter. Bruce G. Allen Investments LLC now owns 492 shares of the computer hardware maker’s stock valued at $53,000 after purchasing an additional 327 shares in the last quarter. Finally, Campbell Capital Management Inc. lifted its holdings in shares of NVIDIA by 5,900.0% during the first quarter. Campbell Capital Management Inc. now owns 600 shares of the computer hardware maker’s stock valued at $65,000 after purchasing an additional 590 shares during the last quarter. 65.27% of the stock is owned by institutional investors.\n\nGet NVIDIA alerts:\n\nNVIDIA Stock Up 0.9%\n\nNVDA stock opened at $188.89 on Friday. The company has a market cap of $4.59 trillion, a price-to-earnings ratio of 53.81, a P/E/G ratio of 1.35 and a beta of 2.12. The company has a debt-to-equity ratio of 0.08, a quick ratio of 3.60 and a current ratio of 4.21. The business’s 50-day moving average is $177.83 and its two-hundred day moving average is $147.65. NVIDIA Corporation has a fifty-two week low of $86.62 and a fifty-two week high of $191.05.\n\nNVIDIA Announces Dividend\n\nNVIDIA ( NASDAQ:NVDA Get Free Report ) last released its quarterly earnings results on Wednesday, August 27th. The computer hardware maker reported $1.05 EPS for the quarter, beating the consensus estimate of $1.01 by $0.04. The firm had revenue of $46.74 billion during the quarter, compared to analyst estimates of $45.65 billion. NVIDIA had a net margin of 52.41% and a return on equity of 101.74%. The business’s revenue for the quarter was up 55.6% compared to the same quarter last year. During the same quarter in the prior year, the firm earned $0.68 EPS. NVIDIA has set its Q3 2026 guidance at EPS. As a group, analysts forecast that NVIDIA Corporation will post 2.77 earnings per share for the current year.\n\nThe business also recently disclosed a quarterly dividend, which was paid on Thursday, October 2nd. Stockholders of record on Thursday, September 11th were paid a $0.01 dividend. This represents a $0.04 annualized dividend and a dividend yield of 0.0%. The ex-dividend date was Thursday, September 11th. NVIDIA’s dividend payout ratio is 1.14%.\n\nInsider Buying and Selling\n\nIn other news, CEO Jen Hsun Huang sold 75,000 shares of the firm’s stock in a transaction dated Wednesday, October 1st. The stock was sold at an average price of $186.61, for a total value of $13,995,750.00. Following the transaction, the chief executive officer owned 71,083,203 shares of the company’s stock, valued at $13,264,836,511.83. This trade represents a 0.11% decrease in their ownership of the stock. The transaction was disclosed in a filing with the Securities & Exchange Commission, which is available through this hyperlink. Also, CFO Colette Kress sold 30,500 shares of the business’s stock in a transaction that occurred on Friday, September 19th. The shares were sold at an average price of $176.40, for a total value of $5,380,200.00. Following the transaction, the chief financial officer owned 2,883,402 shares of the company’s stock, valued at approximately $508,632,112.80. This trade represents a 1.05% decrease in their ownership of the stock. The disclosure for this sale can be found here. Over the last quarter, insiders have sold 4,097,407 shares of company stock valued at $714,378,504. Company insiders own 4.17% of the company’s stock.\n\nWall Street Analyst Weigh In\n\nNVDA has been the topic of several recent research reports. Wells Fargo & Company upped their price target on NVIDIA from $185.00 to $220.00 and gave the stock an “overweight” rating in a research note on Monday, August 11th. New Street Research boosted their target price on NVIDIA from $200.00 to $235.00 and gave the stock a “buy” rating in a report on Friday, September 12th. Wedbush restated an “outperform” rating and set a $210.00 price target on shares of NVIDIA in a report on Thursday, August 28th. Craig Hallum upped their price target on shares of NVIDIA from $195.00 to $245.00 and gave the stock a “buy” rating in a research note on Thursday, August 28th. Finally, Barclays reissued an “overweight” rating and set a $240.00 price objective (up from $200.00) on shares of NVIDIA in a research report on Monday, September 22nd. Four analysts have rated the stock with a Strong Buy rating, thirty-six have issued a Buy rating, four have issued a Hold rating and one has assigned a Sell rating to the company’s stock. According to MarketBeat, NVIDIA presently has a consensus rating of “Moderate Buy” and a consensus price target of $211.00.\n\nGet Our Latest Stock Report on NVIDIA\n\nNVIDIA Profile\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nRecommended Stories\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/03/nvidia-corporation-nvda-stake-boosted-by-bfsg-llc/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Nvidia CEO Jensen Huang Reportedly Frustrated As Trump's Commerce Secretary Slows UAE Chips Deal Over China Link",
      "content": "Benzinga and Yahoo Finance LLC may earn commission or revenue on some items through the links below.\n\nA multibillion-dollar deal for Nvidia Corporation (NASDAQ:NVDA) to supply advanced AI chips to the UAE has been stalled for months, reportedly frustrating CEO Jensen Huang as U.S. Commerce Secretary Howard Lutnick pushes Abu Dhabi to finalize investments before shipments proceed.\n\nNvidia's market cap has reached $4.59 trillion, with shares climbing 58.97% over the past year and advancing 36.61% in 2025 to date. On Thursday, the stock rose 0.91%, according to Benzinga Pro.\n\nDeal Faces Unexpected Delays\n\nThe agreement, announced in May, was meant to showcase the White House's push to expand U.S. tech influence abroad while countering China's AI ambitions.\n\nTrending: If there was a new fund backed by Jeff Bezos offering a 7-9% target yield with monthly dividends would you invest in it?\n\nHowever, the Emirati investments have yet to materialize, baffling some administration officials, reported the Wall Street Journal, citing people familiar with the matter.\n\nThe stalled deal is seen as a setback for Huang and White House AI Czar David Sacks, who view such agreements as crucial to advancing U.S. tech strategy and maintaining an edge over China in the AI race.\n\n\"Sacks and Secretary Lutnick are integral to the President's AI agenda and are working diligently to get deals done on behalf of the American people,\" White House spokesman Kush Desai told the publication.\n\nSecurity Concerns Over UAE-China Ties\n\nThe Commerce Department's approval is required before Nvidia can deliver the chips.\n\nLutnick has conditioned approval on the UAE finalizing its U.S. investments, while also raising concerns about the Gulf nation's close relationship with China, the report added.\n\nSee Also: An EA Co-Founder Shapes This VC Backed Marketplace—Now You Can Invest in Gaming's Next Big Platform\n\nNvidia Execs And CEO Jensen Huang's Frustration\n\nHuang and Nvidia executives have privately expressed frustration over the delays, the sources said.\n\nOne senior Nvidia executive denied that the company is alarmed, the report added.\n\n\n\nAn Nvidia spokesperson told Benzinga in an emailed statement that the company supports the Trump administration's AI action plan, including the Middle East agreements. \"Look forward to providing any assistance they need.\"\n\n\n\nThe Commerce Department did not immediately respond to Benzinga's request for comments.\n\nTrump's Broader AI Strategy\n\nThe UAE deal was touted by President Donald Trump during his May visit to Abu Dhabi, part of what the White House said was more than $200 billion in bilateral agreements.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-ceo-jensen-huang-reportedly-203016661.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "GSB Wealth Management LLC Lowers Stock Position in NVIDIA Corporation $NVDA",
      "content": "GSB Wealth Management LLC lessened its stake in shares of NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 0.8% in the 2nd quarter, HoldingsChannel reports. The institutional investor owned 32,351 shares of the computer hardware maker’s stock after selling 260 shares during the quarter. NVIDIA makes up 1.2% of GSB Wealth Management LLC’s investment portfolio, making the stock its 17th biggest position. GSB Wealth Management LLC’s holdings in NVIDIA were worth $5,111,000 as of its most recent SEC filing.\n\nOther hedge funds also recently bought and sold shares of the company. Pachira Investments Inc. increased its stake in NVIDIA by 1.0% during the second quarter. Pachira Investments Inc. now owns 6,450 shares of the computer hardware maker’s stock worth $1,019,000 after purchasing an additional 63 shares during the period. HFG Wealth Management LLC increased its stake in NVIDIA by 3.4% during the second quarter. HFG Wealth Management LLC now owns 2,075 shares of the computer hardware maker’s stock worth $328,000 after purchasing an additional 68 shares during the period. Burkett Financial Services LLC increased its stake in NVIDIA by 1.3% during the second quarter. Burkett Financial Services LLC now owns 5,450 shares of the computer hardware maker’s stock worth $861,000 after purchasing an additional 70 shares during the period. Guided Capital Wealth Management LLC increased its stake in NVIDIA by 0.3% during the second quarter. Guided Capital Wealth Management LLC now owns 27,858 shares of the computer hardware maker’s stock worth $4,401,000 after purchasing an additional 70 shares during the period. Finally, Luts & Greenleigh Group Inc. increased its stake in NVIDIA by 0.4% during the second quarter. Luts & Greenleigh Group Inc. now owns 19,894 shares of the computer hardware maker’s stock worth $3,143,000 after purchasing an additional 76 shares during the period. Hedge funds and other institutional investors own 65.27% of the company’s stock.\n\nGet NVIDIA alerts:\n\nNVIDIA Trading Up 0.9%\n\nNVDA opened at $188.89 on Friday. NVIDIA Corporation has a one year low of $86.62 and a one year high of $191.05. The company has a debt-to-equity ratio of 0.08, a quick ratio of 3.60 and a current ratio of 4.21. The company has a market cap of $4.59 trillion, a P/E ratio of 53.81, a PEG ratio of 1.35 and a beta of 2.12. The business’s 50-day simple moving average is $177.83 and its 200-day simple moving average is $147.65.\n\nNVIDIA Dividend Announcement\n\nNVIDIA ( NASDAQ:NVDA Get Free Report ) last posted its earnings results on Wednesday, August 27th. The computer hardware maker reported $1.05 earnings per share for the quarter, beating the consensus estimate of $1.01 by $0.04. NVIDIA had a return on equity of 101.74% and a net margin of 52.41%.The business had revenue of $46.74 billion during the quarter, compared to the consensus estimate of $45.65 billion. During the same period in the previous year, the business earned $0.68 EPS. The business’s quarterly revenue was up 55.6% on a year-over-year basis. NVIDIA has set its Q3 2026 guidance at EPS. As a group, equities research analysts expect that NVIDIA Corporation will post 2.77 EPS for the current fiscal year.\n\nThe company also recently announced a quarterly dividend, which was paid on Thursday, October 2nd. Stockholders of record on Thursday, September 11th were issued a $0.01 dividend. This represents a $0.04 annualized dividend and a dividend yield of 0.0%. The ex-dividend date of this dividend was Thursday, September 11th. NVIDIA’s payout ratio is presently 1.14%.\n\nInsider Transactions at NVIDIA\n\nIn other news, CEO Jen Hsun Huang sold 75,000 shares of the business’s stock in a transaction dated Wednesday, October 1st. The stock was sold at an average price of $186.61, for a total value of $13,995,750.00. Following the completion of the sale, the chief executive officer directly owned 71,083,203 shares of the company’s stock, valued at approximately $13,264,836,511.83. The trade was a 0.11% decrease in their position. The transaction was disclosed in a document filed with the Securities & Exchange Commission, which is accessible through this link. Also, CFO Colette Kress sold 30,500 shares of the business’s stock in a transaction dated Friday, September 19th. The shares were sold at an average price of $176.40, for a total value of $5,380,200.00. Following the completion of the sale, the chief financial officer directly owned 2,883,402 shares of the company’s stock, valued at $508,632,112.80. The trade was a 1.05% decrease in their ownership of the stock. The disclosure for this sale can be found here. Insiders sold a total of 4,097,407 shares of company stock valued at $714,378,504 over the last quarter. Company insiders own 4.17% of the company’s stock.\n\nWall Street Analysts Forecast Growth\n\nNVDA has been the topic of a number of recent research reports. Truist Financial boosted their price target on shares of NVIDIA from $210.00 to $228.00 and gave the stock a “buy” rating in a research note on Thursday, August 28th. BNP Paribas upgraded NVIDIA to a “hold” rating in a research note on Friday, August 1st. UBS Group reiterated a “buy” rating on shares of NVIDIA in a research note on Tuesday, September 23rd. Mizuho lifted their price objective on NVIDIA from $192.00 to $205.00 and gave the company an “outperform” rating in a research note on Thursday, August 14th. Finally, Sanford C. Bernstein reiterated a “buy” rating on shares of NVIDIA in a research note on Tuesday, September 23rd. Four research analysts have rated the stock with a Strong Buy rating, thirty-six have given a Buy rating, four have given a Hold rating and one has assigned a Sell rating to the stock. According to MarketBeat.com, the stock currently has an average rating of “Moderate Buy” and a consensus price target of $211.00.\n\nGet Our Latest Stock Analysis on NVDA\n\nNVIDIA Profile\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nFeatured Stories\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/03/gsb-wealth-management-llc-lowers-stock-position-in-nvidia-corporation-nvda/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "With new open models and simulation libraries, Nvidia aims to accelerate robotics R&D",
      "content": null,
      "source": "SiliconANGLE News",
      "url": "https://siliconangle.com/2025/10/02/new-open-models-simulation-libraries-nvidia-aims-accelerate-robotics-rd/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "AI chip firm Cerebras Systems files to withdraw its highly anticipated US listing",
      "content": "AI chip startup Cerebras Systems, which competes with industry leader Nvidia in the booming AI chip market, on Friday filed to withdraw its plans for an initial public offering in the United States, effective immediately.\n\nIts withdrawal comes as U.S. IPO activity picks up in recent months, reversing an earlier slowdown caused by trade-policy uncertainty, with recent listings, such as that of data center real estate investment trust Fermi, getting warm receptions amid surging investor enthusiasm for AI-related stocks.\n\n\"Given that Cerebras just very recently completed a sizeable fund raise, it is of no surprise that they are holding off to pursue the IPO at this time,\" said Josef Schuster, CEO of IPO research firm IPOX.\n\nCerebras had on Tuesday said it raised $1.1 billion in a funding round led by Fidelity Management & Research and Atreides Management, valuing the company at $8.1 billion. The round added investors Tiger Global, Valor Equity Partners and 1789 Capital, the fund in which U.S. President Donald Trump's son is a partner.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nBut CEO Andrew Feldman said at the time the company still plans to hold a public offering.\n\nLast year, Cerebras filed for an initial public offering on the Nasdaq. The company’s highly anticipated listing was delayed by a U.S. national security review of a $335 million investment by G42, an Abu Dhabi-based cloud computing and AI company.\n\n\"We believe this is more a company-specific strategic decision and does not tell us anything about the state of U.S. IPO sentiment, which we view as exceptionally strong,\" Schuster added.\n\nSunnyvale, California-based Cerebras Systems makes high-performance AI chips and systems designed to speed up training and running large AI models.",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/business/ai-chip-firm-cerebras-systems-files-withdraw-its-highly-anticipated-us-listing-5384471",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "900-Mile 2023 Faraday Future FF 91 2.0 Futurist Alliance",
      "content": "This 2023 Faraday Future FF 91 is #4 of a planned 300 2.0 Futurist Alliance examples designated for production, and it was purchased new by the current owner. Now with ~900 miles, the car is finished in Onyx Black Satin paint over coordinated leather upholstery and features an all-wheel-drive powertrain with three electric motors, a liquid-cooled 142-kWh battery pack, and a direct-drive system. Equipment includes 22″ forged aluminum wheels, programmable LED lights, and rear-hinged rear doors, and driver aids consist of adaptive cruise control, automatic emergency braking, and traction control. The cabin houses 11 interior display screens along with heated, ventilated, and massaging seats, including the “Zero Gravity” rear seats. This FF 91 is now offered on dealer consignment with a clean Carfax report and a clean California title.\n\nLos Angeles, California-based Faraday Future was founded in 2014 and previewed the FF 91 as a concept at the 2017 Consumer Electronics Show in Las Vegas, Nevada. It received mechanical revisions before entering production at the automaker’s Hanford, California, plant as the FF 91 2.0 in 2023. The Futurist Alliance edition was the first variant offered out of a planned three FF 91 trim levels and carried a factory-advertised price of $309,000.\n\nThe aluminum bodywork on this example is finished in black and is equipped with approximately 30 sensors for stability and driver-assist systems as well as programmable LED lighting, power-folding mirrors, rear-hinged rear doors, and a rear spoiler.\n\nThe 22″ forged aluminum wheels feature black accents, and they are mounted with Pirelli Scorpion Zero tires. The car features Faraday Future’s “All-Terrain AI Body Control Technology” system as well as emergency braking, adaptive cruise control, and smart parking systems.\n\nThe cockpit features power-adjustable seats trimmed in black leather with heating, cooling, and massaging functions. A total of 11 screens are fitted throughout the cabin, including a 17″ front passenger display. The car is equipped with Qualcomm 8155p and Nvidia Orin X computer platforms to power various driving and infotainment systems as well as three separate 5G LTE modems on different networks.\n\nTwo “Zero Gravity” bucket seats and a 27″ display are located in the rear of the cabin. Touchscreen control panels are integrated into the door panels.\n\nThe heated multifunction steering wheel fronts a configurable information display. The odometer is located in the vertically oriented central screen and displays ~900 miles.\n\nThe B-pillar plaque denotes the car as #4 of a planned 300 2.0 Futurist Alliance examples.\n\nThe single front and two rear electric motors are powered by a liquid-cooled 142-kWh lithium-ion battery pack to produce a factory-rated 1,050 horsepower and 1,458 lb-ft of torque. Power is sent to all four wheels through a single-speed direct-drive transmission with traction control.\n\nThe window sticker lists delivery to Faraday Future in Gardena, California, along with factory equipment, colors, and a total MSRP of $312k. The manufacturer’s literature and two key cards are included in the sale.\n\nThe Carfax report is free of accidents or other reported damage.\n\nThe current California title is a duplicate.",
      "source": "Bringatrailer.com",
      "url": "https://bringatrailer.com/listing/2023-faraday-future-ff-91-2-0-futurist-alliance/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "nvidia-mmath 25.9",
      "content": "MMATH\n\nThis is the official repository for the paper \"MMATH: A Multilingual Benchmark for Mathematical Reasoning\".\n\n📖 Introduction\n\nMMATH is a new benchmark specifically designed for multilingual complex reasoning. It comprises 374 carefully selected math problems from high-quality sources, including AIME, CNMO, and MATH-500, and covers ten typologically and geographically diverse languages. Each problem is translated and validated through a rigorous pipeline that combines frontier LLMs with human verification, ensuring semantic consistency.\n\nNVIDIA Eval Factory\n\nMMATH provides you with evaluation clients that are specifically built to evaluate model endpoints using our Standard API.\n\nLaunching an evaluation for an LLM\n\nInstall the package\n\npip install nvidia-mmath\n\n(Optional) Set a token to your API endpoint if it's protected\n\nexport MY_API_KEY = \"your_api_key_here\" export HF_TOKEN = \"your_huggingface_token_here\"\n\nList the available evaluations\n\neval-factory ls\n\nAvailable tasks:\n\nmmath_en (in mmath)\n\nmmath_zh (in mmath)\n\nmmath_ar (in mmath)\n\nmmath_es (in mmath)\n\nmmath_fr (in mmath)\n\nmmath_ja (in mmath)\n\nmmath_ko (in mmath)\n\nmmath_pt (in mmath)\n\nmmath_th (in mmath)\n\nmmath_vi (in mmath)\n\nRun the evaluation of your choice\n\neval-factory run_eval \\ --eval_type mmath_en \\ --model_id meta/llama-3.1-8b-instruct \\ --model_url https://integrate.api.nvidia.com/v1/chat/completions \\ --model_type chat \\ --api_key_name MY_API_KEY \\ --output_dir /workspace/results\n\nGather the results\n\ncat /workspace/results/results.yml\n\nCommand-Line Tool\n\nEach package comes pre-installed with a set of command-line tools, designed to simplify the execution of evaluation tasks. Below are the available commands and their usage for the mmath evaluations:\n\nCommands\n\n1. List Evaluation Types\n\neval-factory ls\n\nDisplays the evaluation types available within the harness.\n\n2. Run an evaluation\n\nThe eval-factory run_eval command executes the evaluation process. Below are the flags and their descriptions:\n\nRequired flags:\n\n--eval_type <string> : The type of evaluation to perform (e.g., mmath_en, mmath_zh, etc.)\n\n: The type of evaluation to perform (e.g., mmath_en, mmath_zh, etc.) --model_id <string> : The name or identifier of the model to evaluate.\n\n: The name or identifier of the model to evaluate. --model_url <url> : The API endpoint where the model is accessible.\n\n: The API endpoint where the model is accessible. --model_type <string> : The type of the model to evaluate, currently either \"chat\", \"completions\", or \"vlm\".\n\n: The type of the model to evaluate, currently either \"chat\", \"completions\", or \"vlm\". --output_dir <directory> : The directory to use as the working directory for the evaluation. The results, including the results.yml output file, will be saved here.\n\nOptional flags:\n\n--api_key_name <string> : The name of the environment variable that stores the Bearer token for the API, if authentication is required.\n\n: The name of the environment variable that stores the Bearer token for the API, if authentication is required. --run_config <path> : Specifies the path to a YAML file containing the evaluation definition.\n\n: Specifies the path to a YAML file containing the evaluation definition. --overrides <string> : Override configuration parameters (e.g., 'config.params.limit_samples=10').\n\nExample\n\neval-factory run_eval \\ --eval_type mmath_en \\ --model_id meta/llama-3.1-8b-instruct \\ --model_type chat \\ --model_url https://integrate.api.nvidia.com/v1/chat/completions \\ --output_dir ./evaluation_results\n\nIf the model API requires authentication, set the API key in an environment variable and reference it using the --api_key_name flag:\n\nexport MY_API_KEY = \"your_api_key_here\" eval-factory run_eval \\ --eval_type mmath_en \\ --model_id meta/llama-3.1-8b-instruct \\ --model_type chat \\ --model_url https://integrate.api.nvidia.com/v1/chat/completions \\ --api_key_name MY_API_KEY \\ --output_dir ./evaluation_results\n\nConfiguring evaluations via YAML\n\nEvaluations in MMATH are configured using YAML files that define the parameters and settings required for the evaluation process. These configuration files follow a standard API which ensures consistency across evaluations.\n\nExample of a YAML config:\n\nconfig : type : mmath_en params : parallelism : 50 limit_samples : 20 target : api_endpoint : model_id : meta/llama-3.1-8b-instruct type : chat url : https://integrate.api.nvidia.com/v1/chat/completions api_key : NVIDIA_API_KEY\n\nThe priority of overrides is as follows:\n\ncommand line arguments user config (as seen above) task defaults (defined per task type) framework defaults\n\nThe --dry_run option allows you to print the final run configuration and command without executing the evaluation.\n\nExample:\n\neval-factory run_eval \\ --eval_type mmath_en \\ --model_id meta/llama-3.1-8b-instruct \\ --model_type chat \\ --model_url https://integrate.api.nvidia.com/v1/chat/completions \\ --output_dir ./evaluation_results \\ --dry_run\n\n🛠️ Code and Data Usage\n\nMMATH has the following resources. The mmath folder contains the benchmark data. The train folder contains the training data at Section 3. mmath_eval.py is the main program to evaluate the accuracy results, while calculate_lcr.py calculates the value of LCR as defined in our paper.\n\n│ calculate_lcr.py │ mmath_eval.py │ utils.py │ ├─mmath │ ar.json │ en.json │ es.json │ fr.json │ ja.json │ ko.json │ pt.json │ th.json │ vi.json │ zh.json │ └─train enSFT-3k.json enThink-3k.json nativeThink-3k.json\n\nThe example in mmath/xx.json has the following format:\n\n{ \"question\" : \"Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.\" , # The ques t io n \"answer\" : \"204\" , # The a ns wer \"data_source\" : \"AIME2024\" , # The da ta source , which migh t be AIME 2024 /AIME 2025 /CNMO/MATH 500 \"data_source_id\" : 0 , # The i n dex i n origi nal da ta \"lang\" : \"en\" , # La n guage t ype \"gid\" : 0 # The global id i n our be n chmark MMATH },\n\nThe example in train/yy.json has the following format:\n\n{ \"index\" : 0 , \"answer\" : \"364\" , \"conversations\" :[ { \"from\" : \"user\" , \"value\" : \"For a positive integer \\\\( n \\\\), consider the function\n\n\n\n\\\\[\n\nf(n)=\\\\frac{4n+\\\\sqrt{4n^2-1}}{\\\\sqrt{2n+1}+\\\\sqrt{2n-1}}\n\n\\\\]\n\n\n\nCalculate the value of\n\n\n\n\\\\[\n\nf(1)+f(2)+f(3)+\\\\cdots+f(40)\n\n\\\\]\" }, { \"from\" : \"assistant\" , \"value\" : \"<think>\n\nOkay, let's see. I need to find the sum of f(1) + f(2) + ...Thus, the sum is:\n\n\n\n\\\\[\n\n\\\\frac{1}{2} (729 - 1) = \\\\frac{728}{2} = 364.\n\n\\\\]\n\n\n\nThe final answer is:\n\n\n\n\\\\[\n\n\\\\boxed{364}\n\n\\\\]\" } ] },\n\n🧪 Experiment Setup\n\nEnvironment Setups\n\nTo accelerate the process of environment setup, we use uv to manage the packages. And our training code is based on LLaMA-Factory, you can install it based on your requirements (e.g, with -e option).\n\nconda create -n mmath python = 3 .10 conda activate mmath pip install uv uv pip install -r requirements.txt\n\nEvaluation Commands\n\nAccuracy Results\n\nTo calculate accuracy results on our benchmark, you can run with:\n\nexport CUDA_VISIBLE_DEVICES = 0 ,1 python mmath_eval.py --model_name_or_path DeepSeek-R1-Distill-Qwen-32B --tensor_parallel_size 2\n\nThis will generate a results directory with a subdirectory with the model name (e.g, DeepSeek-R1-Distill-Qwen-32B). Inside the directory are the results belonging to different languages, such as en.json .\n\nLCR Results\n\nAs for calculating LCR, please download the lid.176.bin with:\n\nwget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n\nAfter that, please set the model_list_full variable in calculate_lcr.py . Then, you can run the command using python calculate_lcr.py .\n\nmodel_list_full = [ \"DeepSeek-R1-Distill-Qwen-32B\" , # ... ]\n\nThis will rewrite some keys in results/model_name/xx.json and output a LaTeX table about the whole results.\n\nTraining Setups\n\nAs mentioned before, our training code is based on LLaMA-Factory. Here we provide the hyperparameters used in our paper.\n\n### model model_name_or_path : Qwen2.5-32B-Instruct trust_remote_code : true ### method stage : sft template : qwen do_train : true finetuning_type : full deepspeed : examples/deepspeed/ds_z3_config.json # choices: [ds_z0_config.json, ds_z2_config.json, ds_z3_config.json] packing : false ### dataset dataset : en-Think cutoff_len : 32768 overwrite_cache : true preprocessing_num_workers : 16 dataloader_num_workers : 4 ### output output_dir : Qwen2.5-32B-Instruct-en-Think logging_steps : 10 save_strategy : epoch plot_loss : true overwrite_output_dir : true save_only_model : true save_total_limit : 10 ### train per_device_train_batch_size : 1 gradient_accumulation_steps : 1 learning_rate : 1.0e-5 num_train_epochs : 3 lr_scheduler_type : cosine warmup_ratio : 0.1 save_total_limit : 10 bf16 : true ddp_timeout : 180000000 resume_from_checkpoint : null enable_liger_kernel : true\n\n📄 Attribution\n\nThis project is a fork of the original MMATH: A Multilingual Benchmark for Mathematical Reasoning repository created by the RUCAIBox team at Renmin University of China.\n\nOriginal Repository\n\nOriginal Authors\n\nThe original MMATH benchmark was created by:\n\nWenyang Luo - Renmin University of China\n\n- Renmin University of China Wayne Xin Zhao - Renmin University of China\n\n- Renmin University of China Jing Sha - Renmin University of China\n\n- Renmin University of China Shijin Wang - Renmin University of China\n\n- Renmin University of China Ji-Rong Wen - Renmin University of China\n\nLicense\n\nThe original MMATH repository is licensed under the MIT License. This fork maintains the same license terms while adding NVIDIA-specific packaging and evaluation capabilities.\n\nAcknowledgments\n\nWe thank the original MMATH authors for creating this comprehensive multilingual mathematical reasoning benchmark and making it publicly available to the research community.\n\n📄 Citation",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-mmath/25.9/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "AI chip firm Cerebras files to withdraw highly anticipated US listing",
      "content": "AI chip startup Cerebras Systems, which competes with industry leader Nvidia in the booming AI chip market, on Friday filed to withdraw its plans for an initial public offering in the United States, effective immediately.\n\nIts withdrawal comes as U.S. IPO activity picks up in recent months, reversing an earlier slowdown caused by trade-policy uncertainty, with recent listings, such as that of data center real estate investment trust Fermi, getting warm receptions amid surging investor enthusiasm for AI-related stocks.\n\n\"Given that Cerebras just very recently completed a sizeable fund raise, it is of no surprise that they are holding off to pursue the IPO at this time,\" said Josef Schuster, CEO of IPO research firm IPOX.\n\nCerebras had on Tuesday said it raised $1.1 billion in a funding round led by Fidelity Management & Research and Atreides Management, valuing the company at $8.1 billion. The round added investors Tiger Global, Valor Equity Partners and 1789 Capital, the fund in which U.S. President Donald Trump's son is a partner.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nBut CEO Andrew Feldman said at the time the company still plans to hold a public offering.\n\nLast year, Cerebras filed for an initial public offering on the Nasdaq. The company’s highly anticipated listing was delayed by a U.S. national security review of a $335 million investment by G42, an Abu Dhabi-based cloud computing and AI company.\n\n\"We believe this is more a company-specific strategic decision and does not tell us anything about the state of U.S. IPO sentiment, which we view as exceptionally strong,\" Schuster added.\n\nSunnyvale, California-based Cerebras Systems makes high-performance AI chips and systems designed to speed up training and running large AI models.",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/business/ai-chip-firm-cerebras-files-withdraw-highly-anticipated-us-listing-5384471",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "The Zacks Analyst Blog Highlights NVIDIA, Microsoft, IBM, D-Wave and IonQ",
      "content": "For Immediate Release\n\nChicago, IL – October 3, 2025 – Zacks.com announces the list of stocks featured in the Analyst Blog. Every day the Zacks Equity Research analysts discuss the latest news and events impacting stocks and the financial markets. Stocks recently featured in the blog include: NVIDIA NVDA, Microsoft MSFT, IBM IBM, D-Wave QBTS and IonQ IONQ.\n\nHere are highlights from Thursday’s Analyst Blog:\n\nStocks to Gain from Quantum Computing in 2025\n\nThis year has seen quantum computing being pushed from lab interests toward practical deployments. Vendors and tech giants published official updates showing progress on error correction, larger qubit systems, hybrid quantum-classical stacks and new research centers aimed at real-world use.\n\nGoogle reiterated its Willow roadmap and published research on error correction and scalable chips and NVIDIA launched a dedicated “Quantum Day” and announced an Accelerated Quantum Research Center to couple AI supercomputing with quantum research. Pure plays like Rigetti highlighted multi-chip systems and new commercial availability in their quarterly results. Together, these companies have sketched a year of measurable engineering advances and growing commercialization pathways.\n\nBelow are four stocks expected to gain from quantum computing in 2025.\n\nMicrosoft\n\nMicrosoft’s first-half 2025 quantum computing-based developments center on Majorana 1 and on partnerships to scale quantum hardware and control. Earlier this year, the company unveiled Majorana 1 as a breakthrough topological-qubit processor and a measurement/control approach intended to simplify qubit control and make very large qubit counts practical, positioning Microsoft to pursue a distinct, potentially more scalable hardware path than superconducting or trapped-ion approaches.\n\nMicrosoft’s focus on developer toolchains and collaborations to accelerate scalable systems suggests the company is pushing both hardware differentiation and cloud integration as its path to commercial quantum advantage. For investors who prefer a diversified tech heavyweight’s exposure to quantum instead of startups, Microsoft’s official roadmap points to multi-front engagement.\n\nIBM\n\nIBM in 2025 is pursuing a stepwise engineering route to fault-tolerant quantum computing that includes building a new IBM Quantum Data Center and an explicit roadmap toward large-scale, fault-tolerant machines. IBM also highlighted international System Two deployments, including a collaboration with RIKEN, along with continued Nighthawk-family hardware and software releases to expand circuit complexity, all signaling IBM’s investment in data-center-scale infrastructure, strategic partnerships and software stacks to support near-term commercial users and research collaborators.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/zacks-analyst-blog-highlights-nvidia-091000163.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "The “Premier Anomaly”",
      "content": "The \"Premier Anomaly\"\n\nThere’s a scene that plays out in nearly every investment seminar: Someone in the audience asks if it’s possible to consistently beat the market.\n\nThe speaker – usually quoting Eugene Fama, father of the Efficient Market Hypothesis – smiles and says: “Sorry, but research shows you can’t.”\n\nExcept that’s not quite what Fama said.\n\nIn fact, the Nobel Prize-winning economist who built his entire career proving markets are efficient made a stunning admission: There’s one glaring exception to his theory.\n\nOne pattern that refuses to go away, no matter how many academics try to explain it.\n\nFama called it “the premier anomaly” – and it’s one that I’ve staked my entire career on: momentum.\n\nThe Pattern That Shouldn’t Exist\n\nHere’s what momentum means in plain English: Stocks that have been winning tend to keep winning.\n\nStocks that have been losing tend to keep losing. At least for a while.\n\nThis shouldn’t happen in an efficient market.\n\nIf everyone can see that a stock has been going up, why would smart money keep buying? Shouldn’t they expect it to fall back to “fair value”?\n\nYet 2024 experienced one of the strongest momentum runs of the past thirty years.\n\nThe AI boom created exactly the kind of explosive moves momentum traders dream about – stocks rising not because of subtle improvements in fundamentals, but because capital itself became a force multiplier.\n\nThink about Nvidia’s journey from $200 to over $900 in less than a year.\n\nOr the lesser-known names that rode the AI wave – companies building data centers, cooling systems, networking infrastructure.\n\nMany of these moves weren’t driven by patient value investors poring over spreadsheets. They were driven by what traders call “price action” – the raw force of buying pressure creating its own momentum.\n\nThe Academic Backbone\n\nThe funny thing about momentum is that it’s one of the most heavily researched phenomena in all of finance.\n\nIt’s not some fringe theory cooked up by day traders. It’s been validated across:\n\nMultiple decades of data\n\nInternational markets from Asia to Europe\n\nDifferent asset classes – stocks, bonds, commodities, currencies\n\nVarious holding periods from weeks to months\n\nThe seminal research came in 1993, when academics Narasimhan Jegadeesh and Sheridan Titman published findings showing that buying recent winners and selling recent losers generated significant excess returns.\n\nTheir work sent shockwaves through the finance world because it directly contradicted the prevailing wisdom that markets were perfectly efficient.\n\nWhat made this research bulletproof was its simplicity.\n\nThe strategy didn’t require insider information, complex algorithms, or privileged access. Just basic price data – information available to anyone with a newspaper (or today, a smartphone).\n\nWhen asked about momentum strategies and whether markets can be beaten, Fama responded: “Ya, Momentum is the biggest example.”\n\nWhy Does Momentum Work?\n\nIf momentum is so well-documented, why doesn’t everyone exploit it until it disappears?\n\nThat’s the $64,000 question.\n\nAcademics have offered several explanations:\n\nBehavioral Factors: Investors systematically underreact to news.\n\nWhen a company announces strong earnings, people are initially skeptical.\n\nThey wait for confirmation.\n\nBy the time the story becomes obvious, the stock has already made a significant move – but there’s often more to come as late adopters finally jump in.\n\nInstitutional Constraints: Large funds can’t move quickly.\n\nBy the time a pension fund approves a position in a hot stock, retail traders and hedge funds have already captured the early gains.\n\nBut paradoxically, when the institutions finally arrive with billions to deploy, they create the next leg up.\n\nRisk and Crashes: Momentum doesn’t work all the time.\n\nIt experiences periodic crashes – sharp, sudden reversals that can wipe out months of gains in days.\n\nMany investors can’t stomach this volatility, which keeps the strategy from becoming overcrowded.\n\nThe AI Momentum Machine\n\nWhich brings us to today’s market. The AI sector has become a laboratory for studying momentum in real-time.\n\nWhile Nvidia saw nearly a 200% increase last year, the median semiconductor company was down – a staggering divergence that may be one for the history books.\n\nThis bifurcation is textbook momentum: Capital concentrates in the strongest names, leaving laggards behind.\n\nIt’s not about which companies have the “best” technology or the most reasonable valuations.\n\nIt’s about which stocks are demonstrating the strongest price action.\n\nLook at the pattern:\n\nAI emerges as the dominant narrative Early movers establish uptrends Each successive wave of buyers strengthens those trends Traditional metrics like P/E ratios become irrelevant The strongest stocks pull away from the pack\n\nThis isn’t just happening in obvious names like Nvidia.\n\nIt’s cascading through the entire supply chain – chip designers, foundries, data center operators, power infrastructure companies, even coffee chains incorporating AI into their operations.\n\nThe Technical Framework\n\nProfessional momentum traders don’t just buy whatever moved up yesterday.\n\nThey look for specific patterns:\n\nStage 1: Establishing the Uptrend A stock breaks out from a period of consolidation on strong volume. This initial move often catches fundamental analysts off guard – the news hasn’t changed, so why is it suddenly moving?\n\nStage 2: The Momentum Phase Price makes higher highs and higher lows in a steady rhythm. Pullbacks are shallow and brief. This is where the real money gets made, as the trend becomes self-reinforcing.\n\nStage 3: The Acceleration This is what traders sometimes call a “vertical move” or “parabolic phase.” Price gaps up on huge volume. Everyone who was skeptical starts feeling FOMO (fear of missing out). This phase can last days or weeks.\n\nStage 4: The Exhaustion Eventually, all momentum runs end. The trick is recognizing when the character of price action changes – when dips start getting deeper, rallies become unconvincing, volume dries up.\n\nThe Options Leverage Question\n\nHere’s where momentum trading gets both more powerful and more dangerous: options.\n\nWhen you buy a stock, your potential gain is unlimited but it takes substantial capital to generate meaningful returns.\n\nA 50% move on a $10,000 position nets you $5,000 – nice, but not life-changing.\n\nOptions, however, offer leverage.\n\nThat same 50% move in the underlying stock might generate a 200% or 300% return on an options position – turning that $10,000 into $30,000 or more.\n\nThe catch? Options are wasting assets.\n\nEvery day that passes without the expected move, you lose money to time decay. And if you’re wrong about direction, you can lose your entire investment.\n\nThis makes options ideal for momentum strategies in theory: You’re betting on fast moves in stocks already in motion.\n\nBut it requires precision timing – getting in just as momentum accelerates, and getting out before it stalls.\n\nWhat the Data Really Shows\n\nLet’s be clear about something important: While momentum as a factor has delivered excess returns historically, that doesn’t mean every momentum trade wins.\n\nResearch shows that momentum strategies can experience predictable crashes, where the likelihood of loss becomes high enough that professional managers wouldn’t commit their own funds – yet they keep clients’ money invested due to competitive pressures and fee structures.\n\nThe average momentum strategy might win 55-60% of the time.\n\nBut the winners can be large enough to more than compensate for the losers.\n\nIt’s the opposite of “picking up pennies in front of a steamroller” – it’s more like “getting hit by small cars repeatedly while waiting for the occasional dump truck full of cash.”\n\nRecent analysis of momentum performance shows that success rates vary dramatically by market conditions.\n\nIn strong trending markets, momentum shines. In choppy, range-bound environments, it struggles. The skill isn’t just in identifying momentum – it’s in recognizing when market conditions favor the strategy.\n\nThe Current Setup\n\nSo where does that leave us now, in late 2025?\n\nHistorical patterns suggest that after such strong momentum performance, a reversal often follows in the subsequent year.\n\nThat doesn’t mean momentum strategies will stop working – it means the market leaders might change.\n\nThe AI trade has been extraordinary, but it’s also crowded.\n\nEveryone knows the narrative. When everyone knows something, the opportunity either needs to evolve or it needs to pause.\n\nSmart momentum traders aren’t just looking at last year’s winners.\n\nThey’re scanning for the next sector showing the early signs of institutional accumulation – unusual volume on up days, tight consolidation patterns after initial moves, breadth expanding within an industry group.\n\nThat might still be AI, but perhaps in different names – the picks-and-shovels plays rather than the obvious leaders.\n\nOr it might be an entirely different sector: gold miners, biotech, crypto-related stocks, or something we’re not even thinking about yet.\n\nThe Bottom Line\n\nMomentum trading isn’t a magic formula. It’s what Eugene Fama called “the premier anomaly” – a persistent market pattern that offers opportunity but comes with significant risk.\n\nIf you’re considering a momentum approach:\n\nDo:\n\nUnderstand you’re trading price action, not fundamentals\n\nUse proper position sizing (never bet the farm on one trade)\n\nHave a clear exit strategy for both wins and losses\n\nRecognize that options magnify both gains AND losses\n\nAccept that even good strategies go through rough patches\n\nDon’t:\n\nExpect to win on every trade\n\nIgnore risk management because you’re “sure” about a setup\n\nChase moves that have already gone vertical\n\nTrade with money you can’t afford to lose\n\nForget that past performance never guarantees future results\n\nWe’ll dive more into some of these themes in the next few weeks.",
      "source": "Dailyreckoning.com",
      "url": "https://dailyreckoning.com/the-premier-anomaly/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Buy, Sell or Hold: Nvidia Stock At $190",
      "content": "Key Points\n\n\n\n\n\n\n\n\n\n\n\n\n\nNvidia (NVDA) thrives on AI tailwinds, posting 56% revenue growth in the second quarter.\n\n\n\n\n\n\n\n\n\nGeopolitical tensions between the U.. and China make winning back the lost $8 billion in revenue from the region difficult.\n\n\n\n\n\n\n\n\n\nAnalysts favor NVDA with a buy…\n\nThis story appeared on 247wallst.com , 2025-10-04 14:50:25.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/0f732b1c29007d49",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Nvidia And These AI Plays Lead 5 Stocks Near Buy Points",
      "content": "AI data centers are a driver of three of the stocks on this weekend's watchlist.\n\nThe post Nvidia And These AI Plays Lead 5 Stocks Near Buy Points appeared first on Investor's Business Daily.\n\nThis story appeared on investors.com , 2025-10-04 15:59:59.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/e9be380c94c20ee9",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Nvidia Competitor Cerebras Shelves IPO Plans Days After Touching $8 Billion Valuation",
      "content": "Artificial intelligence chipmaker Cerebras Systems scrapped plans for an IPO on Friday, days after the company announced a fresh fundraising round that sent its valuation up to $8 billion.\n\nIn a filing with the U.S. Securities and Exchange Commission (SEC), the Nvidia Corp. (NASDAQ:NVDA)…\n\nThis story appeared on benzinga.com , 2025-10-04 07:12:29.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/898c05aaa95ad79f",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Here’s How Stock Losses Can Boost Your Tax Refund",
      "content": "No one invests with the intention of taking losses. On the contrary, the entire purpose of investing is to grow your money, either through capital gains or income. Even though you may have to pay taxes on those gains, they are always preferable to taking losses.\n\nRead Next: 5 Ways You Can Reduce Your Tax Bill Like a Millionaire, According to Robert Kiyosaki\n\nLearn More: 7 Luxury SUVs That Will Become Affordable in 2025\n\nOf course, there’s also no such thing as a perfect investor. Even professional money managers regularly take losses — it’s just a part of the process. The good news, however, is you can use your inevitable losses as a benefit when tax time rolls around. Here’s how:\n\nOffsetting Gains\n\nIf you have taxable capital gains, you can offset some or all of those gains by taking capital losses. This process is sometimes referred to as tax-loss harvesting.\n\nImagine, for example, you sell Nvidia stock for a $15,000 profit in July. As December rolls around, you realize you have a $15,000 loss in your existing Apple position. You can sell your Apple shares, capture that $15,000 loss, and offset your total gain on Nvidia, resulting in a tax liability of zero.\n\nOne thing to be aware of with this strategy is the “wash-sale” provision. In the words of the IRS, “A wash sale is the sale of securities at a loss and the acquisition of same (substantially identical) securities within 30 days of sale date (before or after).” Essentially, you can’t sell Apple at a loss to offset your gain in Nvidia, and then buy Apple back within the 30 days before or after you sold it.\n\nIt’s also important to note that you should never sell a stock simply for tax purposes. If you’re a long-term believer in Apple, for example, you shouldn’t sell it just to offset your gain because you can’t buy it back for 30 days. During that time, Apple shares may stage a rally, offsetting any tax benefit you may have generated. Only harvest tax losses in shares you would consider selling anyway, from an investment perspective.\n\nTrending Now: Here’s How to Avoid a Huge Tax Bill After a Successful Side Gig\n\nReducing Taxable Income\n\nIf your realized capital losses exceed your capital gains, you can use those excess losses to offset up to $3,000 in ordinary income.\n\nImagine a scenario in which you have $10,000 in capital gains, $13,000 in capital losses and a $70,000 salary. When you offset your gains with your losses, you’re left with $3,000 in excess losses. You can apply that $3,000 to reduce your taxable salary from $70,000 to $67,000, resulting in additional tax savings — or boosting the size of your refund.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/stock-losses-boost-tax-refund-165358640.html",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "nvidia-nat-mcp 1.3.0a20251004",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-mcp/1.3.0a20251004/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Nvidia, Fujitsu to work together on AI robots and other technology",
      "content": "By Yuri Kageyama\n\nU.S. technology company Nvidia and Fujitsu, a Japanese telecommunications and computer maker, agreed Friday to work together on artificial intelligence to deliver smart robots and a variety of other innovations using Nvidia's computer chips.\n\n“The AI industrial revolution has already begun. Building the infrastructure to power it is essential in Japan and around the world,” Nvidia Chief Executive Jensen Huang said, hugging his Fujitsu counterpart Takahito Tokita on stage.\n\n“Japan can lead the world in AI and robotics,” Huang told reporters at a Tokyo hotel.\n\nThe companies will work together on building what they called “an AI infrastructure,” or the system on which the various futuristic AI uses will be based, including health care, manufacturing, the environment, next-generation computing and customer services. The hope is to establish that AI infrastructure for Japan by 2030.\n\nIt initially will be tailored for the Japanese market, leveraging Fujitsu’s decades-long experience here, but may later expand globally, and will utilize Nvidia’s GPUs, or graphics processing units, which are essential for AI, according to both sides.\n\nThe two executives did not outline specific projects or give a monetary figure for planned investments. But exploring a collaboration in AI for robots with Yaskawa Electric Corp., a Japanese machinery and robot maker, was noted as a possible example. AI will be constantly evolving and learning, they said.\n\nFujitsu and Nvidia have been working together on AI, speeding up manufacturing with digital twins and robotics to tackle aging Japan’s labor shortages.\n\nTokita said the companies were taking a “humancentric” approach aimed at keeping Japan competitive.\n\n“Through our collaboration with Nvidia, we aim to create new, unprecedented technologies and contribute to solving even more serious social issues,” said Tokita.\n\n© 2025 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed without permission.",
      "source": "Japan Today",
      "url": "https://japantoday.com/category/tech/nvidia-and-fujitsu-agree-to-work-together-on-ai-robots-and-other-technology",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Dow Jones Futures: Rally At Highs With Nvidia In Buy Zone, Palantir A Sell; Tesla FSD v14 Due",
      "content": "Dow Jones futures will open Sunday evening, along with S&P 500 futures and Nasdaq futures. The stock market rally hit record highs this past week, shrugging off a government shutdown. Growth stocks saw some selling Friday. Palantir Technologies (PLTR) sold off on a report of a flawed Army…\n\nThis story appeared on investors.com , 2025-10-04 11:53:51.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/7a37ccf2aea31561",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Tokyo University of Technology Unveils AI-Focused Supercomputer",
      "content": "Oct 04 (News On Japan) - Tokyo University of Technology unveiled its new supercomputer, named Seiran, on October 2nd, marking the start of full-scale operations. Equipped with the latest GPUs from U.S. chipmaker Nvidia, the system is designed specifically for generative AI and is the largest of its kind among Japan’s private universities.\n\nSeiran delivers AI processing power comparable to RIKEN’s flagship Fugaku supercomputer while consuming only about one-176th of the electricity. The university aims to strengthen its AI education program by giving students access to cutting-edge resources in an open learning environment.\n\nIn addition to academic use, the university has signed a partnership agreement with Hachioji City, where its campus is located. Together they plan to apply Seiran to projects such as trial operations of self-driving buses and experiments in smart agriculture, using the system’s computing power to accelerate local innovation.\n\nSource: テレ東BIZ",
      "source": "Newsonjapan.com",
      "url": "https://newsonjapan.com/article/147142.php",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Prediction: 1 Artificial Intelligence (AI) Stock Will Be Worth More Than Alphabet and Amazon Combined by 2030 (Hint: Not Nvidia)",
      "content": "Prediction: 1 Artificial Intelligence (AI) Stock Will Be Worth More Than Alphabet and Amazon Combined by 2030 (Hint: Not Nvidia)\n\nKey Points\n\n-\n\nMicrosoft's enterprise-focused AI strategy offers it greater resiliency.\n\n-\n\nFor example, the company has a substantial contracted…\n\nThis story appeared on finance.yahoo.com , 2025-10-04 15:45:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/91bd16377a195a73",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "The War Over Defense Tech",
      "content": "1.\n\nLast October, on a Martin Luther–inspired website called www.18theses.com, a software executive named Shyam Sankar published a four-thousand-word polemic with the title “The Defense Reformation.” “As a nation, we are in an undeclared state of emergency,” it begins. There follows a litany of provocations: Chinese escalation in the South China Sea, Iranian attacks on US military bases, the October 7 attacks in Israel, “an estimated 1 million casualties in brutal combat in Ukraine.” All this, Sankar writes, amounts to “a hot Cold War II.”\n\nIt is a war, he argues, for which the US is catastrophically underprepared: “In the current environment, American industries can’t produce a minimum line of ships, subs, munitions, aircraft, and more.” The problem lies with American capitalism in its present form, which—as Sankar lamented last year on a military podcast called The Merge—has left legacy defense firms like Lockheed Martin dominated by “fifth-generation MBA cadre[s]” who care more “about cash flow and buybacks and dividends than…about the honest hard work of engineering innovation.” Under these conditions the defense department’s subsidies for private business, he writes in “The Defense Reformation,” have neither “the supposed advantages of a planned economy nor the (far superior) advantages of a free market.”\n\nSankar is the CTO and executive vice-president of Palantir, the start-up cofounded in 2003 by Peter Thiel that specializes in a peculiar hybrid of big-data manipulation and McKinsey-style consulting work. Many of Sankar’s Palantir colleagues and peers at other Thielworld start-ups—notably Anduril, which bills itself as a pioneering disruptor in software-heavy military hardware—have advanced a similar criticism of the neoliberal state, bemoaning its declining interventions in manufacturing and research and lambasting the legacy defense firms, often nicknamed “primes,” for their sclerosis, inefficiency, and alleged monopolistic behavior. The innovative, capitalist spirit and manly vitalism that defined the defense department through the cold war is, for this group, long gone. The task of the hour, as Sankar writes in “The Defense Reformation,” is therefore nothing less than “to resurrect the American Industrial Base.”\n\nYou might think this would mean something like what, under the previous administration, went by the name Bidenomics: initiatives such as the CHIPS Act or the Inflation Reduction Act, which paled in comparison to total federal defense spending—the combined estimated cost of those two bills, which would be spread over a number of years, was about half the annual defense bill—but nonetheless aimed to bring high-tech manufacturing back to US shores. You would be wrong. “The most important and malleable weapons system,” Sankar writes, is not missiles or other military hardware but software, by which he presumably means technologies like large-scale data manipulation, narrow forms of computerized optimization applied to “smart” weapons systems and robotics, sensors, autonomous weapons systems, and artificial intelligence.\n\nInvesting lavishly in such technology and teaching “our warriors…to wield the software industrial base to maximize lethality” will catalyze what Sankar has elsewhere called a “software-driven reindustrialization” akin to previous industrial revolutions based around water, steam, coal, or oil. For a range of figures in the emergent defense-tech sector to which Palantir and Anduril belong, this will require wrenching guaranteed contracts from the bloated primes and promoting competition by having branches of the armed services bid against one another, not to mention allowing even more sales elsewhere. It will also require binding the state closer to a range of tech giants—especially firms like Meta, Amazon, and Microsoft­—that have thus far, on this view, neglected their patriotic duty to engage in defense work and profited from feminized “ad-tech” instead.\n\nThese arguments have found a broad and receptive audience. In recent years a range of politicians have aligned themselves with the priorities of defense-tech firms, especially as successive White Houses worry about a belligerent Russia, a rising China, and the vulnerabilities exposed by Covid-induced supply shocks—all of which have reenergized a longstanding criticism of Reagan-era political-economic shifts that hobbled productive industries. The Obama and Biden administrations both empowered tech companies at the expense of the primes; Biden, skeptical of free trade and hawkish on China, courted Silicon Valley firms that promised to bring back domestic manufacturing and reindustrialize the rust belt and former defense hubs. But in recent years talk about “software-driven reindustrialization” has become especially widespread on a faction of the new right. That the Trump adviser and conspiracy theorist Laura Loomer could rail on X against Lockheed Martin, with its “woke agenda,” for “delivering F-35 fighter jets that are simply not ready for combat”—and that Elon Musk could respond to her that, in any case, “crewed aircraft will be destroyed instantly by cheap drone swarms”—owes much to the rhetoric of Sankar and his peers.\n\nThis new Silicon Valley defense-tech and finance group—their grievances, ideology, and policy visions—has become central to Trump’s second term. Several defense-tech boosters have assumed powerful positions in the administration, most notably one of Anduril’s former senior directors, Michael Obadal, who was just confirmed as Army under secretary, the second-highest ranking civilian official in the Army. Since January Palantir and Anduril have received many billions in contracts, with more on the way. ICE has contracted Palantir since 2011 for software it uses to enforce sanctions and make arrests, and in April signed a new $30 million contract with the company to, in The New York Times’s words, “build a platform to track migrant movements in real time.” Presumably the deal will help ICE’s director, Todd Lyons, realize a vision he laid out that same month at the Border Security Expo in Phoenix, where he said that he wants his agency to run like Amazon Prime, “but with human beings.”\n\nAdvertisement\n\nThese trends show no signs of stopping. Defense Secretary Pete Hegseth has directed the Department of Defense—now calling itself the Department of War—to increase its spending on software, which, he stresses, is “at the core of every weapon and supporting system we field to remain the strongest, most lethal fighting force in the world.” Trump has signed executive orders designed to ease restrictions on defense exports and speed up and reduce oversight of the DoD’s acquisition process. In September the army announced a new venture-capital-style model for procurement called “Fuze.” Firms like Palantir and their new constellation of Silicon Valley funders stand to benefit handsomely from these developments. “We’re moving to a software-driven, autonomous…battlefield,” the managing director for a prominent private equity firm said at a defense summit earlier this year. “Well, if you want daily software upgrades, you gotta pay software margins.”\n\n*\n\nFew would contest that the political economy of American defense is troubled. Defense monopolies have stifled competition; companies have slowed their investment in production and concentrated instead on payouts to themselves and shareholders; costs and schedules have spun out of control. By now, as the scholar William Hartung has written, the federal government’s ballooning defense budget goes increasingly to “costly, dysfunctional weapons systems that are ill-suited to addressing current challenges.” Yet venture-funded defense-tech firms like Palantir and Anduril have positioned themselves as the solution to these ills without any clear evidence that they can deliver on that promise. The problem, put simply, is that they don’t have expertise in building things. Because they are above all instruments of financialization, designed to bring future values into the present, they tend to be better at generating short-term profits and juicing shareholder value than at creating durable, high-performing software or hardware systems.\n\nAnduril and other companies that offer “autonomous,” AI-enhanced hardware, for instance, have by now attracted criticism from a range of commentators: the evidence indicates that, despite their claims to the contrary, Silicon Valley drones and counterdrones have underperformed in Ukraine, where fighters have tended to prefer cheaper, hardier Chinese and homegrown drones instead. Adopting Palantir’s signature data-organizing software, too, could have significant problems for companies and government agencies in the long term. The software’s code is closed-source and privately hosted by Palantir, which retains the power—subject to the terms of its contracts and to the extent they prove enforceable—to change, update, or terminate it. Using it as the “data backbone” for a vast and complicated system makes it distinctly costly and burdensome to switch software in the future, not to mention to train and retrain its users.\n\nMeanwhile, as several critics have argued, the user loses a significant measure of control over the system itself. “The single fundamental problem with the Palantir contract is that the government is outsourcing all of the work to one company in one go,” a data expert told the New Statesman earlier this year, “and what you get is vendor lock-in. The state doesn’t understand the work, they can’t see the work…. You develop no knowledge, no understanding of it.” On the podcast Second Breakfast, the lawyer and former Army officer Eric Robinson related that, when he used Palantir’s software in the 2010s, “they would recode your data ingest so you couldn’t export it again,” with the result that “you had to pay for their tech to effectively be part of your order of battle…. It often seems like a form of long-term rent seeking.”\n\nIn the telling of companies like Palantir and Anduril, their innovation, efficiency, and software expertise qualify them to jump-start a new era of American industrial policy. But not only do they seem ill-suited for such a task, they have publicly backed the Trump administration as it destroys the foundations of what industrial policy the country has. Alex Karp, the CEO of Palantir, has, for instance, denounced “wokeness” for “corrupting and corroding our institutions,” echoing the rhetoric that Trump and other Republicans have used to attack measures like the CHIPS Act for including some redistributive initiatives and giving workers benefits like child care. We are now in a situation, in other words, where an array of right-wing firms and think tanks perversely extol the virtues of industrial policy and American renewal even as they support politicians and financial institutions that are currently dismantling the infrastructure to actually do industrial policy.\n\nAdvertisement\n\nHow did we get here? The answer lies, in part, in the fact that defense-related industries like the semiconductor sector have themselves long obscured their real relationship to industrial policy. It is a central tragedy of the long US century that military Keynesianism—the use of military spending to spur economic growth and enable spending on welfare and other public goods—has been the organizing principle for the country’s economy and social life since World War II. The defense budget—last year’s allocation was close to $900 billion—goes not just to weapons construction but also to a welfare state within a state: housing, health care, and social services. It funds a great deal of civilian industry, from wooden pallets to satellites and smartphones, not to mention research fundamental to the US economy and some degree of economic redistribution. Because of its sheer scale and reach, defense spending is unique in its ability to facilitate regional coalitions across party lines by directing funding to specific geographical targets: state-specific projects, bases, consortia, and so on.\n\nNational Archives and Records Administration/Wikimedia Commons An armorer’s assistant installing a machine gun in a Lockheed P-38 plane at an aircraft plant in the Western US, circa November 1942\n\nBy forcing policymakers to appeal to “national security” (which since the 1980s has expanded to encompass “economic security”)1 to justify any efforts at industrial policy or social welfare, this system has long hobbled our ability to build a better world. But during the 1970s and 1980s, when a newly organized right wing took aim at state spending and capacity across the board, even the essential national-security fields of electronics and defense found their access to long-term government support under threat. To retain it, they arrived at a kind of truce. In public, these firms would happily chalk their success up to their own entrepreneurial genius. Under the radar, however, a range of policymakers and industry leaders worked to patch together a precarious, largely hidden system of government support that allowed the businesses—albeit in compromised form—to keep relying on federal planning, funding, and stewardship.\n\nNow the new Silicon Valley defense firms are taking advantage of this state of affairs to press their own interests. Rather than downplaying their reliance on the government in public while reaping the benefits of industrial policy in practice, though, they have done just the opposite, indulging in rhetoric about the return of the strong state and “reindustrialization” even as they help dismantle the state in the service of financial capital. Understanding the implications of this shift requires grasping the complexities of the relationship that tech and defense firms have long enjoyed with US state power.\n\n2.\n\nIn moments of “revolutionary crisis,” Karl Marx wrote, men “anxiously conjure up the spirits of the past to their service, borrowing from them names, battle slogans, and costumes in order to present this new scene in world history in time-honored disguise and borrowed language.” The defense-tech elite are no exception: they talk obsessively about the past, transmuting political-economic reality into a story of great-men-as-founders. Karp praises the Manhattan Project and welcomes comparisons to Oppenheimer. A Los Angeles Times piece from last year discovered that Palmer Luckey, the much-profiled founder of Anduril, has a preoccupation with purchasing cold war military relics: the red nuclear phone, “a couple of submarines,” at least one ICBM site. He hopes one day, the profile notes, to acquire “the entire US ground-based nuclear deterrent system…to turn it into a vast museum.”\n\nTheir account of twentieth-century military-economic history is distinctly revisionist. In his appearance last year on The Merge, Sankar explained how to fix the defense-industrial base. “The reality is you focus on winning,” he said:\n\nI’m not a founder of Palantir, but I think about going back to that World War II–era period and the immediate cold war, it was founders. We think of it as Northrop Grumman and Martin Marietta, but it was Jack Northrop and Glenn Martin and Howard Hughes and Henry Kaiser, and even inside of government, the Kelly Johnsons, the John Boyds. These are uniquely hardheaded, creative, difficult people that are required to win. And I think every start-up understands that. That’s what a start-up looks like.\n\nThe truth is dramatically different. The two world wars turned industrial power into US military dominance not because they empowered the genius of individuals but because they built a new and formidable state.2 Industrial and state capacity—not to mention the relationship between industry and government—were forever transformed. World War I inaugurated the use of cost-plus contracts, which stipulate that the government pay for all the costs of development and production plus a set profit. World War II offered the US a taste of a centralized planned economy: the war effort consumed 57 percent of the national income, and the government itself converted all the plants it needed to manufacture war material.3 In 1942, for instance, the War Production Board—which centralized control of investment and production—forced the whiskey industry to divert 60 percent of its production to industrial alcohol and modernized productive processes.\n\nIt would not be an exaggeration to attribute the many new industries that emerged, modernized, or accelerated in the postwar years—aeronautics, vastly improved automobiles and motors, chemical and especially petrochemical firms, modern shipbuilding, electronics, atomic energy, logistics—to centralized government planning and funding. With government help, as Hartung notes in his study Prophets of War, the aviation industry’s production increased by 13,500 percent.4 New plants cropped up across the country, especially in the South and West, inaugurating the long-term industrialization of those regions. Cooperative large-scale applied research proliferated through the National Defense Research Committee, which commandeered both industry and academic resources and personnel. In his 1992 study of US industrial policy, the historian Otis Graham noted that the Defense Plant Corporation built “some 30 percent of the plant capacity on which American mobilization depended,” which was crucial to the postwar aircraft industry.5 Business leaders resisted their subjection to government administrators, and as soon as the war was over they sought to erase these years from public memory. But the fact remained that US defense contractors and technology firms owed their existence to extensive, heavy-handed government planning.\n\n*\n\nGovernment support, oversight, and coordination of important industries largely persisted throughout the cold war. In the immediate postwar period military contracts slowed, but the Korean War ensured another boom that lasted until the wind down of the Vietnam War two decades later. The Department of Defense “directed a large portion of the nation’s scientific and engineering resources throughout the postwar era,” Graham wrote, “frequently picking winning technologies and products by supplying the military’s clients—chiefly the weapons, aerospace, telecommunications, and data processing industries—with R&D support and purchasing of output.” The government covered nearly all basic research (which mostly occurs at government labs and universities), and much of the research and development conducted by private industry. Companies had plenty of money to invest and reinvest in production—and the DoD pressured them to do just that.\n\nScience History Institute An employee inspecting the control board for a solvent recovery system at the Hercules Powder Company plant in Hopewell, Virginia, 1940s\n\nAs the scholar Christophe Lécuyer shows in his study Making Silicon Valley, all this investment made the US semiconductor industry possible.6 DoD contracts remade Fairchild, the industry’s pioneering firm, into a major company, and Fairchild in turn brought suppliers and equipment-makers to the Bay Area. The DoD not only funded the development of microelectronics but prioritized incorporating them into military systems; starting in 1963, Lécuyer notes, proposals had to include them for the projects to receive funding.\n\nDefense Secretary Robert McNamara’s initiatives before and especially during the Vietnam War transformed defense spending and the industrial policy associated with it. Much was made by General Westmoreland, starting in the late 1960s, of the promise that war would become an “electronic battlefield,” with armies taking advantage of all “the advanced technology of communications, sensors, fire direction, and the required automatic data processing” to control the fighting from afar.7 That this vision failed to materialize and cost the US dearly—in lives, reputation, and resources—doesn’t seem to have led anyone to rethink its premises.\n\nIn the late 1960s disenchanted defense workers organized to shift industries such as chemicals and electronics away from war and toward the public good, or at least toward private consumption—an effort known as “civilianization.” At the same time, a civilian market for computer chips was exploding. Those initiatives, the planned Vietnam wind down, and détente with the USSR all helped shrink the federal government’s spending on defense in general and military R&D in particular. But it was a brief experiment that came with significant backlash, helping propel Reagan to the presidency and shaping his industrial policy. The federal share of research dollars remained high for much of the cold war, funding the development of lasers, nuclear energy, rockets, aerospace, computers, scientific instruments, data processing, and telecommunications while neglecting automobiles, steel, pharmaceuticals, and textiles—all of which moved offshore to a greater degree than they already had.\n\n3.\n\nThe first major political-economic changes after World War II came with the neoliberal turn of the 1980s and 1990s. During these years several crises descended upon a range of productive sectors that had historically relied on federal industrial policy. Internationally, Japan perfected production techniques in high-tech manufacturing—of cars, machine tools, memory chips, and other electronics—and quickly approached dominance in many areas considered central to “national security,” like semiconductors and supercomputing. American pundits at the time identified this trend as a direct threat to American-style capitalism and US power.8 The period’s neoliberal economic reforms—which reduced and limited the nature of government spending while demonizing the most basic forms of long-term planning—weakened productive industries still further, leaving manufacturers beholden to shareholder demands for ever more profits and vulnerable to new threats from financial institutions.\n\nThese conditions posed a distinct threat to productive sectors like the semiconductor industry. And yet Intel, which by 1992 was leading the industry in cutting-edge chips, managed to thrive nonetheless. When reporters asked how they did it, the company’s executives pointed to what they called “Moore’s Law,” the idea, named after Intel cofounder Gordon Moore, that chips regularly became smaller and more powerful according to something like a natural principle. Moore’s Law became a fixture of the industry’s marketing presentations, press releases, and internal conferences.9 Over the years it helped convince defense leaders like Clinton’s secretary of defense, William Perry, and his protégée Ash Carter that technological solutions could eventually be found for their most pressing and difficult political problems. Moore’s Law remains an unquestioned assumption of scientific, military and national security state discourse and policy, undergirding the entire political-economic imagination of the post–cold war United States. Just as intellectuals started worrying that there might be fundamental limits to capitalist growth, it posited a horizon of infinite progress.\n\nThe truth was more complicated. Intel, founded in 1968 by Moore and Robert Noyce, came to prominence by developing some of the first commercial metal-oxide semiconductor chips. Those semiconductors had immediate, tangible benefits, including low power consumption, high noise immunity, and cost efficiency. Working from that basis, the company did regularly improve its output with a kind of lawlike consistency in this era. But it wasn’t Moore’s Law that won the battle with the Japanese. Instead, Intel and others in the semiconductor industry built coalitions to carve out exceptions to many of the period’s neoliberal reforms, reaping the benefits of extraordinary state support. Among other things, the Reagan administration offered tax incentives to subsidize factory construction and investment in manufacturing, encouraged coordination and cartelization by offering antimonopoly relief and state planning, and used economic sanctions and diplomatic pressure to force concessions from Japan, such as giving foreign—which in effect meant US—chip manufacturers 20 percent of their market share and sharing significant manufacturing knowledge.\n\nIntel Free Press/Wikimedia Commons Andy Grove (left), the longtime head of Intel, sitting with the company’s founders, Robert Noyce and Gordon Moore, 1978\n\nUnder Reagan it was an open secret that the government’s treatment of the semiconductor industry, among others, amounted to a form of industrial policy. These measures had the backing of a powerful—if peculiar—bipartisan coalition that was preoccupied with sustaining American hegemony: national security and foreign policy hawks, factions in the business world, and a group of tech-friendly liberals, like Massachusetts senator Paul Tsongas and Tennessee senator Al Gore, who became known as the “Atari Democrats.” They were reacting to a new right that objected to industrial policy as such, on the grounds that any government planning and economic intervention smacked of communism: in late 1980 the first installment of the Heritage Foundation’s Mandate for Leadership—like its successor, Project 2025—called for destroying large swaths of government by loosening regulations and oversight, centralizing power in the executive, demolishing state capacity, and eliminating or significantly cutting funding for many programs and agencies.\n\nThe new right lacked the political leverage to end industrial policy entirely. But between 1980 and 1993 they succeeded at making it politically toxic, forcing the industry and its allies to adjust their tactics. Bill Clinton, an Atari Democrat, took office hoping to build the US’s own version of Japan’s powerful Ministry of International Trade and Industry; however hostile he was to labor, he implemented significant industrial policy for semiconductors immediately after his election. After Newt Gingrich’s Contract for America coalition swept Congress in 1994, however, the administration’s room for maneuver narrowed. It was still able to ensure some level of subsidies and planning for semiconductor firms like Intel. But it came to rely heavily on foreign policy measures—like sanctions, trade deals, diplomatic pressure, and throwing around US power to shape new international economic organizations like the World Trade Organization—to open new markets and ensure other benefits for tech companies. By the end of Clinton’s second term, a kind of tacit settlement had locked into place. Even as they continued to depend on these various forms of state support, semiconductor companies, tech entrepreneurs who relied on ever-improving semiconductors, and politicians on both sides of the aisle would insist they owed their success to the information-tech revolution, with its promise of infinite growth and cheap consumer goods, all predicated on the work of individual entrepreneurial geniuses.\n\nThis rift between rhetoric and reality has only grown since. Today’s executives hardly seem to understand the conditions of their own industries; it is as if, on some level, they believe the flattering public narrative their predecessors spun. During his interview on The Merge, Sankar remarked that he and his peers are “children…of a Noycean culture.” In a sense this is not untrue. Intel’s Noyce and Sankar both downplay their industry’s debt to industrial policy; Palantir, not unlike Intel before it, is in part in the business of selling what Wired recently called “a seamless, almost magical solution to complex problems.” But Sankar clearly meant the analogy in a different sense: to lay claim to Noyce’s record of success, to brandish his legacy of American entrepreneurial technological genius, and to insist that Silicon Valley firms’ track record of such triumphs should entitle them to remake government in their own image.\n\n*\n\nThe defense industry faced the same pressures that nearly destroyed US semiconductor firms at the dawn of the post–cold war era. In his last year in office Jimmy Carter reversed the cuts that had depressed the industry for much of the 1970s, and in his first term Reagan initiated an enormous military buildup. All this, Graham writes, strengthened the military’s claim on “the nation’s scientific and engineering resources, and thus its influence on industrial structure.”\n\nBut other developments spelled trouble. By the early 1980s financial regulations were being loosened, and corporations were under increasing pressure—legal, managerial, and structural—to secure shareholder profits in the short term at the expense of long-term health. A low-margin productive industry like defense was badly suited to the era. By the mid-1980s firms were focusing on increasing their financial performance by using stock buybacks and cost-reduction strategies like just-in-time inventory management—ordering only enough resources to cover immediate needs. All this compromised their ability to respond flexibly to crises and to make high-quality products.\n\nIn 1985 the Reagan administration started reducing defense spending again and limited other avenues for profit. Facing increased political scrutiny, Reagan officials had recently made a big show of auditing firms for the appearance of wasteful spending, introducing policies that tightened defense profits and increased accounting paperwork. Many companies, like GE, curtailed their defense wings or left the sector entirely to boost their stock values for an increasingly defense-skeptical Wall Street. The 1980s also saw the rise of corporate raiders, later known as private equity firms, which would acquire a majority share of a company’s stock, take control of its operations, and then “restructure” it, which usually meant stripping it for parts and paying themselves astronomical sums of money. Between 1982 and 1990 such outfits nearly destroyed several defense firms, including Martin Marietta and Lockheed, and left them weakened with large debt-to-equity ratios. With loosened financial rules and low margins came consolidation: between 1985 and 1988 ten of the top sixty defense firms acquired or were acquired by others.\n\nPerhaps no person’s career tracks how the defense industry navigated these changes more clearly than that of Norm Augustine. Born in 1935, Augustine got his start in defense at the Douglas Aircraft Company in 1958. His first foray into government came in 1965 as one of McNamara’s young hires, brought in from the private sector to cut waste using “economic efficiency” measures like cost-benefit analysis. He then ping-ponged between the public and private defense sectors: after serving as the under secretary of the Army he joined Martin Marietta, then one of the country’s largest defense firms. Between 1980 and 1982, meanwhile, he chaired the Defense Science Board, authoring reports on threats to the defense industrial base and its dependence on the troubled semiconductor sector. Rising in the ranks of Martin Marietta over the 1980s, Augustine saw that defense was in turmoil; he later referred to the decade as the industry’s “dark ages.”\n\nDenver Post/Getty Images Martin Marietta CEO Thomas G. Pownall (center) and Norman Augustine (right) talking with a shareholder, 1983\n\nThe fall of the USSR and Clinton’s electoral victory brought a new existential threat. Federal defense funding plummeted: between 1989 and 1997 procurement declined by 60 percent. The result was something like the industry’s Great Depression; in 1995 Augustine told a House committee that an estimated three quarters of the sector, about 90,000 firms, had evaporated in the span of a decade. As defense programs became fewer and more expensive, the remaining firms started making riskier bids, overpromising on cost, time, and quality.\n\nIn 1993 Clinton’s defense secretary, Les Aspin, invited the CEOs of major defense firms to the Pentagon for a dinner that would become known as the “last supper.” The then-deputy defense secretary, William Perry, showed them a slideshow of necessary defense capacity: “We expect defense companies to go out of business,” he told them. When we talked in a recent interview, Augustine told me he feared the administration would nationalize at least significant parts of the industry. They were faced with either entering new markets, consolidating, or downsizing. In the five years that followed, Augustine consolidated many firms under Lockheed Martin, itself the product of the merger of Lockeed and Martin Marietta, forming the country’s largest defense firm. In 1995 the new company went public, at which point it started prioritizing stock prices and other contemporary markers of financial health.\n\nIt worked: in 1997 Augustine wrote that the company’s share price had nearly doubled in two years. And yet in the process Lockheed Martin closed a quarter of its plants and laid off 100,000 workers, vastly paring down management and labor in the name of efficiency. The benefits of all this cost-cutting rarely went to the government. Nor were many of the gains reinvested in production. Lockheed Martin had become good at getting contracts; Augustine wrote in the Harvard Business Review about harnessing the “natural competitive instincts in human beings.” But the products themselves suffered: they were more expensive, slower to deliver, and of lower quality.\n\n*\n\nThe state’s priorities were also changing. The Gulf War seemed to vindicate Westmoreland’s Vietnam-era dreams of an “electronic battlefield.” William Perry, soon elevated to defense secretary, became a firm believer that the US was on the cusp of a “revolution in military affairs”—the idea, as the RAND analyst Paul K. Davis has summarized it, that “technological developments sometimes make possible a qualitative change in the nature of warfare.” That conviction moved him to prioritize funding, developing, and promoting “dual-use” technologies that could be applied to both commercial and military settings. He and Clinton built closer relationships with technology firms, offering them greater access to government and policymaking.10 In the late 1990s, as the researcher Barry D. Watts notes in a 2008 report, the Pentagon encouraged defense companies to “act more like commercial firms.”\n\nAugustine was well-positioned to adapt to these conditions. He had advocated for government support for the semiconductor industry during its crisis: asking “why DoD or the government should provide support for the semiconductor industry,” he testified to the Senate in 1987, “would be much like asking at the outset of World War II why we should buy ships and airplanes because it might help the shipbuilding and the aircraft industries.” From his perch on initiatives like the Defense Science Board, he not only observed but shaped how Intel and others had navigated the changing political-economic waters; now he hoped to replicate their accomplishments.\n\nBetween 1993 and 1998, as Hartung has shown, Augustine lobbied intensely—and successfully—for immense government subsidies for defense in general and the new Lockheed Martin in particular. Those subsidies came in many forms, from aid for mergers—“closing plants, relocating equipment, paying severance to laid-off workers, and providing ‘golden parachutes’ to board members and executives,” as Hartung puts it—to antitrust exemptions and subsidies for arms exports (especially to new NATO countries). “To say that Augustine is wired into the Washington policy-making process is an understatement,” Hartung noted in 1996. “For most of his career, he has been one of a handful of people drawing up the blueprints for American defense policies and deciding where the wiring should be placed.”\n\nIn the 1990s companies like Intel experimented with setting up their own venture capital arms, government-backed consortia, and new institutions whose purpose was to plan and shape the markets around them. Augustine followed their lead: he and other defense industry leaders managed to insulate themselves both from democratic accountability and from the vagaries of anti-statist politics by creating experimental public institutions. In 1998 George Tenet’s CIA enlisted Augustine to help found a nonprofit venture capital firm called In-Q-Tel that gives start-ups long-term guidance and directs them to lucrative, stable government contracts. Unlike traditional VCs, In-Q-Tel claims to focus more on technology and less on profits, though over the years it seems to have helped these new companies make money more than it has helped the government acquire important technology. It was In-Q-Tel that assured the success of, among others, Palantir, Anduril, and the drone company Skydio.\n\nAugustine, who turned ninety this July, hardly ever uses words like “industrial policy” or “neoliberalism,” but in practice he and his peers became influential critics of the neoliberal turn. He has argued that, in the financialized economy, “the tax structure discourages long-term investments” and lamented that shareholders hoping for short-range profit want Lockheed Martin not to “invest in research.” Elsewhere, he has called for renewed federal funding for public education and criticized US companies for moving “much of their manufacturing capability abroad.” In an influential 2005 report called Rising Above the Gathering Storm, he and his colleagues argued that “the prosperity the United States enjoys today is due in no small part to investments the nation has made in research and development at universities, corporations, and national laboratories over the last fifty years.” The “pressures” on that sector, they warned, “could seriously erode this past success.”\n\nIn such moments, Augustine sounds uncannily both like architects of Bidenomics such as Jake Sullivan and Jennifer Harris and like right-wing tech-defense figures such as Sankar, who has similarly criticized “the financialization of the defense industrial base.” There is a certain irony here: by founding In-Q-Tel and seeding a bipartisan consensus around what plagued America’s political economy, Augustine—perhaps inadvertently—helped create the coalition now hoping to displace the company he has spent much of his life running.\n\n4.\n\nDefense stocks tanked in 1998 and 1999, and credit agencies downgraded their debt to nearly “uninvestable” levels. As the industry consolidated, firms got even bigger, more complex, and, via joint contracts, increasingly linked to one another. By 2000 they were in a delicate position. With relatively low profits and cash flow but high debt-to-equity ratios, they increasingly focused less on investing in essential R&D than on trying to grow in the short term by competing recklessly for contracts.\n\nLibrary of Congress Prints and Photographs Division A pilot operating the instrument panel of the Lockheed Martin C-130J-30 Hercules cargo plane during a demonstration flight for Pentagon personnel and press over Andrews Air Force Base, Maryland, 1998\n\nThen came the wars in Iraq and Afghanistan, which, as Hartung has shown in Prophets of War, inaugurated an industry-wide bonanza. Companies like Lockheed Martin entered new markets: “enhanced interrogation,” translation, dubiously legal surveillance. The Bush administration was full of defense monopoly affiliates, among them Secretary of the Air Force James Roche, a former vice president at Northrop Grumman; Secretary of the Navy Gordon England, a former executive at General Dynamics; and Edward Aldridge, who was a member of Lockheed Martin’s board of directors while serving on the president’s commission on space.\n\nCongress subsidized Lockheed Martin for arming new Eastern European NATO members; in 2008 US companies accounted for two thirds of the world’s new arms sales. At the same time, the DoD came to focus on counterinsurgency and counterterrorism techniques that relied heavily on information technology, like cyberwar and “network-centric warfare.” Defense Secretary Donald Rumsfeld wanted to make “the leap into the information age” by pursuing drones and surveillance.\n\nNone of this meant that the trend toward military privatization slowed. It continued apace through the Iraq War, from the US military’s contracts with mercenaries like Blackwater to private contracts for hardware. On Second Breakfast, the former Green Beret Justin McIntosh describes how outsourcing military functions to contractors during the Syrian conflict forced him into a situation not unlike The Wages of Fear:\n\nI had a truck that had a bent rod. These trucks that we’re driving around in, these MRAPs and these large RG-33s…[require] a contractor [to] come in and work on it. We were in an area where we had been shot at. I had to medically evacuate some guys. The contractors did not want to travel. They wanted me to drive this truck hundreds of kilometers to the safe base where they could then repair it.\n\nThe problem, McIntosh continued, was that “we had already taken all of that capability that existed within the United States military”—for instance, the ability to repair its own equipment—and “shifted it over to the private sector. It gave them control.”\n\n*\n\nThis tendency toward privatization continued through the Obama administration, during which defense officials started to fixate on reducing costs. (“The gusher has been turned off,” Defense Secretary Robert Gates announced in 2010.) Obama saw bloated defense monopolies as an obstacle to this goal. But rather than addressing the structure of the industry or its political economy, the administration focused on improving its topline numbers by switching out the supposedly corrupt, atrophied defense giants for new firms from the Democrat-friendly tech sector, which promised to replace the functions of the legacy firms more cheaply.\n\nAn influential proponent of this turn was Ash Carter, whom Obama nominated as his defense secretary in 2014. Carter and his deputy, Robert Work, had a “simple but ambitious” agenda, as the anthropologist Roberto González has written: “to harness the best and brightest ideas from the tech industry for Pentagon use.”11 Carter’s emphasis would be not on training soldiers but on developing drones, automation, satellites, and other cutting-edge defense technologies sourced from Silicon Valley.\n\nCarter’s focus on unmanned tech was not exactly a break from the Bush era, but the shift to the Valley was. Fueled by experiments like In-Q-Tel, the tech-defense coalition was already looking to gain market share: in 2014, nearly a year before Carter took office, SpaceX sued the Air Force for preferring the primes; in 2016 Palantir filed a lawsuit against the Army for allegedly trying to develop internal intelligence software without adequately considering commercial options. (One of Anduril’s founders, Trae Stephens, has claimed that these lawsuits helped Anduril win defense department contracts.)12 Obama and then Trump both also expanded the department’s ability to use its “other transaction authority,” which allows the government to do business more easily with commercial entities, for example by letting it sign contracts faster and with less oversight.\n\nThe defense start-ups that successfully attracted Silicon Valley financing relied on the extraordinary wealth and political lobbying connections of their founders. “Every defense company that had been founded by a billionaire was a success,” as Luckey—who sold his VR company, Oculus, to Facebook in 2014 for $2 billion—noted in 2024. “I hate that we live in a country where that’s the case,” he added. “But I realized that I had a unique responsibility as one of the very few people who was willing to work on national security and blessed with the resources to actually make a real go at it.”\n\nObama officials proved receptive to such lobbying. During his tenure Carter set up an In-Q-Tel-inspired program called Defense Innovation Unit—Experimental (DIUx), which worked closely with a new Defense Innovation Board, chaired by the former Google CEO Eric Schmidt, to determine the government’s investments in emerging technology, from drones to AI. It encouraged Silicon Valley firms and funders with the promise of long-term contracts for defense tech, as well as evaluation and testing—in effect ensuring their success in advance. Carter also laid the foundations for projects that came to fruition under the first Trump administration: between 2017 and 2019 the Army, the Air Force, and the Navy all launched their own experimental institutions designed to set up tech start-ups with military contracts.\n\nPrivate equity and venture capital saw an opportunity to make nearly guaranteed profits off the government’s investments. Between 2021 and 2024, VCs poured $130 billion into defense. In their book Unit X (2024), two of DIUx’s early directors, Raj M. Shah and Christopher Kirchhoff, claim that by 2017 their work had excited “investors and entrepreneurs in Silicon Valley” about working with the Pentagon by lowering “barriers to entry.” (They decline to specify which ones.) When James Mattis visited DIUx under the first Trump administration, in 2017, Shah and Kirchhoff arranged for him to have dinner with the tech investor Sam Altman (then at Y-Combinator) and the venture capitalist Marc Andreessen, who insisted that the Valley was interested in the defense industry and implored him to support the project. Mattis was enticed by the work they were doing on drones—a later fixation of Andreessen’s.\n\nEmployees at Google expressed discontent with the company’s defense contracts, organizing to block initiatives like Project Maven, a machine learning program for the Pentagon. The project was hardly promising: as Alexander Cockburn wrote last year in Harper’s, an Air Force testing unit found in 2011 that, “among numerous other deficiencies,” the drone-mounted cameras on which it relied “could not ‘readily find and identify targets,’ and its transmission rate was too slow.” But DoD funders were eager to collaborate with Silicon Valley all the same. (According to Cockburn, Amazon, Microsoft, and Palantir were among the subcontractors who joined the Maven project after Google declined to renew the contract in 2018.) Since then employers have used the threat of AI to shrink the pool of tech jobs, costing the workers leverage. By 2022 employee dissent had been largely squashed: Google and other major defense firms all but declared that they were happy to work with the military. Now executives at tech and tech-defense firms brag about joining the army reserves to help with the design and purchase of their products—an arrangement that seems rife with potential conflicts of interest.\n\nThe Biden administration continued many of these Obama-Trump trends. Defense Secretary Lloyd Austin appointed Apple’s Doug Beck to direct DIU—as it was by now simply called—and empowered him to report directly to Austin. Congress gave the program nearly $1 billion for the 2024 financial year, and Biden awarded important hardware contracts to Palantir and Anduril. SpaceX doubled its federal contracts at the beginning of the Biden administration; they had practically doubled again by the end. In late 2022 Austin established the Office of Strategic Capital (OSC) to push investment in defense-oriented small businesses and tech start-ups; under the One Big Beautiful Bill Act, it will have $200 billion to spend, and likely more in the 2026 National Defense Authorization Act. Perhaps most visibly, Deputy Defense Secretary Kathleen Hicks enthusiastically embraced all things tech: at a 2024 event organized by Andreessen’s VC firm, she emphasized that “moving fast and breaking things is necessary to win wars.”\n\nNonetheless DIU’s leaders and their Silicon Valley allies felt that the Biden Department of Defense wasn’t friendly enough. By 2023, Shah and Kirchhoff complain, it still awarded most of its contracts to the primes. “It seemed as if the whole Biden team had forgotten about DIU and Silicon Valley,” they write, “even as Ukraine was aggressively deploying DIU technologies on the battlefield.” Their vision for the department is blunt: “All the Pentagon needs to do is be a great customer. Buy products, and trust that good venture capitalists will pour money into the companies building those products.”\n\n*\n\nAll this support for the tech-defense sector has so far had disappointing results. A congressionally mandated report produced this year by the Government Accountability Office suggests that there were no metrics by which DIU could measure its success at actually bringing new technology into the military. The Biden defense department’s embrace of tech yielded such fruits as the “Replicator Initiative,” which committed in August 2023 to delivering “multiple thousands” of new autonomous systems in eighteen to twenty-four months. Hartung told me that many industry experts found that timeline hard to believe: no program had ever delivered products that fast. The deadline the initiative set has now passed, and his skepticism seems warranted. The initial delivery was said to be in the hundreds, and The Wall Street Journal recently reported that some of the program’s systems “have been unreliable, or were so expensive or slow to be manufactured they couldn’t be bought in the quantity needed.”\n\n\n\nFor many observers, the first real test of Silicon Valley defense tech is how US-made drone technology fares in Ukraine, a war often cited as a laboratory for unmanned warfare. In a speech this past August, published in the Free Press, Luckey described going to the front lines “just a few weeks” after the full-scale Russian invasion “to train Ukrainian soldiers on advanced military technology that I had developed.” He witnessed “remarkable” feats, he said: “with drones costing just a few thousand dollars each, a handful of Ukrainian pilots remotely carpeted airstrips with explosives thousands of miles into Russia.” (He seems to have been playing fast and loose with chronology: Ukrainian drones reached hundreds of miles into Russian territory that December; it would take them still longer to reach thousands.)\n\nDrone technology has indeed been crucial to the conflict, especially more recently, as troops have been harder to come by on both sides. But a range of commentators have cautioned against assuming it therefore represents “the future of war.” Prominent defense think tanks like RUSI have warned that “overreliance on uncrewed aerial systems” has created “significant problems” for Ukraine, in part because it “plays into Russia’s strengths” at short-range air defense and other antidrone capabilities. William LaPlante, Biden’s under secretary of defense for acquisition and sustainment, has echoed this view. “Don’t tell me it’s got AI and quantum in it. I don’t care,” he said at a 2022 conference. “The tech bros aren’t helping us too much in Ukraine…. It’s hardcore production of really serious weaponry. That’s what matters.” (Many drone companies, moreover, still rely on Chinese parts.) The subtext behind the flurry of puff pieces treating drone war as an inevitability is that a trough of money in the small-to-midsize drone market is up for grabs, over which various coalitions are starting to compete.\n\nSean Gallup/Getty Images A soldier in a US Army platoon specializing in unmanned aircraft systems watches an Anduril Ghost-X drone landing during an exercise at the Hohenfels Training Area, Bavaria, February 3, 2025\n\nTo the extent that drones have proven essential in Ukraine, for that matter, hardware made in the US—by firms like Microsoft, Skydio, AeroVironment, and Cyberlux—has fallen short of expectations. Ukrainians have found US-produced drones “fragile and unable to overcome Russian jamming and GPS blackout technology,” The Wall Street Journal reported last year. “At times, they couldn’t take off, complete missions or return home.” Skydio recently announced that one of its controllers was vulnerable to radio interference. The trend of connecting more devices together to create an “Internet of things” often creates new vulnerabilities in turn.\n\nAnduril’s output is no exception. The defense blogger who writes under the name Secretary of Defense Rock observed in one widely shared piece that the company’s products “often amount to little more than rebranding existing technologies with a Silicon Valley gloss.” One of their much-touted anti-drone interceptors, the essay suggests, has “the same core function” as a familiar Raytheon product, “with marginal enhancements, repackaged in a sleeker design and infused with branding language that flatters venture capital expectations more than it reflects operational novelty.” Anduril continues to contend both with high costs and with certain problems in the field: “During an exercise last year in the Pacific called Project Kahuna,” according to the Journal, “drones from different manufacturers connected by Anduril’s software struggled at times to coordinate and perform tasks when out of sight from the operator.” Last month, Reuters has reported, the Army’s chief technology officer circulated a memo identifying a “very high risk” factor in Anduril’s prototype for a “next generation command and control” battlefield communications network: “We cannot control who sees what, we cannot see what users are doing, and we cannot verify that the software itself is secure.”\n\nNone of this should be surprising. Anduril is making moves to scale up production, claiming that it plans to open a “hyperscale manufacturing facility” in Ohio next year—but VC–funded firms don’t usually have the incentives or structure to prioritize taking on high-risk hardware projects. Often such companies focus instead on acquiring other firms in areas they’d like to enter, whose “founders” and engineers tend to quickly depart. They often make cuts for “efficiency” that produce an attractive financial picture in the short term, but damage the company in the long run. “The primary product of the defense VC strategy,” the scholar Elke Schwarz has written in a recent article, “is not a defense technology as such, but financial returns achieved through growth.”\n\nWorse still, she notes, venture capital’s “mandate for hypergrowth” means that VC-funded companies feel even more pressure than regular ones to produce exponential profits; when those companies make defense products, investors stand to reap enormous windfalls if armed conflict escalates around the world. “To get the military-industrial sector to grow fast,” Schwarz writes, “perhaps the best catalyst is war, or at least the embrace of its possibility.” Indeed, in 2023 a representative of America’s Frontier Fund, a VC firm backed by Thiel and Schmidt, told investors that if “the China/Taiwan situation happens,” or more generally “if there is a kinetic event in the Pacific,” then the fund’s investments would go up ten times “overnight.”\n\n5.\n\nResisting the defense-tech sector’s great man theory of history has grown all the more urgent now, as the Trump administration seems intent on placing those “great men” at the helm of the national security state and entrusting them with reindustrializing the sectors attached to it. Michael Obadal, the former Anduril senior director who is now Army under secretary, is part of a large cohort of Silicon Valley–adjacent figures in the administration: Dan Driscoll, a onetime J.D. Vance adviser with a background in private equity and venture capital, was confirmed as Army secretary13; Steve Feinberg, founder of the notorious private equity firm Cerberus Capital Management, which in recent years has invested heavily in defense tech, is in as deputy secretary at the Department of Defense, where he is using his experience to “restructure” the Pentagon; the retired general and venture capitalist Dan Kaine is now chairman of the Joint Chiefs of Staff; the Office of Science and Technology Policy is now headed by Peter Thiel’s former chief of staff; and the assistant secretary of defense for critical technologies is now Michael Dodd, also known as “the Doddfather,” an alumnus of DIU.\n\nAt least until the administration’s recent announcement that it is seeking an equity stake in Lockheed Martin, the primes appeared mostly sanguine about their aspiring competitors. Congress—which tech-defense firms spend millions lobbying14—writes the yearly defense budget, and primes have historically wielded considerable power there; they still receive the bulk of defense spending. Among the legacy firms the prevailing consensus has been that the upstarts will not be able to replace them: their products, after all, are already battle tested.\n\nEven so, the defense-tech contracts are pouring in. The Golden Dome missile defense program—a $175 billion-plus redux of Israel’s Iron Dome and Reagan’s Star Wars missile defense program, which experts call just as unfeasible as it was in the Eighties—seems to be shaping up as a cash giveaway to the tech-defense right; a joint bid from SpaceX, Anduril, and Palantir is reportedly the front-runner for the contract. (Hegseth has ordered major cuts at the Pentagon testing and evaluation office that a congressional panel recently tasked with assessing the program.) Other start-ups hope to privatize hardware testing, and Palantir seems to be positioning itself to assume some of the same functions of the embattled National Oceanic and Atmospheric Administration. New Pentagon rules that facilitate “anything-as-a-service” contracting allow private companies to shut off or modify their products as they desire (within contractual constraints, assuming these are followed), making US arms exports considerably less appealing to other countries but allowing the companies veto power over the use of their services or weapons—and further opportunities for rent-seeking. This past May, Luckey announced that Anduril would, as 60 Minutes put it, surpass “$6 billion in government contracts worldwide” by the end of the year. “We buy a lot of things from Palantir,” Trump said at a recent White House AI summit, calling out Sankar by name.\n\nScott Legato for Palantir Technologies/Getty Images Palantir CTO Shyam Sankar giving a keynote speech at the Inaugural Reindustrialize Conference in front of a projection of Intel cofounder Robert Noyce, Detroit, Michigan, June 26, 2024\n\nDefense-tech executives clearly hope to take advantage of the post-Covid surge of interest in industrial policy. There has been a great deal of chatter in right-wing circles, from Oren Cass’s American Compass to the Heritage Foundation, about the prospect that the US could move from a supposedly feminized service-based economy to a masculine-coded, producerist one organized around defense manufacturing. (In April, Fox News ran the chyron “TRUMP’S MANLY TARIFFS: PUNDIT BELIEVES IT COULD REVERSE CRISIS IN MASCULINITY.”) Even institutions like the American Enterprise Institute, which have historically reviled industrial policy in any form, have jumped on board, publishing papers endorsing industrial policies of different kinds tied to “national security.”\n\nPalantir’s leaders have echoed this rhetoric for their own purposes: Sankar lamented on The Merge that the best minds have gone into fields like ad-tech rather than defense engineering; Karp has declared that US industry has degenerated in the past fifty years to focus on “the consumer market” rather than using technology to “address challenges of industrial and national significance.” Trump himself seems to alternately contradict and endorse this agenda. He has been especially critical of CHIPS, accusing it of offering companies money they didn’t need and requiring them to hire “woke people” that hampered their success; at a recent AI summit he encouraged “all American companies to join us in rejecting poisonous Marxism in our technology.” It is as if he thinks that chip manufacturing can be brought back to the US through permitting reform and tariffs alone. Appalling immigration raids like the recent one on a Hyundai factory in Georgia have conflicted with the administration’s aim to learn from foreign expertise, producing extreme international backlash.\n\nMost recently, under Feinberg’s aegis at the DoD, the administration has pioneered an entirely new form of statecraft: running the Pentagon like a private equity firm. In the past two months the government has made a slew of one-off deals with companies like NVIDIA, AMD, Intel, and a rare earth mineral company called MP Materials. At the center of some of these agreements is a novel reading of the Defense Production Act, which the Senate Armed Services Committee is trying to formalize via a new provision allowing the government to make equity purchases in private firms. The provision has yet to pass—which has not stopped the administration from going ahead anyway.\n\nThe MP Materials agreement is instructive. Feinberg, no stranger to investing in the defense world, reportedly negotiated the deal, which includes a provision to buy magnets from the company despite the fact that they only started manufacturing magnets last year. By offering a price floor and production guarantees, the Department of Defense made it possible for Goldman Sachs and JP Morgan to finance the issuance of equity in the firm—at which point, seemingly for the first time in US history, the DoD itself bought enough equity to become the company’s largest single shareholder and provided a $150 million loan for the company’s California mine.15\n\nEach of these deals works a bit differently. CHIPS had promised Intel $11 billion on the condition that it met certain milestones, including building an arguably unnecessary Ohio megafactory; when the firm appeared unlikely to meet those conditions, the Trump administration exchanged the remaining money for roughly 10 percent equity in the company. With AMD and NVIDIA, the mechanism looked more like a straightforward shakedown: Trump announced that if NVIDIA wants to continue selling AI chips to China, it has to fork over 15 percent of the profits.\n\nThese moves hardly amount to a real industrial strategy. One-off coercive deals with individual companies already seem unlikely to reindustrialize the country, and it remains unclear what the administration will do with its new assets. But that outcome seems even less plausible as the Trump administration takes a sledgehammer to the government’s capacity, oversight, and industrial policy. In a mere nine months the administration has destroyed the infrastructure of research and development on which the semiconductor industry and many others rely; done its best to “get rid of” the “horrible, horrible” CHIPS Act, including the new research infrastructure it created; threatened to arbitrarily revoke awards and enacted swiftly changing tariffs that damage industries; behaved so erratically toward the US’s longtime allies that the EU and others have started looking elsewhere to buy weapons; erased the nonpartisan image on which the military depends for its continued funding and ability to operate; decimated the Pentagon’s civilian staff; devastated green industries while simultaneously promising to drive the price of oil so far down that the industry believes it will cause significant bankruptcies; and curtailed the Department of Defense’s product testing, among much else. None of the defense-tech firms that praise industrial policy in theory have launched any serious public protest against these decisions. The more contracts they get, meanwhile, the more government resources they will siphon away from investing in fields—like climate technologies, welfare, or alternatives to plastics—that would benefit the US’s economy or security.\n\nBigger tech companies such as Meta, Amazon, and Google have, for their part, also moved much closer to the Trump administration. They seem indifferent about the destruction of the infrastructures of research and support upon which they previously relied, perhaps because they believe they can hire researchers on a mercenary basis, outsource research and development to AI, or replace government functions with private ones—a doubtful prospect, since the government’s function as a neutral evaluator and standard-setter seems impossible to replace.16\n\nThe practical problem with this vision, to say nothing of its moral and ethical failings, is that it can only deal with the short term. “We love disruption,” Karp said during the company’s quarterly earnings call in February. “Disruption, at the end of the day, exposes things that aren’t working. There will be ups and downs. There’s a revolution. Some people are going to get their heads cut off. We’re expecting to see really unexpected things and to win.” Tech companies and venture-capital firms have become experts at leveraging this sort of “disruption” to generate value for their shareholders on the basis of imagined future profits, and firms like Palantir and Anduril are no exception. But now they have become so voracious, so all-consuming, that they are putting the country’s productive industries at risk. In the process, they threaten to destroy not just the source of their own profits but the spending and investment that lie at the foundation of the US economy. We may all end up with our heads cut off.",
      "source": "The New York Review of Books",
      "url": "http://www.nybooks.com/online/2025/10/04/the-war-over-defense-tech/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "NVIDIA Corporation $NVDA Shares Bought by Accurate Wealth Management LLC",
      "content": "Accurate Wealth Management LLC increased its position in shares of NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 10.3% in the second quarter, according to its most recent 13F filing with the Securities & Exchange Commission. The institutional investor owned 96,867 shares of the computer hardware maker’s stock after purchasing an additional 9,061 shares during the quarter. NVIDIA makes up approximately 2.4% of Accurate Wealth Management LLC’s holdings, making the stock its 6th biggest holding. Accurate Wealth Management LLC’s holdings in NVIDIA were worth $15,894,000 at the end of the most recent reporting period.\n\nSeveral other hedge funds and other institutional investors have also recently added to or reduced their stakes in the stock. Brighton Jones LLC boosted its stake in NVIDIA by 12.4% during the 4th quarter. Brighton Jones LLC now owns 324,901 shares of the computer hardware maker’s stock worth $43,631,000 after acquiring an additional 35,815 shares during the last quarter. Bank Pictet & Cie Europe AG boosted its position in NVIDIA by 1.0% during the fourth quarter. Bank Pictet & Cie Europe AG now owns 2,346,417 shares of the computer hardware maker’s stock worth $315,100,000 after purchasing an additional 22,929 shares during the period. Highview Capital Management LLC DE boosted its position in shares of NVIDIA by 6.7% in the fourth quarter. Highview Capital Management LLC DE now owns 58,396 shares of the computer hardware maker’s stock valued at $7,842,000 after acquiring an additional 3,653 shares during the period. Hudson Value Partners LLC lifted its position in NVIDIA by 30.7% during the fourth quarter. Hudson Value Partners LLC now owns 50,658 shares of the computer hardware maker’s stock worth $6,805,000 after purchasing an additional 11,900 shares during the period. Finally, Armis Advisers LLC acquired a new position in NVIDIA during the fourth quarter worth about $4,216,000. Institutional investors and hedge funds own 65.27% of the company’s stock.\n\nGet NVIDIA alerts:\n\nInsider Transactions at NVIDIA\n\nIn other NVIDIA news, Director Persis Drell sold 40,000 shares of NVIDIA stock in a transaction on Friday, September 19th. The stock was sold at an average price of $177.65, for a total transaction of $7,106,000.00. Following the completion of the sale, the director directly owned 138,740 shares of the company’s stock, valued at $24,647,161. The trade was a 22.38% decrease in their position. The sale was disclosed in a document filed with the SEC, which is available at this hyperlink. Also, CFO Colette Kress sold 30,500 shares of NVIDIA stock in a transaction on Friday, September 19th. The shares were sold at an average price of $176.40, for a total value of $5,380,200.00. Following the completion of the transaction, the chief financial officer owned 2,883,402 shares in the company, valued at $508,632,112.80. This represents a 1.05% decrease in their ownership of the stock. The disclosure for this sale can be found here. In the last quarter, insiders sold 4,097,407 shares of company stock valued at $714,378,504. Company insiders own 4.17% of the company’s stock.\n\nAnalysts Set New Price Targets\n\nSeveral analysts recently commented on NVDA shares. Wedbush reiterated an “outperform” rating and issued a $210.00 target price on shares of NVIDIA in a report on Thursday, August 28th. Weiss Ratings restated a “buy (b)” rating on shares of NVIDIA in a research note on Saturday, September 27th. Benchmark raised their price objective on NVIDIA from $190.00 to $220.00 and gave the company a “buy” rating in a report on Thursday, August 28th. Jefferies Financial Group restated a “buy” rating and set a $220.00 price target (up from $205.00) on shares of NVIDIA in a research report on Monday, September 29th. Finally, Phillip Securities raised NVIDIA from a “moderate buy” rating to a “strong-buy” rating in a report on Monday, July 14th. Four research analysts have rated the stock with a Strong Buy rating, thirty-seven have issued a Buy rating, four have assigned a Hold rating and one has issued a Sell rating to the stock. According to data from MarketBeat.com, NVIDIA presently has a consensus rating of “Moderate Buy” and an average target price of $211.00.\n\nView Our Latest Stock Report on NVDA\n\nNVIDIA Price Performance\n\nNASDAQ:NVDA opened at $187.62 on Friday. NVIDIA Corporation has a 1 year low of $86.62 and a 1 year high of $191.05. The company has a debt-to-equity ratio of 0.08, a current ratio of 4.21 and a quick ratio of 3.60. The firm has a market capitalization of $4.56 trillion, a price-to-earnings ratio of 53.45, a PEG ratio of 1.37 and a beta of 2.12. The business has a 50 day simple moving average of $178.11 and a 200-day simple moving average of $148.15.\n\nNVIDIA (NASDAQ:NVDA – Get Free Report) last released its quarterly earnings data on Wednesday, August 27th. The computer hardware maker reported $1.05 EPS for the quarter, topping the consensus estimate of $1.01 by $0.04. The company had revenue of $46.74 billion for the quarter, compared to the consensus estimate of $45.65 billion. NVIDIA had a return on equity of 101.74% and a net margin of 52.41%.NVIDIA’s quarterly revenue was up 55.6% on a year-over-year basis. During the same period last year, the business posted $0.68 EPS. NVIDIA has set its Q3 2026 guidance at EPS. Equities analysts forecast that NVIDIA Corporation will post 2.77 EPS for the current year.\n\nNVIDIA Announces Dividend\n\nThe company also recently announced a quarterly dividend, which was paid on Thursday, October 2nd. Shareholders of record on Thursday, September 11th were given a dividend of $0.01 per share. The ex-dividend date of this dividend was Thursday, September 11th. This represents a $0.04 dividend on an annualized basis and a yield of 0.0%. NVIDIA’s payout ratio is 1.14%.\n\nNVIDIA Profile\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nRead More\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/04/nvidia-corporation-nvda-shares-bought-by-accurate-wealth-management-llc/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Huawei Ascend 950 vs Nvidia H200 vs AMD MI300 Instinct: How do they compare?",
      "content": "Huawei Ascend 950DT FP8 formats target efficient inference without accuracy loss\n\nNvidia H200 leans on a mature software ecosystem and Hopper GPU strengths\n\nAMD Instinct MI300’s FP64 parity appeals to serious scientific computation workloads\n\nIn recent years, the demand for AI training and inference computing has pushed chip makers to innovate aggressively - efficiency in memory bandwidth, data formats, interconnects, and total compute output are now as critical as raw FLOPS.\n\nEach company targets demanding scenarios such as generative AI training and high-performance computing, where AI tools increasingly depend on fast accelerators to process massive datasets.\n\nMultiple brands approach the challenge with different compute platform characteristics - so we've tried to help understand these differences and clarify how the Ascend 950 series, H200, and MI300 Instinct compare.\n\nSwipe to scroll horizontally Huawei Ascend 950 vs Nvidia H200 vs AMD MI300 Instinct Category Huawei Ascend 950DT NVIDIA H200 AMD Radeon Instinct MI300 Chip Family / Name Ascend 950 series H200 (GH100, Hopper) Radeon Instinct MI300 (Aqua Vanjaram) Architecture Proprietary Huawei AI accelerator Hopper GPU architecture CDNA 3.0 Process / Foundry Not yet publicly confirmed 5 nm (TSMC) 5 nm (TSMC) Transistors Not specified 80 billion 153 billion Die Size Not specified 814 mm² 1017 mm² Optimization Decode-stage inference & model training General-purpose AI & HPC acceleration AI/HPC compute acceleration Supported Formats FP8, MXFP8, MXFP4, HiF8 FP16, FP32, FP64 (via Tensor/CUDA cores) FP16, FP32, FP64 Peak Performance 1 PFLOPS (FP8 / MXFP8 / HiF8), 2 PFLOPS (MXFP4) FP16: 241.3 TFLOPS, FP32: 60.3 TFLOPS, FP64: 30.2 TFLOPS FP16: 383 TFLOPS, FP32/FP64: 47.87 TFLOPS Vector Processing SIMD + SIMT hybrid, 128-byte memory access granularity SIMT with CUDA and Tensor cores SIMT + Matrix/Tensor cores Memory Type HiZQ 2.0 proprietary HBM (for decode & training variant) HBM3e HBM3 Memory Capacity 144 GB 141 GB 128 GB Memory Bandwidth 4 TB/s 4.89 TB/s 6.55 TB/s Memory Bus Width Not specified 6144-bit 8192-bit L2 Cache Not specified 50 MB Not specified Interconnect Bandwidth 2 TB/s Not specified Not specified Form Factors Cards, SuperPoD servers PCIe 5.0 x16 (server/HPC only) PCIe 5.0 x16 (compute card) Base / Boost Clock Not specified 1365 / 1785 MHz 1000 / 1700 MHz Cores / Shaders Not specified CUDA: 16,896, Tensor: 528 (4th Gen) 14,080 shaders, 220 CUs, 880 Tensor cores Power (TDP) Not specified 600 W 600 W Bus Interface Not specified PCIe 5.0 x16 PCIe 5.0 x16 Outputs None (server use) None (server/HPC only) None (compute card) Target Scenarios Large-scale training & decode inference (LLMs, generative AI) AI training, HPC, data centers AI/HPC compute acceleration Release / Availability Q4 2026 Nov 18, 2024 Jan 4, 2023\n\nArchitecture and design approaches\n\nHuawei’s Ascend 950 series is a proprietary AI accelerator architecture optimized for the decode stage of inference as well as model training, rather than a traditional GPU.\n\nIts design blends SIMD and SIMT processing styles with 128-byte memory access granularity, aiming to balance throughput and flexibility.\n\nNvidia’s H200 is based on the Hopper GPU architecture and integrates 16,896 CUDA cores alongside 528 fourth-generation Tensor cores.\n\nIt uses a single-die GH100 GPU fabricated on a 5 nm TSMC process, maintaining compatibility with Nvidia’s software stack and extensive ecosystem.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAMD’s MI300 Instinct uses the Aqua Vanjaram GPU with the CDNA 3.0 architecture and a chiplet-based MCM design featuring 220 compute units and 880 matrix cores.\n\nThis approach provides a massive transistor budget and a strong focus on high-performance computing.\n\nThe Ascend 950 offers peak performance of one petaflop using FP8, MXFP8, or HiF8 data formats and can double to two petaflops when using MXFP4.\n\nThis highlights Huawei’s focus on emerging low-precision formats designed to improve efficiency during inference without sacrificing accuracy.\n\nNvidia’s H200 delivers 241.3 teraflops in FP16 and 60.3 teraflops in FP32, while AMD’s MI300 provides 383 teraflops in FP16 and nearly 48 teraflops for both FP32 and FP64 workloads.\n\nThe MI300’s FP64 parity with FP32 underlines its suitability for scientific computation, where double-precision is critical, whereas Nvidia’s focus is skewed toward mixed-precision acceleration for AI.\n\nMemory architecture strongly influences training large language models.\n\nHuawei pairs the Ascend 950 with 144GB of HiZQ 2.0 proprietary HBM, delivering 4TB/s of bandwidth and 2TB/s interconnect speed.\n\nNvidia equips the H200 with 141GB of HBM3e memory and a 4.89TB/s bandwidth, slightly ahead in raw throughput.\n\nAMD’s MI300 stands out with 128GB of HBM3 but a wider 8192-bit bus and a leading 6.55TB/s memory bandwidth.\n\nFor massive model training or memory-intensive simulation, AMD’s advantage in bandwidth can translate into faster data movement even if its total memory capacity trails Huawei’s.\n\nThe H200 and MI300 share a 600W thermal design power, fitting into PCIe 5.0 x16 server configurations with no video outputs, underscoring their data center orientation.\n\nHuawei has not disclosed official TDP figures but offers both card formats and integrated SuperPoD servers, suggesting deployment flexibility within its own AI infrastructure solutions.\n\nIts interconnect bandwidth of 2TB/s could be an important factor for multi-chip scaling in data center environments, although details about die size and transistor count remain undisclosed.\n\nNvidia benefits from a mature NVLink and InfiniBand ecosystem, while AMD’s multi-chip module design aims to reduce latency between compute dies.\n\nHuawei clearly aims its Ascend 950 at large-scale training and decode-stage inference for generative AI, a market where Nvidia has long dominated.\n\nIts Q4 2026 availability means Nvidia’s H200, released in late 2024, and AMD’s MI300, available since early 2023, already have a time advantage.\n\nBy the time Ascend 950 hardware reaches customers, both competitors may have iterated on their platforms.\n\nHowever, Huawei’s emphasis on efficient low-precision formats and tight integration with its networking hardware could attract buyers seeking alternatives to U.S. suppliers.\n\nThat said, these accelerators reflect differing philosophies of multiple brands.\n\nAMD prioritizes memory bandwidth and double-precision strength for HPC workloads, while Nvidia leverages ecosystem maturity and software support to maintain dominance in AI training.\n\nHuawei seeks to challenge both with aggressive FP8-class performance and high-capacity proprietary memory.\n\nVia Huawei, Nvidia, TechPowerUp",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/huawei-ascend-950-vs-nvidia-h200-vs-amd-mi300-instinct-how-do-they-compare",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Maseco LLP Buys New Position in NVIDIA Corporation $NVDA",
      "content": "Maseco LLP purchased a new stake in NVIDIA Corporation (NASDAQ:NVDA – Free Report) during the second quarter, Holdings Channel reports. The institutional investor purchased 7,297 shares of the computer hardware maker’s stock, valued at approximately $1,152,000.\n\nA number of other hedge funds also recently bought and sold shares of the stock. Axis Wealth Partners LLC raised its position in NVIDIA by 2.0% in the 2nd quarter. Axis Wealth Partners LLC now owns 4,260 shares of the computer hardware maker’s stock valued at $673,000 after purchasing an additional 83 shares in the last quarter. Cranbrook Wealth Management LLC raised its position in NVIDIA by 3.9% in the 2nd quarter. Cranbrook Wealth Management LLC now owns 6,703 shares of the computer hardware maker’s stock valued at $1,059,000 after purchasing an additional 251 shares in the last quarter. Yarbrough Capital LLC raised its position in NVIDIA by 5.0% in the 2nd quarter. Yarbrough Capital LLC now owns 3,470,565 shares of the computer hardware maker’s stock valued at $548,315,000 after purchasing an additional 165,593 shares in the last quarter. Waycross Partners LLC raised its position in NVIDIA by 3.4% in the 2nd quarter. Waycross Partners LLC now owns 503,808 shares of the computer hardware maker’s stock valued at $79,597,000 after purchasing an additional 16,498 shares in the last quarter. Finally, AM Investment Strategies LLC raised its position in NVIDIA by 19.5% in the 2nd quarter. AM Investment Strategies LLC now owns 58,748 shares of the computer hardware maker’s stock valued at $9,281,000 after purchasing an additional 9,595 shares in the last quarter. Institutional investors and hedge funds own 65.27% of the company’s stock.\n\nGet NVIDIA alerts:\n\nInsider Buying and Selling\n\nIn related news, CEO Jen Hsun Huang sold 75,000 shares of NVIDIA stock in a transaction on Monday, July 14th. The stock was sold at an average price of $164.36, for a total transaction of $12,327,000.00. Following the completion of the transaction, the chief executive officer directly owned 74,648,225 shares of the company’s stock, valued at approximately $12,269,182,261. The trade was a 0.10% decrease in their ownership of the stock. The sale was disclosed in a document filed with the SEC, which can be accessed through this link. Also, Director Mark A. Stevens sold 350,000 shares of the business’s stock in a transaction on Friday, September 19th. The stock was sold at an average price of $176.39, for a total value of $61,736,500.00. Following the completion of the transaction, the director directly owned 7,399,803 shares of the company’s stock, valued at approximately $1,305,251,251.17. This trade represents a 4.52% decrease in their ownership of the stock. The disclosure for this sale can be found here. Over the last ninety days, insiders sold 4,097,407 shares of company stock valued at $714,378,504. 4.17% of the stock is owned by insiders.\n\nAnalyst Upgrades and Downgrades\n\nNVDA has been the topic of a number of analyst reports. Wolfe Research increased their price target on NVIDIA from $220.00 to $230.00 in a research report on Tuesday, September 23rd. UBS Group reissued a “buy” rating on shares of NVIDIA in a research report on Tuesday, September 23rd. BNP Paribas raised NVIDIA to a “hold” rating in a research report on Friday, August 1st. Benchmark raised their target price on NVIDIA from $190.00 to $220.00 and gave the stock a “buy” rating in a research report on Thursday, August 28th. Finally, Loop Capital raised their target price on NVIDIA from $175.00 to $250.00 and gave the stock a “buy” rating in a research report on Wednesday, June 25th. Four investment analysts have rated the stock with a Strong Buy rating, thirty-seven have issued a Buy rating, four have given a Hold rating and one has issued a Sell rating to the company’s stock. According to data from MarketBeat, NVIDIA has an average rating of “Moderate Buy” and a consensus target price of $211.00.\n\nRead Our Latest Stock Report on NVDA\n\nNVIDIA Stock Down 0.7%\n\nNVIDIA stock opened at $187.62 on Friday. The company has a debt-to-equity ratio of 0.08, a current ratio of 4.21 and a quick ratio of 3.60. NVIDIA Corporation has a 1-year low of $86.62 and a 1-year high of $191.05. The company has a market cap of $4.56 trillion, a PE ratio of 53.45, a price-to-earnings-growth ratio of 1.37 and a beta of 2.12. The stock’s 50 day moving average price is $178.11 and its 200 day moving average price is $148.15.\n\nNVIDIA (NASDAQ:NVDA – Get Free Report) last issued its quarterly earnings data on Wednesday, August 27th. The computer hardware maker reported $1.05 earnings per share (EPS) for the quarter, topping the consensus estimate of $1.01 by $0.04. The firm had revenue of $46.74 billion during the quarter, compared to analysts’ expectations of $45.65 billion. NVIDIA had a return on equity of 101.74% and a net margin of 52.41%.NVIDIA’s revenue was up 55.6% on a year-over-year basis. During the same period in the previous year, the firm posted $0.68 earnings per share. NVIDIA has set its Q3 2026 guidance at EPS. On average, sell-side analysts predict that NVIDIA Corporation will post 2.77 EPS for the current fiscal year.\n\nNVIDIA Announces Dividend\n\nThe company also recently disclosed a quarterly dividend, which was paid on Thursday, October 2nd. Investors of record on Thursday, September 11th were issued a dividend of $0.01 per share. The ex-dividend date of this dividend was Thursday, September 11th. This represents a $0.04 annualized dividend and a yield of 0.0%. NVIDIA’s payout ratio is currently 1.14%.\n\nAbout NVIDIA\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nFurther Reading\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/04/maseco-llp-buys-new-position-in-nvidia-corporation-nvda/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "aiqtoolkit-agno 1.3.0a20251004",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/aiqtoolkit-agno/1.3.0a20251004/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Tesla, Nvidia, Google's diverging strategies to define next era of AI infrastructure",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20251001PD220/google-tesla-openai-data-chatgpt.html",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "nvidia-nat-langchain 1.3.0a20251004",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-langchain/1.3.0a20251004/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "nvidia-nat-weave 1.3.0a20251004",
      "content": "For more information about the NVIDIA NeMo Agent toolkit, please visit the NeMo Agent toolkit GitHub Repo .\n\nThis is a subpackage for Weights and Biases Weave integration for observability.\n\nDownload files\n\nDownload the file for your platform. If you're not sure which to choose, learn more about installing packages.\n\nSource Distributions\n\nNo source distribution files available for this release.See tutorial on generating distribution archives\n\nBuilt Distribution\n\nFilter files by name, interpreter, ABI, and platform.\n\nIf you're not sure about the file name format, learn more about wheel file names.\n\nThe dropdown lists show the available interpreters, ABIs, and platforms. Enable javascript to be able to filter the list of wheel files.\n\nCopy a direct link to the current filters Copy",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-weave/1.3.0a20251004/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Magnificent Seven Member Nvidia Stock Breaks Out, Is Actionable Now",
      "content": ", maker of the high-powered chips needed in artificial intelligence, is seeing its stock trade inside a 5% buy zone from a fresh breakout this week. The stock maintains a best-possible 99 Composite Rating, making it one of the top stocks to watch in the IBD Big Cap 20. Shares formed a…\n\nThis story appeared on investors.com , 2025-10-04 22:55:53.750000.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/c64c3b03fa8f5101",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "nvidia-nat-data-flywheel 1.3.0a20251005",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-data-flywheel/1.3.0a20251005/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "nvidia-nat-llama-index 1.3.0a20251005",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-llama-index/1.3.0a20251005/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "aiqtoolkit-agno 1.3.0a20251005",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/aiqtoolkit-agno/1.3.0a20251005/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Daily Tech News 35 September 2025",
      "content": "Daily Tech News 35 September 2025\n\nTop Story\n\n\n\n\n\nThe Eternal September is finally over after 34 years as AOL shuts down its dialup service. (Tom's Hardware)\n\n\n\nLooking around and seeing the current state of the internet, I think they might have left it running a little too long.\n\n\n\n\n\n\n\nLooking around and seeing the current state of the internet, I think they might have left it running a little too long. Speaking of which, how does my upgraded 500Mb internet feel?\n\n\n\nExactly the same as before, on 100Mb, to be honest. Moving from ADSL (I got about 16Mb down and 2Mb up) to a nominal 100/40 connection was a huge upgrade. At least it was until I got hit by lightning and my modem exploded.\n\n\n\nSince I mostly look at (and work on) US-hosted sites, that trans-Pacific latency erases any obvious gains. The new plan is cheaper, though, and the next step down goes all the way to 50/20 and only saves $2.\n\n\n\n\n\nTech News\n\n\n\n\n\nDisclaimer: Makes me want to say, STOP BITING ME!",
      "source": "Acecomments.mu.nu",
      "url": "https://acecomments.mu.nu/?post=416755",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "nvidia-nat-zep-cloud 1.3.0rc2",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-zep-cloud/1.3.0rc2/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Kraft Asset Management LLC Has $266,000 Stake in NVIDIA Corporation $NVDA",
      "content": "Kraft Asset Management LLC lowered its stake in NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 60.8% during the second quarter, according to the company in its most recent Form 13F filing with the SEC. The fund owned 1,681 shares of the computer hardware maker’s stock after selling 2,606 shares during the quarter. Kraft Asset Management LLC’s holdings in NVIDIA were worth $266,000 as of its most recent SEC filing.\n\nA number of other hedge funds and other institutional investors have also modified their holdings of the stock. Kingstone Capital Partners Texas LLC increased its position in shares of NVIDIA by 267,959.7% in the second quarter. Kingstone Capital Partners Texas LLC now owns 382,373,765 shares of the computer hardware maker’s stock valued at $64,976,521,000 after acquiring an additional 382,231,120 shares during the last quarter. UBS AM A Distinct Business Unit of UBS Asset Management Americas LLC increased its position in shares of NVIDIA by 2.9% in the first quarter. UBS AM A Distinct Business Unit of UBS Asset Management Americas LLC now owns 206,794,926 shares of the computer hardware maker’s stock valued at $22,412,434,000 after acquiring an additional 5,896,735 shares during the last quarter. Goldman Sachs Group Inc. increased its position in shares of NVIDIA by 123.5% in the first quarter. Goldman Sachs Group Inc. now owns 187,995,213 shares of the computer hardware maker’s stock valued at $20,374,921,000 after acquiring an additional 103,889,872 shares during the last quarter. Nuveen LLC acquired a new stake in shares of NVIDIA in the first quarter valued at about $15,089,414,000. Finally, Amundi increased its position in NVIDIA by 16.0% during the first quarter. Amundi now owns 135,770,043 shares of the computer hardware maker’s stock worth $13,826,199,000 after buying an additional 18,733,431 shares during the last quarter. Institutional investors and hedge funds own 65.27% of the company’s stock.\n\nGet NVIDIA alerts:\n\nAnalyst Ratings Changes\n\nA number of equities analysts have weighed in on the company. Stifel Nicolaus boosted their price target on NVIDIA from $202.00 to $212.00 and gave the stock a “buy” rating in a research report on Monday, August 25th. Craig Hallum boosted their price target on NVIDIA from $195.00 to $245.00 and gave the stock a “buy” rating in a research report on Thursday, August 28th. DA Davidson raised NVIDIA from a “neutral” rating to a “buy” rating and boosted their price target for the stock from $195.00 to $210.00 in a research report on Thursday, September 11th. BNP Paribas raised NVIDIA to a “hold” rating in a research report on Friday, August 1st. Finally, Rosenblatt Securities reissued a “buy” rating and set a $215.00 price target on shares of NVIDIA in a research report on Tuesday, September 23rd. Four equities research analysts have rated the stock with a Strong Buy rating, thirty-seven have assigned a Buy rating, four have assigned a Hold rating and one has assigned a Sell rating to the stock. According to MarketBeat, the company currently has a consensus rating of “Moderate Buy” and a consensus price target of $211.00.\n\nNVIDIA Stock Down 0.7%\n\nShares of NVDA opened at $187.62 on Friday. NVIDIA Corporation has a one year low of $86.62 and a one year high of $191.05. The company has a market cap of $4.56 trillion, a P/E ratio of 53.45, a P/E/G ratio of 1.36 and a beta of 2.12. The company has a debt-to-equity ratio of 0.08, a current ratio of 4.21 and a quick ratio of 3.60. The firm has a 50 day simple moving average of $178.11 and a two-hundred day simple moving average of $148.36.\n\nNVIDIA (NASDAQ:NVDA – Get Free Report) last announced its quarterly earnings data on Wednesday, August 27th. The computer hardware maker reported $1.05 EPS for the quarter, beating the consensus estimate of $1.01 by $0.04. NVIDIA had a net margin of 52.41% and a return on equity of 101.74%. The business had revenue of $46.74 billion during the quarter, compared to the consensus estimate of $45.65 billion. During the same period in the previous year, the business earned $0.68 earnings per share. The company’s revenue was up 55.6% on a year-over-year basis. NVIDIA has set its Q3 2026 guidance at EPS. Research analysts forecast that NVIDIA Corporation will post 2.77 EPS for the current fiscal year.\n\nNVIDIA Dividend Announcement\n\nThe company also recently disclosed a quarterly dividend, which was paid on Thursday, October 2nd. Shareholders of record on Thursday, September 11th were given a dividend of $0.01 per share. This represents a $0.04 annualized dividend and a yield of 0.0%. The ex-dividend date was Thursday, September 11th. NVIDIA’s payout ratio is currently 1.14%.\n\nInsider Buying and Selling at NVIDIA\n\nIn other NVIDIA news, Director Mark A. Stevens sold 350,000 shares of the business’s stock in a transaction that occurred on Friday, September 19th. The shares were sold at an average price of $176.39, for a total transaction of $61,736,500.00. Following the completion of the transaction, the director directly owned 7,399,803 shares in the company, valued at $1,305,251,251.17. The trade was a 4.52% decrease in their ownership of the stock. The sale was disclosed in a document filed with the Securities & Exchange Commission, which is available at this link. Also, Director Harvey C. Jones sold 250,000 shares of the company’s stock in a transaction on Thursday, September 18th. The stock was sold at an average price of $176.21, for a total transaction of $44,052,500.00. Following the transaction, the director owned 7,183,280 shares of the company’s stock, valued at $1,265,765,768.80. This trade represents a 3.36% decrease in their ownership of the stock. The disclosure for this sale can be found here. Insiders sold a total of 4,097,407 shares of company stock worth $714,378,504 over the last three months. Corporate insiders own 4.17% of the company’s stock.\n\nNVIDIA Company Profile\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nRecommended Stories\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/05/kraft-asset-management-llc-has-266000-stake-in-nvidia-corporation-nvda/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "nvidia-nat-weave 1.3.0rc2",
      "content": "For more information about the NVIDIA NeMo Agent toolkit, please visit the NeMo Agent toolkit GitHub Repo .\n\nThis is a subpackage for Weights and Biases Weave integration for observability.\n\nDownload files\n\nDownload the file for your platform. If you're not sure which to choose, learn more about installing packages.\n\nSource Distributions\n\nNo source distribution files available for this release.See tutorial on generating distribution archives\n\nBuilt Distribution\n\nFilter files by name, interpreter, ABI, and platform.\n\nIf you're not sure about the file name format, learn more about wheel file names.\n\nThe dropdown lists show the available interpreters, ABIs, and platforms. Enable javascript to be able to filter the list of wheel files.\n\nCopy a direct link to the current filters Copy",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-weave/1.3.0rc2/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "NVIDIA Corporation $NVDA Shares Purchased by Norden Group LLC",
      "content": "Norden Group LLC raised its position in NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 14.2% in the second quarter, HoldingsChannel reports. The fund owned 163,455 shares of the computer hardware maker’s stock after purchasing an additional 20,333 shares during the quarter. NVIDIA makes up approximately 2.8% of Norden Group LLC’s holdings, making the stock its 3rd largest holding. Norden Group LLC’s holdings in NVIDIA were worth $25,824,000 as of its most recent SEC filing.\n\nA number of other hedge funds have also recently added to or reduced their stakes in NVDA. Brighton Jones LLC boosted its position in shares of NVIDIA by 12.4% during the fourth quarter. Brighton Jones LLC now owns 324,901 shares of the computer hardware maker’s stock valued at $43,631,000 after buying an additional 35,815 shares during the last quarter. Bank Pictet & Cie Europe AG boosted its position in shares of NVIDIA by 1.0% during the fourth quarter. Bank Pictet & Cie Europe AG now owns 2,346,417 shares of the computer hardware maker’s stock valued at $315,100,000 after buying an additional 22,929 shares during the last quarter. Highview Capital Management LLC DE boosted its position in shares of NVIDIA by 6.7% during the fourth quarter. Highview Capital Management LLC DE now owns 58,396 shares of the computer hardware maker’s stock valued at $7,842,000 after buying an additional 3,653 shares during the last quarter. Hudson Value Partners LLC boosted its position in shares of NVIDIA by 30.7% during the fourth quarter. Hudson Value Partners LLC now owns 50,658 shares of the computer hardware maker’s stock valued at $6,805,000 after buying an additional 11,900 shares during the last quarter. Finally, Universal Beteiligungs und Servicegesellschaft mbH purchased a new position in shares of NVIDIA during the fourth quarter valued at approximately $2,987,733,000. Institutional investors and hedge funds own 65.27% of the company’s stock.\n\nGet NVIDIA alerts:\n\nWall Street Analysts Forecast Growth\n\nSeveral research analysts recently issued reports on the company. JPMorgan Chase & Co. reaffirmed a “buy” rating and set a $215.00 target price on shares of NVIDIA in a research report on Friday, September 19th. Piper Sandler set a $225.00 target price on NVIDIA and gave the company an “overweight” rating in a research report on Wednesday, August 13th. Weiss Ratings reissued a “buy (b)” rating on shares of NVIDIA in a research report on Saturday, September 27th. TD Cowen boosted their price objective on NVIDIA from $140.00 to $235.00 and gave the stock a “buy” rating in a research report on Tuesday, August 19th. Finally, Morgan Stanley boosted their price objective on NVIDIA from $206.00 to $210.00 and gave the stock an “overweight” rating in a research report on Thursday, August 28th. Four equities research analysts have rated the stock with a Strong Buy rating, thirty-seven have issued a Buy rating, four have given a Hold rating and one has assigned a Sell rating to the stock. According to MarketBeat, NVIDIA has a consensus rating of “Moderate Buy” and an average target price of $211.00.\n\nInsider Activity\n\nIn related news, CEO Jen Hsun Huang sold 75,000 shares of the stock in a transaction dated Monday, July 14th. The stock was sold at an average price of $164.36, for a total transaction of $12,327,000.00. Following the completion of the sale, the chief executive officer directly owned 74,648,225 shares in the company, valued at $12,269,182,261. This represents a 0.10% decrease in their position. The sale was disclosed in a legal filing with the SEC, which is available through this link. Also, Director Harvey C. Jones sold 250,000 shares of the stock in a transaction dated Thursday, September 18th. The shares were sold at an average price of $176.21, for a total value of $44,052,500.00. Following the sale, the director owned 7,183,280 shares of the company’s stock, valued at $1,265,765,768.80. This represents a 3.36% decrease in their ownership of the stock. The disclosure for this sale can be found here. In the last three months, insiders have sold 4,097,407 shares of company stock worth $714,378,504. 4.17% of the stock is currently owned by insiders.\n\nNVIDIA Price Performance\n\nShares of NVIDIA stock opened at $187.62 on Friday. The company has a current ratio of 4.21, a quick ratio of 3.60 and a debt-to-equity ratio of 0.08. The firm has a market capitalization of $4.56 trillion, a PE ratio of 53.45, a price-to-earnings-growth ratio of 1.36 and a beta of 2.12. The business’s 50-day moving average price is $178.11 and its 200-day moving average price is $148.36. NVIDIA Corporation has a 12 month low of $86.62 and a 12 month high of $191.05.\n\nNVIDIA (NASDAQ:NVDA – Get Free Report) last announced its quarterly earnings data on Wednesday, August 27th. The computer hardware maker reported $1.05 EPS for the quarter, beating the consensus estimate of $1.01 by $0.04. The firm had revenue of $46.74 billion for the quarter, compared to analyst estimates of $45.65 billion. NVIDIA had a return on equity of 101.74% and a net margin of 52.41%.The company’s revenue was up 55.6% on a year-over-year basis. During the same period in the prior year, the company earned $0.68 EPS. NVIDIA has set its Q3 2026 guidance at EPS. Sell-side analysts forecast that NVIDIA Corporation will post 2.77 EPS for the current fiscal year.\n\nNVIDIA Announces Dividend\n\nThe company also recently disclosed a quarterly dividend, which was paid on Thursday, October 2nd. Stockholders of record on Thursday, September 11th were given a dividend of $0.01 per share. The ex-dividend date was Thursday, September 11th. This represents a $0.04 annualized dividend and a dividend yield of 0.0%. NVIDIA’s dividend payout ratio is 1.14%.\n\nNVIDIA Profile\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nSee Also\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/05/nvidia-corporation-nvda-shares-purchased-by-norden-group-llc/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Stock market today: Dow, S&P 500, Nasdaq futures tick up as government shutdown drags on",
      "content": "US stocks were mixed on Monday as the federal government shutdown entered another week, while a megadeal between AMD (AMD) and OpenAI (OPAI.PVT) lifted hopes for the AI trade.\n\nThe Nasdaq Composite (^IXIC) led the way higher, rising 0.3% amid an over-25% surge from AMD, while the S&P 500 (^GSPC) ticked up 0.2%. But the Dow Jones Industrial Average (^DJI) lost hold of opening gains, falling 0.2%.\n\nIn another jolt to the AI outlook, AMD said Monday it has signed a multiyear deal with OpenAI to supply chips that will bring in tens of billions of dollars in annual revenue. It also gives the ChatGPT owner the option to purchase up to 10% of AMD, one of Nvidia's (NVDA) key rivals.\n\nThat served as another AI-related boost to a market that has proved resilient despite the shutdown in Washington. Wall Street on Friday returned to a strong rally that has pushed major indexes to fresh record highs. Eyes are now on the OpenAI developer event on Monday for potentially market-moving news.\n\nInvestors have focused on upbeat prospects for AI even as the stoppage delays key economic releases such as the monthly jobs report.\n\nOn Wall Street, data-starved investors could still get inputs for calculating the chances of two interest-rate cuts this year. On the Federal Reserve front, President Trump-backed Governor Stephen Miran is set to speak on Wednesday, followed by Chair Jerome Powell on Thursday. And data from non-government sources is also on deck, with the University of Michigan's consumer sentiment report for October the likely highlight.\n\nElsewhere, markets were rattled by political upheavals. In France, the CAC 40 (^FCHI) stock benchmark sank as the euro (EURUSD=X) fell after the sudden resignation of its prime minister pushed the country back into a political crisis. And in Japan, the Nikkei 225 (^N225) surged almost 5% to a record high as an ultraconservative was all but confirmed as the country's next leader in a surprise choice.\n\nMeanwhile, third quarter earnings are set to start trickling in, with results from PepsiCo (PEP), Delta Air Lines (DAL), and Levi Strauss (LEVI) on the docket this week.\n\nLIVE\n\n15 updates",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-dow-sp-500-nasdaq-futures-tick-up-as-government-shutdown-drags-on-232706734.html",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "nvidia-nat-mcp 1.3.0a20251005",
      "content": "For more information about the NVIDIA NeMo Agent toolkit, please visit the NeMo Agent toolkit GitHub Repo .\n\nThis package provides MCP (Model Context Protocol) client functionality, allowing NeMo Agent toolkit workflows to connect to external MCP servers and use their tools as functions.\n\nSubpackage for MCP client integration in NeMo Agent toolkit.\n\nDownload files\n\nDownload the file for your platform. If you're not sure which to choose, learn more about installing packages.\n\nSource Distributions\n\nNo source distribution files available for this release.See tutorial on generating distribution archives\n\nBuilt Distribution\n\nFilter files by name, interpreter, ABI, and platform.\n\nIf you're not sure about the file name format, learn more about wheel file names.\n\nThe dropdown lists show the available interpreters, ABIs, and platforms. Enable javascript to be able to filter the list of wheel files.\n\nCopy a direct link to the current filters Copy",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-mcp/1.3.0a20251005/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Could Nvidia become a $10 trillion company? These analysts see a path",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/19dcabcd2d228c73",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "nvidia-nat-crewai 1.3.0a20251005",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-crewai/1.3.0a20251005/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "aiqtoolkit-mem0ai 1.3.0a20251005",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/aiqtoolkit-mem0ai/1.3.0a20251005/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "EWG Elevate Inc. Acquires 247 Shares of NVIDIA Corporation $NVDA",
      "content": "EWG Elevate Inc. increased its holdings in shares of NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 4.3% in the 2nd quarter, Holdings Channel.com reports. The institutional investor owned 6,023 shares of the computer hardware maker’s stock after purchasing an additional 247 shares during the period. EWG Elevate Inc.’s holdings in NVIDIA were worth $952,000 at the end of the most recent reporting period.\n\nOther institutional investors and hedge funds have also modified their holdings of the company. Kathleen S. Wright Associates Inc. raised its position in NVIDIA by 169.3% in the first quarter. Kathleen S. Wright Associates Inc. now owns 404 shares of the computer hardware maker’s stock valued at $44,000 after purchasing an additional 254 shares during the last quarter. Copia Wealth Management bought a new position in NVIDIA in the fourth quarter valued at about $50,000. Barnes Dennig Private Wealth Management LLC bought a new position in NVIDIA in the first quarter valued at about $51,000. Bruce G. Allen Investments LLC raised its position in NVIDIA by 198.2% in the first quarter. Bruce G. Allen Investments LLC now owns 492 shares of the computer hardware maker’s stock valued at $53,000 after purchasing an additional 327 shares during the last quarter. Finally, Campbell Capital Management Inc. raised its position in NVIDIA by 5,900.0% in the first quarter. Campbell Capital Management Inc. now owns 600 shares of the computer hardware maker’s stock valued at $65,000 after purchasing an additional 590 shares during the last quarter. 65.27% of the stock is currently owned by institutional investors.\n\nGet NVIDIA alerts:\n\nWall Street Analyst Weigh In\n\nA number of brokerages have recently issued reports on NVDA. Barclays restated an “overweight” rating and set a $240.00 price objective (up from $200.00) on shares of NVIDIA in a research report on Monday, September 22nd. Wedbush restated an “outperform” rating and set a $210.00 price objective on shares of NVIDIA in a research report on Thursday, August 28th. Cantor Fitzgerald restated an “overweight” rating and set a $240.00 price objective on shares of NVIDIA in a research report on Friday. Wolfe Research raised their price objective on NVIDIA from $220.00 to $230.00 in a research report on Tuesday, September 23rd. Finally, Wells Fargo & Company raised their price objective on NVIDIA from $185.00 to $220.00 and gave the stock an “overweight” rating in a research report on Monday, August 11th. Four equities research analysts have rated the stock with a Strong Buy rating, thirty-seven have assigned a Buy rating, four have issued a Hold rating and one has given a Sell rating to the stock. Based on data from MarketBeat, the stock has an average rating of “Moderate Buy” and a consensus target price of $211.00.\n\nInsider Activity\n\nIn other news, Director Mark A. Stevens sold 350,000 shares of the firm’s stock in a transaction that occurred on Friday, September 19th. The stock was sold at an average price of $176.39, for a total value of $61,736,500.00. Following the transaction, the director owned 7,399,803 shares in the company, valued at $1,305,251,251.17. This trade represents a 4.52% decrease in their ownership of the stock. The transaction was disclosed in a document filed with the Securities & Exchange Commission, which is available through this hyperlink. Also, Director Harvey C. Jones sold 250,000 shares of the firm’s stock in a transaction that occurred on Thursday, September 18th. The shares were sold at an average price of $176.21, for a total value of $44,052,500.00. Following the completion of the transaction, the director owned 7,183,280 shares in the company, valued at $1,265,765,768.80. This represents a 3.36% decrease in their position. The disclosure for this sale can be found here. Insiders have sold 4,097,407 shares of company stock worth $714,378,504 over the last 90 days. 4.17% of the stock is currently owned by corporate insiders.\n\nNVIDIA Stock Down 0.7%\n\nNVDA stock opened at $187.62 on Friday. NVIDIA Corporation has a twelve month low of $86.62 and a twelve month high of $191.05. The company has a quick ratio of 3.60, a current ratio of 4.21 and a debt-to-equity ratio of 0.08. The stock’s 50 day moving average is $178.11 and its 200-day moving average is $148.36. The firm has a market capitalization of $4.56 trillion, a PE ratio of 53.45, a P/E/G ratio of 1.36 and a beta of 2.12.\n\nNVIDIA (NASDAQ:NVDA – Get Free Report) last posted its earnings results on Wednesday, August 27th. The computer hardware maker reported $1.05 earnings per share for the quarter, beating analysts’ consensus estimates of $1.01 by $0.04. NVIDIA had a return on equity of 101.74% and a net margin of 52.41%.The company had revenue of $46.74 billion for the quarter, compared to analyst estimates of $45.65 billion. During the same quarter last year, the company earned $0.68 earnings per share. The company’s revenue for the quarter was up 55.6% on a year-over-year basis. NVIDIA has set its Q3 2026 guidance at EPS. Sell-side analysts expect that NVIDIA Corporation will post 2.77 EPS for the current fiscal year.\n\nNVIDIA Dividend Announcement\n\nThe business also recently announced a quarterly dividend, which was paid on Thursday, October 2nd. Stockholders of record on Thursday, September 11th were issued a $0.01 dividend. This represents a $0.04 dividend on an annualized basis and a dividend yield of 0.0%. The ex-dividend date was Thursday, September 11th. NVIDIA’s dividend payout ratio (DPR) is currently 1.14%.\n\nNVIDIA Company Profile\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nRead More\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/05/ewg-elevate-inc-acquires-247-shares-of-nvidia-corporation-nvda/",
      "timestamp": "2025-10-05"
    }
  ],
  "AMD": [
    {
      "headline": "Meet Lisa Su: CEO and president of Advanced Micro Devices, the main competitor to Nvidia",
      "content": "Lisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion.\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nlighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nLisa Su is the engineer behind one of the most dramatic corporate turnarounds in the tech industry.\n\nThe Taiwanese American CEO is widely credited with transforming AMD from a struggling semiconductor firm on the brink of collapse into a global powerhouse competing head-to-head with Intel and Nvidia.\n\nWhen Su joined AMD in 2012, the company's market value was under $2 billion. Within a decade of her leadership, AMD's innovations in high-performance computing and graphics, especially the Ryzen CPUs and EPYC server processors, catapulted the company's value to roughly $270 billion as of October 2025.\n\nBut Su's leadership has not been without challenges. AMD's two largest competitors, Nvidia and Intel, are now working together in a strategic collaboration. Under the second Trump administration, export regulations related to China, one of AMD's largest markets, are also constantly changing.\n\nHere's a look at the timeline of Su's career, from her early life in New York City to her role as one of the most influential women in tech and innovation:",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/meet-lisa-su-ceo-and-president-of-advanced-micro-device",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "I cloned my voice with AI and it was unsettlingly good",
      "content": null,
      "source": "MakeUseOf",
      "url": "https://www.makeuseof.com/ai-voice-clone-chatterbox/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Select Micro Center Stores: AMD Ryzen 7 7800X3D + ASUS B650E-E TUF Gaming MB $450 + Free Store Pickup",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18662536-select-micro-center-stores-amd-ryzen-7-7800x3d-asus-b650e-e-tuf-gaming-mb-450-free-store-pickup",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "No, Xbox's next gen console hardware plans aren't cancelled — for now, but it's a problem that it was really easy to believe",
      "content": "So today, rumors began to swirl across the internet that Xbox is planning to exit hardware, and move entirely to Xbox Cloud Gaming as the primary way to access content. I can confirm via very trusted sources that this isn't true. At least for now.\n\nBut that, \"at least for now\" qualifier is a real problem. How can we know what will be true next quarter? Let's put aside for a minute the fact that Xbox Game Pass remains a primary driver of revenue, and is most prolific on Xbox console hardware — and that's where the bulk of the users are right now. Let's put aside the fact that Xbox Cloud Gaming is restricted by location and is expensive to run.\n\nCombine that with the fact that with the same silicon, you could give people their own \"cloud\" natively in their house — and get them to use their own electricity to power it. You know, like a console. It doesn't make a lot of sense on paper. But regardless, that's where we're at.\n\nUPDATE: Microsoft has at least confirmed that, for now, that the rumors are false, as noted in the statement above. But how did we get here? The original report continues below.\n\nAll of these rumors emerged in the wake of Microsoft's barely-explicable 50% price rise in Xbox Game Pass Ultimate, and the weird tone-deaf way in which they tried to present it as a \"good thing\" throwing in Fortnite Crew and stuff people didn't really ask for.\n\nThe fact these latest hardware exit rumors continue to seem plausible is a real problem, despite the source of the rumors. It showcases, to me, a very deep disconnect between Microsoft and how its audience and the community at large views gaming in general.\n\nMicrosoft's multi-year partnership with AMD for next-gen Xbox hardware is still the present plan\n\nXbox + AMD: Powering the Next Generation of Xbox - YouTube Watch On\n\nI could easily be just as random a source claiming that Xbox hardware is still on the table, but it was our sources that confirmed the existence of the Xbox Series X|S, their specs, their price, in addition to reports on the cancelled cloud \"Keystone\" console, the shelved first-party Xbox handheld, and more recently, the Xbox Ally. Codenamed Kennan and comprised of Omni (Xbox Ally) and Horseman (Xbox Ally X), the Xbox Ally range is part of Microsoft's multi-year partnership with AMD, which will include tailor-made devices from first party.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nI've asked multiple trusted sources, many of whom spoke to me on the above devices previously which turned out to be true, about what Xbox's present hardware posture is. And with Microsoft's confirmation, there's no reason to think anything is changing.\n\nMicrosoft publicly confirmed that it's still committed to first-party Xbox hardware over the summer, with comments from both President Sarah Bond and AMD CEO Lisa Su on silicon that would power next-gen Xbox devices — both from third and first-party. The statement reiterates this commitment.\n\nThe original comments came from a gaming forum, and suggested that Xbox's focus would be on its core mega franchises like World of Warcraft, Call of Duty, Forza Horizon, and so on, and that hardware plans were \"up in the air,\" not actually cancelled. Those comments morphed into \"Xbox hardware is cancelled\" from various commentators, and have now taken on a life of their own on social media as people speculate on the future of the Xbox platform. From what I've been told, the hardware plans are not even \"up in the air,\" and remain firmly Xbox's path forward. Xbox Series X|S hardware production has not ceased, and new stock will go out to retailers at its usual cadence.\n\nAMD & Xbox | Advancing the Future of Gaming - YouTube Watch On\n\nBut even if Microsoft did come out to squash the rumors themselves, it's hard to have any faith. Microsoft has been incredibly fickle over the past few years, crushed under AI hype, demands from CFO Amy Hood, and a complete dereliction of fan feedback.\n\nThe planned restructuring of Xbox Game Pass was months in the making and, beyond their apparent macroeconomic \"need\" to make even more money, it's based on user behavior and the desire to boost the content fund for the cohort most likely to unsubscribe without new content. Codenames appearing for the new tiers over the summer, and is not the result of a quarterly knee-jerk reaction. But it doesn't matter.\n\nCombined with huge price hikes, retailers like Costco and others removing Xbox hardware, and Microsoft's massive layoffs over the summer — it's not unsurprising people are speculating on Xbox's demise. Microsoft is absolutely awful at managing faith in its consumer products, and I've written previously about how the telemetry driving its decisions and its diffuse focus is leading to a collapse in morale in the brand.\n\nGaming is not a necessity, or a utility — it's driven by sentiment and \"fun\" feeling. people need to also feel good about where they play, and Microsoft is making it incredibly hard to feel good about Xbox right now. It's clearly reaching a crisis point.\n\nXbox the pariah\n\nThis feels like 2013 again. (Image credit: Windows Central)\n\nI've been covering Xbox for over ten years at this point, and I started when Microsoft's bombed Xbox One reveal led to a groundswell of hate for the brand and its future. It was fostered by a sense of betrayal in what Xbox had been and represented, and led to a huge climb down that effectively dismantled the Xbox One platform — and put Xbox firmly in \"third-place\" forever. Lately, it feels like we're back in 2013 again.\n\nThe industry looks very different in 2025, as maturing audiences and a lack of meaningful new player growth has companies breaking the rules to find new revenue streams. We've seen Xbox games flood onto PlayStation, we've even seen PlayStation bring games to Xbox. Microsoft is licensing out the Xbox brand to OEMs with the Xbox Ally (and I'm told more OEM hardware should appear in 2026, too).\n\nThe inconsistency is exhausting for fans, and in a sentiment-driven business, potentially untenable.\n\nThe one constant that Xbox fans could point to among all of this was the clear value of Xbox Game Pass. \"Xbox Game Pass is the best value in gaming,\" or so the meme goes. Despite some price rises over the past couple of years, it was hard to overlook what a stellar year it had thus far, with games like Expedition 33, Blue Prince, DOOM, The Elder Scrolls: Oblivion remake, and others. But with an unprecedented 50% price increase on the tier that actually gets day one games, the negative reaction has been incredibly strong.\n\nIt all just feels like another betrayal, particularly given President Sarah Bond's comments that Xbox Game Pass is profitable, and also hitting $5 billion in revenues. The way Xbox presented the \"changes\" as a \"good thing\" came across as tone deaf, especially given how other companies are pushing up prices while also simultaneously reporting record profits.\n\nSo, it's hardly surprising that these rumors gained so much traction, because even if they're not true today, they could definitely be true tomorrow. It's hard to take anything what today's Xbox says or does on faith, because they're apparently willing to throw anything and everything on the fire if it means a quarterly boost.\n\nThe inconsistency is exhausting for fans, most likely concerning for developers — and in a sentiment-driven business, potentially untenable.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/gaming/no-xboxs-next-gen-console-hardware-plans-arent-cancelled",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Huawei Atlas 950 SuperPoD vs Nvidia DGX SuperPOD vs AMD Instinct Mega POD: How do they compare?",
      "content": "Huawei stacks thousands of NPUs to show brute-force supercomputing dominance\n\nNvidia delivers polish, balance, and proven AI performance that enterprises trust\n\nAMD teases radical networking fabrics to push scalability into new territory\n\nThe race to build the most powerful AI supercomputing systems is intensifying, and major brands now want a flagship cluster that proves it can handle the next generation of trillion-parameter models and data-heavy research.\n\nHuawei’s recently-announced Atlas 950 SuperPoD, Nvidia’s DGX SuperPOD, and AMD’s upcoming Instinct MegaPod each represent different approaches to solving the same problem.\n\nThey all aim to deliver massive compute, memory, and bandwidth in one scalable package, powering AI tools for generative models, drug discovery, autonomous systems, and data-driven science. But how do they compare?\n\nSwipe to scroll horizontally Huawei Ascend 950 vs Nvidia H200 vs AMD MI300 Instinct Category Huawei Ascend 950DT NVIDIA H200 AMD Radeon Instinct MI300 Chip Family / Name Ascend 950 series H200 (GH100, Hopper) Radeon Instinct MI300 (Aqua Vanjaram) Architecture Proprietary Huawei AI accelerator Hopper GPU architecture CDNA 3.0 Process / Foundry Not yet publicly confirmed 5 nm (TSMC) 5 nm (TSMC) Transistors Not specified 80 billion 153 billion Die Size Not specified 814 mm² 1017 mm² Optimization Decode-stage inference & model training General-purpose AI & HPC acceleration AI/HPC compute acceleration Supported Formats FP8, MXFP8, MXFP4, HiF8 FP16, FP32, FP64 (via Tensor/CUDA cores) FP16, FP32, FP64 Peak Performance 1 PFLOPS (FP8 / MXFP8 / HiF8), 2 PFLOPS (MXFP4) FP16: 241.3 TFLOPS, FP32: 60.3 TFLOPS, FP64: 30.2 TFLOPS FP16: 383 TFLOPS, FP32/FP64: 47.87 TFLOPS Vector Processing SIMD + SIMT hybrid, 128-byte memory access granularity SIMT with CUDA and Tensor cores SIMT + Matrix/Tensor cores Memory Type HiZQ 2.0 proprietary HBM (for decode & training variant) HBM3e HBM3 Memory Capacity 144 GB 141 GB 128 GB Memory Bandwidth 4 TB/s 4.89 TB/s 6.55 TB/s Memory Bus Width Not specified 6144-bit 8192-bit L2 Cache Not specified 50 MB Not specified Interconnect Bandwidth 2 TB/s Not specified Not specified Form Factors Cards, SuperPoD servers PCIe 5.0 x16 (server/HPC only) PCIe 5.0 x16 (compute card) Base / Boost Clock Not specified 1365 / 1785 MHz 1000 / 1700 MHz Cores / Shaders Not specified CUDA: 16,896, Tensor: 528 (4th Gen) 14,080 shaders, 220 CUs, 880 Tensor cores Power (TDP) Not specified 600 W 600 W Bus Interface Not specified PCIe 5.0 x16 PCIe 5.0 x16 Outputs None (server use) None (server/HPC only) None (compute card) Target Scenarios Large-scale training & decode inference (LLMs, generative AI) AI training, HPC, data centers AI/HPC compute acceleration Release / Availability Q4 2026 Nov 18, 2024 Jan 4, 2023\n\nThe philosophy behind each system\n\nWhat makes these systems fascinating is how they reflect the strategies of their makers.\n\nHuawei is leaning heavily on its Ascend 950 chips and a custom interconnect called UnifiedBus 2.0 - the emphasis is on building out compute density at an extraordinary scale, then networking it together seamlessly.\n\nNvidia has spent years refining its DGX line and now offers the DGX SuperPOD as a turnkey solution, integrating GPUs, CPUs, networking, and storage into a balanced environment for enterprises and research labs.\n\nAMD is preparing to join the conversation with the Instinct MegaPod, which aims to scale around its future MI500 accelerators and a brand-new networking fabric called UALink.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nWhile Huawei talks about exaFLOP levels of performance today, Nvidia highlights a stable, battle-tested platform, and AMD pitches itself as the challenger offering superior scalability down the road.\n\nAt the heart of these clusters are heavy-duty processors built to deliver immense computational power and handle data-intensive AI and HPC workloads.\n\nHuawei’s Atlas 950 SuperPoD is designed around 8,192 Ascend 950 NPUs, with reported peaks of 8 exaFLOPS in FP8 and 16 exaFLOPS in FP16 - so it is clearly aimed at handling both training and inference at an enormous scale.\n\nNvidia’s DGX SuperPOD, built on DGX A100 nodes, delivers a different flavor of performance - with 20 nodes containing a total of 160 A100 GPUs, it looks smaller in terms of chip count.\n\nHowever, each GPU is optimized for mixed precision AI tasks and paired with high-speed InfiniBand to keep latency low.\n\nAMD’s MegaPod is still on the horizon, but early details suggest it will pack 256 Instinct MI500 GPUs alongside 64 Zen 7 “Verano” CPUs.\n\nWhile its raw compute numbers are not yet published, AMD’s goal is to rival or exceed Nvidia’s efficiency and scale, especially as it uses next-generation PCIe Gen 6 and 3-nanometer networking ASICs.\n\nFeeding thousands of accelerators requires staggering amounts of memory and interconnect speed.\n\nHuawei claims the Atlas 950 SuperPoD carries more than a petabyte of memory, with a total system bandwidth of 16.3 petabytes per second.\n\nThis kind of throughput is designed to keep data moving without bottlenecks across its racks of NPUs.\n\nNvidia’s DGX SuperPOD does not attempt to match such headline numbers, instead relying on 52.5 terabytes of system memory and 49 terabytes of high-bandwidth GPU memory, coupled with InfiniBand links of up to 200Gbps per node.\n\nThe focus here is on predictable performance for workloads that enterprises already run.\n\nAMD, meanwhile, is targeting the bleeding edge with its Vulcano switch ASICs offering 102.4Tbps capacity and 800Gbps per tray external throughput.\n\nCombined with UALink and Ultra Ethernet, this suggests a system that will surpass current networking limits once it launches in 2027.\n\nOne of the biggest differences between the three contenders lies in how they are physically built.\n\nHuawei’s design allows for expansion from a single SuperPoD to half a million Ascend chips in a SuperCluster.\n\nThere are also claims that an Atlas 950 configuration could involve more than a hundred cabinets spread over a thousand square meters.\n\nNvidia’s DGX SuperPOD takes a more compact approach, with its 20 nodes integrated in a cluster style that enterprises can deploy without needing a stadium-sized data hall.\n\nAMD’s MegaPod splits the difference, with two racks of compute trays plus one dedicated networking rack, showing that its architecture is centered around a modular but powerful layout.\n\nIn terms of availability, Nvidia’s DGX SuperPOD is already on the market, Huawei’s Atlas 950 SuperPoD is expected in late 2026, and AMD’s MegaPod is planned for 2027.\n\nThat said, these chips are fighting very different battles under the same banner of AI supercomputing supremacy.\n\nHuawei’s Atlas 950 SuperPoD is a show of brute force, stacking thousands of NPUs and jaw-dropping bandwidth to dominate at scale, but its size and proprietary design may make it harder for outsiders to adopt.\n\nNvidia’s DGX SuperPOD looks smaller on paper, yet it wins on polish and reliability, offering a proven platform that enterprises and research labs can plug in today without waiting for promises.\n\nAMD’s MegaPod, still in development, has the makings of a disruptor, with its MI500 accelerators and radical new networking fabric that could tilt the balance once it arrives, but until then, it is a challenger talking big.\n\nVia Huawei, Nvidia, TechPowerUp",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/huawei-atlas-950-superpod-vs-nvidia-dgx-superpod-vs-amd-instinct-mega-pod-how-do-they-compare",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Working on the HP EliteBook 8 G1a is a good experience, but I think it can be hard to justify the cost of this Ryzen AI business laptop",
      "content": "The HP EliteBook 8 G1a is a showcase for HP’s engineering skills, as it packs a lot into a relatively small chassis without compromising performance or battery life. I just wish it were a little cheaper, so more people could afford a PC with this underlying power.\n\nWhy you can trust TechRadar We spend hours testing every product or service we review, so you can be sure you're buying the best. Find out more about how we test.\n\nHP EliteBook 8 G1a: 30-second review\n\nTo avoid immediate confusion, HP makes a standard version of the EliteBook 8 G1a 14 laptop, and then the Next Gen AI PC Wolf Pro Security Edition (A27BLEA) that this review covers.\n\nWhile these share many of the same hardware components, the Next Gen AI PC Wolf Pro Security Edition (A27BLEA) is specifically designed for business users who need to deploy laptops for power users with enhanced security requirements.\n\nBuilt around the new AMD Ryzen AI 7 PRO 350, this is a highly efficient and yet powerful machine that’s ideal for demanding tasks, like running local AI models.\n\nBut it’s also ideal for a user who runs demanding AI tools, even if this machine wouldn’t realistically cross the threshold into being classed as a mobile workstation.\n\nIf you are looking for that level of performance, a laptop that uses the Ryzen AI 9 HX PRO 375 is probably more appropriate.\n\nThe limitations of the EliteBook 8 G1a are that it doesn’t have a second full M.2 2280 slot, limiting the amount of storage to 3TB with current capacities. And, while the memory modules are upgradable, this system with only one module is starved of memory bandwidth.\n\nIt does come with Wi-Fi 7, HDMI output and Thunderbolt ports, so while it might not be a necessity to have a docking station, it can exploit one effectively.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThis machine isn’t the cheapest to use this new platform, but HP has an excellent selection of EliteBook, ProBook, and ZBook designs that use AMD processors, so there is plenty of choice. With so many machines of this type appearing, it’s hard to pick this one as being exceptional enough to be one of the best business laptops. But HP makes highly effective hardware, and the EliteBook 8 G1a doesn’t undermine that narrative.\n\nHP EliteBook 8 G1a: Price and availability\n\n(Image credit: Mark Pickavance)\n\nHow much does it cost? From $1550/£1515\n\nFrom $1550/£1515 When is it out? Available now\n\nAvailable now Where can you get it? Direct from HP, or via online retailers\n\nSold as the HP EliteBook 8 G1a 14 inch Notebook Next Gen AI PC Wolf Pro Security Edition, the asking price in the UK is £1799.99 for a machine with 64GB of RAM and 1TB of SSD storage.\n\nThe same spec in the USA is priced at $1,899, making it currently a better deal for American buyers.\n\nWhat’s slightly odd is that via the HP store, it isn’t possible to select the spec of the review hardware, which matches 64GB of RAM with 512GB of storage.\n\nChoosing 512GB of storage automatically drops the memory to 32GB.\n\nFor American customers, the cheapest model with the Ryzen AI 7 PRO 350 processor is $1549. European buyers can’t get that combination, and the lowest-priced option in the UK is £1,511.99, with 1TB of storage and 32GB of RAM for that money.\n\nIt should be noted that for those buying into the AI era, local AI models need lots of RAM to run quickly, so it might be pointless to run this CPU with only 16GB of RAM.\n\nThe RAM on these systems can be upgraded, as can the storage, but that’s additional cost and effort beyond the purchase price.\n\nWhile I’m sure other brands will be using a similar platform in the coming months, at this time, the only significant releases are from Asus with the Zenbook S16, and the Lenovo ThinkPad P14s Gen 6 and P16s Gen 4.\n\nThe Lenovo ThinkPad P14s Gen 6 typically retails for around $ 1,240, featuring 32GB of RAM and 1TB of storage. Whereas the P16s Gen 4 is $1500 for one with 64GB of RAM and 1TB of storage.\n\nSo far, Asus isn’t using the PRO variant of the 350, but they do have the even more powerful Ryzen AI 9 HX 370 in the Zenbook S16 series, and you can get one with 32GB of RAM and 1TB of storage for only $1400.\n\nIn the grand scheme of things, the HP asking price for this machine isn’t excessive, but those looking for better value might want to consider the Asus Zenbook S16 series, which could easily save you money and get you a more powerful platform.\n\nWhat’s always important to realise is that retail costs as presented on the brand websites aren’t what corporations pay for bulk orders, and that sort of horse trading could make HP a much more competitive option.\n\nValue: 3.5 / 5\n\nHP EliteBook 8 G1a: Specs\n\nSwipe to scroll horizontally Category Item Processor AMD Ryzen AI 7 350 PRO 2.0GHz (16MB Cache, up to 5.0 GHz, 8 cores, 16 Threads) NPU Performance 50 TOPS (Neural Processing Unit for local AI tasks) Total TOPS 66 TOPS (NPU and CPU combined) Memory 64 GB DDR5-5600 (maximum official capacity) Storage 1 TB M.2 2280 PCIe Gen4 NVMe SSD Storage Exp. M.2 2230 PCIe Gen 4 Graphics AMD Radeon 860M Graphics Display 14\" diagonal, WUXGA (1920 x 1200), IPS, anti-glare, 800 nits, 100% sRGB, HP Sure View 5 integrated privacy screen with HP Eye Ease Camera 5 MP IR AI camera Audio Audio by Poly Studio, dual stereo speakers with discrete amplifiers, integrated dual array microphones Ports Right 1x USB 3.2 Gen 1 Type-A, 1x USB 3.2 Gen 2 Type-C, Kensington nano security lock Ports Left 2x USB4/Thunderbolt 4, 1x HDMI 2.1 TMDS, 1x 3.5mm Combo Audio Jack, SIM Card slot (LTE4 or 5G optional) Wireless MediaTek WiFi 7 MT7925 (2x2) and Bluetooth 5.4 wireless card Battery HP Long Life 3-cell, 62 Wh Li-ion polymer PSU HP 100 W USB Type-C slim adapter Operating System Windows 11 Pro Security HP Wolf Security, TPM 2.0, fingerprint sensor, auto lock/awake, onlook detector Size 31.56 x 22.2 x 1.17 cm (front); 31.56 x 22.2 x 1.55 cm (rear) Weight 1.39 kg Sustainability Low halogen; Bulk packaging available; 30% post-consumer recycled plastic; 80% recycled metal; 100% of HP paper-based packaging is from recycled or certified sustainable sources; Product Carbon Footprint Warranty 1-year limited warranty Colours Glacier silver\n\nHP EliteBook 8 G1a: Design\n\n(Image credit: Mark Pickavance)\n\nSolid construction\n\nLots of ports\n\nCramped keyboard\n\nA Wolf Pro Security Edition\n\nThe HP EliteBook 8 G1a 14-inch Notebook Next Gen AI PC Wolf Pro Security Edition (A27BLEA) nicely blends aesthetics with functionality. Its sleek, minimalist exterior is crafted from high-quality materials, giving it a premium feel and durability. The notebook’s slim profile and lightweight construction make it highly portable, ideal for those who travel for a living.\n\nThe 14-inch display is a standout feature, offering vibrant colours and sharp resolution that make working on the laptop relatively easy. The narrow bezels maximise screen real estate, providing an immersive viewing experience without increasing the overall size and weight of the device. The anti-glare coating ensures that the screen remains readable in various lighting conditions, reducing eye strain during extended use.\n\nWhat I was less enamoured with was the keyboard. The positive aspects are that the keys are well-spaced and provide a satisfying tactile response, making typing a pleasure.\n\nBut the keyboard doesn’t use the full width of the machine, and therefore some keys ended up reduced in size. Not a fan of tiny function keys or the cursor cluster, but despite this, I can type at a reasonable speed on it.\n\nThe backlit feature allows for easy use in low-light environments, adding to the notebook’s versatility. The touchpad is generously sized and highly responsive, supporting multi-touch gestures for improved navigation.\n\n(Image credit: Mark Pickavance)\n\nA real strength of the HP EliteBook 8 G1a is the port selection, since it includes USB-C, USB-A, HDMI, and an audio jack. This selection ensures compatibility with a wide array of peripherals and accessories, enhancing the notebook’s functionality. The inclusion of Wi-Fi 7 and Bluetooth 5.4, using the MediaTek MT7925 (2x2), ensures fast and reliable wireless connectivity.\n\nBeing a Wolf Pro Security Edition, HP add some neat features to provide robust protection against malware and cyber threats, in theory. These include a fingerprint reader and facial recognition technology built to secure logins and safeguard sensitive data. The part of the Wolf Pro technology that IT professionals will gravitate to is the Cloud-Based Management Console, which enables a centralised control for IT teams to monitor and respond to threats. There are lots of other features, like AI and behavioural analysis to detect unknown threats, if you haven’t already deployed equivalent tools in the business environment.\n\nOverall, the HP EliteBook 8 G1a is a well-designed, high-performance notebook that meets the needs of modern professionals and power users, without resorting to discrete GPUs and limited battery life.\n\nDesign: 4 / 5\n\nHP EliteBook 8 G1a: Hardware\n\nAMD Ryzen AI 300 series CPU\n\nRadeon 860M GPU\n\nUpgrades\n\nThe AMD Ryzen 7 350 PRO is one of the new Krackan Point CPUs that have recently come to market, and utilises the AMD mobile chipset FP8, aka Strix Point.\n\nBuilt on the latest 4nm TSMC fabrication, for its size and power consumption, this CPU delivers some exceptional performance, especially for AI use.\n\nFor those who read my Asus Expertbook P3 review, a machine that uses the non-PRO version of this chip, you might be wondering what a PRO spec processor adds.\n\nThe main distinction lies in the fact that the Ryzen AI 7 PRO 350 is tailored for business use, featuring additional functionalities and capabilities specifically designed for enterprise needs that are not present in the consumer variant, the Ryzen AI 7 350. Although both processors utilise the same core architecture and have similar performance potential, the “PRO” label indicates improvements in security, manageability, and reliability explicitly designed for business environments.\n\nWhat that’s worth to you personally, I can’t say, but HP does make a toned-down model with the basic AMD Ryzen 7 350 if you want to save a small amount of money.\n\n(Image credit: Mark Pickavance)\n\nWhat isn’t radical on this platform is the Radeon 860M GPU, which I’d characterise as being a reasonable integrated GPU, but nothing special.\n\nThis balance of a high-end CPU and mid-range GPU hints that it’s built for those power users who aren’t editing 4K videos or modelling in 3D. But what it does well is support local AI challenges for those who need AI functionality, but can’t guarantee cloud services.\n\nThe evolution of AI for business use is still very much at the Proterozoic stage, but for those who are embracing technologies like CoPilot, this hardware is superior to the prior generation.\n\n(Image credit: Mark Pickavance)\n\nWhile not perfect, the upgrade paths in this machine do at least allow for enhanced memory and storage, and potentially the WiFi module when WiFi 8 becomes available.\n\nGetting inside is relatively easy with a small screwdriver and a spudger, and with the underside removed, the battery, memory and storage are all highly accessible.\n\nUnlike the HX 395 hardware, which uses soldered memory, this platform features two SODIMM slots that can accommodate up to 32GB modules, for a maximum capacity of 64GB. It might be that at some point you will be able to get 48GB or 64GB modules, and increase that to 96GB or even 128GB, since the Ryzen AI 7 PRO 350 can address up to 256GB of memory space.\n\nI had two disappointments with the insides, and both related to the storage. The first is that the M.2 2280 slot, pre-installed with a Gen 4 1TB NVMe in my review hardware, didn’t have any form of heatsink or pad to help it dissipate. That effectively limits it to 2TB drives, since 4TB and 8TB options either come with or expect help with cooling.\n\nThe second M.2 slot is only 2230-sized, limiting it to 1TB capacities currently. There isn’t much room, I accept, but a second 2280 slot would have been terrific, since using AI without lots of storage space isn’t ideal.\n\n(Image credit: Mark Pickavance)\n\nHardware: 4 / 5\n\nHP EliteBook 8 G1a: Performance\n\nSwipe to scroll horizontally Laptops Header Cell - Column 1 HP EliteBook 8 G1a 14 AI Asus Expertbook P3 (with dual memory) CPU Row 0 - Cell 1 AMD Ryzen AI 7 PRO 350 AMD Ryzen AI 7 350 Cores/Threads Row 1 - Cell 1 8C 16T 8C 16T TPD Row 2 - Cell 1 15-54W (28W) 15-54W (28W) RAM Row 3 - Cell 1 64GB DDR5-5600 (2x32GB) 32GB DDR5-5600 (2x16GB) SSD Row 4 - Cell 1 500GB WD Blue SN5000 1TB Micron 2500 MTFDKBA1T0QGN Graphics Row 5 - Cell 1 AMD Radeon 860M AMD Radeon 860M NPU Row 6 - Cell 1 AMD Ryzen AI (50 TOPS) AMD Ryzen AI (50 TOPS) 3DMark WildLife 16,844 15,582 Row 8 - Cell 0 FireStrike 6331 6107 Row 9 - Cell 0 TimeSpy 2975 2882 Row 10 - Cell 0 Steel Nomad.L 2364 2262 CineBench24 Single 114 116 Row 12 - Cell 0 Multi 856 909 Row 13 - Cell 0 Ratio 7.48 7.83 GeekBench 6 Single 2857 2886 Row 15 - Cell 0 Multi 13638 13560 Row 16 - Cell 0 OpenCL 24764 24370 Row 17 - Cell 0 Vulkan 34322 33104 CrystalDIsk Read MB/s 7159 7006 Row 19 - Cell 0 Write MB/s 6558 6111 PCMark 10 Office 7576 7763 Row 21 - Cell 0 Battery 14h 31m 18h 17m Battery Whr 62 70 WEI Score 8.2 8.1\n\nSince they use the same platform and memory technology, the HP EliteBook 8 G1a is worthy of comparison with the Asus Expertbook P3, admittedly a cheaper device.\n\nHow HP configured this machine enables it to outperform the P3 in many tests, and it was provided with a better storage device in the bargain.\n\nWhere the P3 overtakes it is in battery life, with the Asus machine having a larger battery and a longer operating time accordingly.\n\nHowever, both these machines run for longer than a typical working day, and the EliteBook 8 G1a is lighter for those who carry their system with them.\n\nOne important note is that the performance of both these laptops can be massively undermined by using only a single memory module, as the review P3 was delivered. Therefore, don’t order one with a single memory module, or if you do, then purchase another identical module to get all the memory bandwidth available.\n\n(Image credit: Mark Pickavance)\n\nPerformance: 4 / 5\n\nHP EliteBook 8 G1a: Final verdict\n\nThe HP EliteBook 8 G1a ticks plenty of corporate boxes, something HP is exceptionally skilled at doing.\n\nWhat it offers is a powerful yet battery-efficient solution with all the latest security enhancements and management tools that corporate IT will love. It also features sufficient ports that most users won’t need a docking station, and the underlying platform is capable of running local AI models and tools.\n\nIt isn’t the cheapest laptop running this AMD Ryzen AI platform, but the quality of construction and features like Thunderbolt ports go some way to justify the extra it can cost over more affordable options.\n\nNot the best 14-inch laptop I’ve seen, but a solid platform that delivers power-user appeal without sacrificing its practicality.\n\nShould you buy a HP EliteBook 8 G1a?\n\nSwipe to scroll horizontally Value You pay a HP premium, but the build quality is good 3.5 / 5 Design A power-packed design that feels substantial 4 / 5 Hardware AI 300 series CPU, DDR5 and special AI sauce is a winning combo 4 / 5 Performance Excellent performer and acceptable battery life 4 / 5 Overall A powerful AI platform for those who need that 4 / 5\n\nBuy it if...\n\nYou need Thunderbolt or USB4\n\nThe AMD Ryzen AI 7 PRO 350 at the heart of this design has Thunderbolt/USB4 ports inherently, but there are laptops around that don’t implement them for various reasons. If you want that technology, and most would, then this machine is for you.\n\nYou like upgrades\n\nLots of bits on this machine can easily be upgraded, including the memory and storage. If you don’t mind using a screwdriver, then there is plenty of potential for enhancements.\n\nDon't buy it if...\n\nYou need exceptional battery life\n\nAccording to HP, this machine should last more than 18 hours, but it only lasted 14 hours in my test. That’s respectable, but other machines that use the latest Intel Ultra 200 processors or the Qualcomm Snapdragon X series can last longer.\n\nYou are on a tight budget\n\nFor the money, this is a decent laptop with plenty of nice features and a good hardware platform, but it’s hardly cheap. There are cheaper options that sacrifice some of the bells and whistles that use the same CPU, which will make your budget stretch further.\n\nFor more productivity machines, we reviewed the best laptops for work and gaming and the best laptops for working from home.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/hp-elitebook-8-g1a-business-laptop-review",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "AMD Versal TRNG Driver Upstreamed To Linux 6.18, Intel Adds New Telemetry For QAT Gen6",
      "content": "All of the crypto subsystem changes have been merged for the in-development Linux 6.18 kernel.A new driver in the cryptographic subsystem is the AMD Versal TRNG driver . This provides true random number generator support with the AMD Versal Adaptive SoCs.\n\nThis driver was contributed by AMD directly for upstreaming to the mainline Linux kernel. This also joins other new Versal support in Linux 6.18 like the new Versal NET DDR EDAC driver Meanwhile the AMD Crypto Co-Processor \"CCP\" driver has added a new API for dealing with SEV-SNP virtualization around cipher text hiding.Over on the Intel side, earlier this year they introduced QAT Gen6 support . For QuickAssist/QAT Gen6 with the Linux 6.18 kernel they are adding ring buffer idle and command queue telemetry support.The crypto pull for Linux 6.18 also includes improvements to the HiSilicon crypto driver, a new TI driver with ECB/CBC AES support, and other changes. See the crypto pull for the full list of crypto changes that were merged to mainline yesterday.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-Crypto",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Lenovo Legion Go 2 Review: A Handheld Made For Big, Meaty Claws",
      "content": "You buy Lenovo’s new Legion Go 2 handheld for the screen. The performance is secondary to how beautiful recent 2D titles look on the 8.8-inch, 1200p OLED display. The Legion Go 2 is otherwise a big, meaty handheld for gamers with big, meaty claws. You’ll struggle to hold it above your head lying in bed unless you’re a professional power lifter; the controls won’t be your favorite; it’s as wonky as its predecessor. And it’s hard to argue anybody should spend well over $1,000 on a gaming handheld rather than just buying a full gaming laptop.\n\nDespite all that, I can’t help but enjoy the hell out of it. My initial hours spent rolling my eyes at everything Lenovo failed to fix from its first iteration slowly morphed into the kind of appreciation that can only occur when a device starts to feel personal. It’s what happened when I downloaded Hollow Knight: Silksong and Hades II to the device and had to hold back a gasp on a crowded plane for how gorgeous both games looked on Lenovo’s big, expensive, beautiful display.\n\nLegion Go 2 It's thick, heavy, and so damn pretty. It's a shame it costs as much as it does. 4 See at Best Buy Pros Beautiful OLED display\n\n144Hz refresh rate with VRR\n\nNew ergonomics\n\nLow-wattage performance uplift Cons Annoying removable controls\n\nFPS mode is pointless\n\nReflective display\n\nVery expensive at $1,350\n\nIt’s the same feeling I get from Valve’s $550 Steam Deck OLED, which uses the same organic light-emitting diode screen technology to present deeper contrast and rich colors. Valve’s handheld maxes out at 800p on an older, custom AMD chipset. Even when you factor in performance and display size, the Steam Deck OLED is still a much, much better deal. My review unit version of the Legion Go 2 with the AMD Ryzen Z2 Extreme processor, 32GB of RAM, and 1TB of storage, costs $1,350. I could literally buy two Steam Decks for this price (more if I opted for the LCD model). For Lenovo’s inflated price, I could run out and buy three $450 Nintendo Switch 2 handhelds. You could nab a version of the Legion Go 2 that starts at $1,100 for a version with a AMD Ryzen Z2, but judging by my tests that chip will land closer in power to handhelds that are three years old and cost much less.\n\nIt’s a ridiculous scenario that consumers are taking the brunt of Donald Trump’s obsession with import taxes, aka tariffs. And in that way, consumers are screwed no matter what. The upcoming Asus ROG Xbox Ally X, which is set to launch on Oct. 16 with the same Ryzen Z2 Extreme chip, will set you back $1,000. The original Legion Go asked for $700 in 2023. The Asus ROG Ally X demanded $800 at launch last year. Both now retail at a higher price, likely due to tariffs. I would tell you to wait and buy a new handheld, but there’s no way to tell if prices might increase in coming months.\n\nReally? You kept FPS mode?\n\nWhat drives me mad using the Legion Go 2 is how Lenovo held back from improving over the 2023 handheld. The revised version is far more ergonomic than the two-year-old device with its sharp corners. Both handhelds let you remove each controller and play with the screen separated, like the Nintendo Switch. The Switch 2 did away with rails and went for magnetic connections for each Joy-Con 2, which makes attaching and detaching the controllers a little easier. Lenovo’s old and new system still use a series of exposed pins you jam into a cavity on each side of the screen. You need two hands and a strong pitching arm to remove each controller with a down and out motion. Reattaching them can be just as annoying.\n\nSee Lenovo Legion Go 2 at Best Buy\n\nThe controller uses Hall effect sticks that are much better at surviving stick drift, though they still feel a little too thin on my fingers compared to other handhelds I’ve used. The Legion Go 2 has slightly redesigned bumper buttons that make it easier to press and the same, large triggers. The $650 Legion Go S had a switch to enable instant triggers with less travel—better for first-person shooter games, but because of the removable controllers you’ll have to stick with the full range of motion.\n\nThe Switch 2’s big standout feature is its new mouse mode enabled just by putting the controller down on a table or your pant’s leg. Lenovo did it first on the Legion Go with its FPS mode. So is it any better now? No, absolutely not. You still need to remove the right controller and flick the “FPS” switch to turn on an optical mouse sensor. You then need to slot it into a base to hold it like an old-school flight stick, where the two side buttons act as the left and right mouse click. The DPI is still low enough you’ll struggle to get it working on anything but a desk. Even when you do, using a joystick and the FPS controller together necessitates changing the in-game controls. I tried it in both Cyberpunk 2077 and Borderlands 4, and it caused such havoc with both titles I was loathe to use the FPS mode again.\n\nAs for I/O, the Legion Go 2 has both a bottom and top USB-4 port. In theory, this could allow you to hook it up to an eGPU. More likely, it’s sole purpose is for charging or hooking up to a dock for HDMI passthrough. As much as Lenovo implies you’ll create a full “battle station” out of your device for instantaneous PC, you don’t want to hook it up to anything larger than a 1440p monitor, and only then for playing games most systems can run anyway.\n\nStrangely enough, one of the best improvements over the last generation handheld is the Legion Go 2’s new soft carrying case. The old case was very protective, but it was also enormous. The new version is smaller and more squat than the default Steam Deck case, which makes lugging around the 8.8-inch handheld onto planes surprisingly easy. There’s two little hidey-holes for the FPS mode stand, but since you’ll never use it, you can stick anything else in there. Just don’t tell me what.\n\nThe Legion Go 2 is so damn pretty\n\nAll the new ergonomics make it easier to hold, but not enough that it won’t feel heavy in your hands. You’ll find you’ll need a table or lap to rest your elbows on, or else you’ll use the built-in kickstand to prop it up on your desk. Either way you hold it, you’ll end up enjoying this handheld mostly for the display. As I said earlier, the 8.8-inch OLED display is sublime. It doesn’t have any higher screen resolution than the Legion Go’s 1,920 x 1,200, but it’s enough to make games pop.\n\nFor my hands, the Legion Go 2 is just large enough where I can grip it and access all the controls. Other users who are smaller in stature may not be so lucky. Ignore all those 11-inch handhelds out there. Near-9-inch devices are more than enough. The screen also sports a 144Hz refresh rate with VRR, or variable refresh rate. All those games that can hit above 100 fps (which, let’s be honest, will mostly be older or 2D titles), will look their peak on the Legion Go 2.\n\nThe screen feels bright enough indoors, but while Lenovo promises you’ll get 1,100 nits of HDR brightness, the screen is not great for using outdoors. It’s blinded by direct sunlight, and even sitting near a window you’ll see most details disappear. The screen is also very reflective. A matte coating would have dulled the display quality, but it’s at the risk of catching a glimpse of your girlfriend walking up behind you.\n\nRyzen Z2 Extreme isn’t a huge leap\n\nThe AMD Ryzen Z2 Extreme APU is purely iterative. If you’ve been watching like a hawk, hoping to devour the latest and fastest handheld chip, this isn’t it. The performance difference generation to generation is minimal. In some games, you could get 5 to 10 fps more at the highest TDP, or thermal design power, People who focus too hard on benchmarks will come away disappointed. If you care more about whether the system can play the latest AAA games, know that you’ll be able to achieve playable frame rates at the max 1200p resolution though only by dropping any hope of ray tracing for more-realistic lighting effects.\n\nSee Lenovo Legion Go 2 at Best Buy\n\nI’m fundamentally a gamer who refuses to drop the resolution of games for the sake of performance. I will lower graphics settings in a desperate attempt to eek out the minimum 30 fps. The Legion Go 2 can manage to take some AAA games into playable states at the max 35W of TDP (thermal design power) once the handheld’s engines are firing on all cylinders. TDP determines how much power is being sent to the processor, which will dictate overall performance. Borderlands 4 is one of those games notorious for running poorly on PC and consoles alike (you won’t find the game on Switch 2 in the coming days, either). I was able to get a stable sub-40 fps on the lowest possible graphics settings. I could achieve a little better frame rates in Indiana Jones and the Great Circle. Even at lower graphics settings, the game still looks and sounds great on the small screen.\n\nOlder games fare better. Control could average 40 to 49 fps at low settings with the handheld plugged in. The Shadow of the Tomb Raider benchmark at 1200p and medium settings preset with AMD’s FSR upscaling saw an average of 44 fps, while at 1080p with the same settings it could hit 48 fps. In Baldur’s Gate III, I could average above 60 fps in the open areas of Act 1 and get between 45 and 55 fps in the city environments of Act III.\n\nIn 3DMark benchmarks, the Legion Go 2 hit a score of 3,305 and 24.48 average fps in Steel Nomad Lite tests. That’s 1,000 points better than the Legion Go S with its Ryzen Z2 Go chip running on Windows, but it’s only a little more than 300 points better than the Z1 Extreme on the Asus ROG Ally X from 2024. The new device hit 3,897 points in Time Spy tests, which again is barely more than 300 points better than an Ally X. It’s not much better than an MSI Claw 8 AI+, which uses a full Intel laptop chip. Simply put, the Legion Go 2 isn’t a huge step over the previous gen at the max wattage.\n\nHowever, the device’s secret sauce is in how well it performs at lower wattages. Tests with multiple games at wattages as low as 34 fps still enabled relatively stable frame rates in games like Shadow of the Tomb Raider. While in Cyberpunk 2077 at full resolution and Steam Deck settings, the device gets 44 fps in benchmarks, at 15W it still managed to eek out nearly 30 fps. I don’t expect anybody will run high-end games on lower power. Instead, the best experience comes from games that are far less intensive. I could net well over 160 fps in Hades II on the “Balanced” performance setting. Hollow Knight: Silksong seems like it was built with the Legion Go 2 in mind with automatic settings to stay around 144Hz. These games play so gloriously on this handheld, I don’t want to play them on anything else. It’s a shame you have to spend $350 more than an Xbox Ally X jut for that pretty screen and higher refresh rate.\n\nWindows still sucks for handhelds, but it could get better\n\nOn balanced power settings, I could game for around 2 hours and 40 minutes before the device was literally begging me to plug it in. In other tests where I was gaming at the full resolution and wattage playing Indiana Jones, it lasted closer to 2 hours. The Legion Go 2 sports a 74Wh battery, which is slightly worse than the ROG Ally X’s 80Wh. The larger OLED display and higher max resolution will inevitably drag the battery life down.\n\nAt this point, players should not expect a handheld that will last very long. The ROG Ally X still has one of the best battery life at full power when it gets closer to 3 hours of runtime. In real life, the difference is negligible. At this point in my life, having a max two hours of playtime is strangely beneficial. If I’m clearing room after room in Hades II late at night, the battery timer is essentially my alarm. If it’s close to 12 a.m. and I’m about to run out of power, it’s a sign I should get some rest.\n\nDepending on the game you’re playing, the device’s fans can get relatively loud. Even at max speed I wouldn’t call them jet engine noise. It’s enough to remind you to be mindful when sitting next to strangers on a plane. The device kept very cool in my time using it. I never felt any heat around the controls, and the area around the fans also didn’t feel steamy when playing a game at max wattage.\n\nI can’t excuse the price, but I had such a good time with the Legion Go 2 it felt like a personal companion after traveling for more than a week and a half away from home. But there’s an elephant in the room shaped like a big “X” we need to address. The Xbox Ally and Xbox Ally X are supposed to launch with a new version of Windows, dubbed the “Full Screen Experience” (FSE) built exclusively for gaming handhelds. While this may fix the lingering usability issues of Windows 11 on a 7- or 8-inch screen, the upgrade should also eliminate background tasks and—hopefully—boost performance by 20%. The issue is that Microsoft has said you may need to wait until next spring to get it on handhelds like the Legion Go 2.\n\nWindows is terrible on handhelds. It gets in the way when trying to put the device to sleep while still in-game. It bombards you with popups for OneDrive that you need to use the touchscreen to excise. It saps power and makes the device run worse than it would if it was running SteamOS, the same Linux-based operating system running on the Steam Deck. In our tests, the Legion Go S with SteamOS outperforms its Windows counterpart by 20 to 30%. Unless you’re dead set on keeping your Xbox Game Pass games handy, I would suggest looking into installing Valve’s software on the Legion Go 2. I have not confirmed whether you can install SteamOS on the new handheld, though if its not compatible at launch, I assume an update may be around the corner. Without the FSE or SteamOS, this can’t be my handheld of choice. With a new operating system, the Legion Go 2 would become the bell of the ball for modern PC handhelds.\n\nSee Lenovo Legion Go 2 at Best Buy",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/lenovo-legion-go-2-review-a-handheld-made-for-big-meaty-claws-2000666394",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Linux 6.18 DRM Pull Includes New Tyr & Rocket Drivers, More AMD & Intel GPU Enhancements",
      "content": "The Direct Rendering Manager \"DRM\" pull request ended up leading to Linus Torvalds complaining over text and Rust code formatting but in the end he pulled all of these kernel graphics driver updates and also the associated \"accel\" accelerator subsystem drivers too.With the Linux 6.18 DRM pull there is a lot of kernel graphics driver improvements across the board, including the new drivers of Tyr and the Rocket accelerator driver. For enhancing existing driver support, the AMD and Intel graphics drivers continue seeing a bulk of the activity. Plus ongoing Rust code work in the DRM subsystem and more.\n\nBelow is a look at the DRM kernel driver changes for Linux 6.18.- The \"Rocket\" accelerator driver is finally mainlined for enabling the NPU found on newer Rockchip SoCs. This is the open-source driver reverse-engineered and started by Tomeu Vizoso. The Rocket accel driver works with new user-space code in Mesa 25.3 for Rockchip NPUs.- The AMDGPU and AMDKFD Checkpoint and Resture \"CRIU\" support for GEM memory objects.- Expanded AMDGPU Video Core Next \"VCN\" engine reset support.- More AMD Cyan Skillfish updates.- The AMDXDNA accelerator driver now supports user-space allocated buffers, improved error reporting, and other enhancements.- A new Intel Xe driver interface for querying VMA count and memory attributes. The intel Intel SLPC \"power_profile\" sysfs interface for the Xe driver for power management tuning.- Intel Xe driver SR-IOV support for CCS surfaces on Xe2+. The SR-IOV PF mode is also now enabled by default on supported platforms. Intel has returned to working on the upstream Habana Labs accelerator driver . There still is no Gaudi 3 support but at least they are back to working on this code under a new set of maintainers.- Intel Xe driver support for madvise in GPU SVM (Shared Virtual Memory).- The Arm Mali Panthor DRM driver added support for Mali G710, G510, G310, Gx15, Gx20, Gx25 GPUs.- Continued work on Nova as the next-generation open-source NVIDIA Linux kernel driver written in Rust.- The initial code around Tyr as a new Rust driver for Arm Mali GPUs . It's not yet usable by end-users, similar to the Nova driver.- Various new Rust abstractions and other work toward making Rust DRM drivers more practical.See this pull for the full list of DRM feature patches this cycle.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-DRM",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "I tested the GMKtec NucBox K12 and I think developers and creators will love the expansive upgrade potential",
      "content": "While classed as a mini PC, the form factor is marginally larger than most. However, with a powerful mid-range CPU and GPU, the extra airflow enabled by the design and the ability to expand potential with an eGPU make this a surprisingly powerful and versatile option. Through the test, it proved exceptionally good for content creation and even mid-range gaming.\n\nWhy you can trust TechRadar We spend hours testing every product or service we review, so you can be sure you're buying the best. Find out more about how we test.\n\nGMKtec NucBox G9: 30-second review\n\nThe moment that the K12 was removed from the box, it was obvious that this was a more measured machine compared with the majority of high-performance Mini PCs that I have looked at in the last year.\n\nFirstly, it's larger, and the design has a depth and flair to it that is lacking from many of the small box machines that I usually test. As I checked over the casing, it was good to see plenty of venting, and while the AMD Ryzen 7 H 225 and AMD Radeon 780M are a powerful combination, these days they sit decidedly in the mid-range. Thankfully, the pricing reflects this, and the larger form also enables plenty of airflow and a pretty decent array of ports across the front and back of the machine.\n\nAgain, while these are all present generation, it seems that GMKtec has gone for high spec, but tried and tested. So, while powerful, there's nothing ground-breaking here, just hardware that the company knows is going to perform and be reliable.\n\nThrough the test, this was certainly the case, and as I ran through the usual array of office applications, web browsing and even delved into image and video editing, the machine, like many of the best mini PCs I've tested, held up with surprising resilience.\n\nAs the pressure was applied with 4K video editing in DaVinci Resolve, the fans kicked in, and while the 1TB internal storage was enough to hold the source files, I connected a working drive through the USB4 ports at the back for more storage, if I was using this machine longer term then I'd install an addition SSD into one of the two spare internal M.2 2280 slots.\n\nThe data transfer rates were excellent, and while the machine certainly has the brute power to process and edit video, internal storage would need an upgrade to be used as a working drive. The USB4 interface, while fast, is nothing compared to the 4000MB/s+ write speeds of the internal drive. Thankfully, those additional slots enable storage to be upgraded to a staggering 24TB, more than enough for even the busiest content creators! Likewise, the RAM can be boosted to 128GB.\n\nGaming performance is equally well balanced, and while you might not be able to ramp the game's graphics to the max, you're going to get some pretty decent gameplay. If you do want to take gaming up a level, then there's the Oculink port so you can attach an eGPU; there's really no limit on the potential.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nConsidering the features of this machine and the ability to max out the storage, RAM, and connect to an eGPU, it all comes together to offer a very solid machine that will make an ideal solution for content creators, developers or anyone looking for a solid, powerful PC that strikes a balance between the latest technology, speed and reliability.\n\nGMKtec NucBox K12: Price and availability\n\nHow much does it cost? From £409 / $409\n\nFrom £409 / $409 When is it out? Available now\n\nAvailable now Where can you get it? Directly from GMKtec or Amazon\n\nThe GMKtec NucBox K12 is widely available with a price starting at £409/$409 for the barebones version. The model that I've looked at in this review is the 32GB RAM with 1 TB SSD, which will set you back $549/549/£550, or you can order the 64GB RAM, 1TB SSD option for $609/£600 directly from the gmktec.com website. The machine is also available from Amazon.com and AliExpress.\n\nHere are a few quick links with a variety of configurations that I've found:\n\nAmazon.com\n\n32GB / 512GB\n\n32GB / 1TB\n\n64GB / 1TB\n\nAmazon.ca\n\n32GB / 1TB\n\n64GB / 1TB\n\nAmazon.co.uk\n\n32GB / 1TB\n\n64GB / 1TB\n\nGMKtec EU\n\nClick here to see the line-up\n\nValue: 4.5 / 5\n\n(Image credit: Alastair Jennings)\n\nGMKtec NucBox K12: Specs\n\nCPU: AMD Ryzen 7 H 255\n\nGraphics: AMD Radeon 780M\n\nRAM: 32GB DDR5 5600MT (128GB Max)\n\nStorage: 1TB M.2 NVMe PCIe 4.0 SSD\n\nFront Ports: 3.5mm Combo jack, USB3.2 Gen2 Type-C (PD/DP/Data), 2×USB3.2 Gen2 Type-A, USB2.0, Clear CMOS\n\nRear Ports: DC port, 3.5mm Combo jack, HDMI 2.1, DP 1.4, USB4, Oculink (PCIe Gen4×4), USB3.2 Gen2 + USB2.0, 2×2.5G LAN (Realtek 8125BG), Fan/LED control button\n\nConnectivity: Wi-Fi 6E, Bluetooth 5.2\n\nAudio: Built-in speakers (basic), headphone/mic combo jack\n\nCamera: None\n\nSize: 117 x 112 x 42 mm\n\nOS Installed: Windows 11 Pro\n\nAccessories: Power adapter, HDMI cable, VESA mount\n\nGMKtec NucBox K12: Design\n\nThe GMKtec NucBox K12 takes a slightly different approach to design compared with many other Mini PCs. Firstly, it's slightly larger, so while still small, there's more airflow potential and plenty of space for accessories.\n\nThe design is clean with a matte black aluminium body, with a folded-over detail that covers the top and bottom fans. On top, there's also a turbo fan button, which gives you some sort of control over the machine's cooling. The main purpose of this machine is as a no-fuss processing machine for content creation, development, or any other task that would put most other machines under sustained strain.\n\nWhile the price point of the machine is decidedly mid-range, the use of metal and the detailing just give this an added feeling of quality, and when you couple that with the fact that even as a mini PC it is so upgradable, you suddenly realise that actually, for what's on offer here, it is exceptionally well-equipped and priced.\n\nWhile the form factor is slightly larger than some others at 117 x 112 x 42 mm and weighing in at X g, it's still light enough to be easily mounted using the VESA mount that's included in the box.\n\n(Image credit: Alastair Jennings)\n\nAround the front, there's a good selection of ports with 3.5mm combo jack, USB3.2 Gen2 Type-C (PD/DP/Data), 2×USB3.2 Gen2 Type-A, USB2.0 and a Clear CMOS button.\n\nAround the back, there's again a good selection of ports with a DC port, a combo jack, an HDMI 2.1, a DP 1.4, an Oculink (PCIe Gen4×4), USB4, a USB3.2 Gen2 + USB2.0, 2×2.5G LAN (Realtek 8125BG) and a Fan/LED control button on top.\n\nAccess to the insides, where you can add up to three M.2 SSDs and RAM, is made by removing the metal fan cover and then going through the top. Everything is nicely laid out, and access to all hardware is easily available if you do want to upgrade in the future.\n\nDesign: 4.5 / 5\n\n(Image credit: Alastair Jennings)\n\nGMKtec NucBox K12: Features\n\nThe AMD Ryzen 7 H 255 offers 8 cores and 16 threads with Zen 4 architecture, and this is coupled with the AMD Radeon 780M with RDNA 3 architecture. In the past, this combination has proven to be well-priced and powerful.\n\nSupporting the processing is an equally impressive range of memory with dual-channel DDR5 5600 MT/s SO-DIMM slots that can take up to two 64GB sticks, giving you 128GB of usable RAM. There are also three M.2 2280 PCIe slots that will enable you to add up to 24TB of storage. This is one of the largest capacities for this price point of Mini PC that I have come across, and again, it is extremely impressive.\n\nIt's worth noting that two of those slots are PCIe 4.0x2, and one is PCIe 4.0x4, with the operating system in the review sample utilising this slot for the SSD to ensure the fastest possible speeds.\n\nUpgradability does seem to be at the heart of this machine. Out of the box, you have a very solid and reliable machine with tried and tested hardware, with a few bits of bang-up-to-date technology to ensure future-proofing. The USB4 offers fast transfer speeds and connection to monitors, and the DDR5 RAM offers exceptional speed.\n\nOn top of the impressive performance I gained from the base 32GB, 1TB SSD review unit, it was obvious with all the cooling options that this machine, if enabled, would have a lot more to give.\n\nWith USB4, USB-C, HDMI and DP ports, you have plenty of potential to link out to monitors at 4K@60Hz, but then with the Oculink port, you can also easily hook into an eGPU for a huge graphics power boost.\n\nAnother feature that reinforces the fact that this machine has been aimed at users who place demands on their systems is the dual 2.5G Ethernet, enabling ultra-fast wired networking, so that there's minimal network lag and again reliability, if again the 2.5G technology is a little dated.\n\nFinally, my review sample arrived with Windows 11 Pro pre-installed, but as ever, you can install Linux, Ubuntu or any variation you need.\n\n(Image credit: Alastair Jennings)\n\nFeatures: 4 / 5\n\nGMKtec NucBox K12: Performance\n\nBenchmark scores CrystalDiskMark Read: 5024.59\n\nCrystalDiskMark Write: 4453.91\n\nGeekbench CPU Multi: 11694\n\nGeekbench CPU Single: 2369\n\nGeekbench GPU: 31240\n\nPCMark Overall: 6705\n\nCinebench CPU Multi: 13519\n\nCinebench CPU Single: 1606\n\nFire Strike Overall: 7512\n\nFire Strike Graphics: 8171\n\nFire Strike Physics: 22243\n\nFire Strike Combined: 2892\n\nTime Spy Overall: 3125\n\nTime Spy Graphics: 2796\n\nTime Spy CPU: 9385\n\nWild Life Overall: 17400\n\nSteel Nomad Overall: 549\n\nWindows Experience Overall: 8.2\n\nGetting started with the GMKtec K12 was fast, with the Wi-Fi connection seeming to be especially robust on the Eero 6 router compared with some of the smaller machines.\n\nAs the machine arrived with Windows 11 Pro installed, it was just a case of running through the standard Windows setup process, and the machine was ready to go.\n\nInitial impressions were good, with the machine running silently and able to cope with multiple browser windows open and editing Google Docs and other spreadsheets without issue. As with most machines these days, the standard office tasks are a given, and everything should run smoothly.\n\nAs the test continued, I installed and opened Photoshop, Lightroom and DaVinci Resolve, quickly pushing the abilities of the machine, but once again the CPU and GPU combo managed to handle everything with seeming ease.\n\nPhotoshop, Lightroom and Bridge in particular ran especially smoothly, with files opening and closing quickly, no doubt due to the exceptionally fast SSD and RAM.\n\nAs I migrated to light video editing in CapCut and then to DaVinci Resolve, the fans did start to kick in, and as graphics were created in Photoshop and brought across to the video editing, there were a few occasions where you could just see the system start to strain. However, it was all well handled, and for an integrated GPU, the Radeon 780M certainly impresses.\n\nAs that processing increased, so did the fan noise, but only slightly. The larger form of the machine, along with the large internal fans, does seem to keep the noise to a minimum, again, a good feature if you're editing video.\n\nChecking through the benchmarks, this reinforced the real-world tests. Microsoft Office and all productivity apps, multimedia worked exceptionally well and as fast and smooth as you could expect on any machine.\n\nCreative applications such as Photoshop and Lightroom run well again, and there's no jittering when using brush tools, and render times in Lightroom are fast.\n\nHowever, as this CPU and GPU are now getting older, they're not supported by AI features or an NPU, so the Photoshop AI processing is noticeably slower than some of the AI-enhanced machines.\n\nAs I moved on to DaVinci Resolve editing 4K video footage from a Sony A7 IV, the results were good. I could feel that I was pushing the system, and the fans kicked in, but short edits were more than achievable, and CapCut, as ever, ran smoothly.\n\nMoving on to gaming, the integrated GPU did start to struggle, and while DiRT Rally and Tekken 8 were perfectly playable, when I moved on to Indiana Jones and the Great Circle and then Hogwarts Legacy, the graphics and resolution did need to drop to the lower settings.\n\nIf you do want to use the machine for gaming, then the Oculink port should come into play, and with the cooling and power of the machine in all other respects, this should make a very decent gaming platform.\n\nPerformance: 4 / 5\n\n(Image credit: Alastair Jennings)\n\nGMKtec NucBox K12: Final verdict\n\n(Image credit: Alastair Jennings)\n\nAs an office machine, the GMKtec K12 is exceptional. Out of the box, it has the speed and reliability to make it a very viable option, and the small size means that it's easily portable if you do need to move it around the office or home.\n\nThe fact that it utilises tried and tested hardware adds to the reliability, and as a machine to test, this has been one of the easiest, just for its speed and ease of use. Likewise, if there is a need to upgrade, then access to the inside is fast, and installation of components should only take a few moments.\n\nWhat I really liked about this machine is just how well-balanced it is. It might be larger than most Mini PCs, but it's still small, and the balance of power and upgradability gives it a level of future-proofing that few other machines of this size or type can offer.\n\nWhen it comes to content creation, the out-of-the-box configuration can handle most business use, short video and image enhancement with ease, and if you need longer productions, then it has the potential and power, especially with a bit of a storage upgrade.\n\nWhile the CPU and GPU are good, they do start to feel the strain under gaming, especially, but even then, with the Oculink option, there's potential.\n\nAs a good, well-priced all-rounder with plenty of upgrade potential, the K12 is a superb option.\n\nShould I buy the GMKtec NucBox K12?\n\nSwipe to scroll horizontally Value Exceptionally well-priced machine with plenty of potential 4.5 Design Great design with a larger form factor that enables plenty of airflow for heavy workloads 4.5 Features A good balance of older and new technology offers speed and reliability 4 Performance Very capable machine for most tasks, including video, with plenty of upgrade potential 4 Overalls A well thought-through machine that can expand as you need 4.5\n\nBuy it if...\n\nYou need power For coders, video editors, or professionals who want to save space and have portability without sacrificing performance. Desk space matters Perfect for minimal setups, VESA mounting if you want to clear your desk, or small enough for travel.\n\nDon't buy it if...",
      "source": "TechRadar",
      "url": "https://www.techradar.com/computing/gmktek-nucbox-k12-mini-pc-review",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Meet Lisa Su: CEO and president of Advanced Micro Devices, the main competitor to Nvidia",
      "content": "Lisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion.\n\nREUTERS/Steve Marcus\n\nAMD's CEO, Lisa Su, grew up in Queens and obtained three…\n\nThis story appeared on businessinsider.com , 2025-10-05 10:16:01.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/ccf28a26f3aecc1a",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Microsoft's new Photos app update is so good that it could well become my favorite photo organizing tool - but you will need a Copilot+ PC to experience it",
      "content": "The app sorts receipts, screenshots, and handwritten notes automatically\n\nCopilot+ PCs are required for Microsoft’s newest Photos app functions\n\nAutomatic classification works even across different languages and scripts\n\nMicrosoft has released a new version of its Photos app, now presented as a more advanced tool for organizing and enhancing digital images.\n\nThe update, now live in the Microsoft Store, relies heavily on local artificial intelligence computation, with new functions tied specifically to Copilot+ PCs.\n\nThe app is not a dedicated photo editor, so it cannot be an Adobe Photoshop alternative. It instead focuses on sorting pictures, tagging documents, and upscaling low-resolution images with AI.\n\nAI-powered photo organization\n\nThe update brings automatic classification using an onboard neural processing unit to scan a library of pictures and sort them into categories such as screenshots, receipts, documents, and handwritten notes.\n\nThis system is meant to reduce the time spent scrolling through unstructured folders.\n\nMicrosoft also says the classification works across languages, so a receipt or document in another script should be tagged correctly.\n\nA “keyword” search option now allows users to quickly filter results, a function that might appeal to those who already store years of digital clutter inside their image folders.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAlongside organizational features, the update introduces a “super resolution” feature that can upscale low-resolution images without relying on external servers.\n\nThe work happens locally on the device, restoring detail that would normally disappear during enlargement.\n\nMicrosoft presents this as a way to bring older or compressed photographs closer to modern display standards.\n\nOn the downside, these AI functions are only available on Copilot+ PCs powered by Intel, AMD, or Qualcomm chips with NPU units.\n\nThat requirement places the most publicized upgrades out of reach for most current Windows users.\n\nIt also frames the Photos app as more of a showcase for Microsoft’s new hardware strategy than a universal solution for managing digital images.\n\nWhile the company promotes the update as a leap in convenience, the limitations suggest that many users will keep relying on existing tools.\n\nSome may stick with a free photo editor already familiar to them, while others will continue returning to established professional packages.\n\nFollow TechRadar on Google News and add us as a preferred source to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!\n\nAnd of course you can also follow TechRadar on TikTok for news, reviews, unboxings in video form, and get regular updates from us on WhatsApp too.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/microsofts-new-photos-app-update-is-so-good-that-it-could-well-become-my-favorite-photo-organizing-tool-but-you-will-need-a-copilot-pc-to-experience-it",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Nintendo Switch 2 supports two different types of Nvidia DLSS — A second, 'light' version for upscaling beyond 1080p, along with the standard, PC-like CNN model",
      "content": "The Nintendo Switch 2 is the only mainstream console that comes with Nvidia hardware inside, while Microsoft and Sony rely on AMD. Therefore, the Switch 2 supports Nvidia's proprietary DLSS technology that helps it upscale games to 1080p and beyond, which is crucial in a handheld with power constraints. It was long speculated that the version of DLSS present on the Switch 2 was unique and unlike the standard models available on PC, and Digital Foundry's latest testing has confirmed that.\n\nNintendo Switch 2 DLSS Image Quality Analysis: \"Tiny\" DLSS/Full-Fat DLSS Confirmed - YouTube Watch On\n\nWhile looking at a diverse selection of titles like Cyberpunk 2077, Street Fighter 6, Hogwarts Legacy, Star Wars Outlaws, The Touryst, and Fast Fusion; Digital Foundry observed that there are two different DLSS versions at work.\n\nFirst up, there's \"Fat DLSS\" that resembles the CNN-based model found on PC, and this can only upscale games to 1080p. It has a cleaner, sharper image in motion, less artifacting, better antialiasing, and smoother camera cuts. Objects move in and out of motion almost identically to how they would on PC — which is to say, gracefully.\n\nBut, as mentioned, it's limited to 1080p. To go past that resolution, Nvidia and Nintendo have developed a special \"DLSS Light\" which can upscale to greater resolutions (remember, Switch 2 is marketed for up to 4K when docked). This version looks better in stills, but looses sharpness as soon as you move because reconstruction techniques get temporarily disabled. It introduces artifacts where you can see unfiltered pixels, but at the benefit of half the frame-time cost, which allows it to scale way past just 1080p.\n\n(Image credit: Jeffrey Kampman/Tom's Hardware)\n\nThis goes to show just how demanding the original version of DLSS is; it doesn't make sense to run that on every game, especially in handheld mode. When you need to reach resolutions higher than 1080p, the light model should still be better, despite its inferior temporal performance. What remains to be seen, though, is whether the newer, more efficient Transformer-based model of DLSS can somehow make its way onto the Switch 2 in the future.\n\nDigital Foundry even reached out to an unnamed but respected developer familiar with DLSS on the Switch, who confirmed that two versions of the tech do indeed exist in the pipeline to choose from. The light version is newer, and more uniquely suited to the Switch 2's hardware capabilities. We haven't seen any first-party Nintendo game utilize DLSS so far either, so that's also something to keep an eye on, given how most Nintendo games focus on precise movement and controls.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/video-games/nintendo/nintendo-switch-2-supports-two-different-types-of-nvidia-dlss-a-second-light-version-for-upscaling-beyond-1080p-along-with-the-standard-pc-like-cnn-model",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "MSI PRO X870-P WIFI ATX AM5 Motherboard + AMD Ryzen 7 7800X3D Processor $499.99",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18662581-msi-pro-x870-p-wifi-atx-am5-motherboard-amd-ryzen-7-7800x3d-processor-499-99",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Prime Exclusive G.SKILL Trident Z5 RGB Series 64GB (2x32GB) Desktop RAM DDR5-6400 PC5-51200 For Intel CPUs + Free Shipping $119.99",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired BabyBubba posted Item 1 of 1 expired BabyBubba posted Prime Exclusive G.SKILL Trident Z5 RGB Series 64GB (2x32GB) Desktop RAM DDR5-6400 PC5-51200 For Intel CPUs + Free Shipping $119.99 $120 $250 52% off Woot! 15 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 2,137 Views Visit Woot! Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details\n\n\n\nShows to be available only to Amazon Prime members.\n\n\n\nhttps://sellout.woot.co m/offers/g...alldeals_2 Woot! has New Prime Exclusive G.SKILL Trident Z5 RGB Series 64GB (2x32GB) Desktop RAM DDR5-6400 PC5-51200 for $119.99. Shipping is free with Amazon Prime.Shows to be available only to Amazon Prime members. Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster BabyBubba Follow Give Rep Message 995 Deal Posts 3,909 Comments Posts 6,337 Reputation Points 216 Votes Submitted Deal Details Community Notes About the Poster\n\n\n\nShows to be available only to Amazon Prime members.\n\n\n\nhttps://sellout.woot.co m/offers/g...alldeals_2 Woot! has New Prime Exclusive G.SKILL Trident Z5 RGB Series 64GB (2x32GB) Desktop RAM DDR5-6400 PC5-51200 for $119.99. Shipping is free with Amazon Prime.Shows to be available only to Amazon Prime members.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18663862-prime-exclusive-g-skill-trident-z5-rgb-series-64gb-2x32gb-desktop-ram-ddr5-6400-pc5-51200-for-intel-cpus-free-shipping-119-99",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Skytech Eclipse Lite 2 Desktop: Ryzen 7 9800X3D, RTX 5080, 32GB RAM, 2TB SSD $2130.99",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18664246-skytech-eclipse-lite-2-desktop-ryzen-7-9800x3d-rtx-5080-32gb-ram-2tb-ssd-2130-99",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Matrix Core Programming on AMD GPUs",
      "content": "TL;DR In this blog post, we walk through how to use Matrix Cores in HIP kernels, with a focus on low-precision data types such as FP16, FP8, and FP4, as well as the new family of Matrix Core instructions with exponent block scaling introduced in the AMD CDNA™4 architecture. Through code examples and illustrations, we provide the necessary knowledge to start programming Matrix Cores, covering modern low-precision floating-point types, the Matrix Core compiler intrinsics, and the data layouts required by the Matrix Core instructions. The blog post is also available on ROCm Blogs.\n\n1. Matrix Cores\n\nMatrix multiplication is an essential part of AI and HPC workloads. The AMD CDNA™ architecture features special-purpose hardware, the Matrix Cores, to accelerate matrix fused-multiply-add (MFMA) operations defined as D:=A*B+C . Please note that MFMA instructions are often used to update a matrix in-place (=accumulation) so that D=C and C:=A*B+C . The matrices A and B are called input matrices, while the matrix D is referred to as the output matrix or accumulator.\n\nThe performance gains from using Matrix Cores are especially significant in mixed-precision mode, where the input matrices use lower-precision data types instead of FP32. The output matrix, however, is stored in FP32 to minimize accuracy loss during accumulation. The tables below show the theoretical peak performance of Matrix Cores with different input data types on both AMD CDNA™3 and AMD CDNA™4 architectures. On the AMD Instinct™ MI325X, using FP16 input matrices delivers nearly an 8x performance increase compared to single-precision, with only minimal accuracy loss. Switching to FP8 further doubles the performance providing a 16x increase when compared to FP32. The AMD CDNA™4 architecture further improves Matrix Core performance, delivering up to 2x higher throughput for FP16 and FP8 compared to the AMD CDNA™3 architecture. In addition, AMD CDNA™4 introduces new low-precision data types such as FP6 and FP4, enabling up to 64x performance gain relative to FP32. Please refer to the AMD CDNA™3 and AMD CDNA™4 white papers for detailed architecture specifications.\n\nType AMD Instinct™ MI325X (CDNA™3) Speedup vs. FP32 Matrix FP64 163.4 TF 1x Matrix FP32 163.4 TF 1x Matrix FP16 1307.4 TF ~8x Matrix FP8 2614.9 TF ~16x\n\nType AMD Instinct™ MI355X (CDNA™4) Speedup vs. FP32 Matrix FP64 78.6 TF ~0.5x Matrix FP32 157.3 TF 1x Matrix FP16 2.5 PF ~16x Matrix FP8 5 PF ~32x Matrix FP6 10 PF ~64x Matrix FP4 10 PF ~64x\n\n2. Low-Precision Floating-Point Types\n\nA binary representation of a floating-point number consists of n bits, where m of n bits represent the mantissa, 1 bit determines the sign and n-m-1 bits represent the exponent. The following image illustrates the binary format of a floating-point number and how the exponent and mantissa are calculated based on its binary representation.\n\nFigure 1: Binary representation of a floating-point number.\n\nFloating-point types are characterized by the number of bits used for the exponent and for the mantissa. Increasing the exponent width extends the range of representable values, while increasing the mantissa width improves precision. Since all floating-point types include the sign bit, a shorthand notation typically specifies only the exponent and mantissa widths. For example, the E4M3 type is an 8-bit floating-point type with 4-bit exponent and 3-bit mantissa. Additionally, a floating-point type is specified by exponent bias - a number that is subtracted from the exponent during conversion from binary format to real value. Given the exponent width, mantissa width, and exponent bias, one can convert the binary representation of a floating-point type (except E8M0) into its real value using the following equation:\n\nFigure 2: Conversion to real value from binary representation for floating-point numbers.\n\nPlease note that the equation takes different forms depending on whether the exponent is zero or not. Often, certain exponent and mantissa values are reserved for special values (e.g. NaN , Infinity ), which limits the range of representable real numbers. For example, the FP16 type has 5-bit exponent with a nominal range of [0, 1, ... 2^5-1] = [0, 1, ... 31] . However, the exponent value E = 31 is reserved for NaN (if the mantissa M != 0 ) and infinity (if the mantissa M = 0 ). Therefore, the largest exponent value that can represent a real number is E = 30 .\n\nThe following table summarizes low-precision types commonly used in modern AI/ML workloads:\n\nWidth Shorthand Exp. bias Range Zero NaN Infinity 16-Bit E5M10 (FP16) 15 ±65504 S 00000 0000000000 S 11111 xxxxxxxxxx S 11111 0000000000 E8M7 (BF16) 127 ±3.3895 * 10^38 S 00000000 0000000 S 11111111 xxxxxxx S 11111111 0000000 8-Bit E4M3FN (FP8, OCP) 7 ±448 S 0000 000 S 1111 111 n/a E4M3FNUZ (FP8) 8 ±240 0 0000 000 1 0000 000 n/a E5M2 (BF8, OCP) 15 ±57344 S 00000 00 S 11111 {01, 10 11} S 11111 00 E5M2FNUZ (BF8) 16 ±57344 0 00000 00 S 00000 00 n/a E8M0 127 2^(±127) n/a 11111111 n/a 6-Bit E2M3 1 ±7.5 S 00 000 n/a n/a E3M2 (BF6) 3 ±28 S 000 00 n/a n/a 4-Bit E2M1 (FP4) 1 ±6 S 00 0 n/a n/a\n\nPlease note that the E4M3 type has two variants: E4M3FN and E4M3FNUZ. Both E4M3FN and E4M3FNUZ use 4 bits for the exponent and 3 bits for the mantissa. They use different exponent biases and differ in the special values they can represent. Neither variant supports infinities, which is why their notations include FN (FiNite). However, E4M3FN supports +0 , -0 , +NaN and -Nan , while E4M3FNUZ supports only +0 and NaN , hence UZ (Unsigned Zero). The image below demonstrates how to convert a binary sequence into a real value, using E4M3FNUZ type as an example:\n\nFigure 3: E4M3FNUZ encoding details.\n\nFP8 types are divided into E4M3 and E5M2 formats. The E5M2 format is sometimes referred to as BF8, similar to BF16, where exponent width is larger compared to FP16. Similar to E4M3, E5M2 is further subdivided into two variants: E5M2 (OCP) and E5M2FNUZ. The AMD CDNA™3 architecture uses FNUZ variants for both E4M3 and E5M2, whereas the CDNA™4 architecture uses E4M3FN and E5M2 (OCP) variants. E4M3FN and E5M2 are standardized formats defined by the Open Compute Project (OCP). For detailed specifications, see the OCP Microscaling Formats (MX) Specification and the ONNX documentation. For visualization of FP8 values and their binary representations please refer to the FP8 Data table. Additionally, see the chapter “Low-precision floating-point types” in the AMD ROCm™ documentation for details on using low-precision types in HIP.\n\nThere is a special 8-bit format, E8M0, which is not used as a standard element data type but instead serves as a scale factor for microscaling types and block-scaled MFMA operations (discussed later in this article). Its value is calculated according to the equation below:\n\nFigure 4: E8M0 encoding details.\n\nThe exponent value E = 255 is reserved for NaN values, limiting the range of representable real numbers to [2^-127 ... 2^127] .\n\nSimilar to FP8, FP6 has two formats: E2M3 and E3M2. The latter, E3M2, is often referred to as BF6 due to its larger exponent width compared to E2M3.\n\n3. Matrix fused-multiply-add (MFMA) Instructions\n\nThe AMD CDNA™3 and CDNA™4 architectures support a variety of MFMA operations, which are characterized by the matrix dimensions M , N , K and the data type of input/output matrices. The following table lists all available floating-point MFMA instructions for the AMD CDNA™3 and CDNA™4 architectures. As can be seen from the table, the AMD CDNA™4 architecture extends the set of available MFMA instructions by adding new FP16/BF16 instructions with larger matrix dimensions. Furthermore, it introduces FP6/FP4 data types and provides a completely new set of FP8/FP6/FP4 instructions where the types can be independently used for the matrices A and B . Finally, the AMD CDNA™4 architecture enables MFMA with block exponent scaling.\n\nType (C,D) ← (A,B) MxNxK (CDNA™3) MxNxK (CDNA™4) Cycles Note FP64 ← FP64 16x16x4 16x16x4 64 FP32 ← FP32 32x32x2 32x32x2 64 16x16x4 16x16x4 32 FP32 ← FP16 (BF16) 32x32x8 32x32x8 32 Both A and B are either FP16 or BF16 16x16x16 16x16x16 16 - 16x16x32 16 - 32x32x16 32 FP32 ← FP8 16x16x32 16x16x32 16 FP8 (E4M3) or BF8 (E5M2) can be used independently for A and B 32x32x16 32x32x16 32 FP32 ← FP8/FP6/FP4 - 16x16x128 16 or 32 FP4, FP6 or FP8 can be used independently for A and B. Larger cycle count if either matrix A or B is FP8 - 32x32x64 32 or 64 FP32 ← MXFP8/MXFP6/MXFP4 - 16x16x128 16 or 32 FP4, FP6 or FP8 can be used independently for A and B. Larger cycle count if either matrix A or B is FP8 - 32x32x64 32 or 64\n\nPlease note that the table lists only floating-point type MFMA instructions with batch size = 1. In addition to them, the AMD CDNA™3 and CDNA™4 architectures support batched MFMA operations, where multiple output matrices are computed in parallel. These instructions are not covered in this article. See the Chapter 7 “Matrix Arithmetic Instructions” in the AMD CDNA™3 and AMD CDNA™4 ISA reference guides for the full list of available MFMA instructions.\n\nThe table above specifies cycle count for each MFMA operation. Given a known cycle count, one can estimate theoretical peak performance in TFLOP/s of corresponding MFMA operation using the formula below:\n\n2*M*N*K * num_matrix_cores * (max_engine_clock / cycle_count) / 10^6,\n\nwhere\n\nnum_matrix_cores is total number of matrix cores in a GPU (specified in white paper) max_engine_clock is max engine clock (peak) in MHz (specified in white paper) cycle_count is cycle count of corresponding MFMA instruction M, N, K are matrix dimensions\n\nUsing this formula and the MFMA instruction 32x32x8 FP16 as an example, we can estimate theoretical peak FP16 Matrix Core performance on the AMD Instinct™ MI325X:\n\n2*32*32*8 * 1216 * (2100 / 32) / 10^6 = 1307.4 TFLOP/s .\n\n4. Compiler Intrinsics\n\nTo use Matrix Core instructions in HIP kernels, LLVM provides built-in compiler intrinsic functions. The list of all available compiler intrinsics can be found in the LLVM Github repository. The syntax of the MFMA intrinsics has the following format:\n\nd_reg = __builtin_amdgcn_mfma_ODType_MxNxKInDType(a_reg, b_reg, c_reg, cbsz, abid, blgp) ,\n\nwhere\n\nMxNxK specifies the shapes of the matrices A , B , C , D , ODType is data type of the matrices C and D , InDType is data type of the input matrices A and B , a_reg is a scalar/vector containing a portion of the matrix A , b_reg is a scalar/vector containing a portion of the matrix B , c_reg is a vector containing a portion of the matrix C , d_reg is a vector containing a portion of the matrix D , cbsz , abid , blgp are broadcast flags. For the following discussion, these flags are irrelevant and are, therefore, set to 0 by default, unless specified otherwise. Please refer to the ISA reference guide for detailed information on the broadcast flags.\n\nFor example,\n\n__builtin_amdgcn_mfma_f32_16x16x16f16 performs 16x16x16 MFMA, where both input matrices A and B have type FP16 and the output matrix has type FP32 __builtin_amdgcn_mfma_f32_32x32x16_fp8_fp8 performs 32x32x16 MFMA, where both input matrices A and B have type FP8(E4M3) and the output matrix is stored in FP32 __builtin_amdgcn_mfma_f32_32x32x16_fp8_bf8 performs 32x32x16 MFMA, where the matrix A has type FP8(E4M3) and the matrix B has type BF8(E5M2) .\n\nThe MFMA instructions are wavefront-level (warp-level) instructions, where all work-items (threads) within a wavefront collectively perform a single MFMA operation and the operands A , B , C , D are distributed across work-items so that each work-item in the wavefront holds a portion of the operands. In order to use the MFMA instructions, it’s required to understand how the operands are distributed across threads within a wavefront. The ISA reference guide fully specifies the data layout for all available MFMA instructions. For illustrative purposes, the next chapter explains a subset of the MFMA instructions and the corresponding data layouts.\n\n5. Examples\n\nImportant note: In the following discussion we assume the matrices are stored in row-major order. The wavefront size on the AMD CDNA™ architecture is 64. The shapes of the matrices A , B , C , D are MxK , KxN , MxN , and MxN , respectively. The first dimension denotes the number of rows and the second dimension the number of columns in a matrix. For example, the matrix A has M rows and K columns.\n\n5.1. __builtin_amdgcn_mfma_f32_32x32x2f32\n\nIn this example we will multiply matrix A of size 32x2 with matrix B of size 2x32 using single wavefront (64 threads) and single MFMA instruction. The output matrix C has shape 32x32 . The input and output matrices are FP32. Since threads within a wavefront collectively perform single MFMA instruction, the operands are distributed across the threads. Each thread stores\n\nM * K / wavefront_size = 32 * 2 / 64 = 1 entries of the matrix A K * N / wavefront_size = 2 * 32 / 64 = 1 entries of the matrix B M * N / wavefront_size = 32 * 32 / 64 = 16 entries of the matrix C\n\nThe operands are distributed according to the scheme below. The matrix elements highlighted in light red are those stored by the thread with index 0 within the wavefront.\n\nFigure 5: Data layout for `__builtin_amdgcn_mfma_f32_32x32x2f32`. The operands are stored in row-major order.\n\nThe code example below demonstrates how this operation can be implemented as a HIP kernel:\n\n#include <hip/hip_runtime.h> using fp32x16_t = __attribute__ (( vector_size ( 16 * sizeof ( float )))) float ; __global__ void mfma_fp32_32x32x2_fp32 ( const float * A , const float * B , float * C ) { float a_reg ; float b_reg ; fp32x16_t c_reg {}; const float * ldg_a_ptr = A + threadIdx . x / 32 + 2 * ( threadIdx . x % 32 ); const float * ldg_b_ptr = B + threadIdx . x % 32 + ( threadIdx . x / 32 ) * 32 ; a_reg = * ldg_a_ptr ; b_reg = * ldg_b_ptr ; c_reg = __builtin_amdgcn_mfma_f32_32x32x2f32 ( a_reg , b_reg , c_reg , 0 , 0 , 0 ); for ( int i = 0 ; i < 4 ; i ++ ) { C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + i * 32 * 8 ] = c_reg [ i * 4 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 1 + i * 32 * 8 ] = c_reg [ i * 4 + 1 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 2 + i * 32 * 8 ] = c_reg [ i * 4 + 2 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 3 + i * 32 * 8 ] = c_reg [ i * 4 + 3 ]; } }\n\nThe GPU kernel can then be invoked on the host using a single wavefront:\n\nmfma_fp32_32x32x2_fp32 <<< 1 , 64 >>> ( A_device , B_device , C_device );\n\nPlease note that we use the vector data type fp32x16_t to store the entries of the matrix C in registers. Additionally, we zero-initialize c , since we compute C = A * B without accumulation.\n\n5.2. __builtin_amdgcn_mfma_f32_16x16x16f16\n\nThis example demonstrates how to multiply matrix A of size 16x16 with matrix B of size 16x16 using single wavefront (64 threads) and single MFMA instruction. The output matrix C has shape 16x16 . The input matrices are stored in FP16 and the output matrix stored in FP32. In this case, each thread stores 4 entries of the matrix A , 4 entries of the matrix B and 4 entries of the matrix C . The data layout for this instruction is shown below. For illustrative purposes, the elements stored by the first thread within the wavefront are highlighted in red.\n\nFigure 6: Data layout for __builtin_amdgcn_mfma_f32_16x16x16f16. The operands are stored in row-major order.\n\nCorresponding HIP kernel is implemented below:\n\n#include <hip/hip_runtime.h> #include <hip/hip_fp16.h> using fp16_t = _Float16 ; using fp16x4_t = __attribute__ (( vector_size ( 4 * sizeof ( fp16_t )))) fp16_t ; using fp32x4_t = __attribute__ (( vector_size ( 4 * sizeof ( float )))) float ; __global__ void mfma_fp32_16x16x16_fp16 ( const fp16_t * A , const fp16_t * B , float * C ) { fp16x4_t a_reg ; fp16x4_t b_reg ; fp32x4_t c_reg {}; a_reg = * reinterpret_cast < const fp16x4_t *> ( A + 4 * ( threadIdx . x / 16 ) + 16 * ( threadIdx . x % 16 )); for ( int i = 0 ; i < 4 ; i ++ ) { b_reg [ i ] = * ( B + i * 16 + threadIdx . x % 16 + ( threadIdx . x / 16 ) * 64 ); } c_reg = __builtin_amdgcn_mfma_f32_16x16x16f16 ( a_reg , b_reg , c_reg , 0 , 0 , 0 ); for ( int i = 0 ; i < 4 ; i ++ ) { * ( C + i * 16 + threadIdx . x % 16 + ( threadIdx . x / 16 ) * 64 ) = c_reg [ i ]; } }\n\nPlease note that both __half and _Float16 types can be used in device code. However, the host supports only _Float16 type for arithmetic operations. As in the previous example, we use vector data types to store the matrix elements in registers.\n\n5.3. __builtin_amdgcn_mfma_f32_32x32x16_fp8_fp8\n\nIn this example we will multiply matrix A of size 32x16 with matrix B of size 16x32 using single wavefront (64 threads) and single MFMA instruction. The output matrix C has shape 32x32 . The input matrices are stored in FP8 and the output matrix is stored in FP32. In this scenario, each thread stores 8 elements of the matrix A , 8 elements of the matrix B and 16 elements of the matrix C . The operands are distributed according to the scheme below. For illustrative purposes, the elements stored by the first thread within the wavefront are highlighted in red.\n\nFigure 7: Data layout for __builtin_amdgcn_mfma_f32_32x32x16_fp8_fp8. The operands are stored in row-major order.\n\nThe code example below implements this operation as a HIP kernel:\n\n#include <hip/hip_runtime.h> #include <hip/hip_fp8.h> using fp8_t = __hip_fp8_storage_t ; using fp8x8_t = __attribute__ (( vector_size ( 8 * sizeof ( fp8_t )))) fp8_t ; using fp32x16_t = __attribute__ (( vector_size ( 16 * sizeof ( float )))) float ; __global__ void mfma_fp32_32x32x16_fp8_fp8 ( const fp8_t * A , const fp8_t * B , float * C ) { fp8x8_t a_reg ; fp8x8_t b_reg ; fp32x16_t c_reg {}; a_reg = * reinterpret_cast < const fp8x8_t *> ( A + ( threadIdx . x / 32 ) * 8 + ( threadIdx . x % 32 ) * 16 ); for ( int i = 0 ; i < 8 ; i ++ ) { b_reg [ i ] = * ( B + i * 32 + threadIdx . x % 32 + ( threadIdx . x / 32 ) * 8 * 32 ); } c_reg = __builtin_amdgcn_mfma_f32_32x32x16_fp8_fp8 (( long ) a_reg , ( long ) b_reg , c_reg , 0 , 0 , 0 ); for ( int i = 0 ; i < 4 ; i ++ ) { C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + i * 32 * 8 ] = c_reg [ i * 4 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 1 + i * 32 * 8 ] = c_reg [ i * 4 + 1 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 2 + i * 32 * 8 ] = c_reg [ i * 4 + 2 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 3 + i * 32 * 8 ] = c_reg [ i * 4 + 3 ]; } }\n\nTo define FP8, we use __hip_fp8_storage_t type from hip_fp8.h . Note that the intrinsic function expects its first two operands to be of type long . To compile the code, the operands a and b are, therefore, converted to long .\n\n5.4. __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f8\n\nImportant note: the MFMA instruction discussed in this example is supported only on AMD CDNA™4 GPUs (gfx950). Please make sure to install AMD ROCm™ version 7.0 or later.\n\nThe AMD CDNA™4 architecture introduces a new family of MFMA instructions with block exponent scaling. The syntax of these instructions differs from the classic MFMA compiler intrinsics:\n\nd_reg = __builtin_amdgcn_mfma_scale_f32_MxNxK_f8f6f4(a_reg, b_reg, c_reg, Atype, Btype, OPSEL_A, scale_a, OPSEL_B, scale_b)\n\nMxNxK specifies shapes of the matrices A , B , C , D a_reg is a vector containing elements of the matrix A , b_reg is a vector containing elements of the matrix B , c_reg is a vector containing elements of the matrix C , d_reg is a vector containing elements of the matrix D , Atype is an integer that specifies the data type of the matrix A . The following values are possible: 0 = E4M3 (fp8), 1 = E5M2(bf8), 2 = E2M3(fp6), 3 = E3M2(bf6), 4 = E2M1(fp4) , Btype is an integer that specifies the data type of the matrix B . The following values are possible: 0 = E4M3 (fp8), 1 = E5M2(bf8), 2 = E2M3(fp6), 3 = E3M2(bf6), 4 = E2M1(fp4) , OPSEL_A , OPSEL_B are OPSEL codes. These arguments are not relevant for the discussion and therefore will be set to 0 , scale_a , scale_b are scalars / vectors containing scale factors of type E8M0 .\n\nAs an example, let’s take a closer look at the instruction __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 . The inputs to this instruction are\n\nMatrix A of size 32x64 Matrix Ax of size 32x2 Matrix B of size 64x32 Matrix Bx of size 2x32\n\nThe output matrix C has shape 32x32 . Specifically, this instruction performs the following operation using single wavefront (64 threads):\n\nFigure 8: Block-scaled matrix multiplication via __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4.\n\nDuring dot product operations, the scales Ax , Bx are applied after the normal dot product and prior to output/accumulation.\n\nIn this example, we will multiply two FP8 matrices using the __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 intrinsic function. The input matrices A , B are stored in FP8 format, while the output matrix is stored in FP32. The scale matrices Ax , Bx contain elements of type E8M0 . Each thread stores 32 entries from the matrix A , 1 entry from the matrix Ax , 32 entries from the matrix B , 1 entry from the matrix Bx and 16 entries from the matrix C . The operands are distributed according to the scheme below. Please note that this scheme is valid only if both input matrices A and B have FP8 type. For illustrative purposes, the matrix elements stored by the thread with threadIdx.x = 0 are highlighted in light red, while the elements stored by the thread with threadIdx.x = 32 within the wavefront are highlighted in light green.\n\nFigure 9: Data layout for __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 with FP8 input matrices. The operands are stored in row-major order.\n\nThe following code example shows how this operation can be implemented as a HIP kernel:\n\n#include <hip/hip_runtime.h> #include <hip/hip_ext_ocp.h> using fp8_t = __amd_fp8_storage_t ; using fp8x32_t = __attribute__ (( vector_size ( 32 * sizeof ( fp8_t )))) fp8_t ; using fp32x16_t = __attribute__ (( vector_size ( 16 * sizeof ( float )))) float ; __global__ void mfma_fp32_32x32x64_fp8_fp8 ( const fp8_t * A , const fp8_t * B , float * C ) { fp8x32_t a_reg ; fp8x32_t b_reg ; fp32x16_t c_reg {}; const fp8_t * ldg_a = A + ( threadIdx . x % 32 ) * 64 + ( threadIdx . x / 32 ) * 16 ; for ( int i = 0 ; i < 2 ; i ++ ) { for ( int j = 0 ; j < 16 ; j ++ ) { a_reg [ i * 16 + j ] = * ( ldg_a + i * 32 + j ); } } const fp8_t * ldg_b = B + threadIdx . x % 32 + 32 * 16 * ( threadIdx . x / 32 ); for ( int i = 0 ; i < 2 ; i ++ ) { for ( int j = 0 ; j < 16 ; j ++ ) { b_reg [ i * 16 + j ] = * ( ldg_b + 32 * j + i * 32 * 32 ); } } uint8_t scale_a = 127 ; uint8_t scale_b = 127 ; c_reg = __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 ( a_reg , b_reg , c_reg , 0 , 0 , 0 , scale_a , 0 , scale_b ); for ( int i = 0 ; i < 4 ; i ++ ) { C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + i * 32 * 8 ] = c_reg [ i * 4 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 1 + i * 32 * 8 ] = c_reg [ i * 4 + 1 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 2 + i * 32 * 8 ] = c_reg [ i * 4 + 2 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 3 + i * 32 * 8 ] = c_reg [ i * 4 + 3 ]; } }\n\nPlease note that in this example we use __amd_fp8_storage_t type defined in hip_ext_ocp.h to represent FP8. This library provides extensions APIs for low-precision and micro-scaling formats, and compared to hip_fp8.h , exposes a wider capability set. gfx950 provides hardware acceleration for these APIs. Most of the APIs are 1 to 1 mapping of hardware instruction. Additionally, we use uint8_t type to represent E8M0 scale factors. Since scale_a and scale_b encode exponent values, the corresponding actual scale factors are 2^(scale_a - 127) and 2^(scale_b - 127) . If scale_a = scale_b = 127 , the actual scale factors are equal to 1 and no scaling is applied.\n\n5.5. __builtin_amdgcn_mfma_scale_f32_32x32x64_f4f4\n\nIn our last example, we demonstrate how to multiply two FP4 matrices using the __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 intrinsic function. As in the previous example, each thread stores 32 entries from the matrix A , 1 entry from the matrix Ax , 32 entries from the matrix B , 1 entry from the matrix Bx and 16 entries from the matrix C . The data layout for the output matrix remains the same as in the FP8 case. However, the data layout for the input matrices is different and depicted below. For illustrative purposes, the matrix elements stored by the thread with threadIdx.x = 0 are highlighted in light red, while the elements stored by the thread with threadIdx.x = 32 within the wavefront are highlighted in light green.\n\nFigure 10: Data layout for __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 with FP4 input matrices. The operands are stored in row-major order.\n\nThe code snippet below demonstrates how to implement this operation as a HIP kernel:\n\n#include <hip/hip_runtime.h> #include <hip/hip_ext_ocp.h> using fp4x2_t = __amd_fp4x2_storage_t ; using fp4x64_t = fp4x2_t __attribute__ (( ext_vector_type ( 32 ))); using fp32x16_t = __attribute__ (( vector_size ( 16 * sizeof ( float )))) float ; __global__ void mfma_fp32_32x32x64_fp4_fp4 ( const fp4x2_t * A , const fp4x2_t * B , float * C ) { fp4x64_t a_reg {}; fp4x64_t b_reg {}; fp32x16_t c_reg {}; const fp4x2_t * ldg_a = A + ( threadIdx . x % 32 ) * 32 + ( threadIdx . x / 32 ) * 16 ; for ( int i = 0 ; i < 16 ; i ++ ) { a_reg [ i ] = * ( ldg_a + i ); } const fp4x2_t * ldg_b = B + ( threadIdx . x % 32 ) / 2 + 16 * 32 * ( threadIdx . x / 32 ); int b_extract_idx = threadIdx . x % 2 ; for ( int i = 0 ; i < 16 ; i ++ ) { uint8_t tmp0 = __amd_extract_fp4 ( * ( ldg_b + 16 * 2 * i ), b_extract_idx ); uint8_t tmp1 = __amd_extract_fp4 ( * ( ldg_b + 16 * ( 2 * i + 1 )), b_extract_idx ); b_reg [ i ] = __amd_create_fp4x2 ( tmp0 , tmp1 ); } uint8_t scale_a = 127 ; uint8_t scale_b = 127 ; c_reg = __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 ( a_reg , b_reg , c_reg , 4 , 4 , 0 , scale_a , 0 , scale_b ); for ( int i = 0 ; i < 4 ; i ++ ) { C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + i * 32 * 8 ] = c_reg [ i * 4 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 1 + i * 32 * 8 ] = c_reg [ i * 4 + 1 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 2 + i * 32 * 8 ] = c_reg [ i * 4 + 2 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 3 + i * 32 * 8 ] = c_reg [ i * 4 + 3 ]; } }\n\nSince memory addressing is not allowed at a granularity smaller than 8 bits, we use __amd_fp4x2_storage_t (an alias for uint8_t ) to store the input matrices and enable pointer operations. Note that the FP4 elements that need to be loaded from the matrix B are not contiguous in memory. To extract a single FP4 element, we use the __amd_extract_fp4 function provided in hip_ext_ocp.h . This function returns one FP4 element (of type uint8_t ) from a fp4x2 vector, based on the index passed as the second argument:\n\nuint8_t __amd_extract_fp4 ( const __amd_fp4x2_storage_t x , const size_t index ) { if ( index == 0 ) return ( x & 0xFu ); return ( x >> 4 ); }\n\nTwo FP4 values are then combined into __amd_fp4x2_storage_t using __amd_create_fp4x2 :\n\n__amd_fp4x2_storage_t __amd_create_fp4x2 ( const uint8_t x , const uint8_t y ) { __amd_fp4x2_storage_t ret = 0 ; ret = x | ( y << 4 ); return ret ; }\n\nThe compiler intrinsic function __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 requires its first two arguments to be 256 bits wide. Since 32 FP4 elements occupy only 128 bits, we define fp4x64_t , which is 256 bits wide. In this type, 128 bits contain data, while the remaining 128 bits are zero. This allows us to pass a_reg and b_reg to the intrinsic function and compile the code successfully.\n\nSummary\n\nIn this article, we introduced Matrix Core instructions available on the AMD CDNA™3 and CDNA™4 architectures. We covered floating-point formats in detail, including modern low-precision element data types such as FP8, FP6, FP4, and the scale data type E8M0. We further explained how the floating-point types are represented as binary sequences and demonstrated, with concrete examples, how to convert their binary representations into real values. Next, we listed Matrix Core instructions supported by the modern CDNA™ architectures and discussed how to calculate the theoretical peak performance of Matrix Cores for specific MFMA instructions. To make the discussion more practical, we reviewed the compiler intrinsic functions that allow users to program Matrix Cores inside HIP kernels. Finally, we examined a subset of MFMA instructions in detail, providing code examples and illustrations to explain data layout and demonstrate how to implement simple mixed-precision MFMA operations in HIP. For additional information on Matrix Cores and low-precision data types, please refer to the following resources:",
      "source": "Github.io",
      "url": "https://salykova.github.io/matrix-cores-cdna",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "PowerSpec G524 Gaming Desktop: Ryzen 5 7600X, RX 7600, 16GB DDR5 RAM, 1TB SSD $770 + Free Store Pickup",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18661171-powerspec-g524-gaming-desktop-ryzen-5-7600x-rx-7600-16gb-ddr5-ram-1tb-ssd-770-free-store-pickup",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Skytech Eclipse Lite 2 Desktop: Ryzen 7 9800X3D, RTX 5080, 32GB RAM, 2TB SSD $2181 + Free Shipping",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18661510-skytech-eclipse-lite-2-ryzen-7-9800x3d-rtx-5080-32gb-ddr5-2tb-ssd-2180-99",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Following This Diet Can Help Slow Down Vision Loss By Up To 34%, Study Shows",
      "content": "While age and genetics play a large role in your likelihood of developing AMD and the progression of the disease, so do lifestyle factors that promote inflammation and oxidative stress. The good news is that lifestyle habits that are anti-inflammatory have a protective effect.",
      "source": "mindbodygreen.com",
      "url": "https://www.mindbodygreen.com/articles/following-this-diet-can-help-slow-down-vision-loss-by-up-to-34-know-more-about-it",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Like a detective novel, reviewing the Asus ExpertBook P3 came with an unexpected twist",
      "content": "On the face of it, a great laptop, until I realised that Asus had flushed 50% of its performance away by making a poor memory choice. That point aside, this is a nice system with more ports than many laptops get these days, and an excellent Ryzen platform.\n\nWhy you can trust TechRadar We spend hours testing every product or service we review, so you can be sure you're buying the best. Find out more about how we test.\n\nAsus ExpertBook P3: 30-second review\n\nAsus has adopted the latest AMD processor technology and developed a series of powerful laptops that leverage their unique combination of power and features.\n\nThe ExpertBook P3 is aimed squarely at power-users who need a large, 16-inch display to work on substantial documents and the horsepower of a powerful Ryzen 7 AI processor for running CoPilot or other AI models.\n\nIt is one of the few business laptops of this generation that don’t assume you will also buy a docking station, as it comes with plenty of ports that include LAN and HDMI.\n\nThere are also options for up to 64GB of RAM and 3TB of SSD storage using two M.2 slots, but be careful about some memory options, as these might impact performance.\n\nWhat Asus offers here is an affordable business laptop that won’t bust budgets but provides many of the higher-end features that users will adore.\n\nThat’s especially true if they use AI models, as the CPU and NPU combine to provide decent local model processing.\n\nWith a 70Wh battery, this machine can efficiently operate at the top level throughout a working day, achieving over 18 hours in my testing.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nOverall, this is a surprisingly cheap machine considering its potential, being half the price of the top-tier AMD platforms, but offering most of the performance.\n\nWith this spec, the ExpertBook P3 might be included in our best business laptops in the near future.\n\nAsus ExpertBook P3: Price and availability\n\n(Image credit: Mark Pickavance)\n\nHow much does it cost? From $1,179.99\n\nFrom $1,179.99 When is it out? Available now\n\nAvailable now Where can you get it? Direct from Asus now, online retailers later\n\nTechnically, the Asus ExpertBook P3 (PM3606) has been available for bulk purchases directly from Asus since June 2025, but it’s soon going to be more widely available through retail outlets for those wanting to make smaller investments.\n\nIn the USA, prices start at $1,179.99 for a machine with an AMD Ryzen AI 5 330 Processor, 16GB of RAM and a 512GB SSD. For one with the review hardware spec, AMD Ryzen AI 7 350, 32GB of RAM and 1TB of storage, expect to pay $1509.99. Discounts are available for those in the military, students and teacher groups.\n\nAsus in the USA will sell individual units, but in Europe, the minimum purchase is three machines, and the price is typically quoted.\n\nWhen you compare this machine to the HP ProBook 4 G1a, a 14-inch laptop that uses the AMD Ryzen 7 250 with Radeon 780M Graphics, the Asus seems to offer more for roughly the same amount of money.\n\nBut many machine makers have chosen $ 1,500 as the price point for this platform, even though you can get the Ryzen 7 250 systems for much closer to $ 1,000.\n\nFor volume buyers, this machine will likely fall somewhere in between, depending on the amount of memory and storage requested.\n\nValue: 4 / 5\n\nAsus ExpertBook P3: Specs\n\nSwipe to scroll horizontally Category Item Processor AMD Ryzen AI 7 350 2.0GHz (16MB Cache, up to 5.0 GHz, 8 cores, 16 Threads) NPU Performance 50 TOPS (Neural Processing Unit for local AI tasks) Total TOPS 66 TOPS (NPU and CPU combined) Memory 32 GB DDR5-5600 (two slots, up to 64GB possible) Storage 1 TB M.2 2280 PCIe Gen4 NVMe SSD Storage Exp. M.2 2230 PCIe Gen 4 Graphics AMD Radeon 860M Graphics Display Non-touch screen, 16.0-inch, WUXGA (1920 x 1200) 16:10, Wide view, Anti-glare display, LED Backlit, 300nits, NTSC: 45%, Screen-to-body ratio:88 % Camera 1080p FHD camera with IR function to support Windows Hello Audio Audio by Dirac, Smart Amp Technology, Built-in speaker, Built-in array microphone Ports Right 1x USB 3.2 Gen 1 Type-A, 2x USB 3.2 Gen 2 Type-C support display/power delivery, 1x HDMI 2.1 TMDS, 1x 3.5mm Combo Audio Jack Ports Left 1x RJ45 Gigabit Ethernet, 1x USB 3.2 Gen 1 Type-A, Kensington nano security lock Wireless MediaTek Wi-Fi 7 MT7925 (2x2) and Bluetooth 5.4 wireless card Battery 70WHrs, 4S1P, 4-cell Li-ion Operating System Windows 11 Pro Security Trusted Platform Module (TPM) 2.0, Support Absolute Persistence 2.0 (Computrace), Microsoft Security Level 3, Microsoft Secured-core PC BIOS Self Recovery, BIOS Integrity Measurement Support, IR webcam with Windows Hello support, Fingerprint sensor integrated with Power Key Size 35.84 x 25.35 x 1.79 ~ 1.80 cm (14.11\" x 9.98\" x 0.70\" ~ 0.71\") Weight 1.74 kg Sustainability FSC Recycled, TCO Certified, 22% Sustainable material Warranty 1-year limited warranty Colours Misty Grey\n\nAsus ExpertBook P3: Design\n\n(Image credit: Mark Pickavance)\n\nThin form factor\n\nLots of ports\n\n16-inch display\n\nNot super-light\n\nThe Asus ExpertBook P3 (PM3606) is designed with the modern professional in mind, or anyone who wants a large screen and a reasonable amount of computing power. One of the most striking features of this laptop is its thin profile. Measuring just 1.79 to 1.80 centimetres in height, the ExpertBook P3 is incredibly slim, making it highly portable and easy to carry around. This thinness does not compromise its durability, as Asus created a robust aluminium chassis that should withstand the rigours of daily use for longer than something made entirely of plastic.\n\nThe port selection on the Asus ExpertBook P3 is great, catering to a wide range of connectivity needs. It includes two USB 3.2 Gen 1 Type-A ports and two USB 3.2 Gen 2 Type-C ports that support display and power delivery. Additionally, there is an HDMI 2.1 port, a 3.5mm combo audio jack, and an RJ45 Gigabit Ethernet port.\n\nMy only reservations here are that the best USB available is only USB 3.2 Gen 2, whereas USB4 is inherent to this processor series, and the cost saving of a gigabit Ethernet over 2.5GbE probably wasn’t worth it.\n\nOn the upside of the port arrangement, there are plenty of ports, ensuring that users can connect multiple devices simultaneously, whether for presentations, data transfer, or internet connectivity. That negates the need for a docking station, unless you want more than two screens.\n\n(Image credit: Mark Pickavance)\n\nAnother standout feature is the 16-inch display of the ExpertBook P3. It boasts a WUXGA (1920 x 1200) resolution with a 16:10 aspect ratio, providing a wide and immersive viewing experience. In the P3 range specifications, it hints that a higher resolution panel with greater than 300 nits of brightness is an option, but for most uses, this display is fine.\n\nObviously, it doesn’t offer the exacting colour representation as an OLED display, but then this machine isn’t priced to expect one of those.\n\nIn addition to its impressive hardware, the Asus ExpertBook P3 is designed with user comfort and productivity in mind. The backlit chiclet keyboard with 1.5mm key travel is spill-resistant, making it both comfortable to type on and resilient to accidental spills. There are only two things about it I’m less than enamoured with, the first of those being that the designers split the return key in half to put the hash key on the top half. Another space issue is one of those direction clusters where the up and down buttons are half the size of the left and right directions. Considering how much space the 16-inch form factor allowed for the keyboard, a better use of space should have been possible.\n\nThe laptop also features a 1080p FHD camera with IR function for Windows Hello, ensuring secure and convenient login, and the power button is also a fingerprint reader if you prefer that biometric approach. The combination of these features makes the ExpertBook P3 a versatile and reliable choice for professionals who need a powerful and portable laptop.\n\nIn conclusion, the Asus ExpertBook P3 (PM3606) is a well-designed laptop that excels in terms of thinness, port selection, and features a decent display quality. Its slim profile, comprehensive connectivity options, and high-quality display make it an excellent choice for professionals who require a reliable and portable device for their daily tasks.\n\nHowever, at 1.75kg, holding this machine by one corner does require a reasonable amount of wrist and arm strength, and therefore, it’s not ideal for use unsupported.\n\n(Image credit: Mark Pickavance)\n\nDesign: 4 / 5\n\nAsus ExpertBook P3: Hardware\n\nAMD Ryzen 300 AI series CPU\n\nRadeon 860M GPU\n\nSome upgrades\n\nIt’s interesting to compare this Ryzen AI 300 series CPU to the one that was in the HP ProBook 4 G1a, as the Ryzen 7 250 in the HP wasn’t from the Ryzen AI 300 (Krackan Point) series, but the Ryzen 200 (Hawk Point) refresh.\n\nThis architecture marks the first step that AMD has taken in the same direction as Intel, dividing cores into those that are purely for performance and others that are more focused on efficiency. To that end, the AMD Ryzen AI 7 350 has four Zen 5 performance cores and four Zen 5c efficiency cores, but both core types offer hyperthreading, allowing for a thread count of sixteen. That’s double what Intel is offering with the Core Ultra 7 258V, and it’s comparable to that in the Core Ultra 9 models.\n\nBut, my testing suggests that for multitasking, this chip is significantly better than the Core Ultra 7 258V, and AMD has the Ryzen AI 9 HX PRO 375, which is better than anything Intel has in its mobile chip space.\n\nWhere this processor also excels is AI neural processing, as it includes the AMD NPU that’s rated at 50TOPS, and another 16TOPS coming directly from the processor.\n\nThe combined 66TOPS is more than enough to run CoPilot locally and also handle some other localised AI tools. For those entirely dedicated to local AI, the Ryzen AI 9 HX PRO 375 has a 55TOPS NPU and a combined 126TOPS, but what the Ryzen AI 7 350 has is much better than some processors.\n\n(Image credit: Mark Pickavance)\n\nThe Core 7 Ultra 165U, for example, only has an NPU that’s rated at 11 TOPS, and doesn’t meet the minimum 50 TOPS combined level to run CoPilot locally.\n\nGiven how hard Intel has been pushing the AI button recently, you’d think they actually had silicon that could walk that walk.\n\nIn short, there are other chips from AMD that deliver even more AI computing power, but the Ryzen AI 7 350 is more than respectable for those who use this technology.\n\nIf a weakness exists here, it’s the GPU, which is the Radeon 860M. While this might not be Intel UHD Graphics bad, and will render raytracing tests, the recent appearance of the Radeon 8060S on the new Ryzen 9 AI chips has put something of a shadow over the 860M, 880M and even 890M GPUs.\n\nThat said, it delivers more than enough graphics power for typical office use, but it doesn’t elevate the ExpertBook P3 into the realms of a mobile workstation.\n\n(Image credit: Mark Pickavance)\n\nFor those who like to upgrade, the news is good and yet not so wonderful, depending on what sort of enhancements you wish to make.\n\nThe first thing to say about this machine is that getting inside isn’t that easy, even if you only need to remove six screws, in theory.\n\nThe underside of the P3 uses a metal cover that is held in place by a large number of clips once the screws have been removed. Getting enough of these to open sufficiently to remove the back isn’t easy, even for someone who wields a spudger semi-professionally. This exercise isn’t something you will want to do multiple times, so consider this a drive-by upgrade.\n\nOnce inside, you will discover that there are two DDR5 SODIM slots, two M.2 slots and an extra one for the WiFi. You can replace the battery if needed, and you can get a suitable replacement.\n\nThe only caveats are that the second M.2 slot is only a 2230-sized one, limiting it to an additional 1TB based on current capacities. According to Asus, the maximum memory modules that this machine will accept are 32GB, resulting in a total of 64 GB.\n\nActually, since the maximum memory addressed by the processor is 256GB, I suspect that it might accept 48GB modules and end up with 96GB, but I’ve not tested that theory. When 64GB modules become widely available, it might be possible to squeeze 128GB into here.\n\nThere is a twist with the memory that I’ll cover in the next section.\n\n(Image credit: Mark Pickavance)\n\nHardware: 4 / 5\n\nAsus ExpertBook P3: Performance\n\nSwipe to scroll horizontally Laptops Header Cell - Column 1 Asus Expertbook P3 Asus Expertbook P3 (dual memory) CPU Row 0 - Cell 1 AMD Ryzen AI 7 350 AMD Ryzen AI 7 350 Cores/Threads Row 1 - Cell 1 8C 16T 8C 16T TPD Row 2 - Cell 1 15-54W (28W) 15-54W (28W) RAM Row 3 - Cell 1 32GB DDR5-5600 (1x32GB) 32GB DDR5-5600 (2x16GB) SSD Row 4 - Cell 1 1TB Micron 2500 MTFDKBA1T0QGN 1TB Micron 2500 MTFDKBA1T0QGN Graphics Row 5 - Cell 1 AMD Radeon 860M AMD Radeon 860M NPU Row 6 - Cell 1 AMD Ryzen AI (50 TOPS) AMD Ryzen AI (50 TOPS) 3DMark WildLife 10,234 15,582 Row 8 - Cell 0 FireStrike 4061 6107 Row 9 - Cell 0 TimeSpy 1959 2882 Row 10 - Cell 0 Steel Nomad.L 1534 2262 CineBench24 Single 117 116 Row 12 - Cell 0 Multi 761 909 Row 13 - Cell 0 Ratio 6.91 7.83 GeekBench 6 Single 2879 2886 Row 15 - Cell 0 Multi 11529 13560 Row 16 - Cell 0 OpenCL 22785 24370 Row 17 - Cell 0 Vulkan 26293 33104 CrystalDIsk Read MB/s 6986 7006 Row 19 - Cell 0 Write MB/s 6104 6111 PCMark 10 Office 7459 7763 Row 21 - Cell 0 Battery 18h 31m 18h 17m Battery Whr 70 70 WEI Score 8.1 8.1\n\nUsually, I like to compare one laptop with another to show how making one choice over another has implications for performance.\n\nBizarrely, in this performance analysis, I’ve compared the Asus Expertbook P3 with itself, with one seemingly small difference that ends up having huge implications.\n\nWhen I received this laptop, I was in the middle of reviewing a machine with the PRO version of the same CPU, and therefore had benchmark data to explore that minor upgrade.\n\nBut it soon became clear that the P3 performed badly, and the difference was so much that something was clearly wrong. Days later, I eventually discovered what was holding the P3 back: the inclusion of a single DDR5 module in the review machine, and not two modules.\n\nIt’s worth noting that DDR5 was sold to the computer industry as being ideal because it has dual channels in a single module, and therefore, single memory modules were fine.\n\nAnd they are, but modern architectures like the one in this laptop can run four memory channels, two on each module, and that increases the amount of bandwidth significantly.\n\nBecause this system uses main memory not only for the CPU, but also for the GPU, the difference, as demonstrated by these results, is like night and day.\n\nWhat I did was remove the single Hynix module and replaced it with two Crucial SODIMMs of roughly the specification that I borrowed from a GMKtec mini PC. And, magically, some test results improved by 50%, disturbingly.\n\nI went back to Asus, keen to discover why a respected brand would do something like this, and their explanation revealed some bent logic that I’ve seen from other brands.\n\nIn the product specifications, there are four possible memory configurations that Asus offers, including two single configurations of 16GB and 32GB, and two dual configurations of 32GB (2x 16GB) and 64GB (2x 32GB).\n\nAccording to Asus, the single module versions are for those who want to upgrade, and they will have a slot free to put that extra module. That approach makes almost no sense. Because the Hynix module in there is an OEM part, and it’s unlikely that they will match that exact part, and without the upgrade, the machine will be massively underperforming.\n\nIf you order multiples of these machines, the best course of action would be to strip half the machines of their modules to upgrade the rest, and get matching pairs for those machines.\n\nBut the best solution is not to buy any of the single-module machines in the first place. If you want 32GB of RAM then get the dual 16GB machine, not the single 32GB one.\n\nWhen you do have dual modules, this machine performs well, which is why it got the score I gave it, and it’s also excellent on power efficiency. But beware system makers providing options that significantly degrade the performance of their hardware, which are marketed as being for your convenience.\n\n(Image credit: Mark Pickavance)\n\nPerformance: 4 / 5\n\nAsus ExpertBook P3: Final verdict\n\nOn the face of it, a great laptop, until I realised that Asus had flushed 50% of its performance away by making a silly decision on memory modules. That point aside, this is a nice system with more ports than many laptops get these days, and an excellent Ryzen platform.\n\nThere are a few areas where this machine could be improved, opening up the option for a P3 Plus model with a 2.5GbE LAN port and the USB4 ports that the processor natively supports.\n\nBut for the relatively low asking price, for the majority of office users, this machine is excellent, if you don’t make the horrible mistake of buying one with a single memory module.\n\nShould you buy a Asus ExpertBook P3?\n\nSwipe to scroll horizontally Value A powerful system for a modest price 4 / 5 Design Thin and lightweight, with plenty of ports 4 / 5 Hardware AI 300 series CPU with NPU power for local models 4 / 5 Performance Great performance, once you have two memory modules 4 / 5 Overall If you avoid the memory pitfall, this is a decent system 4 / 5\n\nBuy it if...\n\nYou are on a tight budget\n\nFor the money, this is a decent laptop with plenty of nice features and a good hardware platform. Cheaper machines than this will be rehashing old processors and memory technologies.\n\nYou like upgrades\n\nLots of bits on this machine can easily be upgraded, including the memory and storage. However, it isn't the easiest laptop to remove the underside.\n\nDon't buy it if...\n\nYou need Thunderbolt or USB4\n\nThe best USB port on this machine is only USB 3.2 Gen 2, and while it can transfer a file at 1,000MB/s, it pales in comparison to USB4 or Thunderbolt performance. If you want Thunderbolt, then you will need something better than this.\n\nYou need more than 3TB\n\nThe maximum SSD sizes on this system are one 2TB and a 1TB, though you might be able to get a 4TB module to work in the one 2280 M.2 slot. But without a heatsink, you need to make sure it doesn't overheat.\n\nIf you want more storage, find a machine with two 2280 slots, and not this one with a 2280 and a 2230.\n\nFor more professional devices, we reviewed the best laptops for work and gaming and the best laptops for working from home.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/asus-expertbook-p3-business-laptop-review",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Maingear debuts new premium desktop PCs — Apex Rush, Force models start at $6,259, with top-end model featuring hardline tubing and dual 420mm radiators",
      "content": "Popular PC vendor Maingear has today debuted a brand new line-up of extremely potent performance PCs with an eye-watering price tag to match. New this week are the Apex Force and Apex Rush models, starting at a cool $7,469/$6,259 respectively.\n\nFirst up is the new Apex Force, a full-tower chassis housed inside the Phanteks NV9 case. Maingear touts a dual-loop hardline cooling system with offset tubing, upgradable RGB, and more. Support for dual 420mm radiators with three 140mm fans keeps everything cool, which is important given the components on offer.\n\nMaingear Apex Force specs\n\nChassis: Phanteks NV9 (Full-tower)\n\nPhanteks NV9 (Full-tower) Motherboard: Top-tier Z890 and X870E motherboards from Asrock and MSI\n\nTop-tier Z890 and X870E motherboards from Asrock and MSI CPU: AMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K\n\nAMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K GPU: NVIDIA GeForce RTX 5080 and 5090 GPUs\n\nNVIDIA GeForce RTX 5080 and 5090 GPUs RAM: Up to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz)\n\nUp to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz) Storage: Up to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs\n\nUp to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs Cooling: 2x 420mm x 60mm radiators, 6x 140mm x 30mm RGB fans, Custom APEX Integrated Cooling System, Separate GPU and CPU dual loop system, Easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance\n\n2x 420mm x 60mm radiators, 6x 140mm x 30mm RGB fans, Custom APEX Integrated Cooling System, Separate GPU and CPU dual loop system, Easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance Power: Up to 1650W 80+ Titanium PSU\n\nUp to 1650W 80+ Titanium PSU Aesthetics: Acrylic and metal hard tubing with 10-degree offset to match case design, premium metal fittings in various colors, dual coolant color options, multiple translucent coolant colors available, diffused RGB trim kit, motherboard and case RGB control with separate cooling loop zones.\n\nAll of that will set you back a cool $7,469, but that's just the starting price, with upgrade options for beefier processor, GPU, RAM, and storage likely to run you more.\n\nThe new Apex Rush is cheaper (relatively speaking), starting at just $6,259. The dual-chamber mid-tower has panoramic tempered glass, and customization for water cooling with options for hard and soft tubing. Cooling is less prolific at just dual 360mm radiators with six 120mm fans. There are also screwless panels for the cooling system to make draining and filling easier.\n\n(Image credit: Maingear)\n\nMaingear Apex Rush specs\n\nChassis: Lian-Li O11 EVO RGB (Mid-tower)\n\nLian-Li O11 EVO RGB (Mid-tower) Motherboard: Top-tier Z890 and X870E motherboards from Asrock and MSI\n\nTop-tier Z890 and X870E motherboards from Asrock and MSI CPU: AMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K\n\nAMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K GPU: NVIDIA GeForce RTX 5080 and 5090 GPUs\n\nNVIDIA GeForce RTX 5080 and 5090 GPUs RAM: Up to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz)\n\nUp to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz) Storage: Up to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs\n\nUp to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs Cooling: 2x 360mm radiators, 7x 120mm RGB fans, Custom APEX Integrated Cooling System, easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance\n\n2x 360mm radiators, 7x 120mm RGB fans, Custom APEX Integrated Cooling System, easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance Power: Up to 1650W 80+ Titanium PSU\n\nUp to 1650W 80+ Titanium PSU Aesthetics: Soft vinyl or Neoprene tubing with optional braided sleeving or Acrylic and Metal hard tubing, Premium metal fittings in various colors, multiple translucent coolant color options, braided cable sleeving, motherboard and case RGB control with diffused lighting\n\nLike the rest of the lineup, the new Apex Force and Apex Rush PCs come with a one-year warranty, extendable to three years, with financing options also available. Maingear's latest PCs can be found on its website.\n\nFollow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/desktops/gaming-pcs/maingear-debuts-new-premium-desktop-pcs-apex-rush-force-models-start-at-usd6-259-with-top-of-the-line-nvidia-intel-and-amd-in-tow",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Nvidia (NVDA) Stock Trades Up, Here Is Why",
      "content": "What Happened?\n\nShares of leading designer of graphics chips Nvidia (NASDAQ:NVDA) jumped 2.3% in the afternoon session after several Wall Street firms raised their price targets on the stock and reports surfaced of a major deal involving its advanced AI systems.\n\nThe positive sentiment was fueled by a reported deal where cloud provider CoreWeave agreed to supply Meta Platforms with up to $14.2 billion in AI computing power using Nvidia's latest GB300 systems. This agreement highlighted the immense and sustained demand for AI infrastructure from major tech companies. Further boosting investor confidence, several financial firms, including KeyBanc, Barclays, and Citi, increased their price targets for Nvidia. Analysts pointed to an improving supply of key components and strong, continued spending in the AI sector as the primary reasons for their optimistic outlook, which helped push the stock to a record high.\n\nAfter the initial pop the shares cooled down to $186.21, up 2.4% from previous close.\n\nIs now the time to buy Nvidia? Access our full analysis report here, it’s free.\n\nWhat Is The Market Telling Us\n\nNvidia’s shares are quite volatile and have had 18 moves greater than 5% over the last year. In that context, today’s move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.\n\nThe previous big move we wrote about was 8 days ago when the stock gained 4.1% on the news that the company announced a partnership with OpenAI that included plans for a potential investment of up to $100 billion.\n\nThe deal aimed to supply OpenAI with advanced AI hardware for its next generation of AI models and the buildout of massive data centers. According to the announcement, the partnership involved deploying at least 10 gigawatts of Nvidia's systems for OpenAI's AI infrastructure. This news solidified Nvidia's central role in the future of artificial intelligence.\n\nNvidia is up 34.6% since the beginning of the year, and at $186.21 per share, has set a new 52-week high. Investors who bought $1,000 worth of Nvidia’s shares 5 years ago would now be looking at an investment worth $13,762.\n\nUnless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-nvda-stock-trades-why-185050056.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "$50 Battering RAM Attack Breaks Intel and AMD Cloud Security Protections",
      "content": "A group of academics from KU Leuven and the University of Birmingham has demonstrated a new vulnerability called Battering RAM to bypass the latest defenses on Intel and AMD cloud processors.\n\n\"We built a simple, $50 interposer that sits quietly in the memory path, behaving transparently during startup and passing all trust checks,\" researchers Jesse De Meulemeester, David Oswald, Ingrid Verbauwhede, and Jo Van Bulck said on a website publicizing the findings. \"Later, with just a flip of a switch, our interposer turns malicious and silently redirects protected addresses to attacker-controlled locations, allowing corruption or replay of encrypted memory.\"\n\nBattering RAM compromises Intel's Software Guard Extensions (SGX) and AMD's Secure Encrypted Virtualization with Secure Nested Paging (SEV-SNP) hardware security features, which ensure that customer data remains encrypted in memory and protected during use.\n\nIt affects all systems using DDR4 memory, specifically those relying on confidential computing workloads running in public cloud environments to secure data from the cloud service provider using hardware-level access control and memory encryption.\n\nThe attack, in a nutshell, involves leveraging a custom-built, low-cost DDR4 interposer hardware hack to stealthily redirect physical addresses and gain unauthorized access to protected memory regions. The interposer makes use of simple analog switches to actively manipulate signals between the processor and memory, and can be built for less than $50.\n\nOn Intel platforms, Battering RAM achieves arbitrary read access to victim plaintext or write plaintext into victim enclaves, whereas on AMD systems, the attack can be used to sidestep recent firmware mitigations against BadRAM, which was documented by the researchers back in December 2024, and introduce arbitrary backdoors into the virtual machine without raising any suspicion.\n\nSuccessful exploitation of the vulnerability can allow a rogue cloud infrastructure provider or insider with limited physical access to compromise remote attestation and enable the insertion of arbitrary backdoors into protected workloads.\n\nBattering RAM was reported to the vendors earlier this year, following which Intel, AMD, and Arm have responded that physical attacks are currently considered out of scope of their product's threat model. However, defending against Battering RAM would require a fundamental redesign of memory encryption itself, the researchers noted.\n\n\"Battering RAM exposes the fundamental limits of the scalable memory encryption designs currently used by Intel and AMD, which omit cryptographic freshness checks in favor of larger protected memory sizes,\" they added. \"Battering RAM [...] is capable of introducing memory aliases dynamically at runtime. As a result, Battering RAM can circumvent Intel's and AMD's boot-time alias checks.\"\n\nThe disclosure comes as AMD released mitigations for attacks dubbed Heracles and Relocate-Vote disclosed by the University of Toronto and ETH Zürich, respectively, that can leak sensitive data from cloud environments and confidential virtual machines that rely on AMD's SEV-SNP technology by means of a malicious hypervisor.\n\n\"The system lets the hypervisor move data around to manage memory efficiently,\" David Lie, director of the Schwartz Reisman Institute (SRI) at the University of Toronto, said. \"So when data is relocated, AMD's hardware decrypts it from the old location and re-encrypts it for the new location. But, what we found was that by doing this over and over again, a malicious hypervisor can learn recurring patterns from within the data, which could lead to privacy breaches.\"\n\nLast month, ETH Zürich researchers also demonstrated that a CPU optimization known as the stack engine can be abused as a side channel for attacks that lead to information leakage. A proof-of-concept (PoC) has been developed for AMD Zen 5 machines, although it's believed that all models have this \"abusable hardware feature.\"\n\nThe discovery of Battering RAM also follows a report from Vrije Universiteit Amsterdam researchers about a new, realistic attack technique referred to as L1TF Reloaded that combines L1 Terminal Fault (aka Foreshadow) and Half-Spectre gadgets (aka incomplete Spectre-like code patterns) to leak memory from virtual machines running on public cloud services.\n\n\"L1TF is a CPU vulnerability that allows an (attacker) VM to speculatively read any data residing in the (core-local) L1 data cache – including data the VM shouldn't have access to,\" VUSec researchers said. \"At a high level, L1TF Reloaded abuses this to obtain an arbitrary RAM read primitive.\"\n\nGoogle, which provided the researchers with a sole-tenant node in order to conduct the research safely without potentially affecting any other customers, awarded a $151,515 bug bounty and \"applied fixes to the affected assets.\" Amazon said the L1TF Reloaded vulnerability does not impact the guest data of AWS customers running on the AWS Nitro System or Nitro Hypervisor.\n\nSpectre, which first came to light in early 2018, continues to haunt modern CPUs, albeit in the form of different variants. As recently as two weeks ago, academics from ETH Zürich devised a new attack known as VMScape (CVE-2025-40300, CVSS score: 6.5) that breaks virtualization boundaries in AMD Zen CPUs and Intel Coffee Lake processors.\n\nDescribed as a Spectre branch target injection (Spectre-BTI) attack targeting the cloud, it exploits isolation gaps across host and guest in user and supervisor modes to leak arbitrary memory from an unmodified QEMU process. A software fix has been introduced in the Linux kernel to counter the cross-virtualization BTI (vBTI) attack primitive.\n\n\"VMScape can leak the memory of the QEMU process at the rate of 32 B/s on AMD Zen 4,\" the authors said in a study. \"We use VMScape to find the location of secret data and leak the secret data, all within 772 s, extracting the cryptographic key used for disk encryption/decryption as an example.\"",
      "source": "Internet",
      "url": "https://thehackernews.com/2025/10/50-battering-ram-attack-breaks-intel.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Programming AI Accelerators with Triton",
      "content": "Introduction Sure, computing Deep Neural Networks (DNNs) is a computationally expensive endeavour. Luckily, their computation can be parallelized on Graphics Processing Units (GPUs), which excel at performing numerous small tasks concurrently. To enable programmability of this hardware, several frameworks have been released for General Purpose (GPGPU) computing such as CUDA – but remain complex for easy adoption and implementation. This is irksome for researchers and deep learning practitioners who need to iterate through algorithms quickly to achieve optimal performance. Domain Specific Languages (DSLs) and compilers like Triton are excellent for enhancing productivity when writing GPU kernels to accelerate training and inference for AI workloads. Note that this article is covering the Triton DSL and not the Triton Inference Server.\n\nKey Takeaways Triton is a python DSL and compiler initially designed for GPU kernels but has been expanding to support other hardware, including CPUs and AI accelerators.\n\ninitially designed for GPU kernels but has been expanding to support other hardware, including CPUs and AI accelerators. Before Triton, developers primarily used high-level frameworks (like PyTorch) or low-level languages (like CUDA). Triton provides an abstraction layer that simplifies GPU programming compared to low-level languages, while offering more control than high-level frameworks.\n\nThe triton.jit decorator ( @triton.jit ) decorator defines Triton kernels.\n\n) decorator defines Triton kernels. Pointer arithmetic is used for computing memory locations, ensuring that memory accesses are fast.\n\nWhy was Triton Developed? Before Triton, developers had two main options for programming machine learning tasks on different hardware: (1) High-Level Frameworks (like PyTorch) and (2) Low-Level Languages (like CUDA or PTX). The philosophy behind Triton is to let the compiler do the work you don’t want to do, while still giving you control over critical aspects like algorithms and tuning parameters. You still define your algorithm, data types, and precision, but you don’t have to worry about complex tasks such as shared memory management, using tensor cores, and load coalescing and optimizing memory access patterns. The Triton compiler handles all of this automatically, saving the developer significant effort.\n\nThe above diagram and the table below was presented in a talk by Thomas Raoux from OpenAI at the PyTorch 2023 conference :“Triton tries to find an abstraction sweet spot between what you want to expose to users and what you want the compiler to do… Compilers are productivity tools…the goal of Triton is to have the compiler do the work you don’t want to do … but still leaves control on things like algorithms and any knob you want to use to be able to do tuning.” CUDA Triton Torch Op Algorithm User User Compiler Shared memory User Compiler Compiler Barriers User Compiler Compiler Distribution to blocks User User Compiler Grid size User User Compiler Distribution to Warps/threads User Compiler Compiler Tensor Core usage User Compiler Compiler Coalescing User Compiler Compiler Intermediate data layout User Compiler Compiler Workgroup size User User Compiler In this tutorial, we’re going to implement matrix multiplication with Triton. There are a number of other tutorials available in the official documentation including vector addition, fused softmax, low-memory dropout, layer normalization, fused attention (FlashAttention v2), invoking a custom function from an external library, group GEMM, persistent matmul, block scaled matrix multiplication.\n\nAnatomy of a Triton Kernel\n\nThe above figure was presented in the Triton 2024 conference in the Tools for Triton talk by Keren Zhou. It may also be worthwhile to familiarize yourself with the triton.language page in the Triton documentation.\n\nKernel decorator: A @triton.jit decorator defines a triton kernel.\n\nPointers: These are passed into the function and specify the memory location where the elements of value are stored.\n\nProgram IDs: tl.program_id() is used to specify the current program instance\n\nMemory Operations: tl.load and tl.store handle moving tensor values between global memory and Triton’s registers\n\nPrimer on Matrix Multiplication Matrix A with shape (M, K)\n\nMatrix B with shape (K, N)\n\nResulting matrix C has shape (M, N) When implementing matrix multiplication, we want to break it down into smaller chunks – often referred to as tiles or blocks. If we look at the code, we have a doubly nested for loop where one loop is placed inside another. We would use this structure to iterate over two-dimensional data, like a grid, matrix, or table. The outer loops parallelize the work across blocks while the inner loops accumulate the dot products for each tile. A Triton program instance is performing each iteration of the doubly-nested for-loop. for m in range ( 0 , M , BLOCK_SIZE_M ) : for n in range ( 0 , N , BLOCK_SIZE_N ) : acc = zeros ( ( BLOCK_SIZE_M , BLOCK_SIZE_N ) , dtype = float32 ) for k in range ( 0 , K , BLOCK_SIZE_K ) : a = A [ m : m + BLOCK_SIZE_M , k : k + BLOCK_SIZE_K ] b = B [ k : k + BLOCK_SIZE_K , n : n + BLOCK_SIZE_N ] acc += dot ( a , b ) C [ m : m + BLOCK_SIZE_M , n : n + BLOCK_SIZE_N ] = acc For more context on the code:\n\nThe line below extracts a horizontal tile of matrix A with dimensions BLOCK_SIZE_M by BLOCK_SIZE_K. a = A [ m : m + BLOCK_SIZE_M , k : k + BLOCK_SIZE_K ] A : The full matrix\n\nm: m+BLOCK_SIZE_M : This is the row slice. Here, we select a block of rows starting at index m and ending index m+BLOCK_SIZE_M . The outer for loop, for m in range(0,M,BLOCK_SIZE_M): , increments in m steps of BLOCK_SIZE_M, moving the starting point for each new row block. k : k+BLOCK_SIZE_K : This is the column size. Here, we are selecting a block of column that begin with index k and ends at k+BLOCK_SIZE_K. This is addressed by the inner inner for loop, for k in range(0, K, BLOCK_SIZE_K), which iterates through the columns of matrix A in blocks of BLOCK_SIZE_K. The line below extracts a vertical tile of matrix B with dimensions BLOCK_SIZE_K by BLOCK_SIZE_N. b = B [ k : k + BLOCK_SIZE_K , n : n + BLOCK_SIZE_N ] B: The second full matrix\n\nk : k+BLOCK_SIZE_K : In matrix B , this is the row slice. A block of rows is selected from matrix B starting at k and ending at k+BLOCK_SIZE_K .\n\nn : n+BLOCK_SIZE_N : This is the column size. Here, we are selecting a block of columns in matrix B that begin with index n and ends at n+BLOCK_SIZE_N. This is addressed by the inner for loop, for n in range(0, N, BLOCK_SIZE_N), which iterates through the columns of matrix B in blocks of BLOCK_SIZE_N. The core idea here is that by taking slices of our matrices, we can perform calculations – in this case the dot product – on smaller manageable chunks of data that can be loaded on to faster GPU memory leading to better GPU performance.\n\nGetting Started with Triton on DigitalOcean DigitalOcean has AI accelerators and Virtual Machines available as GPU Droplets and Droplets respectively. With respect to GPUs, we offer many solutions including NVIDIA H100 and H200 as well as AMD MI300 and MI325.Create a GPU Droplet and in the web console: git clone https : // github . com / triton - lang / triton . git cd triton pip install - r python / requirements . txt pip install - e . If LLVM isn’t installed on your system, the setup.py script will automatically fetch the official LLVM static libraries and use those for linking. To build using your own LLVM version, check the “Building with a custom LLVM” section on GitHub. After installation, you can verify everything works by running the test suite. make dev - install make test make test - nogpu\n\nConclusion In this tutorial, we covered the motivation behind and the fundamentals of Triton. Additionally, we walked you through a Triton matrix multiplication implementation and benchmarking. Be sure to check out the links scattered throughout the article and the references section for supplementary content.\n\nFinal Thoughts Triton strikes a balance by allowing its users to define and manipulate tensors in SRAM and modify them with the use of torch-like operators, making it possible to write efficient GPU code without extensive CUDA experience. There’s a lot we’re curious about. Particularly, how software and hardware co-evolves. How do open-source languages like Triton affect the CUDA moat? How does Triton compare to CuTe-DSL, Nvidia’s python DSL for kernel programming? What languages does the developer community and industry gravitate toward? And critically, how do these choices shape what gets built: do accessible abstractions democratize AI development, or do they introduce performance ceilings that matter at scale?",
      "source": "Digitalocean.com",
      "url": "https://www.digitalocean.com/community/tutorials/introduction-to-triton-programming",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "William Shatner amd Tom Bergeron Team Up for Holiday Drama Series FAMILY TREE",
      "content": "William Shatner and Tom Bergeron are joining forces for a new holiday dramedy titled Family Tree, which is currently in pre-production and gearing up to begin filming in 2026. The project is being produced by Pathway Pictures.\n\nThe series was created by Shatner and Bergeron, with both set to star and executive-produce alongside Nat Bernstein. The script comes from Katie Amanda Keane and Marla Sokoloff, with Sokoloff also stepping behind the camera to direct.\n\nFamily Tree tells the story of three estranged siblings who reunite during Christmas to sell their rundown childhood home, only to realize that restoring the house could also help mend their broken relationships. Shatner will play Frank, while Bergeron will take on the role of Jeff.\n\nSokoloff, who fans will recognize from her roles in The Practice and Fuller House, shared her excitement about the project, saying:\n\n“Family Tree is about the kind of healing that only happens when you’re stuck together with the people who know you best, and challenge you the most. It’s a story with grief, growth, and humor, wrapped in holiday warmth.\n\n“Katie Amanda Keane and I have always wanted to collaborate on a holiday movie that is rooted in family reality with a touch of holiday magic, and I think we accomplished that with this script.”\n\nShatner also spoke about the project, adding: “I am so pleased to be involved in this magical mysterious Christmas show that celebrates love!”\n\nWith a heartfelt story, a mix of comedy and drama, and Shatner and Bergeron leading the charge, Family Tree looks like it’s shaping up to be a charming addition to the holiday season lineup when it eventually arrives.\n\nSource: Deadline",
      "source": "GeekTyrant",
      "url": "https://geektyrant.com/news/william-shatner-amd-tom-bergeron-team-up-for-holiday-drama-series-family-tree",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Intel's original 64bit extensions for x86",
      "content": "Intel’s original 64bit extensions for x86\n\nIntroduction\n\nIn the late 1900s, Intel was fully invested in Itanium (IA-64) being their future 64bit architecture.\n\nAt that time (allegedly around 1997-1998), some Intel engineers – who were more cautious than their management – built a 64bit extension for their x86 processors as a backstop. It never shipped:\n\nIntel’s Pentium 4 had our own internal version of x86–64. But you could not use it: we were forced to “fuse it off”, meaning that even though the functionality was in there, it could not be exercised by a user.\n\nThis was a marketing decision by Intel — they believed, probably rightly, that bringing out a new 64-bit feature in the x86 would be perceived as betting against their own native-64-bit Itanium, and might well severely damage Itanium’s chances.\n\n– Bob Colwell\n\nAMD announced AMD64, their own 64bit extension to x86, in 1999 (and shipped it in 2003), condemning both Itanium and Intel’s own x86 extension to obscurity.\n\nIntel implemented AMD’s design in Project Yamhill and shipped its first processors with AMD64 in 2004.\n\nHow did Intel’s design look like?\n\nWhile AMD’s 64bit extension design that repurposed inc/dec instructions as the REX prefix is well-documented, there is very little known about Intel’s own 64bit extension design.\n\nHere is what can be reconstructed from Intel’s patent applications from 2000 and 2003:\n\nAn instruction having [a] format […] — where the mode field is 01B , the R/M field is 100B , the index field is 100B — has addressing mode information that is currently unsupported in the IA-32 architecture regardless of the value of the scale field.\n\nAn instruction of [that] format […] thereby includes heretofore unused bit fields (e.g., the two bits of scale field, bits of displacement, etc.), that can support an expanded logical register set for existing instructions formats and legacy operands.\n\nMaterial from the Bristol Community College also mentions this specific combination of bits:\n\nNote that this addressing mode does not allow the use of the ESP register as an index register.\n\nPresumably, Intel left this particular mode undefined to provide the ability to extend the addressing modes in a future version of the CPU.\n\nDifferences from AMD64\n\nAMD’s REX prefix introduced 1 bit R to extend the 3-bit register to 4 bits, allowing access to 16 registers.\n\nThe prefix also added 1 bit W to extend operand size, 1 bit X to extend SIB byte’s index and 1 bit B to extend SIB byte’s base.\n\nIntel’s approach would have added 2 additional bits to the existing 3-bit register encoding, and introduced a second, additional 5-bit register encoding.\n\nIt appears this encoding would have provided a future expansion possibility to 32 registers, even if the implementation may have been limited to 16 registers at first.\n\nIt is unclear what the equivalent of (or the alternative to) AMD64’s W , X and B bits would have been under Intel’s design.\n\nConclusion\n\nSadly, there is no definitive information on how close the patents were to what was shipped (fused-off) in Intel processors of that specific time period.",
      "source": "Soc.me",
      "url": "https://soc.me/interfaces/intels-original-64bit-extensions-for-x86.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "AMD Dense Geometry Format (DGF) Aims to Increase Visual Detail with Future GPUs",
      "content": "Visible Noise Nine months after Nvidia ships a feature, AMD produces a paper about their equivalent, and btw it doesn’t work with any of their existing products. Looks like 90XX is a dead end product.\n\nVisible Noise Why are people so surprised and angry at Nvidia’s success?\n\nVisible Noise They literally have no competition. Nvidia is still delivering features years ahead of AMD.\n\nHecate91 As usual Nvidia fans whine that AMD cards don't have a proprietary to Nvidia feature, then whine anyways when AMD develops something similar because they've never bought an AMD and never have any intention to do anything but mindlessly bash the brand.\n\nAnyway unless the feature does something groundbreaking then it's just another optional feature, I wouldn't expect this to make RDNA4 cards obsolete, and perhaps it could be processed at a driver level or on existing hardware.\n\nNvidia shipped Ray Tracing, it wasn't supported on GTX cards. They shipped MFG, it's not supported on cards prior to RTX50. You don't consider GeForce a dead end lineup, do you ?Because Nvidia is using their success to push their agenda of making the entire planet dependent on their dogshit AI tech that nobody neither wants nor needs.100% AI generated raster ? Miss me with that shit.The latest AMD has been on an Nvidia feature is Ray Reconstruction/Redstone and they barely have a full year of latency on this.Also, I'd like to point out that if you read the article a little bit closer, AMD's tech seems to be better since hitting broader, not just RT perf.And since if could run on raster, it would be hardware agnostic instead of vendor locked.I noticed that so far, when AMD follows, they might be later on delivery, but they follow with better.I'm curious about that \"potential performance hit\" mentioned on the article, how much of a hit are we talking about ? How much variance in outcome can we expect ? How is it behaving at different resolutions and different tiers of details complexity ? Is it hardware agnostic ? How would it run on other brands of cards ?I gotta say, I'm looking forward to this, even if if looks to be hardware dependent to get the intended performance, it kinda sounds like a new \"FSR moment\" to me when they make something that just works for everyone and improves X or Y factor.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341494/amd-dense-geometry-format-dgf-aims-to-increase-visual-detail-with-future-gpus",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Nvidia Stock Edges Up. Can It Keep Its Lead Over AMD?",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/3117c25ef592c136",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "China's 96-core x86 CPU taps chiplet design to rival AMD EPYC and Intel Xeon — 13 chiplets per processor provide up to 384 cores on a single motherboard, but no word on power consumption",
      "content": "Zhaoxin may not produce the best CPUs for gaming, but the leading Chinese fabless semiconductor enterprise is undoubtedly preparing to unleash a highly impressive server chip. Zhaoxin has unveiled its next-generation Kaisheng KH-50000 processors, which the company describes in its press release as \"presenting a 'technological gift' on the eve of the 76th anniversary of the founding of the People's Republic of China.\"\n\nThe KH-50000 utilizes Zhaoxin's latest Century Avenue architecture, named after a famous road in Shanghai. The company is fond of naming its architectures after famous locations within Shanghai because, after all, Zhaoxin is a joint venture between VIA Technologies and the Shanghai government. Century Avenue is the current architecture used by the company for its mainstream KaiXian KX-7000 processors; consequently, it is logical for Zhaoxin to align its latest server processors accordingly. Although Century Avenue is an internally developed architecture by Zhaoxin, many speculate that Century Avenue derives from Centaur Technology's CNS core, prior to the company's split from VIA Technologies in 2021.\n\nZhaoxin utilizes a chiplet design for the KH-50000, similar to AMD's Ryzen and EPYC processors, with a greater emphasis on the latter, given the high number of cores. A chiplet design would enable Zhaoxin to push the core boundary on the KH-50000, effectively matching AMD's EPYC 9004 (codenamed Genoa) series that tops out at 96 cores. Zhaoxin has planned two variants of the KH-50000: the flagship 96-core SKU and a more affordable 72-core SKU, both of which lack simultaneous multithreading (SMT). The KH-50000 represents a monumental leap forward for Zhaoxin, as it provides 3X more cores than the company's existing KH-40000.\n\nZhaoxin's photograph of the KH-50000 reveals that the chipset layout exhibits minor differences from that of AMD; the core design remains consistent, however. The gargantuan I/O die is centrally positioned on the processor, encircled by four clusters of compute dies. Each cluster contains three compute dies, totaling twelve. Each die incorporates eight cores and 32MB of L3 cache. When assembled, the resulting processor comprises a 96-core configuration with 384MB of L3 cache.\n\nZhaoxin Kaisheng KH-50000 Specifications\n\nSwipe to scroll horizontally Processor Architecture Cores / Threads Base / Boost Clock (GHz) L3 Cache (MB) Memory Support PCIe Lanes SATA 3.2 Ports USB Ports Socket Package Size (mm) KH-50000 Century Avenue 96 / 96 2.2 / 3.0 384 12 Channel DDR5-5200 128 PCIe 5.0 + 16 PCIe 4.0 12 4 x USB 3.2 Gen 2 LGA 72 x 76 KH-50000 Century Avenue 72 / 72 2.6 / 3.0 384 12 Channel DDR5-5200 128 PCIe 5.0 + 16 PCIe 4.0 12 4 x USB 3.2 Gen 2 LGA 72 x 76 KH-40000/32 Yongfeng 32 / 32 2.5 / N/A 64 8 Channel DDR4-3200 128 PCIe 3.0 16 8 x USB 3.2 Gen 1 LGA 77.5 x 56.5\n\nThe clock speeds on the KH-50000 aren't too shabby and fall in line with what you'd expect from a server chip. The 96-core variant has a 2.2 GHz base clock and 3.0 GHz boost clock. Since the 72-core chip has fewer cores, Zhaoxin could push the base clock to 2.6 GHz but maintained the same boost clock.\n\nAlthough the company has taken the wraps off the KH-50000, it didn't reveal the TDP or other power metrics for the upcoming server chip. The thing with a chiplet design is that Zhaoxin can effectively utilize older process nodes for the KH-50000. Sanctions don't hurt as much if you don't care about power consumption.\n\nFor comparison, AMD has historically kept its top EPYC chips around the 300-350W range, and that's with SMT. Nonetheless, the chipmaker has recently pushed the power envelope up to 500W, which is understandable when its EPYC processors are maxing out at 192 cores.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nIn addition to core count, the KH-50000 advances the development of Chinese server processors. It now supports up to 12 channels of DDR5-5200 RAM, allowing for a maximum of 3TB of memory, in contrast to the 2TB supported by DDR4-3200 on the KH-40000. Zhaoxin has added Compute Express Link (CXL) interconnect support. Furthermore, the expansion capabilities of the KH-50000 have enjoyed an upgrade to include 128 PCIe 5.0 lanes and 16 PCIe 4.0 lanes, compared to the 128 PCIe 3.0 lanes available on the KH-40000.\n\nThe SATA and USB ports experienced a slight decrease in numbers when comparing the KH-50000 to the KH-40000. However, Zhaoxin has upgraded the latter to support the latest USB 3.2 Gen 2 specification.\n\n(Image credit: Zhaoxin)\n\nThe KH-50000 supports x86 32-bit and 64-bit instructions, including SSE4.2, AVX, and AVX2. Support for virtualization is also present. To adhere to China's security guidelines, the KH-5000 supports the country's proprietary SM2, SM3, and SM4 encryption standards. Notably, Zhaoxin has integrated National Technology's fourth-generation trusted computing chip (likely the NS350) beneath the KH-50000, where the contacts are situated. This chip meets the security requirements of China's GM/T 0012-2020 cryptographic module standard and complies with the international TPM 2.0 (SPEC 1.59) standard.\n\nThe footprint of the KH-50000 measures 72 x 76 mm, which is considerably larger than that of the KH-40000. Notably, it shares dimensions with AMD's Genoa and Bergamo processors, which measure 72 x 75.4 mm and are compatible with the socket SP5. Therefore, the size of the KH-50000 is precisely the same as that of AMD's more recent EPYC chips.\n\nThe KH-50000 slots into a socket with a Land Grid Array (LGA) design, meaning the pins are located on the motherboard rather than on the processor. Zhaoxin's latest server chips are scalable, similar to AMD's EPYC and Intel's Xeon chips. The KH-50000 embraces 2S and 4S systems, where you can accumulate up to 384 cores on the latter. Zhaoxin built its own ZPI (Zhaoxin Processor Interconnect) 5.0 for inter-chip communication.\n\nContrary to AI GPUs, companies in China can still acquire server chips without significant difficulty, albeit potentially at increased costs. Nonetheless, Zhaoxin continues to make considerable progress in the domestic market, and with Chinese authorities firmly committed to utilizing domestically produced technology, the company could achieve success even if the KH-50000 does not rival AMD or Intel's latest server chips.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/chinas-96-core-cpu-taps-chiplet-design-to-rival-amds-epyc-up-to-384-cores-on-a-single-motherboard-but-no-word-yet-on-tdp",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Trump Has Created an ‘Unusual Bull Case’ for Intel Stock. Should You Buy INTC Now?",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/35138552/trump-has-created-an-unusual-bull-case-for-intel-stock-should-you-buy-intc-now",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Intel Linux Setbacks, Linux Kernel Drama & Other Q3 Highlights",
      "content": "So far on this last day of Q3'2025 we are at just over 800 original Linux news articles for the quarter on Linux hardware and open-source software. Here is a look back at what proved to be most popular for the quarter.There was a lot of interesting developments for the Linux kernel this quarter both of technical merit as well as Linux kernel mailing list (LKML) drama. The ongoing Intel layoffs/restructurings have also led to a number of unfortunate setbacks in their Linux/open-source support. Plus a wide array of other interesting Linux/FLOSS developments.Before getting to the Q3'2025 news highlight list (see yesterday's Q3 review / featured article highlights as well)... As one last reminder, if you enjoy all of the daily original content on Phoronix over the past 21 years, today is the last day of the Phoronix.com autumn deal to help with the site by enjoying a discounted rate on Phoronix Premium . Thank you for your support consideration amid these ongoing difficult times for the web/ad industry and rampant ad-block usage and other issues continuing to hamper operations.With that said, here's a look at the most popular Q3'2025 news on Phoronix:Linus Torvalds has grown frustrated enough with seeing \"Link: \" tags within Git commits/patches that often times they are of no value and he's had enough of it. For Linux kernel activity moving forward he's going to be more strict over \"useless\" link tags in Git commit messages.The most depressing news of the week: Intel is ending their performance-optimized Clear Linux distribution. Over the past decade the Clear Linux operating system has shown what's possible with out-of-the-box performance on x86_64 hardware... Not just for Intel platforms but even showing extremely great performance results on AMD x86_64 too. But with the cost-cutting going on at Intel, Clear Linux is now being sunset.Linus Torvalds has used his authority to reject the RISC-V architecture changes for the Linux 6.17 kernel. The RISC-V updates won't land this cycle and will need to try again for v6.18 later in the year. Linus refers to at least some of the proposed RISC-V code as garbage along with being submitted rather late during the merge window.XTX Markets as one of the largest algorithmic trading firms that handles $250 billion in daily traded volume and relies on around 650+ petabytes of storage for its price forecasts and other algorithmic trading data has open-sourced its Linux file-system. XTX developed TernFS for distributed storage after they outgrew their original NFS usage and other file-system alternatives.Amid the ongoing discussion over what will happen too Bcachefs in the mainline Linux kernel, an interesting anecdote around Btrfs was mentioned.Code was open-sourced this week and posted to the Linux kernel mailing list as a \"request for comments\" (RFC) for a multi-kernel architecture. This proposal could allow for multiple independent kernel instances to co-exist on a single physical machine. Each kernel could run on dedicated CPU Cores while sharing underlying hardware resources. This could also allow for some complex use-cases such as real-time (RT) kernels running on select CPU cores.Linus Torvalds has finally come to a decision following his plans to part ways with the Bcachefs file-system and then not merging any Bcachefs updates for Linux 6.17.The newest hardware offering from Raspberry Pi announced today is... a 1TB SSD.Developers behind the Git distributed revision control system are debating whether to make Rust programming language support mandatory.Well, it's an unpleasant afternoon in Linux land with more signs of the ongoing impact from Intel's corporate-wide restructuring. Just after writing about Intel's CPU temperature monitoring driver now left unmaintained/orphaned, more patches hit the public Linux kernel mailing list to mark additional Intel drivers as orphaned and removing maintainer entries for Linux developers no longer at Intel.Ubuntu 25.10's transition to using Rust Coreutils in place of GNU Coreutils has uncovered a few performance issues so far with the Rust version being slower than the C-based GNU Coreutils. Fortunately there still are a few weeks to go until Ubuntu 25.10 releases as stable and upstream developers are working to address these performance gaps.KDE Plasma 6.5 is introducing a change that has been \"years in the wanting\" and that is rounded bottom corners for windows.The Debian release team today shared their final release plans for Debian 13 \"Trixie\" that aims to be out as stable in less than one month's time.The upcoming FFmpeg 8.0 multimedia library release continues to get more exciting almost by the day. The newest feature being squeezed into this next release is a Whisper audio filter for making use of OpenAI's Whisper model for providing automatic speech recognition / transcription capabilities.Several years ago Google engineers began exploring address space isolation for the Linux kernel and ultimately proposing Linux ASI for better dealing with CPU speculative execution attacks. While the hope was it would better cope with the ever growing list of CPU speculative execution vulnerabilities, the effort was thwarted initially by I/O throughput seeing a 70% performance hit. That level of performance cost was unsustainable. But now that I/O overhead has been reduced to just 13%.Amid Intel's ongoing financial difficulties and multiple rounds of layoffs some Linux engineers at Intel left last year and there's been at least one prominent departure this week amid the latest round of challenges at the company.There is yet more apparent fallout from Intel's recent layoffs/restructurings as it impacts the Linux kernel... The coretemp driver that provides CPU core temperature monitoring support for all Intel processors going back many years is now set to an orphaned state with the former driver maintainer no longer at Intel and no one immediately available to serve as its new maintainer.Josef Bacik who is a long-time Btrfs developer and active co-maintainer alongside David Sterba is leaving Meta. Additionally, he's also stepping back from Linux kernel development as his primary job.Just over one year after the Amarok 3.0 release after a six year hiatus that brought it to Qt5 and KDE Frameworks 5, Amarok 3.3 is out today as the first version taking it to Qt6 and KDE Frameworks 6.The latest round of cost-cutting at Intel seems to be having a larger impact on their software engineering efforts than some of their previous rounds of layoffs. In addition to a prominent Linux kernel developer veteran leaving Intel last week where he worked for the past 14 years and responsible for many great upstream improvements, other Intel software engineers working on their Linux/open-source affairs have also been departing. In just the latest instance, one of the upstream Intel Linux kernel drivers is now \"orphaned\" due to the developer departing and no one experienced left to maintain the code.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Q3-2025-Linux-News",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "We tested Hisense's latest flagship QLED TV, and it offers unrivaled brightness at a pretty unbeatable value",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nHisense continues to step up its game with the release of the U8QG, its latest flagship QLED 4K TV. The display boasts one of the brightest pictures on the market while costing less than dimmer models from brands like Samsung and Sony.\n\nBut Hisense didn't stop at just making a bright TV. The U8QG also boasts excellent backlight control, which produces impressive black levels for a TV of this type, along with sparkling specular highlights.\n\nIts color performance is better than last year's U8N, too, but there are some inaccuracies here and there. And though the TV's gaming capabilities are stacked with features like a 165Hz refresh rate, it's a bit disappointing that there are only three HDMI ports. Likewise, the U8QG has some tough competition from the TCL QM8K, which offers similar performance.\n\nChoosing between the Hisense U8QG and the TCL QM8K is challenging, as both have their strengths and weaknesses. However, the Hisense U8QG is often on sale for less, and the incredible brightness it achieves is hard to ignore. This is easily one of the best-performing QLED 4K TVs of the year.\n\nHisense 65-inch U8QG QLED 4K TV The Hisense U8QG impresses with one of the brightest pictures on the market, and pairs that searing luminance with excellent contrast for a dynamic, punchy picture. Check price at Amazon Check price at Walmart Check price at Best Buy What we like Check mark icon A check mark. It indicates a confirmation of your intended interaction. Blazingly bright\n\nCheck mark icon A check mark. It indicates a confirmation of your intended interaction. Excellent contrast for a QLED\n\nCheck mark icon A check mark. It indicates a confirmation of your intended interaction. Includes great gaming features What we don’t like con icon Two crossed lines that form an 'X'. Some color inaccuracies in reds\n\ncon icon Two crossed lines that form an 'X'. Only three HDMI ports\n\ncon icon Two crossed lines that form an 'X'. USB-C DisplayPort doesn’t support HDR or VRR Specifics Resolution: 4K Ultra HD (3840 x 2160)\n\n4K Ultra HD (3840 x 2160) Panel type: QLED, 165Hz with PC\n\nQLED, 165Hz with PC Backlight: Mini LED with local dimming\n\nMini LED with local dimming HDR formats: HDR10, HDR10+, Dolby Vision, HLG\n\nHDR10, HDR10+, Dolby Vision, HLG Smart TV OS: Google TV\n\nGoogle TV HDMI ports: Three HDMI 2.1\n\nThe U8QG has a solid design, but its connection options are a mixed bag\n\nThe U8QG comes with a sturdy pedestal stand. John Higgins/Business Insider\n\nThe Hisense U8QG is available in five sizes: 55, 65, 75, 85, and 100 inches. Hisense provided a 65-inch model for this review. According to reports, the 65- and 85-inch models use a VA panel, while the other three sizes use an ADS Pro panel. VA panels tend to have better contrast, while ADS panels have better viewing angles. This means that the 55-, 75-, and 100-inch models likely offer worse black-level performance than the 65- and 85-inch editions. All sizes have a native 165Hz panel and use the new Hisense Hi-View AI Engine Pro processor.\n\nThe TV comes with a pedestal stand featuring a metal base (the 100-inch size includes left and right feet instead). It supports the TV well and can be attached in two positions, with the higher one offering a little over three inches of clearance to place a soundbar in front. A back panel on the stand covers a cable management channel to keep cords nice and tidy.\n\nIn comparison to other TVs released this year, the U8QG looks rather chunky. The panel measures 1.75 inches thick, and while that is technically less than the thickest point of its predecessor, the previous model got thinner in certain areas. There isn't a central electronics housing that protrudes, so the U8QG's thickness is uniform.\n\nThis chunkier build does allow room for an integrated 4.1.2 sound system, featuring side-firing and up-firing speakers. Although beefier than most tiny TV speakers, the sound still lacks oomph (particularly in the bass), and dialogue clarity suffers as the volume increases. I still recommend pairing the TV with a soundbar for an improved sonic experience.\n\nThe TV has three HDMI ports, instead of the typical four found on most displays in this class. John Higgins/Business Insider\n\nAlso housed on the side of the panel is a USB-C DisplayPort input, a unique inclusion not commonly found on many TVs. This connection is designed for PCs and, at first glance, appears to be geared toward gamers. However, this input doesn't support HDR or VRR (variable refresh rate). I also don't love its position, since a connected cable will be visible protruding from the side of the TV. Not a slick look. For a cleaner appearance and expanded gaming capabilities, the TV's three HDMI 2.1 inputs, located on the back of the panel, remain your best option.\n\nYou'll notice I said three HDMI ports instead of the four found on most TVs in this class. Unfortunately, it seems that including the USB-C input resulted in the removal of one of the HDMI ports. While having three HDMI 2.1 ports with 165Hz VRR is nice, it still limits the maximum number of sources that can be connected to the U8QG.\n\nIf you're using a soundbar connected to the eARC port and have three other sources to connect — perhaps an Xbox, PlayStation, and Apple TV — then you'll have to choose your favorites or play musical inputs when you want to use whichever source is left out. Admittedly, this won't affect the majority of people, but for those it will, it's important to note.\n\nThe remote is the same one Hisense introduced last year. It has a long, silver metallic design with backlit keys. It includes direct buttons for input selection and settings, a feature not offered by every manufacturer, and fits relatively well in the hand (those with smaller hands will need to slide it around in their palm to easily reach all the buttons).\n\nThe U8QG is incredibly bright, but it has some color issues\n\nThe U8QG's QLED panel and Mini LED backlight enable high brightness, creating a vibrant and bold image. John Higgins/Business Insider\n\nHisense is known for underselling its TVs' brightness performance. For years, it's basically been a guarantee that its TVs would measure at least a few hundred nits higher than advertised. But with such a strong push across the industry to increase brightness, I wondered how long its TVs would be able to keep overperforming on their promises. Well, they haven't stopped yet.\n\nAccording to its specifications, the U8QG has a brightness of up to 5,000 nits across all sizes, except for the 55-inch model, which tops out at 3,000 nits. In my measurements — using a Portrait Displays C6 HDR5000, Murideo Seven-G 8K pattern generator, and Calman calibration software — the TV blasted past that number. In HDR Filmmaker mode, it achieved 5,759 nits from a 5% window. Even a 10% window was impressively bright, with a reading of 4,094 nits.\n\nThose are the brightest measurements I've seen on those windows from any TV this year. In comparison, the TCL QM8K, another exceptionally bright TV, came in at 4,999 nits from a 5% window and 3,648 nits from a 10% window. With the default Filmmaker setting in SDR (which has brightness at 45), the U8QG measured 1,512 nits on a 10% window. Increasing the brightness to 100 results in a measurement of 3,297 nits.\n\nWith such a bright image, ambient light is of no consequence. Even if you have large windows in your living room, as I do, the image easily holds up to the sunlight. To a certain extent, the TV is even able to handle reflective light from lamps, as I found it to be less distracting on the U8QG than on other TVs with glossy panels.\n\nThe TV's luminance can be a bit overwhelming in certain settings, but you can adjust it to your preference. John Higgins/Business Insider\n\nThe question is, how much brightness do you actually need? It's true that there are some HDR movies on 4K Blu-ray and streaming that are mastered for 4,000 nits or more — \"The Meg\" and \"Alpha\" are two that us reviewers have been using for a few years to check high-brightness performance. For those kinds of movies, the U8QG's brightness is a boon.\n\nIn \"Alpha,\" one of the final scenes includes a vista with a blazing sun. On lesser TVs, the sun lacks definition, and its yellow blends into the oranges of the evening sky. But on the Hisense U8QG, you can clearly see the circular shape of the sun as it illuminates the sky with rich yellows and oranges.\n\nIn a dark room, however, those bright moments can feel a bit oppressive, and some might prefer to dial down the TV's luminance. Thankfully, the Hisense U8QG affords you the possibility. Although the TV can surpass 5,000 nits, you can also adjust settings to reduce the brightness to a level that's comfortable for you. If you find the luminance too much, I suggest changing the TV's Peak Brightness mode to medium or low.\n\nIn addition to the high brightness, the U8QG has excellent black levels when its local dimming mode is set to high. Blooming (halos around bright objects) is well controlled by the dimming zones, which keep dark sections of the screen inky black while coming close to rivaling the performance of an OLED. The U8QG's blooming performance doesn't quite match that of the TCL QM8K, particularly when viewing subtitles or credits on a dark screen, but in other situations, the difference is negligible.\n\nThat said, the TV does have a tendency to crush black levels in some scenes. \"Blade Runner 2049\" frequently utilizes shadow detail to establish its tone. The walls and corners of Sapper Morton's small home are enshrouded in shadow, but they should still have some definition — the wall by the piano and the corner of the kitchen counter, in particular. On the U8QG, the home appears appropriately dark, but there's some detail missing in the shadows.\n\nA dedicated gaming bar is available for quick adjustments, and the TV features a high 165Hz refresh rate for PCs. John Higgins/Business Insider\n\nThe U8QG's color performance is vibrant with decent accuracy, and the QLED panel covers nearly all of the P3 color gamut. However, there are some issues with oversaturation, particularly in reds. The explosions in \"Mad Max: Fury Road\" appear spectacularly bright and vibrant, but the reds are a bit too intense, causing them to look slightly artificial. The yellow and orange tones of the desert scenes are less affected by the oversaturated reds, and skin tones appear natural without the sunburned look that oversaturation can sometimes cause. But as the TV's grayscale gets closer to white, it leans toward a red tint.\n\nThe U8QG offers a range of gaming features, including AMD FreeSync Premium Pro VRR with a refresh rate of up to 165Hz for PCs and 120Hz for consoles, low input lag, Dolby Vision gaming support, and good motion handling. I noticed some minor smearing while using VRR, but it was nothing excessive that distracted me. My time gaming on the U8QG was enjoyable.\n\nQLED TVs, such as the U8QG, often struggle with viewing angles, particularly those with VA panels, like my review sample. The U8QG does indeed start to lose color vibrancy and veer toward a slightly washed-out appearance when viewed at an angle of approximately 30 degrees. That's similar to the performance I saw on the TCL QM8K. A family sitting on the couch for a movie night won't notice much of a difference, but if a large group is over watching the game, those on the sides will see the loss in quality.\n\nIt's also important to reiterate that my experience with the 65-inch model may not be representative of other sizes, as the U8 series uses different panel types for certain sizes. Sizes with an ADS panel will likely perform better off-angle at the expense of overall contrast.\n\nGoogle TV OS continues to be a great interface\n\nThe Google TV OS is one of our favorites, thanks to its straightforward layout and seamless integration with Google accounts. John Higgins/Business Insider\n\nThe U8QG utilizes the Google TV OS, which works great, offering smooth operation and easy integration with an existing Google account. There are, of course, ads within the Google interface, but they're not too obtrusive, and navigation is fast.\n\nThe Google Store offers thousands of apps for download, including ones you'd expect, such as HBO Max, Disney Plus, and Prime Video, as well as more niche options that aren't available on all built-in streaming OS platforms. F1 fans will be able to follow the season with F1 TV, and comedy fans can revel in the world of Dropout.\n\nGoogle Assistant voice control is supported with the included remote or through hands-free commands via the TV's built-in microphones. Later this year, the U8QG is also set to receive an update to enable support for Gemini, Google's AI chatbot. Compared to Google Assistant, Gemini offers more conversational search functions and provides more extensive information across a wider range of topics.\n\nShould you buy the Hisense U8QG?\n\nThe Hisense U8QG has a few drawbacks, but it's a great fit for buyers who crave a high-brightness TV. John Higgins/Business Insider\n\nThe Hisense U8QG is as good or better than its predecessor, the U8N, in every way. It's brighter, has better HDR color accuracy, excellent contrast — especially for a Mini LED display — and has strong gaming support. Its impressive performance for the price puts it in the mix as one of the top 4K QLED TVs of the year.\n\nBut not everything about the U8QG is perfect. There are some issues with oversaturated color that can make things look off, and the grayscale tracks a bit warm. The decision to replace one of the HDMI inputs with a USB-C DisplayPort is only beneficial to a select few, and the input's placement on the edge of the TV's frame detracts from a sleek, clean installation.\n\nThe U8QG's main competitor is the TCL QM8K, another fantastic, and (not quite as) bright flagship QLED 4K TV. The QM8K has slightly better color and grayscale accuracy, and thanks to TCL's Halo Control System, it's even better at reducing blooming than the Hisense. The QM8K also has four HDMI inputs, but only two of them are version 2.1. You can learn more in our TCL QM8K QLED 4K TV review.\n\nHowever, the Hisense is often discounted for less than the QM8K, and it's available in an additional 55-inch size. If prices were all equal, I'd lean toward the TCL, but if you want to save a bit of money, the Hisense U8QG offers a slightly brighter picture while still maintaining a colorful and punchy image.\n\nFor more display recommendations, be sure to check out our complete guide to the best TVs.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/guides/tech/hisense-u8qg-4k-tv-review",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Can't upgrade your Windows 10 PC? You have 2 weeks to act - and 5 options",
      "content": "DimaSobko/iStock/Getty Images Plus\n\nFollow ZDNET: Add us as a preferred source on Google.\n\nZDNET's key takeaways\n\nWindows 10 support ends on Oct. 14, 2025.\n\nYou have free and paid options for extended updates.\n\nDoing nothing is not a safe option.\n\nHave you decided what to do with your old Windows 10 PCs when they reach their official end-of-support date in two weeks?\n\nThe official deadline is October 14, 2025. Microsoft is not going to back down at the last minute and offer an extension. The hardware requirements aren't going to change, either. So, if you have a laptop or desktop PC that doesn't pass the compatibility checks, Microsoft will block you from upgrading through Windows Update, and they will encourage you to buy a new PC instead.\n\nBut you have other alternatives, including some new ways to continue getting security updates for an extra year at no cost. Don't procrastinate, though -- if you're responsible for one or more Windows 10 PCs that fail Microsoft's Windows 11 compatibility tests, you need to choose one of these five options soon.\n\nAlso: How to get free Windows 10 security updates through Oct. 2026\n\nEven if you and your business aren't affected by this deadline, it's likely that you have friends and family members who own older PCs that are still perfectly functional but can't be upgraded to Windows 11. They've probably been ignoring warning messages for a few months now, but those messages are going to get more insistent as the deadline approaches. You can help them out by sending them a link to this article.\n\n1. Sign up for extended security updates\n\nMicrosoft will continue developing security updates for Windows 10, but they won't be free for everyone. Extended Security Updates (ESUs) for Windows 10 will be available on a subscription basis for up to three years.\n\nAlso: Consumer Reports calls Microsoft 'hypocritical' for stranding millions of Windows 10 PCs\n\nHow much are these paid-for updates going to cost? That depends.\n\nConsumers have the option to receive security updates for one additional year after the end-of-support date, with the deadline pushing out to October 2026. The list price for that subscription is $30 a year, but you can cut the cost to zero by using Microsoft Rewards points earned by using the Bing search engine or the Windows Backup tool. (For details, see How to get Windows 10 extended security updates for free.) That's the obvious choice if you simply want to postpone the decision. Just be aware that the consumer ESU subscription is only good for one year. At the end of that year, you'll have an unsupported PC once again, so make sure you use that time to figure out your exit strategy for October 2026.\n\nAlso: I replaced my Microsoft account password with a passkey - and you should, too\n\nIf you're an administrator at an educational institution with a deployment of Windows 10 Education edition, you're in luck. You can purchase extended updates for up to three years, and the cost will bea mere pittance: $1 per machine for the first year, $2 for the second year, and $4 for the third and final year, taking you all the way to October 2028.\n\nIT pros who manage a fleet of business PCs aren't so lucky and will need to pay dearly to stick with Windows 10. A license for the Extended Security Updates program is sold as a per-device subscription. For the first year, the cost is $61 per PC. For year two, the price doubles, and it doubles again for year three. Do the math, and the cost is staggering: a three-year ESU subscription will cost $61 + $122 + $244, for a total of $427.\n\n2. Buy a new PC (or rent a virtual PC)\n\nMicrosoft and its partners would like you to replace that unsupported hardware with a new PC. You might even be tempted by one of the shiny new Copilot+ PCs, with their dedicated neural processing units, or maybe a powerful gaming PC. But throwing away a perfectly good computer seems wasteful, and it's not an option if you're hanging on to Windows 10 because you have mission-critical software or an expensive hardware device that's incompatible with Windows 11.\n\nAlso: I never pay full price for PCs or Macs, thanks to these 7 money-saving tricks\n\nYou also have the option to rent a new virtual PC by signing up for Windows 365, which allows you to connect remotely to your own Windows 11-powered virtual PC in Microsoft's cloud. A Windows 365 subscription works on Windows 10 and includes extended security updates for the host PC for up to three years. Windows 365 isn't cheap (plans start at $28 a month), but that option probably costs less than a new PC.\n\nFor businesses, replacing a PC that is more than six years old is absolutely the correct option. Ask your CPA about depreciation deductions.\n\n3. Upgrade your 'incompatible' hardware to Windows 11\n\nThat pesky compatibility checker might insist that you can't upgrade your Windows 10 PC to Windows 11, but there are indeed documented ways to bypass those restrictions. You just have to jump through a few technical hoops. Frankly, if you have a PC that is less than 10 years old, this is the easiest, cheapest, and most reliable option.\n\nAlso: The 10 apps I can't live or work without - on Windows, Mac, and mobile\n\nYou can find all the details in this article: How to upgrade your 'incompatible' Windows 10 PC to Windows 11. Here's the short version:\n\nFor PCs originally designed for Windows 10 (basically anything designed in 2016 or later), you need to make one small registry edit and then ensure that your PC is configured to use Secure Boot with the Trusted Platform Module (TPM) enabled. Even an old TPM 1.2 chip will do. As many readers have confirmed via email, this process works seamlessly as long as you've got those configuration details set properly. This option will work even with PCs that are 10 years old.\n\nFor older PCs originally designed for Windows 7 or Windows 8.1, you might need to use a third-party tool called Rufus to bypass installation challenges. That's especially true on PCs that use a legacy BIOS instead of UEFI firmware and for those that don't have access to a TPM. Make sure you have the most recent version of Rufus (version 4.9 or later) to keep up with Microsoft's latest compatibility checks.\n\nThose upgrade options can't save a device whose CPU lacks support for two specific instruction sets -- POPCNT and SSE 4.2. Most PCs built using Intel CPUs from 2009 or later will pass this test; AMD CPUs from 2015 or later should also be OK. As I note in this article, there is no workaround if you own one of those very old PCs that fail this test.\n\nAlso: How to upgrade from Windows 11 Home to Pro - without overpaying\n\nIf you do use one of these upgrade hacks, don't be alarmed by the threatening message you might see when trying to do an unsupported upgrade: \"If you proceed with installing Windows 11, your PC will no longer be supported and won't be entitled to receive updates. Damages to your PC due to lack of compatibility aren't covered under the manufacturer warranty.\"\n\nThat's deliberately misleading language from Microsoft. As I've noted before, that warning doesn't really say that Microsoft is going to cut off your access to updates; it simply says your PC is no longer supported, and you're no longer \"entitled\" to those updates. That bit of legalese is a tell on Microsoft's part, disclaiming corporate responsibility without actually saying what it will do.\n\nIf you don't want to mess with the registry and you're willing to do a clean install on a system that has a TPM but fails the CPU check, just use Rufus to create a bootable Windows 11 installation drive, which bypasses the compatibility checker completely. You'll need to restore your data files from a backup or from the cloud, and you'll also need to install your software from scratch, but that's no more difficult than setting up a new PC.\n\n4. Ditch Windows completely\n\nYou could keep your old hardware and replace Windows 10 with the flavor of Linux you prefer. If you've got the technical know-how and experience to manage the transition, that option is worth considering. Thanks to Google Workspace, Microsoft 365, and a million or so web-based services, you can do just about all your basic work in a web browser these days. You might not even notice what operating system is running that browser.\n\nAlso: Yes, you can run Windows apps on Linux - here are my top 5 ways\n\nSwitching to Google's free ChromeOS Flex might also be possible, although the compatibility requirements for that alternative are just as likely to get in your way. I wrote about my experience here: Installing ChromeOS Flex? 5 things you need to do first to avoid headaches. As I pointed out, \"If you've got an old PC or Mac and you're thinking of installing ChromeOS Flex on it, don't do anything until you check Google's official ChromeOS Flex certified models list.\"\n\nPay special attention to the end-of-support date for the PC you're thinking of upgrading. It doesn't make much sense to replace Windows 10 with a release of ChromeOS Flex that's also set to end support in the next year.\n\nAlso: 7 most Windows-like Linux distros - if you're ready to ditch Microsoft\n\nSwitching to Linux or some derivative of Linux might be a good way to repurpose an old PC. For consumers and businesses with existing investments in Windows software, it might not be a realistic alternative, but it's worth considering.\n\n5. Ignore the end-of-support deadline completely\n\nYou could do nothing at all -- just continue running your unsupported operating system and hope for the best. That's a bad idea that exposes you to the very real possibility that you'll fall prey to a security exploit. Unfortunately, a lot of people are going to do just that. Some percentage of them will end up regretting their decision.\n\nI've heard from some folks who believe that being extra careful and using third-party antivirus software will protect them from harm. I wouldn't bet my business on that strategy.\n\nAlso: Stop paying for antivirus software. Here's why you don't need it\n\nIf you're intent on doing so, consider installing the third-party 0patch agent to deal with any security issues that aren't addressed by Microsoft. The free 0patch personal plan includes patches for known 0-day vulnerabilities, but if you want all Windows 10 patches, or if the PC is used for business or enterprise tasks, you'll need to pay for a 0patch Pro plan at a per-PC rate of €24.95 per year -- for customers in the US, at current exchange rates, that equates to less than $2.50 a month.\n\nI wouldn't recommend that for a PC that you use for business, but if you have a device you use for casual tasks at home, you might be willing to take the risk.\n\nWhat does 'end of support' mean?\n\nFor nearly a quarter-century, Microsoft has had a formal policy of supporting each major operating system release for 10 years. Windows 10 was released in 2015, so its 10 years are up, as expected, in 2025.\n\nThe end date is right there on the Microsoft Support document that lists products retiring or reaching the end of support in 2025. Every retail edition of Windows, as well as the Enterprise and Education editions, is slated for retirement.\n\nIf you have a Windows 10 PC, it faces mandatory retirement in 2025 Screenshot by Ed Bott/ZDNET\n\nThat schedule is defined by Microsoft's Modern Lifecycle Policy, which is documented on the Microsoft Lifecycle page: \"Windows 10 will reach end of support on Oct. 14, 2025. The current version, 22H2, will be the final version of Windows 10, and all editions will remain in support with monthly security update releases through that date.\" In a separate support article, Microsoft reiterates that as of Oct. 14, 2025, it will no longer provide technical support or security and reliability fixes for PCs running Windows 10.\n\nAlso: How to upgrade your 'incompatible' Windows 10 PC to Windows 11 - for free\n\nWhen a Windows version reaches its end-of-support date, the software keeps working, but Windows Update stops delivering security and reliability fixes:\n\n[There] will be no new security updates, non-security updates, or assisted support. Customers are encouraged to migrate to the latest version of the product or service. Paid programs may be available for applicable products.\n\nThat part in the middle sounds encouraging, doesn't it? \"Customers are encouraged to migrate to the latest version of the product or service.\" Unfortunately, that's not a supported option for customers running Windows 10 on hardware that doesn't meet the stringent hardware compatibility requirements of Windows 11. If you try to upgrade one of those PCs to Windows 11, you'll encounter an error message.\n\nAnd then you'll have to choose one of the five options above.",
      "source": "ZDNet",
      "url": "https://www.zdnet.com/article/cant-upgrade-your-windows-10-pc-you-have-2-weeks-to-act-and-5-options/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Nvidia: The story behind the world’s most valuable company - Generate Wealth Weekly",
      "content": "At the heart of Nvidia’s success is its co-founder and CEO, Jensen Huang. Born in Taiwan and raised in the United States, Huang washed dishes and cleaned bathrooms at Denny’s as a teenager, eventually earning a master’s degree in electrical engineering from Stanford.\n\nUnder his guidance, Nvidia has transformed from a graphics company into a global leader in parallel computing and AI. When most saw the GPU as a tool with limited applications, Huang continued to invest huge amounts into R&D while many analysts and investors queried whether or not there would ever be an acceptable return on investment.\n\nNvidia’s leadership was propelled even further through the release of CUDA (Compute Unified Device Architecture) – a programming platform that helps users write software algorithms on top of Nvidia’s GPUs. Launched in 2006, CUDA opened the GPU’s raw computing power to researchers and developers beyond the world of graphics. Suddenly, scientists in fields ranging from genomics to astrophysics could run complex simulations hundreds of times faster than before. But the true inflection point came when AI researchers discovered that Nvidia GPUs could dramatically improve the process of training deep neural networks, enabling breakthroughs in computer vision, natural language processing, and autonomous systems.\n\nToday, Nvidia is the undisputed king of AI hardware. Its GPUs power everything from data centres and high-performance computers to self-driving cars and personal devices. The company’s hardware is the engine behind OpenAI’s Chat GPT models, Google’s vast AI infrastructure, and the world’s most advanced robotics. In addition, Nvidia’s software has become the dominant platform for AI development.\n\nBecause of the market’s insatiable demand for its GPUs the company has seen its market capitalisation soar, recently surpassing the US$4 trillion-dollar mark and becoming the most valuable company in the world. This rise in value has been staggering as it only surpassed the US$1 trillion mark in May of 2023, equating to a 4x increase in value in a little over two years.\n\nIn the process Nvidia has made thousands of its employees millionaires – a recent survey found that a third of Nvidia’s staff have a net wealth in excess of US$20 million. This is easy to understand when you consider that only 10 years ago Nvidia’s shares were trading at less than US$0.60 per share versus the current price of US$175.\n\nBut Nvidia’s rise is not unchallenged. Competition is fierce, with rivals like AMD and Broadcom racing to catch up. And as AI becomes more powerful, there are ethical dilemmas about privacy, job displacement, and the potential misuse of autonomous systems.\n\nIn an age when AI is everywhere, Nvidia is the company quietly making it all possible. From its humble origins as a graphics chip startup, it’s become the backbone of the world’s AI revolution.\n\nGenerate is a New Zealand-owned KiwiSaver and Managed Fund provider managing over $8 billion on behalf of more than 175,000 New Zealanders.\n\nThis article is intended for general information only and should not be considered financial advice. The views expressed are those of the author. All investments carry risk, and past performance is not indicative of future results.\n\nTo see Generate’s Financial Advice Provider Disclosure Statement or Product Disclosure Statement, go to www.generatewealth.co.nz/advertising-disclosures/. The issuer is Generate Investment Management Limited. Past performance is not indicative of future performance.\n\nSign up to Herald Premium Editor’s Picks, delivered straight to your inbox every Friday. Editor-in-Chief Murray Kirkness picks the week’s best features, interviews and investigations. Sign up for Herald Premium here.",
      "source": "New Zealand Herald",
      "url": "https://www.nzherald.co.nz/business/personal-finance/investment/nvidia-the-story-behind-the-worlds-most-valuable-company-generate-wealth-weekly/P4YKZCFDJFDLHERP7UAPHPPIPM/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "China's Zhaoxin breaks into healthcare: 6,000+ hospital PCs run x86 chips against Intel, AMD",
      "content": "China's Zhaoxin breaks into healthcare: 6,000+ hospital PCs run x86 chips against Intel, AMD\n\nShanghai Zhaoxin Semiconductor has scored a breakthrough in China's healthcare sector. On September 23, the x86 chipmaker announced that over 6,000 of its processor-powered desktops won a major hospital procurement bid, an important step for Chinese x86 CPUs in mission-critical medical deployments.\n\nChina's healthcare system is in the midst of rapid digital transformation, with ambitious goals to modernize core hospital information systems by 2025. The transition requires computing platforms that are both powerful and easy to deploy, critical traits in an industry long burdened by fragmented IT ecosystems.\n\nChina's healthcare IT fragmentation\n\nFragmentation remains one of healthcare IT's biggest challenges. Core systems such as hospital information systems (HIS), laboratory information systems (LIS), and picture archiving and communication systems (PACS) still depend on foreign databases like Oracle and SQL Server, which command over 80% market share. Domestic databases account for less than 15%, and migrating decades of records is complicated by format incompatibility and strict real-time demands.\n\nAt one leading provincial hospital, 40% of legacy HIS systems still run on outdated VB6 architecture, with upgrades costing up to CNY800,000 (approx. US$112,500) per system. Provinces are now piloting phased adaptation, rushing \"emergency fixes\" for critical platforms like PACS, while allowing a three-year transition for non-core systems such as office software. The dual-track approach underscores the clash between policy mandates and technical realities.\n\nSmaller hospitals face even sharper challenges: nearly 30% of their systems are too old to run domestic operating systems or new applications, leaving them stuck between costly legacy reuse and risky data migration.\n\nZhaoxin's processor ecosystem strategy\n\nZhaoxin is tackling these pain points with processors that combine compatibility and performance. The firm has independently developed six generations of high-performance CPUs, including the KaiXian desktop and KaiSheng server lines, with products spanning AI PCs, desktops, notebooks, all-in-ones, servers, and embedded platforms.\n\nThe chips support both domestic operating systems: UnionTech Software UOS, NeoKylin, Zhongkefangde Software, and Microsoft Windows. They are compatible with mainstream applications, cloud platforms, databases, development tools, and AI models, while keeping software migration costs low.\n\nFor healthcare, Zhaoxin has introduced \"seamless migration\" and \"one-stop support\" solutions. It has also set up medical application innovation centers with partners, offering hospitals end-to-end guidance from chips to operating systems and applications.\n\nToday, Zhaoxin works with nearly 4,000 partners across systems integration, software, and hardware. Together with domestic OS vendors, it has completed more than 200,000 software-hardware adaptation projects, building a full-stack ecosystem from processors to databases and applications.\n\nFrom 2022 to 2024, Zhaoxin recorded revenues of CNY340 million, CNY555 million, and CNY889 million, respectively, with a compound annual growth rate of 61.71%.\n\nRivaling Intel and AMD in hospitals\n\nBeating out Intel and AMD in a high-profile bid highlights Zhaoxin's progress in performance, compatibility, and cost efficiency. Its processors are built to handle demanding healthcare workloads — from electronic medical records to telemedicine platforms — while maintaining stable operations.\n\nWith integrated security, Zhaoxin CPUs protect patient data across its lifecycle: collection, transmission, storage, and use. This meets China's strict compliance standards, as hospitals lean on secure, high-performance platforms for data-heavy applications.\n\nAs digitalization accelerates, medical data will expand from text records and lab reports to imaging archives and real-time vital signs. Zhaoxin's processors can manage these workloads, minimizing downtime and enabling use cases such as AI diagnostics and cross-regional data sharing.\n\nChina's x86 chips gain traction\n\nThe hospital bid underscores the rising role of Chinese x86 chips in public welfare sectors. By offering strong performance and ecosystem compatibility, Zhaoxin is gaining ground in healthcare digitalization, an arena once dominated by foreign technology.\n\nIf sustained, these gains could speed the localization of hospital IT infrastructure, supporting China's drive for tech independence while laying the groundwork for smarter, more secure healthcare systems.\n\nArticle edited by Jack Wu",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250924VL209/x86-chips-smart-healthcare-shanghai.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Ambitious Wee Beastie Project Aims To Put Desktop NVIDIA RTX 4070 GPU Into 4.75 L Chassis",
      "content": "A rift appears to be forming in the desktop PC market, with full-size desktops on one side and mini PCs on the other side. Of course, there is small, but dedicated community that has sprung up around SFF PCs, but those are often limited, with many calling for flex PSUs and other compromises. The Wee Beastie, a new project on Kickstarter , is a small form-factor PC that hopes to cut back on the compromises, claiming to offer a powerful gaming and LLM-oriented system with an upgradeable dGPU in just 4.75 L volume—this is just 0.25 L more than the Framework Desktop PC , which uses an AMD Ryzen AI+ 395 Max with an iGPU. That said, even the pre-release Kickstarter marketing leaves some questions.The Wee Beastie Super Mini Fishtank, as it is called, is a mini PC with up to an Intel Core Ultra 7 255H CPU and NVIDIA GeForce RTX 4070 12 GB GPU. It will also be available with up to 128 GB of DDR5 RAM and a 16 TB SSD, and it boasts Wi-Fi 7 and room for up to 13 case fans. It will also contain an internal PSU capable of 400 W, which technically falls well below the 550 W we recommend for a desktop RTX 4070. Although the GPU shown on the Kickstarter page has the \" AD104-251-A1\" associated with the desktop variants of the RTX 4070 , the PSU output suggests that there will be some power throttling or down-tuning at play, so RTX 4070 Mobile performance might be what's to be expected here. Often, the most challenging part of projects like these, as was the case with the custom expansion modules on the Framework Laptop 16 until recently, is supporting the MXM standard for future hardware revisions. Although MXM modules are technically an open standard, like ATX, it is not commonly used due to limited demand and size constraints. Currently, the Kickstarter has completed funding, having reached $53,763 of its $2,570 goal, and the SFF PC looks to be going into production as soon as 2026.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341473/ambitious-wee-beastie-project-aims-to-put-desktop-nvidia-rtx-4070-gpu-into-4-75-l-chassis",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Merge tag 'x86_cache_for_v6.18_rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip",
      "content": "\n\nindex 6607dbb1be441f..bf1e6ca6aeb82f 100644\n\n--- a/\n\n+++ b/ diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txtindex 6607dbb1be441f..bf1e6ca6aeb82f 100644--- a/ Documentation/admin-guide/kernel-parameters.txt +++ b/ Documentation/admin-guide/kernel-parameters.txt @@ -6163,7 +6163,7 @@ rdt= [HW,X86,RDT] Turn on/off individual RDT features. List is: cmt, mbmtotal, mbmlocal, l3cat, l3cdp, l2cat, l2cdp, - mba, smba, bmec. + mba, smba, bmec, abmc. E.g. to turn on cmt and turn off mba use: rdt=cmt,!mba\n\nindex c7949dd44f2f3a..006d23af66e19f 100644\n\n--- a/\n\n+++ b/ diff --git a/Documentation/filesystems/resctrl.rst b/Documentation/filesystems/resctrl.rstindex c7949dd44f2f3a..006d23af66e19f 100644--- a/ Documentation/filesystems/resctrl.rst +++ b/ Documentation/filesystems/resctrl.rst @@ -26,6 +26,7 @@ MBM (Memory Bandwidth Monitoring) \"cqm_mbm_total\", \"cqm_mbm_local\" MBA (Memory Bandwidth Allocation) \"mba\" SMBA (Slow Memory Bandwidth Allocation) \"\" BMEC (Bandwidth Monitoring Event Configuration) \"\" +ABMC (Assignable Bandwidth Monitoring Counters) \"\" =============================================== ================================ Historically, new features were made visible by default in /proc/cpuinfo. This @@ -256,6 +257,144 @@ with the following files: # cat /sys/fs/resctrl/info/L3_MON/mbm_local_bytes_config 0=0x30;1=0x30;3=0x15;4=0x15 +\"mbm_assign_mode\": + The supported counter assignment modes. The enclosed brackets indicate which mode + is enabled. The MBM events associated with counters may reset when \"mbm_assign_mode\" + is changed. + :: + + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + [mbm_event] + default + + \"mbm_event\": + + mbm_event mode allows users to assign a hardware counter to an RMID, event + pair and monitor the bandwidth usage as long as it is assigned. The hardware + continues to track the assigned counter until it is explicitly unassigned by + the user. Each event within a resctrl group can be assigned independently. + + In this mode, a monitoring event can only accumulate data while it is backed + by a hardware counter. Use \"mbm_L3_assignments\" found in each CTRL_MON and MON + group to specify which of the events should have a counter assigned. The number + of counters available is described in the \"num_mbm_cntrs\" file. Changing the + mode may cause all counters on the resource to reset. + + Moving to mbm_event counter assignment mode requires users to assign the counters + to the events. Otherwise, the MBM event counters will return 'Unassigned' when read. + + The mode is beneficial for AMD platforms that support more CTRL_MON + and MON groups than available hardware counters. By default, this + feature is enabled on AMD platforms with the ABMC (Assignable Bandwidth + Monitoring Counters) capability, ensuring counters remain assigned even + when the corresponding RMID is not actively used by any processor. + + \"default\": + + In default mode, resctrl assumes there is a hardware counter for each + event within every CTRL_MON and MON group. On AMD platforms, it is + recommended to use the mbm_event mode, if supported, to prevent reset of MBM + events between reads resulting from hardware re-allocating counters. This can + result in misleading values or display \"Unavailable\" if no counter is assigned + to the event. + + * To enable \"mbm_event\" counter assignment mode: + :: + + # echo \"mbm_event\" > /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + + * To enable \"default\" monitoring mode: + :: + + # echo \"default\" > /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + +\"num_mbm_cntrs\": + The maximum number of counters (total of available and assigned counters) in + each domain when the system supports mbm_event mode. + + For example, on a system with maximum of 32 memory bandwidth monitoring + counters in each of its L3 domains: + :: + + # cat /sys/fs/resctrl/info/L3_MON/num_mbm_cntrs + 0=32;1=32 + +\"available_mbm_cntrs\": + The number of counters available for assignment in each domain when mbm_event + mode is enabled on the system. + + For example, on a system with 30 available [hardware] assignable counters + in each of its L3 domains: + :: + + # cat /sys/fs/resctrl/info/L3_MON/available_mbm_cntrs + 0=30;1=30 + +\"event_configs\": + Directory that exists when \"mbm_event\" counter assignment mode is supported. + Contains a sub-directory for each MBM event that can be assigned to a counter. + + Two MBM events are supported by default: mbm_local_bytes and mbm_total_bytes. + Each MBM event's sub-directory contains a file named \"event_filter\" that is + used to view and modify which memory transactions the MBM event is configured + with. The file is accessible only when \"mbm_event\" counter assignment mode is + enabled. + + List of memory transaction types supported: + + ========================== ======================================================== + Name Description + ========================== ======================================================== + dirty_victim_writes_all Dirty Victims from the QOS domain to all types of memory + remote_reads_slow_memory Reads to slow memory in the non-local NUMA domain + local_reads_slow_memory Reads to slow memory in the local NUMA domain + remote_non_temporal_writes Non-temporal writes to non-local NUMA domain + local_non_temporal_writes Non-temporal writes to local NUMA domain + remote_reads Reads to memory in the non-local NUMA domain + local_reads Reads to memory in the local NUMA domain + ========================== ======================================================== + + For example:: + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + local_reads,remote_reads,local_non_temporal_writes,remote_non_temporal_writes, + local_reads_slow_memory,remote_reads_slow_memory,dirty_victim_writes_all + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + local_reads,local_non_temporal_writes,local_reads_slow_memory + + Modify the event configuration by writing to the \"event_filter\" file within + the \"event_configs\" directory. The read/write \"event_filter\" file contains the + configuration of the event that reflects which memory transactions are counted by it. + + For example:: + + # echo \"local_reads, local_non_temporal_writes\" > + /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + local_reads,local_non_temporal_writes + +\"mbm_assign_on_mkdir\": + Exists when \"mbm_event\" counter assignment mode is supported. Accessible + only when \"mbm_event\" counter assignment mode is enabled. + + Determines if a counter will automatically be assigned to an RMID, MBM event + pair when its associated monitor group is created via mkdir. Enabled by default + on boot, also when switched from \"default\" mode to \"mbm_event\" counter assignment + mode. Users can disable this capability by writing to the interface. + + \"0\": + Auto assignment is disabled. + \"1\": + Auto assignment is enabled. + + Example:: + + # echo 0 > /sys/fs/resctrl/info/L3_MON/mbm_assign_on_mkdir + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_on_mkdir + 0 + \"max_threshold_occupancy\": Read/write file provides the largest value (in bytes) at which a previously used LLC_occupancy @@ -380,10 +519,77 @@ When monitoring is enabled all MON groups will also contain: for the L3 cache they occupy). These are named \"mon_sub_L3_YY\" where \"YY\" is the node number. + When the 'mbm_event' counter assignment mode is enabled, reading + an MBM event of a MON group returns 'Unassigned' if no hardware + counter is assigned to it. For CTRL_MON groups, 'Unassigned' is + returned if the MBM event does not have an assigned counter in the + CTRL_MON group nor in any of its associated MON groups. + \"mon_hw_id\": Available only with debug option. The identifier used by hardware for the monitor group. On x86 this is the RMID. +When monitoring is enabled all MON groups may also contain: + +\"mbm_L3_assignments\": + Exists when \"mbm_event\" counter assignment mode is supported and lists the + counter assignment states of the group. + + The assignment list is displayed in the following format: + + <Event>:<Domain ID>=<Assignment state>;<Domain ID>=<Assignment state> + + Event: A valid MBM event in the + /sys/fs/resctrl/info/L3_MON/event_configs directory. + + Domain ID: A valid domain ID. When writing, '*' applies the changes + to all the domains. + + Assignment states: + + _ : No counter assigned. + + e : Counter assigned exclusively. + + Example: + + To display the counter assignment states for the default group. + :: + + # cd /sys/fs/resctrl + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + + Assignments can be modified by writing to the interface. + + Examples: + + To unassign the counter associated with the mbm_total_bytes event on domain 0: + :: + + # echo \"mbm_total_bytes:0=_\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=_;1=e + mbm_local_bytes:0=e;1=e + + To unassign the counter associated with the mbm_total_bytes event on all the domains: + :: + + # echo \"mbm_total_bytes:*=_\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=_;1=_ + mbm_local_bytes:0=e;1=e + + To assign a counter associated with the mbm_total_bytes event on all domains in + exclusive mode: + :: + + # echo \"mbm_total_bytes:*=e\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + When the \"mba_MBps\" mount option is used all CTRL_MON groups will also contain: \"mba_MBps_event\": @@ -1429,6 +1635,125 @@ View the llc occupancy snapshot:: # cat /sys/fs/resctrl/p1/mon_data/mon_L3_00/llc_occupancy 11234000 + +Examples on working with mbm_assign_mode +======================================== + +a. Check if MBM counter assignment mode is supported. +:: + + # mount -t resctrl resctrl /sys/fs/resctrl/ + + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + [mbm_event] + default + +The \"mbm_event\" mode is detected and enabled. + +b. Check how many assignable counters are supported. +:: + + # cat /sys/fs/resctrl/info/L3_MON/num_mbm_cntrs + 0=32;1=32 + +c. Check how many assignable counters are available for assignment in each domain. +:: + + # cat /sys/fs/resctrl/info/L3_MON/available_mbm_cntrs + 0=30;1=30 + +d. To list the default group's assign states. +:: + + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + +e. To unassign the counter associated with the mbm_total_bytes event on domain 0. +:: + + # echo \"mbm_total_bytes:0=_\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=_;1=e + mbm_local_bytes:0=e;1=e + +f. To unassign the counter associated with the mbm_total_bytes event on all domains. +:: + + # echo \"mbm_total_bytes:*=_\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignment + mbm_total_bytes:0=_;1=_ + mbm_local_bytes:0=e;1=e + +g. To assign a counter associated with the mbm_total_bytes event on all domains in +exclusive mode. +:: + + # echo \"mbm_total_bytes:*=e\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + +h. Read the events mbm_total_bytes and mbm_local_bytes of the default group. There is +no change in reading the events with the assignment. +:: + + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_total_bytes + 779247936 + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_total_bytes + 562324232 + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_local_bytes + 212122123 + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_local_bytes + 121212144 + +i. Check the event configurations. +:: + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + local_reads,remote_reads,local_non_temporal_writes,remote_non_temporal_writes, + local_reads_slow_memory,remote_reads_slow_memory,dirty_victim_writes_all + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + local_reads,local_non_temporal_writes,local_reads_slow_memory + +j. Change the event configuration for mbm_local_bytes. +:: + + # echo \"local_reads, local_non_temporal_writes, local_reads_slow_memory, remote_reads\" > + /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + local_reads,local_non_temporal_writes,local_reads_slow_memory,remote_reads + +k. Now read the local events again. The first read may come back with \"Unavailable\" +status. The subsequent read of mbm_local_bytes will display the current value. +:: + + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_local_bytes + Unavailable + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_local_bytes + 2252323 + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_local_bytes + Unavailable + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_local_bytes + 1566565 + +l. Users have the option to go back to 'default' mbm_assign_mode if required. This can be +done using the following command. Note that switching the mbm_assign_mode may reset all +the MBM counters (and thus all MBM events) of all the resctrl groups. +:: + + # echo \"default\" > /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + mbm_event + [default] + +m. Unmount the resctrl filesystem. +:: + + # umount /sys/fs/resctrl/ + Intel RDT Errata ================\n\nindex a80cca9aa6ff2b..62d16c20a888eb 100644\n\n--- a/\n\n+++ b/ diff --git a/MAINTAINERS b/MAINTAINERSindex a80cca9aa6ff2b..62d16c20a888eb 100644--- a/ MAINTAINERS +++ b/ MAINTAINERS @@ -21186,6 +21186,7 @@ M: Tony Luck <tony.luck@intel.com> M: Reinette Chatre <reinette.chatre@intel.com> R: Dave Martin <Dave.Martin@arm.com> R: James Morse <james.morse@arm.com> +R: Babu Moger <babu.moger@amd.com> L: linux-kernel@vger.kernel.org S: Supported F: Documentation/filesystems/resctrl.rst\n\nindex 751ca35386b0ef..b2a562217d3ffc 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/include/asm/cpufeatures.h b/arch/x86/include/asm/cpufeatures.hindex 751ca35386b0ef..b2a562217d3ffc 100644--- a/ arch/x86/include/asm/cpufeatures.h +++ b/ arch/x86/include/asm/cpufeatures.h @@ -496,6 +496,7 @@ #define X86_FEATURE_TSA_L1_NO (21*32+12) /* AMD CPU not vulnerable to TSA-L1 */ #define X86_FEATURE_CLEAR_CPU_BUF_VM (21*32+13) /* Clear CPU buffers using VERW before VMRUN */ #define X86_FEATURE_IBPB_EXIT_TO_USER (21*32+14) /* Use IBPB on exit-to-userspace, see VMSCAPE bug */ +#define X86_FEATURE_ABMC (21*32+15) /* Assignable Bandwidth Monitoring Counters */ /* * BUG word(s)\n\nindex b60d3711a7089e..73393a66d3ab05 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.hindex b60d3711a7089e..73393a66d3ab05 100644--- a/ arch/x86/include/asm/msr-index.h +++ b/ arch/x86/include/asm/msr-index.h @@ -1230,6 +1230,8 @@ /* - AMD: */ #define MSR_IA32_MBA_BW_BASE 0xc0000200 #define MSR_IA32_SMBA_BW_BASE 0xc0000280 +#define MSR_IA32_L3_QOS_ABMC_CFG 0xc00003fd +#define MSR_IA32_L3_QOS_EXT_CFG 0xc00003ff #define MSR_IA32_EVT_CFG_BASE 0xc0000400 /* AMD-V MSRs */\n\nindex feb93b50e990ac..575f8408a9e7c6 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/include/asm/resctrl.h b/arch/x86/include/asm/resctrl.hindex feb93b50e990ac..575f8408a9e7c6 100644--- a/ arch/x86/include/asm/resctrl.h +++ b/ arch/x86/include/asm/resctrl.h @@ -44,7 +44,6 @@ DECLARE_PER_CPU(struct resctrl_pqr_state, pqr_state); extern bool rdt_alloc_capable; extern bool rdt_mon_capable; -extern unsigned int rdt_mon_features; DECLARE_STATIC_KEY_FALSE(rdt_enable_key); DECLARE_STATIC_KEY_FALSE(rdt_alloc_enable_key); @@ -84,21 +83,6 @@ static inline void resctrl_arch_disable_mon(void) static_branch_dec_cpuslocked(&rdt_enable_key); } -static inline bool resctrl_arch_is_llc_occupancy_enabled(void) -{ - return (rdt_mon_features & (1 << QOS_L3_OCCUP_EVENT_ID)); -} - -static inline bool resctrl_arch_is_mbm_total_enabled(void) -{ - return (rdt_mon_features & (1 << QOS_L3_MBM_TOTAL_EVENT_ID)); -} - -static inline bool resctrl_arch_is_mbm_local_enabled(void) -{ - return (rdt_mon_features & (1 << QOS_L3_MBM_LOCAL_EVENT_ID)); -} - /* * __resctrl_sched_in() - Writes the task's CLOSid/RMID to IA32_PQR_MSR *\n\nindex 187d527ef73b6e..06ca5a30140c2f 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/kernel/cpu/resctrl/core.c b/arch/x86/kernel/cpu/resctrl/core.cindex 187d527ef73b6e..06ca5a30140c2f 100644--- a/ arch/x86/kernel/cpu/resctrl/core.c +++ b/ arch/x86/kernel/cpu/resctrl/core.c @@ -107,7 +107,7 @@ u32 resctrl_arch_system_num_rmid_idx(void) struct rdt_resource *r = &rdt_resources_all[RDT_RESOURCE_L3].r_resctrl; /* RMID are independent numbers for x86. num_rmid_idx == num_rmid */ - return r->num_rmid; + return r->mon.num_rmid; } struct rdt_resource *resctrl_arch_get_resource(enum resctrl_res_level l) @@ -365,8 +365,10 @@ static void ctrl_domain_free(struct rdt_hw_ctrl_domain *hw_dom) static void mon_domain_free(struct rdt_hw_mon_domain *hw_dom) { - kfree(hw_dom->arch_mbm_total); - kfree(hw_dom->arch_mbm_local); + int idx; + + for_each_mbm_idx(idx) + kfree(hw_dom->arch_mbm_states[idx]); kfree(hw_dom); } @@ -400,25 +402,27 @@ static int domain_setup_ctrlval(struct rdt_resource *r, struct rdt_ctrl_domain * */ static int arch_domain_mbm_alloc(u32 num_rmid, struct rdt_hw_mon_domain *hw_dom) { - size_t tsize; - - if (resctrl_arch_is_mbm_total_enabled()) { - tsize = sizeof(*hw_dom->arch_mbm_total); - hw_dom->arch_mbm_total = kcalloc(num_rmid, tsize, GFP_KERNEL); - if (!hw_dom->arch_mbm_total) - return -ENOMEM; - } - if (resctrl_arch_is_mbm_local_enabled()) { - tsize = sizeof(*hw_dom->arch_mbm_local); - hw_dom->arch_mbm_local = kcalloc(num_rmid, tsize, GFP_KERNEL); - if (!hw_dom->arch_mbm_local) { - kfree(hw_dom->arch_mbm_total); - hw_dom->arch_mbm_total = NULL; - return -ENOMEM; - } + size_t tsize = sizeof(*hw_dom->arch_mbm_states[0]); + enum resctrl_event_id eventid; + int idx; + + for_each_mbm_event_id(eventid) { + if (!resctrl_is_mon_event_enabled(eventid)) + continue; + idx = MBM_STATE_IDX(eventid); + hw_dom->arch_mbm_states[idx] = kcalloc(num_rmid, tsize, GFP_KERNEL); + if (!hw_dom->arch_mbm_states[idx]) + goto cleanup; } return 0; +cleanup: + for_each_mbm_idx(idx) { + kfree(hw_dom->arch_mbm_states[idx]); + hw_dom->arch_mbm_states[idx] = NULL; + } + + return -ENOMEM; } static int get_domain_id_from_scope(int cpu, enum resctrl_scope scope) @@ -516,6 +520,9 @@ static void domain_add_cpu_mon(int cpu, struct rdt_resource *r) d = container_of(hdr, struct rdt_mon_domain, hdr); cpumask_set_cpu(cpu, &d->hdr.cpu_mask); + /* Update the mbm_assign_mode state for the CPU if supported */ + if (r->mon.mbm_cntr_assignable) + resctrl_arch_mbm_cntr_assign_set_one(r); return; } @@ -535,9 +542,13 @@ static void domain_add_cpu_mon(int cpu, struct rdt_resource *r) d->ci_id = ci->id; cpumask_set_cpu(cpu, &d->hdr.cpu_mask); + /* Update the mbm_assign_mode state for the CPU if supported */ + if (r->mon.mbm_cntr_assignable) + resctrl_arch_mbm_cntr_assign_set_one(r); + arch_mon_domain_online(r, d); - if (arch_domain_mbm_alloc(r->num_rmid, hw_dom)) { + if (arch_domain_mbm_alloc(r->mon.num_rmid, hw_dom)) { mon_domain_free(hw_dom); return; } @@ -707,6 +718,7 @@ enum { RDT_FLAG_MBA, RDT_FLAG_SMBA, RDT_FLAG_BMEC, + RDT_FLAG_ABMC, }; #define RDT_OPT(idx, n, f) \\ @@ -732,6 +744,7 @@ static struct rdt_options rdt_options[] __ro_after_init = { RDT_OPT(RDT_FLAG_MBA, \"mba\", X86_FEATURE_MBA), RDT_OPT(RDT_FLAG_SMBA, \"smba\", X86_FEATURE_SMBA), RDT_OPT(RDT_FLAG_BMEC, \"bmec\", X86_FEATURE_BMEC), + RDT_OPT(RDT_FLAG_ABMC, \"abmc\", X86_FEATURE_ABMC), }; #define NUM_RDT_OPTIONS ARRAY_SIZE(rdt_options) @@ -863,15 +876,24 @@ static __init bool get_rdt_alloc_resources(void) static __init bool get_rdt_mon_resources(void) { struct rdt_resource *r = &rdt_resources_all[RDT_RESOURCE_L3].r_resctrl; + bool ret = false; - if (rdt_cpu_has(X86_FEATURE_CQM_OCCUP_LLC)) - rdt_mon_features |= (1 << QOS_L3_OCCUP_EVENT_ID); - if (rdt_cpu_has(X86_FEATURE_CQM_MBM_TOTAL)) - rdt_mon_features |= (1 << QOS_L3_MBM_TOTAL_EVENT_ID); - if (rdt_cpu_has(X86_FEATURE_CQM_MBM_LOCAL)) - rdt_mon_features |= (1 << QOS_L3_MBM_LOCAL_EVENT_ID); + if (rdt_cpu_has(X86_FEATURE_CQM_OCCUP_LLC)) { + resctrl_enable_mon_event(QOS_L3_OCCUP_EVENT_ID); + ret = true; + } + if (rdt_cpu_has(X86_FEATURE_CQM_MBM_TOTAL)) { + resctrl_enable_mon_event(QOS_L3_MBM_TOTAL_EVENT_ID); + ret = true; + } + if (rdt_cpu_has(X86_FEATURE_CQM_MBM_LOCAL)) { + resctrl_enable_mon_event(QOS_L3_MBM_LOCAL_EVENT_ID); + ret = true; + } + if (rdt_cpu_has(X86_FEATURE_ABMC)) + ret = true; - if (!rdt_mon_features) + if (!ret) return false; return !rdt_get_mon_l3_config(r); @@ -965,7 +987,7 @@ static enum cpuhp_state rdt_online; /* Runs once on the BSP during boot. */ void resctrl_cpu_detect(struct cpuinfo_x86 *c) { - if (!cpu_has(c, X86_FEATURE_CQM_LLC)) { + if (!cpu_has(c, X86_FEATURE_CQM_LLC) && !cpu_has(c, X86_FEATURE_ABMC)) { c->x86_cache_max_rmid = -1; c->x86_cache_occ_scale = -1; c->x86_cache_mbm_width_offset = -1; @@ -977,7 +999,8 @@ void resctrl_cpu_detect(struct cpuinfo_x86 *c) if (cpu_has(c, X86_FEATURE_CQM_OCCUP_LLC) || cpu_has(c, X86_FEATURE_CQM_MBM_TOTAL) || - cpu_has(c, X86_FEATURE_CQM_MBM_LOCAL)) { + cpu_has(c, X86_FEATURE_CQM_MBM_LOCAL) || + cpu_has(c, X86_FEATURE_ABMC)) { u32 eax, ebx, ecx, edx; /* QoS sub-leaf, EAX=0Fh, ECX=1 */\n\nindex 5e3c41b3643737..9f4c2f0aaf5c80 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/kernel/cpu/resctrl/internal.h b/arch/x86/kernel/cpu/resctrl/internal.hindex 5e3c41b3643737..9f4c2f0aaf5c80 100644--- a/ arch/x86/kernel/cpu/resctrl/internal.h +++ b/ arch/x86/kernel/cpu/resctrl/internal.h @@ -37,6 +37,15 @@ struct arch_mbm_state { u64 prev_msr; }; +/* Setting bit 0 in L3_QOS_EXT_CFG enables the ABMC feature. */ +#define ABMC_ENABLE_BIT 0 + +/* + * Qos Event Identifiers. + */ +#define ABMC_EXTENDED_EVT_ID BIT(31) +#define ABMC_EVT_ID BIT(0) + /** * struct rdt_hw_ctrl_domain - Arch private attributes of a set of CPUs that share * a resource for a control function @@ -54,15 +63,15 @@ struct rdt_hw_ctrl_domain { * struct rdt_hw_mon_domain - Arch private attributes of a set of CPUs that share * a resource for a monitor function * @d_resctrl: Properties exposed to the resctrl file system - * @arch_mbm_total: arch private state for MBM total bandwidth - * @arch_mbm_local: arch private state for MBM local bandwidth + * @arch_mbm_states: Per-event pointer to the MBM event's saved state. + * An MBM event's state is an array of struct arch_mbm_state + * indexed by RMID on x86. * * Members of this structure are accessed via helpers that provide abstraction. */ struct rdt_hw_mon_domain { struct rdt_mon_domain d_resctrl; - struct arch_mbm_state *arch_mbm_total; - struct arch_mbm_state *arch_mbm_local; + struct arch_mbm_state *arch_mbm_states[QOS_NUM_L3_MBM_EVENTS]; }; static inline struct rdt_hw_ctrl_domain *resctrl_to_arch_ctrl_dom(struct rdt_ctrl_domain *r) @@ -102,6 +111,7 @@ struct msr_param { * @mon_scale: cqm counter * mon_scale = occupancy in bytes * @mbm_width: Monitor width, to detect and correct for overflow. * @cdp_enabled: CDP state of this resource + * @mbm_cntr_assign_enabled: ABMC feature is enabled * * Members of this structure are either private to the architecture * e.g. mbm_width, or accessed via helpers that provide abstraction. e.g. @@ -115,6 +125,7 @@ struct rdt_hw_resource { unsigned int mon_scale; unsigned int mbm_width; bool cdp_enabled; + bool mbm_cntr_assign_enabled; }; static inline struct rdt_hw_resource *resctrl_to_arch_res(struct rdt_resource *r) @@ -159,6 +170,42 @@ union cpuid_0x10_x_edx { unsigned int full; }; +/* + * ABMC counters are configured by writing to MSR_IA32_L3_QOS_ABMC_CFG. + * + * @bw_type : Event configuration that represents the memory + * transactions being tracked by the @cntr_id. + * @bw_src : Bandwidth source (RMID or CLOSID). + * @reserved1 : Reserved. + * @is_clos : @bw_src field is a CLOSID (not an RMID). + * @cntr_id : Counter identifier. + * @reserved : Reserved. + * @cntr_en : Counting enable bit. + * @cfg_en : Configuration enable bit. + * + * Configuration and counting: + * Counter can be configured across multiple writes to MSR. Configuration + * is applied only when @cfg_en = 1. Counter @cntr_id is reset when the + * configuration is applied. + * @cfg_en = 1, @cntr_en = 0 : Apply @cntr_id configuration but do not + * count events. + * @cfg_en = 1, @cntr_en = 1 : Apply @cntr_id configuration and start + * counting events. + */ +union l3_qos_abmc_cfg { + struct { + unsigned long bw_type :32, + bw_src :12, + reserved1: 3, + is_clos : 1, + cntr_id : 5, + reserved : 9, + cntr_en : 1, + cfg_en : 1; + } split; + unsigned long full; +}; + void rdt_ctrl_update(void *arg); int rdt_get_mon_l3_config(struct rdt_resource *r); @@ -168,5 +215,6 @@ bool rdt_cpu_has(int flag); void __init intel_rdt_mbm_apply_quirk(void); void rdt_domain_reconfigure_cdp(struct rdt_resource *r); +void resctrl_arch_mbm_cntr_assign_set_one(struct rdt_resource *r); #endif /* _ASM_X86_RESCTRL_INTERNAL_H */\n\nindex c261558276cdd4..c8945610d45550 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/kernel/cpu/resctrl/monitor.c b/arch/x86/kernel/cpu/resctrl/monitor.cindex c261558276cdd4..c8945610d45550 100644--- a/ arch/x86/kernel/cpu/resctrl/monitor.c +++ b/ arch/x86/kernel/cpu/resctrl/monitor.c @@ -31,11 +31,6 @@ */ bool rdt_mon_capable; -/* - * Global to indicate which monitoring events are enabled. - */ -unsigned int rdt_mon_features; - #define CF(cf) ((unsigned long)(1048576 * (cf) + 0.5)) static int snc_nodes_per_l3_cache = 1; @@ -135,7 +130,7 @@ static int logical_rmid_to_physical_rmid(int cpu, int lrmid) if (snc_nodes_per_l3_cache == 1) return lrmid; - return lrmid + (cpu_to_node(cpu) % snc_nodes_per_l3_cache) * r->num_rmid; + return lrmid + (cpu_to_node(cpu) % snc_nodes_per_l3_cache) * r->mon.num_rmid; } static int __rmid_read_phys(u32 prmid, enum resctrl_event_id eventid, u64 *val) @@ -166,18 +161,14 @@ static struct arch_mbm_state *get_arch_mbm_state(struct rdt_hw_mon_domain *hw_do u32 rmid, enum resctrl_event_id eventid) { - switch (eventid) { - case QOS_L3_OCCUP_EVENT_ID: - return NULL; - case QOS_L3_MBM_TOTAL_EVENT_ID: - return &hw_dom->arch_mbm_total[rmid]; - case QOS_L3_MBM_LOCAL_EVENT_ID: - return &hw_dom->arch_mbm_local[rmid]; - default: - /* Never expect to get here */ - WARN_ON_ONCE(1); + struct arch_mbm_state *state; + + if (!resctrl_is_mbm_event(eventid)) return NULL; - } + + state = hw_dom->arch_mbm_states[MBM_STATE_IDX(eventid)]; + + return state ? &state[rmid] : NULL; } void resctrl_arch_reset_rmid(struct rdt_resource *r, struct rdt_mon_domain *d, @@ -206,14 +197,16 @@ void resctrl_arch_reset_rmid(struct rdt_resource *r, struct rdt_mon_domain *d, void resctrl_arch_reset_rmid_all(struct rdt_resource *r, struct rdt_mon_domain *d) { struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); - - if (resctrl_arch_is_mbm_total_enabled()) - memset(hw_dom->arch_mbm_total, 0, - sizeof(*hw_dom->arch_mbm_total) * r->num_rmid); - - if (resctrl_arch_is_mbm_local_enabled()) - memset(hw_dom->arch_mbm_local, 0, - sizeof(*hw_dom->arch_mbm_local) * r->num_rmid); + enum resctrl_event_id eventid; + int idx; + + for_each_mbm_event_id(eventid) { + if (!resctrl_is_mon_event_enabled(eventid)) + continue; + idx = MBM_STATE_IDX(eventid); + memset(hw_dom->arch_mbm_states[idx], 0, + sizeof(*hw_dom->arch_mbm_states[0]) * r->mon.num_rmid); + } } static u64 mbm_overflow_count(u64 prev_msr, u64 cur_msr, unsigned int width) @@ -224,15 +217,33 @@ static u64 mbm_overflow_count(u64 prev_msr, u64 cur_msr, unsigned int width) return chunks >> shift; } +static u64 get_corrected_val(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 rmid, enum resctrl_event_id eventid, u64 msr_val) +{ + struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); + struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); + struct arch_mbm_state *am; + u64 chunks; + + am = get_arch_mbm_state(hw_dom, rmid, eventid); + if (am) { + am->chunks += mbm_overflow_count(am->prev_msr, msr_val, + hw_res->mbm_width); + chunks = get_corrected_mbm_count(rmid, am->chunks); + am->prev_msr = msr_val; + } else { + chunks = msr_val; + } + + return chunks * hw_res->mon_scale; +} + int resctrl_arch_rmid_read(struct rdt_resource *r, struct rdt_mon_domain *d, u32 unused, u32 rmid, enum resctrl_event_id eventid, u64 *val, void *ignored) { - struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); - struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); int cpu = cpumask_any(&d->hdr.cpu_mask); - struct arch_mbm_state *am; - u64 msr_val, chunks; + u64 msr_val; u32 prmid; int ret; @@ -243,17 +254,76 @@ int resctrl_arch_rmid_read(struct rdt_resource *r, struct rdt_mon_domain *d, if (ret) return ret; + *val = get_corrected_val(r, d, rmid, eventid, msr_val); + + return 0; +} + +static int __cntr_id_read(u32 cntr_id, u64 *val) +{ + u64 msr_val; + + /* + * QM_EVTSEL Register definition: + * ======================================================= + * Bits Mnemonic Description + * ======================================================= + * 63:44 -- Reserved + * 43:32 RMID RMID or counter ID in ABMC mode + * when reading an MBM event + * 31 ExtendedEvtID Extended Event Identifier + * 30:8 -- Reserved + * 7:0 EvtID Event Identifier + * ======================================================= + * The contents of a specific counter can be read by setting the + * following fields in QM_EVTSEL.ExtendedEvtID(=1) and + * QM_EVTSEL.EvtID = L3CacheABMC (=1) and setting QM_EVTSEL.RMID + * to the desired counter ID. Reading the QM_CTR then returns the + * contents of the specified counter. The RMID_VAL_ERROR bit is set + * if the counter configuration is invalid, or if an invalid counter + * ID is set in the QM_EVTSEL.RMID field. The RMID_VAL_UNAVAIL bit + * is set if the counter data is unavailable. + */ + wrmsr(MSR_IA32_QM_EVTSEL, ABMC_EXTENDED_EVT_ID | ABMC_EVT_ID, cntr_id); + rdmsrl(MSR_IA32_QM_CTR, msr_val); + + if (msr_val & RMID_VAL_ERROR) + return -EIO; + if (msr_val & RMID_VAL_UNAVAIL) + return -EINVAL; + + *val = msr_val; + return 0; +} + +void resctrl_arch_reset_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 unused, u32 rmid, int cntr_id, + enum resctrl_event_id eventid) +{ + struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); + struct arch_mbm_state *am; + am = get_arch_mbm_state(hw_dom, rmid, eventid); if (am) { - am->chunks += mbm_overflow_count(am->prev_msr, msr_val, - hw_res->mbm_width); - chunks = get_corrected_mbm_count(rmid, am->chunks); - am->prev_msr = msr_val; - } else { - chunks = msr_val; + memset(am, 0, sizeof(*am)); + + /* Record any initial, non-zero count value. */ + __cntr_id_read(cntr_id, &am->prev_msr); } +} + +int resctrl_arch_cntr_read(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 unused, u32 rmid, int cntr_id, + enum resctrl_event_id eventid, u64 *val) +{ + u64 msr_val; + int ret; + + ret = __cntr_id_read(cntr_id, &msr_val); + if (ret) + return ret; - *val = chunks * hw_res->mon_scale; + *val = get_corrected_val(r, d, rmid, eventid, msr_val); return 0; } @@ -346,12 +416,13 @@ int __init rdt_get_mon_l3_config(struct rdt_resource *r) unsigned int mbm_offset = boot_cpu_data.x86_cache_mbm_width_offset; struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); unsigned int threshold; + u32 eax, ebx, ecx, edx; snc_nodes_per_l3_cache = snc_get_config(); resctrl_rmid_realloc_limit = boot_cpu_data.x86_cache_size * 1024; hw_res->mon_scale = boot_cpu_data.x86_cache_occ_scale / snc_nodes_per_l3_cache; - r->num_rmid = (boot_cpu_data.x86_cache_max_rmid + 1) / snc_nodes_per_l3_cache; + r->mon.num_rmid = (boot_cpu_data.x86_cache_max_rmid + 1) / snc_nodes_per_l3_cache; hw_res->mbm_width = MBM_CNTR_WIDTH_BASE; if (mbm_offset > 0 && mbm_offset <= MBM_CNTR_WIDTH_OFFSET_MAX) @@ -366,7 +437,7 @@ int __init rdt_get_mon_l3_config(struct rdt_resource *r) * * For a 35MB LLC and 56 RMIDs, this is ~1.8% of the LLC. */ - threshold = resctrl_rmid_realloc_limit / r->num_rmid; + threshold = resctrl_rmid_realloc_limit / r->mon.num_rmid; /* * Because num_rmid may not be a power of two, round the value @@ -375,12 +446,17 @@ int __init rdt_get_mon_l3_config(struct rdt_resource *r) */ resctrl_rmid_realloc_threshold = resctrl_arch_round_mon_val(threshold); - if (rdt_cpu_has(X86_FEATURE_BMEC)) { - u32 eax, ebx, ecx, edx; - + if (rdt_cpu_has(X86_FEATURE_BMEC) || rdt_cpu_has(X86_FEATURE_ABMC)) { /* Detect list of bandwidth sources that can be tracked */ cpuid_count(0x80000020, 3, &eax, &ebx, &ecx, &edx); - r->mbm_cfg_mask = ecx & MAX_EVT_CONFIG_BITS; + r->mon.mbm_cfg_mask = ecx & MAX_EVT_CONFIG_BITS; + } + + if (rdt_cpu_has(X86_FEATURE_ABMC)) { + r->mon.mbm_cntr_assignable = true; + cpuid_count(0x80000020, 5, &eax, &ebx, &ecx, &edx); + r->mon.num_mbm_cntrs = (ebx & GENMASK(15, 0)) + 1; + hw_res->mbm_cntr_assign_enabled = true; } r->mon_capable = true; @@ -401,3 +477,91 @@ void __init intel_rdt_mbm_apply_quirk(void) mbm_cf_rmidthreshold = mbm_cf_table[cf_index].rmidthreshold; mbm_cf = mbm_cf_table[cf_index].cf; } + +static void resctrl_abmc_set_one_amd(void *arg) +{ + bool *enable = arg; + + if (*enable) + msr_set_bit(MSR_IA32_L3_QOS_EXT_CFG, ABMC_ENABLE_BIT); + else + msr_clear_bit(MSR_IA32_L3_QOS_EXT_CFG, ABMC_ENABLE_BIT); +} + +/* + * ABMC enable/disable requires update of L3_QOS_EXT_CFG MSR on all the CPUs + * associated with all monitor domains. + */ +static void _resctrl_abmc_enable(struct rdt_resource *r, bool enable) +{ + struct rdt_mon_domain *d; + + lockdep_assert_cpus_held(); + + list_for_each_entry(d, &r->mon_domains, hdr.list) { + on_each_cpu_mask(&d->hdr.cpu_mask, resctrl_abmc_set_one_amd, + &enable, 1); + resctrl_arch_reset_rmid_all(r, d); + } +} + +int resctrl_arch_mbm_cntr_assign_set(struct rdt_resource *r, bool enable) +{ + struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); + + if (r->mon.mbm_cntr_assignable && + hw_res->mbm_cntr_assign_enabled != enable) { + _resctrl_abmc_enable(r, enable); + hw_res->mbm_cntr_assign_enabled = enable; + } + + return 0; +} + +bool resctrl_arch_mbm_cntr_assign_enabled(struct rdt_resource *r) +{ + return resctrl_to_arch_res(r)->mbm_cntr_assign_enabled; +} + +static void resctrl_abmc_config_one_amd(void *info) +{ + union l3_qos_abmc_cfg *abmc_cfg = info; + + wrmsrl(MSR_IA32_L3_QOS_ABMC_CFG, abmc_cfg->full); +} + +/* + * Send an IPI to the domain to assign the counter to RMID, event pair. + */ +void resctrl_arch_config_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + enum resctrl_event_id evtid, u32 rmid, u32 closid, + u32 cntr_id, bool assign) +{ + struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); + union l3_qos_abmc_cfg abmc_cfg = { 0 }; + struct arch_mbm_state *am; + + abmc_cfg.split.cfg_en = 1; + abmc_cfg.split.cntr_en = assign ? 1 : 0; + abmc_cfg.split.cntr_id = cntr_id; + abmc_cfg.split.bw_src = rmid; + if (assign) + abmc_cfg.split.bw_type = resctrl_get_mon_evt_cfg(evtid); + + smp_call_function_any(&d->hdr.cpu_mask, resctrl_abmc_config_one_amd, &abmc_cfg, 1); + + /* + * The hardware counter is reset (because cfg_en == 1) so there is no + * need to record initial non-zero counts. + */ + am = get_arch_mbm_state(hw_dom, rmid, evtid); + if (am) + memset(am, 0, sizeof(*am)); +} + +void resctrl_arch_mbm_cntr_assign_set_one(struct rdt_resource *r) +{ + struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); + + resctrl_abmc_set_one_amd(&hw_res->mbm_cntr_assign_enabled); +}\n\nindex 6b868afb26c319..4cee6213d66738 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/kernel/cpu/scattered.c b/arch/x86/kernel/cpu/scattered.cindex 6b868afb26c319..4cee6213d66738 100644--- a/ arch/x86/kernel/cpu/scattered.c +++ b/ arch/x86/kernel/cpu/scattered.c @@ -51,6 +51,7 @@ static const struct cpuid_bit cpuid_bits[] = { { X86_FEATURE_COHERENCY_SFW_NO, CPUID_EBX, 31, 0x8000001f, 0 }, { X86_FEATURE_SMBA, CPUID_EBX, 2, 0x80000020, 0 }, { X86_FEATURE_BMEC, CPUID_EBX, 3, 0x80000020, 0 }, + { X86_FEATURE_ABMC, CPUID_EBX, 5, 0x80000020, 0 }, { X86_FEATURE_TSA_SQ_NO, CPUID_ECX, 1, 0x80000021, 0 }, { X86_FEATURE_TSA_L1_NO, CPUID_ECX, 2, 0x80000021, 0 }, { X86_FEATURE_AMD_WORKLOAD_CLASS, CPUID_EAX, 22, 0x80000021, 0 },\n\nindex 3c39cfacb25183..0d0ef54fc4de1f 100644\n\n--- a/\n\n+++ b/ diff --git a/fs/resctrl/ctrlmondata.c b/fs/resctrl/ctrlmondata.cindex 3c39cfacb25183..0d0ef54fc4de1f 100644--- a/ fs/resctrl/ctrlmondata.c +++ b/ fs/resctrl/ctrlmondata.c @@ -473,12 +473,12 @@ ssize_t rdtgroup_mba_mbps_event_write(struct kernfs_open_file *of, rdt_last_cmd_clear(); if (!strcmp(buf, \"mbm_local_bytes\")) { - if (resctrl_arch_is_mbm_local_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) rdtgrp->mba_mbps_event = QOS_L3_MBM_LOCAL_EVENT_ID; else ret = -EINVAL; } else if (!strcmp(buf, \"mbm_total_bytes\")) { - if (resctrl_arch_is_mbm_total_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) rdtgrp->mba_mbps_event = QOS_L3_MBM_TOTAL_EVENT_ID; else ret = -EINVAL; @@ -563,10 +563,15 @@ void mon_event_read(struct rmid_read *rr, struct rdt_resource *r, rr->r = r; rr->d = d; rr->first = first; - rr->arch_mon_ctx = resctrl_arch_mon_ctx_alloc(r, evtid); - if (IS_ERR(rr->arch_mon_ctx)) { - rr->err = -EINVAL; - return; + if (resctrl_arch_mbm_cntr_assign_enabled(r) && + resctrl_is_mbm_event(evtid)) { + rr->is_mbm_cntr = true; + } else { + rr->arch_mon_ctx = resctrl_arch_mon_ctx_alloc(r, evtid); + if (IS_ERR(rr->arch_mon_ctx)) { + rr->err = -EINVAL; + return; + } } cpu = cpumask_any_housekeeping(cpumask, RESCTRL_PICK_ANY_CPU); @@ -582,7 +587,8 @@ void mon_event_read(struct rmid_read *rr, struct rdt_resource *r, else smp_call_on_cpu(cpu, smp_mon_event_count, rr, false); - resctrl_arch_mon_ctx_free(r, evtid, rr->arch_mon_ctx); + if (rr->arch_mon_ctx) + resctrl_arch_mon_ctx_free(r, evtid, rr->arch_mon_ctx); } int rdtgroup_mondata_show(struct seq_file *m, void *arg) @@ -653,10 +659,16 @@ int rdtgroup_mondata_show(struct seq_file *m, void *arg) checkresult: + /* + * -ENOENT is a special case, set only when \"mbm_event\" counter assignment + * mode is enabled and no counter has been assigned. + */ if (rr.err == -EIO) seq_puts(m, \"Error\n\n\"); else if (rr.err == -EINVAL) seq_puts(m, \"Unavailable\n\n\"); + else if (rr.err == -ENOENT) + seq_puts(m, \"Unassigned\n\n\"); else seq_printf(m, \"%llu\n\n\", rr.val);\n\nindex 9a8cf6f11151d9..cf1fd82dc5a99e 100644\n\n--- a/\n\n+++ b/ diff --git a/fs/resctrl/internal.h b/fs/resctrl/internal.hindex 9a8cf6f11151d9..cf1fd82dc5a99e 100644--- a/ fs/resctrl/internal.h +++ b/ fs/resctrl/internal.h @@ -52,19 +52,31 @@ static inline struct rdt_fs_context *rdt_fc2context(struct fs_context *fc) } /** - * struct mon_evt - Entry in the event list of a resource + * struct mon_evt - Properties of a monitor event * @evtid: event id + * @rid: resource id for this event * @name: name of the event + * @evt_cfg: Event configuration value that represents the + * memory transactions (e.g., READS_TO_LOCAL_MEM, + * READS_TO_REMOTE_MEM) being tracked by @evtid. + * Only valid if @evtid is an MBM event. * @configurable: true if the event is configurable - * @list: entry in &rdt_resource->evt_list + * @enabled: true if the event is enabled */ struct mon_evt { enum resctrl_event_id evtid; + enum resctrl_res_level rid; char *name; + u32 evt_cfg; bool configurable; - struct list_head list; + bool enabled; }; +extern struct mon_evt mon_event_all[QOS_NUM_EVENTS]; + +#define for_each_mon_event(mevt) for (mevt = &mon_event_all[QOS_FIRST_EVENT]; \\ + mevt < &mon_event_all[QOS_NUM_EVENTS]; mevt++) + /** * struct mon_data - Monitoring details for each event file. * @list: Member of the global @mon_data_kn_priv_list list. @@ -99,6 +111,8 @@ struct mon_data { * @evtid: Which monitor event to read. * @first: Initialize MBM counter when true. * @ci: Cacheinfo for L3. Only set when @d is NULL. Used when summing domains. + * @is_mbm_cntr: true if \"mbm_event\" counter assignment mode is enabled and it + * is an MBM event. * @err: Error encountered when reading counter. * @val: Returned value of event counter. If @rgrp is a parent resource group, * @val includes the sum of event counts from its child resource groups. @@ -113,6 +127,7 @@ struct rmid_read { enum resctrl_event_id evtid; bool first; struct cacheinfo *ci; + bool is_mbm_cntr; int err; u64 val; void *arch_mon_ctx; @@ -226,6 +241,8 @@ struct rdtgroup { #define RFTYPE_DEBUG BIT(10) +#define RFTYPE_ASSIGN_CONFIG BIT(11) + #define RFTYPE_CTRL_INFO (RFTYPE_INFO | RFTYPE_CTRL) #define RFTYPE_MON_INFO (RFTYPE_INFO | RFTYPE_MON) @@ -375,6 +392,41 @@ bool closid_allocated(unsigned int closid); int resctrl_find_cleanest_closid(void); +void *rdt_kn_parent_priv(struct kernfs_node *kn); + +int resctrl_mbm_assign_mode_show(struct kernfs_open_file *of, struct seq_file *s, void *v); + +ssize_t resctrl_mbm_assign_mode_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off); + +void resctrl_bmec_files_show(struct rdt_resource *r, struct kernfs_node *l3_mon_kn, + bool show); + +int resctrl_num_mbm_cntrs_show(struct kernfs_open_file *of, struct seq_file *s, void *v); + +int resctrl_available_mbm_cntrs_show(struct kernfs_open_file *of, struct seq_file *s, + void *v); + +void rdtgroup_assign_cntrs(struct rdtgroup *rdtgrp); + +void rdtgroup_unassign_cntrs(struct rdtgroup *rdtgrp); + +int event_filter_show(struct kernfs_open_file *of, struct seq_file *seq, void *v); + +ssize_t event_filter_write(struct kernfs_open_file *of, char *buf, size_t nbytes, + loff_t off); + +int resctrl_mbm_assign_on_mkdir_show(struct kernfs_open_file *of, + struct seq_file *s, void *v); + +ssize_t resctrl_mbm_assign_on_mkdir_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off); + +int mbm_L3_assignments_show(struct kernfs_open_file *of, struct seq_file *s, void *v); + +ssize_t mbm_L3_assignments_write(struct kernfs_open_file *of, char *buf, size_t nbytes, + loff_t off); + #ifdef CONFIG_RESCTRL_FS_PSEUDO_LOCK int rdtgroup_locksetup_enter(struct rdtgroup *rdtgrp);\n\nindex 7326c28a7908f3..4076336fbba6db 100644\n\n--- a/\n\n+++ b/ diff --git a/fs/resctrl/monitor.c b/fs/resctrl/monitor.cindex 7326c28a7908f3..4076336fbba6db 100644--- a/ fs/resctrl/monitor.c +++ b/ fs/resctrl/monitor.c @@ -336,7 +336,7 @@ void free_rmid(u32 closid, u32 rmid) entry = __rmid_entry(idx); - if (resctrl_arch_is_llc_occupancy_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) add_rmid_to_limbo(entry); else list_add_tail(&entry->list, &rmid_free_lru); @@ -346,27 +346,97 @@ static struct mbm_state *get_mbm_state(struct rdt_mon_domain *d, u32 closid, u32 rmid, enum resctrl_event_id evtid) { u32 idx = resctrl_arch_rmid_idx_encode(closid, rmid); + struct mbm_state *state; - switch (evtid) { - case QOS_L3_MBM_TOTAL_EVENT_ID: - return &d->mbm_total[idx]; - case QOS_L3_MBM_LOCAL_EVENT_ID: - return &d->mbm_local[idx]; - default: + if (!resctrl_is_mbm_event(evtid)) return NULL; + + state = d->mbm_states[MBM_STATE_IDX(evtid)]; + + return state ? &state[idx] : NULL; +} + +/* + * mbm_cntr_get() - Return the counter ID for the matching @evtid and @rdtgrp. + * + * Return: + * Valid counter ID on success, or -ENOENT on failure. + */ +static int mbm_cntr_get(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, enum resctrl_event_id evtid) +{ + int cntr_id; + + if (!r->mon.mbm_cntr_assignable) + return -ENOENT; + + if (!resctrl_is_mbm_event(evtid)) + return -ENOENT; + + for (cntr_id = 0; cntr_id < r->mon.num_mbm_cntrs; cntr_id++) { + if (d->cntr_cfg[cntr_id].rdtgrp == rdtgrp && + d->cntr_cfg[cntr_id].evtid == evtid) + return cntr_id; + } + + return -ENOENT; +} + +/* + * mbm_cntr_alloc() - Initialize and return a new counter ID in the domain @d. + * Caller must ensure that the specified event is not assigned already. + * + * Return: + * Valid counter ID on success, or -ENOSPC on failure. + */ +static int mbm_cntr_alloc(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, enum resctrl_event_id evtid) +{ + int cntr_id; + + for (cntr_id = 0; cntr_id < r->mon.num_mbm_cntrs; cntr_id++) { + if (!d->cntr_cfg[cntr_id].rdtgrp) { + d->cntr_cfg[cntr_id].rdtgrp = rdtgrp; + d->cntr_cfg[cntr_id].evtid = evtid; + return cntr_id; + } } + + return -ENOSPC; } -static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) +/* + * mbm_cntr_free() - Clear the counter ID configuration details in the domain @d. + */ +static void mbm_cntr_free(struct rdt_mon_domain *d, int cntr_id) +{ + memset(&d->cntr_cfg[cntr_id], 0, sizeof(*d->cntr_cfg)); +} + +static int __mon_event_count(struct rdtgroup *rdtgrp, struct rmid_read *rr) { int cpu = smp_processor_id(); + u32 closid = rdtgrp->closid; + u32 rmid = rdtgrp->mon.rmid; struct rdt_mon_domain *d; + int cntr_id = -ENOENT; struct mbm_state *m; int err, ret; u64 tval = 0; + if (rr->is_mbm_cntr) { + cntr_id = mbm_cntr_get(rr->r, rr->d, rdtgrp, rr->evtid); + if (cntr_id < 0) { + rr->err = -ENOENT; + return -EINVAL; + } + } + if (rr->first) { - resctrl_arch_reset_rmid(rr->r, rr->d, closid, rmid, rr->evtid); + if (rr->is_mbm_cntr) + resctrl_arch_reset_cntr(rr->r, rr->d, closid, rmid, cntr_id, rr->evtid); + else + resctrl_arch_reset_rmid(rr->r, rr->d, closid, rmid, rr->evtid); m = get_mbm_state(rr->d, closid, rmid, rr->evtid); if (m) memset(m, 0, sizeof(struct mbm_state)); @@ -377,8 +447,12 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) /* Reading a single domain, must be on a CPU in that domain. */ if (!cpumask_test_cpu(cpu, &rr->d->hdr.cpu_mask)) return -EINVAL; - rr->err = resctrl_arch_rmid_read(rr->r, rr->d, closid, rmid, - rr->evtid, &tval, rr->arch_mon_ctx); + if (rr->is_mbm_cntr) + rr->err = resctrl_arch_cntr_read(rr->r, rr->d, closid, rmid, cntr_id, + rr->evtid, &tval); + else + rr->err = resctrl_arch_rmid_read(rr->r, rr->d, closid, rmid, + rr->evtid, &tval, rr->arch_mon_ctx); if (rr->err) return rr->err; @@ -402,8 +476,12 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) list_for_each_entry(d, &rr->r->mon_domains, hdr.list) { if (d->ci_id != rr->ci->id) continue; - err = resctrl_arch_rmid_read(rr->r, d, closid, rmid, - rr->evtid, &tval, rr->arch_mon_ctx); + if (rr->is_mbm_cntr) + err = resctrl_arch_cntr_read(rr->r, d, closid, rmid, cntr_id, + rr->evtid, &tval); + else + err = resctrl_arch_rmid_read(rr->r, d, closid, rmid, + rr->evtid, &tval, rr->arch_mon_ctx); if (!err) { rr->val += tval; ret = 0; @@ -419,8 +497,8 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) /* * mbm_bw_count() - Update bw count from values previously read by * __mon_event_count(). - * @closid: The closid used to identify the cached mbm_state. - * @rmid: The rmid used to identify the cached mbm_state. + * @rdtgrp: resctrl group associated with the CLOSID and RMID to identify + * the cached mbm_state. * @rr: The struct rmid_read populated by __mon_event_count(). * * Supporting function to calculate the memory bandwidth @@ -428,9 +506,11 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) * __mon_event_count() is compared with the chunks value from the previous * invocation. This must be called once per second to maintain values in MBps. */ -static void mbm_bw_count(u32 closid, u32 rmid, struct rmid_read *rr) +static void mbm_bw_count(struct rdtgroup *rdtgrp, struct rmid_read *rr) { u64 cur_bw, bytes, cur_bytes; + u32 closid = rdtgrp->closid; + u32 rmid = rdtgrp->mon.rmid; struct mbm_state *m; m = get_mbm_state(rr->d, closid, rmid, rr->evtid); @@ -459,7 +539,7 @@ void mon_event_count(void *info) rdtgrp = rr->rgrp; - ret = __mon_event_count(rdtgrp->closid, rdtgrp->mon.rmid, rr); + ret = __mon_event_count(rdtgrp, rr); /* * For Ctrl groups read data from child monitor groups and @@ -470,8 +550,7 @@ void mon_event_count(void *info) if (rdtgrp->type == RDTCTRL_GROUP) { list_for_each_entry(entry, head, mon.crdtgrp_list) { - if (__mon_event_count(entry->closid, entry->mon.rmid, - rr) == 0) + if (__mon_event_count(entry, rr) == 0) ret = 0; } } @@ -602,44 +681,49 @@ static void update_mba_bw(struct rdtgroup *rgrp, struct rdt_mon_domain *dom_mbm) } static void mbm_update_one_event(struct rdt_resource *r, struct rdt_mon_domain *d, - u32 closid, u32 rmid, enum resctrl_event_id evtid) + struct rdtgroup *rdtgrp, enum resctrl_event_id evtid) { struct rmid_read rr = {0}; rr.r = r; rr.d = d; rr.evtid = evtid; - rr.arch_mon_ctx = resctrl_arch_mon_ctx_alloc(rr.r, rr.evtid); - if (IS_ERR(rr.arch_mon_ctx)) { - pr_warn_ratelimited(\"Failed to allocate monitor context: %ld\", - PTR_ERR(rr.arch_mon_ctx)); - return; + if (resctrl_arch_mbm_cntr_assign_enabled(r)) { + rr.is_mbm_cntr = true; + } else { + rr.arch_mon_ctx = resctrl_arch_mon_ctx_alloc(rr.r, rr.evtid); + if (IS_ERR(rr.arch_mon_ctx)) { + pr_warn_ratelimited(\"Failed to allocate monitor context: %ld\", + PTR_ERR(rr.arch_mon_ctx)); + return; + } } - __mon_event_count(closid, rmid, &rr); + __mon_event_count(rdtgrp, &rr); /* * If the software controller is enabled, compute the * bandwidth for this event id. */ if (is_mba_sc(NULL)) - mbm_bw_count(closid, rmid, &rr); + mbm_bw_count(rdtgrp, &rr); - resctrl_arch_mon_ctx_free(rr.r, rr.evtid, rr.arch_mon_ctx); + if (rr.arch_mon_ctx) + resctrl_arch_mon_ctx_free(rr.r, rr.evtid, rr.arch_mon_ctx); } static void mbm_update(struct rdt_resource *r, struct rdt_mon_domain *d, - u32 closid, u32 rmid) + struct rdtgroup *rdtgrp) { /* * This is protected from concurrent reads from user as both * the user and overflow handler hold the global mutex. */ - if (resctrl_arch_is_mbm_total_enabled()) - mbm_update_one_event(r, d, closid, rmid, QOS_L3_MBM_TOTAL_EVENT_ID); + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + mbm_update_one_event(r, d, rdtgrp, QOS_L3_MBM_TOTAL_EVENT_ID); - if (resctrl_arch_is_mbm_local_enabled()) - mbm_update_one_event(r, d, closid, rmid, QOS_L3_MBM_LOCAL_EVENT_ID); + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + mbm_update_one_event(r, d, rdtgrp, QOS_L3_MBM_LOCAL_EVENT_ID); } /* @@ -712,11 +796,11 @@ void mbm_handle_overflow(struct work_struct *work) d = container_of(work, struct rdt_mon_domain, mbm_over.work); list_for_each_entry(prgrp, &rdt_all_groups, rdtgroup_list) { - mbm_update(r, d, prgrp->closid, prgrp->mon.rmid); + mbm_update(r, d, prgrp); head = &prgrp->mon.crdtgrp_list; list_for_each_entry(crgrp, head, mon.crdtgrp_list) - mbm_update(r, d, crgrp->closid, crgrp->mon.rmid); + mbm_update(r, d, crgrp); if (is_mba_sc(NULL)) update_mba_bw(prgrp, d); @@ -842,38 +926,819 @@ out_unlock: mutex_unlock(&rdtgroup_mutex); } -static struct mon_evt llc_occupancy_event = { - .name = \"llc_occupancy\", - .evtid = QOS_L3_OCCUP_EVENT_ID, +/* + * All available events. Architecture code marks the ones that + * are supported by a system using resctrl_enable_mon_event() + * to set .enabled. + */ +struct mon_evt mon_event_all[QOS_NUM_EVENTS] = { + [QOS_L3_OCCUP_EVENT_ID] = { + .name = \"llc_occupancy\", + .evtid = QOS_L3_OCCUP_EVENT_ID, + .rid = RDT_RESOURCE_L3, + }, + [QOS_L3_MBM_TOTAL_EVENT_ID] = { + .name = \"mbm_total_bytes\", + .evtid = QOS_L3_MBM_TOTAL_EVENT_ID, + .rid = RDT_RESOURCE_L3, + }, + [QOS_L3_MBM_LOCAL_EVENT_ID] = { + .name = \"mbm_local_bytes\", + .evtid = QOS_L3_MBM_LOCAL_EVENT_ID, + .rid = RDT_RESOURCE_L3, + }, }; -static struct mon_evt mbm_total_event = { - .name = \"mbm_total_bytes\", - .evtid = QOS_L3_MBM_TOTAL_EVENT_ID, +void resctrl_enable_mon_event(enum resctrl_event_id eventid) +{ + if (WARN_ON_ONCE(eventid < QOS_FIRST_EVENT || eventid >= QOS_NUM_EVENTS)) + return; + if (mon_event_all[eventid].enabled) { + pr_warn(\"Duplicate enable for event %d\n\n\", eventid); + return; + } + + mon_event_all[eventid].enabled = true; +} + +bool resctrl_is_mon_event_enabled(enum resctrl_event_id eventid) +{ + return eventid >= QOS_FIRST_EVENT && eventid < QOS_NUM_EVENTS && + mon_event_all[eventid].enabled; +} + +u32 resctrl_get_mon_evt_cfg(enum resctrl_event_id evtid) +{ + return mon_event_all[evtid].evt_cfg; +} + +/** + * struct mbm_transaction - Memory transaction an MBM event can be configured with. + * @name: Name of memory transaction (read, write ...). + * @val: The bit (eg. READS_TO_LOCAL_MEM or READS_TO_REMOTE_MEM) used to + * represent the memory transaction within an event's configuration. + */ +struct mbm_transaction { + char name[32]; + u32 val; }; -static struct mon_evt mbm_local_event = { - .name = \"mbm_local_bytes\", - .evtid = QOS_L3_MBM_LOCAL_EVENT_ID, +/* Decoded values for each type of memory transaction. */ +static struct mbm_transaction mbm_transactions[NUM_MBM_TRANSACTIONS] = { + {\"local_reads\", READS_TO_LOCAL_MEM}, + {\"remote_reads\", READS_TO_REMOTE_MEM}, + {\"local_non_temporal_writes\", NON_TEMP_WRITE_TO_LOCAL_MEM}, + {\"remote_non_temporal_writes\", NON_TEMP_WRITE_TO_REMOTE_MEM}, + {\"local_reads_slow_memory\", READS_TO_LOCAL_S_MEM}, + {\"remote_reads_slow_memory\", READS_TO_REMOTE_S_MEM}, + {\"dirty_victim_writes_all\", DIRTY_VICTIMS_TO_ALL_MEM}, }; +int event_filter_show(struct kernfs_open_file *of, struct seq_file *seq, void *v) +{ + struct mon_evt *mevt = rdt_kn_parent_priv(of->kn); + struct rdt_resource *r; + bool sep = false; + int ret = 0, i; + + mutex_lock(&rdtgroup_mutex); + rdt_last_cmd_clear(); + + r = resctrl_arch_get_resource(mevt->rid); + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + for (i = 0; i < NUM_MBM_TRANSACTIONS; i++) { + if (mevt->evt_cfg & mbm_transactions[i].val) { + if (sep) + seq_putc(seq, ','); + seq_printf(seq, \"%s\", mbm_transactions[i].name); + sep = true; + } + } + seq_putc(seq, '\n\n'); + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + + return ret; +} + +int resctrl_mbm_assign_on_mkdir_show(struct kernfs_open_file *of, struct seq_file *s, + void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + int ret = 0; + + mutex_lock(&rdtgroup_mutex); + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + seq_printf(s, \"%u\n\n\", r->mon.mbm_assign_on_mkdir); + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + + return ret; +} + +ssize_t resctrl_mbm_assign_on_mkdir_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + bool value; + int ret; + + ret = kstrtobool(buf, &value); + if (ret) + return ret; + + mutex_lock(&rdtgroup_mutex); + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + r->mon.mbm_assign_on_mkdir = value; + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + + return ret ?: nbytes; +} + +/* + * mbm_cntr_free_all() - Clear all the counter ID configuration details in the + * domain @d. Called when mbm_assign_mode is changed. + */ +static void mbm_cntr_free_all(struct rdt_resource *r, struct rdt_mon_domain *d) +{ + memset(d->cntr_cfg, 0, sizeof(*d->cntr_cfg) * r->mon.num_mbm_cntrs); +} + +/* + * resctrl_reset_rmid_all() - Reset all non-architecture states for all the + * supported RMIDs. + */ +static void resctrl_reset_rmid_all(struct rdt_resource *r, struct rdt_mon_domain *d) +{ + u32 idx_limit = resctrl_arch_system_num_rmid_idx(); + enum resctrl_event_id evt; + int idx; + + for_each_mbm_event_id(evt) { + if (!resctrl_is_mon_event_enabled(evt)) + continue; + idx = MBM_STATE_IDX(evt); + memset(d->mbm_states[idx], 0, sizeof(*d->mbm_states[0]) * idx_limit); + } +} + +/* + * rdtgroup_assign_cntr() - Assign/unassign the counter ID for the event, RMID + * pair in the domain. + * + * Assign the counter if @assign is true else unassign the counter. Reset the + * associated non-architectural state. + */ +static void rdtgroup_assign_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + enum resctrl_event_id evtid, u32 rmid, u32 closid, + u32 cntr_id, bool assign) +{ + struct mbm_state *m; + + resctrl_arch_config_cntr(r, d, evtid, rmid, closid, cntr_id, assign); + + m = get_mbm_state(d, closid, rmid, evtid); + if (m) + memset(m, 0, sizeof(*m)); +} + +/* + * rdtgroup_alloc_assign_cntr() - Allocate a counter ID and assign it to the event + * pointed to by @mevt and the resctrl group @rdtgrp within the domain @d. + * + * Return: + * 0 on success, < 0 on failure. + */ +static int rdtgroup_alloc_assign_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, struct mon_evt *mevt) +{ + int cntr_id; + + /* No action required if the counter is assigned already. */ + cntr_id = mbm_cntr_get(r, d, rdtgrp, mevt->evtid); + if (cntr_id >= 0) + return 0; + + cntr_id = mbm_cntr_alloc(r, d, rdtgrp, mevt->evtid); + if (cntr_id < 0) { + rdt_last_cmd_printf(\"Failed to allocate counter for %s in domain %d\n\n\", + mevt->name, d->hdr.id); + return cntr_id; + } + + rdtgroup_assign_cntr(r, d, mevt->evtid, rdtgrp->mon.rmid, rdtgrp->closid, cntr_id, true); + + return 0; +} + /* - * Initialize the event list for the resource. + * rdtgroup_assign_cntr_event() - Assign a hardware counter for the event in + * @mevt to the resctrl group @rdtgrp. Assign counters to all domains if @d is + * NULL; otherwise, assign the counter to the specified domain @d. + * + * If all counters in a domain are already in use, rdtgroup_alloc_assign_cntr() + * will fail. The assignment process will abort at the first failure encountered + * during domain traversal, which may result in the event being only partially + * assigned. * - * Note that MBM events are also part of RDT_RESOURCE_L3 resource - * because as per the SDM the total and local memory bandwidth - * are enumerated as part of L3 monitoring. + * Return: + * 0 on success, < 0 on failure. + */ +static int rdtgroup_assign_cntr_event(struct rdt_mon_domain *d, struct rdtgroup *rdtgrp, + struct mon_evt *mevt) +{ + struct rdt_resource *r = resctrl_arch_get_resource(mevt->rid); + int ret = 0; + + if (!d) { + list_for_each_entry(d, &r->mon_domains, hdr.list) { + ret = rdtgroup_alloc_assign_cntr(r, d, rdtgrp, mevt); + if (ret) + return ret; + } + } else { + ret = rdtgroup_alloc_assign_cntr(r, d, rdtgrp, mevt); + } + + return ret; +} + +/* + * rdtgroup_assign_cntrs() - Assign counters to MBM events. Called when + * a new group is created. + * + * Each group can accommodate two counters per domain: one for the total + * event and one for the local event. Assignments may fail due to the limited + * number of counters. However, it is not necessary to fail the group creation + * and thus no failure is returned. Users have the option to modify the + * counter assignments after the group has been created. + */ +void rdtgroup_assign_cntrs(struct rdtgroup *rdtgrp) +{ + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); + + if (!r->mon_capable || !resctrl_arch_mbm_cntr_assign_enabled(r) || + !r->mon.mbm_assign_on_mkdir) + return; + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + rdtgroup_assign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID]); + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + rdtgroup_assign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID]); +} + +/* + * rdtgroup_free_unassign_cntr() - Unassign and reset the counter ID configuration + * for the event pointed to by @mevt within the domain @d and resctrl group @rdtgrp. + */ +static void rdtgroup_free_unassign_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, struct mon_evt *mevt) +{ + int cntr_id; + + cntr_id = mbm_cntr_get(r, d, rdtgrp, mevt->evtid); + + /* If there is no cntr_id assigned, nothing to do */ + if (cntr_id < 0) + return; + + rdtgroup_assign_cntr(r, d, mevt->evtid, rdtgrp->mon.rmid, rdtgrp->closid, cntr_id, false); + + mbm_cntr_free(d, cntr_id); +} + +/* + * rdtgroup_unassign_cntr_event() - Unassign a hardware counter associated with + * the event structure @mevt from the domain @d and the group @rdtgrp. Unassign + * the counters from all the domains if @d is NULL else unassign from @d. + */ +static void rdtgroup_unassign_cntr_event(struct rdt_mon_domain *d, struct rdtgroup *rdtgrp, + struct mon_evt *mevt) +{ + struct rdt_resource *r = resctrl_arch_get_resource(mevt->rid); + + if (!d) { + list_for_each_entry(d, &r->mon_domains, hdr.list) + rdtgroup_free_unassign_cntr(r, d, rdtgrp, mevt); + } else { + rdtgroup_free_unassign_cntr(r, d, rdtgrp, mevt); + } +} + +/* + * rdtgroup_unassign_cntrs() - Unassign the counters associated with MBM events. + * Called when a group is deleted. */ -static void l3_mon_evt_init(struct rdt_resource *r) +void rdtgroup_unassign_cntrs(struct rdtgroup *rdtgrp) { - INIT_LIST_HEAD(&r->evt_list); + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); - if (resctrl_arch_is_llc_occupancy_enabled()) - list_add_tail(&llc_occupancy_event.list, &r->evt_list); - if (resctrl_arch_is_mbm_total_enabled()) - list_add_tail(&mbm_total_event.list, &r->evt_list); - if (resctrl_arch_is_mbm_local_enabled()) - list_add_tail(&mbm_local_event.list, &r->evt_list); + if (!r->mon_capable || !resctrl_arch_mbm_cntr_assign_enabled(r)) + return; + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + rdtgroup_unassign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID]); + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + rdtgroup_unassign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID]); +} + +static int resctrl_parse_mem_transactions(char *tok, u32 *val) +{ + u32 temp_val = 0; + char *evt_str; + bool found; + int i; + +next_config: + if (!tok || tok[0] == '\\0') { + *val = temp_val; + return 0; + } + + /* Start processing the strings for each memory transaction type */ + evt_str = strim(strsep(&tok, \",\")); + found = false; + for (i = 0; i < NUM_MBM_TRANSACTIONS; i++) { + if (!strcmp(mbm_transactions[i].name, evt_str)) { + temp_val |= mbm_transactions[i].val; + found = true; + break; + } + } + + if (!found) { + rdt_last_cmd_printf(\"Invalid memory transaction type %s\n\n\", evt_str); + return -EINVAL; + } + + goto next_config; +} + +/* + * rdtgroup_update_cntr_event - Update the counter assignments for the event + * in a group. + * @r: Resource to which update needs to be done. + * @rdtgrp: Resctrl group. + * @evtid: MBM monitor event. + */ +static void rdtgroup_update_cntr_event(struct rdt_resource *r, struct rdtgroup *rdtgrp, + enum resctrl_event_id evtid) +{ + struct rdt_mon_domain *d; + int cntr_id; + + list_for_each_entry(d, &r->mon_domains, hdr.list) { + cntr_id = mbm_cntr_get(r, d, rdtgrp, evtid); + if (cntr_id >= 0) + rdtgroup_assign_cntr(r, d, evtid, rdtgrp->mon.rmid, + rdtgrp->closid, cntr_id, true); + } +} + +/* + * resctrl_update_cntr_allrdtgrp - Update the counter assignments for the event + * for all the groups. + * @mevt MBM Monitor event. + */ +static void resctrl_update_cntr_allrdtgrp(struct mon_evt *mevt) +{ + struct rdt_resource *r = resctrl_arch_get_resource(mevt->rid); + struct rdtgroup *prgrp, *crgrp; + + /* + * Find all the groups where the event is assigned and update the + * configuration of existing assignments. + */ + list_for_each_entry(prgrp, &rdt_all_groups, rdtgroup_list) { + rdtgroup_update_cntr_event(r, prgrp, mevt->evtid); + + list_for_each_entry(crgrp, &prgrp->mon.crdtgrp_list, mon.crdtgrp_list) + rdtgroup_update_cntr_event(r, crgrp, mevt->evtid); + } +} + +ssize_t event_filter_write(struct kernfs_open_file *of, char *buf, size_t nbytes, + loff_t off) +{ + struct mon_evt *mevt = rdt_kn_parent_priv(of->kn); + struct rdt_resource *r; + u32 evt_cfg = 0; + int ret = 0; + + /* Valid input requires a trailing newline */ + if (nbytes == 0 || buf[nbytes - 1] != '\n\n') + return -EINVAL; + + buf[nbytes - 1] = '\\0'; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + rdt_last_cmd_clear(); + + r = resctrl_arch_get_resource(mevt->rid); + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + ret = resctrl_parse_mem_transactions(buf, &evt_cfg); + if (!ret && mevt->evt_cfg != evt_cfg) { + mevt->evt_cfg = evt_cfg; + resctrl_update_cntr_allrdtgrp(mevt); + } + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + + return ret ?: nbytes; +} + +int resctrl_mbm_assign_mode_show(struct kernfs_open_file *of, + struct seq_file *s, void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + bool enabled; + + mutex_lock(&rdtgroup_mutex); + enabled = resctrl_arch_mbm_cntr_assign_enabled(r); + + if (r->mon.mbm_cntr_assignable) { + if (enabled) + seq_puts(s, \"[mbm_event]\n\n\"); + else + seq_puts(s, \"[default]\n\n\"); + + if (!IS_ENABLED(CONFIG_RESCTRL_ASSIGN_FIXED)) { + if (enabled) + seq_puts(s, \"default\n\n\"); + else + seq_puts(s, \"mbm_event\n\n\"); + } + } else { + seq_puts(s, \"[default]\n\n\"); + } + + mutex_unlock(&rdtgroup_mutex); + + return 0; +} + +ssize_t resctrl_mbm_assign_mode_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + struct rdt_mon_domain *d; + int ret = 0; + bool enable; + + /* Valid input requires a trailing newline */ + if (nbytes == 0 || buf[nbytes - 1] != '\n\n') + return -EINVAL; + + buf[nbytes - 1] = '\\0'; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + rdt_last_cmd_clear(); + + if (!strcmp(buf, \"default\")) { + enable = 0; + } else if (!strcmp(buf, \"mbm_event\")) { + if (r->mon.mbm_cntr_assignable) { + enable = 1; + } else { + ret = -EINVAL; + rdt_last_cmd_puts(\"mbm_event mode is not supported\n\n\"); + goto out_unlock; + } + } else { + ret = -EINVAL; + rdt_last_cmd_puts(\"Unsupported assign mode\n\n\"); + goto out_unlock; + } + + if (enable != resctrl_arch_mbm_cntr_assign_enabled(r)) { + ret = resctrl_arch_mbm_cntr_assign_set(r, enable); + if (ret) + goto out_unlock; + + /* Update the visibility of BMEC related files */ + resctrl_bmec_files_show(r, NULL, !enable); + + /* + * Initialize the default memory transaction values for + * total and local events. + */ + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask; + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask & + (READS_TO_LOCAL_MEM | + READS_TO_LOCAL_S_MEM | + NON_TEMP_WRITE_TO_LOCAL_MEM); + /* Enable auto assignment when switching to \"mbm_event\" mode */ + if (enable) + r->mon.mbm_assign_on_mkdir = true; + /* + * Reset all the non-achitectural RMID state and assignable counters. + */ + list_for_each_entry(d, &r->mon_domains, hdr.list) { + mbm_cntr_free_all(r, d); + resctrl_reset_rmid_all(r, d); + } + } + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + + return ret ?: nbytes; +} + +int resctrl_num_mbm_cntrs_show(struct kernfs_open_file *of, + struct seq_file *s, void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + struct rdt_mon_domain *dom; + bool sep = false; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + list_for_each_entry(dom, &r->mon_domains, hdr.list) { + if (sep) + seq_putc(s, ';'); + + seq_printf(s, \"%d=%d\", dom->hdr.id, r->mon.num_mbm_cntrs); + sep = true; + } + seq_putc(s, '\n\n'); + + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + return 0; +} + +int resctrl_available_mbm_cntrs_show(struct kernfs_open_file *of, + struct seq_file *s, void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + struct rdt_mon_domain *dom; + bool sep = false; + u32 cntrs, i; + int ret = 0; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + list_for_each_entry(dom, &r->mon_domains, hdr.list) { + if (sep) + seq_putc(s, ';'); + + cntrs = 0; + for (i = 0; i < r->mon.num_mbm_cntrs; i++) { + if (!dom->cntr_cfg[i].rdtgrp) + cntrs++; + } + + seq_printf(s, \"%d=%u\", dom->hdr.id, cntrs); + sep = true; + } + seq_putc(s, '\n\n'); + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + + return ret; +} + +int mbm_L3_assignments_show(struct kernfs_open_file *of, struct seq_file *s, void *v) +{ + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); + struct rdt_mon_domain *d; + struct rdtgroup *rdtgrp; + struct mon_evt *mevt; + int ret = 0; + bool sep; + + rdtgrp = rdtgroup_kn_lock_live(of->kn); + if (!rdtgrp) { + ret = -ENOENT; + goto out_unlock; + } + + rdt_last_cmd_clear(); + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled || !resctrl_is_mbm_event(mevt->evtid)) + continue; + + sep = false; + seq_printf(s, \"%s:\", mevt->name); + list_for_each_entry(d, &r->mon_domains, hdr.list) { + if (sep) + seq_putc(s, ';'); + + if (mbm_cntr_get(r, d, rdtgrp, mevt->evtid) < 0) + seq_printf(s, \"%d=_\", d->hdr.id); + else + seq_printf(s, \"%d=e\", d->hdr.id); + + sep = true; + } + seq_putc(s, '\n\n'); + } + +out_unlock: + rdtgroup_kn_unlock(of->kn); + + return ret; +} + +/* + * mbm_get_mon_event_by_name() - Return the mon_evt entry for the matching + * event name. + */ +static struct mon_evt *mbm_get_mon_event_by_name(struct rdt_resource *r, char *name) +{ + struct mon_evt *mevt; + + for_each_mon_event(mevt) { + if (mevt->rid == r->rid && mevt->enabled && + resctrl_is_mbm_event(mevt->evtid) && + !strcmp(mevt->name, name)) + return mevt; + } + + return NULL; +} + +static int rdtgroup_modify_assign_state(char *assign, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, struct mon_evt *mevt) +{ + int ret = 0; + + if (!assign || strlen(assign) != 1) + return -EINVAL; + + switch (*assign) { + case 'e': + ret = rdtgroup_assign_cntr_event(d, rdtgrp, mevt); + break; + case '_': + rdtgroup_unassign_cntr_event(d, rdtgrp, mevt); + break; + default: + ret = -EINVAL; + break; + } + + return ret; +} + +static int resctrl_parse_mbm_assignment(struct rdt_resource *r, struct rdtgroup *rdtgrp, + char *event, char *tok) +{ + struct rdt_mon_domain *d; + unsigned long dom_id = 0; + char *dom_str, *id_str; + struct mon_evt *mevt; + int ret; + + mevt = mbm_get_mon_event_by_name(r, event); + if (!mevt) { + rdt_last_cmd_printf(\"Invalid event %s\n\n\", event); + return -ENOENT; + } + +next: + if (!tok || tok[0] == '\\0') + return 0; + + /* Start processing the strings for each domain */ + dom_str = strim(strsep(&tok, \";\")); + + id_str = strsep(&dom_str, \"=\"); + + /* Check for domain id '*' which means all domains */ + if (id_str && *id_str == '*') { + ret = rdtgroup_modify_assign_state(dom_str, NULL, rdtgrp, mevt); + if (ret) + rdt_last_cmd_printf(\"Assign operation '%s:*=%s' failed\n\n\", + event, dom_str); + return ret; + } else if (!id_str || kstrtoul(id_str, 10, &dom_id)) { + rdt_last_cmd_puts(\"Missing domain id\n\n\"); + return -EINVAL; + } + + /* Verify if the dom_id is valid */ + list_for_each_entry(d, &r->mon_domains, hdr.list) { + if (d->hdr.id == dom_id) { + ret = rdtgroup_modify_assign_state(dom_str, d, rdtgrp, mevt); + if (ret) { + rdt_last_cmd_printf(\"Assign operation '%s:%ld=%s' failed\n\n\", + event, dom_id, dom_str); + return ret; + } + goto next; + } + } + + rdt_last_cmd_printf(\"Invalid domain id %ld\n\n\", dom_id); + return -EINVAL; +} + +ssize_t mbm_L3_assignments_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off) +{ + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); + struct rdtgroup *rdtgrp; + char *token, *event; + int ret = 0; + + /* Valid input requires a trailing newline */ + if (nbytes == 0 || buf[nbytes - 1] != '\n\n') + return -EINVAL; + + buf[nbytes - 1] = '\\0'; + + rdtgrp = rdtgroup_kn_lock_live(of->kn); + if (!rdtgrp) { + rdtgroup_kn_unlock(of->kn); + return -ENOENT; + } + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event mode is not enabled\n\n\"); + rdtgroup_kn_unlock(of->kn); + return -EINVAL; + } + + while ((token = strsep(&buf, \"\n\n\")) != NULL) { + /* + * The write command follows the following format: + * \"<Event>:<Domain ID>=<Assignment state>\" + * Extract the event name first. + */ + event = strsep(&token, \":\"); + + ret = resctrl_parse_mbm_assignment(r, rdtgrp, event, token); + if (ret) + break; + } + + rdtgroup_kn_unlock(of->kn); + + return ret ?: nbytes; } /** @@ -900,24 +1765,43 @@ int resctrl_mon_resource_init(void) if (ret) return ret; - l3_mon_evt_init(r); - if (resctrl_arch_is_evt_configurable(QOS_L3_MBM_TOTAL_EVENT_ID)) { - mbm_total_event.configurable = true; + mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID].configurable = true; resctrl_file_fflags_init(\"mbm_total_bytes_config\", RFTYPE_MON_INFO | RFTYPE_RES_CACHE); } if (resctrl_arch_is_evt_configurable(QOS_L3_MBM_LOCAL_EVENT_ID)) { - mbm_local_event.configurable = true; + mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID].configurable = true; resctrl_file_fflags_init(\"mbm_local_bytes_config\", RFTYPE_MON_INFO | RFTYPE_RES_CACHE); } - if (resctrl_arch_is_mbm_local_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) mba_mbps_default_event = QOS_L3_MBM_LOCAL_EVENT_ID; - else if (resctrl_arch_is_mbm_total_enabled()) + else if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) mba_mbps_default_event = QOS_L3_MBM_TOTAL_EVENT_ID; + if (r->mon.mbm_cntr_assignable) { + if (!resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + resctrl_enable_mon_event(QOS_L3_MBM_TOTAL_EVENT_ID); + if (!resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + resctrl_enable_mon_event(QOS_L3_MBM_LOCAL_EVENT_ID); + mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask; + mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask & + (READS_TO_LOCAL_MEM | + READS_TO_LOCAL_S_MEM | + NON_TEMP_WRITE_TO_LOCAL_MEM); + r->mon.mbm_assign_on_mkdir = true; + resctrl_file_fflags_init(\"num_mbm_cntrs\", + RFTYPE_MON_INFO | RFTYPE_RES_CACHE); + resctrl_file_fflags_init(\"available_mbm_cntrs\", + RFTYPE_MON_INFO | RFTYPE_RES_CACHE); + resctrl_file_fflags_init(\"event_filter\", RFTYPE_ASSIGN_CONFIG); + resctrl_file_fflags_init(\"mbm_assign_on_mkdir\", RFTYPE_MON_INFO | + RFTYPE_RES_CACHE); + resctrl_file_fflags_init(\"mbm_L3_assignments\", RFTYPE_MON_BASE); + } + return 0; }\n\nindex 77d08229d85502..0320360cd7a6eb 100644\n\n--- a/\n\n+++ b/ diff --git a/fs/resctrl/rdtgroup.c b/fs/resctrl/rdtgroup.cindex 77d08229d85502..0320360cd7a6eb 100644--- a/ fs/resctrl/rdtgroup.c +++ b/ fs/resctrl/rdtgroup.c @@ -123,14 +123,8 @@ void rdt_staged_configs_clear(void) static bool resctrl_is_mbm_enabled(void) { - return (resctrl_arch_is_mbm_total_enabled() || - resctrl_arch_is_mbm_local_enabled()); -} - -static bool resctrl_is_mbm_event(int e) -{ - return (e >= QOS_L3_MBM_TOTAL_EVENT_ID && - e <= QOS_L3_MBM_LOCAL_EVENT_ID); + return (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID) || + resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)); } /* @@ -196,7 +190,7 @@ static int closid_alloc(void) lockdep_assert_held(&rdtgroup_mutex); if (IS_ENABLED(CONFIG_RESCTRL_RMID_DEPENDS_ON_CLOSID) && - resctrl_arch_is_llc_occupancy_enabled()) { + resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) { cleanest_closid = resctrl_find_cleanest_closid(); if (cleanest_closid < 0) return cleanest_closid; @@ -981,7 +975,7 @@ static int rdt_last_cmd_status_show(struct kernfs_open_file *of, return 0; } -static void *rdt_kn_parent_priv(struct kernfs_node *kn) +void *rdt_kn_parent_priv(struct kernfs_node *kn) { /* * The parent pointer is only valid within RCU section since it can be @@ -1141,7 +1135,7 @@ static int rdt_num_rmids_show(struct kernfs_open_file *of, { struct rdt_resource *r = rdt_kn_parent_priv(of->kn); - seq_printf(seq, \"%d\n\n\", r->num_rmid); + seq_printf(seq, \"%d\n\n\", r->mon.num_rmid); return 0; } @@ -1152,9 +1146,12 @@ static int rdt_mon_features_show(struct kernfs_open_file *of, struct rdt_resource *r = rdt_kn_parent_priv(of->kn); struct mon_evt *mevt; - list_for_each_entry(mevt, &r->evt_list, list) { + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled) + continue; seq_printf(seq, \"%s\n\n\", mevt->name); - if (mevt->configurable) + if (mevt->configurable && + !resctrl_arch_mbm_cntr_assign_enabled(r)) seq_printf(seq, \"%s_config\n\n\", mevt->name); } @@ -1735,9 +1732,9 @@ next: } /* Value from user cannot be more than the supported set of events */ - if ((val & r->mbm_cfg_mask) != val) { + if ((val & r->mon.mbm_cfg_mask) != val) { rdt_last_cmd_printf(\"Invalid event configuration: max valid mask is 0x%02x\n\n\", - r->mbm_cfg_mask); + r->mon.mbm_cfg_mask); return -EINVAL; } @@ -1803,6 +1800,44 @@ static ssize_t mbm_local_bytes_config_write(struct kernfs_open_file *of, return ret ?: nbytes; } +/* + * resctrl_bmec_files_show() — Controls the visibility of BMEC-related resctrl + * files. When @show is true, the files are displayed; when false, the files + * are hidden. + * Don't treat kernfs_find_and_get failure as an error, since this function may + * be called regardless of whether BMEC is supported or the event is enabled. + */ +void resctrl_bmec_files_show(struct rdt_resource *r, struct kernfs_node *l3_mon_kn, + bool show) +{ + struct kernfs_node *kn_config, *mon_kn = NULL; + char name[32]; + + if (!l3_mon_kn) { + sprintf(name, \"%s_MON\", r->name); + mon_kn = kernfs_find_and_get(kn_info, name); + if (!mon_kn) + return; + l3_mon_kn = mon_kn; + } + + kn_config = kernfs_find_and_get(l3_mon_kn, \"mbm_total_bytes_config\"); + if (kn_config) { + kernfs_show(kn_config, show); + kernfs_put(kn_config); + } + + kn_config = kernfs_find_and_get(l3_mon_kn, \"mbm_local_bytes_config\"); + if (kn_config) { + kernfs_show(kn_config, show); + kernfs_put(kn_config); + } + + /* Release the reference only if it was acquired */ + if (mon_kn) + kernfs_put(mon_kn); +} + /* rdtgroup information files for one cache resource. */ static struct rftype res_common_files[] = { { @@ -1813,6 +1848,13 @@ static struct rftype res_common_files[] = { .fflags = RFTYPE_TOP_INFO, }, { + .name = \"mbm_assign_on_mkdir\", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_mbm_assign_on_mkdir_show, + .write = resctrl_mbm_assign_on_mkdir_write, + }, + { .name = \"num_closids\", .mode = 0444, .kf_ops = &rdtgroup_kf_single_ops, @@ -1827,6 +1869,12 @@ static struct rftype res_common_files[] = { .fflags = RFTYPE_MON_INFO, }, { + .name = \"available_mbm_cntrs\", + .mode = 0444, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_available_mbm_cntrs_show, + }, + { .name = \"num_rmids\", .mode = 0444, .kf_ops = &rdtgroup_kf_single_ops, @@ -1841,6 +1889,12 @@ static struct rftype res_common_files[] = { .fflags = RFTYPE_CTRL_INFO | RFTYPE_RES_CACHE, }, { + .name = \"num_mbm_cntrs\", + .mode = 0444, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_num_mbm_cntrs_show, + }, + { .name = \"min_cbm_bits\", .mode = 0444, .kf_ops = &rdtgroup_kf_single_ops, @@ -1916,6 +1970,28 @@ static struct rftype res_common_files[] = { .write = mbm_local_bytes_config_write, }, { + .name = \"event_filter\", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = event_filter_show, + .write = event_filter_write, + }, + { + .name = \"mbm_L3_assignments\", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = mbm_L3_assignments_show, + .write = mbm_L3_assignments_write, + }, + { + .name = \"mbm_assign_mode\", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_mbm_assign_mode_show, + .write = resctrl_mbm_assign_mode_write, + .fflags = RFTYPE_MON_INFO | RFTYPE_RES_CACHE, + }, + { .name = \"cpus\", .mode = 0644, .kf_ops = &rdtgroup_kf_single_ops, @@ -2168,10 +2244,48 @@ int rdtgroup_kn_mode_restore(struct rdtgroup *r, const char *name, return ret; } +static int resctrl_mkdir_event_configs(struct rdt_resource *r, struct kernfs_node *l3_mon_kn) +{ + struct kernfs_node *kn_subdir, *kn_subdir2; + struct mon_evt *mevt; + int ret; + + kn_subdir = kernfs_create_dir(l3_mon_kn, \"event_configs\", l3_mon_kn->mode, NULL); + if (IS_ERR(kn_subdir)) + return PTR_ERR(kn_subdir); + + ret = rdtgroup_kn_set_ugid(kn_subdir); + if (ret) + return ret; + + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled || !resctrl_is_mbm_event(mevt->evtid)) + continue; + + kn_subdir2 = kernfs_create_dir(kn_subdir, mevt->name, kn_subdir->mode, mevt); + if (IS_ERR(kn_subdir2)) { + ret = PTR_ERR(kn_subdir2); + goto out; + } + + ret = rdtgroup_kn_set_ugid(kn_subdir2); + if (ret) + goto out; + + ret = rdtgroup_add_files(kn_subdir2, RFTYPE_ASSIGN_CONFIG); + if (ret) + break; + } + +out: + return ret; +} + static int rdtgroup_mkdir_info_resdir(void *priv, char *name, unsigned long fflags) { struct kernfs_node *kn_subdir; + struct rdt_resource *r; int ret; kn_subdir = kernfs_create_dir(kn_info, name, @@ -2184,8 +2298,25 @@ static int rdtgroup_mkdir_info_resdir(void *priv, char *name, return ret; ret = rdtgroup_add_files(kn_subdir, fflags); - if (!ret) - kernfs_activate(kn_subdir); + if (ret) + return ret; + + if ((fflags & RFTYPE_MON_INFO) == RFTYPE_MON_INFO) { + r = priv; + if (r->mon.mbm_cntr_assignable) { + ret = resctrl_mkdir_event_configs(r, kn_subdir); + if (ret) + return ret; + /* + * Hide BMEC related files if mbm_event mode + * is enabled. + */ + if (resctrl_arch_mbm_cntr_assign_enabled(r)) + resctrl_bmec_files_show(r, kn_subdir, false); + } + } + + kernfs_activate(kn_subdir); return ret; } @@ -2608,10 +2739,8 @@ static int rdt_get_tree(struct fs_context *fc) goto out_root; ret = schemata_list_create(); - if (ret) { - schemata_list_destroy(); - goto out_ctx; - } + if (ret) + goto out_schemata_free; ret = closid_init(); if (ret) @@ -2637,6 +2766,8 @@ static int rdt_get_tree(struct fs_context *fc) if (ret < 0) goto out_info; + rdtgroup_assign_cntrs(&rdtgroup_default); + ret = mkdir_mondata_all(rdtgroup_default.kn, &rdtgroup_default, &kn_mondata); if (ret < 0) @@ -2675,15 +2806,16 @@ out_mondata: if (resctrl_arch_mon_capable()) kernfs_remove(kn_mondata); out_mongrp: - if (resctrl_arch_mon_capable()) + if (resctrl_arch_mon_capable()) { + rdtgroup_unassign_cntrs(&rdtgroup_default); kernfs_remove(kn_mongrp); + } out_info: kernfs_remove(kn_info); out_closid_exit: closid_exit(); out_schemata_free: schemata_list_destroy(); -out_ctx: rdt_disable_ctx(); out_root: rdtgroup_destroy_root(); @@ -2822,6 +2954,7 @@ static void free_all_child_rdtgrp(struct rdtgroup *rdtgrp) head = &rdtgrp->mon.crdtgrp_list; list_for_each_entry_safe(sentry, stmp, head, mon.crdtgrp_list) { + rdtgroup_unassign_cntrs(sentry); free_rmid(sentry->closid, sentry->mon.rmid); list_del(&sentry->mon.crdtgrp_list); @@ -2862,6 +2995,8 @@ static void rmdir_all_sub(void) cpumask_or(&rdtgroup_default.cpu_mask, &rdtgroup_default.cpu_mask, &rdtgrp->cpu_mask); + rdtgroup_unassign_cntrs(rdtgrp); + free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); kernfs_remove(rdtgrp->kn); @@ -2946,6 +3081,7 @@ static void resctrl_fs_teardown(void) return; rmdir_all_sub(); + rdtgroup_unassign_cntrs(&rdtgroup_default); mon_put_kn_priv(); rdt_pseudo_lock_release(); rdtgroup_default.mode = RDT_MODE_SHAREABLE; @@ -3057,10 +3193,9 @@ static int mon_add_all_files(struct kernfs_node *kn, struct rdt_mon_domain *d, struct mon_evt *mevt; int ret, domid; - if (WARN_ON(list_empty(&r->evt_list))) - return -EPERM; - - list_for_each_entry(mevt, &r->evt_list, list) { + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled) + continue; domid = do_sum ? d->ci_id : d->hdr.id; priv = mon_get_kn_priv(r->rid, domid, mevt, do_sum); if (WARN_ON_ONCE(!priv)) @@ -3427,9 +3562,12 @@ static int mkdir_rdt_prepare_rmid_alloc(struct rdtgroup *rdtgrp) } rdtgrp->mon.rmid = ret; + rdtgroup_assign_cntrs(rdtgrp); + ret = mkdir_mondata_all(rdtgrp->kn, rdtgrp, &rdtgrp->mon.mon_data_kn); if (ret) { rdt_last_cmd_puts(\"kernfs subdir error\n\n\"); + rdtgroup_unassign_cntrs(rdtgrp); free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); return ret; } @@ -3439,8 +3577,10 @@ static int mkdir_rdt_prepare_rmid_alloc(struct rdtgroup *rdtgrp) static void mkdir_rdt_prepare_rmid_free(struct rdtgroup *rgrp) { - if (resctrl_arch_mon_capable()) + if (resctrl_arch_mon_capable()) { + rdtgroup_unassign_cntrs(rgrp); free_rmid(rgrp->closid, rgrp->mon.rmid); + } } /* @@ -3716,6 +3856,9 @@ static int rdtgroup_rmdir_mon(struct rdtgroup *rdtgrp, cpumask_var_t tmpmask) update_closid_rmid(tmpmask, NULL); rdtgrp->flags = RDT_DELETED; + + rdtgroup_unassign_cntrs(rdtgrp); + free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); /* @@ -3763,6 +3906,8 @@ static int rdtgroup_rmdir_ctrl(struct rdtgroup *rdtgrp, cpumask_var_t tmpmask) cpumask_or(tmpmask, tmpmask, &rdtgrp->cpu_mask); update_closid_rmid(tmpmask, NULL); + rdtgroup_unassign_cntrs(rdtgrp); + free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); closid_free(rdtgrp->closid); @@ -4022,9 +4167,14 @@ static void rdtgroup_setup_default(void) static void domain_destroy_mon_state(struct rdt_mon_domain *d) { + int idx; + + kfree(d->cntr_cfg); bitmap_free(d->rmid_busy_llc); - kfree(d->mbm_total); - kfree(d->mbm_local); + for_each_mbm_idx(idx) { + kfree(d->mbm_states[idx]); + d->mbm_states[idx] = NULL; + } } void resctrl_offline_ctrl_domain(struct rdt_resource *r, struct rdt_ctrl_domain *d) @@ -4050,7 +4200,7 @@ void resctrl_offline_mon_domain(struct rdt_resource *r, struct rdt_mon_domain *d if (resctrl_is_mbm_enabled()) cancel_delayed_work(&d->mbm_over); - if (resctrl_arch_is_llc_occupancy_enabled() && has_busy_rmid(d)) { + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID) && has_busy_rmid(d)) { /* * When a package is going down, forcefully * decrement rmid->ebusy. There is no way to know @@ -4084,32 +4234,41 @@ void resctrl_offline_mon_domain(struct rdt_resource *r, struct rdt_mon_domain *d static int domain_setup_mon_state(struct rdt_resource *r, struct rdt_mon_domain *d) { u32 idx_limit = resctrl_arch_system_num_rmid_idx(); - size_t tsize; + size_t tsize = sizeof(*d->mbm_states[0]); + enum resctrl_event_id eventid; + int idx; - if (resctrl_arch_is_llc_occupancy_enabled()) { + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) { d->rmid_busy_llc = bitmap_zalloc(idx_limit, GFP_KERNEL); if (!d->rmid_busy_llc) return -ENOMEM; } - if (resctrl_arch_is_mbm_total_enabled()) { - tsize = sizeof(*d->mbm_total); - d->mbm_total = kcalloc(idx_limit, tsize, GFP_KERNEL); - if (!d->mbm_total) { - bitmap_free(d->rmid_busy_llc); - return -ENOMEM; - } + + for_each_mbm_event_id(eventid) { + if (!resctrl_is_mon_event_enabled(eventid)) + continue; + idx = MBM_STATE_IDX(eventid); + d->mbm_states[idx] = kcalloc(idx_limit, tsize, GFP_KERNEL); + if (!d->mbm_states[idx]) + goto cleanup; } - if (resctrl_arch_is_mbm_local_enabled()) { - tsize = sizeof(*d->mbm_local); - d->mbm_local = kcalloc(idx_limit, tsize, GFP_KERNEL); - if (!d->mbm_local) { - bitmap_free(d->rmid_busy_llc); - kfree(d->mbm_total); - return -ENOMEM; - } + + if (resctrl_is_mbm_enabled() && r->mon.mbm_cntr_assignable) { + tsize = sizeof(*d->cntr_cfg); + d->cntr_cfg = kcalloc(r->mon.num_mbm_cntrs, tsize, GFP_KERNEL); + if (!d->cntr_cfg) + goto cleanup; } return 0; +cleanup: + bitmap_free(d->rmid_busy_llc); + for_each_mbm_idx(idx) { + kfree(d->mbm_states[idx]); + d->mbm_states[idx] = NULL; + } + + return -ENOMEM; } int resctrl_online_ctrl_domain(struct rdt_resource *r, struct rdt_ctrl_domain *d) @@ -4144,7 +4303,7 @@ int resctrl_online_mon_domain(struct rdt_resource *r, struct rdt_mon_domain *d) RESCTRL_PICK_ANY_CPU); } - if (resctrl_arch_is_llc_occupancy_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) INIT_DELAYED_WORK(&d->cqm_limbo, cqm_handle_limbo); /* @@ -4219,7 +4378,7 @@ void resctrl_offline_cpu(unsigned int cpu) cancel_delayed_work(&d->mbm_over); mbm_setup_overflow_handler(d, 0, cpu); } - if (resctrl_arch_is_llc_occupancy_enabled() && + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID) && cpu == d->cqm_work_cpu && has_busy_rmid(d)) { cancel_delayed_work(&d->cqm_limbo); cqm_setup_limbo_handler(d, 0, cpu);\n\nindex 6fb4894b8cfd1f..a7d92718b653f5 100644\n\n--- a/\n\n+++ b/ diff --git a/include/linux/resctrl.h b/include/linux/resctrl.hindex 6fb4894b8cfd1f..a7d92718b653f5 100644--- a/ include/linux/resctrl.h +++ b/ include/linux/resctrl.h @@ -157,27 +157,42 @@ struct rdt_ctrl_domain { }; /** + * struct mbm_cntr_cfg - Assignable counter configuration. + * @evtid: MBM event to which the counter is assigned. Only valid + * if @rdtgroup is not NULL. + * @rdtgrp: resctrl group assigned to the counter. NULL if the + * counter is free. + */ +struct mbm_cntr_cfg { + enum resctrl_event_id evtid; + struct rdtgroup *rdtgrp; +}; + +/** * struct rdt_mon_domain - group of CPUs sharing a resctrl monitor resource * @hdr: common header for different domain types * @ci_id: cache info id for this domain * @rmid_busy_llc: bitmap of which limbo RMIDs are above threshold - * @mbm_total: saved state for MBM total bandwidth - * @mbm_local: saved state for MBM local bandwidth + * @mbm_states: Per-event pointer to the MBM event's saved state. + * An MBM event's state is an array of struct mbm_state + * indexed by RMID on x86 or combined CLOSID, RMID on Arm. * @mbm_over: worker to periodically read MBM h/w counters * @cqm_limbo: worker to periodically read CQM h/w counters * @mbm_work_cpu: worker CPU for MBM h/w counters * @cqm_work_cpu: worker CPU for CQM h/w counters + * @cntr_cfg: array of assignable counters' configuration (indexed + * by counter ID) */ struct rdt_mon_domain { struct rdt_domain_hdr hdr; unsigned int ci_id; unsigned long *rmid_busy_llc; - struct mbm_state *mbm_total; - struct mbm_state *mbm_local; + struct mbm_state *mbm_states[QOS_NUM_L3_MBM_EVENTS]; struct delayed_work mbm_over; struct delayed_work cqm_limbo; int mbm_work_cpu; int cqm_work_cpu; + struct mbm_cntr_cfg *cntr_cfg; }; /** @@ -256,39 +271,52 @@ enum resctrl_schema_fmt { }; /** + * struct resctrl_mon - Monitoring related data of a resctrl resource. + * @num_rmid: Number of RMIDs available. + * @mbm_cfg_mask: Memory transactions that can be tracked when bandwidth + * monitoring events can be configured. + * @num_mbm_cntrs: Number of assignable counters. + * @mbm_cntr_assignable:Is system capable of supporting counter assignment? + * @mbm_assign_on_mkdir:True if counters should automatically be assigned to MBM + * events of monitor groups created via mkdir. + */ +struct resctrl_mon { + int num_rmid; + unsigned int mbm_cfg_mask; + int num_mbm_cntrs; + bool mbm_cntr_assignable; + bool mbm_assign_on_mkdir; +}; + +/** * struct rdt_resource - attributes of a resctrl resource * @rid: The index of the resource * @alloc_capable: Is allocation available on this machine * @mon_capable: Is monitor feature available on this machine - * @num_rmid: Number of RMIDs available * @ctrl_scope: Scope of this resource for control functions * @mon_scope: Scope of this resource for monitor functions * @cache: Cache allocation related data * @membw: If the component has bandwidth controls, their properties. + * @mon: Monitoring related data. * @ctrl_domains: RCU list of all control domains for this resource * @mon_domains: RCU list of all monitor domains for this resource * @name: Name to use in \"schemata\" file. * @schema_fmt: Which format string and parser is used for this schema. - * @evt_list: List of monitoring events - * @mbm_cfg_mask: Bandwidth sources that can be tracked when bandwidth - * monitoring events can be configured. * @cdp_capable: Is the CDP feature available on this resource */ struct rdt_resource { int rid; bool alloc_capable; bool mon_capable; - int num_rmid; enum resctrl_scope ctrl_scope; enum resctrl_scope mon_scope; struct resctrl_cache cache; struct resctrl_membw membw; + struct resctrl_mon mon; struct list_head ctrl_domains; struct list_head mon_domains; char *name; enum resctrl_schema_fmt schema_fmt; - struct list_head evt_list; - unsigned int mbm_cfg_mask; bool cdp_capable; }; @@ -372,8 +400,29 @@ u32 resctrl_arch_get_num_closid(struct rdt_resource *r); u32 resctrl_arch_system_num_rmid_idx(void); int resctrl_arch_update_domains(struct rdt_resource *r, u32 closid); +void resctrl_enable_mon_event(enum resctrl_event_id eventid); + +bool resctrl_is_mon_event_enabled(enum resctrl_event_id eventid); + bool resctrl_arch_is_evt_configurable(enum resctrl_event_id evt); +static inline bool resctrl_is_mbm_event(enum resctrl_event_id eventid) +{ + return (eventid >= QOS_L3_MBM_TOTAL_EVENT_ID && + eventid <= QOS_L3_MBM_LOCAL_EVENT_ID); +} + +u32 resctrl_get_mon_evt_cfg(enum resctrl_event_id eventid); + +/* Iterate over all memory bandwidth events */ +#define for_each_mbm_event_id(eventid) \\ + for (eventid = QOS_L3_MBM_TOTAL_EVENT_ID; \\ + eventid <= QOS_L3_MBM_LOCAL_EVENT_ID; eventid++) + +/* Iterate over memory bandwidth arrays in domain structures */ +#define for_each_mbm_idx(idx) \\ + for (idx = 0; idx < QOS_NUM_L3_MBM_EVENTS; idx++) + /** * resctrl_arch_mon_event_config_write() - Write the config for an event. * @config_info: struct resctrl_mon_config_info describing the resource, domain @@ -416,6 +465,26 @@ static inline u32 resctrl_get_config_index(u32 closid, bool resctrl_arch_get_cdp_enabled(enum resctrl_res_level l); int resctrl_arch_set_cdp_enabled(enum resctrl_res_level l, bool enable); +/** + * resctrl_arch_mbm_cntr_assign_enabled() - Check if MBM counter assignment + * mode is enabled. + * @r: Pointer to the resource structure. + * + * Return: + * true if the assignment mode is enabled, false otherwise. + */ +bool resctrl_arch_mbm_cntr_assign_enabled(struct rdt_resource *r); + +/** + * resctrl_arch_mbm_cntr_assign_set() - Configure the MBM counter assignment mode. + * @r: Pointer to the resource structure. + * @enable: Set to true to enable, false to disable the assignment mode. + * + * Return: + * 0 on success, < 0 on error. + */ +int resctrl_arch_mbm_cntr_assign_set(struct rdt_resource *r, bool enable); + /* * Update the ctrl_val and apply this config right now. * Must be called on one of the domain's CPUs. @@ -528,6 +597,63 @@ void resctrl_arch_reset_rmid_all(struct rdt_resource *r, struct rdt_mon_domain * */ void resctrl_arch_reset_all_ctrls(struct rdt_resource *r); +/** + * resctrl_arch_config_cntr() - Configure the counter with its new RMID + * and event details. + * @r: Resource structure. + * @d: The domain in which counter with ID @cntr_id should be configured. + * @evtid: Monitoring event type (e.g., QOS_L3_MBM_TOTAL_EVENT_ID + * or QOS_L3_MBM_LOCAL_EVENT_ID). + * @rmid: RMID. + * @closid: CLOSID. + * @cntr_id: Counter ID to configure. + * @assign: True to assign the counter or update an existing assignment, + * false to unassign the counter. + * + * This can be called from any CPU. + */ +void resctrl_arch_config_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + enum resctrl_event_id evtid, u32 rmid, u32 closid, + u32 cntr_id, bool assign); + +/** + * resctrl_arch_cntr_read() - Read the event data corresponding to the counter ID + * assigned to the RMID, event pair for this resource + * and domain. + * @r: Resource that the counter should be read from. + * @d: Domain that the counter should be read from. + * @closid: CLOSID that matches the RMID. + * @rmid: The RMID to which @cntr_id is assigned. + * @cntr_id: The counter to read. + * @eventid: The MBM event to which @cntr_id is assigned. + * @val: Result of the counter read in bytes. + * + * Called on a CPU that belongs to domain @d when \"mbm_event\" mode is enabled. + * Called from a non-migrateable process context via smp_call_on_cpu() unless all + * CPUs are nohz_full, in which case it is called via IPI (smp_call_function_any()). + * + * Return: + * 0 on success, or -EIO, -EINVAL etc on error. + */ +int resctrl_arch_cntr_read(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 closid, u32 rmid, int cntr_id, + enum resctrl_event_id eventid, u64 *val); + +/** + * resctrl_arch_reset_cntr() - Reset any private state associated with counter ID. + * @r: The domain's resource. + * @d: The counter ID's domain. + * @closid: CLOSID that matches the RMID. + * @rmid: The RMID to which @cntr_id is assigned. + * @cntr_id: The counter to reset. + * @eventid: The MBM event to which @cntr_id is assigned. + * + * This can be called from any CPU. + */ +void resctrl_arch_reset_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 closid, u32 rmid, int cntr_id, + enum resctrl_event_id eventid); + extern unsigned int resctrl_rmid_realloc_threshold; extern unsigned int resctrl_rmid_realloc_limit;\n\nindex a25fb9c4070d3c..acfe07860b346c 100644\n\n--- a/\n\n+++ b/ diff --git a/include/linux/resctrl_types.h b/include/linux/resctrl_types.hindex a25fb9c4070d3c..acfe07860b346c 100644--- a/ include/linux/resctrl_types.h +++ b/ include/linux/resctrl_types.h @@ -34,11 +34,18 @@ /* Max event bits supported */ #define MAX_EVT_CONFIG_BITS GENMASK(6, 0) -/* - * Event IDs, the values match those used to program IA32_QM_EVTSEL before - * reading IA32_QM_CTR on RDT systems. - */ +/* Number of memory transactions that an MBM event can be configured with */ +#define NUM_MBM_TRANSACTIONS 7 + +/* Event IDs */ enum resctrl_event_id { + /* Must match value of first event below */ + QOS_FIRST_EVENT = 0x01, + + /* + * These values match those used to program IA32_QM_EVTSEL before + * reading IA32_QM_CTR on RDT systems. + */ QOS_L3_OCCUP_EVENT_ID = 0x01, QOS_L3_MBM_TOTAL_EVENT_ID = 0x02, QOS_L3_MBM_LOCAL_EVENT_ID = 0x03, @@ -47,4 +54,7 @@ enum resctrl_event_id { QOS_NUM_EVENTS, }; +#define QOS_NUM_L3_MBM_EVENTS (QOS_L3_MBM_LOCAL_EVENT_ID - QOS_L3_MBM_TOTAL_EVENT_ID + 1) +#define MBM_STATE_IDX(evt) ((evt) - QOS_L3_MBM_TOTAL_EVENT_ID) + #endif /* __LINUX_RESCTRL_TYPES_H */",
      "source": "Kernel.org",
      "url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=2cb8eeaf00efc037988910de17ffe592b23941a6",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "中古パソコン販売のPCバル『Windows11乗り換え応援フェア』に限定商品続々登場! 人気の富士通LIFEBOOK Aシリーズ・Win11搭載15.6インチノートPCが19,800円で限定15台!!",
      "content": "株式会社バルテック（本社：東京都新宿区）のグループ会社、株式会社バルテックフィールドサービス（本社：東京都新宿区）が運営する中古パソコンの販売サイト「PCバル」（https://www.smaphodock24.jp/used/）では、2025年10月14日に控えたWindows10サポート終了を踏まえ、パソコンの乗り換えが必要なユーザー様に向け開催中の『Windows11乗り換え応援フェア』、好評のフェア限定商品に第３弾として、税込19,800円の富士通LIFEBOOK Aシリーズを15台追加!!\n\n限定15台・税込19,800円 富士通LIFEBOOK Aシリーズはこちら\n\n１． 全台システム要件適合・1,000台以上のWindows11搭載PC\n\nコスパ重視の第8世代からハイスペックの第12・第13世代まで幅広いラインナップのWindows11搭載中古パソコンをご用意!\n\nもちろんパソコン修理店が母体のPCバルならでは、独自の検査基準・項目に基づき状態をチェック後入念に整備しているので、安心してお使いいただけます!\n\nWindows11搭載中古ノートパソコン\n\nWindows11搭載中古デスクトップパソコン\n\n2． 乗り換えフェア限定・特別価格Windows11搭載中古パソコン\n\nさらに! 期間中はPCバルが特選した中古パソコンをフェア限定商品としてサプライズ価格で続々とご提供! PCバルは価格でも皆様のWindows11乗り換えを応援します!!\n\nWindow11乗り換え応援フェア限定商品はこちら\n\n新たに登場したフェア限定商品第3弾・ワンプライス19,800円でお届けする人気の富士通Aシリーズを限定15台!!\n\n新着・税込19,800円 富士通LIFEBOOK Aシリーズ 15.6インチはこちら\n\n☆第8世代Core i5＋8GBメモリで快適動作、実用性の高さが魅力の15.6インチPC\n\n大好評であっという間に売れたワンプライス18,150円のマウス製ノートPC・まだ少々在庫がありますので、こちらも要チェックで!\n\n残り僅か・税込18,150円 MOUSE MPro-NB391H-SSD 13.3インチ/MPro-NB510H 15.6インチ\n\n☆第8世代Core i5＋Mem8GB(1台だけ16GBモデルあり)＋SSD 240GB~1TB\n\n他にも多彩なフェア限定商品をご用意していますのでお見逃しなく! !\n\n税込22,222円 Lenovo ThinkPad X390 LTE 13.3 Intel Core i5-8265U 8GB\n\n☆コスパ最重視でWin11搭載PCを選ぶなら! 第8世代CPUで軽作業なら楽々♪\n\n税込54,321円 HP ELITE DRAGONFLY G2 Intel Core i5-1135G7 13.3 8GB\n\n☆第11世代CPU搭載、スタイリッシュなブルーが印象的な人気機種\n\n税込67,890円 DELL Inspiron 5415 14 AMD Ryzen 7-5700U 8GB\n\n☆高いマルチコア性能でクリエイティブワークの強い味方・RYZEN 7搭載！\n\n第8世代X1カーボンや第10世代LIFEBOOK Uシリーズなど他にも人気機種をサプライズ価格でご用意しておりますが、いずれも数に限りがありますので、ぜひお早めに!\n\n3． 選べる2つの特典で乗り換え応援!\n\n期間中にフェア限定商品をご成約の方には、MS Officeと高い互換性なのにリーズナブルな価格で人気のキングソフト製定番オフィスソフト『WPS Office 2 Standard Edition』をもれなくプレゼント!\n\nさらに、PCバル各店とWEBSHOPでそれぞれ特典をご用意!\n\n【PCバル各店店頭でのご購入】\n\nPCバル各店店頭でフェア限定商品をご購入のお客様には、今お使いのパソコンからデータのお引越し(データ移行)を、通常の50%OFFでご提供!\n\n大事なデータがあるからパソコンを換えるのは抵抗が…という心配はご無用です。\n\nご希望のお客様は店頭ご購入時に店頭でお申し付けください。\n\n【PCバルWEBSHOPでのご購入】\n\nPCバルWEBSHOP でフェア限定商品をご購入のお客様には、WPS Office 2に加え、ウイルス＆フィッシング対策・システムメンテナンスを1つでこなす『セキュリティPro』(キングソフト製)をプレゼント!\n\n■「PCバル」3つの安心\n\n（https://www.smaphodock24.jp/used/）\n\n１．専門店ならではのこだわり\n\n取扱商品は仕入れ後にパソコン整備士の資格を持ったスタッフが、独自の検査基準・項目に基づき状態をチェック後入念に整備。長く使える・故障の少ない状態でお届けできるようメンテナンスした上で販売しています。安定性と体感速度に影響するコンポーネンツはSSD＋RAMメモリ8GB以上を標準構成※とし、プロが手掛けたリフレッシュPCとして高度化・高速化するパソコンの使用環境に対応しお客様満足度の向上を目指しています。\n\n※一部標準構成外の商品もございます。\n\n２．お客様に寄り添った情報掲載・商品説明\n\n写真と説明だけで選ぶネットの商品でも安心してお選びいただけるよう、スペック情報だけでなく「動作には問題ないものの、細かなキズや使用感がある部分など…」といった状態も丁寧にご案内しています。\n\n店頭展示品についても、スタッフが実物をご案内しながら、納得いただけるようわかりやすくご説明しています。\n\n３．安心保証&充実サポート\n\n購入時から最大6ヶ月間の保証※が中古PCに付いてくる！パソコン修理専門店を10年以上全国に展開するPCバルならではの修理技術が可能にする手厚いサポートです。保証期間内中の修理ではお客様の費用負担はゼロ(適用条件あり)！ 保証期間終了後に故障が発生した場合でも、症状状態ご予算に応じ当社の技術スタッフが最善のご提案を致します。\n\n※中古PCの保証適用条件はWEB保証書へのアクセスまたは(紙)保証書でご確認ください。\n\n※商品により保証期間が異なります。詳しくは各商品ページをご確認ください。\n\n◆会社概要\n\n□株式会社バルテック\n\n事業内容：ICT機器及びソフトウェアの開発・製造・管理\n\n設立： 1993年3月23日\n\n所在地：〒163-1103 東京都新宿区西新宿6-22-1 新宿スクエアタワー3階\n\nURL：https://www.webjapan.co.jp/\n\n□株式会社バルテックフィールドサービス\n\n事業内容：ICT機器及びソフトウェアの施工、保守、修理\n\nパソコン修理サービス店のフランチャイズ展開\n\nURL：https://www.smaphodock24.jp/",
      "source": "Prtimes.jp",
      "url": "https://prtimes.jp/main/html/rd/p/000000787.000008585.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Dell Ryzen 7 Laptop Bundle Crashes to 64% Off, Loaded With Freebies and Likely Gone Before October Prime Day",
      "content": "If you happen to be on the hunt for a new laptop, whether that’s because you’re a student in need of something to complete assignments, a small business owner looking to handle your business needs, or just some guy looking to watch YouTube and draw pictures, come check out the Dell Inspiron 15. This laptop has a touchscreen and is bundled with some bonus accessories. The Amazon listing has the full price set at $2,200, but the limited time deal indicates its been marked down by 64% to just $800. Some quick napkin math will tell you that’s a $1,400 discount.\n\nYou might be thinking that’s absolutely ridiculous. How can this laptop be on sale for that much off? Well, you’re right to be suspicious. When we look at this bundle’s price history, we can see it has only existed on Amazon for about a month. After first being listed, it immediately dropped in price and it’s mostly been at that $800 amount since.\n\nSee at Amazon\n\nLots of sellers on Amazon will artificially inflate the list price so that when they mark it down, the sale looks enormous. Even if we go to Dell’s website, we’ll find versions of this model laptop going for about the same as you find it here. All that said, this is a pretty good value.\n\nWhat you’re getting is a 15.6-inch touchscreen laptop that’s powered by the AMD Ryzen 7 7730U. With that we also have an integrated graphics card, 32GB of memory, and a full 1TB of internal storage on its SSD. This laptop is designed to be able to take on school, work, entertainment, and any other sort of everyday task an average user might encounter — and it’s got the specs to support that.\n\nThe screen’s touch controls allow you to operate the laptop as if it’s a tablet, choosing to use pinch, zoom, and swipe gestures like you would on a mobile device. It has a resolution of 1080p and uses an anti-glare coating to help minimize reflections, making for more comfortable viewing in bright settings.\n\nBonus Gifts Included\n\nAlong with the laptop, you also get a number of free accessories. This Dell Inspiron 15 comes with a stylus pen to be used on the touchscreen, a cleaning clothe, a laptop sleeve for traveling, a USB flash drive with 128GB on it, as well as some port covers and webcam covers. Plus, the laptop comes pre-installed with Windows 11 Pro.\n\nRight now, you can get the Dell Inspiron 15 and all these goodies for just $800.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/dell-ryzen-7-laptop-bundle-crashes-to-64-off-loaded-with-freebies-and-likely-gone-before-october-prime-day-2000629976",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "IREN (IREN) Doubles GPU Fleet to 23,000, Raises Revenue Target",
      "content": "IREN Limited (NASDAQ:IREN) is one of the best performing ASX stocks in 2025. On September 22, the company said it had doubled its GPU fleet to 23,000 units after acquiring 12,400 more GPUs for about $674 million. The expanded fleet now includes a mix of NVIDIA H100s & H200s (1,900), NVIDIA B200s & B300s (19,100), NVIDIA GB300s (1,200), and AMD MI350Xs (1,100).\n\nIREN (IREN) Doubles GPU Fleet to 23,000, Raises Revenue Target\n\nIREN raised its annualized run-rate revenue (ARR) target for its AI Cloud segment to more than $500 million by the end of Q1 2026. The company previously targeted 10,900 GPUs by year-end, but strong market demand led to a larger fleet and a higher ARR goal. It now plans to support up to 60,000 GPUs, especially at its British Columbia sites.\n\nThe management expects that the GPU investments will bolster long-term revenue and improve operational efficiency. It is particularly banking on the Blackwell architecture, which offers improvements in AI performance and energy efficiency. Deliveries and deployment will occur at the Prince George campus and other facilities in British Columbia.\n\nIREN Limited (NASDAQ:IREN) is a sustainable Bitcoin mining and AI infrastructure company. It develops and operates large-scale data centers powered by renewable energy, with major facilities in Texas and British Columbia. Its main products are mined bitcoin and high-performance AI cloud services.\n\nWhile we acknowledge the potential of IREN as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: Conservative Stock Portfolio: 11 Best Stocks to Buy Now and 10 Best Performing Penny Stocks to Buy Now.\n\nDisclosure: None. This article is originally published at Insider Monkey.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/iren-iren-doubles-gpu-fleet-190126547.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "AMD teases DGF tricks for next-gen UDNA GPUs",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/amd-teases-dgf-tricks-for-next-gen-udna-gpus/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Stock market today: S&P 500, Nasdaq futures rise as AI optimism grows, while Dow stalls amid US shutdown",
      "content": "US stocks rose on Thursday as the AI trade continued to power a push for fresh records amid new buzz around OpenAI (OPAI.PVT). Meanwhile, investors kept an eye on developments in Washington, weighing the chances of a lengthy US government shutdown.\n\nThe tech-heavy Nasdaq Composite (^IXIC) rose 0.4%. The S&P 500 (^GSPC) gained 0.1%. The Dow Jones Industrial Average (^DJI) rose 0.2%. All three major averages posted new records.\n\nStocks rose one day after the S&P 500 closed above 6,700 for the first time. A wave of good news from the AI sector lifted chip stocks worldwide, with Nvidia (NVDA) rising to a record high. AMD (AMD) and SK Hynix (000660.KS, HXSCL) also gained.\n\nOpenAI's (OPAI.PVT) valuation soared to $500 billion after an employee share sale, boosting tech rally hopes despite fears of an AI bubble. The ChatGPT maker ousted Elon Musk's SpaceX (SPAX.PVT) as the most valuable startup in the world.\n\nMarkets have so far been unperturbed by the US government shutdown, which looks set to drag on at least until the end of the week. President Trump is amping up his rhetoric against Democrats, threatening to fire \"thousands\" of federal workers and canceling billions of dollars in federal funding to blue states.\n\nTrump said he is meeting on Thursday with OMB Director Russ Vought, who has been leading White House strategy in the shutdown, to discuss which \"Democrat Agencies\" should be cut.\n\nIn any case, Friday's scheduled release of the September jobs report is all but certain to be delayed. That has Wall Street looking elsewhere during the federal data blackout, as Fed policymakers have indicated cracks in the labor market will loom large in their October rate decision.\n\nPrivate data from the firm Challenger, Gray & Christmas released Thursday found hiring plans at their lowest level since 2009, even as layoffs fell. The report provided more evidence of the softening \"low hire, low fire\" labor market after Wednesday's ADP report. Investors remain near-unanimous on bets for a cut at the Fed's next meeting.\n\nElsewhere in corporates, Tesla (TSLA) shares took a hit despite a record sales quarter as investors turned focus to future performance without the federal EV tax credit.\n\nLIVE COVERAGE IS OVER\n\n25 updates",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-sp-500-nasdaq-futures-rise-as-ai-optimism-blots-out-us-shutdown-230340381.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "AMD in early talks to make chips at Intel Foundry, report says",
      "content": "Intel is in the early stages of talks with AMD about making the fabless chip designer an Intel Foundry customer, according to a report from Semafor.\n\n\n\nThe report, citing \"people familiar with the matter,\" doesn't say just how much of AMD's chip manufacturing would move to Intel. The company currently fabs its chips at TSMC. (Intel fabs some products at TSMC, too.)\n\n\n\nIn the past several weeks, Intel has seen a flurry of activity and investments. The United States announced a 9.9% ownership stake in Intel, while Softbank bought $2 billion worth of shares. Alongside Nvidia, Intel announced new x86 chips using Nvidia graphics technology, with the graphics giant also purchasing $5 billion in Intel shares. There have also been reports that Intel and Apple have been exploring ways to work together.\n\n\n\nSuch a partnership with AMD could validate former Intel CEO Pat Gelsinger's vision. He had previously expressed interest in building chips for all of the world's major tech companies, including long-time rival AMD. It's unknown if AMD is considering a stock purchase similar to Nvidia.\n\n\n\nAMD would be a major get for Intel, the latter of which has talked to many companies in a search for foundry customers. Current Intel CEO Lip-Bu Tan has suggested the company could stop offering its 18A node entirely if there isn't enough demand for it.\n\nIntel and AMD did not respond to requests for comment from Tom's Hardware in time for publication.\n\n\n\nIt makes sense for Intel's former rivals — especially American companies — to consider coming to the table. The White House is pushing for 50% of chips bound for America to be built domestically, and tariffs on chips aren't off the table. Additionally, doing business with Intel could make the US government, Intel's largest shareholder, happy, which can be good for business. AMD faced export restrictions on its GPUs earlier this year as the US attempted to throttle China's AI business.\n\n\n\nIn general, Intel's Foundry technology is perceived as less advanced than TSMC's, but partnering with Intel could provide a backup if AMD ever needs one.",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/amd-in-early-talks-to-make-chips-at-intel-foundry-report-says",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Learn the Exact Volatility Levels the Best Options Traders Use to Fine-Tune Their Strategies",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/124d7b2761cb57af",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "(PR) IBM and AMD Collaborate with Zyphra on Next Generation AI Infrastructure",
      "content": "\"This collaboration marks the first time AMD's full-stack training platform—spanning compute through networking—has been successfully integrated and scaled on IBM Cloud, and Zyphra is honored to lead the way in developing frontier models with AMD silicon on IBM Cloud,\" said Krithik Puthalath, CEO and Chairman of Zyphra. \"We're excited to partner with IBM and AMD to power the next era of open-source, enterprise superintelligence.\"\n\n\"Scaling AI workloads faster and more efficiently is a key differentiator in achieving ROI for established enterprises and emerging companies alike,\" said Alan Peacock, GM of IBM Cloud. \"We are delighted to support Zyphra's strategic roadmap as we collaborate with AMD to deliver scalable, economical AI infrastructure that can accelerate Zyphra's model training.\"\n\n\"The IBM and AMD collaboration delivers innovation at the speed and scale clients demand, representing a new standard in AI infrastructure,\" said Philip Guido, EVP and Chief Commercial Officer, AMD. \"By combining IBM enterprise cloud expertise with AMD leadership in high-performance computing and AI acceleration, we are supporting Zyphra's pioneering work in multimodal and inference-efficient AI, enabling organizations everywhere to build smarter businesses and unlock AI solutions that drive real-world outcomes.\"\n\nIBM (NYSE: IBM) and AMD (NASDAQ: AMD) today announced a collaboration to deliver advanced AI infrastructure to Zyphra, an open-source AI research and product company based in San Francisco, California. Under a multi-year agreement between IBM and Zyphra, IBM is positioned to deliver a large cluster of AMD Instinct MI300X GPUs on IBM Cloud for Zyphra to use for training frontier multimodal foundation models. This collaboration is expected to deliver among the largest advanced generative AI training capabilities to date powered by an AMD stack running on IBM Cloud.Zyphra recently closed a Series A financing round at a $1B valuation to build a leading open-source/open-science superintelligence lab focused on advancing fundamental innovations in novel neural network architectures, long-term memory, and continual learning.Zyphra partnered with IBM and AMD for their cutting-edge product roadmaps and ability to deliver GPU accelerators at the rapid pace required to drive Zyphra's innovation forward. This agreement is the first large-scale, dedicated training cluster on IBM Cloud leveraging AMD Instinct MI300X GPUs and AMD Pensando Pollara 400 AI NICs and AMD Pensando Ortano DPUs. The initial deployment was made available to Zyphra in early September with planned expansion in 2026.Zyphra will use the advanced training cluster to develop multimodal foundation models across language, vision and audio modalities to power Maia, a general purpose superagent designed to deliver productivity benefits for knowledge workers across enterprise. IBM and AMD are uniquely positioned to continue scaling computational resources as Zyphra's AI model training needs expand.Last year, IBM and AMD announced a collaboration to deploy AMD Instinct MI300X accelerators as a service on IBM Cloud. Known for its security, reliability and scalability, IBM Cloud's robust infrastructure complements the capabilities of the AMD Instinct MI300X. This offering was designed to enhance performance and power efficiency for Gen AI models and high-performance computing (HPC) applications.IBM and AMD are forging new ground in AI infrastructure, helping redefine performance, efficiency, and scale for enterprise and startup customers. Their hybrid infrastructure environment offers a foundation for scaling AI, with options such as hybrid multi-cloud that can help boost cloud ROI and value for clients' generative AI deployments.IBM and AMD also recently announced plans to develop next-generation computing architectures, known as quantum-centric supercomputing, leveraging IBM's leadership in developing the world's most performant quantum computers and software, and AMD's leadership in high-performance computing and AI accelerators.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341528/ibm-and-amd-collaborate-with-zyphra-on-next-generation-ai-infrastructure",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Russian shelling cuts power to decommissioned Chernobyl nuclear power plant",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/a9bc2470e447be47",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Government shutdown means Fed lacks crucial data as it considers rate cuts",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/2b9c1fef521fcdcb",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Advanced Matrix Multiplication Optimization on Modern Multi-Core Processors",
      "content": "TL;DR The code is available at sgemm.c. This blog post walks through optimizing multi-threaded FP32 matrix multiplication on modern processors using FMA3 and AVX2 vector instructions. The implementation delivers strong performance on a variety of x86-64 CPUs, both in single-threaded and multithreaded scenarios. However, to reach peak performance, you’ll need to fine-tune hyperparameters - such as the number of threads, kernel size, and tile sizes. Additionally, on AVX-512 CPUs, the BLAS libraries might be notably faster due to AVX-512 instructions, which were intentionally omitted here to support a broader range of processors. Performance results for Intel Core Ultra 265 and AMD Ryzen 7 9700X are shown below.\n\nP.S. Please feel free to get in touch if you are interested in collaborating. My contact information is available on the homepage.\n\n1. Introduction\n\nMatrix multiplication is an essential part of nearly all modern neural networks. Despite using matmul daily in PyTorch, NumPy, or JAX, I’ve never really thought about how it is designed and implemented internally to take full advantage of hardware capabilities. NumPy, for instance, relies on external BLAS (Basic Linear Algebra Subprograms) libraries. These libraries contain high-performance, optimized implementations of common linear algebra operations, such as the dot product, matrix multiplication, vector addition, and scalar multiplication. Examples of BLAS libraries include:\n\nIntel MKL - optimized for Intel CPUs Accelerate - optimized for Apple CPUs BLIS - open-source, multi-vendor, BLAS-like Library Instantiation Software GotoBLAS - open-source, multi-vendor OpenBLAS - open-source, multi-vendor, fork of GotoBLAS\n\nA closer look at the OpenBLAS code reveals a mix of C and low-level assembly. In fact, OpenBLAS, GotoBLAS, and BLIS are written in C/FORTRAN/Assembly and contain matmul implementations manually optimized for different CPU microarchitectures. My goal was to implement the matrix multiplication in pure C (without low-level assembly code) so that it works for any matrix size, runs on all modern x86-64 processors, and competes with existing BLAS libraries. At the sime time I wanted to keep the code simple and easy to extend. After some research, I found a few great step-by-step tutorials on implementing fast matrix multiplication from scratch, covering both theory and practice:\n\nI highly recommend these clear and well-explained tutorials with alternative implementations. They helped me better understand the topic and, in some sense, motivated me to write my own implementation. The reason is that all three solutions above work only for specific matrix sizes and do not achieve performance of the BLAS libraries. Unsatisfied with these results, I kept researching and came across two fascinating papers: “Anatomy of High-Performance Matrix Multiplication” and “Anatomy of High-Performance Many-Threaded Matrix Multiplication”. The first introduces GotoBLAS, a high-performance BLAS implementation by Kazushige Goto. The second reviews the matmul design used in the BLIS library (an extended version of GotoBLAS) and explores different parallelization strategies. Due to its superior high-level design, I had a feeling that the matmul implementation from the BLIS library can outperform existing BLAS implementations even if written in pure C and not manually finetuned using inline assembly. In the next chapters we’ll step-by-step implement the algorithm from scratch and compare against OpenBLAS. Before diving into optimizations, let’s first go over how to install OpenBLAS and properly benchmark the code on a CPU.\n\n2. How to Install and Benchmark OpenBLAS\n\nI benchmarked the code on the following machine:\n\nCPU: AMD Ryzen 7 9700X\n\nRAM: 32GB DDR5 6000 MHz CL36\n\nOpenBLAS 0.3.26\n\nCompiler: GCC 13.3\n\nCompiler flags: -O3 -march=native -mno-avx512f -fopenmp\n\nOS: Ubuntu 24.04.1 LTS\n\nImportant! To obtain reproducible and accurate results, minimize the number of active tasks, particularly when benchmarking multi-threaded code. Windows systems generally deliver lower performance compared to Linux due to higher number of active background tasks.\n\nTo benchmark OpenBLAS, start by installing it according to the installation guide. During installation, make sure to set an appropriate TARGET and disable AVX512 instructions for a fair comparison. For Zen4/5 processors compile OpenBLAS with:\n\nmake TARGET = ZEN\n\nOtherwise, OpenBLAS defaults to AVX512 instructions. After installation, you can run FP32 matmul using the OpenBLAS API:\n\n#include <cblas.h> cblas_sgemm ( CblasColMajor , CblasNoTrans , CblasNoTrans , m , n , k , 1 , A , m , B , k , 0 , C , m );\n\nThe benchmark evaluates the custom implementation and the OpenBLAS API on square matrices, ranging from m=n=k=200 to m=n=k=10000 in steps of 200 . To obtain consistent and accurate results, matrix multiplication is repeated n_iter times, and performance is measured as median execution time.\n\nTo multiply two float32 matrices - $A$ of size $M \\times K$ and $B$ of size $K \\times N$, for each element of the resulting matrix $C$ of size $M \\times N$, we need to compute the dot product between a row of $A$ and a column of $B$. This requires $K$ (additions) + $K$ (multiplications) = $2K$ Floating Point Operations (FLOP) per element of $C$ or $2MNK$ FLOP in total. A metric often used to evaluate matmul performance is called FLOP per second or FLOP/s or FLOPS, and it can be derived from the execution time as FLOPS=FLOP/exec_time=(2*m*n*k)/exec_time .\n\n3. Theoretical Limit\n\nThe image below shows a simplified model of the computer’s memory hierarchy (for now, ignore the layers between the registers and the main memory(=RAM); we will discuss them later).\n\nTo perform arithmetic operations on data stored in RAM (off-chip memory, slow and large capacity), the data must be first transferred to CPU and placed in CPU registers (on-chip memory, fast and small capacity). Modern x86-64 CPUs support SIMD (Single Instruction Multiple Data) extensions, which allow multiple pieces of data to be processed in parallel. There are various SIMD extensions, but the ones relevant to our discussion are Advanced Vector Extensions (AVX2) and Fused Multiply-Add (FMA). Both AVX2 and FMA operate on data stored in special 256-bit YMM registers. Each YMM register can hold 8 packed single-precision (32-bit) floats. The FMA2 instructions perform element-wise multiply-add operation on data stored in the YMM registers. The corresponding assembly instruction is called VFMADD231PS (PS stands for PackedSingle) and takes three vector registers ( YMM1 , YMM2 , YMM3 ) as input to compute YMM1 = YMM2 * YMM3 + YMM1 .\n\nAccording to the intel intrinsics guide or https://uops.info/table.html, for my CPU the throughput (TP) of the fused-multiply-add instruction is 0.5 cycles/instruction or with other words 2 instructions/cycle:\n\nTheoretically, Ryzen 9700X can perform 32 FLOP per cycle: 8 (floats in YMM register) * 2 (add + mul) * 2 (1/TP). Therefore, the theoretical peak FLOPS in single-threaded mode can be roughly estimated as CPU_CLOCK_SPEED * 32 or n_cores * CPU_CLOCK_SPEED * 32 in multi-threaded mode. For example, assuming a sustainable clock speed of 4.7 GHz for an 8-core 9700X processor, the theoretical peak FLOPS in a multi-threaded setting would be 1203 FLOPS.\n\n4. Naive Implementation\n\nIn this tutorial we assume that matrices are stored in column-major order: e.g. matrix A of shape MxN is stored as contiguous array of length M*N and an element A[row][col] is accessed via C raw pointer ptr[col*M + row] , where 0 <= col <= N-1 and 0 <= row <= M-1 .\n\nThe simplest implementation of $C=AB$ can be described as follows:\n\nvoid matmul_naive ( float * A , float * B , float * C , const int M , const int N , const int K ) { for ( int i = 0 ; i < M ; i ++ ) { for ( int j = 0 ; j < N ; j ++ ) { for ( int p = 0 ; p < K ; p ++ ) { C [ j * M + i ] += A [ p * M + i ] * B [ j * K + p ]; } } } }\n\nHere, we iterate over all rows (the outermost loop) and all columns (the second loop) of C and for each element of C we calculate the dot product (the innermost loop) between the corresponding row of matrix A and column of matrix B . It’s always good to start with a simple and robust algorithm that can later be used to test optimized implementations.\n\n5. Kernel\n\nThe key idea of high-performance matrix multiplication on CPU is to develop a function that efficiently computes a sub-matrix of $C$. Then, by iterating over $C$ and applying this function to all non-overlapping sub-matrices, we can significantly speed up the entire matrix multiplication operation. For this, we, first, partition the matrix $C$ of shape $M \\times N$ into smaller non-overlapping sub-matrices of shape $m_R \\times n_R$, with $n_R \\ll N$ and $m_R \\ll M$. To calculate $C=AB$, we iterate over $C$ and compute each of its non-overlapping $m_R \\times n_R$ sub-matrices as shown below:\n\nThe function that computes an $m_R \\times n_R$ sub-matrix $\\bar{C}$ of $C$ is called a kernel (aka. micro-kernel using BLIS notation). This function is the core of high-performance matrix multiplication. When we say a matrix multiplication algorithm is optimized for a specific CPU architecture, it usually refers to kernel optimization. For example, OpenBLAS contains kernels optimized for different CPU microarchitectures.\n\nLet’s take a closer look at the kernel. To compute an $m_R \\times n_R$ sub-matrix $\\bar{C}$ of $C$, we need to multiply corresponding $m_R \\times K$ sub-matrix $\\bar{A}$ of $A$ with $K \\times n_R$ sub-matrix $\\bar{B}$ of $B$ as shown in the figure below:\n\nIf we were to do this in a naive manner using the dot product, we would need to fetch $2K$ elements from RAM to calculate a single element of $\\bar{C}$ or $2K m_R n_R$ elements in total to compute $\\bar{C}$. There is, however, an alternative strategy that can reduce the number of fetched elements.\n\nFirst, we initialize the matrix $\\bar{C}$ with zeros and store it in registers. Since both $n_R$ and $m_R$ are small, the entire matrix fits within the registers. Here, the subscript $R$ in $n_R$ and $m_R$ denotes “register”. Next, we iterate over the dimension $K$, and in each iteration, we:\n\nload 1 column of $\\bar{A}$ and 1 row of $\\bar{B}$ from RAM into the registers. Again, note that both the row and column vectors are limited in size and can be stored in the registers. compute the outer product between the two vectors and add the result of the outer product to the matrix $\\bar{C}$.\n\nAfter $K$ iterations, the computation of the matrix $\\bar{C}$ is completed and it can be stored into RAM. $\\bar{C}$ is often referred to as the accumulator, because it accumulates the outer products along the dimension $K$. A single accumulation step of the outer product between two vectors is also known as rank-1 update.\n\nOuter product between a column vector and a row vector.\n\nIn total, we fetch $(m_R + n_R)K$ elements from RAM into registers. Compared to the naive approach, this reduces the number of memory accesses by a factor of\n\n\\[\\frac{2m_Rn_RK}{(m_R + n_R)K} = \\frac{2m_Rn_R}{m_R + n_R}\\]\n\nThis factor is maximized when both $m_R$, $n_R$ are large and equal. However, the values of $m_R$ and $n_R$ are typically constrained by the available register memory.\n\nNow, let’s discuss in detail how the outer product and accumulation can be efficiently implemented using SIMD FMA instructions. Unfortunately, there are no SIMD instructions that compute the outer product in a single step. Therefore, we need to decompose the outer product into simpler operations. The figure below illustrates the process:\n\nHere, we compute the outer product between a column vector of size $m_R$ and a row vector of size $n_R$ to update an accumulator $\\bar{C}$ of size $m_R \\times n_R$. The accumulator is stored in the YMM registers, with each column of the accumulator spanning one or multiple YMM registers. The column vector is also stored in the YMM registers (highlighted as yellow). Since each YMM register holds 8 floats, the dimension $m_R$ must be divisible by 8. The accumulator is updated column by column. During the first iteration we broadcast the first element of the row vector to a vector of size $m_R$ and place it in the YMM registers (highlighted as green). Then, we element-wise multiply the column vector with the broadcasted vector and accumulate the result to the first column of the accumulator $\\bar{C}$ using FMA instruction. We repeat this process for the remaining elements of the row vector to update the corresponding columns of the accumulator. After $n_R$ iterations, the rank-1 update of the accumulator is completed.\n\nThe last thing we need to discuss before implementing the kernel in C is how to choose the kernel size i.e. $m_R$ and $n_R$. CPUs with AVX support have 16 YMM registers. From our previous discussion, we know that we need $(m_R/8) \\cdot n_R$ registers to store the accumulator $\\bar{C}$, $m_R/8$ registers to store the column vector and 1 register (because we can reuse the same register for all FMA operations) for the broadcasted vector. We want $m_R$ and $n_R$ to be as large as possible while satisfying the following conditions:\n\n$\\Big(\\cfrac{m_R}{8} \\cdot n_R + \\cfrac{m_R}{8} + 1\\Big) <= 16$\n\n$m_R$ is a multiple of 8\n\nIn theory we want $m_R = n_R$ to minimize the number of fetched elements. However, in practice, a non-square kernel with $m_R = 16, n_R = 6$ showed the best performance on my CPU. Therefore, we will implement this kernel in the next section. Feel free to experiment with other kernel sizes, such as $8 \\times 8, 8 \\times 12$, $8 \\times 13$, $8 \\times 14$, $32 \\times 2$ and compare their performance on your CPU.\n\nLet’s implement the algorithm discussed above using the $16 \\times 6$ kernel. The code of this implementation can be found at matmul_kernel.c. To use SIMD instructions in C we first need to include the immintin.h library:\n\n#include <immintrin.h>\n\nThe implementation of the algorithm is straightforward: we iterate over matrix $C$ and apply the kernel function to each of it’s non-overlapped $16 \\times 6$ sub-matrices $\\bar{C}$.\n\nvoid matmul_kernel ( float * A , float * B , float * C , const int M , const int N , const int K ) { for ( int i = 0 ; i < M ; i += 16 ) { for ( int j = 0 ; j < N ; j += 6 ) { kernel_16x6 ( & A [ i ], & B [ j * K ], & C [ j * M + i ], M , N , K ); } } }\n\nThe kernel function is declared as follows:\n\nvoid kernel_16x6 ( float * A_start , float * B_start , float * C_start , int M , int N , int K );\n\nThe function takes as input pointers to the starting positions of $\\bar{A}, \\bar{B}$, and $\\bar{C}$ along with the matrix problem size. It then computes $16 \\times 6$ sub-matrix $\\bar{C}$ of $C$ according to $\\bar{C} = \\bar{A} \\bar{B}$.\n\nInside the kernel function, first, we declare the variables stored in the YMM registers:\n\n__m256 C_accum [ 6 ][ 2 ] = {}; // zero-initialized __m256 b_packFloat8 ; __m256 a0_packFloat8 ; __m256 a1_packFloat8 ;\n\nA variable of type __m256 is a 256-bit vector that represents the contents of a YMM register, which holds eight 32-bit floating-point values. C_accum is the accumulator stored in the YMM registers. The variable b_packFloat8 contains a broadcasted element from a row vector of $\\bar{B}$, while a0_packFloat8 and a1_packFloat8 represent a column vector of $\\bar{A}$. Since the column vector contains 16 floats, it requires two YMM registers for storage.\n\nSIMD intrinsics are well documented and can be found in the Intel Intrinsics Guide. For example, _mm256_loadu_ps\n\nThe kernel iterates over the dimension $K$ and in each iteration performs a rank-1 update of the accumulator:\n\nfor ( int p = 0 ; p < K ; p ++ ) { // Load column vector of size 16 // { a0_packFloat8 = _mm256_loadu_ps ( & A_start [ p * M ]); a1_packFloat8 = _mm256_loadu_ps ( & A_start [ p * M + 8 ]); // } // Broadcast scalar element to vector of size 8 // { b_packFloat8 = _mm256_broadcast_ss ( & B_start [ p ]); // } // Update the first column of the accumulator // { C_accum [ 0 ][ 0 ] = _mm256_fmadd_ps ( a0_packFloat8 , b_packFloat8 , C_accum [ 0 ][ 0 ]); C_accum [ 0 ][ 1 ] = _mm256_fmadd_ps ( a1_packFloat8 , b_packFloat8 , C_accum [ 0 ][ 1 ]); // } ... ... ... b_packFloat8 = _mm256_broadcast_ss ( & B_start [ 5 * K + p ]); // update the last column of the accumulator // { C_accum [ 5 ][ 0 ] = _mm256_fmadd_ps ( a0_packFloat8 , b_packFloat8 , C_accum [ 5 ][ 0 ]); C_accum [ 5 ][ 1 ] = _mm256_fmadd_ps ( a1_packFloat8 , b_packFloat8 , C_accum [ 5 ][ 1 ]); // } }\n\nAfter $K$ rank-1 updates, the computation of the accumulator is complete, and the result can be stored in RAM:\n\n// Store the accumulator column by column: for ( int j = 0 ; j < 6 ; j ++ ) { _mm256_storeu_ps ( & C_start [ j * M ], C_accum [ j ][ 0 ]); _mm256_storeu_ps ( & C_start [ j * M + 8 ], C_accum [ j ][ 1 ]); }\n\nLet’s take a look at the generated assembly code to see if it actually contains SIMD FMA instructions and uses the YMM registers:\n\ngcc -O3 -mno-avx512f -march = native matmul_kernel.c -S\n\n// matmul_kernel.s ... vfmadd231ps %ymm14, %ymm1, %ymm13 vfmadd231ps %ymm14, %ymm0, %ymm12 vmovaps %ymm13, 32(%rsp) vmovaps %ymm12, 64(%rsp) vbroadcastss (%rax,%r9), %ymm14 vfmadd231ps %ymm14, %ymm1, %ymm10 vfmadd231ps %ymm14, %ymm0, %ymm11 vmovaps %ymm10, 96(%rsp) vmovaps %ymm11, 128(%rsp) vbroadcastss (%rax,%r9,2), %ymm14 addq $4, %rax vfmadd231ps %ymm14, %ymm1, %ymm2 vfmadd231ps %ymm14, %ymm0, %ymm3 ...\n\n6. Padding\n\nYou may have noticed that the current implementation only works for matrix sizes where $M$ and $N$ are multiples of $m_R$ and $n_R$, respectively. Specifically, the kernel assumes that matrix $\\bar{C}$ has dimensions $m_R \\times n_R$, matrix $\\bar{A}$ is $m_R \\times K$ and matrix $\\bar{B}$ is $K \\times n_R$. Our goal is to generalize the kernel so that it can handle matrices $\\bar{C}, \\bar{A}, \\bar{B}$ with dimensions $m \\times n, m \\times K, K \\times n$, even when $m\n\neq m_R$ and $n\n\neq n_R$, as shown below:\n\nFirst, when storing the accumulator, we need to ensure that elements are only stored within the matrix boundaries. If the number of overlapping columns, $n$, is smaller than $n_R$, the process is straightforward - we simply iterate over $n$ columns instead of​ $n_R$:\n\n// n - number of overlapped columns within C boundary // \"j < n\" instead \"j < 6\", since n can be less than 6. for ( int j = 0 ; j < n ; j ++ ) { _mm256_storeu_ps ( & C_start [ j * M ], C_accum [ j ][ 0 ]); _mm256_storeu_ps ( & C_start [ j * M + 8 ], C_accum [ j ][ 1 ]); }\n\nThe case where the number of overlapped rows $m$ differs from $m_R$ is a bit trickier because _mm256_storeu_ps stores 8 elements at once. Fortunately, immintrin.h library contains _mm256_maskstore_ps function, which stores packed floats according to mask values. The function takes three arguments as input:\n\nfloat *a __m256i mask __m256 b\n\n__m256i is a vector datatype that holds eight 32-bit integers. Each integer in mask corresponds to a data element in b . The most significant bit (MSB) of each integer in mask represents the mask bit. If the mask bit is zero, the corresponding value in b is not stored in the memory location pointed to by a . For example, the MSB of unsigned integer 2147483648 (binary format 10000000 00000000 00000000 00000000 ) is 1 , so the corresponding data element in b will be stored. On the other hand, the MSB of unsigned integer 2147483647 (binary format 01111111 11111111 11111111 11111111 ) is 0 , meaning the corresponding data element in b will not be stored.\n\nIf $m\n\neq m_R$ , we generate integer masks by left-shifting unsigned integer 65535 (= 00000000 00000000 11111111 111111111 in binary format) depending on the number of overlapped rows $m$. In the code snippet below the function _mm256_setr_epi32() creates a __m256i vector from eight 32-bit integers.\n\n__m256i masks [ 2 ]; if ( m != 16 ) { const uint32_t bit_mask = 65535 ; masks [ 0 ] = _mm256_setr_epi32 ( bit_mask << ( m + 15 ), bit_mask << ( m + 14 ), bit_mask << ( m + 13 ), bit_mask << ( m + 12 ), bit_mask << ( m + 11 ), bit_mask << ( m + 10 ), bit_mask << ( m + 9 ), bit_mask << ( m + 8 )); masks [ 1 ] = _mm256_setr_epi32 ( bit_mask << ( m + 7 ), bit_mask << ( m + 6 ), bit_mask << ( m + 5 ), bit_mask << ( m + 4 ), bit_mask << ( m + 3 ), bit_mask << ( m + 2 ), bit_mask << ( m + 1 ), bit_mask << m ); for ( int j = 0 ; j < n ; j ++ ) { _mm256_maskstore_ps ( & C_start [ j * M ], masks [ 0 ], C_accum [ j ][ 0 ]); _mm256_maskstore_ps ( & C_start [ j * M + 8 ], masks [ 1 ], C_accum [ j ][ 1 ]); } }\n\nThe compiler auto-vectorizes the sequential bit-shifting operations using a combination of vpaddd and vpsllvd instructions, making the mask computation very efficient. There is, however, an alternative method to compute the masks, as will be shown later.\n\nWhen loading elements from matrices $\\bar{A}$ and $\\bar{B}$ inside the kernel, we need to check that the loads are within the matrix boundaries. One way to do this is by using _mm256_maskload_ps when loading elements from the matrix $\\bar{A}$ and looping over $n$ elements instead of $n_R$ when loading elements from the matrix $\\bar{B}$. However, this method would significantly degrade the kernel’s performance. The additional instructions required to compute the loading masks introduce overhead, and since $n$ is not a compile-time constant, the compiler cannot unroll the loop efficiently. Instead, if $m\n\neq m_R$, we copy the matrix $\\bar{A}$ into a buffer, pad it with zeros and pass the padded matrix of size $m_R \\times K$ to the kernel. We do the same for the matrix $\\bar{B}$ if $n\n\neq n_R$. The implementation straightforwardly follows the description:\n\n#define BLOCK_A_MAXSIZE 500000 #define BLOCK_B_MAXSIZE 200000 static float blockA_buffer [ BLOCK_A_MAXSIZE ] __attribute__ (( aligned ( 64 ))); static float blockB_buffer [ BLOCK_B_MAXSIZE ] __attribute__ (( aligned ( 64 ))); void matmul_pack ( float * A , float * B , float * C , const int M , const int N , const int K ) { for ( int i = 0 ; i < M ; i += 16 ) { const int m = min ( 16 , M - i ); float * blockA = & A [ i ]; int blockA_ld = M ; if ( m != 16 ) { pack_blockA ( & A [ i ], blockA_buffer , m , M , K ); blockA = blockA_buffer ; blockA_ld = 16 ; } for ( int j = 0 ; j < N ; j += 6 ) { const int n = min ( 6 , N - j ); float * blockB = & B [ j * K ]; if ( n != 6 ) { pack_blockB ( & B [ j * K ], blockB_buffer , n , N , K ); blockB = blockB_buffer ; } kernel_16x6 ( blockA , blockB , & C [ j * M + i ], m , n , M , K , blockA_ld ); } } }\n\nFor further implementations details, please check matmul_pad.h\n\n7. Cache Blocking\n\nLet’s revisit the computer’s memory hierarchy. Previously, we focused on the main memory (DRAM) and the CPU registers, but we skipped an important intermediary: the CPU cache system.\n\nUnlike DRAM, the CPU cache is an on-chip memory designed to store frequently and/or recently accessed data from the main memory. This helps minimize data transfers between the main memory and CPU registers. Although the cache is much faster than DRAM, it has a limited storage capacity. To optimize data access, modern desktop CPUs use a multi-level cache hierarchy. This typically includes L1, L2, and L3 caches, each offering progressively larger storage but with increasing access times. L1 cache is the fastest and closest to the CPU core.\n\nIntel Core i9-13900K labelled die shot. Source: How are Microchips Made?\n\nTo improve access speed, CPUs transfer data between main memory and cache in fixed-size chunks called cache lines or cache blocks. When a cache line is loaded from main memory, it is stored as a cache entry. For example, in AMD Ryzen Zen CPUs, the cache line size is 64 bytes. The cache takes advantage of data locality - how programs typically access memory. When a single floating-point number is requested from a continuous array in memory, the cache doesn’t just fetch that one value; it also preloads the next floating-point numbers and stores them in the cache. This is why reading data sequentially from an array is much more efficient than randomly accessing scattered memory locations. When the CPU needs to read or write to a memory location, it first checks if the data is already in the cache. This leads to two possible scenarios:\n\nCache Hit - If the requested memory location is found in the cache, the CPU can access it instantly, avoiding the need to fetch data from the much slower DRAM. Cache Miss - If the requested data is not in the cache, the CPU retrieves it from the main memory and stores it in the cache for future access.\n\nSince the cache has limited space, it must decide which data to replace when new information needs to be stored. This decision is governed by a cache replacement policy. Some of the most common policies include:\n\nLRU (Least Recently Used): Replaces the cache entry that has gone unused the longest. LFU (Least Frequently Used): Evicts the entry that has been accessed the least often. LFRU (Least Frequently Recently Used): A hybrid approach that considers both recent and overall access frequency.\n\nSimilar to registers, once data is loaded into the cache, we want to reuse the data as much as possible to reduce main memory accesses. Given the cache’s limited capacity, storing entire input matrices $C, B, A$ in the cache isn’t feasible. Instead, we divide them into smaller blocks, load these blocks into the cache, and reuse them for rank-1 updates. This technique is often referred to as tiling or cache blocking, allowing us to handle matrices of arbitrary size effectively.\n\nThe single-threaded matrix multiplication with cache blocking can be visualized as shown in the image borrowed from the official BLIS repository:\n\nLet’s step through the diagram and discuss it. In the outer-most loop (5th loop) we iterate over dimension $N$, dividing matrix $C$ into blocks $C_j$ of size $M \\times n_c$ and matrix $B$ into blocks $B_j$ of size $K \\times n_c$. The subscript $c$ in $n_c$ stands for cache. In the 4th loop we iterate over dimension $K$ and divide matrix $A$ into $A_j$ of size $M \\times k_c$ and $B_j$ into $B_p$ of size $k_c \\times n_c$. Notice $B_p$ has fixed, limited size and can now be loaded into the cache. $B_p$ is packed into $\\tilde{B}_p$, padded with zeros, if necessary, and loaded into the L3 cache. I In the 3rd loop we iterate over dimension $M$ and divide $C_j$ into $C_i$ (there is a typo in the diagram) of size $m_c \\times n_c$ and $A_p$ into $A_j$ of size $m_c \\times k_c$. Matrix $A_j$ is now restricted in size and can be loaded entirely into the L2 cache. $A_j$ is packed into $\\tilde{A}_j$ and padded with zeros if needed. Note how we reuse the same $\\tilde{B}_p$ block from the L3 cache for different $A_j$ blocks. Both $m_c$ and $n_c$ are chosen to be a multiple of $m_R$ and $n_R$ respectively.\n\nIn the last two loops we simply iterate over cached blocks and divide them into $m_R \\times k_c$ and $k_c \\times n_R$ panels. These panels are then passed to the kernel to perform rank-1 updates on the $m_R \\times n_R$ sub-matrix of $C$, similarly to what we have already done in the previous chapter. Each panel of $\\tilde{B}_p$ is loaded into the L1 cache and reused for multiple panels of $\\tilde{A}_j$. Keep in mind that $\\tilde{A}_j$ and $\\tilde{B}_p$ are packed differently. During rank-1 updates we sequentially read a panel of $\\tilde{A}_j$ column by column and a panel of $\\tilde{B}_p$ row by row. Thus, each panel inside $\\tilde{A}_j$ is stored in column-major order, while each panel inside $\\tilde{B}_p$ is stored in row-major order.\n\nDifferent CPU models have different cache sizes. To achieve peak performance, it’s crucial to optimize three key parameters: cache sizes for L1, L2, and L3 cashes (represented by $k_c$​, $m_c$​, and $n_c$​ respectively). Theoretically, these parameters should be chosen so that:\n\n$k_c​ \\times n_c$​ fills the entire L3 cache.\n\n$m_c​ \\times k_c​$ fills the entire L2 cache.\n\n$k_c​ \\times n_R$​ fills the entire L1 cache.\n\nWhile these values provide a good starting point, using larger values often leads to better performance in practice. Unfortunately (or fortunately), we cannot manually place data into the cache or control which cache levels store the data; the CPU manages this automatically using cache replacement policies. Therefore, cache blocking and cache reuse must be implemented at the algorithm level through, for example, well-designed loops and strategic data access patterns.\n\nThe implementation matmul_cache.h straightforwardly follows the algorithm depicted in the diagram:\n\nvoid matmul_cache ( float * A , float * B , float * C , const int M , const int N , const int K ) { for ( int j = 0 ; j < N ; j += NC ) { const int nc = min ( NC , N - j ); for ( int p = 0 ; p < K ; p += KC ) { const int kc = min ( KC , K - p ); pack_blockB ( & B [ j * K + p ], blockB_packed , nc , kc , K ); for ( int i = 0 ; i < M ; i += MC ) { const int mc = min ( MC , M - i ); pack_blockA ( & A [ p * M + i ], blockA_packed , mc , kc , M ); for ( int jr = 0 ; jr < nc ; jr += NR ) { for ( int ir = 0 ; ir < mc ; ir += MR ) { const int mr = min ( MR , mc - ir ); const int nr = min ( NR , nc - jr ); kernel_16x6 ( & blockA_packed [ ir * kc ], & blockB_packed [ jr * kc ], & C [( j + jr ) * M + ( i + ir )], mr , nr , kc , M ); } } } } } }\n\n8. Kernel Micro-Optimizations\n\nInstead of using arrays of __m256 to define the accumulator $\\bar{C}$ and the masks\n\n__m256 C_buffer [ 6 ][ 2 ]; __m256i masks [ 2 ];\n\nwe explicitly unroll them\n\n__m256 C00 = _mm256_setzero_ps (); __m256 C10 = _mm256_setzero_ps (); __m256 C01 = _mm256_setzero_ps (); __m256 C11 = _mm256_setzero_ps (); __m256 C02 = _mm256_setzero_ps (); __m256 C12 = _mm256_setzero_ps (); __m256 C03 = _mm256_setzero_ps (); __m256 C13 = _mm256_setzero_ps (); __m256 C04 = _mm256_setzero_ps (); __m256 C14 = _mm256_setzero_ps (); __m256 C05 = _mm256_setzero_ps (); __m256 C15 = _mm256_setzero_ps (); __m256i packed_mask0 ; __m256i packed_mask1 ;\n\nBy doing this, GCC can better optimize the code avoiding register spilling. Additionally, we use vector instructions to calculate the masks as follows:\n\nstatic int8_t mask [ 32 ] __attribute__ (( aligned ( 64 ))) = { - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 }; packed_mask0 = _mm256_cvtepi8_epi32 ( _mm_loadu_si64 ( & mask [ 16 - mr ])); packed_mask1 = _mm256_cvtepi8_epi32 ( _mm_loadu_si64 ( & mask [ 16 - mr + 8 ]));\n\nThe corresponding implementation can be found at matmul_micro.h\n\n9. Multithreading\n\nThere are indeed many loops that can be potentially parallelized. To achieve high-performance, we want to parallelize both packing and arithmetic operations. Let’s start with the arithmetic operations. The 5th, 4th, 3rd loops around the micro-kernel iterate over matrix dimensions in chunks of cache block sizes $n_c$, $k_c$, $m_c$. To efficiently parallelize the loops and keep all threads busy, we want number of iterations (=matrix dimension / cache block size) to be at least = number of threads (generally, the more the better). In other words, the input matrix dimension should be at least = number of threads * cache block size. As we discussed earlier, we also want cache blocks to fully occupy the corresponding cache levels. On modern CPUs, the second requirement results in cache block sizes of thousand(s) of elements. For example, on my Ryzen 9700X, cache block sizes of $n_c=1535$, $m_c=1024$ attain the best performance in the single-threaded scenario. Given the number of available cores on Ryzen 9700X, we need input matrices with dimensions of at least $\\max(m_c, n_c) \\times \\text{number of cores} = 1535 \\times 8 = 12280$ to be able to distribute the work over all cores.\n\nIn contrast, the last two loops iterate over cache blocks, dividing them into $m_R, n_R$ blocks. Since $n_R, m_R$ are typically very small (<20), these loops are ideal candidates for parallelization. Moreover, we can choose $m_c, n_c$ to be multiples of number of cores so that the work is evenly distributed across all cores.\n\nOn my machine, parallelizing the second and first inner loops jointly with collapse(2) results in the best performance:\n\n#pragma omp parallel for collapse(2) num_threads(NTHREADS) for ( int jr = 0 ; jr < nc ; jr += NR )\n\nMore on OpenMP here, here and here.\n\nFor many-core processors (> 16 cores), consider utilizing nested parallelism and parallelizing 2-3 loops to increase the performance.\n\nTogether with arithmetic operations, we will also parallelize the packing of both $\\tilde{A}$ and $\\tilde{B}$:\n\nvoid pack_blockA ( float * A , float * blockA_packed , const int mc , const int kc , const int M ) #pragma omp parallel for num_threads(NTHREADS) for ( int i = 0 ; i < mc ; i += MR )\n\nvoid pack_blockB ( float * B , float * blockB_packed , const int nc , const int kc , const int K ) #pragma omp parallel for num_threads(NTHREADS) for ( int j = 0 ; j < nc ; j += NR )\n\nSimilar to the second loop (and the first loop) around the micro-kernel, the packing loops can be efficiently parallelized due to the high number of iterations and the flexibility of choosing $m_c, n_c$. For the multi-threaded implementation the values\n\n\\[m_c = m_R \\times \\text{number of threads} \\times 5\\] \\[n_c = n_R \\times \\text{number of threads} \\times 50\\]\n\nprovide the best performance on my machine, leading to the final optimized multi-threaded implementation matmul_parallel.h",
      "source": "Github.io",
      "url": "https://salykova.github.io/gemm-cpu",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Intel Gains on Report That It’s in Talks to Add AMD as Customer",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/ec99db0a1eaeec85",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Trading Day: Shutdown? Stocks up!",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/7e271fc37b1b6ed3",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Apple Shelves Vision Headset Revamp to Prioritize Meta-Like AI Glasses",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/63da37611e6386ec",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Relief for Fed From Supreme Court’s Cook Order May Be Fleeting",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/37f2a351ff4d7979",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Windows 10's upcoming End of Life is bad news for PC gamers who hate Windows 11, as Capcom issues warning",
      "content": "Capcom has announced it will no longer guarantee stability for Monster Hunter games after October 14\n\nThis is a result of Windows 10's End of Life, as Microsoft shifts focus to Windows 11\n\nIt could leave other game developers and publishers doing the same thing, and drive users to other operating systems\n\nMicrosoft's Windows 10 only has days left before its inevitable demise, with security updates ending on October 14, and despite the gesture of free extended support for users in Europe, it likely won't stop the impact that the OS's abandonment will have on games.\n\nAs reported by TweakTown, Capcom has announced that it can no longer 'guarantee' game stability for Windows 10 users playing Monster Hunter: World, Monster Hunter: Wilds, or Monster Hunter: Rise, once Microsoft ends support commencing October 14. This would likely be due to future system updates or game title updates, where Capcom won't be providing fixes in cases of incompatibility.\n\nIt's unclear if Capcom will also leave Windows 10 support behind for its other titles, like Street Fighter 6 and the upcoming Resident Evil Requiem, especially with the former receiving frequent updates and new DLC, but it wouldn't be surprising if the same case applies (at least later down the line).\n\nThis essentially leaves gamers who don't like Windows 11 to either install an alternative like Tiny11, which is a bloatware-free version of Windows 11, switch to Valve's SteamOS, or make the dreaded switch to Windows 11.\n\nGame support being dropped by Capcom, potentially alongside other game developers and publishers, shouldn't impact those on hardware that is incompatible with Windows 11, as gaming (at least with more modern demanding titles) on these systems would be difficult with older hardware to begin with – but it also serves as a wake-up call for a hardware upgrade for many users.\n\nAnalysis: sorry not sorry, but Valve's SteamOS is looking more appealing each day\n\n(Image credit: Steam)\n\nIt's already a bold move from Microsoft to part ways with Windows 10, since there are still many users on the operating system, but its impact on gaming looks like it could spread wider than anticipated. In that case, Valve's SteamOS is looking like a stronger option for gamers who are adamantly staying away from Windows 11.\n\nI'm not here to regurgitate why I prefer SteamOS over Windows 11 again, but the simple fact is that game performance is better on the Linux-based OS, and I have no doubts that it will stay that way for a while, even after Microsoft's anticipated 'full-screen experience' implementation for desktop PCs.\n\nGet daily insight, inspiration and deals in your inbox Sign up for breaking news, reviews, opinion, top tech deals, and more. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFortunately, I don't have an urgent need to switch over to SteamOS since Windows 11 is stable enough for my desktop gaming PC, but once improvements are made for Nvidia GPUs and apps like Discord, I'll make the switch in a heartbeat.\n\nWith that being said, if you're using an AMD GPU and you don't want to move over to Windows 11, I'd say you're better off leaping over to Linux. SteamOS is built to provide a console-like, simple gaming experience, and more importantly, in this case, you won't run into issues of losing game stability due to devs begrudgingly abandoning support.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/computing/windows/windows-10s-upcoming-end-of-life-is-bad-news-for-pc-gamers-who-hate-windows-11-as-capcom-issues-warning",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Stockholm-based driverless truck startup Einride raised about $100M, a source says at a $1B+ valuation, up from a valuation of €400M in a 2021 funding round",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/f715ee281cc18c9f",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "US takes a stake in another company, this one is operating a massive lithium mine in Nevada",
      "content": "The U.S. government is taking a minority stake in Lithium Americas, a company that is developing one of the world’s largest lithium mines in northern Nevada.\n\nThe Department of Energy will take a 5% equity stake in the miner, which is based in Vancouver. It will also take a 5% stake in the Thacker Pass lithium mining project, a joint venture with General Motors.\n\nThacker Pass is considered crucial in reducing U.S. reliance on China for lithium, a critical material used to produce the high tech batteries used in cell phones, electric vehicles and renewable energy. Both Republicans and Democrats support the project and narrowing the production gap. China is the world’s largest lithium processor.\n\nU.S. Energy Secretary Chris Wright said in a statement that the deal with Lithium Americas “helps reduce our dependence on foreign adversaries for critical minerals by strengthening domestic supply chains and ensures better stewardship of American taxpayer dollars.”\n\nThacker Pass is expected to produce 40,000 metric tons of battery-quality lithium carbonate per year in its first phase, enough to help power 800,000 EVs.\n\nThe equity stake in Lithium Americas is the latest example of the direct intervention by the Trump administration with private companies. The government is getting a 10% stake in Intel through the conversion of billions in previously granted government funds and pledges. The administration spent $400 million of taxpayer money in July on MP Materials stock to make the U.S government the biggest owner in the Las Vegas rare earths miner. Trump also made a deal with Nvidia and AMD to give the U.S. government a 15% cut of revenue from selling certain chips to China.\n\nLithium Americas said Wednesday that it reached a non-binding agreement in principle with the DOE to advance the first draw of $435 million on the federal loan. The DOE has agreed to defer $182 million of debt service over the first five years of the loan.\n\nThe White House and Canada's Lithium Americas seemed to be moving forward with the deal late last month, as both parties agreed on changes to an approximately $2.3 billion federal loan that could allow the project to move forward to extract the silver-white metal used in electric vehicle batteries. GM has pledged more than $900 million to help develop Thacker Pass, which holds enough lithium to build 1 million electric vehicles annually.\n\nDan Ives, an analyst with Wedbush, called Thacker Pass is a “massive opportunity” for the U.S. to reduce its reliance on China and other foreign adversaries for lithium.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/us-takes-minority-stake-company-115743865.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Nvidia Stock Is on Pace for a Record High. Can It Keep Its Lead Over AMD?",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/466938187963b376",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Washington takes stake in company building one of the world’s largest lithium mines as it races to catch up with China",
      "content": "The U.S. government is taking a minority stake in Lithium Americas, a company that is developing one of the world’s largest lithium mines in northern Nevada.\n\nThe Department of Energy will take a 5% equity stake in the miner, which is based in Vancouver. It will also take a 5% stake in the Thacker Pass lithium mining project, a joint venture with General Motors.\n\nThacker Pass is considered crucial in reducing U.S. reliance on China for lithium, a critical material used to produce the high tech batteries used in cell phones, electric vehicles and renewable energy. Both Republicans and Democrats support the project and narrowing the production gap. China is the world’s largest lithium processor.\n\nU.S. Energy Secretary Chris Wright said in a statement that the deal with Lithium Americas “helps reduce our dependence on foreign adversaries for critical minerals by strengthening domestic supply chains and ensures better stewardship of American taxpayer dollars.”\n\nThacker Pass is expected to produce 40,000 metric tons of battery-quality lithium carbonate per year in its first phase, enough to help power 800,000 EVs.\n\nThe equity stake in Lithium Americas is the latest example of the direct intervention by the Trump administration with private companies. The government is getting a 10% stake in Intel through the conversion of billions in previously granted government funds and pledges. The administration spent $400 million of taxpayer money in July on MP Materials stock to make the U.S government the biggest owner in the Las Vegas rare earths miner. Trump also made a deal with Nvidia and AMD to give the U.S. government a 15% cut of revenue from selling certain chips to China.\n\nLithium Americas said Wednesday that it reached a non-binding agreement in principle with the DOE to advance the first draw of $435 million on the federal loan. The DOE has agreed to defer $182 million of debt service over the first five years of the loan.\n\nThe White House and Canada’s Lithium Americas seemed to be moving forward with the deal late last month, as both parties agreed on changes to an approximately $2.3 billion federal loan that could allow the project to move forward to extract the silver-white metal used in electric vehicle batteries. GM has pledged more than $900 million to help develop Thacker Pass, which holds enough lithium to build 1 million electric vehicles annually.\n\nDan Ives, an analyst with Wedbush, called Thacker Pass is a “massive opportunity” for the U.S. to reduce its reliance on China and other foreign adversaries for lithium.\n\n“Despite having some of the largest deposits, the U.S. produced less than 1% of the global lithium supply but this deal helps reduce dependence on foreign adversaries for critical minerals strengthening domestic supply chains and ensuring better stewardship of American taxpayer dollars with lithium production set to grow exponentially over the coming years,” he wrote.\n\nShares of Lithium Americas spiked more than 30% Wednesday.",
      "source": "Fortune",
      "url": "https://fortune.com/2025/10/01/president-trump-administration-investment-electric-vehicles-united-states-lithium-energy-stake-company-deaprrtment-of-energy-general-motors-chris-wright-battery-washington-snaps-up-stake-in-lithium-am/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Intel stock pops on news company is in early talks to add AMD as a customer",
      "content": "The U.S. government, Nvidia and Softbank have all taken recent stakes in Intel.\n\nThis story appeared on cnbc.com , 2025-10-01 18:33:44.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/dee93ff2f56a4291",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "(PR) Starforge Systems Launches Jujutsu Kaisen 0 PC Collection",
      "content": "PC: Whether fulfilling a lifelong promise or simply trying to rid yourself of a curse, you'll want to be well equipped for the battle ahead. Luckily, there's the Jujutsu Kaisen 0 PC from Starforge. This high-quality PC not only honors the esteemed film, but also features a AMD RX 9070 XT 16 GB GPU, AMD Ryzen 5 7600X CPU and a custom UV printed case.\n\nWall Art: $59.99 If aesthetics are more your style, the collection's wall art is accented with dynamic, stunning artistry starring the film's characters. Immerse yourself in the hidden reality of the Jujutsu Kaisen 0 world with these carefully detailed acrylic wall art panels. ($59.99 individually)\n\nDesk Mat: $49.99 Complete the collection with the accompanying Jujutsu Kaisen 0 desk mat that acts as a perfect compliment to any existing art. This themed 900x400mm is an excellent cover for your desk or an extra-large mousepad.\n\n\n\nAttention all Jujutsu Kaisen 0 fans! Starforge Systems is excited to announce the launch of their all-new Limited Edition PC collection celebrating the iconic anime film, Jujutsu Kaisen 0. Featuring powerful components and striking artwork that stars the movie's cast, this collection is a must have, no matter how obsessed you are with Gojo.The Jujutsu Kaisen 0 PC bundle ($2399.99) brings the world of Jujutsu Kaisen to life, and fans can now channel their inner sorcerer with the PC, desk mat and wall art from Starforge Systems' collection.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341540/starforge-systems-launches-jujutsu-kaisen-0-pc-collection",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Intel in early talks to add AMD as foundry customer, Semafor reports",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/4af988d48873dae1",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Lenovo Legion Go 2 review: AMD’s Ryzen Z2 Extreme makes gains at 800p",
      "content": "The Lenovo Legion Go 2 boosts performance at low resolutions with the AMD Ryzen Z2 Extreme. Lenovo improves ergonomics and adds a gorgeous OLED screen, but the system is still bulky, heavy, and quite pricey.\n\nWhy you can trust Tom's Hardware Our expert reviewers spend hours testing and comparing products and services so you can choose the best for you. Find out more about how we test.\n\nFor the last few years, most of the best PC gaming handhelds were running on the same chips. But with its new Lenovo Legion Go 2, Lenovo is using the latest AMD Ryzen Z2 Extreme , while also making plenty of upgrades to the design.The new Legion Go still has detachable controllers and an 8.8-inch screen. But now, that screen is OLED (albeit with a lesser resolution than last time around), and the system has better ergonomics. But it's still bulky, heavy, and our unit was $1,349.99 as tested (though it does seem like the market may follow with increased prices). Still, the Z2 Extreme does offer some performance benefits, particularly at 1280 x 800pIf you want a slew of hardware features, the Legion is an obvious, if expensive, way to go. If you're willing to have a simpler experience without OLED and detachable controllers, there are still plenty of options on the handheld market that cost less, though admittedly few with the Z2 Extreme just yet.\n\nDesign of the Lenovo Legion Go 2\n\nThere's no doubt about it: The Legion Go 2 is a thick, bulky handheld. That mass allows for the connection to the removable controllers, and hopefully, we'll also find that it allows for strong cooling.Lenovo's \"TrueStrike\" controllers still resemble Nintendo's Switch Joy-Cons in that they disconnect from the system and control it wirelessly, but that's where most of the comparisons end. These controllers are bulky, though Lenovo has improved the ergonomics from the original, and they fit more comfortably in my hands thanks to more rounded edges. There's still a standard Xbox-style A/B/X/Y layout with offset joysticks. On the rear, the left controller has two buttons, while the right controller has one (as well as two customizable buttons to use in mouse mode).\n\n(Image credit: Tom's Hardware)\n\nThe controllers now have Hall effect joysticks that should prevent drift, and a redesigned D-Pad sits on a pivot disk. The buttons are a bit less tactile than I'd like, but I got used to them quickly. Beyond the two rear buttons on each controller, the right controller also features three customizable buttons through Legion Space, and it still features a mouse sensor for the \"FPS mode\" from the previous generation, with an included base. In short, the controller sits in base vertically, letting you grip the controller like a joystick, while moving it like a mouse.\n\nFPS mode works, but I rarely found it my go-to mode, as I tend to be sitting without a desk when I'm playing on a handheld. If you do use it, you'll have to do a lot of button remapping. In several games I played, certain commands didn't have a default mapping. You can create as many profiles as you want, but if you play lots of shooters, you'll want to save lots of presets and switch between them before games.\n\nImage 1 of 2 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nI do wish the right control stick were slightly lower on the controller. On a standard Xbox controller, the stick is under the buttons like it is here, but ever so slightly more to the left. When I played Tony Hawk's Pro Skater 3 + 4, my thumb rubbed against the stick when I was pressing buttons to jump and do tricks.\n\nWhat did take me a bit of time to get used to was the sheer number of menu and options buttons. The left controller has four (one for Legion Space, one for the Xbox-style view button, and dedicated buttons for Alt-Tab and showing the Windows desktop), while the right side has a more standard two for quick settings (I used this a lot) and an Xbox Menu button.\n\nImage 1 of 2 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nI still wish there were a regular Xbox button for Game Bar (there is a shortcut to act as one, however).\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe right controller still has a touchpad, but there isn’t a corresponding one on the left side. I much prefer the Steam Deck's option to have both, if you're going to go that route at all.\n\nLenovo's controllers connect to the system with Pogo pins. Each controller slides into a rail system and then disconnects with a push button. The disconnect is easy enough, but I sometimes had a hard time sliding the controllers back in, and ended up scratching some paint on the rail on the right controller. The system also comes with a cover for one set of pins to cover the right rail in FPS mode. I do wish it included two covers for people who use both controllers disconnected often.\n\nImage 1 of 2 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nOn top of the system, there's a USB4 Type-C port, volume rocker, and the power button, which now also doubles as a fingerprint reader. All of the other ports — another USB-C port, a 3.5 mm headphone jack, and a microSD card slot — are on the bottom of the system. This is a good layout, allowing you to charge and attach a USB-C peripheral at the same time. The fingerprint reader is useful, but it's a bit of a stretch to reach when holding the system in handheld mode.There are RGB circles around the joysticks, providing a bit of customizable decoration. While colors can be changed in the Legion Space app, the light rings can also be used to show how much battery is left (based on a series of blinking patterns) and if the controllers are connected.\n\n(Image credit: Tom's Hardware)\n\nThe back of the system has a sturdy kickstand that covers most of the width of the console. You won't have any worries about this thing falling over. Above the kickstand are a series of vents, which suck in cool air, run it over the Z2 Extreme, and then exhaust through vents on the top. These were far enough from my hands that I didn't even think about them when playing games.\n\nAt 11.64 x 5.38 x 1.66 inches with the controllers on, it's thicker than the original Go, but ever so slightly smaller in other dimensions. The Asus ROG Ally X is substantially smaller at 11.02 x 4.37 x 1.45 inches, while the Steam Deck OLED is the widest of the bunch at 11.73 x 4.6 x 1.97 inches.\n\n\n\nAt 2.03 pounds with the controllers, the Legion Go 2 is heavier than the original Go (1.88 pounds), the Ally X (1.49 pounds), and the Steam Deck OLED (1.41 pounds). While some people may prefer the large screen and controllers, I felt the weight immediately and would sometimes end play sessions with tired hands and wrists.\n\nLenovo Legion Go 2 Specifications and Components\n\nThe Legion Go 2 is the first PC gaming handheld that we're testing with AMD's Ryzen Z2 Extreme processor. Like the Z1 Extreme before it, this is an 8-core, 16-thread processor, but it's now using three Zen 5 cores and five Zen 5c cores.The Z2 Extreme has a max boost clock of up to 5 GHz on the Zen 5 cores, (3.3 GHz on the Zen 5c cores) and a base clock of 2 GHz. (That max boost is actually 0.1 GHz slower than the Z1 Extreme). While the Z2 Extreme shares a 28W TDP with its predecessor, it has a 15-35W configurable TDP, which is higher than the Z1 Extreme's 9-30W cTDP. The 16-core GPU is a bump up from the 12-core GPU in the Z1 Extreme, and now it uses more recent Radeon RDNA 3.5 graphics.\n\nThe 32GB of RAM in this Legion Go 2 review unit should help it, as the CPU and GPU share the RAM. It's a step above what we saw in the Asus ROG Ally X, which used 24GB of RAM.The 1TB drive that Lenovo includes is an M.2 2242 SSD, but if you want to upgrade on your own, the slot can fit standard-length M.2 2280 drives.\n\nLenovo's 74 WHr battery is a big increase over the 49.2 WHr cell in the original Legion Go. The Ally X has a slightly larger 80 WHr battery.\n\nSwipe to scroll horizontally Processor AMD Ryzen Z2 Extreme (8 cores, 16 threads, 15-35W cTDP) Graphics AMD Radeon RDNA 3.5 graphics (16 cores) Memory 32GB LPDDR5x-8000, soldered Storage 1TB M.2 2242 SSD, M.2 2280 slot Display 8.8-inch, 1920 x 1200, 30-144 Hz, OLED, touch Networking Wi-Fi 6E, Bluetooth 5.3 Ports 2x USB 4.0 40 Gbps, 3.5 mm headphone jack, microSD card reader, Pogo pin connectors for controllers Battery 74 WHr Power Adapter 65 W Operating System Windows 11 Home Dimensions System with controllers: 11.64 x 5.38 x 1.66 inches (295.6 x 136.7 x 42.25 mm)\n\n\n\nWithout controllers: 8.11 x 5.38 x 0.90 inches (206 x 136.7 x 22.95 mm) Weight 2.03 pounds with controllers (920 grams) Accessories FPS mode puck, carrying case Price (as configured) $1,349.99\n\nGaming and Graphics Performance on the Lenovo Legion Go 2\n\nThe Z2 Extreme and its integrated 16-core Radeon RDNA 3.5 graphics offer a boost over Z1 Extreme and the custom chips in the Steam Deck. I don't think it's inherently worth upgrading if you have one of those systems, though it should allow for some slight boosts in quality.\n\nOut of the box, Lenovo's default thermal mode is \"Performance,\" though there are also \"Quiet\" and \"Balanced\" options. The default fan option is \"smart,\" which features a gentle curve, though you can adjust it. In our benchmark testing, we test handhelds plugged in and unplugged to see performance differences. We ran the Legion Go 2 unplugged at the default performance setting. Plugged in, I used a custom mode with a 35W TDP and a 45W burst, along with fans running full speed. That TDP increase tended to show bigger improvements at lower resolutions.\n\nIn a note for reviewers, though, Lenovo suggested that performance mode is recommended when plugged into the wall. So while we're reviewing at defaults, you'll probably want to step down to at least balanced mode when unplugged for longer battery life.\n\nNote that while we ran our benchmarks at 1280 x 800 and 1920 x 1200, we had to adjust those to standard 1080p and 720p for the Asus ROG Ally X, which has a 16:9 screen, unlike the Legion Go 2, Legion Go, and Steam Deck.\n\nWhen I played Tony Hawk's Pro Skater at 1280 x 800 on performance mode at high settings, the game ran between 73 and 93 frames per second. Marvel's Midnight Suns easily hit a 60 FPS cap I instituted on medium settings when I had thermals on balanced mode.\n\nImage 1 of 4 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nOn the Shadow of the Tomb Raider benchmark at medium settings, the system ran at 66 frames per second at 800p unplugged and 75 FPS plugged in at a slightly higher TDP. At 1200p, it ran at 42 FPS unplugged and 47 FPS plugged in. This showed a large improvement over the previous generations at 800p.\n\nUsing Cyberpunk 2077's Steam Deck Preset, the Legion Go 2 again made strides at 800p at 47 FPS unplugged and 57 FPS plugged in. At 1200p, the game was playable, but this was one area where this system lost to the original ROG Ally X.\n\nThe trends continued in Red Dead Redemption 2's lowest (favor performance) settings using Vulkan. The game ran at 65 FPS unplugged at 800p and 80 FPS plugged in. At 1200p, it ran at 46 FPS and 50 FPS, respectively.\n\nYou probably won't be using a handheld to play Borderlands 4, so we gave Borderlands 3 another run (medium settings, DX11). Shocker: more gains at 800p, hitting 76 FPS plugged in and 67 FPS unplugged. At 1200p, it ran at 50 FPS unplugged and 56 FPS with the TDP boost plugged in.\n\nWe also ran our 15-run Metro Exodus stress test. For handhelds, we drop this down to low settings at 720p while plugged in. Given the results, we may need to reconsider that in the future to make it more stressful. The Legion Go 2 ran the game at an average 123 frames and was largely consistent between the runs.\n\nThe Zen 5 cores ran at an average of 3.8 GHz during the test, while the Zen 5c ran at 2.74 GHz. The integrated GPU averaged 1.963.47 MHz.\n\nLenovo Legion Space on the Lenovo Legion Go 2\n\nAt its best, Lenovo's Legion Space is the best software I've seen that attempts to mask Windows 11's flaws for gaming handhelds. At its worst, I had it freeze on me mid-game. Windows 11 is still just not great without a mouse and keyboard.\n\nThen again, Microsoft's handheld gaming mode for Windows 11 is likely to come to the Legion Go 2 next year (or you could try to run a leaked version now ), so this may all be moot in a few months.\n\nImage 1 of 3 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nLegion Space can show system stats, let you adjust and calibrate controls, and launch installed games. It often launched in the background when I booted the system up, though sometimes it would come to the foreground, oddly enough. There's also a store to buy games through Lenovo, but I prefer to stick to the big launchers.\n\nThe part I enjoyed most was the quick settings menu, which acts like what we've seen on the Steam Deck and ROG Ally X. But among Windows devices, the Legion Go 2's menu was the most responsive, easiest to navigate, and has the most useful shortcuts. I used it a surprising amount.\n\n(Image credit: Tom's Hardware)\n\nIt also has the system's performance profiles. While the system defaults to Performance mode out of the box, enthusiasts may appreciate the custom option that lets you make adjustments on a watt-by-watt basis.\n\nThere are also numerous shortcuts for everything from taking screenshots to increasing or decreasing power consumption. The shortcut to see all of the shortcuts is the Legion Space button + LB.\n\nThe one big problem I had with Legion Space was trying to remap controls while in a game. It was too much, and the software kept freezing up and telling me to update my controllers (there was no new firmware for the controllers.)\n\nIt might be more helpful for Legion Space to always launch on boot, but it's easy enough to open with a touch of a button on the left controller.\n\nOf course, this all runs with Windows 11, which means all of its shortcomings. To set the devices up, you'll need to use lots of usernames and passwords for launchers, all of which require poking at the touchscreen unless you connect a keyboard.\n\nDisplay on the Lenovo Legion Go 2\n\nThe Legion Go 2's 8.8-inch display has seen some changes since the last generation of Legion Go. While the last screen was very pretty, this one uses OLED technology for more vivid colors and deeper blacks. The 1920 x 1200 resolution is a drop from 2560 x 1600 on the original Go, but in general I'm OK with this, as the integrated graphics available aren't capable of running too many games at that resolution anyway.\n\nAnd the screen is beautiful. Games look great. In Tony Hawk's Pro Skater 3 + 4, the Tokyo tournament level is filled with neon pink, purple, and blue ramps and rails that contrast with the cement of streets and bike lanes. The OLED screen made those colors scream, and those ramps looked great as I had skaters do grab tricks over them. In Marvel's Midnight Suns, Doctor Strange's red cape contrasted against Venom's symbiote skin in an early game mission.\n\n(Image credit: Tom's Hardware)\n\nThe Legion Go did very well on our measured tests, covering 135.8% of the DCI-P3 , by volume, and 191.7% of the sRGB space, far and away beating the rest of the field. And while it's definitely usable at 445 nits of brightness, it's dimmer than the non-OLED Go, as well as the Asus ROG Ally X and Steam Deck OLED. (The original Steam Deck can't hold a candle to any of these screens.)\n\nWhen the screen's brightness is way up, it looks incredible. When you have it turned down, you start to notice how glossy reflective it is. When I took a break from work to use the system to play some games at my desk, which is next to a window, it wasn't as pleasant to use. But if you want to save battery by turning down the luminosity, you'll have to deal with it.\n\nBattery Life on the Lenovo Legion Go 2\n\nThe bad news is that despite being thicker and bringing a bigger battery, the Legion Go 2 won't last through a cross-country flight for most games.\n\nAt one point in my testing, I spent an hour and a half playing Marvel's Midnight Suns at what I thought were pretty generous settings. I set the screen to 800p and played the game at 720p; knocked the power profile down to balanced; set the screen to just 30% brightness, which was still usable in the dark room I was playing in; limited the frame rate to 60 frames per second; and played on medium settings in the game.\n\nAfter an hour, I was down to 66% of battery. By the full hour and a half, I was down to 50%, with the system estimating I had an hour and 28 minutes remaining.\n\nAnother time, I spent an hour playing Tony Hawk's Pro Skater 3 + 4. This time I had the screen at 50% brightness and 144 Hz, but still at 1280 x 800. When I was done, 54% of the battery remained, with the Legion predicting I had 1 hour and 51 minutes remaining.\n\nBattery life will depend heavily on what games you play and the settings you play them at, but that initial three-hour window for a game with fairly light recommended settings isn't a great look. If you play a 2D game like Stardew Valley or Dead Cells, sure, expect more. If you run Cyberpunk 2077 as hard as you can to get playable frame rates on the Legion, expect less.\n\nAudio on the Lenovo Legion Go 2\n\nThe 2W stereo speakers on the Legion Go 2 do a decent job, but they have one disadvantage: they're on top of the handheld. That means they point just a little bit away from you.\n\nStill, they were more than loud enough. Full volume easily filled a small room, and I was more than comfortable at 60%. When I played Tony Hawk's Pro Skater 3 + 4, the system was challenged with both music and game sound effects. The vocals and guitars on KennyHoopla and Travis Barker's \"hollywood sucks//\" sounded clear, even under the sounds of grinding on rails, wheels rolling, and skaters yelping in pain as they fell. The only thing that really suffered was the deepest low end. In this case, it was the drums in the background song, and you don't hire Travis Barker if you don't want great drums.\n\nHeat on the Lenovo Legion Go 2\n\nI measured skin temperatures while running our Metro Exodus stress test. The system stayed cool where it was important.\n\nThe controllers each measured roughly 84 degrees Fahrenheit. It makes sense these would stay cool, as they're technically separate units, even though I had them attached to the system for the test.\n\nThe hottest point on the rear of the system reached 98.3 F, near the vents. My fingers didn't reach there. The hottest point was the exhaust by the top vent at 106.3 F, though again, it's far from where I would grip the system in handheld mode.\n\nDuring the test, the CPU averaged 65.5 degrees Celsius, while the GPU cores averaged 62.9 C.\n\nUpgradeability of the Lenovo Legion Go 2\n\nBefore you open the Legion Go 2, you're best off removing the controllers to prevent wobble. Once they're off, there are eight Phillips head screws screws on the back to remove. Two of those are underneath the kickstand, so you'll want to lift that to its maximum angle. Those two screws are very recessed, so you'll need a thin screwdriver, which I didn't have on me. What we do know, we've been able to find from Lenovo's detailed maintenance manual .\n\nOnce those are out, you'll need a pry tool to loosen the clips and remove the back.\n\nWhile you can swap out the M.2 SSD , it's not immediately visible. You also have to remove the battery and the fan to get access, which isn't as easy as some competitors. Once you do that, a single screw holds down the M.2 2242 SSD, just like any other PC. While Lenovo is using an M.2 2242, the slot supports M.2 2280, which is more common.\n\nLenovo Legion Go 2 Configurations\n\nThere's no good way to say it — the Lenovo Legion Go 2 is a very expensive gaming handheld. As tested, with the Z2 Extreme, 32GB of RAM, and 1TB SSD, the Legion Go 2 is a whopping $1,349.99. Lenovo includes a carrying case this time around, which is a nice addition, but the handheld should have more storage for this price.\n\nA cheaper configuration at Best Buy is $1,099.99 with the base Ryzen Z2, 16GB of RAM, and 1TB of storage.\n\nEarlier this year, Lenovo said the Legion Go 2 would start at $1,049 , so we're likely to see variants with different amounts of RAM, storage, and Z-series chips.\n\nImage 1 of 2 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nAll that said, handheld prices have definitely increased since we worried about the $799.99 price tag on the Asus ROG Ally X last year.\n\nMicrosoft and Asus' ROG Xbox Ally X, with the same Z2 Extreme, is going to be $999. We're hitting the point where you can get a decent gaming laptop for the price of a handheld. For the price of our review unit, you could get a $499.99 Nintendo Switch 2 and a top-end $649 Steam Deck OLED with 1TB of storage — a total of $1,148.99 — and still afford multiple games.\n\nBottom Line\n\nThere is a definite audience for the Lenovo Legion Go 2. People who want the most powerful AMD Z-series variant (and forgetting about a few rare Strix Halo handhelds), an OLED display, and want to be able to disconnect the controllers from the system like a Nintendo Switch.\n\nFor $1,349.99, though, you really need to want all those things. On the other hand, the Legion Go 2 offers some of them exclusively. No other major brand has detachable controllers, and the only other significant handheld from a major company that has an OLED screen is the Steam Deck OLED. In the Windows world, it's really the only one, unless you get into smaller brands like Aya Neo.\n\nThe Z2 Extreme does bump performance up over the Z1, but the biggest gains are still at 1280 x 800p. I'm of the opinion that if you have a handheld and you like it, it's not a must upgrade, but if you haven't, you'll get solid performance with the right settings.\n\nThe system is heavy, though, at over two pounds, and the battery drains pretty quick, even at low screen brightness levels. If you want all of these features and have $1,349 to spare, though, the Legion Go 2 is perhaps the most full-featured system out there. But cheaper competitors are good enough that I'd suggest at least giving them a look first.",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/video-games/handheld-gaming/lenovo-legion-go-2-review",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Ninkear A15 Air: Notebook with Ryzen APU, numpad and fingerprint sensor is now available",
      "content": "All things considered, the Ninkear A15 Air is a fairly affordable notebook that appears to be quite portable as well. For the laptop, the company has chosen an AMD Ryzen APU over an Intel processor.\n\n4 Reviews ← exclude selected types\n\nWhilst Ninkear may not be a household name amongst laptop manufacturers, we have already had the opportunity to cover and review some of the company’s products, including the A16 Pro. The recently launched 3500U-powered Ninkear A15 Air is now available for €349 ($398) including shipping, with stocks dispatched from Europe. However, the product currently doesn’t ship to the US, and customers may encounter issues with warranty support.\n\nPerhaps unsurprisingly at its price point, the A15 Air lacks a dedicated GPU and probably can’t deliver blazingly fast performance. It is powered by an AMD Ryzen 5 3500U, a highly dated processor that we’ve seen in older laptops. That said, the system should offer enough performance for watching YouTube videos or browsing the web. The device is also equipped with 16 GB of DDR4 memory and a 512 GB SSD, providing a decent amount of RAM and storage.\n\nWeighing 1.75 kg (3.86 lb) and measuring 1.9 cm (0.75 in) thick, the Ninkear A15 Air features a 15.6-inch display with a 1080p resolution, 60 Hz refresh rate, and 45% NTSC (~65% sRGB) gamut coverage. It also offers two USB-C ports (both capable of video output), an HDMI interface, an Ethernet port, and a memory card reader. Other notable features include Wi-Fi 5 support, a fingerprint sensor, and a built-in webcam.\n\nThe A15 Air was previously available with a more powerful APU, the Ryzen 5 4600H, but that SKU appears to be all sold out now.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Ninkear-A15-Air-Notebook-with-Ryzen-APU-numpad-and-fingerprint-sensor-is-now-available.1129840.0.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "US health insurers reduce Medicare Advantage operations in 2026",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/436cab944d5649d6",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "【Razer】次世代接続性能を誇る「Razer Thunderbolt(TM) 5 Dock Chroma」と「Razer Core X V2」を発表2025年10月10日（金）発売",
      "content": "ゲーマー向けライフスタイルブランドとして世界をリードするRazer™（本社：米国カリフォルニア州およびシンガポール、共同創業者兼CEO：Min-Liang Tan）は、最新のThunderbolt™ 5に対応した2つの先進的なPCアクセサリー「Razer Thunderbolt™ 5 Dock Chroma」と外付けGPUボックス「Razer Core X V2」を発表しました。2025年10月2日（木）より予約開始いたします。販売開始は2025年10月10日（金）を予定しています\n\nPCの接続性と外付けグラフィックス性能を進化させるこのパワフルな2製品は、帯域幅の拡大、臨場感ある映像体験、そして柔軟なモジュール構成を可能にし、仕事にもゲームにも最適です。Thunderbolt™ 5は、最大120Gb/sの転送速度を実現し、高速接続の新たな基準を打ち立てます。これにより、高性能な周辺機器や高速ストレージの使用、複数の4Kディスプレイの同時接続が可能になり、他のThunderbolt™デバイスとのデイジーチェーン接続にも対応。圧倒的な生産性と没入感あふれるゲーム体験を提供します。\n\n1本のケーブルで3画面4K構成をすっきり接続できるシンプルな環境づくりから、ノートPCにデスクトップクラスのGPU性能を与えるブーストまで、RazerのThunderbolt™ 5対応製品は、安定したパフォーマンス、スマートなケーブル管理、そして幅広いデバイスとの互換性を備えています。\n\nRazerのノートPC＆アクセサリー部門責任者トラヴィス・ファーストは次のように述べています。\n\n「Razer Thunderbolt™ 5 Dock Chromaは、急速に高まる高速データ転送やマルチディスプレイ対応のニーズに応えるために設計されました。Razer Core X V2 は、その体験をさらに拡張する製品です。最新のNVIDIAおよびAMDグラフィックスカードに対応することで、超薄型のThunderbolt™対応ノートPCでも、デスクトップ級のグラフィックス性能を実現できます。クリエイティブやゲーミング用途にも対応する、スムーズで強力な外部GPUソリューションです」\n\n\n\nIntel社のマーケティング部門ジェネラルマネージャーのベン・ハッカー氏のコメント\n\n「RazerはThunderbolt™ 5が約束する“圧倒的なパフォーマンス、比類なき柔軟性、そしてシームレスなユーザー体験”を着実に実現し続けています。モバイルコンピューティングの未来を共に切り拓いていけることを誇りに思います」\n\nRazer Thunderbolt™ 5 Dock Chroma：高速転送と多彩な接続をシンプルに\n\nRazer Thunderbolt™ 5 Dock Chromaは、進化する現代のワークステーションやゲーミング環境のニーズに応えるために設計されました。3台の4Kディスプレイを同時にサポートし、高速データ転送に対応、M.2 用ストレージスロットを備えたこのドックは、多彩な機能をひとつの効率的なハブに集約しています。大容量のメディアファイルを扱うクリエイターから、スマートで高性能な環境を求めるゲーマーまで、幅広いユーザーの複数デバイスによる作業を支援する、豊富なポート構成とThunderbolt Share機能を搭載した多用途なソリューションです。\n\n主な特長：\n\nトリプル4Kディスプレイ対応\n\n最大3台の4Kディスプレイを144Hzで駆動し、生産性向上からエンターテインメントまで滑らかで没入感のある映像体験を提供します。\n\nThunderbolt™ 5の高速帯域幅\n\n最大120Gb/sの高速データ転送を実現し、接続されたデバイス間で低遅延のパフォーマンスを可能にします。\n\nストレージスロットと共有機能\n\n別途M.2 SSDを用意することで、最大8TBの内部ストレージによる高速ファイルアクセスを実現。さらにThunderbolt Share機能により、複数PC間でのファイル転送やKVM機能のようなマルチPCコントロールが可能となり、マルチタスクや作業効率を大幅に向上させます。\n\n豊富な接続ポートで一括管理\n\n計10の入出力ポートを備えており、高リフレッシュレートのモニター、ゲーミング周辺機器、外部ストレージ、入力デバイスなど幅広い接続に対応します。最新機器から従来機器まで多世代のデバイスをシームレスに統合し、ケーブルの煩雑さを抑えてすっきりとした作業環境を実現します。\n\n最大140Wの電力供給\n\n250Wの専用電源アダプターにより、ノートPCへ最大140Wの高速充電が可能。パワーを多く必要とする機器も安心して使えます。\n\n※Whiteモデル「Razer Thunderbolt™ 5 Dock Mercury White」は、ライティング機能「Razer Chroma™ RGB」を搭載しておりません。\n\nRazer Core X V2：ノートPCでデスクトップ級のグラフィックス性能を実現\n\n「Razer Core X V2」は、Thunderbolt™ 4、Thunderbolt™ 5、そして一部の USB4 ゲーミングノートやハンドヘルド端末など、対応デバイス向けに設計された次世代の外付けグラフィックスエンクロージャーです。柔軟性と圧倒的なグラフィック性能を両立し、持ち運びやすいノートPCを、ゲーミング・コンテンツ制作・将来を見据えた高性能デスクトップ環境へと変貌させる、プラグアンドプレイ対応のアップグレードソリューションです。\n\nRazer Core X V2は、フルサイズのPCIeグラフィックスカードと標準ATX電源に対応しており、最新のNVIDIA® GeForce®やAMD Radeon™ GPUを簡単に取り付けることができます。Thunderbolt™ 5接続により、Thunderbolt™ 4の最大2倍の帯域幅を実現し、高速なデータ転送と幅広いデバイス間でのシームレスなパフォーマンスを提供します。\n\n設置は直感的かつスピーディで、わずか数分でデスクトップ級のグラフィックス性能を利用可能にします。筐体には通気性に優れたスチール製シャーシと、システム負荷に応じて自動で回転数を調整する120mmファンを搭載。さらに高度な制御を求めるユーザーには、Razer Synapseソフトウェアを使用することで、冷却性能と静音性の最適化に向けたファンカーブのカスタマイズも可能です。\n\n1本のThunderbolt™ 5ケーブルでRazer Core X V2をホストデバイスに接続。必要に応じてデスクトップ級のグラフィックス性能を提供するとともに、最大140Wの給電にも対応し、高性能なモバイルコンピューティングに最適なソリューションとなっています。\n\n※本製品にグラフィックスカードと電源ユニットは付属していません。対応する寸法を公式サイトの製品ページにてご確認の上、別途ご用意ください。\n\nRazer Thunderbolt™ 5 Dock ChromaとRazer Core X V2の登場により、Razerはゲーマーやクリエイター、プロフェッショナル向けに、パフォーマンスを追求したラップトップアクセサリーのエコシステムをさらに拡充します。これらの新製品は、高速性、柔軟性、機能性のバランスを追求し、あらゆる環境でユーザーが最適なセットアップを実現できるようサポートします。\n\n公式サイトURLは、以下の各製品リンクをご参照ください\n\n※Whiteモデル「Razer Thunderbolt™ 5 Dock Mercury White」は、ライティング機能「Razer Chroma™ RGB」を搭載しておりません。\n\n\n\n■「Razer Thunderbolt™ 5 Dock Chroma / Razer Core X V2」取扱店\n\n全国の家電量販店、PCショップ、オンラインショップ等で販売いたします。\n\n■販売店様からのお問合せ\n\n株式会社アユート\n\nPC事業部\n\nWEB： https://www.aiuto-jp.co.jp/contact/b2b.php\n\n■Razerについて\n\nRazer™は、ゲーマーのためにゲーマーによって設立された、世界的な大手ライフスタイルブランド企業で、「For Gamers. By Gamers™」（ゲーマーの為にゲーマーが作る）をスローガンに掲げています。\n\nRazerの商標である3つの頭を持つ蛇は、世界中のゲーミングコミュニティやeスポーツコミュニティで最も認知されているロゴの一つです。あらゆる大陸にファンを持つRazerは、ハードウェア、ソフトウェア、サービスで構成された、ゲーマーを対象とする世界最大のエコシステムを設計・構築してきました。\n\nRazerは、高性能ゲーミング周辺機器やBladeゲーミングノートPCといった、受賞歴のあるハードウェアを提供しています。Razer Chroma RGBやRazer Synapseなどで構成されるRazerのソフトウェアスイートは、カスタマイズ機能や照明効果機能、最適化機能を備え、2億5,000万人以上のユーザーに利用されています。またRazerは、ゲーマー、若者、ミレニアル世代、Z世代向けに、Razer Goldを使用した決済サービスを提供しています。これは、68,000を超えるゲームタイトルで利用できる、世界最大のゲーム決済サービスのひとつです。さらに、この決済サービスに連動した報酬プログラムであるRazer Silverを提供しています。\n\nRazerは、持続可能な未来の実現に取り組んでおり、#GoGreenWithRazer活動（さまざまな取り組みを通じて環境への影響を最小限に抑えるための、10年間のロードマップ）を通じて社会的責任を果たすべく努力しています。\n\n2005年に設立されたRazerは、カリフォルニア州アーバインとシンガポールの2か所に本拠地を構え、ハンブルクと上海に地域統括本部を置き、世界各地の19か所に事業所を展開しています。これまで数々のブランドアクティベーションを行ってきたRazerは、2025年に20周年を迎えます。詳細についてはhttps://rzr.to/20anniをご覧ください。\n\n■Razer公式リンク\n\nRazer日本公式サイト：https://www.razer.com/jp-jp/\n\nRazer JP X (旧：Twitter) アカウント：https://www.x.com/razerjp\n\n* (C) 2025 Razer Inc. All rights reserved.\n\n* 仕様、および、デザインは予告なしに変更される場合があります。\n\n* その他、記載されている会社名、製品名は、各社の登録商標または商標です\n\nRazer — For Gamers. By Gamers.TM\n\npress.razer.com",
      "source": "Prtimes.jp",
      "url": "https://prtimes.jp/main/html/rd/p/000000031.000163154.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "AMD (AMD) Stock Is Up, What You Need To Know",
      "content": "What Happened?\n\nShares of computer processor maker AMD (NASDAQ:AMD) jumped 3.6% in the afternoon session after the company announced an expanded artificial intelligence (AI) partnership and reports surfaced of a potential manufacturing deal with rival Intel.\n\nThe collaboration with enterprise AI firm Cohere involved deploying Cohere's AI models on AMD's Instinct GPU-powered infrastructure, a move aimed at competing in the enterprise and sovereign AI markets. In separate reports, it was noted that AMD was in early discussions to use Intel's foundry services for some of its chip production, which would mark a shift from its current producer, TSMC. The stock's rise was also supported by broader positive sentiment for the semiconductor sector, as strong demand for data center and AI chips lifted several major tech companies.\n\nAfter the initial pop the shares cooled down to $170.47, up 3.9% from previous close.\n\nIs now the time to buy AMD? Access our full analysis report here, it’s free.\n\nWhat Is The Market Telling Us\n\nAMD’s shares are very volatile and have had 22 moves greater than 5% over the last year. In that context, today’s move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.\n\nThe previous big move we wrote about was 14 days ago when the stock dropped 3% on the news that its key rivals, Nvidia and Intel, announced a major strategic collaboration, creating a formidable competitor in the chip space. The surprise deal saw Nvidia invest $5 billion in Intel, and the two semiconductor giants teamed up to jointly develop new chips for both AI data centers and personal computers. This partnership directly challenged AMD's position in those critical markets. The collaboration aimed to fuse Intel's x86 CPUs with Nvidia's powerful RTX graphics chiplets. This move appeared to worry investors because it threatened to weaken a key advantage AMD held. The new alliance between two of its biggest rivals presented a significant competitive threat, raising concerns about AMD's future market share.\n\nAMD is up 41.3% since the beginning of the year, and at $170.47 per share, it is trading close to its 52-week high of $184.42 from August 2025. Investors who bought $1,000 worth of AMD’s shares 5 years ago would now be looking at an investment worth $2,084.\n\nHere at StockStory, we certainly understand the potential of thematic investing. Diverse winners from Microsoft (MSFT) to Alphabet (GOOG), Coca-Cola (KO) to Monster Beverage (MNST) could all have been identified as promising growth stories with a megatrend driving the growth. So, in that spirit, we’ve identified a relatively under-the-radar profitable growth stock benefiting from the rise of AI, available to you FREE via this link.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/amd-amd-stock-know-172042259.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Gold Holds Five-Day Rally on Fed Cut Bets, US Shutdown Concerns",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/9abcf4eba0bef51e",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "AMD Stock Is Surging Thursday: What's Driving The Action?",
      "content": "Advanced Micro Devices Inc (NASDAQ:AMD) shares are trading higher late Thursday, extending gains from Wednesday’s session fueled by multiple developments. Here’s what investors need to know.\n\nWhat To Know: Investor enthusiasm is largely being driven by a Wednesday report that competitor…\n\nThis story appeared on benzinga.com , 2025-10-02 20:28:39.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/e4eaad1a11bab064",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Intel shares surge on potential AMD chip manufacturing deal, hitting 9-month high",
      "content": "A possible deal between two longtime rivals in the tech world sends Intel's shares surging, as the company continues its push into the foundry business.\n\nThis story appeared on bizjournals.com , 2025-10-02 17:05:51.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/bd657f54451d4de9",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "MSI Almost Confirms \"Zen 6\" Coming to Socket AM5",
      "content": "An MSI representative, without taking names, confirmed that the company's AMD 800-series chipset motherboards will \"be ready for future CPUs,\" in response to a question on whether they support \"Zen 6.\" This would be the first near-confirmation from a motherboard manufacturer that AMD is readying its Ryzen \"Olympic Ridge\" desktop processor for Socket AM5. This would make \"Zen 6\" the third microarchitecture for the socket, in line with how AMD released three microarchitectures for its previous Socket AM4.\"Olympic Ridge\" will be a chiplet-based processor much like all AMD Ryzen desktop chips going back to the Ryzen 3000 series. These are expected to feature \"Zen 6\" cores in CPU complex dies (CCDs) built on the 2 nm TSMC N2 process, with AMD expected to increase CPU core counts per CCD for the first time in all these generations. The chip is also expected to introduce a new client I/O die (cIOD) very likely built on the 4 nm TSMC N4P node, which will come with significantly lower TDP than the current one built on 6 nm, and come with a revamped set of DDR5 memory controllers that supports higher speeds. All this said, AMD is rumored to be working on an even newer desktop socket, the new AM6 , with a pin count in the range of 2,100 pins. It's likely that \"Zen 7\" will be designed for this socket.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341567/msi-almost-confirms-zen-6-coming-to-socket-am5",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "AMD wants to double DDR5 memory bandwidth using clever trick, patent reveals - but this is no SOCAMM rival, and AMD's previous memory project didn't end well",
      "content": "AMD patent reveals new RAM design aimed at doubling DDR5 data bandwidth\n\nProposed HB-DIMM approach uses pseudo channels and buffer chips to boost throughput\n\nAMD’s past memory ventures struggled, raising questions about new patent’s commercial path\n\nAMD has apparently developed a way to push memory performance beyond the current DDR5 limits, according to a newly published patent.\n\nSpotted by Tech4Gamers, the filing concerns, “a high-bandwidth memory module architecture” which could potentially double data rates without changing the underlying DRAM chips.\n\nThe proposed design achieves up to 12.8Gbps on the memory bus, compared with DDR5’s native 6.4Gbps.\n\nNot AMD's first memory rodeo\n\nIt does so through the use of high-bandwidth dual in-line memory modules, or HB-DIMMs, which combine multiple DRAM chips with buffer chips.\n\nThese buffers handle data transmission at twice the normal speed, effectively scaling bandwidth with today’s technology rather than requiring an entirely new standard.\n\nThe use of pseudo channels and intelligent signal routing to improve throughput are also covered in the patent.\n\nA register clock driver circuit decodes memory commands and uses a chip identifier bit to direct signals to independently addressable channels.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThis will allow parallel access, and flexible clocking modes to help maintain DDR5 compatibility.\n\nData transfer would use a non-interleaved format to simplify signal integrity and reduce latency.\n\nAMD argues in the filing DDR5 has struggled to keep up with the bandwidth demands of graphics processors and servers, making an upgrade in module architecture necessary.\n\nIn allowing configurations to switch between pseudo-channel and quad-rank modes, it would be possible to tailor the design for high-performance computing, AI workloads, and gaming systems that require faster memory.\n\nThis development comes as competitors pursue their own solutions. Nvidia’s earlier SOCAMM 1 project was abandoned after technical problems, with the company now working on SOCAMM 2 as, separately, are Samsung, SK Hynix, and Micron.\n\nWhile those efforts focus on modular designs and extreme data rates for data centers, AMD’s proposal is positioned as an adaptable improvement for existing DDR5 systems.\n\nThis wouldn’t be the first time AMD has entered the memory arena of course. Back in 2012, the company partnered with Patriot Memory and VisionTek to sell branded DDR3 kits, although that venture wasn’t a huge success.\n\nWhether the new patent will result in a commercial product remains to be seen, but it’s another example of the growing pressure on the industry to find ways of moving beyond DDR5’s current roadmap.\n\n(Image credit: AMD)",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/amd-wants-to-double-ddr5-memory-bandwidth-using-clever-trick-patent-reveals-but-this-is-no-socamm-rival-and-amds-previous-memory-project-didnt-end-well",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "SilverStone Intros XE360PD Dual-Pump AIO CLC for 1P HEDTs and Workstations",
      "content": "SilverStone today introduced the XE360PD, a single-socket variant of the XE360PDD dual-block AIO CLC that the company originally launched for 2P servers and workstations. The XE360PD comes in a socket-agnostic form, you are required to separately purchase a retention module kit specific to your socket type. The XAC-MK-4189 is meant for Intel LGA4189, the XAC-MK-4710 for Intel Sockets LGA4677 and LGA4710; and the XAC-MK-SP5 for AMD Sockets SP5 and sTR5. Moving on to the cooler itself, and the SilverStone XE360PD comes with a large, 38 mm-thick 360 mm x 120 mm radiator with two integrated pumps located in the radiator, one of which tugs at coolant flow from the block, while the other pushes it back into the block after circulation through the radiator. The radiator channels and fins are made of aluminium.The water block is made of nickel-plated copper all around. Each of the two pumps turns at speeds of up to 4,000 RPM, and takes in 3-pin DC input and 12 V. The rubber tube is 45 cm in length, and features Nylon sleeving. SilverStone includes three high-performance 120 mm fans with the cooler. These come with double ball bearings, take in 4-pin PWM input, and feature a liquid crystal polymer (LCP) based impeller. Each of the fans turns at speeds ranging between 800 and 3,000 RPM, pushing up to 95.1 CFM of airflow, at 5.2 mm H₂O static pressure, and a maximum noise output of 39.6 dBA. SilverStone didn't reveal pricing.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341557/silverstone-intros-xe360pd-dual-pump-aio-clc-for-1p-hedts-and-workstations",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Top Uranium Miner Weighs New Listing to Bolster Valuation",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/1e02c6b959c0611a",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Intel in negotiations to make AMD’s chips, according to insiders",
      "content": "Intel is trying to claw its way back into relevance with some big moves lately, such as its recently announced alliance with Nvidia. But there’s more going on behind the scenes, including some negotiations with AMD, according to a report by Semafor.\n\nThe aim of this Intel-AMD agreement would be to produce AMD chips in Intel’s own factories, known as foundries. (A foundry manufactures semiconductors according to customer designs.) Intel would therefore realize AMD’s designs, although both compete in the processor market.\n\nThe deal is not yet finalized and an agreement could take months, as further hurdles (such as regulatory reviews) are still pending.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2928109/intel-in-negotiations-to-make-amds-chips-according-to-insiders.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Australia’s IFM Investors to Wind Down Private Equity Unit",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/13b67bc4426b0e29",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Micron takes the HBM lead with fastest ever HBM4 memory with a 2.8TB/s bandwidth - putting it ahead of Samsung and SK Hynix",
      "content": "Micron claims 2.8TB/s bandwidth for HBM4, surpassing JEDEC baseline and rivals\n\nSamples of next-gen memory shipped to customers, with HBM4E customization ahead\n\nMicron's HBM revenue grows to $8 billion annualized run rate as AI demand rises\n\nMicron has announced it has begun shipping samples of its next-generation HBM4 memory, claiming industry-leading performance and efficiency.\n\nSpeaking during the company’s recent Q4 2025 earnings call, Micron CEO Sanjay Mehrotra said the modules achieve more than 2.8TB/s of bandwidth and pin speeds above 11Gbps.\n\nThis places them well ahead of the official JEDEC HBM4 specification of 2TB/s and 8Gbps.\n\nIndustry-leading performance\n\n“Micron’s HBM4 12-high remains on track to support customer platform ramps, even as the performance requirements for HBM4 bandwidth and pin speeds have increased,” Mehrotra told investors.\n\nHe added the company’s approach delivers “industry-leading performance as well as best-in-class power efficiency,” citing Micron’s 1-gamma DRAM, in-house CMOS base die, and packaging innovations as key differentiators.\n\nMicron also confirmed plans for HBM4E, which will extend the base design with options for customer-specific customization of the logic die.\n\n“For HBM4E, Micron will offer standard products as well as the option for customization of the base logic die,” Mehrotra said.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n“Customization requires close collaboration with customers and we expect HBM4E with customized base logic die to deliver higher gross margins than standard HBM4E.”\n\nDeveloped in collaboration with TSMC, the technology will allow major customers such as Nvidia and AMD to tailor accelerators with memory stacks optimized for lower latency and better packet routing.\n\nThis would mark the first time HBM is delivered with a custom base die, a shift that could change how accelerators are designed and differentiated.\n\nBack in January 2025, the firm announced plans to take a bigger slice of the $100 billion HBM market and it is a fast-growing part of Micron’s business.\n\nThe company reported that high-bandwidth memory revenue reached nearly $2 billion in its latest quarter, an annualized rate of $8 billion.\n\nWith Samsung and SK Hynix also advancing HBM4 development, Micron is staking a claim to the lead, at least in terms of raw bandwidth.\n\nMehrotra concluded the earnings call by reiterating the company broader strategy: “Micron closed out a record-breaking fiscal year with exceptional Q4 performance, underscoring our leadership in technology, products, and operational execution,” he said.\n\nVia TechPowerUp",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/micron-takes-the-hbm-lead-with-fastest-ever-hbm4-memory-with-a-2-8tb-s-bandwidth-putting-it-ahead-of-samsung-and-sk-hynix",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Shielding vision from screen strain: How superfoods and screen habits can support eye health",
      "content": "Shielding vision from screen strain: How superfoods and screen habits can support eye health\n\nLutein and zeaxanthin, found in many fruits and vegetables, protect the macula by absorbing harmful blue light and reducing oxidative stress.\n\nStudies show that eating lutein-rich foods or taking supplements can improve visual function and reduce the risk of age-related macular degeneration (AMD).\n\nPistachios, when consumed in moderation, help increase macular pigment optical density, supporting vision health.\n\nIncorporating leafy greens, orange-yellow fruits, and omega-3 rich fish into your diet can help maintain eye health and protect against AMD.\n\nNutrition can slow AMD progression but cannot reverse existing damage, emphasizing the need for ongoing medical treatment.\n\nIn today’s digital age, urban dwellers are constantly scrolling through their phones and staring at screens for extended periods, leading to blurred vision, dry eyes, and presbyopia. While pistachios have shown promise in supporting eye health, they are just one part of a broader strategy to protect our vision. A growing body of research highlights the critical role of lutein and zeaxanthin, two carotenoids found in various fruits and vegetables, in safeguarding the macula—the part of the retina responsible for sharp central vision. As our understanding of diet and eye health deepens, so does the realization that simple food choices and healthier screen habits can support lasting vision. But who needs these nutrients most, and how can they best be incorporated into our daily routines?\n\nWho needs lutein supplementation most\n\nFor those concerned about their vision, consulting a nutritionist like Yiling Huang, founder of Koii Nutrition Counseling Center, can offer valuable guidance. Huang recommends lutein supplementation particularly for individuals who fit into one of several key categories:\n\nHeavy device users: Extended screen time can cause significant eye strain.\n\nOlder adults: Aging diminishes the body’s ability to absorb nutrients, necessitating additional supplementation.\n\nPeople with low intake of produce: Fruits and vegetables are primary sources of antioxidants, and insufficient intake can lead to deficiencies.\n\nHuang advises her clients to limit pistachio consumption to 1 ounce (about 20-30 grams) a day and pair this with a variety of lutein-rich foods, such as dark green leafy vegetables and citrus fruits. She explains that while pistachios contain valuable nutrients, consuming too much can contribute to excessive calorie and fat intake. Huang suggests eating at least half to one bowl of dark green vegetables daily, which can provide approximately 6 to 12 milligrams of lutein—sufficient for most people’s needs. However, individuals with significant eye strain or dryness may benefit from higher intakes, up to 30 milligrams daily. Customized advice from a nutritionist ensures adequacy for varied dietary needs and restrictions.\n\nMaximizing lutein absorption\n\nMany people find that lutein supplements are ineffective, often because they take them incorrectly. Since lutein is fat-soluble, its absorption is optimized when taken after meals that contain healthy fats. Huang stresses the importance of avoiding supplementation on an empty stomach, as this reduces effectiveness. Pairing lutein with other antioxidants also creates a synergistic effect, enhancing its protective capabilities.\n\nAdditionally, comprehensive nutrition is key to maintaining healthy eyes. For instance, vitamin A, DHA from fish oil, and astaxanthin can help relieve dry eyes, while anthocyanins and astaxanthin assist in eye fatigue from frequent use of digital devices. Specific nutrients like beta-carotene and vitamin B1 may help address issues like presbyopia and cataracts. Huang’s personal routine involves eating dark green vegetables and carrots rich in beta-carotene, and supplementing fish oil when fish intake is insufficient.\n\nLutein-rich foods for eye health\n\nTo achieve optimal eye health, incorporating a variety of foods rich in lutein and zeaxanthin is crucial. These essential nutrients are found in diverse foods, providing a range of benefits for eye health:\n\nDark Green Leafy Vegetables: Sweet potato leaves, baby bok choy, spinach, kale, broccoli, and Swiss chard.\n\nYellow and Orange Vegetables: Corn, pumpkin, carrots, and bell peppers.\n\nFruits: Kiwi, papaya, oranges, and tangerines.\n\nHuang emphasizes the importance of regularly consuming these superfoods, ideally including dark green vegetables in at least half to one bowl per day. Combining these with corn or citrus fruits can significantly boost the intake of lutein and zeaxanthin. However, as with any dietary recommendation, personalized adjustments based on individual needs and health conditions are important. Consulting with a nutritionist can help tailor a precise plan.\n\nHistorical context and contemporary relevance\n\nThe role of diet in preventing and managing age-related macular degeneration (AMD) has been a topic of increasing interest. Studies have consistently shown that a diet rich in lutein and zeaxanthin can reduce the risk of AMD by up to 40%, according to a Harvard study that followed over 100,000 participants. This research underscores the importance of nutrition in maintaining eye health, especially given the increasing prevalence of age-related vision diseases. Moreover, the significance of lutein and zeaxanthin in protecting against light damage and oxidative stress is well-documented, making these nutrients indispensable for preserving macular health.\n\nNourishing your vision through everyday choices\n\nAs our understanding of macular health and dietary benefits continues to evolve, it’s clear that preventative measures can significantly impact our vision over time. By choosing a balanced diet that includes lutein-rich foods and adhering to healthier habits, such as reducing screen time and incorporating regular eye exercises, individuals can support their eye health. While nutrition can’t reverse existing damage caused by AMD, it can undoubtedly slow its progression and improve quality of life. Embracing these simple yet powerful strategies can go a long way in safeguarding our vision and ensuring a clearer, brighter future.\n\nSources for this article include:\n\nTheEpochTimes.com\n\nScienceDirect.com\n\nClevelandClinic.org",
      "source": "Naturalnews.com",
      "url": "https://www.naturalnews.com/2025-10-02-how-superfoods-screen-habits-support-eye-health.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Iowa district hired superintendent despite false Morgan State doctorate claim on his resume",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/81932a1c31d6a8db",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Ninkear A15 Air: Notebook with Ryzen APU, numpad and fingerprint sensor is now available with a different APU",
      "content": "All things considered, the Ninkear A15 Air is a fairly affordable notebook that appears to be quite portable as well. For the laptop, the company has chosen an AMD Ryzen APU over an Intel processor.\n\n4 Reviews ← exclude selected types\n\nWhilst Ninkear may not be a household name amongst laptop manufacturers, we have already had the opportunity to cover and review some of the company’s products, including the A16 Pro. The recently launched 3500U-powered Ninkear A15 Air is now available for €349 ($398) including shipping, with stocks dispatched from Europe. However, the product currently doesn’t ship to the US, and customers may encounter issues with warranty support.\n\nPerhaps unsurprisingly at its price point, the A15 Air lacks a dedicated GPU and probably can’t deliver blazingly fast performance. It is powered by an AMD Ryzen 5 3500U, a highly dated processor that we’ve seen in older laptops. That said, the system should offer enough performance for watching YouTube videos or browsing the web. The device is also equipped with 16 GB of DDR4 memory and a 512 GB SSD, providing a decent amount of RAM and storage.\n\nWeighing 1.75 kg (3.86 lb) and measuring 1.9 cm (0.75 in) thick, the Ninkear A15 Air features a 15.6-inch display with a 1080p resolution, 60 Hz refresh rate, and 45% NTSC (~65% sRGB) gamut coverage. It also offers two USB-C ports (both capable of video output), an HDMI interface, an Ethernet port, and a memory card reader. Other notable features include Wi-Fi 5 support, a fingerprint sensor, and a built-in webcam.\n\nThe A15 Air was previously available with a more powerful APU, the Ryzen 5 4600H, but that SKU appears to be all sold out now.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Ninkear-A15-Air-Notebook-with-Ryzen-APU-numpad-and-fingerprint-sensor-is-now-available-with-a-different-APU.1129840.0.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Cracks are forming in the AI capex boom, warns Morgan Stanley. What to buy and sell.",
      "content": null,
      "source": "MarketWatch",
      "url": "https://www.marketwatch.com/story/cracks-are-forming-in-the-ai-capex-boom-warns-morgan-stanley-what-to-buy-and-sell-a9f23771",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Marketing Is Helping Carnival Charge More for Its Cruises",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/2345272e28d54c32",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Erasing Encephalitis — Why Vaccine Brain Injuries Became Autism",
      "content": null,
      "source": "Mercola.com",
      "url": "https://articles.mercola.com/sites/articles/archive/2025/10/03/why-vaccine-brain-injuries-became-autism.aspx",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Snapdragon X2 Elite hype is real. So why am I so wary?",
      "content": "Welcome to The Full Nerd newsletter—your weekly dose of hardware talk from the enthusiasts at PCWorld. Missed the shocking topics on our YouTube show or freshest news from across the web? You’re in the right place.\n\nWant this newsletter to come directly to your inbox? Sign up on our website!\n\nSkepticism is normal. But cynicism is different. It blocks receptivity—as I realized after this week’s discussion about Qualcomm’s launch of its Snapdragon X2 Elite and Elite Extreme processors.\n\nTFN regular and my colleague Mark Hachman joined us to chat about the press briefings he attended last week, which included a reveal of phenomenal benchmark results. According to its numbers, Qualcomm’s second-gen Snapdragon Elite chips don’t just smash the baseline set by its predecessors. They smoke Intel and AMD’s laptop CPUs, too. In Cinebench 2024, the X2 Elite Extreme outpaced rival silicon like the Ryzen AI 9 HX 370 and Core Ultra 7 155H by as much as 56 percent in single-core performance. Meanwhile, in multi-core performance, the Snapdragon X2 Elite Extreme posted a lead of over a 200 percent.\n\nQualcomm claims this insanity extends to gaming as well, teasing a doubling of performance in games—which would boost the expected output from 1080p 30fps at Low settings to 60fps. For the thin-and-light laptops that Snapdragon Elite chips would power, this shot in the arm for gaming would be impressive.\n\nAnd yet, while guiding the conversation, I poked at the shadows lurking on the periphery of this information. I wanted to know: Where’s the PC vendor support? The software support? (Especially games…) Why didn’t Qualcomm focus more on its battery life performance, where it already stands strong?\n\nI still believe these are fair questions. But after the show, I thought back to when another semiconductor company made a fresh push into laptops. We think of this company with positivity today, but five years ago, AMD faced a tough uphill battle.\n\nQualcomm’s new Snapdragon X2 Elite Extreme chip looks like it’ll zoom. Mark Hachman / Foundry\n\nAt the time, Intel held around 90 percent of the market. AMD mobile chips also carried the reputation of being low-performance, found only in cheap budget laptops. So while Team Red had turned around its desktop reputation, this initiative met with reserve and even cynicism.\n\nWe now know that such unwillingness to consider success for AMD was unfounded. AMD’s mobile chips now sit comfortably shoulder-to-shoulder with Intel’s best—and even set the bar for expectations in high performance (i.e., Strix Halo). AMD has also steadily gained ground in the market—Intel’s now down to just under 80 percent for laptop share, according to recent reports.\n\nSo yes, my questions were fair. Qualcomm still needs more robust software support. And it can be confident in the Snapdragon Elite reputation for long battery life. But I think it’s worth calling myself out here. I didn’t shine light on these areas with an attitude of curiosity. I was wary—and it’s not yet justified.\n\nBecause that last piece of the puzzle—PC vendor support—never happens in a vacuum. Laptop makers won’t offer Qualcomm models without interest. And I don’t have independent benchmark results yet to warrant anything more than reserve.\n\nIf I want to see more innovation, I can’t let skepticism get the better of me. It’ll turn into cynicism, blocking the spirit of The Full Nerd. Gordon always championed the idea of companies pushing into the unknown. In this era of economic turbulence, such an approach is even riskier. It’s up to us in the stands to remain open. We could otherwise accidentally kill off incredible hardware with indifference, before it ever launches.\n\nIn this episode of The Full Nerd\n\nIn this episode of The Full Nerd, Alaina Yee, Brad Chacos, and Mark Hachman dig into the details of Qualcomm’s new Snapdragon X2 Elite and Elite Extreme chips (including the Elite Extreme’s eye-popping benchmarks) and if Windows 10’s looming death is really a big deal. With Will out this week, I take up the mantle of indignant chicken over Microsoft’s [censored] promise of 500 rewards points for using the Bing app.\n\n(Yes, yes, I know, more fool me.)\n\nI also lowered Brad’s respect for me by confessing I like rubber domes better than mechanical switches. Why? You’ll have to tune into the Q&A section to get the full context. (Also, shoutout to the homies on our Discord server, who’ve been offering great advice about my issues with using a mechanical ergo keyboard.)\n\nI had strong feelings this week. Willis Lai / Foundry\n\nMissed our live show? Subscribe now to The Full Nerd Network YouTube channel, and activate notifications. We also answer viewer questions in real-time!\n\nDon’t miss out on our NEW shows too—you can catch episodes of Dual Boot Diaries and The Full Nerd: Extra Edition now!\n\nAnd if you need more hardware talk during the rest of the week, come join our Discord community—it’s full of cool, laid-back nerds.\n\nThis week’s confounding nerd news\n\nI did a double-take when I heard of Microsoft’s unexpected Game Pass price hike. Same for the idea that the world’s getting literally darker (but not colder).\n\nAt least we still have pieces of joy out there to take comfort in—like the wonderful hit of nostalgia I got from imagining the sound of 12 56K modems all blaring at once.\n\nLinkedIn is training its AI on your data: I almost missed this news. I’m sour about it too, because you can’t retroactively take back any data already in use.\n\nThese keycaps sound so good: I might have unusual switch preferences (or unnatural, depending who you ask), but I still enjoy the sound of mechanical keyboards. Mike Crider, our resident keyboard guru, recently tested one with ceramic keycaps. I could listen to it on repeat for a while, to be honest. It’s soothing.\n\nI’d be down to be serenaded by 12 56K modems: Not indefinitely, mind you. But I’m very onboard with this kick of doing fun stuff with old tech.\n\nEarth is getting darker, NASA warns: So we’re gonna roast in perpetual twilight at some point? Cool cool cool. (Read the article; it’s not actually this outcome. Yet.)\n\nI’m still wary of AI browsers: But I have to admit, I found it interesting reading someone else’s hands-on experience with one. If you ignore the security and privacy concerns of such an AI browser, the potential to help people with accessibility challenges is cool.\n\nLife on Mars, discovered soon? Honestly, I don’t care which country snags a viable sample first. I’m more curious about what we’ll find out.\n\nThis sleeper build jolted me awake: I admit, I was nodding off a bit while scrolling through r/sffpc this week. Then I saw this one my feed. I rarely take to sleeper builds, but I dig this one’s understated retro flavor. (Also cute: this “itty bitty” $25 build with seasoned parts.)\n\nMicrosoft slaps Game Pass Ultimate with a staggering 50 percent price hike: Ouch. (I guess Microsoft plans to make money by losing subscribers.)\n\nMaybe gamers don’t hate Windows 11: You know, I actually forgot to consider how motivated people are by deadlines. Now I’m wondering what the October and November Steam surveys will look.\n\nWill Adam sniff this next? I’m not sure how I feel about an SSD with a built-in oil diffuser. But I am sure Adam would give this a go.\n\nSomeone owns almost every graphics card ever made: You know that sound made by the claw-machine aliens in Toy Story? Yeah, that was me when I saw the picture of the collection.\n\nCatch you all next week—or maybe later today during my first PC build livestream in awhile! (I’m finally getting to build in the Hyte X50!)\n\n~Alaina\n\nThis newsletter is dedicated to the memory of Gordon Mah Ung, founder and host of The Full Nerd, and executive editor of hardware at PCWorld.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2928623/snapdragon-x2-elite-hype-is-real-so-why-am-i-so-wary.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "U.S. stock market futures today surge as AI optimism drives Dow, S&P 500, Nasdaq higher – Tesla, Nvidia, AMD lead rally – here’s the top stock to watch",
      "content": "Live Events\n\nU.S. stock market futures today\n\nS&P 500: +1.1% week-to-date\n\n\n\n\n\n+1.1% week-to-date Dow Jones: +0.6%\n\n\n\n\n\n+0.6% Nasdaq: +1.6%\n\nWhat role is technology and AI playing in the rally?\n\nNvidia (NVDA): Leading the sector with an all-time high, Nvidia is a key player in AI chips and data center hardware, benefiting from strong demand and investments in generative AI.\n\nPalantir Technologies (PLTR): Rising sharply due to growing enterprise adoption of its AI software platform, with a 143% increase in stock year-to-date.\n\nCoreWeave (CRWV): A cloud platform specialized in hosting generative AI applications, surging over 240% since its IPO in early 2025 and making a major deal with Meta.\n\nNebius Group (NBIS): A hyperscaler focusing on AI infrastructure, with stock soaring more than fourfold this year and expanding ventures into autonomous driving and AI data services.\n\nAppLovin (APP): Focuses on AI-powered mobile advertising and analytics solutions, with a revenue surge of 77% year-over-year in Q2 2025 and over 120% stock gain this year.\n\nAdvanced Micro Devices (AMD) and Broadcom (AVGO): Growing AI chip segment players, with Broadcom giving a robust forecast for AI chip sales boosting its stock by 44% this year.\n\nCloudflare (NET): Surged 99% in 2025, known for its AI content management and security offerings.\n\nOther notable tech giants contributing to AI optimism include Meta Platforms, Microsoft, Google (Alphabet), and Amazon, which continue to invest heavily in AI technologies and cloud infrastructure.\n\nCrude oil trends\n\nWTI Crude (Nov ’25): $60.84, +0.36 (0.60%) Friday morning\n\n\n\n\n\n$60.84, +0.36 (0.60%) Friday morning WTI weekly: -7.5%\n\n\n\n\n\n-7.5% Brent weekly: -8.5%\n\n\n\n\n\nHow is the government shutdown affecting markets?\n\nas a Reliable and Trusted News Source Addas a Reliable and Trusted News Source Add Now!\n\n\n\n\n\n(You can now subscribe to our\n\n(You can now subscribe to our Economic Times WhatsApp channel\n\nU.S. stock futures moved higher on Friday morning, showing strength even as the federal government shutdown entered its third day. Investors seemed focused on Wall Street’s rally, with optimism in technology and artificial intelligence driving market momentum across all major indexes.Futures tied to the Dow Jones Industrial Average gained 99 points, or 0.2%. S&P 500 and Nasdaq 100 futures also climbed 0.2% each.The shutdown entered its third day on Friday. It has heightened concerns about inflation, a slowing labor market, and macroeconomic risks.Treasury Secretary Scott Bessent warned the funding lapse could affect GDP, growth, and federal workers. The Congressional Budget Office estimates 750,000 federal employees may be furloughed daily.Paul Christopher, head of global investment strategy at Wells Fargo, said, “These events have modest negative economic impacts, but reopening the federal bureaucracy erases those nicks to the economy.”Market analysts suggest that technology remains the backbone of this performance. Companies like Nvidia , AMD, and Tesla continue attracting heavy investor interest. Artificial intelligence remains the primary growth engine, providing optimism even while Washington’s political gridlock dominates national headlines.The Labor Department paused most activity during the shutdown. The September nonfarm payroll report, normally released Friday, was delayed.This removes a key data point for the Federal Reserve’s October interest rate decision. Investors now rely on other indicators to gauge labor market trends.Indexes remain on track for gains this week:The Dow Jones futures posted modest gains in early trading. S&P 500 futures also showed strength, while Nasdaq futures led the advance.Together, they are pushing Wall Street closer to record highs, reflecting confidence that corporate profits will stay resilient despite uncertainty in Washington.Markets appear to be signaling that the long-term story — innovation, AI, and digital growth — outweighs the short-term risks of a government shutdown.Technology shares are once again at the heart of Wall Street’s momentum. Companies like Nvidia, AMD, and Tesla have attracted strong premarket interest, showing how much investors are betting on innovation.The sector has been the main driver of stock gains this year, and enthusiasm around artificial intelligence continues to grow.These companies collectively underpin the tech sector's strong gains, driving the current stock market optimism tied to AI advancements and infrastructure expansion.Rose 0.9%.Rebounded 1.8% in premarket after a 5% drop Thursday.Surged 3.5%, reflecting AI chip market strength.Up about 8% after CEO Barbara Humpton said the company is in close talks with the White House.Dropped 3% after announcing U.S. export restrictions could cut Q4 revenue by $110 million. Shares are still up 37% YTD.Investors believe demand for advanced chips and AI-driven products will remain high. This has created strong revenue expectations that keep attracting capital into the sector. Even in a politically tense environment, traders see technology stocks as reliable growth engines.AI has been described as the “new industrial revolution” for markets. It is shaping not only the direction of tech companies but also the performance of the broader indexes. As long as AI spending grows, many analysts believe Wall Street will keep riding this wave of optimism.Up 18.7% YTD after a buy rating from Berenberg citing strong investor interest.Crude oil is set for weekly losses.This marks the worst weekly performance for both since June.The U.S. government is in a partial shutdown after lawmakers failed to agree on a funding bill. Several federal agencies are affected, while essential services such as Social Security and Medicare continue to operate.The shutdown has heightened worries about macroeconomic risks, inflation, and a slowing labor market. Investors are watching to see how long the shutdown lasts and what impact it may have.Paul Christopher, head of global investment strategy at Wells Fargo, said, “These events have modest negative economic impacts, but the eventual reopening of the federal bureaucracy erases those nicks to the economy.”Treasury Secretary Scott Bessent warned the lapse in funding could impact GDP, growth, and working Americans. The Congressional Budget Office estimates 750,000 federal workers may be furloughed each day.For now, Wall Street appears calm, but the longer the shutdown lasts, the higher the risks become. Markets are keeping a close eye on developments in Washington.",
      "source": "The Times of India",
      "url": "https://economictimes.indiatimes.com/news/international/us/u-s-stock-market-futures-today-surge-as-ai-optimism-drives-dow-sp-500-nasdaq-higher-tesla-nvidia-amd-lead-rally-heres-the-top-stock-to-watch/articleshow/124290538.cms",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "This Week in Security: CVSS 0, Chwoot, and Not in the Threat Model",
      "content": "This week a reader sent me a story about a CVE in Notepad++, and something isn’t quite right. The story is a DLL hijack, a technique where a legitimate program’s Dynamic Link Library (DLL) is replaced with a malicious DLL. This can be used for very stealthy persistence as well as escalation of privilege. This one was assigned CVE-2025-56383, and given a CVSS score of 8.4.\n\nThe problem? Notepad++ doesn’t run as a privileged user, and the install defaults to the right permissions for the folder where the “vulnerable” DLL is installed. Or as pointed out in a GitHub issue on the Proof of Concept (PoC) code, why not just hijack the notepad++ executable?\n\nThis is key when evaluating a vulnerability write-up. What exactly is the write-up claiming? And what security boundary is actually being broken? The Common Weakness Enumeration (CWE) list can be useful here. This vulnerability is classified as CWE-427, an uncontrolled search path element — which isn’t actually what the vulnerability claims, and that’s another clue that something is amiss here. In reality this “vulnerability” applies to every application that uses a DLL: a CVSS 0.\n\nSmish Boxes\n\nThere’s a trend to replace land lines with cellular modems. While wearing my phone tech hat, I’ve even installed a few cellular routers in hotel telecom closets. It turns out there’s a potential problem with that particular arrangement. Hotels and other commercial installations often assign a public IP address to each piece of equipment, and as a result it’s not uncommon for that equipment to be directly exposed to the Internet. And what happens when cellular routers are exposed to the Internet, sometimes with vulnerabilities or even default credentials? Naturally, scammers use them to send spammy SMS messages.\n\nThe scale of the problem is surprising. After researchers at Sekoia discovered the problem, they discovered 18,000 of these devices accessible on the Internet. It seems like this campaign may be responsible for the majority of the SMS spam being sent in modern smishing campaigns. It also appears that there may be an unknown 0-day being exploited in the campaign.\n\nVMWare\n\nVMware just fixed CVE-2025-41244, a local privilege escalation vulnerability that has been in use in the wild since at least October of last year. This vulnerability is in the service discovery feature of VMware Aria. The idea is that the installed VMware Tools can discover running services and probe for version numbers.\n\nOn a Linux guest, this probe works by listing the currently running processes, and if the a process matches one of the regular expressions, that process is run with the -v flag. As root. Yes, this vulnerability that was being actively exploited in the wild by a Chinese threat actor for over a year, was as simple as an over-matching regex and carelessly running binaries as root. The trick favored by the attackers was to place a malicious binary at /tmp/httpd , run it as a regular user, and just wait for the VMware tooling to come along and run it as root.\n\nSudo Chwoot\n\nThe maintainers behind sudo fixed a pair of vulnerabilities back in June that allowed a local attacker to escalate privileges. The most interesting of the two abuses is in the handling of the chroot option, resulting in an attack [Rich Mirch] refers to as “chwoot”.\n\nThe actual weakness is that sudo would use the chroot() system call while setting up the chroot environment, prior to dropping privileges. In this state, sudo performs Name Service Switch calls as root, which results in looking for /etc/nsswitch.conf inside the chroot directory. This config file can trigger a shared library load, and since it’s happening in the context of a chroot, that library is also first loaded from the chroot directory if it exists there, resulting in a handy escalation to root.\n\nThis behavior is enabled for all users by default, resulting in a serious vulnerability on many Linux machines. It was fixed and disclosed back in June, but has now been added to the CISA list of known exploited vulnerabilities.\n\nNot in the Threat Model\n\nIntel and AMD both have trusted computing solutions for encrypted VMs, that among other things, encrypt the bits in memory so even a compromised kernel can’t extract data from the running VM. The approaches from both companies are similar, using symmetric encryption with the memory location as part of the encryption Initialization Vector (IV). This means that while the same key is in use, a plaintext value in a given memory location will always be represented by the same encrypted value. Two pieces of research came out this week suggesting that this codebook-like behavior has security ramifications.\n\nBefore we dive into the rest of the details, it’s worth pointing out that asymmetric encryption is likely not a viable option for VM memory encryption, due to the processing latency overhead. The exploit here is to physically connect to the memory sticks inside a target computer, and record the encrypted bits. In some cases, an attacker can later run a malicious VM on the same hardware, and use the physical hack to replay the captured bits, allowing easy decryption. Another option is to replay the VM attestation report, falsely claiming that the virtual machine is still fully protected.\n\nWhat’s initially surprising is that both Intel and AMD have maintained that their SGX and SEV-SNP systems are not intended to protect against physical access. But seeing what is possible with physical modification to system memory, it’s no longer a surprising line to draw. The other interesting note is that so far these attacks are limited to DDR4, as DDR5 memory has a higher data rate, making the entire operation even more difficult.\n\nBit and Bytes\n\nRed Hat has confirmed that one of its GitLab instances was compromised by Crimson Collective, leading to the exfiltration of over 500 GB of data. This seems to include customer data related to consulting contracts.\n\nRCE Security dug into a product called TRUfusion Enterprise, a data transfer solution that is marketed as undergoing regular audits. It came as a surprise that they found four vulnerabilities that could be called low-hanging fruit. The takeaway: not all audits are created equal, and there’s no guarantee that this style of code review will catch every bug.\n\nOur last two links are both about memory management. The first is from Cybervelia, looking at how to find uninitialized memory access with just a program binary and no source code. Binary Ninja is the tool that really shines here, but it’s certainly not an easy task.\n\nThe other is the latest from Google’s Project Zero, taking a look at some non-obvious ways to defeat Address Layout Randomization using careful analysis of hash tables. Very in-depth work, and on-brand for Project Zero. Enjoy!",
      "source": "Hackaday",
      "url": "https://hackaday.com/2025/10/03/this-week-in-security-cvss-0-chwoot-and-not-in-the-threat-model/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Apple’s M5 MacBook Pro Just Leaked Through FCC Filings, But There’s a Slight Delay",
      "content": "Apple’s playing coy again, but the FCC just handed us a breadcrumb trail that leads straight to the M5 MacBook Pro. While Tim Cook’s team stays radio silent on official announcements, regulatory filings have surfaced with model number A3434, a designation that doesn’t match any existing Apple laptop in their current lineup. The timing checks out perfectly with Apple’s usual product cadence, appearing just weeks before what could be a launch announcement. We’re likely looking at late 2025 or early 2026 for availability, which means the hype machine is already spinning at full throttle.\n\nHere’s what makes this filing particularly interesting: it confirms wireless standards testing, but conspicuously leaves out Wi-Fi 7 support that’s expected to debut on the M5 iPad Pro models. Whether that’s a deliberate hardware choice, a testing limitation, or Apple segmenting features across product lines remains unclear. But it raises questions about Apple’s connectivity strategy across their M5 ecosystem, especially when the iPhone 17 already shipped with the N1 chip that enables Wi-Fi 7, Bluetooth 6, and enhanced AirDrop functionality. The inconsistency feels odd for a company that usually maintains feature parity across flagship devices.\n\nDesigner: Apple\n\nThe actual hardware refresh appears to be evolution rather than revolution. Don’t expect a dramatic redesign after the 2021 overhaul that brought back MagSafe, upgraded the display with ProMotion and mini-LED backlighting, and added back the HDMI port and SD card slot that professionals actually wanted. Apple’s sticking with that form factor, which makes sense given how well received it was after years of that questionable Touch Bar experiment. The real story lives inside the chassis with the M5 silicon, reportedly delivering a 15 to 25 percent performance bump over the M4 while improving energy efficiency. That’s the kind of generational leap that keeps Apple Silicon competitive with whatever Intel and AMD are throwing at the wall.\n\nApple’s planning the full spectrum of configurations with standard M5, M5 Pro, and M5 Max variants, following the established playbook. Development codenames J714 and J716 have surfaced in supply chain reports, pointing to at least two distinct MacBook Pro models in the pipeline. The M5 Max will likely pack the same ridiculous core counts we’ve come to expect, probably pushing 40 GPU cores and unified memory configurations up to 128GB for the pros running demanding workloads. Thunderbolt 5 support is expected on higher-end models, doubling bandwidth to 80 Gbps bidirectional, which matters significantly for anyone daisy-chaining multiple 8K displays or working with massive RAW video files.\n\nThe release timing breaks from Apple’s recent October pattern for MacBook Pro refreshes. Bloomberg’s Mark Gurman notes that mass production is “nearing” but not yet in full swing, suggesting a potential delay into early 2026. Apple pulled this same move with the M2 Pro and M2 Max MacBook Pros, launching them in January 2023 instead of the expected October 2022 window. Supply chain constraints, chip yields, or simply wanting to space out major product launches could all factor into the decision. The iPhone 17 launch in September already gave Apple its big moment this fall, so pushing the MacBook Pro into Q1 2026 creates another news cycle without cannibalizing holiday sales of existing M4 models.\n\nWhat remains frustrating is how little has actually leaked beyond these FCC filings and vague performance estimates. No concrete benchmark scores, no detailed specifications on memory bandwidth improvements, nothing about potential changes to the Neural Engine for AI workloads. Apple’s gotten better at plugging leaks, which is great for their controlled narrative but terrible for those of us trying to make informed purchasing decisions. The M4 MacBook Pros are still relatively fresh, having launched less than a year ago, so anyone who bought in recently shouldn’t feel too burned. But if you’ve been holding out with an Intel MacBook Pro or even an M1 generation machine, the M5 refresh represents a compelling four-generation leap that will be immediately noticeable in compile times, export speeds, and battery life.",
      "source": "Yanko Design",
      "url": "https://www.yankodesign.com/2025/10/03/apples-m5-macbook-pro-just-leaked-through-fcc-filings-but-theres-a-slight-delay/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Next-gen imaging tech could catch sight-stealing diseases early",
      "content": "Scientists have developed a powerful new dual-imaging tool that maps the retina’s structure and oxygen use in unprecedented detail. This breakthrough could one day help doctors spot sight-stealing diseases long before symptoms appear.\n\nOur retinas convert light into electrical signals that are transmitted to the brain, where they’re processed into images. It’s a process that requires a great deal of oxygen. If the oxygen supply is disrupted, for example, due to restricted blood flow, it can lead to serious, vision-affecting conditions such as glaucoma, age-related macular degeneration (AMD), and diabetic retinopathy.\n\nIn a new study, researchers from Johns Hopkins University and the University of Pennsylvania developed and tested a novel retinal imaging system that combines two cutting-edge techniques to map the retina’s structure and oxygen levels to better study oxygen metabolism.\n\nThe researchers’ dual-channel system used visible light optical coherence tomography (VIS-OCT) to capture ultra-detailed structural images of the eye and phosphorescence lifetime ophthalmoscopy (PLIM-SLO) to directly measure oxygen partial pressure (pO 2 ) in the organ’s tiny blood vessels, or microvasculature. In simple terms, pO 2 is the amount of oxygen dissolved in the blood at a given location. It is a key indicator of how much oxygen is available to the tissues.\n\nSimultaneous collection of images using VIS-OCT (top) and PLIM (bottom) Stephanie Nolen et al. (2025)\n\nThese methods were used to image the eyes of live mice. VIS-OCT uses visible light to create high-resolution 3D images of retinal layers and can also capture blood flow dynamics. PLIM-SLO involves injecting a safe, oxygen-sensitive dye called Oxyphor 2P, which emits light that changes depending on oxygen levels. By measuring how quickly this light fades (that is, its phosphorescence lifetime), the researchers could calculate pO 2 at the capillary level. Both systems shared the same optical path, allowing them to capture structural and oxygenation data at the same time and in perfect alignment. The researchers also tested how pO 2 readings changed as they varied the mice’s inhaled oxygen to validate the novel technique’s accuracy.\n\nPLIM-SLO accurately measured oxygen levels in arterioles, venules, and capillaries. As the researchers had expected, PLIM-SLO revealed that arterioles (very small branches of arteries) had the highest oxygen, venules (the smallest veins that return deoxygenated blood) had the lowest, with capillaries in between. Adjusting the system’s focus allowed the researchers to image oxygen at different retinal depths, revealing the structure and oxygen profile of multiple vascular layers – something that previous methods couldn’t achieve. Changes in inhaled oxygen led to predictable changes in retinal oxygen levels, confirming that measurements reflected real physiological changes. Importantly, the system linked oxygen measurements with structural and flow data, laying the groundwork for future studies of retinal oxygen metabolism and disease processes.\n\nMicrovasculature oxygen partial pressure maps at systemic oxygen levels from 69% (left), 78% (middle), and 88% (right) Stephanie Nolen et al. (2025)\n\nBecause the system was only tested in mice, its performance in humans hasn’t yet been evaluated. Additional limitations of the study include that the approach requires careful calibration to correct for light interference between the two systems, which is a technical challenge. Also, some physiological factors, such as pH and carbon dioxide levels, had to be estimated rather than directly measured, potentially introducing small errors.\n\nPutting aside these limitations, this multimodal system could significantly advance eye disease research and diagnostics by providing a more complete picture of retinal health. It could help scientists understand how oxygen supply changes in diseases like diabetic retinopathy, glaucoma, and macular degeneration. Clinicians may one day use similar technology to detect early disease-related changes before vision is affected.\n\nThe study was financially supported by grants from the National Eye Institute, the National Institute of Biomedical Imaging and Bioengineering, and the National Science Foundation Graduate Research Fellowship Program. It was published in the journal Neurophotonics.\n\nSource: SPIE",
      "source": "New Atlas",
      "url": "https://newatlas.com/medical-tech/dual-imaging-technology-retinal-oxygen-metabolism/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "AMD Gains CPU Share as Intel Hits Record Low on Steam September Hardware Survey",
      "content": "A new month has started, meaning that the Steam Hardware and Software Survey has just finished collecting data for September 2025. And there was a subtle, yet clear message about the CPU market: Intel has slipped to its lowest share on record among Steam users, while AMD continues to close the gap. Valve's monthly snapshot shows Intel at about 58.61% and AMD around 41.31%. That shift is the main story this month and suggests a significant change in gamer preferences that warrants a closer examination. The recent movements are not massive, but they are consistent from one month to the next. AMD added roughly 2% points since June, continuing a pattern that started last year, while Intel has been losing ground month after month. A significant part of AMD's momentum stems from its gaming-focused X3D chips and the strong reception they have received in benchmark and real-world tests.Pricing and aggressive promotions for AMD-based systems have also helped. Intel's share is falling even though it remains the largest single vendor, and recent CPU launches have failed to halt the downward trend among Steam users. If both companies continue at their current rates, AMD could become the more common choice among Steam players within a year, marking the first time this has happened in the survey's history. What this means in practice is important for gamers, builders, and the wider PC supply chain. Hardware makers and retailers may shift their inventory and marketing strategies to meet the rising demand for AMD. Game developers are also taking notice. For Intel, the path back will require more compelling launches, clearer messaging, and competitive pricing. The company recently advertised gaming parity with top AMD SKUs and offered better content creation results. For AMD, the challenge will be to turn momentum into sustained leadership without sacrificing margins or running into supply constraints. Either way, the CPU rivalry is no longer a background story. It is directly \"streamed\" on Steam.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341589/amd-gains-cpu-share-as-intel-hits-record-low-on-steam-september-hardware-survey",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Minisforum releases M1-1295 mini-PC with Intel Core i9-12950HX and up to 64 GB RAM",
      "content": "Minisforum has released a new mini-PC that is selling globally as the M1-1295. Available with an Intel Core i9-12950HX processor and numerous ports, the Minisforum M1-1295 mirrors AMD Ryzen AI 9 HX 370-based alternatives when it comes to CPU performance.\n\n4 Reviews ← exclude selected types\n\nMinisforum has just released the MS-S1 Max with AMD's Ryzen AI Max+ 395 APU. Silently, it has also introduced the M1-1295, an Intel Alder Lake-based system with relatively stripped-back styling. A simple silver box, the M1-1295 lacks any ports on its front side that usually adorn modern mini-PCs.\n\nInstead, Minisforum has included a small power button with all ports pushed to the rear of the device. As the image below shows, Minisforum has packed in four USB ports, 2.5 Gigabit LAN, three display outputs and even dedicated microphone and line-in and line-out inputs within a housing that measures 195 x 193 x 52 mm and weighs 1.12 kg.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Minisforum-releases-M1-1295-mini-PC-with-Intel-Core-i9-12950HX-and-up-to-64-GB-RAM.1130797.0.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "GIGABYTE A520I AC AMD A520 Socket AM4 Mini ITX DDR4-SDRAM Motherboard for $79.99 at Woot! (7 replies)",
      "content": "GIGABYTE A520I AC AMD A520 Socket AM4 Mini ITX DDR4-SDRAM Motherboard for $79.99 at Woot.com. Shipping is free for Amazon Prime Members (must login with your Amazon account and select a shipping address in order for Woot to apply free shipping) or is otherwise $6 per order.LINK: https://computers.woot. com/offers...cket-am4-2",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18659035-gigabyte-a520i-ac-amd-a520-socket-am4-mini-itx-ddr4-sdram-motherboard-for-79-99-at-woot",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "中古パソコン販売の「PCバル」、『Windows11乗り換え応援フェア』、限定商品好評販売中・Win11搭載ノートPCが税込19,800円～!!",
      "content": "株式会社バルテック（本社：東京都新宿区）のグループ会社、株式会社バルテックフィールドサービス（本社：東京都新宿区）が運営する中古パソコンの販売サイト「PCバル」（https://www.smaphodock24.jp/used/）では、2025年10月14日に控えたWindows10サポート終了を踏まえ、パソコンの乗り換えが必要なユーザー様に向け開催中の『Windows11乗り換え応援フェア』、好評のフェア限定商品にワンプライス19,800円シリーズが登場、富士通・Lenovo・HPの3機種から選べる!!\n\n好評・税込19,800円 富士通LIFEBOOK A579/A はこちら\n\n新着・税込19,800円 Lenovo ThinkPad L15 はこちら\n\n新着・税込19,800円 HP ProBook 430 G6 はこちら\n\n１． 全台システム要件適合・1,000台以上のWindows11搭載PC\n\nコスパ重視の第8世代からハイスペックの第12・第13世代まで\n\n幅広いラインナップのWindows11搭載中古パソコンをご用意!\n\nもちろんパソコン修理店が母体のPCバルならでは、独自の検査基準・項目に基づき\n\n状態をチェック後入念に整備しているので、安心してお使いいただけます!\n\nWindows11搭載中古ノートパソコン\n\nWindows11搭載中古デスクトップパソコン\n\n2． 乗り換えフェア限定・特別価格Windows11搭載中古パソコン\n\nさらに! 期間中はPCバルが特選した中古パソコンをフェア限定商品として\n\nサプライズ価格で続々とご提供! PCバルは価格でも皆様のWindows11乗り換えを応援します!!\n\nWindow11乗り換え応援フェア限定商品はこちら\n\n新着商品あり! フェア限定ワンプライス税込19,800円シリーズのご紹介!\n\n好評・税込19,800円 富士通LIFEBOOK Aシリーズ 15.6インチはこちら\n\n☆第8世代Core i5＋8GBメモリで快適動作、実用性の高さが魅力の15.6インチノートPC\n\n新着・税込19,800円 Lenovo ThinkPad L15 はこちら\n\n☆第10世代搭載機!! メモリ2スロなのでメモリ増設でさらに快適動作♪\n\n新着・税込19,800円 HP ProBook 430 G6 はこちら\n\n☆モバイル派に最適・スタイリッシュなHPシルバーのコンパクトボディ\n\n他にも多彩なフェア限定商品をご用意していますのでお見逃しなく!!\n\n税込22,222円 Lenovo ThinkPad X390 LTE 13.3 Intel Core i5-8265U 8GB\n\n☆コスパ最重視でWin11搭載PCを選ぶなら! 第8世代CPUで軽作業なら楽々♪\n\n税込54,321円 HP ELITE DRAGONFLY G2 Intel Core i5-1135G7 13.3 8GB\n\n☆第11世代CPU搭載、スタイリッシュなブルーが印象的な人気機種\n\n税込67,890円 DELL Inspiron 5415 14 AMD Ryzen 7-5700U 8GB\n\n☆高いマルチコア性能でクリエイティブワークの強い味方・RYZEN 7搭載！\n\n第8世代X1カーボンや第10世代LIFEBOOKなど\n\n気機種をサプライズ価格でご用意しておりますが、\n\nいずれも数に限りがありますので、ぜひお早めに!!\n\n3． 選べる2つの特典で乗り換え応援!\n\n期間中にフェア限定商品をご成約の方には、MS Officeと高い互換性なのにリーズナブルな価格で\n\n人気のキングソフト製定番オフィスソフト『WPS Office 2 Standard Edition』をもれなくプレゼント!\n\nさらに、PCバル各店とWEBSHOPでそれぞれ特典をご用意!\n\n【PCバル各店店頭でのご購入】\n\nPCバル各店店頭でフェア限定商品をご購入のお客様には、\n\n今お使いのパソコンからデータのお引越し(データ移行)を、通常の50%OFFでご提供!\n\n大事なデータがあるからパソコンを換えるのは抵抗が…という心配はご無用です。\n\nご希望のお客様は店頭ご購入時に店頭でお申し付けください。\n\n【PCバルWEBSHOPでのご購入】\n\nPCバルWEBSHOP でフェア限定商品をご購入のお客様には、WPS Office 2に加え、\n\nウイルス＆フィッシング対策・システムメンテナンスを\n\n1つでこなす『セキュリティPro』(キングソフト製)をプレゼント!\n\n■「PCバル」3つの安心\n\n１．専門店ならではのこだわり\n\n取扱商品は仕入れ後にパソコン整備士の資格を持ったスタッフが、独自の検査基準・項目に基づき状態をチェック後入念に整備。長く使える・故障の少ない状態でお届けできるようメンテナンスした上で販売しています。安定性と体感速度に影響するコンポーネンツはSSD＋RAMメモリ8GB以上を標準構成※とし、プロが手掛けたリフレッシュPCとして高度化・高速化するパソコンの使用環境に対応しお客様満足度の向上を目指しています。\n\n※一部標準構成外の商品もございます。\n\n２．お客様に寄り添った情報掲載・商品説明\n\n実機を見て触れる事のないWEBページ掲載商品を安心してお選び頂くため、商品のスペック情報はもちろん通常使用が可能でも少し気になるかも…という部位の状態を含め、お選びいただく際に安心頂ける情報提供を目指しています。店頭展示中の商品については、スタッフにお声がけ頂ければ実機をご案内しながらお客様にご納得頂ける丁寧なご説明を心掛けています。\n\n３．安心保証&充実サポート\n\n購入時から最大6ヶ月間の保証※が中古PCに付いてくる！パソコン修理専門店を10年以上全国に展開するPCバルならではの修理技術が可能にする手厚いサポートです。保証期間内中の修理ではお客様の費用負担はゼロ(適用条件あり)！ 保証期間終了後に故障が発生した場合でも、症状状態ご予算に応じ当社の技術スタッフが最善のご提案を致します。\n\n※中古PCの保証適用条件はWEB保証書へのアクセスまたは(紙)保証書でご確認ください。\n\n※商品により保証期間が異なります。詳しくは各商品ページをご確認ください。\n\n◆会社概要\n\n□株式会社バルテック\n\n事業内容：ICT機器及びソフトウェアの開発・製造・管理\n\n設立： 1993年3月23日\n\n所在地：〒163-1103 東京都新宿区西新宿6-22-1 新宿スクエアタワー3階\n\nURL：https://www.webjapan.co.jp/\n\n□株式会社バルテックフィールドサービス\n\n事業内容：ICT機器及びソフトウェアの施工、保守、修理\n\nパソコン修理サービス店のフランチャイズ展開\n\nURL：https://www.smaphodock24.jp/",
      "source": "Prtimes.jp",
      "url": "https://prtimes.jp/main/html/rd/p/000000790.000008585.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Stocks Settle Mixed as Tech Rally Loses Steam",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/35225113/stocks-settle-mixed-as-tech-rally-loses-steam",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "AMD not going to fab chips at Intel Foundry, SemiAccurate reports",
      "content": "We use cookies to improve user experience, and analyze website traffic.\n\nFor these reasons, we may share your site usage data with our analytics partners. By clicking \"Accept Cookies\" you consent to store on your device all the technologies described in our Cookie Policy.",
      "source": "Thefly.com",
      "url": "https://thefly.com/permalinks/entry.php/id4207611/AMD;INTC-AMD-not-going-to-fab-chips-at-Intel-Foundry-SemiAccurate-reports",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "ASRock Extends Motherboard Warranty Amid CPU Burning, but Only in Japan",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/asrock-extends-motherboard-warranty-amid-cpu-burning-but-only-in-japan/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Chip Legend Jim Keller Expresses Optimism For Intel Foundry But Says It Needs Work",
      "content": "A wafer of 2nm chips fabricated by IBM.\n\n\n\nThe ports on the back of a Blackhole card are 800 Gbps QSFP+ networking.\n\nJim Keller image ©Impress PC Watch.\n\nAmong chip nerds, Jim Keller is a name that needs no introduction, but if you aren't familiar, he's a veteran from the days of Digital Equipment Corporation. He contributed directly to the DEC Alpha, the AMD K7 and K8 cores powering the Athlon and original Opteron , and then later came back to AMD to direct the design of Zen , before making his way to Tesla and Intel for short stints as well. He's now running his own shop at Tenstorrent, a chipmaker focused on AI processors. Like most chip companies, Tenstorrent doesn't have its own fabs, so it needs a partner who does to make its chips, and Keller says Intel could be that place—with some work.More specifically, speaking to Nikkei Asia, Keller said that Tenstorrent is talking to TSMC, Samsung, and Japan's Rapidus for access to 2nm fabrication, but that Intel could also be an option in the future. Nikkei Asia quoted him as saying \"they still have a lot of work to do ... to deliver a really solid technology roadmap.\"This actually lines up pretty well with the fact that Intel purportedly killed 18A as an option for external orders. If the company simply isn't ready to offer its services to external customers, then it wouldn't make sense to take those orders yet. Intel hasn't talked too much about 14A yet, but Intel CEO Lip-Bu Tan remarked that the company absolutely has to get a customer for 14A or it may not be able to continue developing leading-edge process technology anymore. This would seem to indicate that Intel is working hard to prepare 14A for external customers.Keller said a lot more than that in the interview with Nikkei Asia , but not about Intel. He noted that his company Tenstorrent is one of the first serious chip companies to begin talks with Rapidus, a new startup in Japan that we reported on way back in 2022 , before it was named. Rapidus is a collaboration between most of the tech companies in Japan as well as the US' IBM, funded primarily by the Japanese government, to the tune of over $8 billion USD.IBM actually demonstrated working 2nm chips based on GAAFETs as early as 2021 , long before Intel or TSMC were there. IBM was actually also first at 5nm (also with GAAFETs) and 7nm, too, but the company doesn't operate big commercial fabs, so they're primarily focused on simply advancing the science of transistor research. An important partner, for a commercial fab; Rapidus had a pilot line going in July for its upcoming 2nm process, but full mass production isn't planned until 2027.Tenstorrent is already shipping processors; this isn't a vaporware company . The Blackhole is positioned as a cost-effective and highly scalable alternative to NVIDIA desktop GPUs for AI training and inference. We haven't tested them yet, but reviews and anecdotes from around the web suggest that the strength of the product is in its scalability thanks to integrated networking, but that there are still software struggles, as is so often the case. Even AMD is still fighting that battle, as we noted in our review of the HP Z2 Mini G1a",
      "source": "Hot Hardware",
      "url": "https://hothardware.com/news/jim-keller-says-intel-foundry-needs-work",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Lenovo LOQ 15 Gen10 review",
      "content": "Lenovo's hit the mark just right on three things in particular. The graphics card. The screen. The build quality. It's exceptional in those elements and delivers excellent 1080p gaming performance. Sadly, however, due to what are assumedly cost-cutting measures on the RAM and SSD front, it doesn't quite nail the landing with its entry-level model.\n\nPC Gamer's got your back Our experienced team dedicates many hours to every review, to really get to the heart of what matters most to you. Find out more about how we evaluate games and hardware.\n\nYou know what my biggest bugbear is for budget laptops? It's the screen. It is always the screen. For some reason, notebook manufacturers seem to have this almost obsession with pairing massively underwhelming graphics cards with panels that would put most 4K TVs to shame. It's madness. Yes, they might be these phenomenally pixel-dense, OLED, 240 Hz, crystal-clear colour, uber mode displays, capable of projecting the most beautiful, stunning picture you've ever seen in your life directly into your retinas. But as soon as you load up a game and that mobile GPU kicks into life, fans whirring at a million miles a minute, you'll inevitably be graced with the slow chug of growing disappointment, as the approximation of a AAA power-point presentation starts juddering its way across your shiny new device.\n\nIt's driven me mad for years. That might sound ridiculous, I'll admit that, but I've reviewed a lot of budget laptops in my time that do this, and it's frustrating because it doesn't need to be the case. You gain very little by doing that. Thank the dear and fluffy lord Gabe Newell then (he doesn't have anything to do with this, I don't think, I haven't checked), that Lenovo's LOQ 15 Gen10 ditches that seemingly age-old laptop manufacturer mantra in favor of a more practical GPU and screen pairing instead.\n\nAt its core, the Gen10 comes complete with an Nvidia GeForce RTX 5060, a Ryzen 7 250, and, more importantly than that, a simple, elegant, beautifully crisp and punchy 15.6-inch, 1920x1080 IPS display, running at around 144 Hz. And it does all of that with a sub $1400 price point.\n\nNow, yes, I know what you're thinking, technically, no, that graphics card isn't really a \"true\" RTX 5060. I mean, it sort of is, so far as the name's the same and the core RTX Blackwell architecture matches it as well, but it's lost about 15% of its CUDA cores, and a not-so-subtle 12% of everything else, (ray tracing cores, ROPs, TMUs, Tensor cores, you know, all the good stuff that makes DLSS 4, kinda, work). Heck, I suppose we should be thankful it still touts that same 8 GB of GDDR7 VRAM.\n\nLOQ 15 specs (Image credit: Future) Model No: 15AHP10\n\nCPU: AMD Ryzen 7 250\n\nGPU: Nvidia RTX 5060 115W\n\nRAM: 16 GB DDR5-5600\n\nStorage: 512 GB PCIe 4.0 SSD\n\nScreen Size: 15.6-inch IPS\n\nRefresh Rate: 144 Hz\n\nResolution: 1920 x 1080\n\nBattery: 60 Whr\n\nDimensions: 15.6 ~ 23.9 mm x 359.9 mm x 258.7 mm | 0.94 x 14.17 x 10.19 inches\n\nWeight: 2.3 kg | 5.07 lbs\n\nPrice: $1,389 | £1,300\n\nThe good news, though, is that on the whole, that mobile RTX 5060 does actually deliver when it comes to 1080p gaming. Most titles easily averaged well into the 60 fps mark and above, the only exception, of course, being Cyberpunk 2077 without any DLSS support (which still achieved a relatively respectable 36 fps). Chuck on DLSS Quality and the beautiful silky goodness that is MFG, and that too climbs well into the 100s.\n\nIt's so refreshing to be able to just game at your native resolution on a laptop at this price point, without having to worry about dialling the graphics preset down, or swapping around resolutions and getting stretched pixels or worse. Plus, that 15.6-inch screen is already delivering a pixel density greater than a 32-inch 4K panel does. Alrighty. Stop the press, cancel the review, clearly this is the best gaming laptop of 2025, right? Isn't that right, tiny human? Well, just hang on one minute. It's not all sun-lit uplands and frame rates. We need to talk about the storage and memory setup on this thing. Because, to be blunt. It sucks.\n\nIn its default configuration, the one I'm testing here, the LOQ 15 comes with a single stick of 16 GB DDR5 at 5,600 MT/s. Do you know what Ryzen loves more than memory frequency? Memory bandwidth. There are times, particularly when loading programs, running multiple applications, or intense, high-load activities, when you almost feel this stuttering effect occur on the Gen10. There's a lag as you attempt to move an application across the screen or open up Task Manager. It's chilling to be blunt, giving Windows Vista vibes, and I don't like it.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFor an additional $65, Lenovo will pop an extra 16 GB stick in there for you, but to be honest, this should've been two 8GB dual-channel sticks to begin with, retaining that budget price point. At least so you're not left wondering if the whole system's locking up because you just opened Paint, or because your memory setup sucks.\n\nAgain, on the SSD front, it's similarly just not good enough. The stock model is a SanDisk WD Blue SN5000S, QLC affair, not too dissimilar from the WD Blue SN5000 I reviewed late last year. That's fine, nothing particularly wrong with that for a budget unit. At least, that is, until you see the capacity. It's a 512 GB model, which once Windows is installed, sits at around 370 GB of total available space. I couldn't even install our entire benchmarking suite in one go; it was that small. I had to test games, then delete them and install other games and then test those… Again, Lenovo will happily pop in a 1 TB variant, but for an additional $60 added on to the price tag, which should've been included as standard, given it's a gaming laptop.\n\nImage 1 of 3 (Image credit: Future) (Image credit: Future) (Image credit: Future)\n\nMy list of mild grievances continues with the battery life, which petered out at just 89 minutes. Although that is better than some of the more premium, more power-hungry units out there, the LOQ is generally hampered by its relatively small 60 WHr battery and AMD's relatively power-hungry Ryzen 7 250 CPU. Now, I've been harsh here, I have. This is a budget notebook, effectively. It can't all be brilliant at the end of it all, and there is still a lot to love about it, far beyond that of just the screen being the right pick for that graphics card.\n\nCPU performance is impressive, even with that single-channel memory, and it beats out other RTX 5060 notebooks like Gigabyte's Gaming A16 in average fps too, that one in particular featuring an Intel Core i7-13620H (a damning indictment of Intel's currently poor Ultra line gaming performance, it'd seem), which is nothing to sniff at.\n\nAnd the overall build quality of this thing? Purely outstanding. It is a gaming notebook; you can tell that from the get-go, there's no hiding that. There are angles and edges, embossed logos, and a jutting webcam divot, among other things, along with a whole host of I/O ports protruding out of its bottom. But it's not ostentatious.\n\nThere's a suaveness to it, from the \"luna grey\" metallic satin finish to the heft and bulk of the thing. It feels solid, yet remains sleek, like it's designed for even the most aggro of esports streamers to wail on after they go 0-3 in competitive. I've played around with laptops four times the cost of this thing that pale in comparison when it comes to the build quality on show here, and that's not nothing.\n\nImage 1 of 5 (Image credit: Future) (Image credit: Future) (Image credit: Future) (Image credit: Future) (Image credit: Future)\n\nBuy if... ✅ You don't mind the upgrade path: There's no denying it. The single-channel memory and 512 GB SSD on the base model are massively underwhelming. If you don't mind spending a little extra or can upgrade the two, then the Lenovo LOQ 15 is a fine choice for 1080p gaming.\n\nDon't buy if... ❌ You're looking for something with a bit more flair: Aside from the above, the LOQ is very much a marmite style. You'll either love how subtle it is for a gaming notebook or despise it. If you're looking for something a little flashier, this ain't it.\n\nCooling is impressive as well, and throughout my time testing, temps rarely got over 70 degrees, even under intense loads. Yes, fan noise is a thing, particularly when it's plugged in, but it's all manageable in Lenovo's Legion app, which, although relatively barebones, does a good enough job of managing noise in exchange for heat, which again you've got a good 20 degrees to play with. There are, of course, your state-mandated AI apps integrated in here as well, requiring Lenovo account sign-up and more, along with the usual intrusive McAfee anti-virus pre-install to be aware of, but from a software perspective, that's about it for bloatware.\n\nElegant. Sophisticated. Well paired. Dialled in to a T. Yet flawed. That is what the LOQ 15 represents. With resplendent gaming performance and a sleek, sharp design that eschews the usual \"gamer\" nonsense in favor of sophisticated style instead, it's a laptop that checks a lot of boxes. Yet, it's not without fault, and although it entertains well enough, it could've been far, far better if only Lenovo had tweaked that entry-level model's configuration first. Still, for the price, you'd be hard pressed to find an RTX 5060 notebook that packs as much punch as the LOQ 15 does into that price, and for that, I doth my hat to you fine Lenovo, you have done well.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/gaming-laptops/lenovo-loq-15-gen10-review/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Does the rise of the NPU spell the beginning of the end for discrete GPUs?",
      "content": "I was recently writing my MSI Prestige A16 AI+ review, and it got me thinking about the future of laptops. My drifting off had absolutely nothing to do with the quality of MSI's latest offering; I did give it a solid 4 stars after all, but was rather a result of the huge upsurge we've seen in AI-branded laptops.\n\nIn the last 18 months, I've lost track of the number of AI laptops we've tested, and it shows no signs of slowing down. As a result, I've been questioning if high-end creatives are going to need discrete GPUs in the future or if CPUs and Neural Processing Units (NPUs) will begin to dominate the landscape.\n\nTo make sure we're all on the same page, an NPU is a specialised microprocessor designed to drastically accelerate artificial intelligence. From a creativity perspective, an NPU takes on the role of AI inference that was previously handled inefficiently by a GPU or, for lighter tasks, the CPU. As a result, laptops are able to make fast, informed decisions without needing to run extensive calculations on the GPU.\n\n(Image credit: Intel)\n\nWhat we're finding is that the type of creative tasks we're performing is changing, and as a result, the gravitational pull of processing is moving away from discrete GPUs and towards NPUs. The point is overstated, but at the very least, the need for entry-level discrete GPUs is becoming increasingly redundant.\n\nFor example, why pay for a separate, small discrete GPU when the NPU and integrated graphics can handle all but the most intensive tasks while saving battery and space?\n\nAt this point in time, we've not yet witnessed a reduction in the requirement for high-end dedicated GPUs in specialised fields. These powerful standalone cards, with their massive parallel processing cores and dedicated high-speed VRAM, remain indispensable for workloads where power efficiency is secondary to raw performance.\n\nDiscrete GPUs are still required for high-fidelity 4K video editing, graphics-heavy gaming, and professional 3D rendering, but it's not beyond the realms of possibility for AI to become so powerful that discrete GPUs become entirely unnecessary. One example from my own world of 3D visualisation would be that rather than needing a GPU to calculate physically accurate results, AI will be able to access its knowledge base and generate the same results.\n\nGet the Creative Bloq Newsletter Daily design news, reviews, how-tos and more, as picked by the editors. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n(Image credit: AMD)\n\nI appreciate we're many years away from this reality, but given the AI progress we've witnessed in the past two years, I wouldn't be surprised if we see it a lot sooner than most would think.\n\nFor now, the CPU with an NPU and integrated GPU dominates for energy-efficient, everyday computing and basic on-device AI, while the discrete GPU maintains its stronghold by offering the unmatched computational horsepower required for the most demanding visual and AI workloads.\n\nThe discrete GPU market doesn't look like it's being eliminated any time soon, but I'll be interested to see how AI-branded laptops evolve in 2026 and whether they begin to erode the need for high-end and very expensive GPUs.",
      "source": "Creative Bloq",
      "url": "https://www.creativebloq.com/3d/does-the-rise-of-the-npu-spell-the-beginning-of-the-end-for-discrete-gpus",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "CyberLink PowerDirector Ultimate 2026 v24.0.1001.1",
      "content": "Posted on Oct 3rd, 2025 at 8:20 pm in Applications Windows by Ash\n\nDescription: Award-winning video editing software for professional creators. Create. Edit. Share. Video editing, made for everyone. No experience necessary. Do more, faster with customizable templates. Discover and create attention-grabbing video intros alongside our community of creatives.\n\nKickstart Your Projects\n\n- No experience necessary.\n\n- Do more, faster with customizable templates.\n\nSave Time With Thousands of Shareable Video Intros\n\nDiscover and create attention-grabbing video intros alongside our community of creatives.\n\nMask Designer\n\nRemove unwanted objects, or composite clips together.\n\n- Custom Masks\n\n- Image Masks\n\n- Text Masks\n\nTitle Designer\n\nChoose from drag-and-drop presets or get creative with an array of gradient, border, and shadow tools.\n\n- Motion Graphics\n\n- Sound Effects\n\n- Blending Modes\n\n- Special Effects\n\nPiP Designer\n\nUse animated stickers, shapes, and callouts to grab your viewers’ attention.\n\n- In/Out Animations\n\n- Animated Stickers and Graphics\n\n- Custom Shapes and Callouts\n\nAI Motion Tracking\n\nAdd text or graphics that automatically follow the motion of any object.\n\nAI Sky Replacement\n\nFrom blissful blue skies to dramatic sunsets, don’t let bad weather ruin your perfect shot.\n\nAI Object Detection\n\nInstantaneously create masks with automatic object selection for cars, people, pets, and more.\n\nSystem Requirements\n\n- Microsoft Windows 11, 10, 8/8.1, 7 (64 bit OS only).\n\n* Microsoft Windows 11 or 10 required for AI features and NVIDIA Audio/Video Denoise and Room Echo Removal.\n\n- Intel Core™ i-series and above.\n\n- Haswell (4th generation) processor: Core i7-4770 (only Core and Xeon branded), and above required for AI features.\n\n- AMD Phenom® II and above.\n\n- AMD A8-7670K and above, AMD Ryzen™ 3 1200 and above required for AI features.\n\n- Standard Video: 128 MB VGA VRAM or higher.\n\n- 360-video: DirectX 11 compatible.\n\n- AI Plugin: 2 GB VGA VRAM or higher.\n\n- NVIDIA Audio/Video Denoise and Room Echo Removal: NVIDIA GeForce RTX 2060, NVIDIA Quadro RTX 3000, NVIDIA TITAN RTX, or higher.\n\n- 4GB memory required (6GB or above recommended).\n\n- 8GB memory or higher required for NVIDIA Audio/Video Denoise and Room Echo Removal.\n\n- 7GB space required.\n\n- Burning drive is required for disc burning purpose.\n\n- Windows compatible sound card is required.\n\n- 1024 x 768, 16-bit color or above.\n\nSupported Languages\n\n- English\n\n- French\n\n- German\n\n- Italian\n\n- Spanish (European)\n\n- Chinese Simplified\n\n- Chinese Traditional\n\n- Japanese\n\n- Korean\n\n- Dutch\n\nRelease Name: CyberLink PowerDirector Ultimate 2026 v24.0.1001.1\n\nSize: 679.2 MB\n\nLinks: HOMEPAGE – NFO – Torrent Search\n\nDownload: RAPiDGATOR",
      "source": "Rlsbb.to",
      "url": "https://post.rlsbb.to/cyberlink-powerdirector-ultimate-2026-v24-0-1001-1/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Chip designer Jim Keller says Intel still has 'a lot of work to do' — would consider it for Tenstorrent AI chip production, already in talks with TSMC, Rapidus, and Samsung for 2nm tech",
      "content": "AI chip design startup, Tenstorrent, has announced it's working with a range of companies to build out its next-generation AI chips. These include TSMC, Samsung, and Japanese firm Rapidus, all of which will provide their latest 2nm process nodes to develop future AI hardware. CEO and AMD and Apple Veteran, Jim Keller, has also said he'd consider working with Intel, but that it \"still [has] a lot of work to do,\" according to Nikkei Asia.\n\nTenstorrent was founded in 2016, with Jim Keller coming on as CTO in 2020 and then CEO in 2023. It's targeting a different approach to giants like Nvidia in its chip production, focusing more on cutting costs and maximizing efficiency. Its current chips, like the Blackhole AI accelerator, are built on TSMC's 6nm node, while an upcoming Quasar chip design uses Samsung's 4nm process. Beyond that, it wants 2nm for whatever comes next.\n\nIt's rare for companies to work with such a range of manufacturers for cutting-edge chips, but Tenstorrent claims it can do it because it uses chiplets for its designs. That lets it have different fabricators build different chips for it, and then it can package them altogether on a single die.\n\nAlongside TSMC and Samsung, it is also working with Japanese firm Rapidus, a startup set up in just 2022 and supported by a range of Japanese businesses. Its sole model is to produce cutting-edge 2nm hardware by 2027. This is partly to reinvigorate Japan's semiconductor industry, but also to create localized and national capacity for advanced semiconductor production, as many countries are looking to do following the AI boom.\n\nTenstorrent has also worked with GlobalFoundries in the past, and has said it won't rule out using Intel's process technology in the future. Keller just seemingly wants to see where that technology goes, especially following recent investments from Nvidia and the US government.\n\nSpeaking on Intel with Nikkei Asia, Jelly said that \"they still have a lot of work to do ... to deliver a really solid technology roadmap.\"\n\nMore immediately, Keller is looking to undercut the competition and target smaller companies that want to still leverage the capabilities of locally run AI, not just those building out giant multi-billion-dollar data centers.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n\"Everybody says Nvidia, OpenAI, Google ... Well, the long tail of small applications is very large, too,\" Keller said. \"We have developers who buy a $10,000 workstation and they're really happy. ... There's a lot of them, and that will lead to bigger business.\"\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/semiconductors/chip-designer-jim-keller-says-intel-still-has-a-lot-of-work-to-do-would-consider-it-for-tenstorrent-ai-chip-production-already-in-talks-with-tsmc-rapidus-and-samsung-for-2nm-tech",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Path Tracing Took 6 Months to Implement in DOOM: The Dark Ages; id Software Dev Thinks the Tech Will Spread Further",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/path-tracing-took-six-months-to-implement-doom-the-dark-ages/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Cracking a long-standing weakness in a classic algorithm for programming reconfigurable chips",
      "content": "This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:\n\nCredit: Pixabay/CC0 Public Domain\n\nResearchers from EPFL, AMD, and the University of Novi Sad have uncovered a long-standing inefficiency in the algorithm that programs millions of reconfigurable chips used worldwide, a discovery that could reshape how future generations of these are designed and programmed.\n\nMany industries, including telecoms, automotive, aerospace and particle physics rely on a special breed of chip called the Field-Programmable Gate Array (FPGA). Unlike traditional chips, FPGAs can be reconfigured almost endlessly, making them invaluable in fast-moving fields where designing a custom chip would take years and cost a fortune. But this flexibility comes with a catch: FPGA efficiency depends heavily on the software used to program them.\n\nSince the late 1990s, an algorithm known as PathFinder has been the backbone of FPGA routing. Its job: connecting thousands of tiny circuit components without creating overlaps.\n\nFor decades, it worked so well that it became the standard. However, as circuits grew larger, engineers began encountering frustrating slowdowns and occasional outright failures. Designs that should have worked were often labeled \"unroutable.\"\n\nNow, with colleagues from the University of Novi Sad and the technology company AMD, researchers from the Parallel Systems Architecture Laboratory (PARSA) in the School of Computer and Communication Sciences have come one step closer to untangling the inner workings of this classic algorithm.\n\nIn their paper, which received the Best Paper Award at the 33rd IEEE International Symposium on Field-Programmable Custom Computing Machines, they revealed why these failures happen and how PathFinder's limits can be overcome.\n\nCracks in the algorithm\n\n\"In fact, it's not surprising that PathFinder sometimes fails,\" explained Shashwat Shrivastava, Ph.D. student with PARSA and first author of the paper.\n\n\"Very early on, researchers showed that the problem behind FPGA routing is extremely hard. Later, the creators of the original algorithm, together with a few collaborators, found cases where PathFinder would never succeed—but they noted such cases wouldn't appear in practice.\"\n\nFor decades, it seemed they were correct—PathFinder worked surprisingly well.\n\n\"PathFinder worked so well, in fact, that when it failed, people rarely questioned the algorithm. Instead of venturing inside to see what was going on, they tweaked its parameters, modified circuits, or switched to larger FPGAs,\" added Stefan Nikolić, an EPFL alumnus and now a professor at the University of Novi Sad.\n\n\"Part of the reason for this is that it is rather difficult to understand what PathFinder is actually doing on examples of practical importance. Modern circuits are so large that their signals form veritable on-chip jungles.\"\n\nEnter the forest\n\n\"So, we really needed to look at the individual trees in that jungle,\" continued Shrivastava, \"and I really mean trees. Each signal—a connection that carries information between circuit components—must reach multiple destinations without overlapping other signals. FPGA routing is essentially about building one tree for each signal on the chip.\"\n\nWhile working on another project that relied on PathFinder, the team kept seeing results that defied intuition. At first, they blamed external factors, not the algorithm itself. Eventually, they realized they needed controlled examples: small, tricky cases where a solution definitely existed, and in which PathFinder should succeed.\n\n\"We needed real, practical examples, and lots of them, to understand what was really going on,\" Shrivastava explains. \"So, we built a framework to automatically extract small, hard problems from real circuits. Watching how PathFinder struggled with these helped us uncover issues that had remained hidden for a very long time.\"\n\nPower in partnership\n\n\"This breakthrough would have been much harder without industry support,\" said Mirjana Stojilović, Shrivastava's Ph.D. advisor. \"From the start, we collaborated with Chirag Ravishankar and Dinesh Gaitonde from AMD. They helped us model FPGAs as close as possible to commercial devices, ensuring our findings had real-world impact.\"\n\nOnce the framework was ready, things moved quickly. The team found that PathFinder often built routing trees larger than necessary, increasing the risk of overlaps. The problem came from the order in which it created and added new branches to the trees.\n\n\"In retrospect, this is intuitive, but somehow it went largely unnoticed for many years,\" Shrivastava said. \"Our first solution was simple: try different orders and pick the one that results in the smallest tree. Experimentally, it worked surprisingly well.\"\n\nThe team is now exploring more scalable solutions. \"I am especially proud that Summer@EPFL interns have been contributing significantly. One of them, Sun Tanaka, is also a co-author of the paper,\" added Stojilović.\n\n\"Our discovery could reshape how millions of FPGAs are programmed and influence the design of future generations of these reconfigurable chips.\"\n\nMore information: Shashwat Shrivastava et al, Guaranteed Yet Hard to Find: Uncovering FPGA Routing Convergence Paradox, 2025 IEEE 33rd Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM) (2025). DOI: 10.1109/fccm62733.2025.00060",
      "source": "Tech Xplore",
      "url": "https://techxplore.com/news/2025-10-weakness-classic-algorithm-reconfigurable-chips.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "7 reasons Proxmox is the best OS for your homelab",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/reasons-proxmox-best-os-for-your-homelab/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "ViprTech Reaper 2.5 Liquid-Cooled PC - Ryzen 7 8700F 5.0GHz, AMD RX 9060XT 16GB, 32G DDR5, 2T SSD, Sold by ViprTech $1199.99",
      "content": "Deal History includes data from multiple reputable stores, such as Best Buy, Target, and Walmart. The lowest price among stores for a given day is selected as the \"Sale Price\".\n\n\n\nSale Price does not include sale prices at Amazon unless a deal was posted by a community member.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18660010-viprtech-reaper-2-5-liquid-cooled-pc-ryzen-7-8700f-5-0ghz-amd-rx-9060xt-16gb-32g-ddr5-2t-ssd-sold-by-viprtech-1199-99",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Your RAM has more than one XMP profile, and here's when to use the others",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/your-ram-has-more-than-one-xmp-profile-and-heres-when-to-use-the-others/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "The 43rd Golden Joystick Awards Have Opened Voting",
      "content": null,
      "source": "Bleeding Cool News",
      "url": "https://bleedingcool.com/games/the-43rd-golden-joystick-awards-have-opened-voting/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Hell freezes over: AMD may team up with Intel to produce chips - but I don't expect Intel foundries to push out Ryzen CPUs anytime soon",
      "content": "Intel in talks to produce AMD chips despite major technology hurdles\n\nAMD may shift limited production to Intel while protecting flagship processors\n\nWashington favors US chipmaking as Intel woos investors and potential customers\n\nBack in February 2025, well before everyone suddenly got interested in throwing money at Intel, I wrote that the iconic but beleaguered chip maker could be about to merge with GlobalFoundries - a rumor made all the more salacious as GloFlo is AMD’s former foundry.\n\nThe headline I gave it started with “Hell freezes, pigs fly” because frankly it seemed like an unlikely situation.\n\nFast forward to now, and Semafor is reporting that Intel is in early talks to add AMD as a foundry customer, which isn’t as unlikely as it would have been a few months ago, but still…\n\nNot flagship chips though\n\nIntel has been on something of a charm offensive lately, seeking customers and investors to back its push to establish itself as a contract chipmaker.\n\nIn recent weeks it has lined up financial support from the White House, Nvidia, and SoftBank, been in talks with Apple and TSMC, and no doubt had a few behind closed door conversations with other members of the so-called Magnificent 7.\n\nFor AMD, any foundry deal with Intel would be more than a little complicated. Its most advanced processors are built on TSMC’s leading-edge nodes, which Intel can’t yet match.\n\nThis makes it unlikely AMD would hand over production of its flagship products to its long-time rival.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAt best, the resurgent chip maker might win some lower-margin or less complex chips, which would still help diversify AMD’s supply chain and earn goodwill in Washington.\n\nAs a commenter on Tom’s Hardware suggested, “I am wondering if AMD will make the embedded (low power APUs) and networking (Pensando) stuff in Intel's fabs. That would make the most sense to me, due to supply distances. Makes little to no sense to do chips in the USA, send them to Taiwan/Malaysia and then back to the USA.”\n\nIt's not yet clear how far discussions have gone, or whether they would involve AMD taking a direct stake in Intel’s foundry arm, as other partners have done.\n\nSemafor says both companies have so far declined to comment on the matter.\n\nFollow TechRadar on Google News and add us as a preferred source to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!\n\nAnd of course you can also follow TechRadar on TikTok for news, reviews, unboxings in video form, and get regular updates from us on WhatsApp too.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/hell-freezes-over-amd-may-team-up-with-intel-to-produce-chips-but-i-dont-expect-intel-foundries-to-push-out-ryzen-cpus-anytime-soon",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "International Business Machines (IBM) and AMD Announce Collaboration For Delivering Advanced AI Infrastructure",
      "content": "International Business Machines (IBM) and AMD Announce Collaboration For Delivering Advanced AI Infrastructure\n\nInternational Business Machines Corporation (NYSE:IBM) is one of the Best Quantum Computing Stocks to Buy and Hold for 5 Years. On October 1, International Business Machines…\n\nThis story appeared on finance.yahoo.com , 2025-10-04 21:15:54.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b6aeb5b60bf2e106",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Ditching smart home subscriptions for open-source Home Assistant",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/ditched-smart-home-subscriptions-switched-to-home-assistant/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "How to Check CPU Temperature – A Practical Guide for Windows, macOS, Linux & BIOS",
      "content": "Click here to buy secure, speedy, and reliable Web hosting, Cloud hosting, Agency hosting, VPS hosting, Website builder, Business email, Reach email marketing at 20% discount from our Gold Partner Hostinger You can also read 12 Top Reasons to Choose Hostinger’s Best Web Hosting\n\nYou suspect your PC is running hotter than it used to — fans sound louder, battery life is shorter, games stutter. That nagging worry (“is my CPU cooking itself?”) grows when temperatures spike under load. Left unchecked, sustained high temps can cause throttling, instability, and shorter hardware lifespan. The good news: checking CPU temperature is fast and repeatable. In this guide I’ll show how to check CPU temperature across Windows, macOS, Linux and BIOS, explain what numbers actually matter, and give a simple troubleshooting checklist so you can fix the cause — not just the symptom.\n\nIntel® DSA is a free tool from Intel that keeps your drivers up to date. It scans your computer, finds outdated or missing drivers for Intel hardware, and helps you install the latest ones. This makes sure your system stays stable and performs well.\n\nWhy monitoring CPU temperature matters\n\nProtect performance: Modern CPUs throttle clocks under high temperatures to avoid damage — which reduces performance.\n\nCatch failures early: A rising idle temperature over weeks or months often means a failing cooler, clogged vents, or dried thermal paste.\n\nPeace of mind: Knowing normal idle and load ranges for your CPU helps you distinguish “normal” from “problem”.\n\nQuick fact: CPU manufacturers publish maximum operating thresholds (Tjunction/Tcase) and internal protections — CPUs will throttle or shut down near those limits to protect silicon. See Intel and AMD documentation for how to find your processor’s exact spec.\n\nHow to check CPU temperature\n\nBIOS/UEFI — best for baseline (before OS drivers). Built-in OS tools — some platforms expose temps natively. Third-party monitoring apps — detailed, real-time graphs and logging. Command-line tools — ideal for Linux or automation.\n\nBelow I walk through each method with step-by-step instructions.\n\nWindows Memory Diagnostic is a built-in tool for checking potential issues with your computer’s RAM (Random Access Memory). Faulty RAM can cause crashes, slow performance, or unexpected restarts. This guide will walk you through how to use this tool effectively, along with additional tips for troubleshooting and improving memory performance.\n\n1) Check CPU temperature in BIOS / UEFI (works on all PCs)\n\nWhy use BIOS? It shows temperatures before the OS loads — good baseline for idle temps.\n\nSteps:\n\nRestart PC and press the BIOS/UEFI key (common keys: Delete, F2, F10 — check your motherboard manual).\n\nNavigate to Hardware Monitor , PC Health , or H/W Status .\n\nLook for CPU Temperature, Core Temp, or similar. Note idle reading (room temp ~22°C gives typical idle 30–40°C on desktops; laptops run higher).\n\nTip: If BIOS reports much higher idle than expected, suspect cooling or thermal contact problems.\n\n2) Windows — built-in and third-party options\n\nBuilt-in: Windows 11 (newer builds) exposes CPU temperature in Task Manager for supported hardware; however coverage depends on OEM drivers and sensor support. Where available, Task Manager gives a quick check but is limited.\n\nBest third-party tools (Windows):\n\nHWiNFO — detailed sensor reporting, per-core temps, logging, and real-time graphs.\n\nCore Temp — lightweight, per-core temperature reporting and TjMax comparison.\n\nHWMonitor — simple list of sensors (temps, voltages, fan speeds).\n\nHow to use (example with HWiNFO):\n\nDownload HWiNFO (portable) and run Sensors-only. Watch Core # and Package temperatures; enable logging if you want a record. Stress-test with a tool (Cinebench, Prime95) while monitoring to see load temps.\n\nPractical note: Windows tools may report per-core and package temps differently — package temp is often the best single-number indicator for the whole CPU.\n\n3) macOS — simple options\n\niStat Menus (paid) — system-wide sensors including CPU package temps and historical charts.\n\nIntel Power Gadget (Intel Macs) — shows package power/temperature (for Intel-based Macs).\n\nApple Silicon: macOS limits direct sensor exposure for Apple Silicon; rely on Activity Monitor + manufacturer info for behavior; third-party tools are limited.\n\n4) Linux — command-line and GUI\n\nlm-sensors : sudo apt install lm-sensors → sudo sensors-detect → sensors to read temps.\n\npsensor: GUI that graphs temps and fan speeds, built on lm-sensors.\n\nPro tip: Use watch -n 1 sensors to monitor temps in a terminal during stress tests.\n\n5) Interpreting numbers — what’s safe and what’s not\n\nIdle temps: Desktop CPUs: ~30–45°C typical; laptops: 40–60°C typical (depends on design).\n\nLoad temps: Many modern desktop CPUs commonly run 70–85°C under sustained heavy loads with stock cooling; short spikes into 90°C may occur.\n\nManufacturer limits: Intel/AMD list maximum operating (junction) temperatures in official specs — often around 95–110°C, varying by model. Rely on the product page/spec sheet for your exact CPU.\n\nRule of thumb: sustained temps above 90–95°C deserve investigation. Temperatures near the documented max trigger throttling and increase wear.\n\nUse temperature trends as predictive maintenance\n\nMost guides tell you how to check a temperature now. Here’s a practical extension: log daily idle temps for 2–4 weeks to build a baseline. If your idle temp increases steadily (for example, 5–10°C over a month), that often signals:\n\nDust-clogged heatsink or fans\n\nDrying/deteriorating thermal paste\n\nNew background process or driver misbehavior\n\nHow to implement a simple trend: set HWiNFO or lm-sensors to log a timestamped idle temp once per day (or at boot). Plot or inspect values weekly. If average idle rises beyond a comfortable delta (e.g., +5°C month-over-month), schedule a cleaning or thermal service. This predictive approach prevents sudden failures and keeps performance consistent.\n\nIntel®-Based Systems for Everything You Do\n\n\n\nClick here to find out what’s for you\n\nIntel-based systems are used in a variety of devices, including desktop PCs, laptops, servers, and more. Intel processors are available in many different models and generations, and are designed for a range of tasks.\n\nMini-case study — laptop that got hotter after 12 months\n\nScenario: A user reported idle temps rising from 45°C to 62°C across 12 months.\n\nInvestigation: Logs (HWiNFO) showed steps up after a Windows update and after heavy browsing sessions. Physical check found dust buildup and a partially blocked fan intake. After cleaning vents and reapplying thermal paste, idle temps returned to ~46°C and load temps dropped ~8°C.\n\nLesson: Combine software monitoring with simple physical maintenance — logs point to “when” and inspection fixes the “why”.\n\nTroubleshooting checklist\n\nCheck background processes (Task Manager / top). Clean dust & improve airflow — especially laptops. Check cooler seating / reapply thermal paste (desktop CPU cooler reseat often helps). Update BIOS/firmware and chipset drivers. Improve case airflow (add/reposition fans, use mesh panels). Consider a better cooler — aftermarket air or AIO liquid for high-TDP chips. Throttle profiles / power plans — set balanced or custom profiles if needed. If temps exceed spec despite fixes, contact manufacturer.\n\nKey Takeaways\n\nHow to Check CPU Temperature: use BIOS for baseline, OS tools for quick checks, and third-party apps for deep monitoring.\n\nKnow your CPU’s spec: maximum operating temperatures vary by model — consult the manufacturer. Intel\n\nTrend logging is powerful: daily idle temperature trends can predict cooling degradation before it becomes critical.\n\nSustained temps above ~90°C generally need action.\n\nFixes are often simple: cleaning, reseating cooler, or reapplying thermal paste frequently solve rising temps.\n\nDo You Know the 7 Potential Disadvantages of Artificial Intelligence (AI)\n\nFAQs (People Also Ask)\n\nQ: What is a normal CPU temperature at idle?\n\nA: For desktops ~30–45°C is common; laptops typically run higher (40–60°C) depending on chassis and cooling.\n\nQ: Can CPUs be damaged by high temperature?\n\nA: Modern CPUs have thermal protections (throttling, shutdown). Repeated sustained overheating can shorten lifespan, so address sustained temps near spec limits.\n\nQ: Which tool is best to monitor CPU temperature on Windows?\n\nA: HWiNFO is widely recommended for detail and logging; Core Temp and HWMonitor are simpler alternatives.\n\nQ: Should I rely on Task Manager for CPU temperature?\n\nA: Task Manager (Windows 11) can show temps on supported systems, but it’s not as detailed as dedicated sensor tools and depends on driver support.\n\nConclusion\n\nYou don’t need to be a technician to know how to check CPU temperature — a few clicks or a quick BIOS visit gives you the numbers, and simple logs reveal trends. Once you can measure reliably, you can prevent throttling, extend hardware life, and keep performance predictable. Try one monitoring tool today, take a baseline reading, and add simple logging — that small habit pays off fast.\n\nStart by checking your CPU temperature now (BIOS or HWiNFO). If you found abnormal numbers, follow the troubleshooting checklist above — and subscribe to SmashingApps for more practical hardware guides and step-by-step fixes.",
      "source": "Smashingapps.com",
      "url": "https://www.smashingapps.com/how-to-check-cpu-temperature/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "HP 15 Laptop: 15.6\" FHD, Ryzen 7 5825U, 8GB RAM, 512GB SSD $299.99 (3 replies)",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18660451-hp-15-laptop-15-6-fhd-ryzen-7-5825u-8gb-ram-512gb-ssd-299-99",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Analysts Set Clearside Biomedical, Inc. (NASDAQ:CLSD) PT at $63.00",
      "content": "Clearside Biomedical, Inc. (NASDAQ:CLSD – Get Free Report) has earned an average rating of “Hold” from the six brokerages that are presently covering the firm, Marketbeat.com reports. Five research analysts have rated the stock with a hold recommendation and one has assigned a buy recommendation to the company. The average 1-year price target among brokerages that have issued ratings on the stock in the last year is $63.00.\n\nCLSD has been the subject of several research reports. Stifel Nicolaus lowered shares of Clearside Biomedical from a “buy” rating to a “hold” rating and set a $30.00 price target for the company. in a research note on Friday, July 18th. Jones Trading cut Clearside Biomedical from a “strong-buy” rating to a “hold” rating in a research report on Thursday, July 17th. Chardan Capital downgraded Clearside Biomedical from a “buy” rating to a “neutral” rating in a research note on Friday, July 18th. Needham & Company LLC cut Clearside Biomedical from a “moderate buy” rating to a “hold” rating and set a $45.00 price objective for the company. in a research note on Thursday, July 17th. Finally, Wall Street Zen raised Clearside Biomedical to a “sell” rating in a report on Saturday, September 20th.\n\nGet Clearside Biomedical alerts:\n\nCheck Out Our Latest Report on CLSD\n\nClearside Biomedical Stock Up 7.4%\n\nShares of CLSD stock opened at $4.37 on Wednesday. The firm has a market capitalization of $22.89 million, a price-to-earnings ratio of -0.79 and a beta of 2.05. The stock has a fifty day moving average of $5.33 and a 200 day moving average of $9.88. Clearside Biomedical has a 52 week low of $3.32 and a 52 week high of $24.75.\n\nClearside Biomedical (NASDAQ:CLSD – Get Free Report) last issued its quarterly earnings data on Friday, August 8th. The company reported ($0.90) EPS for the quarter, topping the consensus estimate of ($1.80) by $0.90. The company had revenue of $0.49 million during the quarter, compared to the consensus estimate of $0.50 million. Equities research analysts anticipate that Clearside Biomedical will post -0.48 earnings per share for the current year.\n\nInstitutional Trading of Clearside Biomedical\n\nA hedge fund recently raised its stake in Clearside Biomedical stock. Northern Trust Corp grew its position in Clearside Biomedical, Inc. (NASDAQ:CLSD – Free Report) by 24.0% in the 4th quarter, according to its most recent disclosure with the SEC. The fund owned 165,499 shares of the company’s stock after buying an additional 32,048 shares during the period. Northern Trust Corp owned approximately 0.22% of Clearside Biomedical worth $157,000 as of its most recent SEC filing. 18.75% of the stock is owned by institutional investors.\n\nAbout Clearside Biomedical\n\n(Get Free Report)\n\nClearside Biomedical, Inc, a biopharmaceutical company, focuses on the revolutionizing the delivery of therapies to the back of the eye through the suprachoroidal space. It offers XIPERE, a triamcinolone acetonide suprachoroidal injectable suspension for the treatment of uveitis macular edema. It also develops CLS-AX, an axitinib injectable suspension for suprachoroidal injection, which is in Phase IIb clinical trial to treat wet AMD.\n\nRecommended Stories\n\nReceive News & Ratings for Clearside Biomedical Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Clearside Biomedical and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/04/analysts-set-clearside-biomedical-inc-nasdaqclsd-pt-at-63-00/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Maxsun Intros Powerful AI Workstation PC, Featuring Up To Four Intel Arc Pro B60 48G Turbo GPUs, Bringing A Massive 192 GB VRAM Capacity",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/maxsun-intros-powerful-ai-workstation-pc-featuring-up-to-four-intel-arc-pro-b60-48g-turbo-gpus/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "International Business Machines (IBM) and AMD Announce Collaboration For Delivering Advanced AI Infrastructure",
      "content": "International Business Machines Corporation (NYSE:IBM) is one of the Best Quantum Computing Stocks to Buy and Hold for 5 Years. On October 1, International Business Machines Corporation (NYSE:IBM) and AMD announced a collaboration focused on delivering advanced AI infrastructure to Zyphra, which is an open-source AI research and product company. Under the multi-year agreement between International Business Machines Corporation (NYSE:IBM) and Zyphra, the former is positioned to deliver a large cluster of AMD Instinct™ MI300X GPUs on IBM Cloud for Zyphra to use for training frontier multimodal foundation models.\n\nInternational Business Machines (IBM) and AMD Announce Collaboration For Delivering Advanced AI Infrastructure\n\nNotably, the collaboration is anticipated to deliver among the largest advanced generative AI training capabilities to date, powered by an AMD stack running on IBM Cloud. Elsewhere, at the Q2 2025 earnings call, International Business Machines Corporation (NYSE:IBM) stated that, in Quantum, it achieved a major milestone with the deployment of IBM Quantum System Two in Japan in partnership with RIKEN. This highlights the first installation outside the US, strengthening its commitment to global leadership in quantum computing. Notably, IBM Quantum® is a full-stack quantum computing provider.\n\nWhile we acknowledge the potential of IBM as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you’re looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 13 Cheap AI Stocks to Buy According to Analysts and 11 Unstoppable Growth Stocks to Invest in Now\n\nDisclosure: None. This article is originally published at Insider Monkey.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/international-business-machines-ibm-amd-211554992.html",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Top Technology Stocks To Add to Your Watchlist – October 2nd",
      "content": "NVIDIA, Advanced Micro Devices, and Microsoft are the three Technology stocks to watch today, according to MarketBeat’s stock screener tool. Technology stocks are shares in companies whose primary business involves developing, manufacturing or distributing technology products and services—ranging from software and hardware to semiconductors, internet platforms and IT services. These equities often appeal to investors seeking high growth potential driven by innovation and digital transformation, though they can also exhibit greater volatility and risk compared with more traditional sectors. These companies had the highest dollar trading volume of any Technology stocks within the last several days.\n\nGet alerts:\n\nNVIDIA (NVDA)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nAdvanced Micro Devices (AMD)\n\nAdvanced Micro Devices, Inc. operates as a semiconductor company worldwide. It operates through Data Center, Client, Gaming, and Embedded segments. The company offers x86 microprocessors and graphics processing units (GPUs) as an accelerated processing unit, chipsets, data center, and professional GPUs; and embedded processors, and semi-custom system-on-chip (SoC) products, microprocessor and SoC development services and technology, data processing unites, field programmable gate arrays (FPGA), and adaptive SoC products.\n\nRead Our Latest Research Report on AMD\n\nMicrosoft (MSFT)\n\nMicrosoft Corporation develops and supports software, services, devices and solutions worldwide. The Productivity and Business Processes segment offers office, exchange, SharePoint, Microsoft Teams, office 365 Security and Compliance, Microsoft viva, and Microsoft 365 copilot; and office consumer services, such as Microsoft 365 consumer subscriptions, Office licensed on-premises, and other office services.\n\nRead Our Latest Research Report on MSFT\n\nFurther Reading",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/04/top-technology-stocks-to-add-to-your-watchlist-october-2nd/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Huawei Ascend 950 vs Nvidia H200 vs AMD MI300 Instinct: How do they compare?",
      "content": "Huawei Ascend 950DT FP8 formats target efficient inference without accuracy loss\n\nNvidia H200 leans on a mature software ecosystem and Hopper GPU strengths\n\nAMD Instinct MI300’s FP64 parity appeals to serious scientific computation workloads\n\nIn recent years, the demand for AI training and inference computing has pushed chip makers to innovate aggressively - efficiency in memory bandwidth, data formats, interconnects, and total compute output are now as critical as raw FLOPS.\n\nEach company targets demanding scenarios such as generative AI training and high-performance computing, where AI tools increasingly depend on fast accelerators to process massive datasets.\n\nMultiple brands approach the challenge with different compute platform characteristics - so we've tried to help understand these differences and clarify how the Ascend 950 series, H200, and MI300 Instinct compare.\n\nSwipe to scroll horizontally Huawei Ascend 950 vs Nvidia H200 vs AMD MI300 Instinct Category Huawei Ascend 950DT NVIDIA H200 AMD Radeon Instinct MI300 Chip Family / Name Ascend 950 series H200 (GH100, Hopper) Radeon Instinct MI300 (Aqua Vanjaram) Architecture Proprietary Huawei AI accelerator Hopper GPU architecture CDNA 3.0 Process / Foundry Not yet publicly confirmed 5 nm (TSMC) 5 nm (TSMC) Transistors Not specified 80 billion 153 billion Die Size Not specified 814 mm² 1017 mm² Optimization Decode-stage inference & model training General-purpose AI & HPC acceleration AI/HPC compute acceleration Supported Formats FP8, MXFP8, MXFP4, HiF8 FP16, FP32, FP64 (via Tensor/CUDA cores) FP16, FP32, FP64 Peak Performance 1 PFLOPS (FP8 / MXFP8 / HiF8), 2 PFLOPS (MXFP4) FP16: 241.3 TFLOPS, FP32: 60.3 TFLOPS, FP64: 30.2 TFLOPS FP16: 383 TFLOPS, FP32/FP64: 47.87 TFLOPS Vector Processing SIMD + SIMT hybrid, 128-byte memory access granularity SIMT with CUDA and Tensor cores SIMT + Matrix/Tensor cores Memory Type HiZQ 2.0 proprietary HBM (for decode & training variant) HBM3e HBM3 Memory Capacity 144 GB 141 GB 128 GB Memory Bandwidth 4 TB/s 4.89 TB/s 6.55 TB/s Memory Bus Width Not specified 6144-bit 8192-bit L2 Cache Not specified 50 MB Not specified Interconnect Bandwidth 2 TB/s Not specified Not specified Form Factors Cards, SuperPoD servers PCIe 5.0 x16 (server/HPC only) PCIe 5.0 x16 (compute card) Base / Boost Clock Not specified 1365 / 1785 MHz 1000 / 1700 MHz Cores / Shaders Not specified CUDA: 16,896, Tensor: 528 (4th Gen) 14,080 shaders, 220 CUs, 880 Tensor cores Power (TDP) Not specified 600 W 600 W Bus Interface Not specified PCIe 5.0 x16 PCIe 5.0 x16 Outputs None (server use) None (server/HPC only) None (compute card) Target Scenarios Large-scale training & decode inference (LLMs, generative AI) AI training, HPC, data centers AI/HPC compute acceleration Release / Availability Q4 2026 Nov 18, 2024 Jan 4, 2023\n\nArchitecture and design approaches\n\nHuawei’s Ascend 950 series is a proprietary AI accelerator architecture optimized for the decode stage of inference as well as model training, rather than a traditional GPU.\n\nIts design blends SIMD and SIMT processing styles with 128-byte memory access granularity, aiming to balance throughput and flexibility.\n\nNvidia’s H200 is based on the Hopper GPU architecture and integrates 16,896 CUDA cores alongside 528 fourth-generation Tensor cores.\n\nIt uses a single-die GH100 GPU fabricated on a 5 nm TSMC process, maintaining compatibility with Nvidia’s software stack and extensive ecosystem.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAMD’s MI300 Instinct uses the Aqua Vanjaram GPU with the CDNA 3.0 architecture and a chiplet-based MCM design featuring 220 compute units and 880 matrix cores.\n\nThis approach provides a massive transistor budget and a strong focus on high-performance computing.\n\nThe Ascend 950 offers peak performance of one petaflop using FP8, MXFP8, or HiF8 data formats and can double to two petaflops when using MXFP4.\n\nThis highlights Huawei’s focus on emerging low-precision formats designed to improve efficiency during inference without sacrificing accuracy.\n\nNvidia’s H200 delivers 241.3 teraflops in FP16 and 60.3 teraflops in FP32, while AMD’s MI300 provides 383 teraflops in FP16 and nearly 48 teraflops for both FP32 and FP64 workloads.\n\nThe MI300’s FP64 parity with FP32 underlines its suitability for scientific computation, where double-precision is critical, whereas Nvidia’s focus is skewed toward mixed-precision acceleration for AI.\n\nMemory architecture strongly influences training large language models.\n\nHuawei pairs the Ascend 950 with 144GB of HiZQ 2.0 proprietary HBM, delivering 4TB/s of bandwidth and 2TB/s interconnect speed.\n\nNvidia equips the H200 with 141GB of HBM3e memory and a 4.89TB/s bandwidth, slightly ahead in raw throughput.\n\nAMD’s MI300 stands out with 128GB of HBM3 but a wider 8192-bit bus and a leading 6.55TB/s memory bandwidth.\n\nFor massive model training or memory-intensive simulation, AMD’s advantage in bandwidth can translate into faster data movement even if its total memory capacity trails Huawei’s.\n\nThe H200 and MI300 share a 600W thermal design power, fitting into PCIe 5.0 x16 server configurations with no video outputs, underscoring their data center orientation.\n\nHuawei has not disclosed official TDP figures but offers both card formats and integrated SuperPoD servers, suggesting deployment flexibility within its own AI infrastructure solutions.\n\nIts interconnect bandwidth of 2TB/s could be an important factor for multi-chip scaling in data center environments, although details about die size and transistor count remain undisclosed.\n\nNvidia benefits from a mature NVLink and InfiniBand ecosystem, while AMD’s multi-chip module design aims to reduce latency between compute dies.\n\nHuawei clearly aims its Ascend 950 at large-scale training and decode-stage inference for generative AI, a market where Nvidia has long dominated.\n\nIts Q4 2026 availability means Nvidia’s H200, released in late 2024, and AMD’s MI300, available since early 2023, already have a time advantage.\n\nBy the time Ascend 950 hardware reaches customers, both competitors may have iterated on their platforms.\n\nHowever, Huawei’s emphasis on efficient low-precision formats and tight integration with its networking hardware could attract buyers seeking alternatives to U.S. suppliers.\n\nThat said, these accelerators reflect differing philosophies of multiple brands.\n\nAMD prioritizes memory bandwidth and double-precision strength for HPC workloads, while Nvidia leverages ecosystem maturity and software support to maintain dominance in AI training.\n\nHuawei seeks to challenge both with aggressive FP8-class performance and high-capacity proprietary memory.\n\nVia Huawei, Nvidia, TechPowerUp",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/huawei-ascend-950-vs-nvidia-h200-vs-amd-mi300-instinct-how-do-they-compare",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Testing the HP EliteBook X G1a 14 revealed an AI-centric business laptop designed for early adopters",
      "content": "A great demonstration of what Ryzen AI 395 Max+ machines can offer. Remarkably powerful, yet it can still last a long working day on a single battery charge. Makes Intel Core Ultra 200 machines look like they’re running on economy gasoline.\n\nWhy you can trust TechRadar We spend hours testing every product or service we review, so you can be sure you're buying the best. Find out more about how we test.\n\nHP EliteBook X G1a 14 AI: 30-second review\n\nI thought HP naming conventions were silly, but the excessively convoluted title of HP EliteBook X G1a 14 AI borders on self-parody.\n\nTo interpret, this is an EliteBook X model of the G1a generation, featuring a fourteen-inch display, and it has extra AI features applied, much like cream frosting on a birthday cake.\n\nThe critical technology under its hood is an AMD Ryzen AI 9 HX PRO 375 coming directly from AMD’s equally obtuse product labelling department. Under the hood, it uses one of the new Strix Point chips, and only one rung below the extreme Strix Halo series processors.\n\nFor a laptop, this is a computing powerhouse with twelve cores and twenty-four threads, equipped with a decent Radeon 890M GPU. In the review machine, it features 64GB of LPDDR5x-8533 memory.\n\nThe caveat to such a powerful laptop is two-fold: firstly, it can eat through its 75Wh battery quicker than something less gun-ho, and it costs around $2300 to own one.\n\nWhy would you want to spend that much on a laptop? This machine is ideal for anyone who wants to run AI models locally. The NPU is rated at 55 TOPS, and when combined with the CPU’s AI power, the combined rating reaches 85 TOPS, which is impressive for a laptop system, but less than the Zbook Ultra G1a.\n\nHowever, if this seems attractive to you, then you might also want to consider the HP ZBook Ultra G1a 14, as it utilises the AMD Ryzen AI 3950X Max, a full-blown Strix Halo chip.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nIf you are looking for a powerhouse for users who need all the help they can get, the HP EliteBook X G1a 14 AI is up there with the best business laptops we've reviewed.\n\nHP EliteBook X G1a 14 AI: Price and availability\n\n(Image credit: Mark Pickavance)\n\nHow much does it cost? From $1850/2028\n\nFrom $1850/2028 When is it out? Available now\n\nAvailable now Where can you get it? Direct from HP or via Amazon\n\nIn the current crop of HP business laptops, this is one of the more expensive options, but part of that price is that these machines come with either 16, 32 or 64GB of DDR5-8000 RAM.\n\nWhat’s mildly hilarious is that on the HP website in the US, they claim that the MSRP for the review hard spec is $5,149, where they’re offering it at $2,299. In Europe, HP don’t claim anything like that, probably because it’s against the law here to claim a price reduction from a cost that nobody ever paid.\n\nFor those wanting this machine at the lowest cost, HP has a model for $1,848 that comes with 16GB of RAM and 512GB of storage. But you need to be aware that you can’t upgrade the RAM later.\n\nThe cost in the UK of the review hardware with 64GB of RAM and 1TB of storage is £2,027.99 VAT included. In the UK, you can’t get a machine using the 16GB of RAM, but you can get one with the Ryzen 7 AI Pro processor, 32GB of RAM and 512GB of storage for £1,631.99. Given the specification, that is a reasonable cost.\n\nThe products that this machine competes directly with are the Lenovo ThinkPad P14s Gen 6, which typically sells for only $1459 in the US, but £2,399 in the UK. However, that comes with the AMD Ryzen AI 9 HX 370, not the 375. For those interested, the only difference between the two is that the 375 offers 55 TOPS AI processing, compared to 50 on the 370.\n\nAsus also has a machine built around the 370, but wants £2,699 or $2199.99 for the ProArt P16 (H7606), making it even more expensive than the HP.\n\nFrom that perspective, it looks pricey, but given how few brands are offering the top-level 375 processor, this is not insanely expensive. And, it’s easier to get than the Zbook Ultra.\n\nValue: 3.5 / 5\n\nHP EliteBook X G1a 14 AI: Specs\n\nSwipe to scroll horizontally Category Item Processor AMD Ryzen? AI 9 HX PRO 375 (up to 5.1 GHz max boost clock, 24 MB L3 cache, 12 cores, 24 threads) NPU Performance 55 TOPS (Neural Processing Unit for local AI tasks) Total TOPS 85 TOPS (NPU and CPU combined) Memory 64 GB LPDDR5x-8533 MT/s (soldered, non-upgradable) Storage 1 TB PCIe Gen4 NVMe TLC M.2 SSD Graphics AMD Radeon 890M Graphics Display 14-inch diagonal 2.8K OLED touch display Camera 5 MP IR AI camera Audio Quad stereo speakers, dual microphones, Poly Studio tuning, AI noise reduction Ports Right 1x Thunderbolt 4 (USB-C), 1x USB-A, Security cable slot Ports Left 1x HDMI, 1x Thunderbolt 4 (USB-C), 1x USB-C (10Gbps charging), 1x headphone/mic combo Wireless MediaTek Wi-Fi 7 MT7925 (2x2) and Bluetooth 5.4 wireless card Battery HP XL-Long Life 4-cell, 74.5 Wh Li-ion polymer PSU HP 100 W USB Type-C slim adapter Operating System Windows 11 Pro Security HP Wolf Security, TPM 2.0, fingerprint sensor, auto lock/awake, onlook detector Size 31.22 x 21.46 x 0.92 cm (front); 31.22 x 21.46 x 1.31 cm (rear) Weight 1.49 kg Sustainability Up to 90% recycled magnesium, 50% recycled plastic in keycaps, recyclable packaging Warranty 3-year basic hardware and software\n\nHP EliteBook X G1a 14 AI: Design\n\n(Image credit: Mark Pickavance)\n\nThin and elegant\n\nLots of USB\n\nStunning OLED screen\n\nEasy access but little to upgrade\n\nOn the outside, this machine is practically identical to the Zbook Ultra, as they share the same upper chassis, OLED display, keyboard and touchpad.\n\nThe underside features a single large perforated vent that spans 90% of the width and 20% of the depth, providing ample airflow for the internal components. As I discovered later, only the ends of this are actually open to flow, making much of it irrelevant to cooling.\n\nIt’s a mostly metal exterior, making it feel cool to the touch when you pick it up in the morning.\n\nThe port layout is also common to the Zbook Ultra, featuring a Thunderbolt port on each side, as well as an additional USB-C, USB-A, and HDMI port. That’s enough ports to avoid needing to budget for a docking station, and if you do include one, it only needs to deliver 100W to cover the recharge requirements.\n\nI’ve mentioned this 2.8K OLED panel in glowing terms before, as HP has utilised it on a selection of 14-inch laptops; it’s terrific for content creators and also touch-capable. Its only limitation is that because it’s protected by glass for touching, it does suffer from reflections in bright sun conditions.\n\nRemoving four screws and some spudger actions gets you inside relatively easily. Additionally, since this is a metal skin, the likelihood of damaging the underside is significantly reduced compared to a plastic skin.\n\n(Image credit: Mark Pickavance)\n\nRemoving the back revealed an identical layout to the Zboiok Ultra, with two fans that suck in air from either end of the perforated slot for cooling the CPU, memory and other motherboard components.\n\nThe single M.2 2280 slot features a dedicated heatsink that utilises the undertray via a thermal pad to dissipate heat. That means any drive cloning to a larger capacity will require an external USB or Thunderbolt caddy. It’s interesting that this machine is generally offered with a maximum of 1TB, but I’m confident that at least a 2TB or even 4TB might work, as long as the drive doesn’t have a permanent heat sink attached.\n\nAs the memory is soldered to the motherboard, the only reasons to go in here are a storage swap or to replace the battery, since those are the only user-replaceable parts.\n\nThe amount of commonality between this and the ZBook Ultra suggests that HP didn’t expect to sell a large number of these, so it didn’t warrant much that was unique.\n\nApart from the lack of upgrades, this is a design that packs plenty of power into a relatively small chassis, revealing the same ethos that created the ZBook Ultra. I’m not sure which came first, or if they arrived as twins.\n\nDesign: 4 / 5\n\nHP EliteBook X G1a 14 AI: Hardware\n\nAMD Ryzen AI 9 HX PRO 375\n\nRadeon 890M GPU\n\nBandwidth of LPDDR5x-8533\n\nAMD has spawned no less than three processor ranges from its Zen 5/RDNA3.5/XDNA2 architecture in the Ryzen AI 300 series.\n\nThese are divided into the Krackan Point, Strix Point and Strix Halo models, with the top being the Ryzen AI Max+ PRO 395 from the Strix Halo line. The AMD Ryzen AI 9 HX PRO 375 in this machine is a Strix Point design, and the top of that food chain.\n\nThis is a twelve-core CPU with four Zen 5 and eight Zen 5a cores, and all cores have hyperthreading, enabling twenty-four thread processing. This contrasts strongly with Intel’s 200 series designs, which have three core levels, not just performance and efficiency, and hyperthreading is no longer supported.\n\nIf you need more cores, the Ryzen AI Max+ chips offer a 16-core, 32-thread option, but that silicon is also clocked higher, with a base clock of 3GHz. In contrast, the AMD Ryzen AI 9 HX PRO has a 2GHz base. But the Zen 5 cores can boost to 5.1GHz, and the reduction in cores allows for heat to be better shared around the chip. The amount of L3 cache here is 24MB, which sounds great until you realise the AI Max+ 395 has 64MB.\n\nThe downgrade to the AMD Ryzen AI 9 HX PRO also includes the GPU, which receives a previous-generation 890M, rather than the new Radeon 8060s.\n\nThere might be some confusion about the GPU, as many benchmarks and tools I used to test this system repeatedly reported that it has an 880M, not a 890M. But given how small the difference is between those two GPU designs, that’s a mistake that’s easy to make.\n\nSadly, that one change does result in significantly less graphics performance, so those wanting the best integrated GPU should opt for a laptop with the Ryzen AI Max+ chip or one with a discrete mobile GPU.\n\n(Image credit: Mark Pickavance)\n\nWhere the AMD Ryzen AI 9 HX PRO excels is in AI processing, with an NPU rated for 55 TOPS, surpassing the 50 TOPS required by Microsoft to run CoPilot locally. When combined with the CPU, the total TOPS capability is 85.\n\nFor most AI users, running local models is a decent level of performance, although the combined capability of the AMD Ryzen AI 395 Max+ is 126 TOPS combined.\n\nTherefore, in the AMD processor lineup, this is the second-best AI option and is easily better than anything Intel offers.\n\nWhat elevates this chip’s designs is that, alongside the increases in cores, threads and cache, AMD also introduced support for LPDDR5x-8533. That one change delivers a massive bandwidth boost for these systems, and it also makes the GPUs that share main memory perform dramatically better.\n\nThe memory model used is something you should keep in mind when considering the performance of this machine in our tests.\n\n(Image credit: Mark Pickavance)\n\nHardware: 4.5 / 5\n\nHP EliteBook X G1a 14 AI: Performance\n\nSwipe to scroll horizontally Laptops Header Cell - Column 1 HP EliteBook X G1a 14 AI HP Zbook Ultra G1a 14 CPU Row 0 - Cell 1 AMD Ryzen AI 9 HX PRO 375 AMD Ryzen AI 395 Max+ Cores/Threads Row 1 - Cell 1 12C 24T 16C 32T TPD Row 2 - Cell 1 15-54W (28W) 45-120W(55W) RAM Row 3 - Cell 1 64GB DDR5-8000 64GB LPDDR5-8000 SSD Row 4 - Cell 1 1TB Micron 3500 MTFDKBA1T0TGD 2TB Kingston OM8PGP42048N Graphics Row 5 - Cell 1 AMD Radeon 890M AMD Radeon 8060S NPU Row 6 - Cell 1 AMD Ryzen AI (55/85 TOPS) AMD Ryzen AI (50/126 TOPS) 3DMark WildLife 23173 49780 Row 8 - Cell 0 FireStrike 9029 19558 Row 9 - Cell 0 TimeSpy 3966 8506 Row 10 - Cell 0 Steel Nomad.L 3381 7968 CineBench24 Single 116 114 Row 12 - Cell 0 Multi 1152 1244 Row 13 - Cell 0 Ratio 9.98 10.95 GeekBench 6 Single 2914 2876 Row 15 - Cell 0 Multi 15320 16747 Row 16 - Cell 0 OpenCL 38787 78855 Row 17 - Cell 0 Vulkan 48494 74848 CrystalDIsk Read MB/s 7109 6683 Row 19 - Cell 0 Write MB/s 6786 4937 PCMark 10 Office 7965 7919 Row 21 - Cell 0 Battery 12h 46m 10h 48m Battery Whr 74.5 74.5 Row 23 - Cell 0 PSU 100W 140W WEI Score 8.3 9.5\n\nThese numbers might seem a bit cruel, but the comparison I went with was the HP ZBook Ultra G1a 14, a machine that’s almost physically identical but uses the pinnacle of AMD’s mobile processor technology, the impressive AMD Ryzen AI 395 Max+.\n\nAs you might expect, the EliteBook X G1a can’t match the Zbook Ultra G1a when it comes to any test that uses graphics, since the 8060s GPU is imperious.\n\nBut as a computing platform, it certainly holds its ground. And if I were to put an Intel machine up against it, like the HP EliteBook Ultra G1i with its Intel Core i7-258V CPU, then the EliteBook X G1a would be the one that had the edge in processing and graphics.\n\nIt has one significant win against the Zbook Ultra, and that’s battery life, as going slightly slower delivers an additional two hours of running time. Neither of these machines can compete with the Snapdragon X laptops in terms of longevity, but the EliteBook X G1a should easily get most people through a working day. And, it can recover 46% of the battery capacity in 30 minutes.\n\nThe takeaway from testing is that, by any laptop standard, this is a fast and powerful system that is only overshadowed by others, such as the Zbook Ultra, which uses an even more impressive CPU and GPU. A question needs to be asked about how much you are prepared to pay for this performance level, or even higher.\n\n(Image credit: Mark Pickavance)\n\nPerformance: 4.5 / 5\n\nHP EliteBook X G1a 14 AI: Final verdict\n\nIt’s curious how the order in which I review things can significantly influence my thinking about them, and the EliteBook X G1a falls into that category. Had I not seen the HP Zbook Ultra G1a 14 and its breathtaking performance, then I’d probably be more enthusiastic about the EliteBook X G1a, because it’s spectacular compared to almost everything else.\n\nIts problem is that if you are prepared to spend a lot, and some clearly are, then the HP ZBook Ultra G1a 14 is the machine to have, not this one.\n\nHowever, if you are happy to have something which is powerful and suitable for local AI, then this is exceptional and should deliver the punchy performance you need.\n\nIt’s not cheap, but it’s built for its purpose and priced accordingly.\n\nShould you buy a HP EliteBook X G1a 14 AI?\n\nSwipe to scroll horizontally Value Expensive but lovely engineering 3.5 / 5 Design Common parts to Zbook Ultra, but a solid design 4 / 5 Hardware AI 300 series AI CPU, DDR5 and new 8060s Radeon make it amazingly powerful 4.5 / 5 Performance Better than anything Intel, but AMD has a better CPU/GPU combo 4.5 / 5 Overall Punchy system that isn't cheap but is effective 4 / 5\n\nBuy it if...\n\nYou need AI performance\n\nWhile not on the level of a discrete video card, the TOPS performance of this platform is exceptional, and way above the minimum requirement to run CoPilot locally.\n\nYou want an excellent OLED Display\n\nThe 14-inch 2.8K OLED screen offers superb colour accuracy, deep contrast, and a smooth 120Hz refresh rate. Ideal for presentations, creative work, and video calls, it elevates the visual experience far beyond typical business panels.\n\nDon't buy it if...\n\nYou want the fastest laptop\n\nWhile this is a powerful system, machines using the AMD Ryzen AI 395 Max+ are even quicker. Those who want one of those from HP should consider the Zbook Ultra G1a.\n\nYou need exceptional battery life\n\nWhile this PC lasted nearly 13 hours in my test, it isn't the most power-efficient laptop around. Machines that use the latest Intel Ultra 200 processors or the Qualcomm Snapdragon X series can last longer.\n\nFor more options, we reviewed the best laptops for work and gaming and the best laptops for working from home.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/hp-elitebook-x-g1a-ai-14-business-laptop-review",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Intel Is the “Insurance Policy” For Every US Fabless Chip Firms Like Apple, NVIDIA & AMD Against Supply Risks Around TSMC, Says Renowned Analyst",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/intel-is-the-insurance-policy-for-every-us-fabless-chip/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "The War Over Defense Tech",
      "content": "1.\n\nLast October, on a Martin Luther–inspired website called www.18theses.com, a software executive named Shyam Sankar published a four-thousand-word polemic with the title “The Defense Reformation.” “As a nation, we are in an undeclared state of emergency,” it begins. There follows a litany of provocations: Chinese escalation in the South China Sea, Iranian attacks on US military bases, the October 7 attacks in Israel, “an estimated 1 million casualties in brutal combat in Ukraine.” All this, Sankar writes, amounts to “a hot Cold War II.”\n\nIt is a war, he argues, for which the US is catastrophically underprepared: “In the current environment, American industries can’t produce a minimum line of ships, subs, munitions, aircraft, and more.” The problem lies with American capitalism in its present form, which—as Sankar lamented last year on a military podcast called The Merge—has left legacy defense firms like Lockheed Martin dominated by “fifth-generation MBA cadre[s]” who care more “about cash flow and buybacks and dividends than…about the honest hard work of engineering innovation.” Under these conditions the defense department’s subsidies for private business, he writes in “The Defense Reformation,” have neither “the supposed advantages of a planned economy nor the (far superior) advantages of a free market.”\n\nSankar is the CTO and executive vice-president of Palantir, the start-up cofounded in 2003 by Peter Thiel that specializes in a peculiar hybrid of big-data manipulation and McKinsey-style consulting work. Many of Sankar’s Palantir colleagues and peers at other Thielworld start-ups—notably Anduril, which bills itself as a pioneering disruptor in software-heavy military hardware—have advanced a similar criticism of the neoliberal state, bemoaning its declining interventions in manufacturing and research and lambasting the legacy defense firms, often nicknamed “primes,” for their sclerosis, inefficiency, and alleged monopolistic behavior. The innovative, capitalist spirit and manly vitalism that defined the defense department through the cold war is, for this group, long gone. The task of the hour, as Sankar writes in “The Defense Reformation,” is therefore nothing less than “to resurrect the American Industrial Base.”\n\nYou might think this would mean something like what, under the previous administration, went by the name Bidenomics: initiatives such as the CHIPS Act or the Inflation Reduction Act, which paled in comparison to total federal defense spending—the combined estimated cost of those two bills, which would be spread over a number of years, was about half the annual defense bill—but nonetheless aimed to bring high-tech manufacturing back to US shores. You would be wrong. “The most important and malleable weapons system,” Sankar writes, is not missiles or other military hardware but software, by which he presumably means technologies like large-scale data manipulation, narrow forms of computerized optimization applied to “smart” weapons systems and robotics, sensors, autonomous weapons systems, and artificial intelligence.\n\nInvesting lavishly in such technology and teaching “our warriors…to wield the software industrial base to maximize lethality” will catalyze what Sankar has elsewhere called a “software-driven reindustrialization” akin to previous industrial revolutions based around water, steam, coal, or oil. For a range of figures in the emergent defense-tech sector to which Palantir and Anduril belong, this will require wrenching guaranteed contracts from the bloated primes and promoting competition by having branches of the armed services bid against one another, not to mention allowing even more sales elsewhere. It will also require binding the state closer to a range of tech giants—especially firms like Meta, Amazon, and Microsoft­—that have thus far, on this view, neglected their patriotic duty to engage in defense work and profited from feminized “ad-tech” instead.\n\nThese arguments have found a broad and receptive audience. In recent years a range of politicians have aligned themselves with the priorities of defense-tech firms, especially as successive White Houses worry about a belligerent Russia, a rising China, and the vulnerabilities exposed by Covid-induced supply shocks—all of which have reenergized a longstanding criticism of Reagan-era political-economic shifts that hobbled productive industries. The Obama and Biden administrations both empowered tech companies at the expense of the primes; Biden, skeptical of free trade and hawkish on China, courted Silicon Valley firms that promised to bring back domestic manufacturing and reindustrialize the rust belt and former defense hubs. But in recent years talk about “software-driven reindustrialization” has become especially widespread on a faction of the new right. That the Trump adviser and conspiracy theorist Laura Loomer could rail on X against Lockheed Martin, with its “woke agenda,” for “delivering F-35 fighter jets that are simply not ready for combat”—and that Elon Musk could respond to her that, in any case, “crewed aircraft will be destroyed instantly by cheap drone swarms”—owes much to the rhetoric of Sankar and his peers.\n\nThis new Silicon Valley defense-tech and finance group—their grievances, ideology, and policy visions—has become central to Trump’s second term. Several defense-tech boosters have assumed powerful positions in the administration, most notably one of Anduril’s former senior directors, Michael Obadal, who was just confirmed as Army under secretary, the second-highest ranking civilian official in the Army. Since January Palantir and Anduril have received many billions in contracts, with more on the way. ICE has contracted Palantir since 2011 for software it uses to enforce sanctions and make arrests, and in April signed a new $30 million contract with the company to, in The New York Times’s words, “build a platform to track migrant movements in real time.” Presumably the deal will help ICE’s director, Todd Lyons, realize a vision he laid out that same month at the Border Security Expo in Phoenix, where he said that he wants his agency to run like Amazon Prime, “but with human beings.”\n\nAdvertisement\n\nThese trends show no signs of stopping. Defense Secretary Pete Hegseth has directed the Department of Defense—now calling itself the Department of War—to increase its spending on software, which, he stresses, is “at the core of every weapon and supporting system we field to remain the strongest, most lethal fighting force in the world.” Trump has signed executive orders designed to ease restrictions on defense exports and speed up and reduce oversight of the DoD’s acquisition process. In September the army announced a new venture-capital-style model for procurement called “Fuze.” Firms like Palantir and their new constellation of Silicon Valley funders stand to benefit handsomely from these developments. “We’re moving to a software-driven, autonomous…battlefield,” the managing director for a prominent private equity firm said at a defense summit earlier this year. “Well, if you want daily software upgrades, you gotta pay software margins.”\n\n*\n\nFew would contest that the political economy of American defense is troubled. Defense monopolies have stifled competition; companies have slowed their investment in production and concentrated instead on payouts to themselves and shareholders; costs and schedules have spun out of control. By now, as the scholar William Hartung has written, the federal government’s ballooning defense budget goes increasingly to “costly, dysfunctional weapons systems that are ill-suited to addressing current challenges.” Yet venture-funded defense-tech firms like Palantir and Anduril have positioned themselves as the solution to these ills without any clear evidence that they can deliver on that promise. The problem, put simply, is that they don’t have expertise in building things. Because they are above all instruments of financialization, designed to bring future values into the present, they tend to be better at generating short-term profits and juicing shareholder value than at creating durable, high-performing software or hardware systems.\n\nAnduril and other companies that offer “autonomous,” AI-enhanced hardware, for instance, have by now attracted criticism from a range of commentators: the evidence indicates that, despite their claims to the contrary, Silicon Valley drones and counterdrones have underperformed in Ukraine, where fighters have tended to prefer cheaper, hardier Chinese and homegrown drones instead. Adopting Palantir’s signature data-organizing software, too, could have significant problems for companies and government agencies in the long term. The software’s code is closed-source and privately hosted by Palantir, which retains the power—subject to the terms of its contracts and to the extent they prove enforceable—to change, update, or terminate it. Using it as the “data backbone” for a vast and complicated system makes it distinctly costly and burdensome to switch software in the future, not to mention to train and retrain its users.\n\nMeanwhile, as several critics have argued, the user loses a significant measure of control over the system itself. “The single fundamental problem with the Palantir contract is that the government is outsourcing all of the work to one company in one go,” a data expert told the New Statesman earlier this year, “and what you get is vendor lock-in. The state doesn’t understand the work, they can’t see the work…. You develop no knowledge, no understanding of it.” On the podcast Second Breakfast, the lawyer and former Army officer Eric Robinson related that, when he used Palantir’s software in the 2010s, “they would recode your data ingest so you couldn’t export it again,” with the result that “you had to pay for their tech to effectively be part of your order of battle…. It often seems like a form of long-term rent seeking.”\n\nIn the telling of companies like Palantir and Anduril, their innovation, efficiency, and software expertise qualify them to jump-start a new era of American industrial policy. But not only do they seem ill-suited for such a task, they have publicly backed the Trump administration as it destroys the foundations of what industrial policy the country has. Alex Karp, the CEO of Palantir, has, for instance, denounced “wokeness” for “corrupting and corroding our institutions,” echoing the rhetoric that Trump and other Republicans have used to attack measures like the CHIPS Act for including some redistributive initiatives and giving workers benefits like child care. We are now in a situation, in other words, where an array of right-wing firms and think tanks perversely extol the virtues of industrial policy and American renewal even as they support politicians and financial institutions that are currently dismantling the infrastructure to actually do industrial policy.\n\nAdvertisement\n\nHow did we get here? The answer lies, in part, in the fact that defense-related industries like the semiconductor sector have themselves long obscured their real relationship to industrial policy. It is a central tragedy of the long US century that military Keynesianism—the use of military spending to spur economic growth and enable spending on welfare and other public goods—has been the organizing principle for the country’s economy and social life since World War II. The defense budget—last year’s allocation was close to $900 billion—goes not just to weapons construction but also to a welfare state within a state: housing, health care, and social services. It funds a great deal of civilian industry, from wooden pallets to satellites and smartphones, not to mention research fundamental to the US economy and some degree of economic redistribution. Because of its sheer scale and reach, defense spending is unique in its ability to facilitate regional coalitions across party lines by directing funding to specific geographical targets: state-specific projects, bases, consortia, and so on.\n\nNational Archives and Records Administration/Wikimedia Commons An armorer’s assistant installing a machine gun in a Lockheed P-38 plane at an aircraft plant in the Western US, circa November 1942\n\nBy forcing policymakers to appeal to “national security” (which since the 1980s has expanded to encompass “economic security”)1 to justify any efforts at industrial policy or social welfare, this system has long hobbled our ability to build a better world. But during the 1970s and 1980s, when a newly organized right wing took aim at state spending and capacity across the board, even the essential national-security fields of electronics and defense found their access to long-term government support under threat. To retain it, they arrived at a kind of truce. In public, these firms would happily chalk their success up to their own entrepreneurial genius. Under the radar, however, a range of policymakers and industry leaders worked to patch together a precarious, largely hidden system of government support that allowed the businesses—albeit in compromised form—to keep relying on federal planning, funding, and stewardship.\n\nNow the new Silicon Valley defense firms are taking advantage of this state of affairs to press their own interests. Rather than downplaying their reliance on the government in public while reaping the benefits of industrial policy in practice, though, they have done just the opposite, indulging in rhetoric about the return of the strong state and “reindustrialization” even as they help dismantle the state in the service of financial capital. Understanding the implications of this shift requires grasping the complexities of the relationship that tech and defense firms have long enjoyed with US state power.\n\n2.\n\nIn moments of “revolutionary crisis,” Karl Marx wrote, men “anxiously conjure up the spirits of the past to their service, borrowing from them names, battle slogans, and costumes in order to present this new scene in world history in time-honored disguise and borrowed language.” The defense-tech elite are no exception: they talk obsessively about the past, transmuting political-economic reality into a story of great-men-as-founders. Karp praises the Manhattan Project and welcomes comparisons to Oppenheimer. A Los Angeles Times piece from last year discovered that Palmer Luckey, the much-profiled founder of Anduril, has a preoccupation with purchasing cold war military relics: the red nuclear phone, “a couple of submarines,” at least one ICBM site. He hopes one day, the profile notes, to acquire “the entire US ground-based nuclear deterrent system…to turn it into a vast museum.”\n\nTheir account of twentieth-century military-economic history is distinctly revisionist. In his appearance last year on The Merge, Sankar explained how to fix the defense-industrial base. “The reality is you focus on winning,” he said:\n\nI’m not a founder of Palantir, but I think about going back to that World War II–era period and the immediate cold war, it was founders. We think of it as Northrop Grumman and Martin Marietta, but it was Jack Northrop and Glenn Martin and Howard Hughes and Henry Kaiser, and even inside of government, the Kelly Johnsons, the John Boyds. These are uniquely hardheaded, creative, difficult people that are required to win. And I think every start-up understands that. That’s what a start-up looks like.\n\nThe truth is dramatically different. The two world wars turned industrial power into US military dominance not because they empowered the genius of individuals but because they built a new and formidable state.2 Industrial and state capacity—not to mention the relationship between industry and government—were forever transformed. World War I inaugurated the use of cost-plus contracts, which stipulate that the government pay for all the costs of development and production plus a set profit. World War II offered the US a taste of a centralized planned economy: the war effort consumed 57 percent of the national income, and the government itself converted all the plants it needed to manufacture war material.3 In 1942, for instance, the War Production Board—which centralized control of investment and production—forced the whiskey industry to divert 60 percent of its production to industrial alcohol and modernized productive processes.\n\nIt would not be an exaggeration to attribute the many new industries that emerged, modernized, or accelerated in the postwar years—aeronautics, vastly improved automobiles and motors, chemical and especially petrochemical firms, modern shipbuilding, electronics, atomic energy, logistics—to centralized government planning and funding. With government help, as Hartung notes in his study Prophets of War, the aviation industry’s production increased by 13,500 percent.4 New plants cropped up across the country, especially in the South and West, inaugurating the long-term industrialization of those regions. Cooperative large-scale applied research proliferated through the National Defense Research Committee, which commandeered both industry and academic resources and personnel. In his 1992 study of US industrial policy, the historian Otis Graham noted that the Defense Plant Corporation built “some 30 percent of the plant capacity on which American mobilization depended,” which was crucial to the postwar aircraft industry.5 Business leaders resisted their subjection to government administrators, and as soon as the war was over they sought to erase these years from public memory. But the fact remained that US defense contractors and technology firms owed their existence to extensive, heavy-handed government planning.\n\n*\n\nGovernment support, oversight, and coordination of important industries largely persisted throughout the cold war. In the immediate postwar period military contracts slowed, but the Korean War ensured another boom that lasted until the wind down of the Vietnam War two decades later. The Department of Defense “directed a large portion of the nation’s scientific and engineering resources throughout the postwar era,” Graham wrote, “frequently picking winning technologies and products by supplying the military’s clients—chiefly the weapons, aerospace, telecommunications, and data processing industries—with R&D support and purchasing of output.” The government covered nearly all basic research (which mostly occurs at government labs and universities), and much of the research and development conducted by private industry. Companies had plenty of money to invest and reinvest in production—and the DoD pressured them to do just that.\n\nScience History Institute An employee inspecting the control board for a solvent recovery system at the Hercules Powder Company plant in Hopewell, Virginia, 1940s\n\nAs the scholar Christophe Lécuyer shows in his study Making Silicon Valley, all this investment made the US semiconductor industry possible.6 DoD contracts remade Fairchild, the industry’s pioneering firm, into a major company, and Fairchild in turn brought suppliers and equipment-makers to the Bay Area. The DoD not only funded the development of microelectronics but prioritized incorporating them into military systems; starting in 1963, Lécuyer notes, proposals had to include them for the projects to receive funding.\n\nDefense Secretary Robert McNamara’s initiatives before and especially during the Vietnam War transformed defense spending and the industrial policy associated with it. Much was made by General Westmoreland, starting in the late 1960s, of the promise that war would become an “electronic battlefield,” with armies taking advantage of all “the advanced technology of communications, sensors, fire direction, and the required automatic data processing” to control the fighting from afar.7 That this vision failed to materialize and cost the US dearly—in lives, reputation, and resources—doesn’t seem to have led anyone to rethink its premises.\n\nIn the late 1960s disenchanted defense workers organized to shift industries such as chemicals and electronics away from war and toward the public good, or at least toward private consumption—an effort known as “civilianization.” At the same time, a civilian market for computer chips was exploding. Those initiatives, the planned Vietnam wind down, and détente with the USSR all helped shrink the federal government’s spending on defense in general and military R&D in particular. But it was a brief experiment that came with significant backlash, helping propel Reagan to the presidency and shaping his industrial policy. The federal share of research dollars remained high for much of the cold war, funding the development of lasers, nuclear energy, rockets, aerospace, computers, scientific instruments, data processing, and telecommunications while neglecting automobiles, steel, pharmaceuticals, and textiles—all of which moved offshore to a greater degree than they already had.\n\n3.\n\nThe first major political-economic changes after World War II came with the neoliberal turn of the 1980s and 1990s. During these years several crises descended upon a range of productive sectors that had historically relied on federal industrial policy. Internationally, Japan perfected production techniques in high-tech manufacturing—of cars, machine tools, memory chips, and other electronics—and quickly approached dominance in many areas considered central to “national security,” like semiconductors and supercomputing. American pundits at the time identified this trend as a direct threat to American-style capitalism and US power.8 The period’s neoliberal economic reforms—which reduced and limited the nature of government spending while demonizing the most basic forms of long-term planning—weakened productive industries still further, leaving manufacturers beholden to shareholder demands for ever more profits and vulnerable to new threats from financial institutions.\n\nThese conditions posed a distinct threat to productive sectors like the semiconductor industry. And yet Intel, which by 1992 was leading the industry in cutting-edge chips, managed to thrive nonetheless. When reporters asked how they did it, the company’s executives pointed to what they called “Moore’s Law,” the idea, named after Intel cofounder Gordon Moore, that chips regularly became smaller and more powerful according to something like a natural principle. Moore’s Law became a fixture of the industry’s marketing presentations, press releases, and internal conferences.9 Over the years it helped convince defense leaders like Clinton’s secretary of defense, William Perry, and his protégée Ash Carter that technological solutions could eventually be found for their most pressing and difficult political problems. Moore’s Law remains an unquestioned assumption of scientific, military and national security state discourse and policy, undergirding the entire political-economic imagination of the post–cold war United States. Just as intellectuals started worrying that there might be fundamental limits to capitalist growth, it posited a horizon of infinite progress.\n\nThe truth was more complicated. Intel, founded in 1968 by Moore and Robert Noyce, came to prominence by developing some of the first commercial metal-oxide semiconductor chips. Those semiconductors had immediate, tangible benefits, including low power consumption, high noise immunity, and cost efficiency. Working from that basis, the company did regularly improve its output with a kind of lawlike consistency in this era. But it wasn’t Moore’s Law that won the battle with the Japanese. Instead, Intel and others in the semiconductor industry built coalitions to carve out exceptions to many of the period’s neoliberal reforms, reaping the benefits of extraordinary state support. Among other things, the Reagan administration offered tax incentives to subsidize factory construction and investment in manufacturing, encouraged coordination and cartelization by offering antimonopoly relief and state planning, and used economic sanctions and diplomatic pressure to force concessions from Japan, such as giving foreign—which in effect meant US—chip manufacturers 20 percent of their market share and sharing significant manufacturing knowledge.\n\nIntel Free Press/Wikimedia Commons Andy Grove (left), the longtime head of Intel, sitting with the company’s founders, Robert Noyce and Gordon Moore, 1978\n\nUnder Reagan it was an open secret that the government’s treatment of the semiconductor industry, among others, amounted to a form of industrial policy. These measures had the backing of a powerful—if peculiar—bipartisan coalition that was preoccupied with sustaining American hegemony: national security and foreign policy hawks, factions in the business world, and a group of tech-friendly liberals, like Massachusetts senator Paul Tsongas and Tennessee senator Al Gore, who became known as the “Atari Democrats.” They were reacting to a new right that objected to industrial policy as such, on the grounds that any government planning and economic intervention smacked of communism: in late 1980 the first installment of the Heritage Foundation’s Mandate for Leadership—like its successor, Project 2025—called for destroying large swaths of government by loosening regulations and oversight, centralizing power in the executive, demolishing state capacity, and eliminating or significantly cutting funding for many programs and agencies.\n\nThe new right lacked the political leverage to end industrial policy entirely. But between 1980 and 1993 they succeeded at making it politically toxic, forcing the industry and its allies to adjust their tactics. Bill Clinton, an Atari Democrat, took office hoping to build the US’s own version of Japan’s powerful Ministry of International Trade and Industry; however hostile he was to labor, he implemented significant industrial policy for semiconductors immediately after his election. After Newt Gingrich’s Contract for America coalition swept Congress in 1994, however, the administration’s room for maneuver narrowed. It was still able to ensure some level of subsidies and planning for semiconductor firms like Intel. But it came to rely heavily on foreign policy measures—like sanctions, trade deals, diplomatic pressure, and throwing around US power to shape new international economic organizations like the World Trade Organization—to open new markets and ensure other benefits for tech companies. By the end of Clinton’s second term, a kind of tacit settlement had locked into place. Even as they continued to depend on these various forms of state support, semiconductor companies, tech entrepreneurs who relied on ever-improving semiconductors, and politicians on both sides of the aisle would insist they owed their success to the information-tech revolution, with its promise of infinite growth and cheap consumer goods, all predicated on the work of individual entrepreneurial geniuses.\n\nThis rift between rhetoric and reality has only grown since. Today’s executives hardly seem to understand the conditions of their own industries; it is as if, on some level, they believe the flattering public narrative their predecessors spun. During his interview on The Merge, Sankar remarked that he and his peers are “children…of a Noycean culture.” In a sense this is not untrue. Intel’s Noyce and Sankar both downplay their industry’s debt to industrial policy; Palantir, not unlike Intel before it, is in part in the business of selling what Wired recently called “a seamless, almost magical solution to complex problems.” But Sankar clearly meant the analogy in a different sense: to lay claim to Noyce’s record of success, to brandish his legacy of American entrepreneurial technological genius, and to insist that Silicon Valley firms’ track record of such triumphs should entitle them to remake government in their own image.\n\n*\n\nThe defense industry faced the same pressures that nearly destroyed US semiconductor firms at the dawn of the post–cold war era. In his last year in office Jimmy Carter reversed the cuts that had depressed the industry for much of the 1970s, and in his first term Reagan initiated an enormous military buildup. All this, Graham writes, strengthened the military’s claim on “the nation’s scientific and engineering resources, and thus its influence on industrial structure.”\n\nBut other developments spelled trouble. By the early 1980s financial regulations were being loosened, and corporations were under increasing pressure—legal, managerial, and structural—to secure shareholder profits in the short term at the expense of long-term health. A low-margin productive industry like defense was badly suited to the era. By the mid-1980s firms were focusing on increasing their financial performance by using stock buybacks and cost-reduction strategies like just-in-time inventory management—ordering only enough resources to cover immediate needs. All this compromised their ability to respond flexibly to crises and to make high-quality products.\n\nIn 1985 the Reagan administration started reducing defense spending again and limited other avenues for profit. Facing increased political scrutiny, Reagan officials had recently made a big show of auditing firms for the appearance of wasteful spending, introducing policies that tightened defense profits and increased accounting paperwork. Many companies, like GE, curtailed their defense wings or left the sector entirely to boost their stock values for an increasingly defense-skeptical Wall Street. The 1980s also saw the rise of corporate raiders, later known as private equity firms, which would acquire a majority share of a company’s stock, take control of its operations, and then “restructure” it, which usually meant stripping it for parts and paying themselves astronomical sums of money. Between 1982 and 1990 such outfits nearly destroyed several defense firms, including Martin Marietta and Lockheed, and left them weakened with large debt-to-equity ratios. With loosened financial rules and low margins came consolidation: between 1985 and 1988 ten of the top sixty defense firms acquired or were acquired by others.\n\nPerhaps no person’s career tracks how the defense industry navigated these changes more clearly than that of Norm Augustine. Born in 1935, Augustine got his start in defense at the Douglas Aircraft Company in 1958. His first foray into government came in 1965 as one of McNamara’s young hires, brought in from the private sector to cut waste using “economic efficiency” measures like cost-benefit analysis. He then ping-ponged between the public and private defense sectors: after serving as the under secretary of the Army he joined Martin Marietta, then one of the country’s largest defense firms. Between 1980 and 1982, meanwhile, he chaired the Defense Science Board, authoring reports on threats to the defense industrial base and its dependence on the troubled semiconductor sector. Rising in the ranks of Martin Marietta over the 1980s, Augustine saw that defense was in turmoil; he later referred to the decade as the industry’s “dark ages.”\n\nDenver Post/Getty Images Martin Marietta CEO Thomas G. Pownall (center) and Norman Augustine (right) talking with a shareholder, 1983\n\nThe fall of the USSR and Clinton’s electoral victory brought a new existential threat. Federal defense funding plummeted: between 1989 and 1997 procurement declined by 60 percent. The result was something like the industry’s Great Depression; in 1995 Augustine told a House committee that an estimated three quarters of the sector, about 90,000 firms, had evaporated in the span of a decade. As defense programs became fewer and more expensive, the remaining firms started making riskier bids, overpromising on cost, time, and quality.\n\nIn 1993 Clinton’s defense secretary, Les Aspin, invited the CEOs of major defense firms to the Pentagon for a dinner that would become known as the “last supper.” The then-deputy defense secretary, William Perry, showed them a slideshow of necessary defense capacity: “We expect defense companies to go out of business,” he told them. When we talked in a recent interview, Augustine told me he feared the administration would nationalize at least significant parts of the industry. They were faced with either entering new markets, consolidating, or downsizing. In the five years that followed, Augustine consolidated many firms under Lockheed Martin, itself the product of the merger of Lockeed and Martin Marietta, forming the country’s largest defense firm. In 1995 the new company went public, at which point it started prioritizing stock prices and other contemporary markers of financial health.\n\nIt worked: in 1997 Augustine wrote that the company’s share price had nearly doubled in two years. And yet in the process Lockheed Martin closed a quarter of its plants and laid off 100,000 workers, vastly paring down management and labor in the name of efficiency. The benefits of all this cost-cutting rarely went to the government. Nor were many of the gains reinvested in production. Lockheed Martin had become good at getting contracts; Augustine wrote in the Harvard Business Review about harnessing the “natural competitive instincts in human beings.” But the products themselves suffered: they were more expensive, slower to deliver, and of lower quality.\n\n*\n\nThe state’s priorities were also changing. The Gulf War seemed to vindicate Westmoreland’s Vietnam-era dreams of an “electronic battlefield.” William Perry, soon elevated to defense secretary, became a firm believer that the US was on the cusp of a “revolution in military affairs”—the idea, as the RAND analyst Paul K. Davis has summarized it, that “technological developments sometimes make possible a qualitative change in the nature of warfare.” That conviction moved him to prioritize funding, developing, and promoting “dual-use” technologies that could be applied to both commercial and military settings. He and Clinton built closer relationships with technology firms, offering them greater access to government and policymaking.10 In the late 1990s, as the researcher Barry D. Watts notes in a 2008 report, the Pentagon encouraged defense companies to “act more like commercial firms.”\n\nAugustine was well-positioned to adapt to these conditions. He had advocated for government support for the semiconductor industry during its crisis: asking “why DoD or the government should provide support for the semiconductor industry,” he testified to the Senate in 1987, “would be much like asking at the outset of World War II why we should buy ships and airplanes because it might help the shipbuilding and the aircraft industries.” From his perch on initiatives like the Defense Science Board, he not only observed but shaped how Intel and others had navigated the changing political-economic waters; now he hoped to replicate their accomplishments.\n\nBetween 1993 and 1998, as Hartung has shown, Augustine lobbied intensely—and successfully—for immense government subsidies for defense in general and the new Lockheed Martin in particular. Those subsidies came in many forms, from aid for mergers—“closing plants, relocating equipment, paying severance to laid-off workers, and providing ‘golden parachutes’ to board members and executives,” as Hartung puts it—to antitrust exemptions and subsidies for arms exports (especially to new NATO countries). “To say that Augustine is wired into the Washington policy-making process is an understatement,” Hartung noted in 1996. “For most of his career, he has been one of a handful of people drawing up the blueprints for American defense policies and deciding where the wiring should be placed.”\n\nIn the 1990s companies like Intel experimented with setting up their own venture capital arms, government-backed consortia, and new institutions whose purpose was to plan and shape the markets around them. Augustine followed their lead: he and other defense industry leaders managed to insulate themselves both from democratic accountability and from the vagaries of anti-statist politics by creating experimental public institutions. In 1998 George Tenet’s CIA enlisted Augustine to help found a nonprofit venture capital firm called In-Q-Tel that gives start-ups long-term guidance and directs them to lucrative, stable government contracts. Unlike traditional VCs, In-Q-Tel claims to focus more on technology and less on profits, though over the years it seems to have helped these new companies make money more than it has helped the government acquire important technology. It was In-Q-Tel that assured the success of, among others, Palantir, Anduril, and the drone company Skydio.\n\nAugustine, who turned ninety this July, hardly ever uses words like “industrial policy” or “neoliberalism,” but in practice he and his peers became influential critics of the neoliberal turn. He has argued that, in the financialized economy, “the tax structure discourages long-term investments” and lamented that shareholders hoping for short-range profit want Lockheed Martin not to “invest in research.” Elsewhere, he has called for renewed federal funding for public education and criticized US companies for moving “much of their manufacturing capability abroad.” In an influential 2005 report called Rising Above the Gathering Storm, he and his colleagues argued that “the prosperity the United States enjoys today is due in no small part to investments the nation has made in research and development at universities, corporations, and national laboratories over the last fifty years.” The “pressures” on that sector, they warned, “could seriously erode this past success.”\n\nIn such moments, Augustine sounds uncannily both like architects of Bidenomics such as Jake Sullivan and Jennifer Harris and like right-wing tech-defense figures such as Sankar, who has similarly criticized “the financialization of the defense industrial base.” There is a certain irony here: by founding In-Q-Tel and seeding a bipartisan consensus around what plagued America’s political economy, Augustine—perhaps inadvertently—helped create the coalition now hoping to displace the company he has spent much of his life running.\n\n4.\n\nDefense stocks tanked in 1998 and 1999, and credit agencies downgraded their debt to nearly “uninvestable” levels. As the industry consolidated, firms got even bigger, more complex, and, via joint contracts, increasingly linked to one another. By 2000 they were in a delicate position. With relatively low profits and cash flow but high debt-to-equity ratios, they increasingly focused less on investing in essential R&D than on trying to grow in the short term by competing recklessly for contracts.\n\nLibrary of Congress Prints and Photographs Division A pilot operating the instrument panel of the Lockheed Martin C-130J-30 Hercules cargo plane during a demonstration flight for Pentagon personnel and press over Andrews Air Force Base, Maryland, 1998\n\nThen came the wars in Iraq and Afghanistan, which, as Hartung has shown in Prophets of War, inaugurated an industry-wide bonanza. Companies like Lockheed Martin entered new markets: “enhanced interrogation,” translation, dubiously legal surveillance. The Bush administration was full of defense monopoly affiliates, among them Secretary of the Air Force James Roche, a former vice president at Northrop Grumman; Secretary of the Navy Gordon England, a former executive at General Dynamics; and Edward Aldridge, who was a member of Lockheed Martin’s board of directors while serving on the president’s commission on space.\n\nCongress subsidized Lockheed Martin for arming new Eastern European NATO members; in 2008 US companies accounted for two thirds of the world’s new arms sales. At the same time, the DoD came to focus on counterinsurgency and counterterrorism techniques that relied heavily on information technology, like cyberwar and “network-centric warfare.” Defense Secretary Donald Rumsfeld wanted to make “the leap into the information age” by pursuing drones and surveillance.\n\nNone of this meant that the trend toward military privatization slowed. It continued apace through the Iraq War, from the US military’s contracts with mercenaries like Blackwater to private contracts for hardware. On Second Breakfast, the former Green Beret Justin McIntosh describes how outsourcing military functions to contractors during the Syrian conflict forced him into a situation not unlike The Wages of Fear:\n\nI had a truck that had a bent rod. These trucks that we’re driving around in, these MRAPs and these large RG-33s…[require] a contractor [to] come in and work on it. We were in an area where we had been shot at. I had to medically evacuate some guys. The contractors did not want to travel. They wanted me to drive this truck hundreds of kilometers to the safe base where they could then repair it.\n\nThe problem, McIntosh continued, was that “we had already taken all of that capability that existed within the United States military”—for instance, the ability to repair its own equipment—and “shifted it over to the private sector. It gave them control.”\n\n*\n\nThis tendency toward privatization continued through the Obama administration, during which defense officials started to fixate on reducing costs. (“The gusher has been turned off,” Defense Secretary Robert Gates announced in 2010.) Obama saw bloated defense monopolies as an obstacle to this goal. But rather than addressing the structure of the industry or its political economy, the administration focused on improving its topline numbers by switching out the supposedly corrupt, atrophied defense giants for new firms from the Democrat-friendly tech sector, which promised to replace the functions of the legacy firms more cheaply.\n\nAn influential proponent of this turn was Ash Carter, whom Obama nominated as his defense secretary in 2014. Carter and his deputy, Robert Work, had a “simple but ambitious” agenda, as the anthropologist Roberto González has written: “to harness the best and brightest ideas from the tech industry for Pentagon use.”11 Carter’s emphasis would be not on training soldiers but on developing drones, automation, satellites, and other cutting-edge defense technologies sourced from Silicon Valley.\n\nCarter’s focus on unmanned tech was not exactly a break from the Bush era, but the shift to the Valley was. Fueled by experiments like In-Q-Tel, the tech-defense coalition was already looking to gain market share: in 2014, nearly a year before Carter took office, SpaceX sued the Air Force for preferring the primes; in 2016 Palantir filed a lawsuit against the Army for allegedly trying to develop internal intelligence software without adequately considering commercial options. (One of Anduril’s founders, Trae Stephens, has claimed that these lawsuits helped Anduril win defense department contracts.)12 Obama and then Trump both also expanded the department’s ability to use its “other transaction authority,” which allows the government to do business more easily with commercial entities, for example by letting it sign contracts faster and with less oversight.\n\nThe defense start-ups that successfully attracted Silicon Valley financing relied on the extraordinary wealth and political lobbying connections of their founders. “Every defense company that had been founded by a billionaire was a success,” as Luckey—who sold his VR company, Oculus, to Facebook in 2014 for $2 billion—noted in 2024. “I hate that we live in a country where that’s the case,” he added. “But I realized that I had a unique responsibility as one of the very few people who was willing to work on national security and blessed with the resources to actually make a real go at it.”\n\nObama officials proved receptive to such lobbying. During his tenure Carter set up an In-Q-Tel-inspired program called Defense Innovation Unit—Experimental (DIUx), which worked closely with a new Defense Innovation Board, chaired by the former Google CEO Eric Schmidt, to determine the government’s investments in emerging technology, from drones to AI. It encouraged Silicon Valley firms and funders with the promise of long-term contracts for defense tech, as well as evaluation and testing—in effect ensuring their success in advance. Carter also laid the foundations for projects that came to fruition under the first Trump administration: between 2017 and 2019 the Army, the Air Force, and the Navy all launched their own experimental institutions designed to set up tech start-ups with military contracts.\n\nPrivate equity and venture capital saw an opportunity to make nearly guaranteed profits off the government’s investments. Between 2021 and 2024, VCs poured $130 billion into defense. In their book Unit X (2024), two of DIUx’s early directors, Raj M. Shah and Christopher Kirchhoff, claim that by 2017 their work had excited “investors and entrepreneurs in Silicon Valley” about working with the Pentagon by lowering “barriers to entry.” (They decline to specify which ones.) When James Mattis visited DIUx under the first Trump administration, in 2017, Shah and Kirchhoff arranged for him to have dinner with the tech investor Sam Altman (then at Y-Combinator) and the venture capitalist Marc Andreessen, who insisted that the Valley was interested in the defense industry and implored him to support the project. Mattis was enticed by the work they were doing on drones—a later fixation of Andreessen’s.\n\nEmployees at Google expressed discontent with the company’s defense contracts, organizing to block initiatives like Project Maven, a machine learning program for the Pentagon. The project was hardly promising: as Alexander Cockburn wrote last year in Harper’s, an Air Force testing unit found in 2011 that, “among numerous other deficiencies,” the drone-mounted cameras on which it relied “could not ‘readily find and identify targets,’ and its transmission rate was too slow.” But DoD funders were eager to collaborate with Silicon Valley all the same. (According to Cockburn, Amazon, Microsoft, and Palantir were among the subcontractors who joined the Maven project after Google declined to renew the contract in 2018.) Since then employers have used the threat of AI to shrink the pool of tech jobs, costing the workers leverage. By 2022 employee dissent had been largely squashed: Google and other major defense firms all but declared that they were happy to work with the military. Now executives at tech and tech-defense firms brag about joining the army reserves to help with the design and purchase of their products—an arrangement that seems rife with potential conflicts of interest.\n\nThe Biden administration continued many of these Obama-Trump trends. Defense Secretary Lloyd Austin appointed Apple’s Doug Beck to direct DIU—as it was by now simply called—and empowered him to report directly to Austin. Congress gave the program nearly $1 billion for the 2024 financial year, and Biden awarded important hardware contracts to Palantir and Anduril. SpaceX doubled its federal contracts at the beginning of the Biden administration; they had practically doubled again by the end. In late 2022 Austin established the Office of Strategic Capital (OSC) to push investment in defense-oriented small businesses and tech start-ups; under the One Big Beautiful Bill Act, it will have $200 billion to spend, and likely more in the 2026 National Defense Authorization Act. Perhaps most visibly, Deputy Defense Secretary Kathleen Hicks enthusiastically embraced all things tech: at a 2024 event organized by Andreessen’s VC firm, she emphasized that “moving fast and breaking things is necessary to win wars.”\n\nNonetheless DIU’s leaders and their Silicon Valley allies felt that the Biden Department of Defense wasn’t friendly enough. By 2023, Shah and Kirchhoff complain, it still awarded most of its contracts to the primes. “It seemed as if the whole Biden team had forgotten about DIU and Silicon Valley,” they write, “even as Ukraine was aggressively deploying DIU technologies on the battlefield.” Their vision for the department is blunt: “All the Pentagon needs to do is be a great customer. Buy products, and trust that good venture capitalists will pour money into the companies building those products.”\n\n*\n\nAll this support for the tech-defense sector has so far had disappointing results. A congressionally mandated report produced this year by the Government Accountability Office suggests that there were no metrics by which DIU could measure its success at actually bringing new technology into the military. The Biden defense department’s embrace of tech yielded such fruits as the “Replicator Initiative,” which committed in August 2023 to delivering “multiple thousands” of new autonomous systems in eighteen to twenty-four months. Hartung told me that many industry experts found that timeline hard to believe: no program had ever delivered products that fast. The deadline the initiative set has now passed, and his skepticism seems warranted. The initial delivery was said to be in the hundreds, and The Wall Street Journal recently reported that some of the program’s systems “have been unreliable, or were so expensive or slow to be manufactured they couldn’t be bought in the quantity needed.”\n\n\n\nFor many observers, the first real test of Silicon Valley defense tech is how US-made drone technology fares in Ukraine, a war often cited as a laboratory for unmanned warfare. In a speech this past August, published in the Free Press, Luckey described going to the front lines “just a few weeks” after the full-scale Russian invasion “to train Ukrainian soldiers on advanced military technology that I had developed.” He witnessed “remarkable” feats, he said: “with drones costing just a few thousand dollars each, a handful of Ukrainian pilots remotely carpeted airstrips with explosives thousands of miles into Russia.” (He seems to have been playing fast and loose with chronology: Ukrainian drones reached hundreds of miles into Russian territory that December; it would take them still longer to reach thousands.)\n\nDrone technology has indeed been crucial to the conflict, especially more recently, as troops have been harder to come by on both sides. But a range of commentators have cautioned against assuming it therefore represents “the future of war.” Prominent defense think tanks like RUSI have warned that “overreliance on uncrewed aerial systems” has created “significant problems” for Ukraine, in part because it “plays into Russia’s strengths” at short-range air defense and other antidrone capabilities. William LaPlante, Biden’s under secretary of defense for acquisition and sustainment, has echoed this view. “Don’t tell me it’s got AI and quantum in it. I don’t care,” he said at a 2022 conference. “The tech bros aren’t helping us too much in Ukraine…. It’s hardcore production of really serious weaponry. That’s what matters.” (Many drone companies, moreover, still rely on Chinese parts.) The subtext behind the flurry of puff pieces treating drone war as an inevitability is that a trough of money in the small-to-midsize drone market is up for grabs, over which various coalitions are starting to compete.\n\nSean Gallup/Getty Images A soldier in a US Army platoon specializing in unmanned aircraft systems watches an Anduril Ghost-X drone landing during an exercise at the Hohenfels Training Area, Bavaria, February 3, 2025\n\nTo the extent that drones have proven essential in Ukraine, for that matter, hardware made in the US—by firms like Microsoft, Skydio, AeroVironment, and Cyberlux—has fallen short of expectations. Ukrainians have found US-produced drones “fragile and unable to overcome Russian jamming and GPS blackout technology,” The Wall Street Journal reported last year. “At times, they couldn’t take off, complete missions or return home.” Skydio recently announced that one of its controllers was vulnerable to radio interference. The trend of connecting more devices together to create an “Internet of things” often creates new vulnerabilities in turn.\n\nAnduril’s output is no exception. The defense blogger who writes under the name Secretary of Defense Rock observed in one widely shared piece that the company’s products “often amount to little more than rebranding existing technologies with a Silicon Valley gloss.” One of their much-touted anti-drone interceptors, the essay suggests, has “the same core function” as a familiar Raytheon product, “with marginal enhancements, repackaged in a sleeker design and infused with branding language that flatters venture capital expectations more than it reflects operational novelty.” Anduril continues to contend both with high costs and with certain problems in the field: “During an exercise last year in the Pacific called Project Kahuna,” according to the Journal, “drones from different manufacturers connected by Anduril’s software struggled at times to coordinate and perform tasks when out of sight from the operator.” Last month, Reuters has reported, the Army’s chief technology officer circulated a memo identifying a “very high risk” factor in Anduril’s prototype for a “next generation command and control” battlefield communications network: “We cannot control who sees what, we cannot see what users are doing, and we cannot verify that the software itself is secure.”\n\nNone of this should be surprising. Anduril is making moves to scale up production, claiming that it plans to open a “hyperscale manufacturing facility” in Ohio next year—but VC–funded firms don’t usually have the incentives or structure to prioritize taking on high-risk hardware projects. Often such companies focus instead on acquiring other firms in areas they’d like to enter, whose “founders” and engineers tend to quickly depart. They often make cuts for “efficiency” that produce an attractive financial picture in the short term, but damage the company in the long run. “The primary product of the defense VC strategy,” the scholar Elke Schwarz has written in a recent article, “is not a defense technology as such, but financial returns achieved through growth.”\n\nWorse still, she notes, venture capital’s “mandate for hypergrowth” means that VC-funded companies feel even more pressure than regular ones to produce exponential profits; when those companies make defense products, investors stand to reap enormous windfalls if armed conflict escalates around the world. “To get the military-industrial sector to grow fast,” Schwarz writes, “perhaps the best catalyst is war, or at least the embrace of its possibility.” Indeed, in 2023 a representative of America’s Frontier Fund, a VC firm backed by Thiel and Schmidt, told investors that if “the China/Taiwan situation happens,” or more generally “if there is a kinetic event in the Pacific,” then the fund’s investments would go up ten times “overnight.”\n\n5.\n\nResisting the defense-tech sector’s great man theory of history has grown all the more urgent now, as the Trump administration seems intent on placing those “great men” at the helm of the national security state and entrusting them with reindustrializing the sectors attached to it. Michael Obadal, the former Anduril senior director who is now Army under secretary, is part of a large cohort of Silicon Valley–adjacent figures in the administration: Dan Driscoll, a onetime J.D. Vance adviser with a background in private equity and venture capital, was confirmed as Army secretary13; Steve Feinberg, founder of the notorious private equity firm Cerberus Capital Management, which in recent years has invested heavily in defense tech, is in as deputy secretary at the Department of Defense, where he is using his experience to “restructure” the Pentagon; the retired general and venture capitalist Dan Kaine is now chairman of the Joint Chiefs of Staff; the Office of Science and Technology Policy is now headed by Peter Thiel’s former chief of staff; and the assistant secretary of defense for critical technologies is now Michael Dodd, also known as “the Doddfather,” an alumnus of DIU.\n\nAt least until the administration’s recent announcement that it is seeking an equity stake in Lockheed Martin, the primes appeared mostly sanguine about their aspiring competitors. Congress—which tech-defense firms spend millions lobbying14—writes the yearly defense budget, and primes have historically wielded considerable power there; they still receive the bulk of defense spending. Among the legacy firms the prevailing consensus has been that the upstarts will not be able to replace them: their products, after all, are already battle tested.\n\nEven so, the defense-tech contracts are pouring in. The Golden Dome missile defense program—a $175 billion-plus redux of Israel’s Iron Dome and Reagan’s Star Wars missile defense program, which experts call just as unfeasible as it was in the Eighties—seems to be shaping up as a cash giveaway to the tech-defense right; a joint bid from SpaceX, Anduril, and Palantir is reportedly the front-runner for the contract. (Hegseth has ordered major cuts at the Pentagon testing and evaluation office that a congressional panel recently tasked with assessing the program.) Other start-ups hope to privatize hardware testing, and Palantir seems to be positioning itself to assume some of the same functions of the embattled National Oceanic and Atmospheric Administration. New Pentagon rules that facilitate “anything-as-a-service” contracting allow private companies to shut off or modify their products as they desire (within contractual constraints, assuming these are followed), making US arms exports considerably less appealing to other countries but allowing the companies veto power over the use of their services or weapons—and further opportunities for rent-seeking. This past May, Luckey announced that Anduril would, as 60 Minutes put it, surpass “$6 billion in government contracts worldwide” by the end of the year. “We buy a lot of things from Palantir,” Trump said at a recent White House AI summit, calling out Sankar by name.\n\nScott Legato for Palantir Technologies/Getty Images Palantir CTO Shyam Sankar giving a keynote speech at the Inaugural Reindustrialize Conference in front of a projection of Intel cofounder Robert Noyce, Detroit, Michigan, June 26, 2024\n\nDefense-tech executives clearly hope to take advantage of the post-Covid surge of interest in industrial policy. There has been a great deal of chatter in right-wing circles, from Oren Cass’s American Compass to the Heritage Foundation, about the prospect that the US could move from a supposedly feminized service-based economy to a masculine-coded, producerist one organized around defense manufacturing. (In April, Fox News ran the chyron “TRUMP’S MANLY TARIFFS: PUNDIT BELIEVES IT COULD REVERSE CRISIS IN MASCULINITY.”) Even institutions like the American Enterprise Institute, which have historically reviled industrial policy in any form, have jumped on board, publishing papers endorsing industrial policies of different kinds tied to “national security.”\n\nPalantir’s leaders have echoed this rhetoric for their own purposes: Sankar lamented on The Merge that the best minds have gone into fields like ad-tech rather than defense engineering; Karp has declared that US industry has degenerated in the past fifty years to focus on “the consumer market” rather than using technology to “address challenges of industrial and national significance.” Trump himself seems to alternately contradict and endorse this agenda. He has been especially critical of CHIPS, accusing it of offering companies money they didn’t need and requiring them to hire “woke people” that hampered their success; at a recent AI summit he encouraged “all American companies to join us in rejecting poisonous Marxism in our technology.” It is as if he thinks that chip manufacturing can be brought back to the US through permitting reform and tariffs alone. Appalling immigration raids like the recent one on a Hyundai factory in Georgia have conflicted with the administration’s aim to learn from foreign expertise, producing extreme international backlash.\n\nMost recently, under Feinberg’s aegis at the DoD, the administration has pioneered an entirely new form of statecraft: running the Pentagon like a private equity firm. In the past two months the government has made a slew of one-off deals with companies like NVIDIA, AMD, Intel, and a rare earth mineral company called MP Materials. At the center of some of these agreements is a novel reading of the Defense Production Act, which the Senate Armed Services Committee is trying to formalize via a new provision allowing the government to make equity purchases in private firms. The provision has yet to pass—which has not stopped the administration from going ahead anyway.\n\nThe MP Materials agreement is instructive. Feinberg, no stranger to investing in the defense world, reportedly negotiated the deal, which includes a provision to buy magnets from the company despite the fact that they only started manufacturing magnets last year. By offering a price floor and production guarantees, the Department of Defense made it possible for Goldman Sachs and JP Morgan to finance the issuance of equity in the firm—at which point, seemingly for the first time in US history, the DoD itself bought enough equity to become the company’s largest single shareholder and provided a $150 million loan for the company’s California mine.15\n\nEach of these deals works a bit differently. CHIPS had promised Intel $11 billion on the condition that it met certain milestones, including building an arguably unnecessary Ohio megafactory; when the firm appeared unlikely to meet those conditions, the Trump administration exchanged the remaining money for roughly 10 percent equity in the company. With AMD and NVIDIA, the mechanism looked more like a straightforward shakedown: Trump announced that if NVIDIA wants to continue selling AI chips to China, it has to fork over 15 percent of the profits.\n\nThese moves hardly amount to a real industrial strategy. One-off coercive deals with individual companies already seem unlikely to reindustrialize the country, and it remains unclear what the administration will do with its new assets. But that outcome seems even less plausible as the Trump administration takes a sledgehammer to the government’s capacity, oversight, and industrial policy. In a mere nine months the administration has destroyed the infrastructure of research and development on which the semiconductor industry and many others rely; done its best to “get rid of” the “horrible, horrible” CHIPS Act, including the new research infrastructure it created; threatened to arbitrarily revoke awards and enacted swiftly changing tariffs that damage industries; behaved so erratically toward the US’s longtime allies that the EU and others have started looking elsewhere to buy weapons; erased the nonpartisan image on which the military depends for its continued funding and ability to operate; decimated the Pentagon’s civilian staff; devastated green industries while simultaneously promising to drive the price of oil so far down that the industry believes it will cause significant bankruptcies; and curtailed the Department of Defense’s product testing, among much else. None of the defense-tech firms that praise industrial policy in theory have launched any serious public protest against these decisions. The more contracts they get, meanwhile, the more government resources they will siphon away from investing in fields—like climate technologies, welfare, or alternatives to plastics—that would benefit the US’s economy or security.\n\nBigger tech companies such as Meta, Amazon, and Google have, for their part, also moved much closer to the Trump administration. They seem indifferent about the destruction of the infrastructures of research and support upon which they previously relied, perhaps because they believe they can hire researchers on a mercenary basis, outsource research and development to AI, or replace government functions with private ones—a doubtful prospect, since the government’s function as a neutral evaluator and standard-setter seems impossible to replace.16\n\nThe practical problem with this vision, to say nothing of its moral and ethical failings, is that it can only deal with the short term. “We love disruption,” Karp said during the company’s quarterly earnings call in February. “Disruption, at the end of the day, exposes things that aren’t working. There will be ups and downs. There’s a revolution. Some people are going to get their heads cut off. We’re expecting to see really unexpected things and to win.” Tech companies and venture-capital firms have become experts at leveraging this sort of “disruption” to generate value for their shareholders on the basis of imagined future profits, and firms like Palantir and Anduril are no exception. But now they have become so voracious, so all-consuming, that they are putting the country’s productive industries at risk. In the process, they threaten to destroy not just the source of their own profits but the spending and investment that lie at the foundation of the US economy. We may all end up with our heads cut off.",
      "source": "The New York Review of Books",
      "url": "http://www.nybooks.com/online/2025/10/04/the-war-over-defense-tech/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Is AMD fabbing at Intel Foundry?",
      "content": "A few days ago, a financial note went around saying AMD is going to fab chips at Intel Foundry. What has SemiAccurate heard about this deal and what does it mean?\n\nLets do this in the format of a Q and A session to save time.\n\nQ: Is AMD fabbing at Intel?\n\nA: TLDR is no.\n\nQ: Longer answer?\n\nA:…\n\nThis story appeared on semiaccurate.com , 2025-10-05 13:13:32.351000.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/c7b25b122ee7fc5e",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Lenovo LOQ: 15.6\" FHD IPS 144Hz, Ryzen 7 250, RTX 5060, 16GB DDR5, 512GB SSD $799.99 (2 replies)",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18662707-lenovo-loq-15-6-fhd-ips-144hz-ryzen-7-250-rtx-5060-16gb-ddr5-512gb-ssd-799-99",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Weekly Market Wrap: Intel, Nvidia and Electronic Arts made major news",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/markets/weekly-market-wrap-intel-nvidia-and-electronic-arts-made-the-most-news",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Upgrade (25H2)",
      "content": "You can upgrade a PC running Windows 10 or an earlier version of Windows 11 to Windows 11 version 25H2. If this PC is supported, meaning that it meets the Windows 11 hardware requirements and isn’t connected to any incompatible peripherals, the upgrade process is seamless and can even be quick. But you can manually update any Windows 10 or 11 PC to Windows 11 version 25H2 if you don’t receive it automatically through Windows Update.\n\n🖥️ Understand the Windows 11 minimum hardware requirements\n\nWhen Windows 11 debuted in 2021, some of its minimum hardware requirements were seen as arbitrary, but few were particularly onerous. Today, these requirements are even less problematic, but my recommendations for the minimum processor, RAM, and storage are much higher and more realistic than what Microsoft requires.\n\nMicrosoft requires that a PC include the following hardware components before it you can install or upgrade it to Windows 11.\n\nMicroprocessor. A reasonably modern 64-bit microprocessor or system on a chip (SoC) with a clock speed of 1 GHz. 🔗 The specific processors vary by silicon manufacturer, but generally speaking, processors released in late 2017 or more recently are compatible.\n\n✅ Tip: I recommend the newest microprocessor you can afford. Unless you’re a gamer, Qualcomm Snapdragon X-series Arm processors are the best choice. But if you have to use a traditional x86-style PC for compatibility reasons, modern AMD chips are more reliable than those made by Intel.\n\nRAM. 4 GB or more.\n\n✅ Tip: 16 GB is the bare minimum for a good experience with Windows 11. If you can afford it, 32 GB is even better.\n\nStorage. 64 GB of hard disk (HDD), eMMC, or SSD storage.\n\n✅ Tip: 512 GB of SSD storage is a more realistic minimum. 1 TB or more is even better.\n\nFirmware. Unified Extensible Firmware Interface (UEFI) with Secure Boot enabled.\n\nSecurity platform. Trusted Platform Module (TPM) version 2.0.\n\n✅ Tip: TPM 2.0 debuted in 2014, and all modern PCs include this security chipset or a superset like Microsoft Pluton.\n\nDisplay. A 9-inch display or bigger with a high-definition (HD, 720p) or higher resolution with 8-bits of color or more (256 colors).\n\n✅ Tip: A display with a Full HD (1920 x 1080, 1080p) or Full HD+ (1920 x 1200) is a more realistic minimum, depending on the size of the screen.\n\n🖱️ Find out if your PC meets the minimum requirements\n\nIf you’re not sure whether your current PC meets the Windows 11 minimum hardware requirements, you can download and run 🔗 Microsoft’s PC Health Check app to find out. If you’re using a reasonably modern PC, you should discover that it meets the minimum requirements. If it does, you can move ahead with the upgrade.\n\n🖲️ What to do if your PC doesn’t meet the minimum requirements\n\nIf your PC doesn’t meet the minimum hardware requirements, Microsoft will block the upgrade. So you have a decision to make based on the reason it failed. In some cases, like Secure Boot and TPM 2.0, it may be a simple matter of enabling a feature that’s not currently enabled.\n\n✅ Tip: You enable Secure Boot and TPM 2.0 in your PC’s firmware. Instructions for accessing this interface vary by PC, so check with your PC’s or motherboard’s user guide for details.\n\nI don’t recommend upgrading a PC to Windows 11 if it doesn’t meet the minimum hardware requirements. They are minimums, after all, and if your PC doesn’t meet them, the experience won’t be good. Worse, Microsoft threatens users with the following if they bypass its block and upgrade anyway:\n\nThe PC will be unsupported.\n\nMicrosoft might stop delivering security updates. Note that it’s never done this, and I can’t imagine it ever would.\n\nThe PC might be less secure. If you decline to enable Secure Boot or TPM 2.0 on your PC, it will be less secure.\n\nMicrosoft might display an annoying watermark on the Desktop. Note that it has never done this to customers using a current, non-preview version of Windows 11.\n\nIf you still want to upgrade to Windows 11 and understand the downsides to doing so, you can. This is described in the next section.\n\n🔼 Upgrade to Windows 11 version 25H2\n\nIf your PC is running a supported version of Windows 10 or 11 and there are no upgrade blockers in place for your PC configuration, you will be offered the Windows 11 version 25H2 upgrade in Windows Update. This is the simplest and best way to upgrade. The PC will need to reboot and it could take up to 20 minutes to complete the offline upgrade process.\n\n✅ Tip: If you are currently using Windows 11 version 24H2, the upgrade is delivered as an 🔗 enablement package (eKB) because the two versions share the same code base. This upgrade still requires a reboot, but it happens much more quickly.\n\nIf you’re not offered the upgrade to Windows 11 version 25H2 in Windows Update, you will need to upgrade manually. To get started, 🔗 download the Windows 11 installation disc image (ISO) file from Microsoft. Then, mount the ISO as a virtual disk in your PC’s file system by double-clicking it after it fully downloads. In the File Explorer window that opens, run Setup.exe to start Windows Setup.\n\nIf you see a dialog like the following, you will have to follow the steps in the next section.\n\nOtherwise, you can jump ahead to the section Complete Windows Setup.\n\n⛔ Bypass an upgrade blocker\n\nTo work around a compatibility blocker that prevents the upgrade, close Windows Setup by clicking the “Cancel” button. Then, open a Terminal window and then type the following command, replacing the D:, if necessary, with the correct drive letter for the virtual installation disk:\n\nD:\\setup.exe /product server\n\nAfter tapping Enter, click “Yes” in the User Account Control (UAC) dialog that appears. Windows Setup will run normally, though it will say you’re installing Windows Server, not Windows 11. Don’t worry, you’re just upgrading to Windows 11.\n\nNow, you can continue normally as described below.\n\n✔️ Complete Windows Setup\n\nWindows Setup guides you through several straightforward screens. It will check for updates (though you can optionally disable that by clicking the “Change how Setup downloads updates” link in the first step) and make sure your PC meets the Windows 11 minimum hardware requirements before finally landing on the “Ready to install” stage. This one requires some thought.\n\nUnless you choose otherwise, Windows Setup will perform a traditional, non-destructive in-place upgrade in which Windows 11 is updated to version 25H2, but everything else on the PC—including your user accounts, documents and other files, any customizations you’ve made, and installed apps—is retained. That may be what you want, but you can click “Change what to keep” to see other options.\n\nThese options are:\n\nKeep personal files and apps. This is the default option, a traditional, non-destructive in-place upgrade.\n\nThis is the default option, a traditional, non-destructive in-place upgrade. Keep personal files only. This is a non-traditional and partially destructive upgrade in which your user accounts and their associated documents and other files are retained but customizations and installed app are not.\n\nThis is a non-traditional and partially destructive upgrade in which your user accounts and their associated documents and other files are retained but customizations and installed app are not. Nothing. This most destructive of options is a clean install in which Windows is updated to version 25H2 but your user accounts, documents and other files, customizations, and installed apps are all removed.\n\n➡️ Learn more: Here, I assume you are choosing one of the first two options, though the process you experience is the same until Windows Setup is complete. You can learn about performing a clean install of Windows 11 in the Install chapter.\n\nAfter choosing what to keep, Windows Setup will continue without requiring any intervention. Though it switches to a blue full-screen experience, you can still do other work on the PC, at least until it reboots.\n\nEventually, Setup will reboot the PC and enter an offline phase in which it completes the upgrade. This process can take up to 30 minutes to complete, depending on your PC.\n\nWhen Setup completes, the PC reboots again and you can sign-in normally when the Lock screen appears.",
      "source": "Thurrott.com",
      "url": "https://www.thurrott.com/books/windows-11-field-guide/upgrade-to-windows-11/327928/upgrade-25h2",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Stock market today: Dow, S&P 500, Nasdaq futures rise as shutdown drags on, AMD-OpenAI deal boosts hopes",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_8ed595e2-820b-43a9-8617-4e13545d854d",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Xbox Might Be Going Full Third Party and Leaving Hardware for Good – Rumor",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/xbox-might-go-full-third-party-leaving-hardware-for-good-rumor/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "AMD Unveils Fast Motion Response To Enhance Frame Gen For PC Gamers",
      "content": "(click to enlarge)\n\nArmored Core VI is kind of a blurry game in the best case. (click to enlarge)\n\nAMD has fully AI-powered frame generation on the way with its FSR Redstone project , but that's not here yet. In the interim, the company has something interesting: the option to customize \"Fast Motion Response\" within its \"Fluid Motion Frames\" technology. In essence, the idea is this: frame generation can cause image artifacting when the camera is moving rapidly, so let's just disable it at those times. This is similar thinking to AMD's Radeon Boost and Radeon Chill technologies, which increase resolution or frame rate (from a low baseline) when the user is moving around in a game.To enable the option right now, you'll have to install the latest AMD driver, which could be a problem because it's likely that your GPU is not supported. That's because the latest AMD driver is actually the AMD Software: PyTorch on Windows Preview Edition, and this driver only supports a very small subset of Radeon GPUs. We expect that this feature will land in the standard Radeon drivers very soon, but if you want to try it right now, you've got to have a Radeon RX 9000 GPU a Radeon PRO W7900 , a Radeon PRO R9700 , or a Ryzen AI 9/Max processor.If you have one of those GPUs, simply install the new driver and you're good to go. Head to the Graphics settings in the AMD Adrenalin software and enable AMD's Fluid Motion Frames, known as AFMF. You'll then see the standard two options to set Search mode and Performance mode, and below that, a third option to configure Fast Motion Response, like so:The description of the feature is straightforward enough; essentially you can pick whether you want AFMF to attempt to blend frames even during rapid camera motion, or you can decide if you want AFMF to turn off entirely during rapid camera motion, returning you to the native frame rate. We tested the feature in Armored Core VI: Fires of Rubicon and found that it did indeed work exactly as advertised—but that the difference in the two settings is fairly small.Armored Core VI is a game that makes heavy use of screen blurring effects as well as motion blur, and in that title, the difference between AFMF on and off is only noticeable through the change in visual fluidity, which is both significant and obvious. It's kind of a \"best case\" for the technology, because you typically play with a gamepad , so any additional input lag is harder to notice, and the aforementioned reliance on screen blur effects masks any potential artifacting from the frame generation technology.As such, while we definitely noticed the drop in visual fluidity with Fast Motion Response set to \"Repeat Frame,\" we weren't able to pick out any particular artifacting from the \"Blend Frame\" mode. It looks great.If you are the type that hates screen blur, and habitually disables motion blur and temporal anti-aliasing in every game, you may be much more sensitive to visual artifacts from rapid motion under frame generation, and as a result, you may prefer the \"Repeat Frame\" option, which reduces visual fluidity but also has the potential to reduce graphics artifacts . Likewise if you are playing a game with a sharper visual presentation and prize clarity over fluidity—although in those kinds of games, you're probably going to want to avoid frame generation altogether.In the end, while we don't prefer the Repeat Frame option, we do think it's really cool that AMD gives users control over this function. AMD's graphics software stack gets a bad rap from gamers, primarily because FSR 1-3 upscaling was mostly inferior to DLSS, but we've been impressed with AFMF in particular in our time with it, primarily on handhelds and mobile devices like the ROG Ally X and the ROG Flow z13. It takes Armored Core VI from a somewhat unsmooth 45 FPS experience in the native 2560×1600 resolution of the ROG Flow z13 to a very nicely Freesync'd ≈90 FPS that looks phenomenal, both smooth and sharp, on that machine.If you haven't tried out this function, give it a shot in your favorite game and tell us what you think.",
      "source": "Hot Hardware",
      "url": "https://hothardware.com/news/amd-fast-motion-response",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Intel Core Ultra 5 245KF - Core Ultra 5 (Series 2) Arrow Lake 14-Core (6P+8E) Desktop Processor + Cooler Master Hyper 212 Spectrum V3 Air Cooler - $169.99 + Free Shipping",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18663130-intel-core-ultra-5-245kf-core-ultra-5-series-2-arrow-lake-14-core-6p-8e-desktop-processor-cooler-master-hyper-212-spectrum-v3-air-cooler-169-99-free-shipping",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Show HN: Nomad task driver for Cloud Hypervisor",
      "content": "Nomad Cloud Hypervisor Driver\n\nNomad task driver for the Cloud Hypervisor VMM\n\nThe nomad-driver-ch is a task driver for HashiCorp Nomad that enables orchestration of Intel Cloud Hypervisor virtual machines. This driver provides a modern, lightweight alternative to traditional hypervisor solutions while maintaining full compatibility with Nomad's scheduling and resource management capabilities.\n\n🚀 Key Features\n\n🏃‍♂️ Lightweight Virtualization : Leverages Intel Cloud Hypervisor for minimal overhead VM orchestration\n\n: Leverages Intel Cloud Hypervisor for minimal overhead VM orchestration 🔧 Dynamic Resource Management : CPU, memory, and disk allocation with Nomad's resource constraints\n\n: CPU, memory, and disk allocation with Nomad's resource constraints 🌐 Advanced Networking : Bridge networking with static IP support and dynamic configuration\n\n: Bridge networking with static IP support and dynamic configuration ☁️ Cloud-Init Integration : Automatic VM provisioning with user data, SSH keys, and custom scripts\n\n: Automatic VM provisioning with user data, SSH keys, and custom scripts 💾 Flexible Storage : Virtio-fs shared filesystems and disk image management with thin provisioning\n\n: Virtio-fs shared filesystems and disk image management with thin provisioning 🎮 VFIO Device Passthrough : GPU, NIC, and PCI device passthrough with allowlist-based security\n\n: GPU, NIC, and PCI device passthrough with allowlist-based security 🔒 Security Isolation : Secure VM boundaries with configurable seccomp filtering\n\n: Secure VM boundaries with configurable seccomp filtering 📊 Resource Monitoring : Real-time VM statistics and health monitoring\n\n: Real-time VM statistics and health monitoring 🔄 Lifecycle Management: Complete VM lifecycle with start, stop, restart, and recovery capabilities\n\n📋 Table of Contents\n\n🚀 Quick Start\n\nPrerequisites\n\n⚠️ IMPORTANT: Cloud Hypervisor has no bootloader. You MUST always provide both kernel and initramfs parameters in your task configuration, even when using full disk images. The driver will fail if either is missing.\n\nNomad v1.4.0 or later\n\nv1.4.0 or later Cloud Hypervisor v48.0.0 or later\n\nv48.0.0 or later Linux kernel with KVM support\n\nwith KVM support Bridge networking configured on host\n\nBasic Example\n\njob \"web-server\" { datacenters = [ \" dc1 \" ] type = \" service \" group \"web\" { task \"nginx\" { driver = \" ch \" config { image = \" /var/lib/images/alpine-nginx.img \" network_interface { bridge { name = \" br0 \" static_ip = \" 192.168.1.100 \" } } } resources { cpu = 1000 memory = 512 } } } } ``` # # 📦 Installation # ## 1. Install Dependencies ** Cloud Hypervisor : ** ```bash # Download and install Cloud Hypervisor v48+ wget https : // github.com/cloud-hypervisor/cloud-hypervisor/releases/download/v48.0/cloud-hypervisor-static sudo mv cloud - hypervisor - static / usr / local / bin / cloud - hypervisor sudo chmod + x / usr / local / bin / cloud - hypervisor # Install ch-remote for VM management wget https : // github.com/cloud-hypervisor/cloud-hypervisor/releases/download/v48.0/ch-remote-static sudo mv ch - remote - static / usr / local / bin / ch - remote sudo chmod + x / usr / local / bin / ch - remote # Optional: ensure binaries are discoverable export PATH = \" /usr/local/bin:$PATH \"\n\n⚠️ glibc requirements: The dynamically-linked release of Cloud Hypervisor requires glibc ≥ 2.34. If you are running on older distributions (Debian 11, Ubuntu 20.04, etc.) use the static binaries shown above or run inside a container/VM that ships a newer glibc.\n\nVirtioFS daemon:\n\n# Install virtiofsd for filesystem sharing sudo apt-get install virtiofsd # Ubuntu/Debian # or sudo yum install virtiofsd # RHEL/CentOS\n\n2. Configure Bridge Networking\n\n# Create bridge interface sudo ip link add br0 type bridge sudo ip addr add 192.168.1.1/24 dev br0 sudo ip link set br0 up # Configure bridge persistence (systemd-networkd) cat > /etc/systemd/network/br0.netdev << EOF [NetDev] Name=br0 Kind=bridge EOF cat > /etc/systemd/network/br0.network << EOF [Match] Name=br0 [Network] IPForward=yes Address=192.168.1.1/24 EOF sudo systemctl restart systemd-networkd\n\n3. Install Driver Plugin\n\nOption A: Download Release\n\n# Download latest release wget https://github.com/ccheshirecat/nomad-driver-ch/releases/latest/download/nomad-driver-ch sudo mv nomad-driver-ch /opt/nomad/plugins/ sudo chmod +x /opt/nomad/plugins/nomad-driver-ch\n\nOption B: Build from Source\n\ngit clone https://github.com/ccheshirecat/nomad-driver-ch.git cd nomad-driver-ch go build -o nomad-driver-ch . sudo mv nomad-driver-ch /opt/nomad/plugins/\n\n4. Configure Nomad\n\nClient Configuration:\n\n# /etc/nomad.d/client.hcl client { enabled = true plugin \"nomad-driver-ch\" { config { # Cloud Hypervisor configuration cloud_hypervisor { bin = \" /usr/bin/cloud-hypervisor \" remote_bin = \" /usr/bin/ch-remote \" virtiofsd_bin = \" /usr/libexec/virtiofsd \" default_kernel = \" /boot/vmlinuz \" default_initramfs = \" /boot/initramfs.img \" } disable_alloc_mounts = false # Network configuration network { bridge = \" br0 \" subnet_cidr = \" 192.168.1.0/24 \" gateway = \" 192.168.1.1 \" ip_pool_start = \" 192.168.1.100 \" ip_pool_end = \" 192.168.1.200 \" } # Allowed image paths for security image_paths = [ \" /var/lib/images \" , \" /opt/vm-images \" ] } } }\n\n5. Start Nomad\n\nsudo systemctl restart nomad\n\nVerify the driver is loaded:\n\nnomad node status -self | grep ch\n\nFor detailed installation instructions, see docs/INSTALLATION.md.\n\n⚙️ Configuration\n\nDriver Configuration\n\nThe driver configuration is specified in the Nomad client configuration file:\n\nplugin \"nomad-driver-ch\" { config { # Cloud Hypervisor binaries cloud_hypervisor { bin = \" /usr/bin/cloud-hypervisor \" # Cloud Hypervisor binary path remote_bin = \" /usr/bin/ch-remote \" # ch-remote binary path virtiofsd_bin = \" /usr/libexec/virtiofsd \" # virtiofsd binary path default_kernel = \" /boot/vmlinuz \" # Default kernel for VMs default_initramfs = \" /boot/initramfs.img \" # Default initramfs for VMs firmware = \" /usr/share/qemu/OVMF.fd \" # UEFI firmware (optional) seccomp = \" true \" # Enable seccomp filtering log_file = \" /var/log/cloud-hypervisor.log \" # VM log file path } # Network configuration network { bridge = \" br0 \" # Bridge interface name subnet_cidr = \" 192.168.1.0/24 \" # Subnet for VMs gateway = \" 192.168.1.1 \" # Gateway IP address ip_pool_start = \" 192.168.1.100 \" # IP pool start range ip_pool_end = \" 192.168.1.200 \" # IP pool end range tap_prefix = \" tap \" # TAP interface prefix } # VFIO device passthrough (not yet implemented) # vfio { # allowlist = [\"10de:*\", \"8086:0d26\"] # PCI device allowlist # iommu_address_width = 48 # IOMMU address width # pci_segments = 1 # Number of PCI segments # } # Security and paths data_dir = \" /opt/nomad/data \" # Nomad data directory image_paths = [ # Allowed image paths \" /var/lib/images \" , \" /opt/vm-images \" , \" /mnt/shared-storage \" ] } }\n\nConfiguration Reference\n\nParameter Type Default Description cloud_hypervisor.bin string /usr/bin/cloud-hypervisor Path to Cloud Hypervisor binary cloud_hypervisor.remote_bin string /usr/bin/ch-remote Path to ch-remote binary cloud_hypervisor.virtiofsd_bin string /usr/libexec/virtiofsd Path to virtiofsd binary cloud_hypervisor.default_kernel string - Default kernel path for VMs cloud_hypervisor.default_initramfs string - Default initramfs path for VMs cloud_hypervisor.firmware string - UEFI firmware path (optional) cloud_hypervisor.seccomp string \"true\" Enable seccomp filtering cloud_hypervisor.log_file string - VM log file path network.bridge string \"br0\" Bridge interface name network.subnet_cidr string \"192.168.1.0/24\" VM subnet CIDR network.gateway string \"192.168.1.1\" Network gateway network.ip_pool_start string \"192.168.1.100\" IP allocation pool start network.ip_pool_end string \"192.168.1.200\" IP allocation pool end network.tap_prefix string \"tap\" TAP interface name prefix vfio.allowlist []string - ⚠️ Not implemented yet vfio.iommu_address_width number - ⚠️ Not implemented yet vfio.pci_segments number - ⚠️ Not implemented yet data_dir string - Nomad data directory image_paths []string - Allowed VM image paths\n\nFor complete configuration details, see docs/CONFIGURATION.md.\n\n📝 Task Examples\n\nBasic VM Task\n\njob \"basic-vm\" { datacenters = [ \" dc1 \" ] group \"app\" { task \"vm\" { driver = \" ch \" config { image = \" /var/lib/images/ubuntu-22.04.img \" hostname = \" app-server \" # REQUIRED: kernel and initramfs (Cloud Hypervisor has no bootloader) kernel = \" /boot/vmlinuz-5.15.0 \" initramfs = \" /boot/initramfs-5.15.0.img \" cmdline = \" console=ttyS0 root=/dev/vda1 \" } resources { cpu = 2000 # 2 CPU cores memory = 2048 # 2GB RAM } # Optional: allow sandbox/CI environments without binaries # skip_binary_validation = true } } }\n\n🧪 Running in CI or locally without KVM: set skip_binary_validation = true in the plugin config (or use the SDK helper when embedding the driver) so tests can run without Cloud Hypervisor binaries present. Production deployments should keep validation enabled to surface misconfiguration early.\n\nVM with Custom User Data\n\njob \"custom-vm\" { datacenters = [ \" dc1 \" ] group \"web\" { task \"nginx\" { driver = \" ch \" config { image = \" /var/lib/images/alpine.img \" hostname = \" nginx-server \" # Cloud-init user data user_data = \" /etc/cloud-init/nginx-setup.yml \" # Default user configuration default_user_password = \" secure123 \" default_user_authorized_ssh_key = \" ssh-rsa AAAAB3NzaC1yc2E... \" # Custom commands to run cmds = [ \" apk add --no-cache nginx \" , \" rc-service nginx start \" , \" rc-update add nginx default \" ] } resources { cpu = 1000 memory = 512 } } } }\n\nVM with Storage and Networking\n\njob \"database\" { datacenters = [ \" dc1 \" ] group \"db\" { task \"postgres\" { driver = \" ch \" config { image = \" /var/lib/images/postgres-14.img \" hostname = \" postgres-primary \" # Enable thin copy for faster startup use_thin_copy = true # Network configuration with static IP network_interface { bridge { name = \" br0 \" static_ip = \" 192.168.1.50 \" gateway = \" 192.168.1.1 \" netmask = \" 24 \" dns = [ \" 8.8.8.8 \" , \" 1.1.1.1 \" ] } } # Custom timezone timezone = \" America/New_York \" } resources { cpu = 4000 # 4 CPU cores memory = 8192 # 8GB RAM } # Mount shared storage volume_mount { volume = \" postgres-data \" destination = \" /var/lib/postgresql \" } } } volume \"postgres-data\" { type = \" host \" source = \" postgres-data \" read_only = false } }\n\nGPU-Accelerated VM\n\njob \"ml-workload\" { datacenters = [ \" dc1 \" ] group \"gpu\" { task \"training\" { driver = \" ch \" config { image = \" /var/lib/images/cuda-ubuntu.img \" hostname = \" ml-trainer \" # VFIO GPU passthrough (not yet implemented) # vfio_devices = [\"10de:2204\"] # NVIDIA RTX 3080 } resources { cpu = 8000 # 8 CPU cores memory = 16384 # 16GB RAM device \"nvidia/gpu\" { count = 1 } } } } }\n\nFor more examples, see docs/EXAMPLES.md.\n\n🌐 Networking\n\nBridge Networking\n\nThe driver supports bridge networking with automatic IP allocation or static IP assignment:\n\nAutomatic IP Allocation\n\nconfig { network_interface { bridge { name = \" br0 \" # IP will be allocated from pool automatically } } }\n\nStatic IP Assignment\n\nconfig { network_interface { bridge { name = \" br0 \" static_ip = \" 192.168.1.100 \" gateway = \" 192.168.1.1 \" netmask = \" 24 \" dns = [ \" 8.8.8.8 \" , \" 1.1.1.1 \" ] } } }\n\nNetwork Configuration Priority\n\nThe driver uses a hierarchical configuration approach:\n\nTask-Level Configuration (highest priority) static_ip , gateway , netmask , dns from task config Driver-Level Configuration (medium priority) IP pool allocation, default gateway, subnet settings DHCP Fallback (lowest priority) When no static configuration is provided\n\nPort Mapping\n\nMap container ports to host ports:\n\nconfig { network_interface { bridge { name = \" br0 \" ports = [ \" web \" , \" api \" ] # Reference port labels from network block } } } network { port \"web\" { static = 80 } port \"api\" { static = 8080 } }\n\nThe driver integrates with cloud-init for automated VM provisioning and configuration.\n\nUser Data Sources\n\nFile-Based User Data\n\nconfig { user_data = \" /etc/cloud-init/web-server.yml \" }\n\nExample user data file ( /etc/cloud-init/web-server.yml ):\n\n# cloud-config packages : - nginx - curl - htop runcmd : - systemctl enable nginx - systemctl start nginx - ufw allow 80 - ufw --force enable write_files : - path : /var/www/html/index.html content : | <!DOCTYPE html> <html> <head><title>Hello from Nomad VM</title></head> <body><h1>VM deployed via Nomad Cloud Hypervisor driver!</h1></body> </html> permissions : ' 0644 '\n\nInline User Data\n\nconfig { user_data = << EOF #cloud-config package_update: true packages: - docker.io runcmd: - systemctl enable docker - systemctl start docker - docker run -d -p 80:80 nginx:alpine EOF }\n\nBuilt-in Cloud-Init Features\n\nUser Authentication\n\nconfig { default_user_password = \" secure-password \" default_user_authorized_ssh_key = \" ssh-rsa AAAAB3NzaC1yc2EAAAADAQAB... \" }\n\nCustom Commands\n\nconfig { # Commands run during boot process cmds = [ \" apt-get update \" , \" apt-get install -y docker.io \" , \" systemctl enable docker \" ] }\n\nNetwork Configuration\n\nCloud-init automatically generates network configuration based on:\n\nStatic IP settings from task configuration\n\nDriver network configuration\n\nDHCP fallback for dynamic assignment\n\n🌐 Networking\n\nStatic IP Configuration\n\nFor static IP assignment, configure the IP in your task:\n\nnetwork_interface { bridge { name = \" br0 \" static_ip = \" 192.168.1.100 \" ports = [ \" http \" , \" https \" ] } }\n\nDHCP Configuration\n\nFor DHCP assignment, omit the static_ip field:\n\nnetwork_interface { bridge { name = \" br0 \" ports = [ \" http \" , \" https \" ] # Port forwarding works with DHCP! } }\n\nDHCP Support: The driver automatically discovers DHCP-assigned IP addresses by parsing dnsmasq lease files. This enables automatic port forwarding for DHCP-based VMs. The driver generates deterministic MAC addresses from task IDs to ensure consistent IP assignment.\n\nRequirements for DHCP:\n\ndnsmasq DHCP server running on the host\n\nLease file accessible at /var/lib/misc/dnsmasq.leases\n\nVM must receive DHCP lease within the normal timeframe\n\nHow it works:\n\nDriver generates deterministic MAC address from task ID VM boots and gets DHCP lease with that MAC Driver parses dnsmasq lease file to find IP for that MAC Port forwarding rules are set up automatically using the discovered IP\n\n💾 Storage\n\nDisk Images\n\nSupported Formats\n\nRaw ( .img )\n\n( ) QCOW2 ( .qcow2 )\n\n( ) VHD ( .vhd )\n\n( ) VMDK ( .vmdk )\n\nThin Provisioning\n\nEnable thin copy for faster VM startup:\n\nconfig { image = \" /var/lib/images/base-ubuntu.img \" use_thin_copy = true }\n\nShared Filesystems\n\nMount host directories into VMs using VirtioFS:\n\njob \"shared-storage\" { group \"app\" { volume \"shared-data\" { type = \" host \" source = \" app-data \" } task \"processor\" { driver = \" ch \" config { image = \" /var/lib/images/data-processor.img \" } volume_mount { volume = \" shared-data \" destination = \" /app/data \" read_only = false } resources { cpu = 2000 memory = 4096 } } } }\n\n🎮 VFIO Device Passthrough\n\nDriver Configuration\n\nConfigure VFIO passthrough at the driver level with device allowlisting for security:\n\nplugin \"nomad-driver-ch\" { config { vfio { # Allowlist specific devices (vendor:device format) allowlist = [ \" 10de:* \" , # All NVIDIA GPUs \" 8086:0d26 \" , # Intel specific device \" 1002:67df \" # AMD Radeon RX 480 ] iommu_address_width = 48 # Default: 48 pci_segments = 1 # Default: 1 } } }\n\nSecurity Note: The allowlist prevents unauthorized device access. Use wildcards ( 10de:* ) for device families or exact vendor:device IDs.\n\nTask Configuration\n\nSpecify PCI devices to pass through to your VM:\n\njob \"ai-training\" { datacenters = [ \" dc1 \" ] constraint { attribute = \" ${ node . unique . name } \" value = \" gpu-node-1 \" } group \"training\" { task \"model-training\" { driver = \" ch \" config { image = \" /var/lib/images/cuda-pytorch.img \" # Pass through NVIDIA RTX 3080 (GPU + Audio controller) vfio_devices = [ \" 0000:01:00.0 \" , \" 0000:01:00.1 \" ] } resources { cpu = 8000 memory = 32768 } } } }\n\nRequirements\n\nIOMMU enabled in BIOS/UEFI\n\nintel_iommu=on or amd_iommu=on in kernel boot parameters\n\nor in kernel boot parameters vfio-pci kernel module loaded\n\nDevices bound to vfio-pci driver (handled automatically by the driver)\n\n## 📊 Monitoring ### Resource Statistics The driver provides real-time VM resource statistics: ```bash # View allocation statistics nomad alloc status <alloc-id> # Monitor resource usage nomad alloc logs -f <alloc-id> <task-name>\n\nVM Health Checks\n\nConfigure health checks for VM services:\n\ntask \"web-server\" { driver = \" ch \" config { image = \" /var/lib/images/nginx.img \" network_interface { bridge { name = \" br0 \" static_ip = \" 192.168.1.100 \" } } } service { name = \" web \" port = \" http \" check { type = \" http \" path = \" / \" interval = \" 30s \" timeout = \" 5s \" address_mode = \" alloc \" } } }\n\n🔧 Troubleshooting\n\nCommon Issues\n\nVM Fails to Start\n\nSymptoms:\n\nTask fails during startup\n\nError: \"Failed to parse disk image format\"\n\nSolutions:\n\n# 1. Verify image format qemu-img info /path/to/image.img # 2. Check image paths configuration nomad agent-info | grep -A 10 virt # 3. Validate kernel/initramfs paths ls -la /boot/vmlinuz * /boot/initramfs * # 4. Test Cloud Hypervisor directly cloud-hypervisor --kernel /boot/vmlinuz --disk path=/path/to/image.img\n\nNetwork Connectivity Issues\n\nSymptoms:\n\nVM has no network access\n\nCannot reach VM from host\n\nSolutions:\n\n# 1. Check bridge configuration ip link show br0 brctl show br0 # 2. Verify TAP interface creation ip link show | grep tap # 3. Test bridge connectivity ping 192.168.1.1 # Gateway IP # 4. Check iptables rules iptables -L -v -n\n\nDebugging Steps\n\n1. Enable Debug Logging\n\nNomad Client:\n\nlog_level = \" DEBUG \" enable_debug = true\n\n2. Inspect VM State\n\n# Check Cloud Hypervisor processes ps aux | grep cloud-hypervisor # Inspect VM via ch-remote ch-remote --api-socket /path/to/api.sock info # Monitor VM console output tail -f /opt/nomad/data/alloc/ < alloc-id > / < task > /serial.log\n\n📚 API Reference\n\nTask Configuration Specification\n\nComplete HCL task configuration reference:\n\nconfig { # Required: VM disk image path image = \" /path/to/vm-image.img \" # Optional: VM hostname hostname = \" my-vm-host \" # Optional: Operating system variant os { arch = \" x86_64 \" # CPU architecture machine = \" q35 \" # Machine type variant = \" ubuntu20.04 \" # OS variant } # Optional: Cloud-init user data user_data = \" /path/to/user-data.yml \" # File path # OR user_data = << EOF # Inline YAML # cloud-config packages : - nginx EOF # Optional: Timezone configuration timezone = \" America/New_York \" # Optional: Custom commands to run cmds = [ \" apt-get update \" , \" systemctl enable nginx \" ] # Optional: Default user configuration default_user_authorized_ssh_key = \" ssh-rsa AAAAB3... \" default_user_password = \" secure-password \" # Optional: Storage configuration use_thin_copy = true # Enable thin provisioning # Optional: Cloud Hypervisor specific kernel = \" /boot/custom-kernel \" # Custom kernel path initramfs = \" /boot/custom-initrd \" # Custom initramfs path cmdline = \" console=ttyS0 quiet \" # Kernel command line # Optional: Network interface configuration network_interface { bridge { name = \" br0 \" # Bridge name (required) ports = [ \" web \" , \" api \" ] # Port labels to expose static_ip = \" 192.168.1.100 \" # Static IP address gateway = \" 192.168.1.1 \" # Custom gateway netmask = \" 24 \" # Subnet mask (CIDR) dns = [ \" 8.8.8.8 \" , \" 1.1.1.1 \" ] # Custom DNS servers } } # Optional: VFIO device passthrough (coming very soon!) # vfio_devices = [\"10de:2204\"] # PCI device IDs # Optional: USB device passthrough usb_devices = [ \" 046d:c52b \" ] # USB vendor:product IDs }\n\nResource Configuration\n\nresources { cpu = 2000 # CPU shares (1 core = 1000) memory = 2048 # Memory in MB # Optional: GPU devices device \"nvidia/gpu\" { count = 1 constraint { attribute = \" ${ device . attr . compute_capability } \" operator = \" >= \" value = \" 6.0 \" } } }\n\n🛠 Development\n\nBuilding from Source\n\nPrerequisites:\n\nGo 1.19 or later\n\nGit\n\nBuild Steps:\n\n# Clone repository git clone https://github.com/ccheshirecat/nomad-driver-ch.git cd nomad-driver-ch # Install dependencies go mod download # Run tests go test ./... # Build binary go build -o nomad-driver-ch . # Install plugin sudo cp nomad-driver-ch /opt/nomad/plugins/\n\nTesting\n\nUnit Tests:\n\ngo test ./...\n\nIntegration Tests:\n\n# Requires Cloud Hypervisor installation sudo go test -v ./virt/... -run Integration\n\n🤝 Contributing\n\nWe welcome contributions! Please see our Contributing Guide for details.\n\nQuick Contribution Checklist\n\nFork the repository\n\nFork the repository Create a feature branch ( git checkout -b feature/amazing-feature )\n\nCreate a feature branch ( ) Write tests for your changes\n\nWrite tests for your changes Ensure all tests pass ( go test ./... )\n\nEnsure all tests pass ( ) Run linting ( golangci-lint run )\n\nRun linting ( ) Commit with clear messages\n\nCommit with clear messages Push to your fork\n\nPush to your fork Create a Pull Request\n\nDevelopment Guidelines\n\nCode Style: Follow Go conventions and use gofmt Testing: Maintain >80% test coverage Documentation: Update docs for user-facing changes Compatibility: Maintain backward compatibility Security: Never commit secrets or credentials\n\n📄 License\n\nThis project is licensed under the Mozilla Public License 2.0 - see the LICENSE file for details.\n\n🙏 Acknowledgments\n\nHashiCorp Nomad team for the excellent orchestration platform\n\nIntel Cloud Hypervisor team for the lightweight VMM\n\nCloud-init project for VM initialization\n\nAll contributors who help improve this driver\n\nMade with ❤️ for the cloud-native community",
      "source": "Github.com",
      "url": "https://github.com/volantvm/nomad-driver-ch",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Show HN: I made an OSS tool to remove Sora 2 Watermark in less than 72h released",
      "content": "Sweeta Remove Watermarks from SORA 2 Video Generations\n\nAbout\n\nSORA 2 is a State-of-the-art model by OpenAI and for the past few days, being on platforms like Instagram and Twitter, I've noticed how many non-technical people just assume the video is real despite the watermark.\n\nThink what would happen if there was no watermark? This is the reason that this project exists. It's not to abuse the great initiative by OpenAI to put logos onto every generation (though temporarily there's also an easy way to bypass that which I wouldn't cover), it's to hopefully encourage them to be harsher and more obvious with it in some form.\n\nSweeta is an AI-powered watermark removal tool specifically designed for SORA 2 video generations. It Uses advanced inpainting models (LaMA) and intelligent detection algorithms, it can seamlessly remove watermarks while (mostly) preserving the original image quality.\n\nRecommended Specs:\n\nOS : Windows 11, macOS 12+, or Ubuntu 20.04+\n\n: Windows 11, macOS 12+, or Ubuntu 20.04+ RAM : 16GB or more\n\n: 16GB or more Storage : 10GB free space\n\n: 10GB free space GPU : NVIDIA GPU with 4GB+ VRAM (or Apple Silicon for macOS)\n\n: NVIDIA GPU with 4GB+ VRAM (or Apple Silicon for macOS) CPU: Multi-core processor (Intel i5/AMD Ryzen 5/Apple M1 or better)\n\nInstallation\n\nPrerequisites\n\nPython & Conda: Install Miniconda (recommended) or Anaconda\n\nWindows\n\nQuick Install (Recommended)\n\nOpen Command Prompt or PowerShell as administrator Navigate to the project folder Run the installation script: cd path\\to\\Sweeta windows\\install_windows.bat Or for PowerShell: powershell - ExecutionPolicy Bypass - File windows\\install_windows.ps1 Follow the on-screen instructions\n\nManual Installation\n\n# Create the conda environment conda env create -f environment.yml # Activate the environment conda activate py312aiwatermark # Install additional dependencies pip install PyQt6 transformers iopaint opencv - python - headless # Download the LaMA model iopaint download -- model lama\n\nLinux\n\n# Navigate to the project directory cd /path/to/Sweeta # Run the setup script bash linux/setup.sh # Or manually: conda env create -f environment.yml conda activate py312aiwatermark pip install PyQt6 transformers iopaint opencv-python-headless iopaint download --model lama\n\nColab\n\nAccess the Colab notebook from here and follow the instructions.\n\nUsage\n\nLaunching the Application\n\nGUI Mode (Recommended)\n\nActivate the conda environment: conda activate py312aiwatermark Launch the GUI application: python remwmgui.py\n\n(would be happy to prepare a hugging face port for Spaces too, which would technically be better but would require community GPU access)\n\nCommand Line Mode\n\nconda activate py312aiwatermark python remwm.py < input_path > < output_path > [options]\n\nExample:\n\npython remwm.py input_video.mp4 output_video.mp4 --max-bbox-percent 15 --force-format MP4 --transparent --overwrite\n\nAvailable options:\n\n--max-bbox-percent : Detection sensitivity (default: 10.0)\n\n: Detection sensitivity (default: 10.0) --force-format : Output format (PNG, WEBP, JPG, MP4, AVI)\n\n: Output format (PNG, WEBP, JPG, MP4, AVI) --transparent : Make watermark areas transparent\n\n: Make watermark areas transparent --overwrite : Overwrite existing files\n\nConfiguration Edit\n\nRefer #ui.yml.example\n\nConfiguration Options\n\nInput Path : Select your source file or folder\n\n: Select your source file or folder Output Path : Choose where to save processed files\n\n: Choose where to save processed files Overwrite Files : Enable to replace existing output files\n\n: Enable to replace existing output files Transparent Watermarks : Make watermark areas transparent (PNG only)\n\n: Make watermark areas transparent (PNG only) Max BBox Percent : Adjust detection sensitivity (1-100%)\n\n: Adjust detection sensitivity (1-100%) Output Format: Choose PNG, WEBP, JPG, or keep original format\n\nCommon Issues\n\nImportError: cannot import name 'cached_download' from 'huggingface_hub'\n\nSolution: This is a version compatibility issue. The installation scripts now automatically install the correct version. If you installed manually, run:\n\npip install \" huggingface-hub<0.20 \" pip install --upgrade iopaint\n\n\"Conda is not recognized as an internal or external command\"\n\nSolution: Ensure Conda is properly installed and added to your system PATH environment variable.\n\nDependency Installation Failures\n\nSolution: Try installing dependencies individually:\n\npip install PyQt6 pip install transformers pip install iopaint pip install opencv-python-headless\n\nApplication Won't Start\n\nSolution: Verify the environment is activated:\n\nconda activate py312aiwatermark python --version # Should show Python 3.12.x\n\nLaMA Model Download Issues\n\nSolution: Ensure stable internet connection and retry:\n\niopaint download --model lama\n\nCUDA/GPU Issues\n\nSolution: Install PyTorch with CUDA support:\n\npip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n\nIf you run into any issues or have something to say, reach out! I'd be happy to talk :) Twitter, LinkedIn\n\nI (tired to) microblog the development process in #journal.md but uh, read it at your own risk lol Will put out a blog or something similiar too.\n\n📄 License & Disclaimer\n\nLicense\n\nThis project is licensed under the Apache License 2.0 - see the LICENSE file for details. Thanks to D-Ogi for the WatermarkRemover-AI model which was heavily modified for this project.\n\n⚠️ Important Disclaimer\n\nTHIS SOFTWARE IS PROVIDED FOR EDUCATIONAL AND RESEARCH PURPOSES ONLY. Use this tool responsibly and ethically.",
      "source": "Github.com",
      "url": "https://github.com/Kuberwastaken/sweeta",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Lenovo Legion 5: 15.3\" FHD+ 165Hz, Ryzen 7 260, RTX 5060, 16GB DDR5, 512GB SSD $899.99 (1 replies)",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18664621-lenovo-legion-5-15-3-fhd-165hz-ryzen-7-260-rtx-5060-16gb-ddr5-512gb-ssd-899-99",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Mario Kart World And Donkey Kong Bananza Shortlisted For 'Console Game Of The Year'",
      "content": "The Switch 2 game library has already scooped up some awards this year, and now that we're at the tail end of 2025, even more nominations are beginning to pop up for Nintendo's new system and its exclusives.\n\nThe UK-based 'Golden Joystick Awards' have returned for ithe 43rd annual event, and it marks the debut of Switch 2 games, which we've highlighted below.\n\nThis includes the launch title Mario Kart World and Donkey Kong Bananza, which was released in the following month. Mario Kart is shortlisted for 'best multiplayer', Donkey Kong is up for 'best audio design', and both titles are in the running for 'console game of the year'. As you can see below, they're up against games like Death Stranding 2 and the recent release, Ghost of Yōtei.\n\nConsole Game of the Year\n\nDonkey Kong Bananza\n\nMonster Hunter Wilds\n\nGhost of Yōtei\n\nDeath Stranding 2: On the Beach\n\nSonic Racing: CrossWorlds\n\nMario Kart World\n\nBest Multiplayer Game\n\nBattlefield 6\n\nPeak\n\nElden ring Nightreign\n\nSplit Fiction\n\nMario Kart World\n\nRematch\n\nBest Audio Design\n\nGhost of Yōtei\n\nBattlefield 6\n\nDonkey Kong Bananza\n\nDeath Stranding 2: On the Beach\n\nTwo Point Museum\n\nCronos: The New Dawn\n\nThat's not all, as the Switch 2 has also been nominated for the 'best gaming hardware' category, and joining it is the system's Pro Controller! Here's what Nintendo's tech will be facing off against:\n\nBest Gaming Hardware\n\nNintendo Switch 2\n\nNintendo Switch 2 Pro Controller\n\nWD_BLACK SN8100 NVMe SSD\n\nElgato Facecam 4K\n\nRazer Blade 16\n\nAMD Ryzen 9 9950X3D\n\nPokémon GO has also been nominated for the \"still playing\" mobile award. As for the 'Ultimate Game of the Year', nominations for this award will be revealed next month. Voting across 21 categories is now open to the public until the end of the month, and the winners for each award will be announced on 20th November.\n\nIf you want to see the other categories and games nominated for the Golden Joystick Awards, check the links below.",
      "source": "Nintendo Life",
      "url": "https://www.nintendolife.com/news/2025/10/mario-kart-world-and-donkey-kong-bananza-shortlisted-for-console-game-of-the-year",
      "timestamp": "2025-10-05"
    }
  ],
  "Intel": [
    {
      "headline": "Meet Lisa Su: CEO and president of Advanced Micro Devices, the main competitor to Nvidia",
      "content": "Lisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion.\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nlighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nLisa Su is the engineer behind one of the most dramatic corporate turnarounds in the tech industry.\n\nThe Taiwanese American CEO is widely credited with transforming AMD from a struggling semiconductor firm on the brink of collapse into a global powerhouse competing head-to-head with Intel and Nvidia.\n\nWhen Su joined AMD in 2012, the company's market value was under $2 billion. Within a decade of her leadership, AMD's innovations in high-performance computing and graphics, especially the Ryzen CPUs and EPYC server processors, catapulted the company's value to roughly $270 billion as of October 2025.\n\nBut Su's leadership has not been without challenges. AMD's two largest competitors, Nvidia and Intel, are now working together in a strategic collaboration. Under the second Trump administration, export regulations related to China, one of AMD's largest markets, are also constantly changing.\n\nHere's a look at the timeline of Su's career, from her early life in New York City to her role as one of the most influential women in tech and innovation:",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/meet-lisa-su-ceo-and-president-of-advanced-micro-device",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "If you just need a laptop for the basics, this one at $349 is an absolute steal",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/asus-vivobook-15-gets-a-serious-discount/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Intel: What Next For The Chip Fabrication Giant?",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/digital-assets/2025/10/05/intel-what-next-for-the-chip-fabrication-giant/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Linux 6.18 DRM Pull Includes New Tyr & Rocket Drivers, More AMD & Intel GPU Enhancements",
      "content": "The Direct Rendering Manager \"DRM\" pull request ended up leading to Linus Torvalds complaining over text and Rust code formatting but in the end he pulled all of these kernel graphics driver updates and also the associated \"accel\" accelerator subsystem drivers too.With the Linux 6.18 DRM pull there is a lot of kernel graphics driver improvements across the board, including the new drivers of Tyr and the Rocket accelerator driver. For enhancing existing driver support, the AMD and Intel graphics drivers continue seeing a bulk of the activity. Plus ongoing Rust code work in the DRM subsystem and more.\n\nBelow is a look at the DRM kernel driver changes for Linux 6.18.- The \"Rocket\" accelerator driver is finally mainlined for enabling the NPU found on newer Rockchip SoCs. This is the open-source driver reverse-engineered and started by Tomeu Vizoso. The Rocket accel driver works with new user-space code in Mesa 25.3 for Rockchip NPUs.- The AMDGPU and AMDKFD Checkpoint and Resture \"CRIU\" support for GEM memory objects.- Expanded AMDGPU Video Core Next \"VCN\" engine reset support.- More AMD Cyan Skillfish updates.- The AMDXDNA accelerator driver now supports user-space allocated buffers, improved error reporting, and other enhancements.- A new Intel Xe driver interface for querying VMA count and memory attributes. The intel Intel SLPC \"power_profile\" sysfs interface for the Xe driver for power management tuning.- Intel Xe driver SR-IOV support for CCS surfaces on Xe2+. The SR-IOV PF mode is also now enabled by default on supported platforms. Intel has returned to working on the upstream Habana Labs accelerator driver . There still is no Gaudi 3 support but at least they are back to working on this code under a new set of maintainers.- Intel Xe driver support for madvise in GPU SVM (Shared Virtual Memory).- The Arm Mali Panthor DRM driver added support for Mali G710, G510, G310, Gx15, Gx20, Gx25 GPUs.- Continued work on Nova as the next-generation open-source NVIDIA Linux kernel driver written in Rust.- The initial code around Tyr as a new Rust driver for Arm Mali GPUs . It's not yet usable by end-users, similar to the Nova driver.- Various new Rust abstractions and other work toward making Rust DRM drivers more practical.See this pull for the full list of DRM feature patches this cycle.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-DRM",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "AMD Versal TRNG Driver Upstreamed To Linux 6.18, Intel Adds New Telemetry For QAT Gen6",
      "content": "All of the crypto subsystem changes have been merged for the in-development Linux 6.18 kernel.A new driver in the cryptographic subsystem is the AMD Versal TRNG driver . This provides true random number generator support with the AMD Versal Adaptive SoCs.\n\nThis driver was contributed by AMD directly for upstreaming to the mainline Linux kernel. This also joins other new Versal support in Linux 6.18 like the new Versal NET DDR EDAC driver Meanwhile the AMD Crypto Co-Processor \"CCP\" driver has added a new API for dealing with SEV-SNP virtualization around cipher text hiding.Over on the Intel side, earlier this year they introduced QAT Gen6 support . For QuickAssist/QAT Gen6 with the Linux 6.18 kernel they are adding ring buffer idle and command queue telemetry support.The crypto pull for Linux 6.18 also includes improvements to the HiSilicon crypto driver, a new TI driver with ECB/CBC AES support, and other changes. See the crypto pull for the full list of crypto changes that were merged to mainline yesterday.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-Crypto",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "I cloned my voice with AI and it was unsettlingly good",
      "content": null,
      "source": "MakeUseOf",
      "url": "https://www.makeuseof.com/ai-voice-clone-chatterbox/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Haptic Touchpad Support Makes It Into Linux 6.18",
      "content": "The HID changes have been merged for Linux 6.18 and are headlined by initial support in the mainline kernel for haptic touchpad handling.As written about last month, haptic touchpad support is ready for the Linux kernel. Haptic touchpads contain force sensors and haptic actuators in place of a traditional button. Haptic touchpads can eliminate mechanical parts and provide a nice clicking effect across the entire touchpad.\n\nFor Linux 6.18, Google engineers were focused on the Elan 2703 haptic touchpad as their initial support target. Google has been leading the work on haptic touchpads for Linux in motivated by their own Chrome OS needs.In addition to the haptic touchpad support, another Linux 6.18 HID addition worth noting is the Sony DualSense controller audio jack handling work.Some of the other HID changes include HID-BPF to be able to re-bind a driver to hid-multitouch, making hidraw ioctls safer, PIDFF improvements, and better configuration of Intel QuickI2C via ACPI.More details on these HID feature updates for Linux 6.18 via this merge",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-HID",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Weekly Market Wrap: Intel, Nvidia and Electronic Arts made major news",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/markets/weekly-market-wrap-intel-nvidia-and-electronic-arts-made-the-most-news",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Microsoft's new Photos app update is so good that it could well become my favorite photo organizing tool - but you will need a Copilot+ PC to experience it",
      "content": "The app sorts receipts, screenshots, and handwritten notes automatically\n\nCopilot+ PCs are required for Microsoft’s newest Photos app functions\n\nAutomatic classification works even across different languages and scripts\n\nMicrosoft has released a new version of its Photos app, now presented as a more advanced tool for organizing and enhancing digital images.\n\nThe update, now live in the Microsoft Store, relies heavily on local artificial intelligence computation, with new functions tied specifically to Copilot+ PCs.\n\nThe app is not a dedicated photo editor, so it cannot be an Adobe Photoshop alternative. It instead focuses on sorting pictures, tagging documents, and upscaling low-resolution images with AI.\n\nAI-powered photo organization\n\nThe update brings automatic classification using an onboard neural processing unit to scan a library of pictures and sort them into categories such as screenshots, receipts, documents, and handwritten notes.\n\nThis system is meant to reduce the time spent scrolling through unstructured folders.\n\nMicrosoft also says the classification works across languages, so a receipt or document in another script should be tagged correctly.\n\nA “keyword” search option now allows users to quickly filter results, a function that might appeal to those who already store years of digital clutter inside their image folders.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAlongside organizational features, the update introduces a “super resolution” feature that can upscale low-resolution images without relying on external servers.\n\nThe work happens locally on the device, restoring detail that would normally disappear during enlargement.\n\nMicrosoft presents this as a way to bring older or compressed photographs closer to modern display standards.\n\nOn the downside, these AI functions are only available on Copilot+ PCs powered by Intel, AMD, or Qualcomm chips with NPU units.\n\nThat requirement places the most publicized upgrades out of reach for most current Windows users.\n\nIt also frames the Photos app as more of a showcase for Microsoft’s new hardware strategy than a universal solution for managing digital images.\n\nWhile the company promotes the update as a leap in convenience, the limitations suggest that many users will keep relying on existing tools.\n\nSome may stick with a free photo editor already familiar to them, while others will continue returning to established professional packages.\n\nFollow TechRadar on Google News and add us as a preferred source to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!\n\nAnd of course you can also follow TechRadar on TikTok for news, reviews, unboxings in video form, and get regular updates from us on WhatsApp too.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/microsofts-new-photos-app-update-is-so-good-that-it-could-well-become-my-favorite-photo-organizing-tool-but-you-will-need-a-copilot-pc-to-experience-it",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "The age of silicon and software began 75 years ago with the patenting of the transistor",
      "content": "75 years ago, the three Bell Labs scientists behind the invention of the transistor would, at last, have the U.S. Patent in their hands. This insignificant-looking semiconductor device with three electrodes sparked the third industrial revolution. Moreover, it ushered in the age of silicon and software, which still dominates business and human society to this day.\n\nThe first working transistor was demonstrated in 1947, but it wasn’t until October 3, 1950, that the patent was secured by John Bardeen, Walter Brattain, and William Shockley. The patent was issued for a “three-electrode circuit element utilizing semiconductor materials.” It would take several more years before the significant impacts transistors would have on business and society were realized.\n\nTransistors replaced the bulky, fragile and power-hungry valves, that stubbornly remain present in some guitar amplifiers, audiophile sound systems, studio gear, where their ‘organic’ sound profile is sometime preferred. We also still see valves in some military, scientific, and microwave/RF applications, where transistors might be susceptible to radiation or other interference. There are other niche use cases.\n\nBeyond miniaturization, transistors would deliver dramatic boosts in - computational speed, energy efficiency, and reliability. Moreover, they became the foundation for integrated circuits and processors, where billions of transistors could operate reliably in a much smaller footprint than taken up by a single valve. Processors featuring a trillion transistors are now on the horizon.\n\n1947: invention, 1950: patent, 1965: Moore’s Law, 2025: billions of transistors per chip.\n\nFor PC enthusiasts, probably the best known piece of transistor lore comes from Intel co-founder Gordon Moore. Of course, we are talking about Moore’s Law, which was an observation by the pioneering American engineer. Moore’s most famous prediction was that “the number of transistors on an integrated circuit will double every two years with minimal rise in cost.” (Law was revised from one to two years in 1975).\n\nImage 1 of 3 (Image credit: Intel) (Image credit: Intel) (Image credit: Intel)\n\nObviously, prior to 1965, when Moore’s Law was set out, the startling advance in transistor technology indicated that such an extrapolation would be reasonable. Even, now, certain semiconductor companies, engineers, and commentators reckon that Moore’s Law is still alive and well. You can see Intel's position in the slides, above.\n\nWhatever the case, it can’t be denied that since the patenting of the transistor, we have seen incredible miniaturization and advances in computing and software, expanding the possibilities of minds and machines. The current tech universe is actually buzzing with firms that reckon they can make machines with minds - artificial intelligence.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/semiconductors/the-age-of-silicon-and-software-began-75-years-ago-with-the-patenting-of-the-transistor",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Lenovo Legion Go 2 Review: A Handheld Made For Big, Meaty Claws",
      "content": "You buy Lenovo’s new Legion Go 2 handheld for the screen. The performance is secondary to how beautiful recent 2D titles look on the 8.8-inch, 1200p OLED display. The Legion Go 2 is otherwise a big, meaty handheld for gamers with big, meaty claws. You’ll struggle to hold it above your head lying in bed unless you’re a professional power lifter; the controls won’t be your favorite; it’s as wonky as its predecessor. And it’s hard to argue anybody should spend well over $1,000 on a gaming handheld rather than just buying a full gaming laptop.\n\nDespite all that, I can’t help but enjoy the hell out of it. My initial hours spent rolling my eyes at everything Lenovo failed to fix from its first iteration slowly morphed into the kind of appreciation that can only occur when a device starts to feel personal. It’s what happened when I downloaded Hollow Knight: Silksong and Hades II to the device and had to hold back a gasp on a crowded plane for how gorgeous both games looked on Lenovo’s big, expensive, beautiful display.\n\nLegion Go 2 It's thick, heavy, and so damn pretty. It's a shame it costs as much as it does. 4 See at Best Buy Pros Beautiful OLED display\n\n144Hz refresh rate with VRR\n\nNew ergonomics\n\nLow-wattage performance uplift Cons Annoying removable controls\n\nFPS mode is pointless\n\nReflective display\n\nVery expensive at $1,350\n\nIt’s the same feeling I get from Valve’s $550 Steam Deck OLED, which uses the same organic light-emitting diode screen technology to present deeper contrast and rich colors. Valve’s handheld maxes out at 800p on an older, custom AMD chipset. Even when you factor in performance and display size, the Steam Deck OLED is still a much, much better deal. My review unit version of the Legion Go 2 with the AMD Ryzen Z2 Extreme processor, 32GB of RAM, and 1TB of storage, costs $1,350. I could literally buy two Steam Decks for this price (more if I opted for the LCD model). For Lenovo’s inflated price, I could run out and buy three $450 Nintendo Switch 2 handhelds. You could nab a version of the Legion Go 2 that starts at $1,100 for a version with a AMD Ryzen Z2, but judging by my tests that chip will land closer in power to handhelds that are three years old and cost much less.\n\nIt’s a ridiculous scenario that consumers are taking the brunt of Donald Trump’s obsession with import taxes, aka tariffs. And in that way, consumers are screwed no matter what. The upcoming Asus ROG Xbox Ally X, which is set to launch on Oct. 16 with the same Ryzen Z2 Extreme chip, will set you back $1,000. The original Legion Go asked for $700 in 2023. The Asus ROG Ally X demanded $800 at launch last year. Both now retail at a higher price, likely due to tariffs. I would tell you to wait and buy a new handheld, but there’s no way to tell if prices might increase in coming months.\n\nReally? You kept FPS mode?\n\nWhat drives me mad using the Legion Go 2 is how Lenovo held back from improving over the 2023 handheld. The revised version is far more ergonomic than the two-year-old device with its sharp corners. Both handhelds let you remove each controller and play with the screen separated, like the Nintendo Switch. The Switch 2 did away with rails and went for magnetic connections for each Joy-Con 2, which makes attaching and detaching the controllers a little easier. Lenovo’s old and new system still use a series of exposed pins you jam into a cavity on each side of the screen. You need two hands and a strong pitching arm to remove each controller with a down and out motion. Reattaching them can be just as annoying.\n\nSee Lenovo Legion Go 2 at Best Buy\n\nThe controller uses Hall effect sticks that are much better at surviving stick drift, though they still feel a little too thin on my fingers compared to other handhelds I’ve used. The Legion Go 2 has slightly redesigned bumper buttons that make it easier to press and the same, large triggers. The $650 Legion Go S had a switch to enable instant triggers with less travel—better for first-person shooter games, but because of the removable controllers you’ll have to stick with the full range of motion.\n\nThe Switch 2’s big standout feature is its new mouse mode enabled just by putting the controller down on a table or your pant’s leg. Lenovo did it first on the Legion Go with its FPS mode. So is it any better now? No, absolutely not. You still need to remove the right controller and flick the “FPS” switch to turn on an optical mouse sensor. You then need to slot it into a base to hold it like an old-school flight stick, where the two side buttons act as the left and right mouse click. The DPI is still low enough you’ll struggle to get it working on anything but a desk. Even when you do, using a joystick and the FPS controller together necessitates changing the in-game controls. I tried it in both Cyberpunk 2077 and Borderlands 4, and it caused such havoc with both titles I was loathe to use the FPS mode again.\n\nAs for I/O, the Legion Go 2 has both a bottom and top USB-4 port. In theory, this could allow you to hook it up to an eGPU. More likely, it’s sole purpose is for charging or hooking up to a dock for HDMI passthrough. As much as Lenovo implies you’ll create a full “battle station” out of your device for instantaneous PC, you don’t want to hook it up to anything larger than a 1440p monitor, and only then for playing games most systems can run anyway.\n\nStrangely enough, one of the best improvements over the last generation handheld is the Legion Go 2’s new soft carrying case. The old case was very protective, but it was also enormous. The new version is smaller and more squat than the default Steam Deck case, which makes lugging around the 8.8-inch handheld onto planes surprisingly easy. There’s two little hidey-holes for the FPS mode stand, but since you’ll never use it, you can stick anything else in there. Just don’t tell me what.\n\nThe Legion Go 2 is so damn pretty\n\nAll the new ergonomics make it easier to hold, but not enough that it won’t feel heavy in your hands. You’ll find you’ll need a table or lap to rest your elbows on, or else you’ll use the built-in kickstand to prop it up on your desk. Either way you hold it, you’ll end up enjoying this handheld mostly for the display. As I said earlier, the 8.8-inch OLED display is sublime. It doesn’t have any higher screen resolution than the Legion Go’s 1,920 x 1,200, but it’s enough to make games pop.\n\nFor my hands, the Legion Go 2 is just large enough where I can grip it and access all the controls. Other users who are smaller in stature may not be so lucky. Ignore all those 11-inch handhelds out there. Near-9-inch devices are more than enough. The screen also sports a 144Hz refresh rate with VRR, or variable refresh rate. All those games that can hit above 100 fps (which, let’s be honest, will mostly be older or 2D titles), will look their peak on the Legion Go 2.\n\nThe screen feels bright enough indoors, but while Lenovo promises you’ll get 1,100 nits of HDR brightness, the screen is not great for using outdoors. It’s blinded by direct sunlight, and even sitting near a window you’ll see most details disappear. The screen is also very reflective. A matte coating would have dulled the display quality, but it’s at the risk of catching a glimpse of your girlfriend walking up behind you.\n\nRyzen Z2 Extreme isn’t a huge leap\n\nThe AMD Ryzen Z2 Extreme APU is purely iterative. If you’ve been watching like a hawk, hoping to devour the latest and fastest handheld chip, this isn’t it. The performance difference generation to generation is minimal. In some games, you could get 5 to 10 fps more at the highest TDP, or thermal design power, People who focus too hard on benchmarks will come away disappointed. If you care more about whether the system can play the latest AAA games, know that you’ll be able to achieve playable frame rates at the max 1200p resolution though only by dropping any hope of ray tracing for more-realistic lighting effects.\n\nSee Lenovo Legion Go 2 at Best Buy\n\nI’m fundamentally a gamer who refuses to drop the resolution of games for the sake of performance. I will lower graphics settings in a desperate attempt to eek out the minimum 30 fps. The Legion Go 2 can manage to take some AAA games into playable states at the max 35W of TDP (thermal design power) once the handheld’s engines are firing on all cylinders. TDP determines how much power is being sent to the processor, which will dictate overall performance. Borderlands 4 is one of those games notorious for running poorly on PC and consoles alike (you won’t find the game on Switch 2 in the coming days, either). I was able to get a stable sub-40 fps on the lowest possible graphics settings. I could achieve a little better frame rates in Indiana Jones and the Great Circle. Even at lower graphics settings, the game still looks and sounds great on the small screen.\n\nOlder games fare better. Control could average 40 to 49 fps at low settings with the handheld plugged in. The Shadow of the Tomb Raider benchmark at 1200p and medium settings preset with AMD’s FSR upscaling saw an average of 44 fps, while at 1080p with the same settings it could hit 48 fps. In Baldur’s Gate III, I could average above 60 fps in the open areas of Act 1 and get between 45 and 55 fps in the city environments of Act III.\n\nIn 3DMark benchmarks, the Legion Go 2 hit a score of 3,305 and 24.48 average fps in Steel Nomad Lite tests. That’s 1,000 points better than the Legion Go S with its Ryzen Z2 Go chip running on Windows, but it’s only a little more than 300 points better than the Z1 Extreme on the Asus ROG Ally X from 2024. The new device hit 3,897 points in Time Spy tests, which again is barely more than 300 points better than an Ally X. It’s not much better than an MSI Claw 8 AI+, which uses a full Intel laptop chip. Simply put, the Legion Go 2 isn’t a huge step over the previous gen at the max wattage.\n\nHowever, the device’s secret sauce is in how well it performs at lower wattages. Tests with multiple games at wattages as low as 34 fps still enabled relatively stable frame rates in games like Shadow of the Tomb Raider. While in Cyberpunk 2077 at full resolution and Steam Deck settings, the device gets 44 fps in benchmarks, at 15W it still managed to eek out nearly 30 fps. I don’t expect anybody will run high-end games on lower power. Instead, the best experience comes from games that are far less intensive. I could net well over 160 fps in Hades II on the “Balanced” performance setting. Hollow Knight: Silksong seems like it was built with the Legion Go 2 in mind with automatic settings to stay around 144Hz. These games play so gloriously on this handheld, I don’t want to play them on anything else. It’s a shame you have to spend $350 more than an Xbox Ally X jut for that pretty screen and higher refresh rate.\n\nWindows still sucks for handhelds, but it could get better\n\nOn balanced power settings, I could game for around 2 hours and 40 minutes before the device was literally begging me to plug it in. In other tests where I was gaming at the full resolution and wattage playing Indiana Jones, it lasted closer to 2 hours. The Legion Go 2 sports a 74Wh battery, which is slightly worse than the ROG Ally X’s 80Wh. The larger OLED display and higher max resolution will inevitably drag the battery life down.\n\nAt this point, players should not expect a handheld that will last very long. The ROG Ally X still has one of the best battery life at full power when it gets closer to 3 hours of runtime. In real life, the difference is negligible. At this point in my life, having a max two hours of playtime is strangely beneficial. If I’m clearing room after room in Hades II late at night, the battery timer is essentially my alarm. If it’s close to 12 a.m. and I’m about to run out of power, it’s a sign I should get some rest.\n\nDepending on the game you’re playing, the device’s fans can get relatively loud. Even at max speed I wouldn’t call them jet engine noise. It’s enough to remind you to be mindful when sitting next to strangers on a plane. The device kept very cool in my time using it. I never felt any heat around the controls, and the area around the fans also didn’t feel steamy when playing a game at max wattage.\n\nI can’t excuse the price, but I had such a good time with the Legion Go 2 it felt like a personal companion after traveling for more than a week and a half away from home. But there’s an elephant in the room shaped like a big “X” we need to address. The Xbox Ally and Xbox Ally X are supposed to launch with a new version of Windows, dubbed the “Full Screen Experience” (FSE) built exclusively for gaming handhelds. While this may fix the lingering usability issues of Windows 11 on a 7- or 8-inch screen, the upgrade should also eliminate background tasks and—hopefully—boost performance by 20%. The issue is that Microsoft has said you may need to wait until next spring to get it on handhelds like the Legion Go 2.\n\nWindows is terrible on handhelds. It gets in the way when trying to put the device to sleep while still in-game. It bombards you with popups for OneDrive that you need to use the touchscreen to excise. It saps power and makes the device run worse than it would if it was running SteamOS, the same Linux-based operating system running on the Steam Deck. In our tests, the Legion Go S with SteamOS outperforms its Windows counterpart by 20 to 30%. Unless you’re dead set on keeping your Xbox Game Pass games handy, I would suggest looking into installing Valve’s software on the Legion Go 2. I have not confirmed whether you can install SteamOS on the new handheld, though if its not compatible at launch, I assume an update may be around the corner. Without the FSE or SteamOS, this can’t be my handheld of choice. With a new operating system, the Legion Go 2 would become the bell of the ball for modern PC handhelds.\n\nSee Lenovo Legion Go 2 at Best Buy",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/lenovo-legion-go-2-review-a-handheld-made-for-big-meaty-claws-2000666394",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Intel's \"Panther Lake\" Microarchitecture Deep Dive Set for October, Full Launch in 2026",
      "content": "The story of Intel's first 18A product, \"Panther Lake,\" remains shrouded in mystery, at least for a few more days. According to earlier reports, Intel was expected to start shipping the first PTL-U and PTL-H SKUs by the end of 2025, with additional SKUs to follow in 2026. However, that situation could be subject to change, according to Golden Pig Upgrade. The rumored October 9 launch date is reserved only for the microarchitecture deep dive, and the launch and final specifications of specific models will occur at CES 2026. Being Intel's first big bet with the 18A node, Panther Lake is a product of years of Intel's manufacturing innovation, which needs to demonstrate that the investment in advanced manufacturing was worthwhile. Reportedly, Intel started limited shipments of its 18A nodes to U.S. customers in Q3, with these wafers already in production and initial output of its own CPUs expected in Q4.Given that Panther Lake is the first 18A node product, we could expect that to be a large part of those shipped wafers, most likely going to OEMs for testing before integration. As a reminder, the low-power PTL-U models are designed for a 15 W TDP and are expected to come in 6-core and 8-core versions. Some SKUs will feature four high-performance P-cores paired with four LPE-cores, while others will have only two LPE-cores complementing four P-cores. Both families will utilize Xe3-based integrated graphics, with entry models featuring four GPU cores. The more powerful PTL-H line will scale up to around 16 CPU cores, comprising four P-Cores, eight E-cores, and four LPE-cores. Some H-series parts might include up to 12 GPU Xe3 cores for integrated graphics, but the final configurations will be revealed when Intel officially launches the Panther Lake product family.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341614/intels-panther-lake-microarchitecture-deep-dive-set-for-october-full-launch-in-2026",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "I went to a day trading meetup and spoke to people with dreams of getting good enough to quit their 9-to-5",
      "content": "Some traders at TraderDaddy's 2-hour class said they aspired to become full-timers.\n\nSome traders at TraderDaddy's 2-hour class said they aspired to become full-timers. Jutharat Pinyodoonyachet for BI\n\nSome traders at TraderDaddy's 2-hour class said they aspired to become full-timers. Jutharat Pinyodoonyachet for BI\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nThe day trader persona on social media looks something like this: A man with a sporty vibe and the swagger of a finance bro says he hit it big in the stock market — and you can too.\n\nYou probably don't envision a room of tired 9-5 workers, poring over candlestick charts and quietly looking for their next big trade. Yet, that's what I found in midtown Manhattan last week when I shadowed an in-person trading course hosted by TraderDaddy, a trading education and mentoring company that says it's been successful at turning some amateurs into profitable traders.\n\nThere are no guarantees, Daniel Alhanti, the CEO and head instructor at TraderDaddy, told the room. Much of a trader's success depends on how hard they're willing to work to understand the market, he said.\n\nThe well-known difficulty of day trading hasn't stopped many Americans who quietly dream of quitting the 9-to-5 lifestyle from trying to make a living in the market. Many, too, have dropped serious cash on courses, coaching, and other kinds of mentorship to boost their chance of success.\n\nThese services have been around for a long time, but they've become more sought after in the years since the pandemic retail-trading boom. According to the Google Trends analytic tool Glimpse, global search interest for \"day trading class\" is up 700% the past quarter and hit an all-time high this summer. Search interest in \"trading coach\" is up 325% over the same timeframe, while interest in \"day trading group\" is up 572%.\n\nOn Coursera, enrollment in online trading courses soared 213% from 2019 to 2024, according to data the online course provider shared with Business Insider. The online trading platform Webull also says it's seen the number of users on its learning platform grow 37% over the last three years.\n\nTraderDaddy's Alhanti, who worked as a financial advisor before becoming a trading instructor, said he witnessed firsthand the surge in interest in trading courses and groups, such as the one he runs.\n\n\"And a lot of it is the same story,\" he said of the wave of newcomers in recent years. \"'I was watching trading on social media, saw people doing it, and I tried to teach myself on YouTube. I couldn't really find anyone else that was doing it, and I was just looking for someone to help me.'\"\n\nAlhanti, who worked as a financial advisor before becoming a trading instructor, says he can identify a successful trader when he sees one. Jutharat Pinyodoonyachet for BI\n\nThe class I attended took place in the evening and had about 30 people in it, with men making up about three-quarters of the class. People trickled into the coworking space a little before 7 p.m. and began to whip out their notebooks, giving it a college lecture vibe.\n\nHere's everything I took away from the night.\n\nThere were a lot of beginners eager to get started\n\n\"Who here is an absolute beginner?\" Alhanti said, gauging the sprinkling of hands that popped into the air. \"Who here has invested in crypto? Option contracts?\"\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nI was surprised at how many in the group appeared to be new to this. Later, when Alhanti asked traders to list the top market-moving events of 2024, the class seemed stumped before someone brought up the presidential election, tariffs, and the Fed rate-cutting cycle.\n\nTraderDaddy says it has noticed an explosion of interest in day trading groups in recent years. Jutharat Pinyodoonyachet for BI\n\nAttendees were passionate about markets\n\nThere seemed to be high enthusiasm for the market. In a side discussion, a few traders spoke heatedly about option contracts for Palantir and whether a particular trade had been profitable.\n\n\"I think they just want to make money more than anything,\" Gerardo Arevalo, a trader at the event, told me, speaking about the work ethic of the group.\n\nAlhanti says he can tell when a trader will be successful. \"You can see it in their eyes when they focus,\" he told me after the class.\n\nBecoming a successful trader is notoriously hard. A 2020 study found that 97% of investors who traded for more than 300 days lost money, and less than 1% earned $54 or more a day.\n\nTechnical analysis and independent thinking were emphasized\n\nFor two hours, Alhanti walked the group through candlestick charts and technical analysis for trades he said his students were most interested in, which included Apple, Tesla, Intel, and the broader S&P 500. The goal was to identify a price breakout—such as when a stock suddenly trades above its 200-day moving average—and of course, buy at the right time.\n\nAlhanti said he wanted to see traders become confident and skilled enough to make their own decisions when trading, as opposed to relying on him to tell them when to buy and sell.\n\nSometimes, when traders in the group make a profit, they text Alhanti in a panic, asking him what to do next, he said.\n\n\"Do not just blindly follow me,\" he said to the class.\n\nMany desire to quit their jobs\n\nA strong desire for financial freedom was a common sentiment among the aspiring traders.\n\nJoshua Villas, a 23-year-old trader who sat in the back, told me he'd spent more than $900 on trading courses. He said he became interested in trading after a conversation with a friend not long after graduating from high school. The gist of the conversation was that day-trading was a ticket to financial freedom.\n\n\"Just hearing that and knowing that someone told you and actually seeing it's real — You kind of just keep going and trying,\" Villas said.\n\nVillas, who was recently laid off from his job as a stylist, added: \"I'd say the end goal is just not to have to worry about survival. I would be happy if I was just able to make enough to keep living.\"\n\nAlhanti says he frequently comes across aspiring traders who say they feel lost or stuck in their careers. Jutharat Pinyodoonyachet for BI\n\nThat's a common story among many traders Alhanti works with. In recent years, he says he's met more younger people who are aspiring traders, people who are unsure of how to start their careers but want income and are seeking mentorship.\n\n\"They don't really know what type of career they want, or where to go, or what to do, but they know that they want to have multiple incomes in their life, trading being one of them,\" Alhanti said.\n\nYacoub Rahman, a 21-year-old college student who trades on the side, said his goal is also to one day become a full-time trader. That endpoint is appealing, largely because trading \"full-time\" isn't anything like working a full-time job, he said.\n\n\"I don't think it would take a long time. Two or three hours, I guess that's enough,\" he predicted about the amount of work required each day.\n\nRahman said he spent around three hours a day studying the market after completing his schoolwork. He added that he aspired to one day have plenty of free time to travel.\n\nArevalo, a 50-year-old trader and computer programmer, said he had effectively entered early retirement and was looking to trade for a living.\n\nBefore trading, Arevalo said he job-hopped, as he was past his prime as a coder and felt expendable to companies he worked for. He now spends six to eight hours a day trading.\n\nAlhanti says he feels bad for many of the traders who come to him feeling lost in their careers, particularly younger people. He himself was caught in the 2008 recession, when the job market for young adults was brutal.\n\n\"They just generally feel behind, and they don't really know what their next steps are,\" he said of younger traders. \"I think a lot of them are really trying to find something that is going to really put them ahead.\"",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/day-trading-course-learn-to-trade-stock-market-quitting-job-2025-9",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "TechCrunch Mobility: Toyota makes a $1.5B bet on the startup ecosystem",
      "content": "Welcome back to TechCrunch Mobility, your hub for all things “future of transportation.” To get this in your inbox, sign up here for free — just click TechCrunch Mobility!\n\nMore than a month ago, I asked you, dear reader, how you thought EV sales would play out once the $7,500 federal tax credit expired on September 30. The majority of those who responded to the poll predicted that EV sales would fall off a cliff.\n\nNow, it’s too early to tell yet; we are just a few days past the end of the quarter. But the expiring tax credit did give many automakers a bit of a sales bump as consumers raced to buy EVs before the deadline.\n\nTesla, which has seen sales growth diminish, just registered its best quarter of deliveries ever at 497,099 vehicles. That’s a massive 29% jump from the second quarter, about a 7% increase over the same period last year, and more than it has ever delivered in a single quarter.\n\nFord Motor, General Motors, and Hyundai also reported record quarterly sales of EVs. Rivian saw deliveries jump to 13,201 vehicles, up from 10,661 and 8,640 in the second and first quarters, respectively.\n\nThe looming question is how will automakers navigate a possible slowdown in EV sales in this post-tax credit era? Rivian has already adjusted its guidance down for 2025. Others may follow.\n\nThe crux for automakers is how to get rid of inventory as the new 2026 models come in without reducing or eliminating profit margins (and in some cases deepening the losses)?\n\nA little bird\n\nImage Credits:Bryce Durbin\n\nThe Department of Energy canceled 321 clean energy projects but wasn’t sharing the details with TechCrunch or the public. Luckily, a little bird shared the complete list of awards the Trump administration had canceled, and the results were revealing.\n\nAltogether, the canceled awards totaled $7.56 billion, with California bearing the brunt, losing $2.2 billion worth of grants, including a $630 million grid-modernization program that could have become a template for the nation. Colorado, Illinois, Massachusetts, Minnesota, New York, and Oregon rounded out the top eight, losing between $300 million and $600 million each.\n\nIt wasn’t until farther down the list that a red state popped up. Indeed, the majority of projects were sited in states that had voted for Kamala Harris in the last presidential election, something many media outlets reported after Office of Management and Budget chief Russell Vought tweeted as much.\n\nBut even in blue states, some awards stuck, possibly due to political connections with the Trump administration or aligned interests. Whatever the case, the move by the DOE suggests the government might be a less reliable partner for businesses, especially small startups.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/techcrunch-mobility-toyota-makes-1-160300263.html",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Legion 5i Gen 10: 15.1\" QHD+ 165Hz OLED, Intel Ultra 7 255HX, RTX 5070, 16GB DDR5, 1TB SSD $1262.24",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18662788-legion-5i-gen-10-15-1-qhd-165hz-oled-intel-ultra-7-255hx-rtx-5070-16gb-ddr5-1tb-ssd-1262-24",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Many Debian/Ubuntu Packages For Intel Accelerators & Other Intel Software Have Been Orphaned",
      "content": "In addition to some Intel Linux kernel drivers being \"orphaned\" following the corporate restructuring at Intel between developers being laid off and others deciding to pursue opportunities elsewhere, these changes have also led to a number of Intel-related software packages within Debian being orphaned. In turn these Intel packages are also relied on by Ubuntu and other downstream Debian Linux distributions.Around one dozen Intel packages within the Debian archive were recently orphaned, a.k.a. now being unmaintained following developer departures from Intel with no one currently taking up the new responsibility, with also needing to be a Debian Developer or Debian Maintainer to contribute.\n\nAmong the Intel-related packages within Debian to recently be marked as orphaned include:- The package for configuring the Intel Data Streaming Accelerators \"DSA\" IP on recent Xeon processors. This is needed for properly configuring the DSA accelerators from user-space for interfacing with the kernel drivers.- Intel QuickAssist Technology OpenSSL engine support.- The QuickAssist Technology library for making use of that hardware acceleration for offloading security, authentication, and compression services.- The Zip library utilizing QAT.- The cache monitoring and configuration of Intel Cache Monitoring Technology, Memory Bandwidth Monitoring, and Cache Allocation Technology.- The Intel Low Power Model Daemon for optimizing active idle power on Intel systems.- The Intel Cryptography Primitives Library.- Intel Multi-Buffer Crypto for IPSec.- Intel's NumaTOP observation tool.- Intel's Power Stress and Shaping Tool (PSST).- The Intel Thermal Daemon.- Thunderbolt / USB4 debugging tools.These packages were all orphaned last month and haven't seen anyone stepping up to maintain them for Debian either from Intel Corp or other interested Debian developers from the community or other organizations. This follows some Intel drivers in the upstream Linux kernel being orphaned like the Intel CPU temperature monitoring driver and Intel also having recently ended open-source projects like the x86-simd-sort library and the sad demise of Clear Linux With the user-space accelerator packages like QAT and DSA being impacted as well as various other Intel libraries and even NumaTOP and other utilities, this could pose a problem if no one steps up to maintain these packages long-term. Again, not only Debian itself being affected but also Ubuntu and other downstream Debian-based Linux distributions. This is a set-back for a nice out-of-the-box experience for Intel hardware on Debian/Debian-derived operating systems and could make it more difficult to leverage Intel accelerators moving forward if having to either run the outdated packages, build your own code from source, or relying on generic packages from Intel.com where available. Hopefully this lack of Intel maintainership to these Debian packages can be rectified soon.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Intel-Debian-Packages-Orphaned",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "These co-CEOs can't imagine running things on their own",
      "content": "Connor Diemand-Yauman and Rebecca Taber Staehelin are co-CEOs of the nonprofit Merit America. The times they've disagreed on strategy tested their thinking in ways that were \"exponentially beneficial,\" she said.\n\nConnor Diemand-Yauman and Rebecca Taber Staehelin are co-CEOs of the nonprofit Merit America. The times they've disagreed on strategy tested their thinking in ways that were \"exponentially beneficial,\" she said. Courtesy Merit America\n\nConnor Diemand-Yauman and Rebecca Taber Staehelin are co-CEOs of the nonprofit Merit America. The times they've disagreed on strategy tested their thinking in ways that were \"exponentially beneficial,\" she said. Courtesy Merit America\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nWhen Connor Diemand-Yauman popped the question to Rebecca Taber Staehelin, he got down on a knee and handed her a rose.\n\nHis gesture drew the attention of others at the Italian food hotspot in San Francisco, where the colleagues were discussing how to structure their work partnership.\n\n\"Everyone in the restaurant started applauding because they thought we were getting married,\" Diemand-Yauman told Business Insider.\n\nWhat he was actually asking Taber Staehelin to formalize in 2019 was their decision to serve as co-CEOs of Merit America, a nonprofit they had founded the year before to help low-wage workers build skills and reach the middle class.\n\nDiemand-Yauman and Taber Staehelin's business arrangement is fairly unusual. There are fewer than 40 public companies in the US that operate with dual CEOs, according to the analytics firm Boardroom Alpha. Yet the setup is having a moment: In little more than a week, Spotify, Comcast, and Oracle have recently announced that they will have co-CEOs lead their organizations.\n\nInstead of getting bogged down by the potential risks of partnerships — uneven power splits, fuzzy accountability, or strategic clashes — some companies are embracing the idea that, in a period when many CEOs' remits are broader than ever, more can be more.\n\n\"It really has allowed us to specialize in the things that we're respectively passionate about and great at,\" Mike Sobel, co-CEO of fintech company Trumid, said of the division of labor he has with his counterpart, Ronnie Mateo.\n\nKnowing who does what\n\nSobel joined Trumid in 2014, when the startup was about five months old. For years after, he and a growing number of colleagues — mostly bond traders and salespeople with experience from across Wall Street — worked alongside Mateo to build a fixed-income platform. In the early days, there were few job titles or defined responsibilities, Sobel told Business Insider.\n\n\"It was just like, 'Everyone grab a shovel,'\" he said.\n\nTrumid co-CEOs Ronnie Mateo and Mike Sobel sometimes \"disagree vehemently,\" but because it's in service of the right answer, it's productive, Sobel said. Courtesy Trumid\n\nAs the company grew, especially during the boom years of the pandemic, so did the need to draw sharper contours around who did what. That clarity was necessary, Sobel said, both for new clients and for employees who joined the New York firm when lockdowns meant people weren't coming to the office. When it had been a smaller group in one place, knowing where to go wasn't as much of a challenge, he said.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nTrumid now has 200 employees and saw its average daily trading volume increase by 62% in 2024, reaching $1.4 trillion for the year.\n\n\"It's very important that titles reflect the reality of responsibilities, and who is accountable for what,\" Sobel said. So, in 2021, Trumid elevated him to co-CEO so that he could run the day-to-day, while Mateo, who founded the company, could be the indefatigable \"locker-room leader,\" chief sales guy, and face of the company, Sobel said.\n\n\"Ronnie is the visionary and the star player,\" he said.\n\nSobel said that internally, in particular, staffers understand who runs what and know that they \"can get a final answer from either one of us.\"\n\nAmong the company's half dozen top execs, there's also a clear sense of who is the specialist in each area, he said.\n\nWhen it comes to decision-making, Sobel said, he understands when it's a call he can make on his own versus one that's consequential enough to merit consulting with Mateo or others on the executive team. In some cases, Sobel might simply want a gut check.\n\n\"I should — and want to — talk to my partner about this, because it's really important,\" he said.\n\nAnother key factor, Sobel said, is the faith he and Mateo have in each other and the rest of their team.\n\n\"I trust in terms of motives, and also trust in terms of excellence,\" he said.\n\nWhen disagreements arise\n\nSobel said he and Mateo tend to be the opposite when it comes to their instincts, which can lead to \"heated debates.\"\n\nYet, because both of them are clear on the shared goal, \"you could disagree vehemently, but it's in the service of the right answer,\" he said. \"It is a productive exercise.\"\n\nSobel said the firm subscribes to the \"disagree and commit\" mantra popularized by Jeff Bezos at Amazon, as well as by former Intel CEO Andy Grove. When leaders at Trumid make a decision, the team gets on board and, regardless of how it turns out, \"there is no keeping score,\" Sobel said.\n\nDiemand-Yauman and Taber Staehelin see it similarly. Early on, Taber Staehelin said, before they became \"a hive mind,\" most disagreement emerged over annual budgeting. She said she tended to be more conservative, while Diemand-Yauman sought to be more ambitious in his approach to investing in growth.\n\nTo resolve disputes, Taber Staehelin said, the pair would step back to refocus on what they were trying to accomplish.\n\n\"It really tested the rigor of the thinking in a way that was exponentially beneficial,\" she said.\n\nTaber Staehelin still has the rose that Diemand-Yauman gave her at a restaurant when they decided to become co-CEOs. Courtesy Merit America\n\nThat's why Diemand-Yauman sees value in having a human copilot. \"When you do it right, it is far better than a single CEO, and when you do it wrong, it's far worse.\"\n\nHe said he wouldn't want to be a solo CEO again, as he was at a prior nonprofit he founded.\n\n\"I can't imagine starting or leading something without a partner,\" Diemand-Yauman said. In part, he said, that's because being a sole CEO can be isolating and because it's often hard to get a straight answer from other teammates.\n\nTaber Staehelin still has the rose that Diemand-Yauman gave her, which she keeps in a shoe box. It's a reminder of what each of them, both of whom are married, has invested in their work spouse.\n\n\"You are with someone who is in the trenches with you and can empathize with what you're going through, who will always honor confidentiality and create a safe space for you to vent and problem-solve,\" Diemand-Yauman said.\n\nTaber Staehelin agreed: \"He's Taylor; I'm Travis.\"",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/co-ceos-on-benefits-having-shared-responsibilities-2025-10",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Cramming for Week 5: Five fantasy sleepers, three predictions, three trends and an intriguing bet",
      "content": "Open Extended Reactions\n\nWeek 5 of the 2025 NFL season is here, and our NFL analysts have you covered in the eleventh hour. Don't miss our last-minute prep for a loaded slate.\n\nHere's what we have: First, analytics writer Seth Walder breaks down three stat trends that could be pivotal this weekend. Then fantasy football writer Eric Moody runs through five players who are rostered in under 50% of ESPN fantasy football leagues as of Saturday and could be started in a jam. That's followed by NFL analyst Matt Bowen predicting three potentially big surprises and sports betting analyst Pamela Maldonado giving her favorite bet for Week 5.\n\nWill the Giants' offense roll against the Saints? Can Lions defensive end Aidan Hutchinson get multiple sacks against the Bengals? Will Browns CB Denzel Ward snag an interception for the second straight game? Which two QBs have sneaky fantasy value this week? And could we see a bunch of points in the Raiders-Colts game? Let's dive in.\n\nJump to:\n\nStat trends | Fantasy sleepers\n\nPotential surprises | Best bet\n\nWalder: Three key stat trends that could determine Week 5 winners\n\nCan Giants receivers Wan'Dale Robinson and Darius Slayton step up against the Saints?\n\nThe numbers suggest they can. New Orleans has one of the most pass-inducing defenses in the NFL, ranking second highest in pass rate over expectation allowed (plus-2%), per NFL Next Gen Stats. It's easy to see why. While the Saints' defense allows minus-0.10 EPA per designed carry (ninth best), it allows 0.25 EPA per dropback (fourth worst).\n\nTwenty-one percent of passes against New Orleans are thrown to receivers in the slot, which ought to specifically help Robinson, who has lined up in the slot 69% of the time. It doesn't end there, as the Saints have allowed 8.6 air yards per attempt this season (fourth most), which should play right into the hands of Slayton, a deep threat who is averaging 12.7 air yards per target.\n\nIs Lions edge rusher Aidan Hutchinson headed for another multi-sack day against the Bengals?\n\nI'm a little surprised to see the Lions leading the entire league in defensive sack rate (10.6%), but Hutchinson is hot since returning from leg surgery. He has a sack in three straight games, including two last Sunday against the Browns. He also ranked in the top five in pass rush win rate at edge that week. Now he and the Lions get to face a Bengals team that is struggling mightily in pass protection.\n\nAs a team, the Bengals rank dead last in pass block win rate (44.6%). Against the Broncos last week, both tackles Amarius Mims and Orlando Brown Jr. ranked in the bottom five in pass block win rate at their position. Add in that backup QB Jake Browning has been sacked 8% of the time (higher-than-average rate), and that the Bengals should have to pass plenty as underdogs. So Hutchinson (and perhaps Al-Quadin Muhammad) should be in for a productive pass rushing day.\n\nCan RB Woody Marks and the Texans have rushing success against the Ravens?\n\nMarks, a fourth-round rookie, burst onto the scene against the Titans with 17 carries for 69 yards and a rushing touchdown; he also had 50 more yards and a touchdown in the receiving game. And there's reason to believe that success could continue this week, thanks to a schematic change this season.\n\nUnder new offensive coordinator Nick Caley, the Texans have shifted from a heavy outside zone team to a heavy duo team, a downhill scheme that uses double-team blocks. Since the start of last season, the Ravens have allowed 3.4 yards per carry to outside zone but 5.0 to duo. The Lions, most notably, gashed Baltimore with duo plays (9.5 yards per carry!) in Week 3.\n\nMoody: Five fantasy sleepers you need to pick up -- and can start this week\n\nRico Dowdle, RB, Carolina Panthers (39.6% rostered)\n\nChuba Hubbard has been ruled out of Sunday's game against the Dolphins with a calf injury, putting Dowdle in line for a heavy workload. He should find success against a Miami defensive front that ranks 28th in run stop win rate and has allowed the seventh-most fantasy points per game to running backs this season. Last season with the Cowboys, Dowdle averaged 12.3 fantasy points in games where he saw 15 or more touches.\n\nJaxson Dart, QB, New York Giants (36.6% rostered)\n\nDart hit the ground running against the Chargers in his first career start, not only leading the Giants to a win but also delivering 19.8 fantasy points. He generates production with both his arm and his legs, and as Seth mentioned above, he has capable targets in Robinson, Slayton and Theo Johnson. The rookie draws a favorable matchup against a Saints defense that has allowed the fifth-most fantasy points per game to quarterbacks.\n\nplay 1:21 Warner: You could feel the spark Jaxson Dart gave the Giants Kurt Warner joins \"The Rich Eisen Show\" to recap Jaxson Dart's performance vs. the Chargers.\n\nElic Ayomanor, WR, Tennessee Titans (35.5% rostered)\n\nAyomanor is the lone bright spot in a Titans offense that ranks 31st in total yards per game (210.5) and 32nd in points per game (12.8). He leads Tennessee in targets (25), receiving yards (151) and touchdowns (2), averaging 9.8 fantasy points per game. That's a solid floor, but his ceiling could be even higher against a Cardinals defense that has allowed the third-most receptions per game to wide receivers.\n\nBrenton Strange, TE, Jacksonville Jaguars (35.1% rostered)\n\nStrange has posted at least 10 fantasy points and seven targets in two straight games. He also leads the Jaguars in receptions (19) and receiving yards (182). He offers fantasy managers a high floor, with at least four catches and 45 yards in three games this season. Strange hasn't found the end zone yet, but that could change against the Chiefs, who might prioritize stopping the Jaguars' prolific running game in the red zone.\n\nBryce Young, QB, Carolina Panthers (15.2% rostered)\n\nYoung is off to a poor start for the second straight season, and a strong performance against Miami could be crucial to getting back on track. He is averaging just 12.9 fantasy points per game, but the Dolphins' defense has allowed the second-most fantasy points per game to opposing quarterbacks. Carolina would be wise to lean on its run game behind an offensive line that ranks seventh in run block win rate, and then build off that with play-action passes against a subpar Miami pass rush.\n\nBowen: Don't be surprised if ...\n\nGiants RB Cam Skattebo scores a touchdown against the Saints\n\nWith Skattebo taking over the lead role in New York, his volume and scoring opportunities are up in Brian Daboll's offense. Skattebo scored a touchdown in two of the past three games and had seven goal-to-goal carries. Plus, with his pass-catching ability (12 receptions), Skattebo could find the end zone on an underneath throw from quarterback Jaxson Dart. The Saints has allowed nine touchdowns through the air this season, which is tied for third worst in the league.\n\nAll of ESPN. All in one place. Watch your favorite events in the newly enhanced ESPN App. Learn more about what plan is right for you. Sign Up Now\n\nBrowns CB Denzel Ward gets another interception versus Vikings\n\nMinnesota quarterback Carson Wentz threw two interceptions last week against the Steelers, and his 38.7 QBR was third worst out of all quarterbacks who started the past two weeks. Behind a Browns defensive front that has generated a pressure rate of 37.8%, the fifth highest in the league, Ward will have opportunities to make plays on the ball, especially when Wentz's decision-making declines late in the down. Ward notched his first interception of the season versus the Lions in Week 4.\n\nLions WR Jameson Williams catches a pass over 25 yards against the Bengals\n\nThe Bengals' defense has allowed six completions of 25 or more yards this season, and I like Williams to create an explosive play. He has seen seven targets of 25 or more air yards through four games, including four against the Browns (only one resulted in a reception). Look for the Lions to set up Jared Goff on a deep shot here, with Williams stretching the defense at the third level.\n\nMaldonado: My favorite bet for Week 5\n\nOVER 47.5 points in Las Vegas Raiders at Indianapolis Colts\n\nThe Colts move the ball better than almost anyone, leading the league in success rate (52.8%) and averaging over 7.0 yards on first down. The Raiders' defense has struggled to get stops, especially in the red zone, where opponents are scoring touchdowns nearly 89% of the time. Indianapolis QB Daniel Jones should also thrive against Las Vegas' heavy Cover 3 looks.\n\nWhile the Raiders' offense is inconsistent, Indy's defense isn't exactly shutting anyone down either, ranking near the bottom in success rate and red zone efficiency. Both teams should finish drives, and if the Raiders are chasing points late, that only helps this matchup to hit the over.",
      "source": "ESPN",
      "url": "https://www.espn.com/nfl/story/_/id/46449711/2025-nfl-week-5-predictions-fantasy-sleepers-upsets-bets-stats-matchups",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Hell freezes over: AMD may team up with Intel to produce chips - but I don't expect Intel foundries to push out Ryzen CPUs anytime soon",
      "content": "Intel in talks to produce AMD chips despite major technology hurdles\n\nAMD may shift limited production to Intel while protecting flagship processors\n\nWashington favors US chipmaking as Intel woos investors and potential customers\n\nBack in February 2025, well before everyone suddenly got interested in throwing money at Intel, I wrote that the iconic but beleaguered chip maker could be about to merge with GlobalFoundries - a rumor made all the more salacious as GloFlo is AMD’s former foundry.\n\nThe headline I gave it started with “Hell freezes, pigs fly” because frankly it seemed like an unlikely situation.\n\nFast forward to now, and Semafor is reporting that Intel is in early talks to add AMD as a foundry customer, which isn’t as unlikely as it would have been a few months ago, but still…\n\nNot flagship chips though\n\nIntel has been on something of a charm offensive lately, seeking customers and investors to back its push to establish itself as a contract chipmaker.\n\nIn recent weeks it has lined up financial support from the White House, Nvidia, and SoftBank, been in talks with Apple and TSMC, and no doubt had a few behind closed door conversations with other members of the so-called Magnificent 7.\n\nFor AMD, any foundry deal with Intel would be more than a little complicated. Its most advanced processors are built on TSMC’s leading-edge nodes, which Intel can’t yet match.\n\nThis makes it unlikely AMD would hand over production of its flagship products to its long-time rival.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAt best, the resurgent chip maker might win some lower-margin or less complex chips, which would still help diversify AMD’s supply chain and earn goodwill in Washington.\n\nAs a commenter on Tom’s Hardware suggested, “I am wondering if AMD will make the embedded (low power APUs) and networking (Pensando) stuff in Intel's fabs. That would make the most sense to me, due to supply distances. Makes little to no sense to do chips in the USA, send them to Taiwan/Malaysia and then back to the USA.”\n\nIt's not yet clear how far discussions have gone, or whether they would involve AMD taking a direct stake in Intel’s foundry arm, as other partners have done.\n\nSemafor says both companies have so far declined to comment on the matter.\n\nFollow TechRadar on Google News and add us as a preferred source to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!\n\nAnd of course you can also follow TechRadar on TikTok for news, reviews, unboxings in video form, and get regular updates from us on WhatsApp too.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/hell-freezes-over-amd-may-team-up-with-intel-to-produce-chips-but-i-dont-expect-intel-foundries-to-push-out-ryzen-cpus-anytime-soon",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Ultra-rare unreleased Pentium 4 with 4.0 GHz clock speed discovered — CPU-Z confirms it is an Intel Pentium Extreme Edition 980",
      "content": "A rare Intel engineering sample from the twilight of the Pentium 4 era has surfaced on social media. We’ve never seen this 4.0 GHz chip before. On Reddit, the current owner of the purported Intel Pentium Extreme Edition 980 processor, diegunguyman, has shared photos of the chip, both front and back, along with a CPU-Z screenshot for some deeper technical details. Due to quirks with the CPU-Z app/online database, this CPU won’t validate correctly.\n\nDiegunguyman reached out on various Subreddits to try and glean more insight into his find. The basic backstory was that “The only text on the CPU itself was written in Sharpie, just the model number and clock speed, 4 GHz.” With no official documentation to reference, the Redditor turned to experts on Subreddits like r/pcmasterrace and r/Intel to seek answers.\n\nA rare breed\n\nThis particular dual-core Hyperthreaded ‘Presler’ P4 is a very interesting sample for a number of reasons. Firstly, the collective wisdom of the flock of attentive Redditors interested in this story indicates that the sample now owned by diegunguyman was likely a loaner chip given to an employee.\n\nThese Employee Loaner Chips are rarer than typical Engineering Samples (ES). Their rarity is probably bolstered by the strict terms of the loan. However, a purported Intel ‘insider’ on Reddit indicates that due to the extensive layoffs at the firm, policing of the loaner system has evaporated.\n\nAnother interesting aspect of this CPU is the reasons that the public never saw with the pinnacle of NetBurst. It is now a matter for the history books, but the processor line already had a poor reputation for its thermals and performance, which played a part.\n\nPivot: Plan B becomes Plan A\n\nWhat likely sealed this ‘ghost’ processor’s fate was Intel’s strategic pivot. Management was already shifting focus to the legendary Core 2 lineup, built on the mobile-first Core microarchitecture. Then we saw Intel’s marketing shift to focusing on the entirely reasonable performance-per-watt metric, and the NetBurst design was quickly relegated to history, with budget / entry-level chips being the primary beneficiaries.\n\nIt is probably fair to say Intel’s Haifa design team and its mobile-first Core microarchitecture were Intel’s saviors. From mid-2006, the new performance-per-watt tuned chips managed to effectively stall the momentum of AMD’s contemporaneous CPUs like the Athlon 64 and X2 designs on the desktop.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/ultra-rare-unreleased-pentium-4-with-4-0-ghz-clock-speed-discovered-cpu-z-confirms-it-is-an-intel-pentium-extreme-edition-980",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "China's Zhaoxin breaks into healthcare: 6,000+ hospital PCs run x86 chips against Intel, AMD",
      "content": "China's Zhaoxin breaks into healthcare: 6,000+ hospital PCs run x86 chips against Intel, AMD\n\nShanghai Zhaoxin Semiconductor has scored a breakthrough in China's healthcare sector. On September 23, the x86 chipmaker announced that over 6,000 of its processor-powered desktops won a major hospital procurement bid, an important step for Chinese x86 CPUs in mission-critical medical deployments.\n\nChina's healthcare system is in the midst of rapid digital transformation, with ambitious goals to modernize core hospital information systems by 2025. The transition requires computing platforms that are both powerful and easy to deploy, critical traits in an industry long burdened by fragmented IT ecosystems.\n\nChina's healthcare IT fragmentation\n\nFragmentation remains one of healthcare IT's biggest challenges. Core systems such as hospital information systems (HIS), laboratory information systems (LIS), and picture archiving and communication systems (PACS) still depend on foreign databases like Oracle and SQL Server, which command over 80% market share. Domestic databases account for less than 15%, and migrating decades of records is complicated by format incompatibility and strict real-time demands.\n\nAt one leading provincial hospital, 40% of legacy HIS systems still run on outdated VB6 architecture, with upgrades costing up to CNY800,000 (approx. US$112,500) per system. Provinces are now piloting phased adaptation, rushing \"emergency fixes\" for critical platforms like PACS, while allowing a three-year transition for non-core systems such as office software. The dual-track approach underscores the clash between policy mandates and technical realities.\n\nSmaller hospitals face even sharper challenges: nearly 30% of their systems are too old to run domestic operating systems or new applications, leaving them stuck between costly legacy reuse and risky data migration.\n\nZhaoxin's processor ecosystem strategy\n\nZhaoxin is tackling these pain points with processors that combine compatibility and performance. The firm has independently developed six generations of high-performance CPUs, including the KaiXian desktop and KaiSheng server lines, with products spanning AI PCs, desktops, notebooks, all-in-ones, servers, and embedded platforms.\n\nThe chips support both domestic operating systems: UnionTech Software UOS, NeoKylin, Zhongkefangde Software, and Microsoft Windows. They are compatible with mainstream applications, cloud platforms, databases, development tools, and AI models, while keeping software migration costs low.\n\nFor healthcare, Zhaoxin has introduced \"seamless migration\" and \"one-stop support\" solutions. It has also set up medical application innovation centers with partners, offering hospitals end-to-end guidance from chips to operating systems and applications.\n\nToday, Zhaoxin works with nearly 4,000 partners across systems integration, software, and hardware. Together with domestic OS vendors, it has completed more than 200,000 software-hardware adaptation projects, building a full-stack ecosystem from processors to databases and applications.\n\nFrom 2022 to 2024, Zhaoxin recorded revenues of CNY340 million, CNY555 million, and CNY889 million, respectively, with a compound annual growth rate of 61.71%.\n\nRivaling Intel and AMD in hospitals\n\nBeating out Intel and AMD in a high-profile bid highlights Zhaoxin's progress in performance, compatibility, and cost efficiency. Its processors are built to handle demanding healthcare workloads — from electronic medical records to telemedicine platforms — while maintaining stable operations.\n\nWith integrated security, Zhaoxin CPUs protect patient data across its lifecycle: collection, transmission, storage, and use. This meets China's strict compliance standards, as hospitals lean on secure, high-performance platforms for data-heavy applications.\n\nAs digitalization accelerates, medical data will expand from text records and lab reports to imaging archives and real-time vital signs. Zhaoxin's processors can manage these workloads, minimizing downtime and enabling use cases such as AI diagnostics and cross-regional data sharing.\n\nChina's x86 chips gain traction\n\nThe hospital bid underscores the rising role of Chinese x86 chips in public welfare sectors. By offering strong performance and ecosystem compatibility, Zhaoxin is gaining ground in healthcare digitalization, an arena once dominated by foreign technology.\n\nIf sustained, these gains could speed the localization of hospital IT infrastructure, supporting China's drive for tech independence while laying the groundwork for smarter, more secure healthcare systems.\n\nArticle edited by Jack Wu",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250924VL209/x86-chips-smart-healthcare-shanghai.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "These Stocks Are Moving the Most Today: Wolfspeed, Boeing, Nvidia, Intel, Jefferies, Firefly Aerospace, and More",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b51f9bf708268820",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Qualcomm’s Snapdragon X2 Elite: The good, the bad, and the ugly",
      "content": "Qualcomm’s scintillating new Snapdragon X2 Elite chips have prompted a ton of conversations in the past few days. Can they make it? What do you like about them? And so on.\n\nWhile I can’t say whether or not the Snapdragon X2 Elite and Elite Extreme will eventually succeed, I can offer you an inside look at what people are talking about–at least what I’ve heard and overheard–at Qualcomm’s Snapdragon Summit in Hawaii. If you want to catch up on all the news, the Snapdragon X2 and X2 Elite offer more cores at up to 5GHz speeds, includes optional embedded memory, and preserves the performance on battery from the first generation.\n\nThe good: eye-watering performance\n\nIf you want a general-purpose productivity laptop, the first-generation Snapdragon X Elite was nearly perfect. The new X2 Elite Extreme looks to be even better, with (controlled) benchmarks that simply blow away Intel’s Core Ultra (Lunar Lake) and AMD’s Ryzen AI 300 chips, from CPU to GPU to the AI-enabling NPU. Qualcomm is really doing almost everything consumers are asking of it in this space.\n\nThe CPU benchmarks look particularly juicy. Compared against rival chips in today’s laptops, the Snapdragon X2 Elite absolutely smokes all comers in the Cinebench benchmark beloved by reviewers, in both single- and multi-core tests.\n\nMark Hachman / Foundry\n\nAnd the Snapdragon X2 Elite’s NPU offers a whopping 80 TOPs, leaving the competition in the dust. Whether consumers are asking for more TOPS from an NPU, though, is a question mark.\n\nRoughly doubling the TOPS from the first version looks great on paper, and certainly bigger numbers are better. But there’s a lot being bet on whether consumer applications will be able to take advantage of its prowess, including this concept of agentic AI everyone is talking about. No one is still quite sure whether that will happen.\n\nUL’s Procyon Computer Vision benchmark tests AI inference performance and can tap into NPUs, unlike some other AI benchmarks. Mark Hachman / Foundry\n\nIt depends on how you see it: Is local AI still a selling point? Either way, the Snapdragon X2 Elite appears loaded with hardware capable of blasting through most of the tasks you throw at it, AI or not.\n\nThe bad: Lukewarm PC vendor support, games, and lack of battery life talk\n\nI couldn’t help but notice that only Asus and HP endorsed the Snapdragon X2 architecture, and via video to boot — not in person at the Snapdragon Summit. The odd “agentic AI” Humain Horizon Pro laptop (which won’t use the X2, but the X1) was there, but not Qualcomm’s established customers. And where was longtime Qualcomm backer, Lenovo?\n\nSure, new partners could always be announced. But I had questions.\n\nAnother question: 3D graphics performance. Yes, supposedly the Snapdragon X2 Elite about doubles the performance of the first-gen X Elite platform, which played (some) games at roughly 30 frames per second at 1080p Low performance. Doubling that is, what, 60 fps at the same resolution and image quality? What about all the games that simply refuse to run well on the first-gen Snapdragon chips?\n\nOn the more enthusiast end of things, “there’s nothing preventing” the Snapdragon X2 from connecting to a discrete GPU like Nvidia’s GeForce RTX, according to Qualcomm’s senior vice president Kedar Kondap…but it doesn’t appear like it has, or will. This is a tough one: Gaming is often seen as a high-profile design win, and proof that a chip like the X2 Elite should be seen as a sexy, high-margin gaming CPU. But doing so would immediately cut into a key Snapdragon benefit: long battery life.\n\nGaming on a phone, weirdly, seems more viable with a Qualcomm Snapdragon processor than on a PC. Qualcomm\n\nAnd that was weird, too: Qualcomm really downplayed the battey life of a Snapdragon X2 laptop, referring it to “multi-day” on a couple of occasions. I’m not sure if that was because the competitive landscape had erased that advantage, or what. But it simply was not a big focus.\n\nAgain, Qualcomm does have a cross to bear in its Arm legacy, and how that affects application compatibility. This only really affects some weird, dusty old business utilities, the occasional printer, and games. But games are the one area where it can make inroads, though Snapdragon simply can’t offer the “it just works” assurance of its X86 rivals anytime soon.\n\nThe ugly: A grab bag\n\nNaturally, any new launch offers opportunities for criticism.\n\nNot only did people take issue with the Microsoft-esque naming scheme — the X2 Elite Extreme, really?! — critics made the very valid point that this was Qualcomm’s first major architecture launch in years. Reviewers got hands-on tests of the X1 Elite two long years ago, in October 2023, ahead of the Snapdragon’s launch alongside Copilot+ PCs in May 2024. Qualcomm followed it up with the cut-down X1 Plus and X in the interim.\n\nAs one attendee pointed out, “You can’t play on that timetable and expect to win against Intel and AMD,” which launch a new or updated mobile chip architecture on an annual cadence.\n\nIntel has been talking about Panther Lake for months…and has already shown more demo systems than Qualcomm has for the X2 Elite. Adam Patrick Murray / Foundry\n\nQualcomm’s X1 Elite also signaled to Intel and AMD that those rivals needed to have their own chips in order. But tying Snapdragon X to Copilot+ and Microsoft’s beleaguered Recall didn’t do much for Qualcomm, if anything. Qualcomm was the flag-bearer for Windows on Arm, and its (now largely undeserved) reputational concerns about app compatibility. Then Intel’s Lunar Lake came along, and offered a very competitive — and maybe even better — chip without any of that baggage.\n\nOne laptop maker told me that they had bought into the original X1 Elite in part as a bargaining chip with Intel. People had a lot of questions about what that meant for Intel’s upcoming “Panther Lake” chip, which should be unveiled this fall.\n\nIn my personal opinion, one of the best things Qualcomm ever did was to simply offer a compelling third option to Intel and AMD. That means we all benefited from an competitive market for PC processors that only continues to heat up.\n\nDisclosure: Qualcomm held its press briefings in Hawaii, and would not pre-brief reporters in other locations or over video meetings. They paid for my room, boarding, and travel expenses, but did not ask for or exert any editorial control over this story or other PCWorld content.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2922904/qualcomms-snapdragon-x2-elite-the-good-the-bad-the-ugly.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Intel, AMD & Arm All Have Notable EDAC Driver Additions For Linux 6.18",
      "content": "The Error Detection And Correction \"EDAC\" subsystem continues seeing a lot of new hardware support and code churn across AMD, Intel, and Arm hardware platforms for the Linux kernel. With Linux 6.18 there are several notable additions.A new EDAC driver for Linux 6.18 is \"a72_edac\" as EDAC support for the Arm Cortex-A72 . While the Arm Cortex-A72 cores have been out for years, with Linux 6.18 there is finally this EDAC driver for being able to report L1 and L2 cache errors with the mainline kernel.Another new EDAC driver for Linux 6.18 is for the AMD Versal NET DDR memory controller for these AMD-Xilinx Versal SoCs.Also on the AMD side, and as noted in the earlier article about the many AMD CPU features in Linux 6.18 , there are a number of new AMD CPU models added to the AMD64 EDAC driver. As explained there the new CPU support appears to include both next-gen AMD EPYC Zen 6 processors with up to 16 memory channels as well as some unreleased Family 26 models limited to 8 memory channels -- perhaps next-gen AMD EPYC 8004 parts?\n\nOn the Intel side, there is support for two more Alder Lake S SoCs added to the ie31200_edac driver. Those Alder Lake S parts added are the Intel Core i7-12700K and Core i5-12600K processors that were mistakenly left out of the driver previously for those prior-generation CPUs.The Intel EDAC driver code has also become more flexible for better handling the addition of new generations of CPUs with more memory controllers.More details on all of the EDAC feature changes for Linux 6.18 via this pull request",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-EDAC",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "US Stock Markets Today: S&P 500, Nasdaq Open In Red Amid Government Shutdown Indications",
      "content": "Wall Street benchmarks witnessed a slippery start on Tuesday, with investor sentiment taking a hit on US Vice President JD Vance's indication of a government shutdown.\n\nAn hour into trade, the Dow Jones Industrial Average saw a decline of 0.18%, the S&P 500 was also down 0.14% while Nasdaq fell 0.10%.\n\nThe uncertainty comes as the S&P 500 is headed for its best September in 15 years, fuelled by looser policy and optimism over artificial intelligence as per news agency Bloomberg.\n\n“The main focus will be the US labor market, which should either confirm or challenge expectations of two more rate cuts in 2025,” said Susana Cruz, a strategist at Panmure Liberum told Bloomberg. “If the shutdown delays the release, that could spark some anxiety.”\n\nSix of the 11 sectoral indices was trading in green. Energy sector led the decline, while the healthcare sector led the advancing sectors.\n\nNvidia Corp., Palantir Technologies, and Alibaba ADR were amongst the gainers for the day. On the other hand, Tilray Inc., Intel Corp., and Tesla were in the red.\n\nSpot gold rose 0.34% to $3,847.03 an ounce after paring record highs. After surging more than 10% this month on optimism over US interest rate cuts and haven demand, traders speculated that Chinese investors pared exposure ahead of the Golden Week holiday, as per Bloomberg.\n\nCrude oil prices slipped, with the West Texas trading 1.77% lower at $62.33 per barrel.\n\nThe Bloomberg Dollar Index fell 0.16%, with the British Pound rising 0.15% at $1.3449 and the Japanese yen down to 147.82 per dollar. Bitcoin, the largest traded cryptocurrency saw a decline of 0.95% to $113,233.9700.\n\nAs the US market opened, the Dow Jones Industrial Average fell 12 points or 0.03%, the S&P 500 was also down 0.12% while Nasdaq fell 0.22% or nearly 50 points.",
      "source": "Ndtvprofit.com",
      "url": "https://www.ndtvprofit.com/markets/us-stock-markets-today-sp-500-nasdaq-open-in-red-amid-government-shutdown-indications",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Stock Market Today: Dow, S&P 500, Nasdaq Set to Open Down as Government Shutdown Nears; Dollar Falls; Bitcoin Prices Recover; China Data; Wolfspeed Stock, Intel, Nvidia and More Movers",
      "content": "LIVE\n\nStock Market News Today: Dow Set to Open Down Amid Government Shutdown Risk\n\nThe S&P 500 and the Nasdaq are also falling in premarket trading. Treasury yields are down and Bitcoin prices are up.\n\nLast Updated:\n\nSep. 30, 2025 at 4:00 AM ET\n\nKey Events\n\nLatest Updates\n\nStock futures were…\n\nThis story appeared on barrons.com , 2025-09-30 07:24:23.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/30e44d3fa686ff85",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "The Linux kernel just got some important upgrades - here's what's new in 6.17",
      "content": "Jon Hicks/Stone/Getty Images\n\nFollow ZDNET: Add us as a preferred source on Google.\n\nZDNET's key takeaways\n\nLinux 6.17 features significant CPU improvements.\n\nIt addresses the eternal Spectre and Meltdown security holes.\n\nThe next release, 6.18, will be a long-term support kernel.\n\nLinus Torvalds is the first to admit that there have been more exciting Linux kernel releases. He announced the release of the 6.17 Linux kernel by writing, \"It's not exciting, which is all good. I think the biggest patch in there is some locking fixes for some Bluetooth races that could cause use-after-free situations. Whee -- that's about as exciting as it gets.\"\n\nAlso: 5 of my favorite Linux distros ready to use out of the box - no setup required\n\nWith that said, 6.17 does come with some notable performance boosts, expanded hardware support, and a medley of improvements aimed at server, desktop, and embedded systems.\n\nThe most important of these improvements is for the AMD Ryzen chip. By delivering improved hardware feedback scheduling for Ryzen chips via the new Hardware Feedback Interface (HFI) driver, hybrid-core laptops and desktops will be more intelligent in handling workload distribution with SmartMux support. The feature works by auto-switching between integrated and discrete graphics based on your workload. So, depending on what you're doing, it can either save power or boost your performance as needed.\n\nAlso: Is this Arch distro the 'ultimate' Linux? That depends on your GPU\n\nMeanwhile, Intel-powered computers are gaining better graphics support. That's especially true for the forthcoming Xe3 (Panther Lake) systems. You'll see these chips in Core Ultra Series 3 laptops by the holidays. Early tests indicated that Linux desktop gamers can expect significant speed improvements in some of their favorite games. Linux 6.17 also comes with Error Detection and Correction (EDAC) support for Intel's Bartlett Lake processors. EDAC is the mechanism used to spot, report, and correct memory errors.\n\nNot every processor will see improvements with 6.17. Some proposed RISC-V patches ticked off Torvalds because they were both late and poorly written. He described them as: \"Garbage. And by 'garbage,' I really mean it. This is stuff that nobody should ever send me, never mind late in a merge window.\" Better luck next release, folks.\n\nThis release also revamps CPU vulnerability management by unifying kernel command-line mitigation options for ancient security holes, such as Spectre and Meltdown. Despite their age, these security problems persist. The new kernel makes it easier for server administrators to streamline performance tweaks and security controls.\n\nOn the storage front, Btrfs gains experimental large-folio support for efficient memory access. In the same release, the most popular Linux file system, Ext4, introduces buffered I/O control. Two new system calls, file_getattr() and file_setattr(), are included for advanced inode file system attribute management.\n\nAlso: I install these 11 apps on every new Linux system, and you should, too - here's why\n\nFor networking, the enhancements include new gateway routing for the Management Component Transport Protocol (MCTP), expansion of the multipath TCP feature, and added support for the DualPI2 congestion control protocol.\n\nLinux 6.17 is not a long-term support (LTS) release. Users who require extended support can stick to 6.12 or wait for the anticipated 6.18 LTS milestone.\n\nAlso: How much RAM does your Linux PC really need in 2025? I did the math so you don't have to\n\nDistributions such as the forthcoming Ubuntu 25.10, currently in beta, have already adopted 6.17 in their latest builds. You can expect to see cutting-edge, rolling distributions, such as Arch Linux, openSUSE Tumbleweed, and Fedora Rawhide, release the 6.17 kernel in the next few days and weeks.\n\nAs usual, the release opens the merge window for kernel 6.18, with dozens of pull requests queued up for review by Torvalds and the core maintainers. Since it will be an LTS release, I expect to see significant improvements in this anticipated end-of-the-year release.",
      "source": "ZDNet",
      "url": "https://www.zdnet.com/article/the-linux-kernel-just-got-some-important-upgrades-heres-whats-new-in-6-17/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Intel's original 64bit extensions for x86",
      "content": "Intel’s original 64bit extensions for x86\n\nIntroduction\n\nIn the late 1900s, Intel was fully invested in Itanium (IA-64) being their future 64bit architecture.\n\nAt that time (allegedly around 1997-1998), some Intel engineers – who were more cautious than their management – built a 64bit extension for their x86 processors as a backstop. It never shipped:\n\nIntel’s Pentium 4 had our own internal version of x86–64. But you could not use it: we were forced to “fuse it off”, meaning that even though the functionality was in there, it could not be exercised by a user.\n\nThis was a marketing decision by Intel — they believed, probably rightly, that bringing out a new 64-bit feature in the x86 would be perceived as betting against their own native-64-bit Itanium, and might well severely damage Itanium’s chances.\n\n– Bob Colwell\n\nAMD announced AMD64, their own 64bit extension to x86, in 1999 (and shipped it in 2003), condemning both Itanium and Intel’s own x86 extension to obscurity.\n\nIntel implemented AMD’s design in Project Yamhill and shipped its first processors with AMD64 in 2004.\n\nHow did Intel’s design look like?\n\nWhile AMD’s 64bit extension design that repurposed inc/dec instructions as the REX prefix is well-documented, there is very little known about Intel’s own 64bit extension design.\n\nHere is what can be reconstructed from Intel’s patent applications from 2000 and 2003:\n\nAn instruction having [a] format […] — where the mode field is 01B , the R/M field is 100B , the index field is 100B — has addressing mode information that is currently unsupported in the IA-32 architecture regardless of the value of the scale field.\n\nAn instruction of [that] format […] thereby includes heretofore unused bit fields (e.g., the two bits of scale field, bits of displacement, etc.), that can support an expanded logical register set for existing instructions formats and legacy operands.\n\nMaterial from the Bristol Community College also mentions this specific combination of bits:\n\nNote that this addressing mode does not allow the use of the ESP register as an index register.\n\nPresumably, Intel left this particular mode undefined to provide the ability to extend the addressing modes in a future version of the CPU.\n\nDifferences from AMD64\n\nAMD’s REX prefix introduced 1 bit R to extend the 3-bit register to 4 bits, allowing access to 16 registers.\n\nThe prefix also added 1 bit W to extend operand size, 1 bit X to extend SIB byte’s index and 1 bit B to extend SIB byte’s base.\n\nIntel’s approach would have added 2 additional bits to the existing 3-bit register encoding, and introduced a second, additional 5-bit register encoding.\n\nIt appears this encoding would have provided a future expansion possibility to 32 registers, even if the implementation may have been limited to 16 registers at first.\n\nIt is unclear what the equivalent of (or the alternative to) AMD64’s W , X and B bits would have been under Intel’s design.\n\nConclusion\n\nSadly, there is no definitive information on how close the patents were to what was shipped (fused-off) in Intel processors of that specific time period.",
      "source": "Soc.me",
      "url": "https://soc.me/interfaces/intels-original-64bit-extensions-for-x86.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Dave Bautista & Jack Champion in 'Trap House' Action Thriller Trailer",
      "content": "Dave Bautista & Jack Champion in 'Trap House' Action Thriller Trailer\n\n\"If we don't get 'em, the cartel will, right? And they don't forget...\" Aura Entertainment has unveiled the official trailer for Trap House, an action thriller from filmmaker Michael Dowse (of Fubar, Goon, What If, Stuber, 8-Bit Christmas). This is set for a full nationwide release in November just before the Thanksgiving holiday. Dave Bautista leading this story about rogue teens getting into big trouble! Trap House is centered on a team of elite DEA agents whose rebellious teenage children use their parents' own tactics—surveillance, infiltration, non-lethal weapons, and special intel—to rob a ruthless drug cartel. Along with Dave Bautista, the movie also stars Jack Champion, Sophia Lillis, Tony Dalton, Whitney Peak, Kate Del Castillo, Zaire Adams, and Bobby Cannavale. The tagline within the trailer: \"This isn't a raid. It's a reckoning.\" This is a totally nuts plot - the kids want to get revenge because the death benefits for a DEA agent are bad, so they decide to go rob the cartels all on their own? Yeah um that seems dangerous, remarkably dangerous.\n\nHere's the main official trailer (+ poster) for Michael Dowse's film Trap House, direct from YouTube:\n\nIn El Paso, Texas, an undercover DEA agent (Dave Bautista) and his partner embark on a game of cat and mouse with their own teenage children, who are using their parents' tactics – surveillance, infiltration, and non-lethal weapons – to rob a dangerous drug cartel. Trap House is directed by acclaimed Canadian filmmaker Michael Dowse, director of the movies Fubar & Fubar: Balls to the Wall , It's All Gone Pete Tong, Take Me Home Tonight, Goon, What If, Stuber, Coffee & Kareem, 8-Bit Christmas, plus the TV series \"Me\" and \"The Sticky\" most recently. The screenplay is written by Gary Scott Thompson and Tom O'Connor; from a story by Gary Scott Thompson. It's produced by Dave Bautista, Rebecca Feuer, Sarah Gabriel, Marc Goldberg, Todd Lundbohm, Jonathan Meisner, Christian Mercuri, and Michael Pruss. Aura Entertainment will debut Dowse's Trap House movie in US theaters starting November 14th, 2025 this fall. Look good?",
      "source": "First Showing",
      "url": "https://www.firstshowing.net/2025/dave-bautista-jack-champion-in-trap-house-action-thriller-trailer/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Intel Corporation (INTC): A Bull Case Theory",
      "content": "We came across a bullish thesis on Intel Corporation on Long-term Investing’s Substack by Sanjiv. In this article, we will summarize the bulls’ thesis on INTC. Intel Corporation's share was trading at $31.22 as of September 24th. INTC’s trailing and forward P/E were 88.08 and 47.39 respectively according to Yahoo Finance.\n\nIntel (INTC) Stock: Morgan Stanley Reiterates Equal Weight, Cautious on Turnaround\n\nPhoto by Slejven Djurakovic on Unsplash\n\nIntel Corporation (INTC) has been navigating a turbulent period following setbacks in 2020, with the company working to regain its footing in advanced chip manufacturing. As of mid-2024, Intel had returned to leading-edge production through substantial investments, under a dual strategy of partially outsourcing manufacturing while trying to make Intel Foundry Services (IFS) profitable—a goal management does not expect to achieve until 2030.\n\nDespite these efforts, the company’s competitive position remains challenging, particularly versus TSMC and Samsung, the dominant players in 3nm–5nm semiconductor manufacturing, and the market initially remained skeptical, with INTC shares declining sharply after disappointing Q2 results in August 2024.\n\nMomentum shifted dramatically in 2025 following a series of strategic developments. Pat Gelsinger’s departure as CEO in March and the appointment of Lip-Bu Tan coincided with the U.S. government acquiring a 10% equity stake in Intel through undisbursed CHIPS Act grants and the Secured Enclave program, effectively designating Intel as a national champion for domestic chip production. This move was followed by major strategic investments from SoftBank and Nvidia, with Nvidia taking a $5 billion stake at $23.26 per share, signaling collaboration on AI-focused chips integrating Intel CPUs with Nvidia GPUs and expanding AI computing infrastructure.\n\nThese developments have propelled INTC shares sharply higher, with year-to-date gains of over 36% leading up to the Nvidia investment. While the market momentum is undeniable, Intel’s future performance will be influenced by government involvement in strategic decision-making and its ability to execute on these collaborations. The investment case now balances the potential upside from increased AI-related orders and strategic positioning against the complexity and uncertainty of government influence, making valuation challenging but the stock an intriguing prospect for investors watching U.S.-based semiconductor growth.\n\nPreviously we covered a bullish thesis on Intel Corporation (INTC) by DeepValue Capital in April 2025, which highlighted AI inference, domestic chip manufacturing, leadership under Lip-Bu Tan, and cost-cutting initiatives. The company's stock price has appreciated approximately by 59% since our coverage. This is because the thesis played out amid renewed investor confidence. Sanjiv shares a similar perspective but emphasizes government stakes and strategic partnerships with Nvidia and SoftBank as key catalysts.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/intel-corporation-intc-bull-case-144310896.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Ambitious Wee Beastie Project Aims To Put Desktop NVIDIA RTX 4070 GPU Into 4.75 L Chassis",
      "content": "A rift appears to be forming in the desktop PC market, with full-size desktops on one side and mini PCs on the other side. Of course, there is small, but dedicated community that has sprung up around SFF PCs, but those are often limited, with many calling for flex PSUs and other compromises. The Wee Beastie, a new project on Kickstarter , is a small form-factor PC that hopes to cut back on the compromises, claiming to offer a powerful gaming and LLM-oriented system with an upgradeable dGPU in just 4.75 L volume—this is just 0.25 L more than the Framework Desktop PC , which uses an AMD Ryzen AI+ 395 Max with an iGPU. That said, even the pre-release Kickstarter marketing leaves some questions.The Wee Beastie Super Mini Fishtank, as it is called, is a mini PC with up to an Intel Core Ultra 7 255H CPU and NVIDIA GeForce RTX 4070 12 GB GPU. It will also be available with up to 128 GB of DDR5 RAM and a 16 TB SSD, and it boasts Wi-Fi 7 and room for up to 13 case fans. It will also contain an internal PSU capable of 400 W, which technically falls well below the 550 W we recommend for a desktop RTX 4070. Although the GPU shown on the Kickstarter page has the \" AD104-251-A1\" associated with the desktop variants of the RTX 4070 , the PSU output suggests that there will be some power throttling or down-tuning at play, so RTX 4070 Mobile performance might be what's to be expected here. Often, the most challenging part of projects like these, as was the case with the custom expansion modules on the Framework Laptop 16 until recently, is supporting the MXM standard for future hardware revisions. Although MXM modules are technically an open standard, like ATX, it is not commonly used due to limited demand and size constraints. Currently, the Kickstarter has completed funding, having reached $53,763 of its $2,570 goal, and the SFF PC looks to be going into production as soon as 2026.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341473/ambitious-wee-beastie-project-aims-to-put-desktop-nvidia-rtx-4070-gpu-into-4-75-l-chassis",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Hance will demo its kilobyte-size AI audio processing software at TechCrunch Disrupt 2025",
      "content": "Hance is working on low energy-consuming, on-device processing that's already attracted the likes of Intel.\n\nThis story appeared on techcrunch.com , 2025-09-30 16:22:28.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/31a4a17bbcaa9dbc",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Optional Windows 11 September update adds tons of new preview features",
      "content": "Other Windows 11 bug fixes\n\nIn addition to new features, here are some noteworthy bug fixes:\n\nIn File Explorer, accented backgrounds are removed in the “Open with” list, overlapping icons and text is fixed when using increased text scaling, and cloud files launch faster now.\n\nAn issue when starting Hyper-V virtual machines with TPM on Arm64 devices has been fixed.\n\nAn issue where some characters didn’t display correctly when Chinese IME was being used.\n\nAn issue where you couldn’t connect to shared files and folders when using the SMB v1 protocol over NetBT was fixed.\n\nThere is still an issue where DRM content can fail to play in Blu-ray/DVD apps (but not in streaming apps like Netflix).",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2925329/optional-windows-11-september-update-adds-tons-of-new-preview-features.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Ukraine Preparing New High-Profile Provocation – Russian Intel",
      "content": "https://sputnikglobe.com/20250930/ukraine-preparing-new-high-profile-provocation--russian-intel-1122889214.html\n\nZelensky Preparing New High-Profile Provocation - Russian Foreign Intel\n\nZelensky Preparing New High-Profile Provocation - Russian Foreign Intel\n\nSputnik International\n\nRussian Foreign Intelligence Service reports that the Kiev regime, after organizing provocations with UAVs in the airspace of Poland and Romania, is not abandoning its attempts to draw European NATO countries into armed confrontation with Moscow.\n\n2025-09-30T08:45+0000\n\n2025-09-30T08:45+0000\n\n2025-09-30T09:22+0000\n\nworld\n\nukraine\n\nrussian foreign intelligence service\n\nrussia\n\nvolodymyr zelensky\n\nkiev\n\npoland\n\nnato\n\nhttps://cdn1.img.sputnikglobe.com/img/07e9/04/14/1121899180_0:160:3072:1888_1920x0_80_0_0_d7a560df4d542add4f92166fe5b4d4bb.jpg\n\n\"Kiev is preparing a new high-profile provocation. The Press Bureau of the Russian Foreign Intelligence Service reports that, according to information received by the Russian Foreign Intelligence Service, the Kiev regime, following its organized drone provocations in the airspace of Poland and Romania, is continuing its attempts to draw European NATO countries into an armed confrontation with Moscow. Another provocation is being developed,\" the SVR said in a statement.The new provocation includes a sabotage and reconnaissance group deployed to Polish territory, allegedly consisting of servicepeople from Russian and Belarusian special forces, the SVR also said, adding that the plan will be implemented by militants from the \"Freedom of Russia Legion*\" and the Belarusian \"Kalinouski Regiment\" fighting on the side of the Ukrainian armed forces.The provocation scenario was developed by the Main Intelligence Directorate of the Ukrainian Ministry of Defense jointly with Polish intelligence services, the SVR said.Kiev plans that after the \"neutralization\" of the sabotage and reconnaissance group by Polish security forces, its members will expose Russia and Belarus for attempting to destabilize the situation in Poland, the SVR said.*recognized as a terrorist organization, banned in Russia\n\nhttps://sputnikglobe.com/20250804/russian-intel-warns-of-uk-plan-to-stage-tanker-incident-1122550775.html\n\nukraine\n\nrussia\n\nkiev\n\npoland\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\n2025\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\nNews\n\nen_EN\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\n1920 1080 true\n\n1920 1440 true\n\n1920 1920 true\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\nSputnik International\n\nhigh-profile provocation, russian foreign intelligence service, organizing provocations",
      "source": "Sputnikglobe.com",
      "url": "https://sputnikglobe.com/20250930/ukraine-preparing-new-high-profile-provocation--russian-intel-1122889214.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Computer Vision Systems Market Expected to Reach USD 75.52 Billion by 2032, Fueled by Widespread AI and ML Adoption Worldwide | SNS Insider",
      "content": "Austin, Sept. 30, 2025 (GLOBE NEWSWIRE) -- The Computer Vision Systems Market Size was valued at USD 19.29 billion in 2024 and is expected to reach USD 75.52 billion by 2032 and grow at a CAGR of 18.63% over the forecast period 2025-2032.\n\nIncreasing use of computer vision due to the need for automation in the logistics, manufacturing, quality control, and medical diagnostics industries. Real-time processing made possible by developments in 3D vision, high-resolution imagery, and synchronized sensors to increase accuracy in areas like gesture tracking, facial identification, object detection, and automated optical inspection are some of the noteworthy results. Organizations may implement scalable and low-latency computer vision solutions thanks to the expanding trend of edge computing and cloud-based deployment models, which greatly boosts industry growth. Over 1,200 warehouses and logistics centers currently use real-time item detection, which enhances automated sorting and inventory tracking, according to the report.\n\n\n\n\n\nDownload PDF Sample of Computer Vision Systems Market @ https://www.snsinsider.com/sample-request/8447\n\nKey Players:\n\nNVIDIA\n\nIntel\n\nAMD\n\nQualcomm\n\nAmbarella\n\nTeledyne Technologies\n\nOmron Corporation\n\nKeyence Corporation\n\nMicrosoft\n\nAmazon Web Services (AWS)\n\nGoogle Cloud\n\nIBM\n\nOpenCV.ai\n\nRoboflow\n\nMatrox Imaging\n\nAllied Vision Technologies\n\nMobileye (Intel)\n\nTesla\n\nAptiv\n\nWorld Labs\n\nComputer Vision Systems Market Report Scope:\n\nReport Attributes Details Market Size in 2024 USD 19.29 Billion Market Size by 2032 USD 75.52 Billion CAGR CAGR of 18.63% From 2025 to 2032 Base Year 2024 Forecast Period 2025-2032 Historical Data 2021-2023 Report Scope & Coverage Market Size, Segments Analysis, Competitive Landscape, Regional Analysis, DROC & SWOT Analysis, Forecast Outlook Key Segments • By Component (Hardware, Software, Services)\n\n• By Deployment Mode (Cloud-based, On-premises, Edge computing devices)\n\n• By Application (Facial recognition, Image classification, Object detection, Object tracking, Optical Character Recognition (OCR), Image Segmentation, Automated optical inspection, 3D vision and depth sensing, Gesture recognition, Others)\n\n• By Industry Vertical (Manufacturing, Healthcare, Retail, Automotive, Security and surveillance, Agriculture, Smart cities, Consumer electronics, Energy and utilities, Others) Customization Scope Available upon request Pricing Available upon request\n\nIf You Need Any Customization on Computer Vision Systems Market Report, Inquire Now @ https://www.snsinsider.com/enquiry/8447\n\nSegmentation Analysis:\n\nBy Component, in 2024, Hardware Segment Led the Market with a Share 58.40%, while Services are the Fastest-growing Segment with a CAGR of 20.38%\n\nHardware component segment occupies a majority share in the Computer Vision Systems Market, largely owing to the large-scale deployment of high-resolution cameras, sensors and GPUs across various industrial verticals. The Services segment is experiencing the highest growth, supported by the growing need for software integration, training and support with AI models, maintenance, consulting, and assistance with cloud-based deploy.\n\nBy Deployment Mode, in 2024, On-premises Dominated the Market with a Share of 65.10%, while Edge Computing Devices Fastest-growing Segment with a CAGR 19.96%\n\nOn-premises deployment is leading the Computer Vision Systems Market, as many organizations like to process their sensitive data locally in order to guarantee security and have control over their critical operations, especially in industries, such as healthcare, manufacturing, and automotive Edge computing devices are having the highest growth rate due to the demand for data processing at real time, low latency applications, and AI based decision making at-edge level.\n\nBy Application, in 2024, Facial Recognition Led the Market with a Share 25.07%, while Object Detection the Fastest-growing Segment with a CAGR 20.24%\n\nFacial Recognition application segment dominated the Computer Vision Systems Market globally, in which computer vision technology is extensively adopted by the government, retail, and corporate sectors for security, surveillance, access control, and identity verification. Object Detection is growing fastest due to increasing need for real-time tracking, anomaly detection, and process optimization from autonomous vehicles, robotics, industrial automation, smart logistics, and others.\n\nBy Industry Vertical, in 2024, Manufacturing Dominated the Market with a Share of 32.03%, while Healthcare is the Fastest-growing Segment with a CAGR of 20.91%\n\nManufacturing tops the industry vertical in the Computer Vision Systems Market, as computer vision is increasingly used for factory deployment for quality inspection, defect detection, assembly verification, and automation globally. Healthcare is experiencing the quickest growth, which is attributed to the rise in uptake of diagnostic imaging, surgical assistance, patient monitoring, and medical image analysis powered by AI.\n\nIn 2024, North America Led the Market in 2024; Asia Pacific is Projected to be the Fastest Growing Region in the Market During 2025-2032\n\nThe computer vision systems market is propelled by the North America region as the market share 32.50%, owned by the early adopters of AI, machine learning, and advanced imaging technologies for various industries. Asia Pacific is a key and fast-growing market for Computer Vision System with a CAGR 19.74%, due to the rapid industrialization and urbanization along with the adoption of the latest technologies.\n\nRecent Developments:\n\nIn May 2024 , Ambarella launched the CV75S AI SoC family built on 5nm technology, enabling power-efficient multi-modal vision-language models and AI inference for cameras and robotics.\n\n, Ambarella launched the CV75S AI SoC family built on 5nm technology, enabling power-efficient multi-modal vision-language models and AI inference for cameras and robotics. In April 2024, Intel announced the Gaudi 3 AI accelerator at Intel Vision 2024, enhancing inference throughput and efficiency for large AI models in data centers and edge devices.\n\nBuy Full Research Report on Computer Vision Systems Market 2025-2032 @ https://www.snsinsider.com/checkout/8447\n\nExclusive Sections of the Report (The USPs):\n\nAlgorithm & Model Performance Metrics – helps you assess the efficiency and maturity of computer vision systems through accuracy and precision rates, real-time processing latency, and the frequency of model updates or optimizations.\n\n– helps you assess the efficiency and maturity of computer vision systems through accuracy and precision rates, real-time processing latency, and the frequency of model updates or optimizations. Human-Machine Interaction Metrics – helps you understand the impact of CV adoption on workforce efficiency by tracking reductions in manual errors, improvements in operator productivity, and user engagement across retail, AR/VR, and industrial applications.\n\n– helps you understand the impact of CV adoption on workforce efficiency by tracking reductions in manual errors, improvements in operator productivity, and user engagement across retail, AR/VR, and industrial applications. Security & Fraud Detection Metrics – helps you evaluate the reliability of CV systems in high-risk environments by analyzing false positive/negative rates, anomaly detection accuracy, and threat response time in surveillance and security applications.\n\n– helps you evaluate the reliability of CV systems in high-risk environments by analyzing false positive/negative rates, anomaly detection accuracy, and threat response time in surveillance and security applications. Product Lifecycle & Reliability Index – helps you measure the operational resilience of CV hardware by monitoring metrics like mean time between failures (MTBF), lifecycle duration of sensors and cameras, and maintenance cost savings achieved through automation.\n\n– helps you measure the operational resilience of CV hardware by monitoring metrics like mean time between failures (MTBF), lifecycle duration of sensors and cameras, and maintenance cost savings achieved through automation. Real-Time Processing Efficiency – helps you benchmark system responsiveness by analyzing average milliseconds per frame in real-time CV applications, enabling performance comparisons across industrial and edge deployments.\n\n– helps you benchmark system responsiveness by analyzing average milliseconds per frame in real-time CV applications, enabling performance comparisons across industrial and edge deployments. Operational Cost Optimization – helps you quantify ROI and cost-effectiveness by assessing reductions in maintenance expenses and productivity gains from automation-driven CV integration.\n\nAbout Us:\n\nSNS Insider is one of the leading market research and consulting agencies that dominates the market research industry globally. Our company's aim is to give clients the knowledge they require in order to function in changing circumstances. In order to give you current, accurate market data, consumer insights, and opinions so that you can make decisions with confidence, we employ a variety of techniques, including surveys, video talks, and focus groups around the world.",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/30/3158449/0/en/Computer-Vision-Systems-Market-Expected-to-Reach-USD-75-52-Billion-by-2032-Fueled-by-Widespread-AI-and-ML-Adoption-Worldwide-SNS-Insider.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "OpenAI might be building its own chip, but it’ll still be dependent on Nvidia — custom chip developed with Broadcom reportedly slips to Q3 2026",
      "content": "OpenAI's long-rumored $10 billion partnership with Broadcom is already showing cracks. The company is widely understood to be developing a custom chip designed specifically for OpenAI's inference workloads, but according to individuals familiar with the matter, the project has \"hit snags\": OpenAI wanted more power, sooner, than Broadcom could deliver, and an internal push to roll the chip out in Q2 2026 has already slipped to Q3 at the earliest, according to a report from The Information.\n\nThe project, which has been kept deliberately quiet, is set to have manufacturing run through TSMC. Once live, the chip could handle inference jobs across OpenAI’s growing fleet of data centers, cutting its exposure to GPU bottlenecks and potentially lowering costs.\n\nHowever, even as OpenAI lays the groundwork for its own silicon, it’s doubling down with Nvidia. A recent infrastructure agreement between the two companies, potentially worth more than $100 billion, would see Nvidia supply GPUs for the next wave of OpenAI-hosted AI clusters. Nvidia’s CEO Jensen Huang recently said that OpenAI “is likely going to be the next multi-trillion-dollar hyperscaler company,” with OpenAI remaining a cornerstone customer for Nvidia’s highest-end systems.\n\nThis, then, highlights the same paradoxical situation we’ve seen time and time again with AI. Amazon, Google, Microsoft, Meta, and now OpenAI are all building their own chips to reduce their reliance on Nvidia, while simultaneously relying on Nvidia more than ever.\n\nA hedge with no clear endgame\n\nBroadcom executives first confirmed what is believed to be the OpenAI deal late last year, saying that a large AI customer had booked billions in long-term orders. Reports quickly tied the deal to OpenAI, which has been growing a small, specialized in-house silicon team since at least mid-2023. The chip is understood to be designed for internal inference tasks and is not intended for commercial release. Broadcom handles the physical design, with TSMC expected to fabricate the chips.\n\nThis deal made OpenAI the latest entrant in a long line of hyperscalers trying to build their own chips. Amazon has its Trainium and Inferentia platforms. Google is now on its fifth-generation TPU. Microsoft is working on its Maia accelerators. Each was billed as a shift away from GPU dependency. Each still runs major workloads on Nvidia silicon.\n\nOpenAI doesn’t shy away from this fact. Its GPT-4 model was trained on Nvidia H100s, and its hosting partners — including CoreWeave and Microsoft — continue to deploy Nvidia hardware at scale. The new custom chip effort might eventually take over some inference jobs, but there’s no evidence it will replace H100 or Blackwell-class GPUs for training. And even if the silicon performs well, it won’t come bundled with Nvidia’s competitive software stack.\n\nThere’s no matching CUDA\n\nThis is the piece challengers still can’t match. Nvidia’s CUDA platform remains the default target for nearly every AI framework in use today. From PyTorch and TensorFlow to popular model compilers and quantization toolkits, most of the AI software stack is optimized for Nvidia’s architecture. Migrating off it means rewriting core libraries, retraining engineers, and adapting models to new hardware, which, ultimately, is a cost few companies are willing to absorb.\n\nOpenAI, like others, is unlikely to abandon CUDA without a compelling reason. Broadcom doesn’t offer its own software ecosystem, which means OpenAI’s team would need to build its own toolchain or adopt one of the open standards still struggling to reach parity. In the meantime, the easiest, fastest way to build and run large-scale models is still with Nvidia’s chips and software.\n\nJensen Huang knows this. Holding an iron grip over the industry, he’s reportedly given a heads-up by the likes of Amazon and Google before they announce a new chip that might compete with Nvidia’s. All this is done on the down low and, according to reports, has become something of an unwritten rule. It’s not required, but it happens, and it shows the degree to which Nvidia still commands power among its customers, even those building chips to hedge against Nvidia.\n\nIt’s not difficult to understand why this is the case. Nvidia is pouring billions into partnerships, infrastructure, and component sourcing. It recently agreed to buy up to $6.3 billion in unused GPU capacity from CoreWeave, invested nearly $1 billion to license Enfabrica’s networking tech, and paid Intel $5 billion as part of a joint development pact. It even agreed to support OpenAI’s next generation of GPU data centers despite OpenAI’s clear intent to use its own chips at some point.\n\nSupply chain headwinds\n\nEven if the OpenAI chip meets its performance goals, it faces supply chain headwinds. CoWoS packaging is still bottlenecked at TSMC, with Nvidia and AMD making up much of the near-term capacity. Advanced HBM memory is also under pressure, with SK hynix and Samsung prioritizing existing customers. So, while Broadcam can bring design expertise, it has no control over the back-end. Nor does OpenAI.\n\nThere’s also the question of scale. Nvidia’s Blackwell platform uses multi-chip modules, enormous memory bandwidth, and proprietary NVLink switching, a monolithic combination that Broadcom can’t offer. If OpenAI’s chip is simpler, it may be cheaper or more efficient per watt, but it also won’t be competitive on peak performance, which limits its value in training future large models.\n\nAll of these point toward a long-term hybrid model, where OpenAI uses both Nvidia and its own custom hardware depending on workload. Which, again, is what all the other hyperscalers are already doing.\n\nThe Broadcam partnership does make some sense for OpenAI from a strategic standpoint. If it ships on time (which looks unlikely) and performs well, it could reduce cost per token and give the company a touch more control over its infrastructure. But early signs aren't encouraging, and, in any case, it won’t be a silver bullet that replaces Nvidia's hardware for training cutting-edge models.\n\nFollow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/semiconductors/open-ai-building-its-own-chip-still-dependent-on-nvidia",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Qualcomm promises it can be an AI winner. What does it know that Nvidia and Intel don’t?",
      "content": "Qualcomm shares may have more growth potential than the market is currently pricing in —but some big hurdles lie ahead.\n\nThis story appeared on marketwatch.com , 2025-09-30 20:58:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/f4b81fbd766411b5",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Synopsys, Inc. (SNPS) Shares Suffer Worst Day Ever Amid Q325 Results Revealing Problems With Major Foundry Customer -- Hagens Berman",
      "content": "SAN FRANCISCO, Sept. 30, 2025 (GLOBE NEWSWIRE) -- On September 10, 2025, investors in Synopsys, Inc. (NASDAQ: SNPS) saw the price of their shares crater over $216 (-36%) after the company reported its Q3 2025 financial results and revealed significant problems with a major foundry customer.\n\nThe development has prompted national shareholders rights firm Hagens Berman to open an investigation into whether Synopsys may have misled investors about its customer risks and growth prospects.\n\nThe firm urges investors in Synopsys who suffered significant losses to submit your losses now. The firm also encourages persons with knowledge who may be able to assist in the investigation to contact its attorneys.\n\nVisit: www.hbsslaw.com/investor-fraud/snps\n\nContact the Firm Now: SNPS@hbsslaw.com\n\n844-916-0895\n\nSynopsys, Inc. (SNPS) Investigation:\n\nIn the past Synopsys has assured investors that, while its largest customer (Intel) had reduced its R&D spend, “it does not impact generally the EDA software[]” and downplayed risks based on its “committed, non-cancellable” agreements with Intel involving a mix of EDA software, IP, and hardware.\n\nThe company’s assurances may have come into question on September 9, 2025, when Synopsys reported its Q3 2025 financial results and shockingly guided for Q4 2025 GAAP EPS of negative $0.27 to negative $0.16.\n\nDuring the earnings call, management revealed the company’s underperformance in its IP business and said it was significantly due to “challenges at a major foundry customer” that is “also having a sizeable impact on the year[.]”\n\nThis news drove the price of Synopsys shares down 36% the next day, its worst-ever single-day percentage decline since going public in 1992.\n\n“We’re investigating whether Synopsys may have misled investors about risks posed by its high concentration with a single customer,” said Reed Kathrein, the Hagens Berman partner leading the investigation.\n\nIf you invested in Synopsys and have substantial losses, or have knowledge that may assist the firm’s investigation, submit your losses now »\n\nIf you’d like more information and answers to frequently asked questions about the Synopsys investigation, read more »\n\nWhistleblowers: Persons with non-public information regarding Synopsys should consider their options to help in the investigation or take advantage of the SEC Whistleblower program. Under the new program, whistleblowers who provide original information may receive rewards totaling up to 30 percent of any successful recovery made by the SEC. For more information, call Reed Kathrein at 844-916-0895 or email SNPS@hbsslaw.com.\n\nAbout Hagens Berman\n\nHagens Berman is a global plaintiffs’ rights complex litigation firm focusing on corporate accountability. The firm is home to a robust practice and represents investors as well as whistleblowers, workers, consumers and others in cases achieving real results for those harmed by corporate negligence and other wrongdoings. Hagens Berman’s team has secured more than $2.9 billion in this area of law. More about the firm and its successes can be found at hbsslaw.com. Follow the firm for updates and news at @ClassActionLaw.",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/30/3158809/32716/en/Synopsys-Inc-SNPS-Shares-Suffer-Worst-Day-Ever-Amid-Q325-Results-Revealing-Problems-With-Major-Foundry-Customer-Hagens-Berman.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Technology Stocks To Follow Today – September 28th",
      "content": "NVIDIA, Apple, Intel, Microsoft, Palantir Technologies, Oracle, and Meta Platforms are the seven Technology stocks to watch today, according to MarketBeat’s stock screener tool. Technology stocks are shares of companies whose core businesses involve developing, manufacturing or distributing technology products and services—ranging from software, hardware and semiconductors to internet platforms and IT consulting. Investors are often drawn to these stocks for their high growth potential driven by rapid innovation, though they can also exhibit above-average volatility and sector-specific risks such as regulatory shifts or technological disruption. These companies had the highest dollar trading volume of any Technology stocks within the last several days.\n\nGet alerts:\n\nNVIDIA (NVDA)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nApple (AAPL)\n\nApple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal computers; iPad, a line of multi-purpose tablets; and wearables, home, and accessories comprising AirPods, Apple TV, Apple Watch, Beats products, and HomePod.\n\nRead Our Latest Research Report on AAPL\n\nIntel (INTC)\n\nIntel Corporation designs, develops, manufactures, markets, and sells computing and related products and services worldwide. It operates through Client Computing Group, Data Center and AI, Network and Edge, Mobileye, and Intel Foundry Services segments. The company's products portfolio comprises central processing units and chipsets, system-on-chips (SoCs), and multichip packages; mobile and desktop processors; hardware products comprising graphics processing units (GPUs), domain-specific accelerators, and field programmable gate arrays (FPGAs); and memory and storage, connectivity and networking, and other semiconductor products.\n\nRead Our Latest Research Report on INTC\n\nMicrosoft (MSFT)\n\nMicrosoft Corporation develops and supports software, services, devices and solutions worldwide. The Productivity and Business Processes segment offers office, exchange, SharePoint, Microsoft Teams, office 365 Security and Compliance, Microsoft viva, and Microsoft 365 copilot; and office consumer services, such as Microsoft 365 consumer subscriptions, Office licensed on-premises, and other office services.\n\nRead Our Latest Research Report on MSFT\n\nPalantir Technologies (PLTR)\n\nPalantir Technologies, Inc. engages in the business of building and deploying software platforms that serve as the central operating systems for its customers. It operates under the Commercial and Government segments. The Commercial segment focuses on customers working in non-government industries. The Government segment is involved in providing services to customers that are the United States government and non-United States government agencies.\n\nRead Our Latest Research Report on PLTR\n\nOracle (ORCL)\n\nOracle Corporation offers products and services that address enterprise information technology environments worldwide. Its Oracle cloud software as a service offering include various cloud software applications, including Oracle Fusion cloud enterprise resource planning (ERP), Oracle Fusion cloud enterprise performance management, Oracle Fusion cloud supply chain and manufacturing management, Oracle Fusion cloud human capital management, Oracle Cerner healthcare, Oracle Advertising, and NetSuite applications suite, as well as Oracle Fusion Sales, Service, and Marketing.\n\nRead Our Latest Research Report on ORCL\n\nMeta Platforms (META)\n\nMeta Platforms, Inc. engages in the development of products that enable people to connect and share with friends and family through mobile devices, personal computers, virtual reality headsets, and wearables worldwide. It operates in two segments, Family of Apps and Reality Labs. The Family of Apps segment offers Facebook, which enables people to share, discuss, discover, and connect with interests; Instagram, a community for sharing photos, videos, and private messages, as well as feed, stories, reels, video, live, and shops; Messenger, a messaging application for people to connect with friends, family, communities, and businesses across platforms and devices through text, audio, and video calls; and WhatsApp, a messaging application that is used by people and businesses to communicate and transact privately.\n\nRead Our Latest Research Report on META\n\nFeatured Articles",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/30/technology-stocks-to-follow-today-september-28th/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Trump Has Created an ‘Unusual Bull Case’ for Intel Stock. Should You Buy INTC Now?",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/0242fe27211b4a8f",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Arm's CEO said he learned a key leadership lesson working under Jensen Huang",
      "content": "Arm's CEO, Rene Haas, said Jensen Huang has a \"set of characteristics of vision, speed, fearlessness, taking risk, and an ability to pivot very, very fast.\"\n\nArm's CEO, Rene Haas, said Jensen Huang has a \"set of characteristics of vision, speed, fearlessness, taking risk, and an ability to pivot very, very fast.\" Samantha Burkardt/SXSW Conference & Festivals via Getty Images\n\nArm's CEO, Rene Haas, said Jensen Huang has a \"set of characteristics of vision, speed, fearlessness, taking risk, and an ability to pivot very, very fast.\" Samantha Burkardt/SXSW Conference & Festivals via Getty Images\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nArm CEO Rene Haas said at Nvidia, he saw up close how bold leadership decisions can change a company's trajectory.\n\nThe CEO of the $150 billion chip design firm spoke about his seven years at Nvidia working on computing products at the All-In Summit 2025 in September, in a conversation posted Wednesday.\n\nHaas said he saw how Jensen Huang built the company by taking bold risks and pivoting quickly.\n\nHaas said Huang changed strategy at an off-site meeting meant to review business roadmaps. \"We're abolishing this product line. We're going to move 2,000 engineers off of project X onto project Y,\" said Haas, adding that the company had only about 6,000 people at the time.\n\nThat abrupt shift — away from making support chips for Intel's processors — proved decisive. Instead of trying to keep up with Intel in PCs, Huang redirected thousands of engineers to focus on Arm-based designs and graphics chips. That move reshaped the company's future, said Haas, who left Nvidia in 2013 to join Arm.\n\n\"You have this amazing set of characteristics of vision, speed, fearlessness, taking risk, and an ability to pivot very, very fast,\" Haas said of Huang, adding that he has \"learned so much\" from working with him.\n\nNvidia is one of Arm's flagship customers — its latest AI chips combine Arm-based CPUs with its own powerful GPUs.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nIn 2020, Nvidia tried to acquire Arm in a $40 billion deal that fell through because of regulatory hurdles. Haas told Business Insider in 2022 that Arm wasn't dwelling on the failed sale and was instead focused on expanding in industries like cloud, networking, automotive, and the Internet of Things.\n\n\"I'm not going to say Jensen is my competitor today,\" Haas said at the All-In Summit.\n\nBut when asked if Arm might eventually make its own chips and go head-to-head with Nvidia, he added: \"I'm not going to say that today, but could we do that? I hinted in the last conference call that we're looking at going a little bit further than we do today.\"\n\nArm and a Nvidia spokesperson declined to comment.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/arm-ceo-rene-haas-leadership-lesson-nvidia-jensen-huang-2025-10",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "USPTO sends layoff notices after Trump administration threatened shutdown RIFs",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/75dd978fe45143eb",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Tackle homework, streaming, and browsing with this 2-in-1 touchscreen laptop for just $70",
      "content": "TL;DR: Take on everyday tasks with this refurbished Lenovo 300E Touchscreen Chromebook — now just $69.97 (MSRP $284.99) through October 12.\n\nLooking for a laptop that keeps up with your day without draining your wallet? The Lenovo 300E 11.6-inch Chromebook brings touchscreen convenience, Chrome OS simplicity, and reliable performance together in one compact device for $69.97 until October 12. Whether you’re writing papers, streaming shows, or juggling multiple tabs, it’s ready to handle the essentials.\n\nThis refurbished model features an Intel N3450 quad-core processor and 4GB of RAM for smooth multitasking, plus 32GB of storage for your must-have apps and files. The 11.6-inch HD touchscreen display gives you crisp visuals at 1366×768 resolution, while built-in Wi-Fi and Bluetooth keep you connected on the go. At just over three pounds, it’s lightweight enough to slip into a backpack, making it an ideal choice for students, travelers, or anyone who wants a reliable second laptop.\n\nAnd because it runs Chrome OS, you’ll have access to Google’s ecosystem of apps, updates through 2028, and seamless integration with your favorite cloud services. This grade-B refurbished unit may show light scuffs or marks, but it delivers strong everyday performance at a fraction of the cost of new models.\n\nUpgrade your daily driver without overspending — a refurbished 2018 Lenovo 300E 11.6″ Touchscreen Chromebook is available now for $69.97 until October 12.\n\nLenovo 300E 11.6″ Touchscreen Chromebook (2018) 4GB RAM 32GB Storage (Refurbished)See Deal\n\nStackSocial prices subject to change.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2921186/tackle-homework-streaming-and-browsing-with-this-2-in-1-touchscreen-laptop-for-just-70.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "No, Sideloading Android Apps Isn't Going Away, Google Says",
      "content": "Despite publicly belittling software patents and lobbying for patent reform that would make it difficult for companies to use such patents in patent-based lawsuits, Google is building an impressive arsenal of patents of its own at a much faster rate than in previous years. While the move may be perceived as an attempt to defend its Android mobile operating system that's under attack from rivals including Apple and Microsoft – as well as to attack them back – it would appear that Google is protecting all of its interests, across a variety of markets that it's currently a player in. MIT's Technology Review reports that this year alone, Google is on track to be awarded about 1,800 patents, putting Google on the top 10 patent recipients list, ahead of companies like GE and Intel. Google is now No. 3 or No. 4 on that list behind the likes of IBM and Microsoft. To help illustrate what a dramatic change this is from the old Google, in 2007 when the iPhone was first introduced, Google was awarded only 38 patents.\n\nSteve Jobs famously said that with the iPhone, Apple decided to \"patent it all,\" after losing a $100 million iPad lawsuit. And Apple proved to be the main opponent in courts of Android, wining several favorable verdicts in cases against Samsung, HTC and Motorola in the U.S. and around the world.\n\nMicrosoft, another important Google rival, is reportedly making around $2 billion a year from licensing deals inked with a large number of Android device makers.\n\nGoogle patents chart versus the competition | Image source: USPTO via MIT's Technology Review\n\nIt's not 2003 anymore, when Google was awarded only four patents all year. Now, the company sits on a trove of around 51,000 patents, and it is now awarded an average of 10 patents every day the U.S. Patent & Trademark office is open. In November 2013, Google was awarded 177 patents. The company's patent war chest also includes over 17,000 patents and 7,000 patent applications from Motorola, which were acquired when Google purchased the company for $12.5 billion last year.",
      "source": "BGR",
      "url": "https://www.bgr.com/general/google-patents-treasure-chest/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Intel Reaffirms $28 Billion Ohio Expansion Despite Delay to 2030",
      "content": "Intel reiterated this week that its long-planned Ohio semiconductor campus remains a core part of its manufacturing strategy after Republican Senator Bernie Moreno demanded clearer answers about delays and potential costs to local taxpayers. In a brief response to Moreno, the company stated that it is coordinating with Ohio officials, the state's congressional delegation, and local stakeholders as it revises the schedule, and emphasized that the site \"remains an important part of our long-term plans to expand leading-edge manufacturing on U.S. soil.\" Intel acknowledged that the timeline has shifted—commercial production is now not expected until at least 2030—and said it will maintain the flexibility to adjust construction and ramping based on customer demand. Moreno's letter highlighted roughly $2 billion in public incentives and nearly $700 million in infrastructure commitments, and he pressed the company for specifics on economic impact and any steps to limit costs to Ohio taxpayers. However, the company's public reply did not answer those questions in detail.Leadership changes, rounds of workforce reductions and the challenge of attracting outside foundry customers have slowed momentum for Intel, while new private investments and a recent federal equity stake have altered financial and strategic calculations. The government involvement has added a national-security angle to the debate and increased scrutiny from state officials and residents who had expected faster job and supply-chain benefits. Intel insists the Ohio campus remains strategic and says it will keep working with stakeholders to align build-out with market realities. For now, the ambitious proposal survives as a long-term bet. Meanwhile, TrendForce reports citing Commercial Times that says Intel started limited 18A node shipments to U.S. customers in Q3, with 18A wafers already in production and initial output of its own CPUs expected in Q4. At least some parts of the manufacturing roadmap remain according to schedule, meaning that the $28 billion Ohio plant project is safe for now.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341534/intel-reaffirms-usd-28-billion-ohio-expansion-despite-delay-to-2030",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "How to stop a single vendor breach from taking down your business",
      "content": "In this Help Net Security video, William Dixon, Senior Executive at Intel 471, examines the future of third-party cyber risk and why it is a growing concern for organizations worldwide. As businesses become more interconnected, the digital ecosystem offers transformative opportunities while also introducing new vulnerabilities.\n\nDixon highlights lessons learned from recent high-profile breaches, which demonstrate how a single compromised vendor can have a cascading impact on thousands of organizations.\n\nHe outlines three key shifts shaping the future of third-party risk management. The first is moving from reactive assessments to proactive, real-time intelligence. The second is shifting from siloed security to building resilient ecosystems. The third is replacing checkbox compliance with data-driven, quantified risk management.\n\nThe video also offers actionable steps for organizations. These include implementing continuous automated monitoring, applying zero-trust principles to vendor access, and strengthening contractual controls to ensure shared responsibility.",
      "source": "Help Net Security",
      "url": "https://www.helpnetsecurity.com/2025/10/01/third-party-cyber-risk-video/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Detour Dog’s DNS Hijacking Infects 30,000 Websites with Strela Stealer",
      "content": "New research from Infoblox Threat Intel has revealed that an established, persistent group of cybercriminals, Detour Dog, has been silently infecting websites around the world since 2020.\n\nThe group, which first focused on simple scams routed through affiliate systems like Los Pollos, has now upgraded its attacks to deliver powerful information-stealing malware called Strela Stealer to home users and so far, has compromised over 30,000 websites.\n\nThe DNS Hijack: Hiding the Attack\n\nDetour Dog’s operations have been tracked by Infoblox since August 2023. Researchers regard their new tactic as especially tricky because the malware is controlled from the server-side, and the malicious activity happens on the website’s host, completely invisible to the visitor. This is achieved through the Domain Name System (DNS), which is like the Internet’s phonebook.\n\nThe attack involves using an unusual part of DNS, called TXT records, to send secret commands to the infected sites to either redirect visitors to scams or fetch and run malicious code. The criminals are extremely cautious because their system is rarely active; while 90% of sites get a harmless response, only 9% cause redirects, and just 1% trigger the full malware attack.\n\nAttack Chain and Detour Dog responses August 6-8 (Source: Infoblox)\n\nThis covert method makes a website appear normal to most people while secretly targeting others based on things like their location or device type. The research, shared with Hackread.com, indicates that this method allows compromised sites to stay infected for over a year because “most visits look normal and only certain visitors are targeted.”\n\nThe scale of the attack’s infrastructure is surprisingly high. When researchers tested a compromised server in August 2025, it received a peak of over 2 million of these secret DNS requests in a single hour.\n\nFrom Scams to Stealers\n\nThe shift to delivering the Strela Stealer reportedly occurred in June and July 2025. However, this malware is operated by a different group, Hive0145, whereas Detour Dog acted as a service provider/partner to distribute it using a backdoor malware, StarFish, for installation.\n\nAttack Vectors (Source: Infoblox)\n\nWhile the campaigns were delivered via REM Proxy and Tofsee botnets, highlighting an affiliation between Detour Dog and these botnet providers, for the June-July campaigns, over 69% of the initial staging domains were controlled by Detour Dog.\n\nMalicious traffic analysis showed that infected websites span across 89 countries, with the largest volume of visitor IP addresses coming from the US (37% of all unique IP addresses,) followed by Germany and Taiwan.\n\nHowever, researchers suspect that this vast traffic is automated bot traffic. That’s because the queries included IP addresses not likely connected to human users, such as those belonging to the US Department of Defence.\n\nAlso, two specific GoDaddy IP addresses accounted for nearly 3 million queries alone, forcing researchers to question how this massive traffic volume is generated. They conclude that the full answer likely requires gaining direct access to the malware on the infected sites.\n\nInfoblox researchers stress that because these attacks bypass traditional security tools, a strong defence at the DNS and network level is essential.",
      "source": "HackRead",
      "url": "https://hackread.com/detour-dog-dns-hijacking-websites-strela-stealer/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Intel stock pops on news company is in early talks to add AMD as a customer",
      "content": "Intel is in early talks with AMD to manufacture chips for it in its foundry business, according to a report from Semafor.\n\nIntel shares rose as much as 6% on the news at one point during trading on Wednesday. AMD shares were flat.\n\nIf AMD were to start manufacturing chips with Intel, it…\n\nThis story appeared on cnbc.com , 2025-10-01 19:40:40.428000.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/9bd3dfcdd2d62173",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "It's time get a flu vaccination. Here's who needs one and why",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/97a99ef630e09d23",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "NFL Week 5 buzz: Gauging Ravens panic, Titans desperation and the QB trade market",
      "content": "Open Extended Reactions\n\nWe're a month into the NFL season, and insiders Jeremy Fowler and Dan Graziano have been making calls to sources around the league for the latest news and buzz on key situations heading into October play.\n\nOne of the biggest storylines of the week is what's going on with the Ravens and their 1-3 start. Jeremy and Dan have intel on the sentiments in Baltimore and how much panic the Ravens are feeling. They are also diving in on the Titans' 0-4 start and long-term ramifications of it, along with what they're hearing on the quarterback front as the Nov. 4 NFL trade deadline approaches.\n\nThat's not all, as Jeremy and Dan will also be examining rookies who have earned themselves more playing time. It's all here, as our reporters answer big questions and empty their notebooks heading into Week 5.\n\nJump to:\n\nPotential Titans changes | Ravens' panic meter\n\nRookies making a move | Will a QB be traded?\n\nMore notes on Week 5\n\nWhat are you hearing on the Titans' 0-4 start and potential changes they could make -- now or in the offseason?\n\nFowler: There is moderate concern among the coaching staff that the front office and ownership might not be as patient as they originally believed, which could lead to change sooner rather than later. The proverbial \"vibes\" simply are not good right now. The front office entered the season with optimism about head coach Brian Callahan, who was a hot name on the coaching circuit in 2024. And though it wouldn't set a win-loss goal in regard to his tenure, Titans brass wanted to see a team that's improving. That's hardly the case in Tennessee, where a minus-69 point differential through four games is by far the worst in the league (next closest is New Orleans at minus-55).\n\nThe overall lack of flow from week to week is only intensifying the discomfort. Callahan relinquishing playcalling duties to assistant Bo Hardegree a week ago could buy the staff a little time, but firing him a week after such a change would be counterproductive. The Titans' bye is Week 10, which feels important. But the expectation among some around the league I've talked to is that the temperature is increasing, especially with owner Amy Adams Strunk's willingness to make drastic changes in recent years.\n\nGraziano: It's one thing to start 0-4 with a rookie quarterback, but it's another to be as noncompetitive as the Titans have been. They had a second-half lead against the Broncos in Week 1, but things seem to have gotten progressively worse each week since. Sunday's loss to Houston was a complete no-show, and to get shut out the week after making an offensive playcaller change doesn't say much about their chances to fix this thing on the fly.\n\nCallahan was Tennessee's top choice as head coach following the 2023 season, and the franchise entered this season with the belief that he was the guy to shepherd Ward's transition into the league. But there have been red flags, including some game management situations and some postgame news conferences in which Callahan seemed unaware of some of the rules governing replay challenges, etc. If the Titans can win a couple of games, I'm sure that will buy him time, but that's a big if right now, and Callahan hasn't helped himself with some of his gaffes.\n\nI will say, from talking to people who follow these situations in the league, that there's belief that this will be a desirable job if and when it comes open. Young, promising QB, new stadium on the horizon, etc. You agree?\n\nFowler: Agreed. This can be a good job, Dan. Cam Ward has serious potential but needs an infusion of pass-catching talent around him. A few drafts can fix that. The offensive line hasn't come together despite significant investments. But offensive tackle JC Latham (currently injured) and guard Peter Skoronski are players to build on. The defense has held up at times.\n\nPresident of football operations Chad Brinker and general manager Mike Borgonzi come from well-established, methodical personnel trees -- the Packers and Chiefs, respectively. That should lead to build-through-the-draft patience ... which I once thought would help Callahan's case, but now I'm not so sure. As you mentioned, game management issues in multiple games this season have not helped his cause. That's such a priority for teams now.\n\nGraziano: Yeah, that's another thing to watch, because Borgonzi and Brinker weren't really in their current roles when the organization hired Callahan. (Maybe Brinker was, but he didn't have as much clearly delineated power at the time.) It's never a comfortable feeling working for people who didn't hire you. And your point about the offensive line is a critical one, because the offensive line coach is Callahan's father, Bill Callahan, who's considered one of the best to ever do that job. I believe Bill wouldn't stick around if Brian got fired, so you're talking about major change in critical areas. I might look foolish in a couple of weeks (or days, who knows?), but if I'm making a prediction, I lean toward the Titans giving Callahan the rest of the year before making a decision.\n\nRate the level of panic in the Ravens' building on a scale of 1-10\n\nGraziano: I say 5, but it's important to note that that's a really high number in Baltimore, where there's typically not much panic at all. This defense has had no answers for anyone but the Browns, and with Nnamdi Madubuike out for the season and a ton of other injuries (Nate Wiggins, Roquan Smith, Ar'Darius Washington, the list goes on and on) on that side of the ball, where are the answers going to come from? Add Lamar Jackson's hamstring injury, and now you have a potential for disaster.\n\nIf Jackson misses significant time, this season could go downhill quickly. Cooper Rush is the backup, and obviously the offense will look a lot different when he starts than it does when Jackson starts. The running game hasn't done anything since the season opener against Buffalo. There are a lot of problems for a team that was a popular preseason Super Bowl pick.\n\nI am guessing the panic meter about the Ravens outside the building -- among fans and those of us who analyze objectively -- is closer to 10 right now. But the Ravens count on the strength and steadiness of coach John Harbaugh, general manager Eric DeCosta and their internal leadership structure to solve problems and get them through tough times. You can bet they're scouring for answers, internally and externally.\n\nBreaking News from Adam Schefter Download the ESPN app and enable Adam Schefter's news alerts to receive push notifications for the latest updates first. Opt in by tapping the alerts bell in the top right corner. For more information, click here.\n\nFowler: I'll go 6. It's worth remembering in times like this that Jackson has a .717 career winning percentage as a starter. That's a Tom Brady-like figure. Assuming Jackson does not miss significant time, the Ravens have a path to a backdoor playoff spot.\n\nAll three losses are to elite teams with championship hopes. It's not like the Ravens are blowing leads to winless teams. The offense is still trying to find its rhythm with personnel groupings -- when to play big people for the run game (such as two or three tight ends) vs. playing through receivers and the passing game more often. There's enough talent on offense to make it work regardless. But this defense is galaxies away from the once-proud unit that charged Super Bowl runs. It's currently serving as a confidence builder for struggling offenses to get right. And losing Madubuike for the year is a crushing blow. That's a premier player on a defensive front that's struggling to generate a pass rush.\n\nGraziano: Like you, I also look at who their losses are against. The Bills, Lions and Chiefs are among the best teams in the league, sure, but the Ravens were supposed to be, too. And in the case of Buffalo and Kansas City, those are losses that could really come back to bite the Ravens late in the season when we're sorting out playoff seeding and tiebreakers. At 1-3, Baltimore is probably hoping it has that problem, but assuming the Ravens come back from this and make the run we all expected, these early-season losses could put them behind the eight ball come playoff seeding time. Sunday's game against the Texans is another that could potentially have implications for tiebreakers and seeding if the Ravens play their way back into contention.\n\nWhen I was at their training camp, I was talking to Harbaugh about the coming season and he was stressing how important it was to get off to a fast start -- how they started 0-2 last season and ended up having to play a playoff game in Buffalo in January instead of playing the Bills at home. I'm sure Harbaugh is as perplexed as the rest of us are about why September went so poorly.\n\nFowler: The Ravens' schedule will ease up. Only one of their next seven opponents (Rams, Week 6) has a winning record. The AFC North is winnable. But it appears they'll have to win shootouts. On defense, the Ravens need more from pass rusher Odafe Oweh, a former first-round pick, and corner Jaire Alexander, who hasn't played since Week 1. Otherwise, my preseason Super Bowl pick looks bleak.\n\nHarbaugh made an unconventional defensive coordinator hire in Zach Orr, a former Ravens linebacker who quickly worked his way up the ranks, in February 2024 to replace Mike Macdonald. Orr was able to help steady a struggling Ravens defense late last season, but this is two consecutive years of suboptimal results for long stretches.\n\nWhich rookie has made a case for more playing time after a strong start?\n\nFowler: He's already getting more time, but Giants running back Cam Skattebo is proving a capable option out of the backfield with Tyrone Tracy Jr. sidelined by injury. Skattebo's recent impact has been undeniable. His ability to knife through tackles and create additional yards will be crucial for a streaky (that's putting it nicely) New York passing offense. He averaged nearly six yards per touch thus far.\n\nAnother emerging offensive option is Seahawks receiver Tory Horton, who is making the most of his limited role. He's averaging just under 27 snaps but has six catches on 10 targets for 74 yards and two touchdowns, including an impressive over-the-shoulder grab in the end zone in Week 3. While Cooper Kupp seems entrenched as Seattle's WR2, Horton is giving the Seahawks something to think about after producing three total touchdowns (including a 95-yard kickoff return). Looks like GM John Schneider got a fifth-round gem.\n\nplay 0:37 Rex Ryan wants Shedeur to start for the Browns Rex Ryan questions why the Browns have not started Shedeur Sanders at quarterback.\n\nGraziano: Woody Marks looks like a more exciting running back than Nick Chubb in Houston, where the Texans are looking for any answer they can find on offense. Wouldn't be surprised to see Marks get a little more run. Chiefs rookie running back Brashard Smith has seen more involvement in the offense in recent weeks and I'm told to expect that to continue.\n\nAnd my guy Harold Fannin Jr., who we pointed out in Week 1 as a rookie to watch, has worked his way into the pass catcher rotation in Cleveland even with David Njoku ahead of him on the Browns' tight end depth chart. The Browns love using Fannin in a lot of different roles, and I think that usage will only expand.\n\nFowler: Cleveland is really excited about Fannin's future -- and that of running back Quinshon Judkins and wide receiver Isaiah Bond. On defense, Carolina edge rusher Nic Scourton has made a quick impression. The Panthers wanted to utilize more young players on defense after a sluggish start, and Scourton, a second-round pick in April, has played 100 snaps over the past two weeks, producing a pass deflection and several quarterback pressures. He has a high motor, plays with power and has a nifty spin move in his arsenal. The youth movement is on for Carolina, which is also giving third-round edge rusher Princely Umanmielen extended snaps.\n\nGraziano: Edge rusher Ashton Gillotte is a player who really excites the Chiefs. He got his hand on a field goal attempt in the Week 3 victory over the Giants and has seen his snap count rise each week as the team continues to trust him more. I would not be surprised to see Kansas City continue to use Gillotte more as the season goes on as they rely more and more on their defense while the offense gets its act together.\n\nTrue or false: A quarterback will be traded before the deadline.\n\nGraziano: True. Now, it could be someone such as Carson Wentz or Kenny Pickett, which wouldn't exactly make headlines, but I think you're asking if it could be someone such as Kirk Cousins or Russell Wilson or one of the Cleveland rookies (Dillon Gabriel was named the Browns starter Wednesday morning). Anything's possible. It doesn't feel like Wilson has a real role in New York, where rookie Jaxson Dart is now the starter and Jameis Winston is signed through 2026 to be his backup. Wilson's trade value is also likely very low right now, so the Giants might wait until someone gets desperate to ship him out.\n\nCousins' situation in Atlanta, as the veteran backup behind Michael Penix Jr., is one we've frequently discussed. He could get dealt, but Atlanta is not desperate to deal him and is still asking for a relatively high price. The Falcons believe he has value as a reliable backup in case something should happen to Penix. And having been on the sideline for Sunday's game against Washington, I can tell you Cousins is one of the prominent voices in Penix's ear between possessions. He's been helpful in Penix's development and, along with offensive coordinator Zac Robinson and quarterbacks coach D.J. Williams, is a helpful extra set of eyes and ears that benefits Penix.\n\nFowler: Man, Pickett getting dealt for the third time in a calendar year would be tough on his real estate portfolio. Do I believe a quarterback will be traded? Yes, so my answer is true. A quarterback with a marquee name, I'm not so sure. Wilson would be the most sensible candidate. Cleveland had some level of interest in Wilson before he signed with the Giants, and his $2 million base salary makes him very tradable.\n\nBut it's uncertain where Cleveland will be from a roster-building standpoint three or four weeks from now. Wilson would be a low-cost play if the Browns aren't satisfied with Gabriel or Shedeur Sanders. And Cleveland explored the Cousins situation before ultimately signing Joe Flacco, trading for Pickett and drafting two passers.\n\nplay 1:01 Orlvosky: Tyreek Hill's injury was tough to watch Dan Orlovsky explains what he was feeling after Tyreek Hill's season-ending injury during \"Monday Night Football.\"\n\nOutside of that, there's not a clear-cut need for teams, barring injury. One intriguing option is Anthony Richardson Sr., who is stuck behind Daniel Jones in Indianapolis. My sense is Richardson would be open to joining a premier playcaller such as Sean McVay as a developmental player so he can reset for 2026.\n\nGraziano: Richardson is an interesting one. I remember a couple of teams wondering whether Indy would be open to moving him during free agency. So far, they've insisted they aren't, but you're right. If Jones keeps playing well and leads them to their first division title in more than a decade, who's to say the Colts don't decide he's their future at quarterback and sign him to an extension?\n\nIn general, acquiring a starting QB at the trade deadline is tough, because in most cases it's a guy who must learn a new offense on the fly. By the time he's up to speed, it could be too late for him to save the season. That's why someone like Richardson, whom teams might view for development in the long term, makes more sense. But there are situations that come up where a team with high hopes finds itself with a sudden need and might be willing to take the risks involved with bringing in someone from outside its system, right?\n\nFowler: That question reminds me that quarterback needs can change in a hurry -- especially after what the Bengals just showed Monday night. Got to wonder if Cincinnati evaluates quarterback options if the downward spiral deepens. After Monday night's lifeless outing, Cincinnati now has gained fewer than 200 offensive yards in three of its first four games. The last team to do that was the 2009 Raiders, who rolled out a combination of JaMarcus Russell, Bruce Gradkowski and Charlie Frye at quarterback.\n\nThe Bengals still believe in Jake Browning, who was far from the only culprit in Denver on Monday, but Cincinnati has too much skill position talent to accept the status quo. At some point, it could need reinforcements at the game's most important position. It might be worth calling recently retired Derek Carr to check on how his shoulder injury is healing.\n\nWhat else are you hearing this week?\n\nGraziano's notes:\n\n• Tyreek Hill's contract with the Dolphins is structured in a way that he might actually benefit from being released before the end of the season. I was looking at his contract to get a sense of his future with Miami now that his season has ended due to the gruesome knee injury he sustained Monday night against the Jets. Hill is owed $36 million for 2026, none of which is guaranteed, even against injury. If Hill is still on the roster as of 4 p.m. ET on the third day of the 2026 league year (March 13, 2026), then $11 million of his 2026 salary becomes fully guaranteed and his $5 million roster bonus vests. So odds are that the Dolphins would release Hill prior to March 13 to avoid owing him $16 million next year, unless the two sides agree to rework the contract before then.\n\nHill's 2025 compensation -- combined salary and bonuses -- comes to $25.85 million, and all of that is guaranteed; he'll get every penny of it. But Hill's 2025 contract also includes $1.8 million in per-game active roster bonuses -- $105,882.36 for each game for which he's a member of the 48-man active roster. That money is conditionally guaranteed, meaning if the team releases him, he'd get the full $1.8 million. But the way the conditional guarantee works is if he's on the 53-man roster but not active on game day, he does not get the $105,882.36 for that week.\n\nThe Dolphins have played four games, and Hill was active for all four, so he has already pocketed $423,529.44. If the Dolphins were to cut him this week, he'd get the remaining $1,376,470.56. But if they keep him on the roster the rest of the season and he isn't active on game days, he won't get any of that $1,376,470.56. So as weird as it sounds, Hill would make more money if the Dolphins release him before the end of the season than he would if they waited until March to cut him.\n\n• Having covered Washington's game in Atlanta this past Sunday and talking to Commanders people, I came away believing quarterback Jayden Daniels has a decent chance to be activated and play this week in Los Angeles against the Chargers. Daniels (knee) was a limited practice participant last week after not practicing at all the week before, and from what I was told, he was close to being cleared to play in Atlanta. The team doctors decided on Friday it was best to hold him out. Keep an eye on whether he logs any full practices this week, which would be a strong indication he's good to go Sunday. Wide receiver Terry McLaurin sounded like he could need another week or two to heal from his quad injury, but the Commanders will know more as the practice week goes along.\n\n• With McLaurin out, the Commanders leaned heavily on Deebo Samuel in Week 4, which isn't a surprise. What might have been a surprise, though, was the extent to which they used Samuel as an outside receiver, instead of just in the slot or in the backfield the way they usually do. What makes them more comfortable doing that is what they've seen from fourth-round rookie wide receiver Jaylin Lane in the slot. So Washington used him there a bit and moved Samuel around more than usual. Once McLaurin and Noah Brown (groin) are back, I'd expect Samuel's usage to revert to the original plan.\n\n• One more Commanders note, for you fantasy managers wondering about the running backs: They're very happy at the moment using a committee with Chris Rodriguez Jr., Jeremy McNichols and rookie Jacory Croskey-Merritt. But they do view Croskey-Merrit as the most capable one of the three to emerge as an all-around threat out of the backfield. And as he gains more experience, I would expect his role to increase. If you have him on your fantasy roster, I'd hold on, because there's a chance he could be the lead back there over the second half of the season.\n\n• I asked some Chiefs people about the way the offense looked with Xavier Worthy back from his shoulder injury. One response I got: \"That's the way it was supposed to look in Brazil before play 3 lol.\"\n\nIt was the third play in the season opener against the Chargers in Brazil on which Worthy collided with Travis Kelce and dislocated his shoulder, and a Chiefs offense that had practiced all offseason with Worthy and the suspended Rashee Rice as its top two wide receivers looked lost for the rest of that game and in Weeks 2 and 3 while Worthy sat out to heal. With Worthy back, the offense sprang to life (against an admittedly undermanned Ravens defense), and Kansas City's expectation is that it will get even better in Week 7 when Rice returns from his six-game personal conduct policy suspension.\n\n• The Browns debated whether to switch from Joe Flacco to Dillon Gabriel this week, in part because it's an odd week with the game against the Vikings in London. But they ultimately decided to make the move. You'll remember of course that the Browns also have fellow rookie Shedeur Sanders and might want to get a look at him in a starting role before the end of the season, too. With Gabriel as the next man up, it'll be interesting to see if they elevate Sanders to the No. 2 spot (he has been the inactive/emergency third QB on game days so far) or if they hold onto Flacco as the game day backup. That'll tell us a lot about where Cleveland thinks Sanders is in his development and what his chances are of seeing some starts this season. For now, Sanders remains the No. 3 behind Gabriel and Flacco.\n\n• The Falcons go into their bye feeling worlds better about their offense than they did a week ago. They lost 30-0 to Carolina in Week 3, then dropped 34 points and 435 yards of offense on the Commanders in Sunday's 34-27 home win. That represented quarterback Michael Penix Jr.'s career high in passing yards (313) and running back Bijan Robinson's career high in scrimmage yards (181). The morning of the game, I saw Falcons QBs coach D.J. Williams on the field and asked how Penix was doing after the shutout. \"He's fine,\" Williams told me. \"He's great. He doesn't ride the wave, the highs and lows. That's one of the things we love about him.\"\n\nThe Falcons never considered sitting Penix down for Kirk Cousins, as bad as things looked in Weeks 2 and 3. Falcons coach Raheem Morris said after the Week 4 game that the way Penix showed up at the facility last Monday -- focused and determined to make up for the Week 3 performance -- left no doubt in Morris' mind that Penix could and would handle this. And his teammates felt the same way. \"Mike's fantastic, and you see it in the leader he has shown himself to be and the competitor that he is,\" Falcons guard Chris Lindstrom told me. \"There's nothing but 100 percent love and confidence in Mike here.\"\n\n• The Steelers are 3-1 and out in front in an AFC North whose other three teams are having all kinds of problems. They squeaked out wins in Week 1 and Week 3 with some serious turnover help from the Jets and Patriots, respectively, but the offense racked up a season-high 313 yards in Week 4 (after averaging 247 in its first three games). That unit is showing steady improvement around veteran quarterback Aaron Rodgers. The Steelers knew coming into the season that the offense would be a work in progress, but they're happy with the way their young O-line is building confidence week by week, and they'll continue to move No. 1 wide receiver DK Metcalf around the formation to maximize his playmaking ability.\n\nStarting running back Jaylen Warren was a surprise inactive Sunday morning due to a knee injury that just didn't feel quite right in pregame warmups. But they're hopeful he'll be fine in Week 6 after the bye. In the meantime, they got to deploy Kenneth Gainwell, who has been impressing them since the spring with his ability to contribute in multiple ways. The team also believes rookie Kaleb Johnson will contribute before season's end, but as of now, they're fine if the backfield is led by Warren (when healthy) and Gainwell.\n\nFowler's notes:\n\n• Despite a 4-0 start, the Eagles are forced to answer for a cryptic tweet from receiver A.J. Brown, which brings their 31st-ranked passing offense into focus. First, to get this out of the way: Brown's contract comes with a dead cap hit of nearly $90 million. That's tough to trade, even for an aggressive front office such as Philadelphia -- though not impossible if designated as a post-June 1 trade. Some execs I spoke to this week don't expect Philadelphia to trade Brown in-season but said that it could be something to entertain in the offseason. It's sort of the worst-kept secret inside the league that Brown's love-hate relationship with Philly's passing game bubbles to the surface from time to time. He's a true competitor and wants to be great. With that comes emotion and inevitable frustration.",
      "source": "ESPN",
      "url": "https://www.espn.com/nfl/story/_/id/46423621/nfl-week-5-buzz-news-updates-fantasy-intel-questions-predictions",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "US takes a stake in another company, this one is operating a massive lithium mine in Nevada",
      "content": "By MICHELLE CHAPMAN\n\nThe U.S. government is taking a minority stake in Lithium Americas, a company that is developing one of the world’s largest lithium mines in northern Nevada.\n\nThe Department of Energy will take a 5% equity stake in the miner, which is based in Vancouver. It will also take a 5% stake in the Thacker Pass lithium mining project, a joint venture with General Motors.\n\nThacker Pass is considered crucial in reducing U.S. reliance on China for lithium, a critical material used to produce the high tech batteries used in cell phones, electric vehicles and renewable energy. Both Republicans and Democrats support the project and narrowing the production gap. China is the world’s largest lithium processor.\n\nU.S. Energy Secretary Chris Wright said in a statement that the deal with Lithium Americas “helps reduce our dependence on foreign adversaries for critical minerals by strengthening domestic supply chains and ensures better stewardship of American taxpayer dollars.”\n\nThacker Pass is expected to produce 40,000 metric tons of battery-quality lithium carbonate per year in its first phase, enough to help power 800,000 EVs.\n\nThe equity stake in Lithium Americas is the latest example of the direct intervention by the Trump administration with private companies. The government is getting a 10% stake in Intel through the conversion of billions in previously granted government funds and pledges. The administration spent $400 million of taxpayer money in July on MP Materials stock to make the U.S government the biggest owner in the Las Vegas rare earths miner. Trump also made a deal with Nvidia and AMD to give the U.S. government a 15% cut of revenue from selling certain chips to China.\n\nLithium Americas said Wednesday that it reached a non-binding agreement in principle with the DOE to advance the first draw of $435 million on the federal loan. The DOE has agreed to defer $182 million of debt service over the first five years of the loan.\n\nFILE – An “Access Restricted” sign is displayed at the Lithium Nevada Corp. mine site at Thacker Pass, April 24, 2023, near Orovada, Nev. (AP Photo/Rick Bowmer, File)\n\nFILE – Construction continues at the Lithium Nevada Corp. mine site Thacker Pass project, April 24, 2023, near Orovada, Nev. (AP Photo/Rick Bowmer, File) Show Caption 1 of 2 FILE – An “Access Restricted” sign is displayed at the Lithium Nevada Corp. mine site at Thacker Pass, April 24, 2023, near Orovada, Nev. (AP Photo/Rick Bowmer, File) Expand\n\nThe White House and Canada’s Lithium Americas seemed to be moving forward with the deal late last month, as both parties agreed on changes to an approximately $2.3 billion federal loan that could allow the project to move forward to extract the silver-white metal used in electric vehicle batteries. GM has pledged more than $900 million to help develop Thacker Pass, which holds enough lithium to build 1 million electric vehicles annually.\n\nDan Ives, an analyst with Wedbush, called Thacker Pass is a “massive opportunity” for the U.S. to reduce its reliance on China and other foreign adversaries for lithium.\n\n“Despite having some of the largest deposits, the U.S. produced less than 1% of the global lithium supply but this deal helps reduce dependence on foreign adversaries for critical minerals strengthening domestic supply chains and ensuring better stewardship of American taxpayer dollars with lithium production set to grow exponentially over the coming years,” he wrote.\n\nShares of Lithium Americas spiked more than 30% Wednesday.",
      "source": "Boston Herald",
      "url": "https://www.bostonherald.com/2025/10/01/trump-lithium-mine/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Seal whiskers can track subtle motions in the ocean",
      "content": "Seal whiskers can track subtle motions in the ocean\n\nHarbor seals use their whiskers to gather all sorts of intel from their surroundings. These exquisitely tuned sensory hairs even seem to allow them to outmaneuver the escape plans of their fishy prey.\n\nSCOTT DETROW, HOST:\n\nSeal whiskers, turns out they're not just for show. They provide the animals with key intel on their surroundings. And new work suggests that maybe they help seals outmaneuver the evasive behavior of the fish they are hunting. Here's science reporter Ari Daniel.\n\nARI DANIEL, BYLINE: A harbor seal sports about a hundred whiskers.\n\nYVONNE KRUGER: So these are sensory hairs in the facial region. And with these whiskers, they can sense the water movements that are generated by fish.\n\nDANIEL: It's as if the fish are leaving behind underwater trails, says Yvonne Kruger, a biologist at the University of Rostock in Germany. Trails that a seal can follow to find the fish and gobble them up.\n\nKRUGER: You can't see it, but you can sense it with the whiskers.\n\nDANIEL: Seals can use their whiskers to pull all sorts of information out of the water. They can determine the direction in which something has traveled, and lab studies suggest seals might even distinguish between the movements of different types of fish. But fish don't just let themselves be eaten. The rainbow trout, for instance, a favorite food of the harbor seal, has an escape strategy.\n\nKRUGER: Rainbow trout are able to camouflage their swimming direction by bending into a C shape. And then they swim away in a different direction they have been swimming before.\n\nDANIEL: This new posture causes the trout to spin off two vortex rings in opposite directions, kind of like smoke rings made out of water. And only one of those rings, the slightly smaller one, moves in the direction the fish is swimming in, potentially confusing a harbor seal in pursuit.\n\nKRUGER: So I wanted to know if a harbor seal can read that camouflage and still follow the fish.\n\nDANIEL: Kruger thought that if a seal could differentiate between the sizes of the vortex rings, it'd know the correct one to chase. To test her idea, she worked with an adult harbor seal living at a marine science center in Germany...\n\n(SOUNDBITE OF SEAL ROARING)\n\nDANIEL: ...Named Filou. Here he is roaring and slapping his side with his flipper.\n\n(SOUNDBITE OF SEAL SLAPPING)\n\nKRUGER: We have a very strong bond. So Filou actually likes to do everything correct. He likes learning new things. If he has one mistake, he gets frustrated. Yeah, he's a nerd.\n\nDANIEL: In the experiment, Filou had to learn to select the bigger of two vortex rings generated artificially underwater. Kruger spent almost two years training him, but he finally got it and was able to distinguish between the rings, even when the size difference was less than the width of your thumb and far less than what they'd need to discern in the wild.\n\nKRUGER: Which tells me that Filou would still be able to follow the correct direction to successfully hunt and prey on the rainbow trout.\n\nDANIEL: It's just one animal, but Kruger and her colleagues say it's likely true of harbor seals more generally. The research is published in the Journal of Experimental Biology.\n\nROBYN GRANT: I would've loved to have some information about the precise movements of the whiskers, but this is a great start to tell us what they're capable of doing.\n\nDANIEL: Robyn Grant is a sensory biologist at Manchester Metropolitan University who wasn't involved in the study. She says it's worth understanding how an animal like a harbor seal senses its surroundings to know how it might be affected by changes to its environment, including extreme weather events.\n\nGRANT: You can imagine that that can mask some of these critical stimuli that the seals would like to pick up.\n\nDANIEL: Plus, Grant says these findings may inspire sensors that could help aquatic robots navigate their surroundings for underwater archaeology or biological surveys.\n\nFor NPR News, I'm Ari Daniel.\n\n(SOUNDBITE OF AMIE BLU SONG, \"EVERYTHING ABOUT HER\")\n\nCopyright © 2025 NPR. All rights reserved. Visit our website terms of use and permissions pages at www.npr.org for further information.\n\nAccuracy and availability of NPR transcripts may vary. Transcript text may be revised to correct errors or match updates to audio. Audio on npr.org may be edited after its original broadcast or publication. The authoritative record of NPR’s programming is the audio record.",
      "source": "NPR",
      "url": "https://www.npr.org/2025/10/01/nx-s1-5554845/seal-whiskers-can-track-subtle-motions-in-the-ocean",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Intel (NASDAQ:INTC) Receives Hold Rating from Deutsche Bank Aktiengesellschaft",
      "content": "Intel (NASDAQ:INTC – Get Free Report)‘s stock had its “hold” rating reiterated by equities researchers at Deutsche Bank Aktiengesellschaft in a research report issued to clients and investors on Monday, MarketBeat.com reports. They presently have a $30.00 price objective on the chip maker’s stock, up from their prior price objective of $23.00. Deutsche Bank Aktiengesellschaft’s target price points to a potential downside of 10.61% from the company’s current price.\n\nA number of other research analysts have also issued reports on the company. Benchmark upgraded Intel from a “hold” rating to a “buy” rating and set a $43.00 target price on the stock in a research report on Friday, September 19th. Northland Securities boosted their price target on Intel from $28.00 to $42.00 in a research report on Friday, September 19th. Erste Group Bank upgraded Intel from a “sell” rating to a “hold” rating in a research report on Monday, September 22nd. Cantor Fitzgerald boosted their price target on Intel from $26.00 to $36.00 and gave the stock a “neutral” rating in a research report on Friday, September 19th. Finally, Stifel Nicolaus boosted their price target on Intel from $21.00 to $24.50 and gave the stock a “hold” rating in a research report on Monday, July 21st. Two analysts have rated the stock with a Buy rating, twenty-four have assigned a Hold rating and five have assigned a Sell rating to the stock. According to MarketBeat, the stock currently has an average rating of “Reduce” and a consensus price target of $26.19.\n\nGet Intel alerts:\n\nCheck Out Our Latest Report on Intel\n\nIntel Trading Down 2.7%\n\nShares of NASDAQ:INTC opened at $33.56 on Monday. Intel has a 1 year low of $17.67 and a 1 year high of $36.30. The firm has a market capitalization of $146.89 billion, a price-to-earnings ratio of -7.04 and a beta of 1.23. The company has a debt-to-equity ratio of 0.42, a current ratio of 1.24 and a quick ratio of 0.92. The business’s 50 day moving average price is $24.60 and its 200-day moving average price is $22.55.\n\nIntel (NASDAQ:INTC – Get Free Report) last announced its earnings results on Thursday, July 24th. The chip maker reported ($0.10) earnings per share (EPS) for the quarter, missing analysts’ consensus estimates of $0.01 by ($0.11). Intel had a negative net margin of 38.64% and a negative return on equity of 3.78%. The business had revenue of $12.86 billion for the quarter, compared to analysts’ expectations of $11.88 billion. During the same quarter last year, the business earned $0.02 EPS. The company’s quarterly revenue was up .5% on a year-over-year basis. Intel has set its Q3 2025 guidance at 0.000-0.000 EPS. On average, equities research analysts forecast that Intel will post -0.11 earnings per share for the current fiscal year.\n\nHedge Funds Weigh In On Intel\n\nA number of institutional investors and hedge funds have recently added to or reduced their stakes in the stock. Verdence Capital Advisors LLC boosted its stake in Intel by 1.1% during the first quarter. Verdence Capital Advisors LLC now owns 45,682 shares of the chip maker’s stock worth $1,037,000 after buying an additional 486 shares during the last quarter. Independent Wealth Network Inc. lifted its stake in shares of Intel by 5.2% in the 2nd quarter. Independent Wealth Network Inc. now owns 9,927 shares of the chip maker’s stock valued at $222,000 after purchasing an additional 490 shares during the last quarter. Cary Street Partners Investment Advisory LLC lifted its stake in shares of Intel by 23.1% in the 1st quarter. Cary Street Partners Investment Advisory LLC now owns 2,614 shares of the chip maker’s stock valued at $59,000 after purchasing an additional 491 shares during the last quarter. HHM Wealth Advisors LLC lifted its stake in shares of Intel by 6.3% in the 2nd quarter. HHM Wealth Advisors LLC now owns 8,384 shares of the chip maker’s stock valued at $188,000 after purchasing an additional 497 shares during the last quarter. Finally, one8zero8 LLC lifted its stake in shares of Intel by 4.2% in the 1st quarter. one8zero8 LLC now owns 12,320 shares of the chip maker’s stock valued at $280,000 after purchasing an additional 500 shares during the last quarter. Institutional investors and hedge funds own 64.53% of the company’s stock.\n\nAbout Intel\n\n(Get Free Report)\n\nIntel Corporation designs, develops, manufactures, markets, and sells computing and related products and services worldwide. It operates through Client Computing Group, Data Center and AI, Network and Edge, Mobileye, and Intel Foundry Services segments. The company's products portfolio comprises central processing units and chipsets, system-on-chips (SoCs), and multichip packages; mobile and desktop processors; hardware products comprising graphics processing units (GPUs), domain-specific accelerators, and field programmable gate arrays (FPGAs); and memory and storage, connectivity and networking, and other semiconductor products.\n\nFeatured Articles\n\nReceive News & Ratings for Intel Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Intel and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/01/intel-nasdaqintc-receives-hold-rating-from-deutsche-bank-aktiengesellschaft/",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Trump causes bipartisan alarm by turning shutdown into DOGE 2.0",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/a30a6f7e926fd85e",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "US said to provide Ukraine with intel for long-range strikes",
      "content": "The United States will start providing Ukraine with intelligence that will support long-range missile strikes on Russia's energy infrastructure, the Wall Street Journal reported, citing unnamed US...\n\nThis story appeared on breakingthenews.net , 2025-10-01 23:18:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/6e0b8ec3f05c77bc",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Intel & TSMC invest billions to transform Arizona into semiconductor powerhouse",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20251001PD210/tsmc-intel-arizona-investment-semiconductors-manufacturing.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Intel’s stock extends its gains on hopes AMD could go from rival to partner",
      "content": "Intel has been the beneficiary of recent financial investments, but a report indicates it’s in talks to book AMD as a manufacturing customer.\n\nThis story appeared on marketwatch.com , 2025-10-01 21:37:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/efc126bcf4336f1c",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Wall Street sets more records, but bond yields drop following discouraging data on the job market",
      "content": "NEW YORK (AP) — Stocks rose to more records on Wednesday, as Wall Street still doesn’t care much about the shutdown of the U.S. government, but yields sank in the bond market following the latest discouraging signals on the economy.\n\nThe S&P 500 climbed 0.3% to top its prior all-time high, which was set last week. The Dow Jones Industrial Average added 43 points, or 0.1%, to its own record set the day before, while the Nasdaq composite rose 0.4%.\n\nThe action was stronger in the bond market, where Treasury yields dropped after a report suggested hiring may have been much weaker across the country last month than economists expected.\n\nEmployers outside the government actually cut 32,000 more jobs than they added, according to the survey by ADP Research, with the Midwest taking particularly hard hits. What’s worse, the survey also revised down its numbers for employment in August, to a loss of 3,000 jobs from a previously reported gain of 54,000.\n\nUsually, traders on Wall Street wait for a more comprehensive jobs report that comes from the U.S. government each month to suss out how the job market is doing. The U.S. government gets its data from a larger sample of employers than the ADP survey, which does not have a perfect track record predicting what the more comprehensive report will say each month.\n\nBut the next Labor Department report, scheduled for Friday, is likely to be delayed because of the shutdown of the U.S. government that began just after midnight.\n\n“Whether this is an accurate statistic or not, people in the markets believe that it signals something,” according to Carl Weinberg, chief economist at High Frequency Economics. “The signal from today’s headline will not be a good one.”\n\nThe hope on Wall Street has been that the job market will continue to slow by a very precise amount: enough to convince the Federal Reserve to keep cutting interest rates, but not by so much that it brings a recession.\n\nThat’s a delicate balance to achieve, and every economic report from the U.S. government that gets delayed only increases the uncertainty about whether it’s possible. Stocks have already run to records on expectations for coming cuts to rates, so a lack of them could send the market lower.\n\nTo be sure, the stock market and economy have typically powered through past shutdowns, particularly if they are short in duration. But this shutdown could be different in a couple ways, including the threat that the White House may use it to push for large-scale firings of federal workers.\n\nOn Wall Street, Nike rose 6.4% after blowing past analysts’ expectations for profit in the latest quarter. The athletic giant reported strong growth for apparel sold in North America.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/asian-shares-mixed-markets-shrug-033016775.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Jefferies Lifts PT on NVIDIA Corporation (NVDA) Stock",
      "content": "NVIDIA Corporation (NASDAQ:NVDA) is one of the Unstoppable Stocks to Buy and Hold for the Next 5 Years. On September 27, Jefferies analyst Blayne Curtis lifted the price target on the company’s stock to $220 from $205, while keeping a “Buy” rating, as reported by The Fly. After NVIDIA Corporation (NASDAQ:NVDA) announced a partnership with OpenAI to deploy 10GW of Nvidia systems, the analyst highlighted that management made clear that this partnership reflects incremental demand and that it doesn’t overlap with existing OpenAI plans with Oracle or Microsoft.\n\nJefferies Lifts PT on NVIDIA Corporation (NVDA) Stock\n\nTalking about the partnership, NVIDIA Corporation (NASDAQ:NVDA) stated that it plans to invest up to $100 billion in OpenAI progressively as each gigawatt is deployed. Notably, the first gigawatt of NVIDIA systems is expected to be deployed in H2 2026 on the NVIDIA Vera Rubin platform. Elsewhere, NVIDIA Corporation (NASDAQ:NVDA) and Intel Corporation collaborated to develop multiple generations of custom data center and PC products, which accelerate applications and workloads throughout hyperscale, enterprise, and consumer markets.\n\nChautauqua Capital Management, a division of Baird Asset Management, is a boutique investment firm that released its Q2 2025 investor letter for the “Baird Chautauqua International and Global Growth Fund”. Here is what the fund said:\n\n“NVIDIA Corporation (NASDAQ:NVDA) reported first quarter results that were extremely solid. The company took a write-down on China-specific datacenter products and flushed out any future China contributions from their guidance, following the new export restrictions introduced in April. Demand commentary ex China was extremely encouraging—Nvidia is outgrowing expectations despite supply constraints and outgrowing competing ASIC products by a large margin. We have been underweight Nvidia relative to the benchmark, which was up 46% in the quarter, given our short-to medium-term concerns that the feverish AI datacenter build may be resulting in overcapacity, which has not come to bear.”\n\nWhile we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you’re looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 13 Cheap AI Stocks to Buy According to Analysts and 11 Unstoppable Growth Stocks to Invest in Now\n\nDisclosure: None. This article is originally published at Insider Monkey.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/jefferies-lifts-pt-nvidia-corporation-062728065.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Disabling IPv6 in Java",
      "content": "Java applications by default support both IPv4 and IPv6, depending on the underlying operating system and network configuration. In some environments, IPv6 may cause connectivity or compatibility issues, especially if your application or infrastructure is not fully IPv6-ready. In such cases, you may want to explicitly disable IPv6 in Java or even at the operating system level. Let us delve into understanding how to use Java to disable IPv6 and the different methods available across operating systems.\n\n1. What is IPv6?\n\nIPv6 (Internet Protocol version 6) is the latest version of the Internet Protocol designed to replace IPv4 due to its limited address space. IPv6 uses 128-bit addresses, allowing for a massive number of unique IP addresses compared to IPv4’s 32-bit addressing. While it provides improvements such as better routing, auto-configuration, and security features, many legacy applications and networks still rely heavily on IPv4. This sometimes creates the need to disable IPv6 temporarily.\n\n2. Use a System Property to Turn Off IPv6\n\nIn Java, you can disable IPv6 by setting a system property called java.net.preferIPv4Stack to true . This forces Java to use IPv4 instead of IPv6 when making network connections.\n\n// DisableIPv6Example.java import java.net.InetAddress; import java.net.UnknownHostException; public class DisableIPv6Example { public static void main(String[] args) { // Set system property to prefer IPv4 System.setProperty(\"java.net.preferIPv4Stack\", \"true\"); try { // Resolve localhost InetAddress localHost = InetAddress.getLocalHost(); System.out.println(\"Hostname: \" + localHost.getHostName()); System.out.println(\"IP Address: \" + localHost.getHostAddress()); // Resolve a domain (example: google.com) InetAddress[] addresses = InetAddress.getAllByName(\"google.com\"); for (InetAddress addr: addresses) { System.out.println(\"Resolved: \" + addr); } } catch (UnknownHostException e) { e.printStackTrace(); } } }\n\n2.1 Code Explanation\n\nThe Java program demonstrates how to disable IPv6 by setting the system property java.net.preferIPv4Stack to true , which forces the application to use IPv4 instead of IPv6. It then retrieves and prints the hostname and IP address of the local machine using InetAddress.getLocalHost() . Additionally, it resolves and prints all IP addresses associated with the domain google.com using InetAddress.getAllByName() . If the host cannot be resolved, it catches and prints the UnknownHostException .\n\n2.2 Code Output\n\nThe program outputs the following when run.\n\nHostname: your-machine-name IP Address: 192.168.1.10 Resolved: google.com/142.250.182.14 Resolved: google.com/142.250.182.100 Resolved: google.com/142.250.182.113 ...\n\nNotice that the resolved addresses are IPv4 (in dotted decimal format) rather than IPv6 (which appears as long hexadecimal sequences like 2404:6800:4009:80b::200e ).\n\n3. OS-Level Command to Disable IPv6\n\nDisabling IPv6 at the OS level ensures that all applications, not just Java, will fall back to IPv4. The commands vary depending on your operating system:\n\nLinux (Temporary Disable): This method disables IPv6 until the system is restarted. It is useful for testing or troubleshooting without permanently modifying system configuration. sudo sysctl -w net.ipv6.conf.all.disable_ipv6=1 sudo sysctl -w net.ipv6.conf.default.disable_ipv6=1 # Output: # net.ipv6.conf.all.disable_ipv6 = 1 # net.ipv6.conf.default.disable_ipv6 = 1\n\nLinux (Permanent Disable): To make the change persistent across reboots, you need to update the /etc/sysctl.conf file so that IPv6 is always disabled when the system starts. This is commonly done on servers where IPv6 is not required. Add the following lines to /etc/sysctl.conf : net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 Then apply the changes using: sudo sysctl -p # Output: # net.ipv6.conf.all.disable_ipv6 = 1 # net.ipv6.conf.default.disable_ipv6 = 1\n\nfile so that IPv6 is always disabled when the system starts. This is commonly done on servers where IPv6 is not required. Add the following lines to : Windows: On Windows, IPv6 can be disabled via the network adapter settings (GUI) or by running a PowerShell command. Disabling IPv6 may affect applications or services that rely on it, so it should be done cautiously. # Run PowerShell as Administrator Disable-NetAdapterBinding -Name \"Ethernet\" -ComponentID ms_tcpip6 # Output: # Name InterfaceDescription Status # ---- -------------------- ------ # Ethernet Intel(R) Ethernet Connection Disconnected # ms_tcpip6 binding removed successfully\n\n4. Conclusion",
      "source": "Javacodegeeks.com",
      "url": "https://www.javacodegeeks.com/disabling-ipv6-in-java.html",
      "timestamp": "2025-10-01"
    },
    {
      "headline": "Ninkear A15 Air: Notebook with Ryzen APU, numpad and fingerprint sensor is now available",
      "content": "All things considered, the Ninkear A15 Air is a fairly affordable notebook that appears to be quite portable as well. For the laptop, the company has chosen an AMD Ryzen APU over an Intel processor.\n\n4 Reviews ← exclude selected types\n\nWhilst Ninkear may not be a household name amongst laptop manufacturers, we have already had the opportunity to cover and review some of the company’s products, including the A16 Pro. The recently launched 3500U-powered Ninkear A15 Air is now available for €349 ($398) including shipping, with stocks dispatched from Europe. However, the product currently doesn’t ship to the US, and customers may encounter issues with warranty support.\n\nPerhaps unsurprisingly at its price point, the A15 Air lacks a dedicated GPU and probably can’t deliver blazingly fast performance. It is powered by an AMD Ryzen 5 3500U, a highly dated processor that we’ve seen in older laptops. That said, the system should offer enough performance for watching YouTube videos or browsing the web. The device is also equipped with 16 GB of DDR4 memory and a 512 GB SSD, providing a decent amount of RAM and storage.\n\nWeighing 1.75 kg (3.86 lb) and measuring 1.9 cm (0.75 in) thick, the Ninkear A15 Air features a 15.6-inch display with a 1080p resolution, 60 Hz refresh rate, and 45% NTSC (~65% sRGB) gamut coverage. It also offers two USB-C ports (both capable of video output), an HDMI interface, an Ethernet port, and a memory card reader. Other notable features include Wi-Fi 5 support, a fingerprint sensor, and a built-in webcam.\n\nThe A15 Air was previously available with a more powerful APU, the Ryzen 5 4600H, but that SKU appears to be all sold out now.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Ninkear-A15-Air-Notebook-with-Ryzen-APU-numpad-and-fingerprint-sensor-is-now-available.1129840.0.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "H-1B visa fees, tariffs, a stake in Intel? How Silicon Valley has fared under Trump",
      "content": "By Levi Sumagaysay, CalMatters\n\nIn exchange for its embrace of Trump 2.0, Silicon Valley has received a grab bag of policies that some experts worry could hurt the U.S. tech industry in the long run.\n\nOn the one hand, corporate tax rates will stay low and the cryptocurrency and artificial…\n\nThis story appeared on siliconvalley.com , 2025-10-02 18:28:02.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/32e17259aa6b54c2",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Ex-US cyber boss slams politics getting in the way of preparedness",
      "content": "interview The bodies responsible for securing America from cyberattacks are currently too fragmented to be successful, according to former US National Cyber Director Chris Inglis, the first person ever to hold that job.\n\nThe Register spoke with Inglis on October 1 as the federal government shut down, a key cyber-threat sharing law expired, funding for a similar intel-swapping effort at the state and local level ended, and the US Cybersecurity and Infrastructure Security Agency reportedly furloughed 65 percent of its workforce.\n\nIn all, it's not a good look for American cybersecurity at a time when the US faces mounting digital threats from China and Russia, along with homegrown cybercriminals.\n\nWhen asked about US cyber-readiness, Inglis told The Register that \"it's almost fractured by design, because we haven't quite stitched it together.\"\n\nHe pointed to at least two current dilemmas. \"One is the cessation of the CISA of 2015.\"\n\nHe's referring to the decade-old Cybersecurity Information Sharing Act: a voluntary cyber-threat information-sharing law between the private sector and the federal government that provides legal protections to companies and other non-federal entities to encourage them to share threat indicators with the feds.\n\nCISA 2015 expired on September 30 despite widespread support from industry - and despite any real opposition from anyone on either side of the political aisle. It seems to have been a case of benign neglect.\n\n\"I don't know anybody who opposes its extension, and yet it has lapsed,\" Inglis said. \"I'm hoping the activities that have taken place under CISA 2015 have been sufficiently valuable to all sides that sharing will continue - to at least some degree - until the legislation can be put back in place.\"\n\nWe need every living soul on the front lines\n\nThe furloughed federal employees, many of whom are tasked with defending government networks and other critical infrastructure, are \"also regrettable,\" Inglis said.\n\n\"Leave aside politics. Each and every person who's on the front lines of this is essential for the collective effort that we're mounting,\" he continued. \"It's not to say that there isn't a bulwark of people in the private sector and non-federal positions who are also important, but we need every living soul on the front lines.\"\n\n\"Fracturing this by design, because we don't have the right sense of a coalition - taking some assets off the field - it's not wise at this moment in time, because the transgressors never have a day off.\" Inglis said.\n\nFormer US National Cyber Director Chris Inglis. Photo credit: Global Cybersecurity Forum - Click to enlarge\n\nPlus, AI allows cybercriminals to scale their attacks much more rapidly, helping them write a convincing phishing email in multiple languages with legit-looking company logos, or make a digital scam more convincing via AI-generated images, audio, and video.\n\n\"Transgressors are studying it, using it every day, at scope and scale, and that becomes something that's not simply a quantity of activity on the periphery of the things we defend, but it takes on a qualitative inflection point, and that's a huge threat,\" Inglis said.\n\nDefenders \"typically lag\" in adopting new technologies because they, unlike the attackers, don't want to ship or use a product with any major defects. This gives the criminals an 8- to 12-month advantage over infosec professionals, according to the former National Cyber Director, and \"we can't afford that at this moment in time.\"\n\nThis doesn't mean skimping on securing AI systems, he added. Safety and security should be built into AI models during development, not layered on as an afterthought, which will cost less in the long-term, Inglis said. But that requires investment, both financial and in terms of human resources, across corporations and government. Overall, he says, securing our digital infrastructure needs to receive the same level of attention and investment as any other core business practice.\n\n\"If we invested more in the resilience of digital infrastructure, if we knew that like the back of our hands - take away the possibility somebody is going to live off your land and you don't know it - we could actually put a dent in this,\" Inglis said. \"You make the case that their business proposition, the viability of that company, depends upon digital infrastructure in the same way that hiring the next CEO, or making wise choices about what markets and what capital structure you have does. That's where we need to place digital infrastructure.\" ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/10/02/exnational_cyber_boss_us_cyber/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Intel bets its future on Nvidia's CUDA",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20251002PD235/intel-partnership-x86-cuda-packaging.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Tenstorrent open to Intel besides TSMC and Samsung for chip production: CEO",
      "content": "TAIPEI -- AI startup Tenstorrent is in talks with the world's top chipmakers TSMC and Samsung about using their cutting-edge 2-nanometer tech to produce its chips, but would not rule out also working with Intel's contract chipmaking service in the future, founder and CEO Jim Keller told…\n\nThis story appeared on asia.nikkei.com , 2025-10-02 00:00:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/21419b502c19af21",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "An Interview with Ben Bajarin About AI Infrastructure",
      "content": "Subscribe to Stratechery Plus for full access. Already subscribed? Log in $15 / month or $150 / year\n\nWith Stratechery Plus you get access to the subscriber-only Stratechery Update and Stratechery Interviews, and the Sharp Tech, Sharp China, Dithering, Greatest of All Talk, and Asianometry podcasts.\n\nStratechery Update\n\nSubstantial analysis of the news of the day delivered via three weekly emails or podcasts. Stratechery Interviews\n\nInterviews with leading public CEOs, private company founders, and discussions with fellow analysts. Dithering\n\nA twice-weekly podcast from John Gruber and myself: 15 minutes an episode, not a minute less, not a minute more. Sharp Tech\n\nAndrew Sharp and myself discuss how technology works and the ways it impacts our lives. Sharp China\n\nA weekly podcast from Andrew Sharp and Sinocism’s Bill Bishop about understanding China and how China impacts the world. Greatest Of All Talk\n\nA twice-weekly podcast from Andrew Sharp and Ben Golliver about the NBA, life, and national parks. Asianometry\n\nAudio and transcripts of the Asianometry YouTube channel, the best source for learning about how tech works.\n\nStratechery Updates are also available via SMS, RSS, or on this site. Please see the Stratechery Update Schedule for more details about delivery times and planned days-off. Please note that all subscriptions auto-renew monthly/annually (but can be cancelled at any time). If you are interested in ordering and managing multiple subscriptions for your team or company, please fill in the form here.\n\nFrequently-Asked Questions\n\nHow do I subscribe to the Stratechery Podcast? Once you are subscribed, please visit your Delivery Preferences where you will find easy-to-follow instructions for adding Stratechery Podcasts to your favorite podcast player.\n\nCan I read Stratechery via RSS? Yes! Create a Stratechery Passport account, go to Delivery Preferences, and add your personalized RSS feed. Free accounts will have access to Weekly Articles, while subscribers will have access to the Daily Update as well.\n\nCan I share a Stratechery Update subscription with a friend? No, the Stratechery Update and Stratechery Podcast are intended for one subscriber only. Sharing emails, using shared inboxes, or sharing RSS feeds is a violation of Stratechery’s Terms of Service, and your account may be suspended or your RSS feed reset. Of course occasional forwarding of the Stratechery Update to interested friends or colleagues is totally fine.\n\nCan I buy a subscription for my team? Yes! You can purchase a team subscription here.\n\nCan I switch to an annual plan? Yes! Just go to your account page, choose the ‘Subscriptions’ tab, and click the Annual upgrade button. You will be charged immediately, with a prorated discount applied for the remainder of your current monthly plan.\n\nDo you offer a student discount? Stratechery is purposely kept at a low price — thousands of dollars less than other analyst reports or newsletters — to ensure it is accessible to everyone, including students.\n\nCan you create a custom invoice that meets my government/company requirements? I am happy to create an invoice to your specification for annual subscribers; however, it is simply not viable for me to offer this service to monthly subscribers. Therefore, if you need a custom invoice please subscribe or switch to an annual subscription and contact Stratechery. June 1, 2021 Update: We are hoping to add native support for custom invoices to Passport; you can subscribe to Passport Updates to be notified when it is available.",
      "source": "Stratechery.com",
      "url": "https://stratechery.com/2025/an-interview-with-ben-bajarin-about-ai-infrastructure/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Maingear’s Apex Liquid-Cooled PCs Will Dominate Your Games And Your Wallet",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/mitchwallace/2025/10/02/maingears-apex-liquid-cooled-pcs-will-dominate-your-games-and-your-wallet/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "【Razer】次世代接続性能を誇る「Razer Thunderbolt(TM) 5 Dock Chroma」と「Razer Core X V2」を発表2025年10月10日（金）発売",
      "content": "ゲーマー向けライフスタイルブランドとして世界をリードするRazer™（本社：米国カリフォルニア州およびシンガポール、共同創業者兼CEO：Min-Liang Tan）は、最新のThunderbolt™ 5に対応した2つの先進的なPCアクセサリー「Razer Thunderbolt™ 5 Dock Chroma」と外付けGPUボックス「Razer Core X V2」を発表しました。2025年10月2日（木）より予約開始いたします。販売開始は2025年10月10日（金）を予定しています\n\nPCの接続性と外付けグラフィックス性能を進化させるこのパワフルな2製品は、帯域幅の拡大、臨場感ある映像体験、そして柔軟なモジュール構成を可能にし、仕事にもゲームにも最適です。Thunderbolt™ 5は、最大120Gb/sの転送速度を実現し、高速接続の新たな基準を打ち立てます。これにより、高性能な周辺機器や高速ストレージの使用、複数の4Kディスプレイの同時接続が可能になり、他のThunderbolt™デバイスとのデイジーチェーン接続にも対応。圧倒的な生産性と没入感あふれるゲーム体験を提供します。\n\n1本のケーブルで3画面4K構成をすっきり接続できるシンプルな環境づくりから、ノートPCにデスクトップクラスのGPU性能を与えるブーストまで、RazerのThunderbolt™ 5対応製品は、安定したパフォーマンス、スマートなケーブル管理、そして幅広いデバイスとの互換性を備えています。\n\nRazerのノートPC＆アクセサリー部門責任者トラヴィス・ファーストは次のように述べています。\n\n「Razer Thunderbolt™ 5 Dock Chromaは、急速に高まる高速データ転送やマルチディスプレイ対応のニーズに応えるために設計されました。Razer Core X V2 は、その体験をさらに拡張する製品です。最新のNVIDIAおよびAMDグラフィックスカードに対応することで、超薄型のThunderbolt™対応ノートPCでも、デスクトップ級のグラフィックス性能を実現できます。クリエイティブやゲーミング用途にも対応する、スムーズで強力な外部GPUソリューションです」\n\n\n\nIntel社のマーケティング部門ジェネラルマネージャーのベン・ハッカー氏のコメント\n\n「RazerはThunderbolt™ 5が約束する“圧倒的なパフォーマンス、比類なき柔軟性、そしてシームレスなユーザー体験”を着実に実現し続けています。モバイルコンピューティングの未来を共に切り拓いていけることを誇りに思います」\n\nRazer Thunderbolt™ 5 Dock Chroma：高速転送と多彩な接続をシンプルに\n\nRazer Thunderbolt™ 5 Dock Chromaは、進化する現代のワークステーションやゲーミング環境のニーズに応えるために設計されました。3台の4Kディスプレイを同時にサポートし、高速データ転送に対応、M.2 用ストレージスロットを備えたこのドックは、多彩な機能をひとつの効率的なハブに集約しています。大容量のメディアファイルを扱うクリエイターから、スマートで高性能な環境を求めるゲーマーまで、幅広いユーザーの複数デバイスによる作業を支援する、豊富なポート構成とThunderbolt Share機能を搭載した多用途なソリューションです。\n\n主な特長：\n\nトリプル4Kディスプレイ対応\n\n最大3台の4Kディスプレイを144Hzで駆動し、生産性向上からエンターテインメントまで滑らかで没入感のある映像体験を提供します。\n\nThunderbolt™ 5の高速帯域幅\n\n最大120Gb/sの高速データ転送を実現し、接続されたデバイス間で低遅延のパフォーマンスを可能にします。\n\nストレージスロットと共有機能\n\n別途M.2 SSDを用意することで、最大8TBの内部ストレージによる高速ファイルアクセスを実現。さらにThunderbolt Share機能により、複数PC間でのファイル転送やKVM機能のようなマルチPCコントロールが可能となり、マルチタスクや作業効率を大幅に向上させます。\n\n豊富な接続ポートで一括管理\n\n計10の入出力ポートを備えており、高リフレッシュレートのモニター、ゲーミング周辺機器、外部ストレージ、入力デバイスなど幅広い接続に対応します。最新機器から従来機器まで多世代のデバイスをシームレスに統合し、ケーブルの煩雑さを抑えてすっきりとした作業環境を実現します。\n\n最大140Wの電力供給\n\n250Wの専用電源アダプターにより、ノートPCへ最大140Wの高速充電が可能。パワーを多く必要とする機器も安心して使えます。\n\n※Whiteモデル「Razer Thunderbolt™ 5 Dock Mercury White」は、ライティング機能「Razer Chroma™ RGB」を搭載しておりません。\n\nRazer Core X V2：ノートPCでデスクトップ級のグラフィックス性能を実現\n\n「Razer Core X V2」は、Thunderbolt™ 4、Thunderbolt™ 5、そして一部の USB4 ゲーミングノートやハンドヘルド端末など、対応デバイス向けに設計された次世代の外付けグラフィックスエンクロージャーです。柔軟性と圧倒的なグラフィック性能を両立し、持ち運びやすいノートPCを、ゲーミング・コンテンツ制作・将来を見据えた高性能デスクトップ環境へと変貌させる、プラグアンドプレイ対応のアップグレードソリューションです。\n\nRazer Core X V2は、フルサイズのPCIeグラフィックスカードと標準ATX電源に対応しており、最新のNVIDIA® GeForce®やAMD Radeon™ GPUを簡単に取り付けることができます。Thunderbolt™ 5接続により、Thunderbolt™ 4の最大2倍の帯域幅を実現し、高速なデータ転送と幅広いデバイス間でのシームレスなパフォーマンスを提供します。\n\n設置は直感的かつスピーディで、わずか数分でデスクトップ級のグラフィックス性能を利用可能にします。筐体には通気性に優れたスチール製シャーシと、システム負荷に応じて自動で回転数を調整する120mmファンを搭載。さらに高度な制御を求めるユーザーには、Razer Synapseソフトウェアを使用することで、冷却性能と静音性の最適化に向けたファンカーブのカスタマイズも可能です。\n\n1本のThunderbolt™ 5ケーブルでRazer Core X V2をホストデバイスに接続。必要に応じてデスクトップ級のグラフィックス性能を提供するとともに、最大140Wの給電にも対応し、高性能なモバイルコンピューティングに最適なソリューションとなっています。\n\n※本製品にグラフィックスカードと電源ユニットは付属していません。対応する寸法を公式サイトの製品ページにてご確認の上、別途ご用意ください。\n\nRazer Thunderbolt™ 5 Dock ChromaとRazer Core X V2の登場により、Razerはゲーマーやクリエイター、プロフェッショナル向けに、パフォーマンスを追求したラップトップアクセサリーのエコシステムをさらに拡充します。これらの新製品は、高速性、柔軟性、機能性のバランスを追求し、あらゆる環境でユーザーが最適なセットアップを実現できるようサポートします。\n\n公式サイトURLは、以下の各製品リンクをご参照ください\n\n※Whiteモデル「Razer Thunderbolt™ 5 Dock Mercury White」は、ライティング機能「Razer Chroma™ RGB」を搭載しておりません。\n\n\n\n■「Razer Thunderbolt™ 5 Dock Chroma / Razer Core X V2」取扱店\n\n全国の家電量販店、PCショップ、オンラインショップ等で販売いたします。\n\n■販売店様からのお問合せ\n\n株式会社アユート\n\nPC事業部\n\nWEB： https://www.aiuto-jp.co.jp/contact/b2b.php\n\n■Razerについて\n\nRazer™は、ゲーマーのためにゲーマーによって設立された、世界的な大手ライフスタイルブランド企業で、「For Gamers. By Gamers™」（ゲーマーの為にゲーマーが作る）をスローガンに掲げています。\n\nRazerの商標である3つの頭を持つ蛇は、世界中のゲーミングコミュニティやeスポーツコミュニティで最も認知されているロゴの一つです。あらゆる大陸にファンを持つRazerは、ハードウェア、ソフトウェア、サービスで構成された、ゲーマーを対象とする世界最大のエコシステムを設計・構築してきました。\n\nRazerは、高性能ゲーミング周辺機器やBladeゲーミングノートPCといった、受賞歴のあるハードウェアを提供しています。Razer Chroma RGBやRazer Synapseなどで構成されるRazerのソフトウェアスイートは、カスタマイズ機能や照明効果機能、最適化機能を備え、2億5,000万人以上のユーザーに利用されています。またRazerは、ゲーマー、若者、ミレニアル世代、Z世代向けに、Razer Goldを使用した決済サービスを提供しています。これは、68,000を超えるゲームタイトルで利用できる、世界最大のゲーム決済サービスのひとつです。さらに、この決済サービスに連動した報酬プログラムであるRazer Silverを提供しています。\n\nRazerは、持続可能な未来の実現に取り組んでおり、#GoGreenWithRazer活動（さまざまな取り組みを通じて環境への影響を最小限に抑えるための、10年間のロードマップ）を通じて社会的責任を果たすべく努力しています。\n\n2005年に設立されたRazerは、カリフォルニア州アーバインとシンガポールの2か所に本拠地を構え、ハンブルクと上海に地域統括本部を置き、世界各地の19か所に事業所を展開しています。これまで数々のブランドアクティベーションを行ってきたRazerは、2025年に20周年を迎えます。詳細についてはhttps://rzr.to/20anniをご覧ください。\n\n■Razer公式リンク\n\nRazer日本公式サイト：https://www.razer.com/jp-jp/\n\nRazer JP X (旧：Twitter) アカウント：https://www.x.com/razerjp\n\n* (C) 2025 Razer Inc. All rights reserved.\n\n* 仕様、および、デザインは予告なしに変更される場合があります。\n\n* その他、記載されている会社名、製品名は、各社の登録商標または商標です\n\nRazer — For Gamers. By Gamers.TM\n\npress.razer.com",
      "source": "Prtimes.jp",
      "url": "https://prtimes.jp/main/html/rd/p/000000031.000163154.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Intel stock is up 50% over the last month, putting U.S. stake at $16 billion",
      "content": "Shares of U.S. chipmaker Intel climbed 3% Thursday, putting the monthly gain over 50%.\n\nThe surge pushed the stock past $37, hiking the value of the U.S. government's 10% stake in Intel to roughly $16 billion.\n\nThe Trump administration negotiated an $8.9 billion investment in Intel common…\n\nThis story appeared on cnbc.com , 2025-10-02 18:53:31.630000.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/e9636883bebbac24",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Intel Reportedly In Early Stage Talks To Make Chips For AMD",
      "content": "Intel Reportedly In Early Stage Talks To Make Chips For AMD\n\n\n\nIntel’s stock jumped over 7% Wednesday after Semafor reported the company is in early talks to make chips for longtime rival AMD in its foundry business. AMD shares also ticked higher, up more than 1% on Wednesday - and is up…\n\nThis story appeared on zerohedge.com , 2025-10-02 13:40:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/093a559a8ba6258e",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Rand Paul Straight Up Compares Trump Taking Stakes In Private Companies to Zohran Mamdani’s Socialism",
      "content": "Sen. Rand Paul (R-KY) joined MSNBC’s Stephanie Ruhle this week to discuss President Donald Trump’s plan to create TrumpRX, a government-run website offering discounts on select prescription drugs.\n\nPaul, a libertarian leaning Republican, pulled no punches in criticizing Trump’s willingness to intervene in the free market and even went so far as to compare the Trump administration to self-identified socialist New York City mayoral candidate Zohran Mamdani.\n\nPaul shared his interview on X and wrote, “If you’re going to criticize the socialist Mamdani for wanting to own grocery stores, you better criticize Republicans who want a share of Intel, of Nvidia, or U.S. Steel. Owning even part of the means of production is a step toward socialism. It’s a bad idea and a dangerous precedent.”\n\nIn the clip from earlier in the week, Ruhle asked Paul, “The president wants a stake in big business. At a New York Economic Club event today, the president’s top trade negotiator said that Trump would, quote, ‘Love a stake in every company that’s doing well.’ What do you think about that? I mean, you are a free markets, true capitalism kind of guy. That doesn’t sound like any free markets I know.”\n\n“Yeah, if you’re going to criticize Mamdani for wanting to own the grocery stores, you have to be equal parts critic to any Republican who wants a share of Nvidia, a share of Intel, or a share of U.S. Steel. It’s a bad idea. It’s a slippery slope. And really, it is heading in the direction of what socialism is, which would be owning all of the means of production. If you only own a percentage of the means of production, it still is a step in the wrong direction,” Paul replied.\n\n“Then what do you think about this new partnership that we just heard about today with Pfizer? It’s going to be known as TrumpRx. Our U.S. government is going to sell Pfizer drugs on a website named after Donald John Trump,” Ruhle followed up.\n\n“I haven’t seen all the details so far, but what I will tell you is part of the news report said that it’s driven Pfizer to a negotiated price, a lower negotiated price on Medicaid. I do think the government should negotiate with the full leverage that they have in size for both Medicaid and Medicare,” Paul replied, adding:\n\nAnd I have voted that way as well. As far as bullying companies or taking a percentage of companies, I’m opposed to that. As far as bullying them to offer a certain price on a new website, doesn’t sound like something I would be for, but I haven’t seen the details. But if it’s just trying to get a better price from Medicaid to pay for drugs, that is taxpayer money, and I think we should get the best deal we can get.\n\nWatch the clip above via MSNBC.",
      "source": "Mediaite",
      "url": "https://www.mediaite.com/politics/rand-paul-straight-up-compares-trump-taking-stakes-in-private-companies-to-zohran-mamdanis-socialism/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Intel in negotiations to make AMD’s chips, according to insiders",
      "content": "Intel is trying to claw its way back into relevance with some big moves lately, such as its recently announced alliance with Nvidia. But there’s more going on behind the scenes, including some negotiations with AMD, according to a report by Semafor.\n\nThe aim of this Intel-AMD agreement would be to produce AMD chips in Intel’s own factories, known as foundries. (A foundry manufactures semiconductors according to customer designs.) Intel would therefore realize AMD’s designs, although both compete in the processor market.\n\nThe deal is not yet finalized and an agreement could take months, as further hurdles (such as regulatory reviews) are still pending.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2928109/intel-in-negotiations-to-make-amds-chips-according-to-insiders.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Intel Stock Has Doubled Since April 8. Here Is Where the Stock Could Be at the End of 2025",
      "content": null,
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/35200959/intel-stock-has-doubled-since-april-8-here-is-where-the-stock-could-be-at-the-end-of-2025",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Chipmakers Add $200 Billion in Global Rally on AI Frenzy",
      "content": "Global chipmakers saw their market value soar as investors rushed to get exposure to artificial intelligence, the latest sign of a frenetic bull run that is pushing tech stocks to all-time highs.\n\nThe sector is being swept up by a wave of good news from AI companies, including ChatGPT-owner OpenAI’s record $500 billion valuation on an employee share sale and its pacts with a group of South Korean chipmakers, as well as a report that Intel Corp. is in talks to add Advanced Micro Devices Inc. as a customer.\n\nMost Read from Bloomberg\n\nThe bullishness has pushed the combined market capitalization of the Philadelphia Stock Exchange Semiconductor Index and a gauge tracking Asia chip stocks up by just over $200 billion in the latest session, according to Bloomberg calculations.\n\nKorean chip stocks were among the biggest gainers on Thursday, surging on the OpenAI deal and sending the Kospi Index to a record high. Shares of SK Hynix Inc. jumped 10%, while Samsung Electronics Co. advanced 3.5%.\n\nIn Europe, chip equipment maker ASML Holding NV gained as much as 4.9% on Thursday, bringing its rise from an August trought to almost 50%. Peers including ASM International NV and BE Semiconductor Industries NV also advanced.\n\nAnalysts say the bull run is being driven by a ‘fear of missing out’, with investors largely dismissing concerns about a bubble developing in the AI sector.\n\n“Tech momentum shows no sign of fading — as if gravity doesn’t exist — with headwinds brushed aside and every AI headline sparking bursts of euphoria,” said Hebe Chen, an analyst at Vantage Markets in Melbourne. “Bubble talk lingers, but it’s FOMO that’s clearly running the show. Momentum looks self-sustaining until upcoming fourth quarter earnings may force the reality check.”\n\nThe recent rally has caused a spike in chipmakers’ valuations: Bloomberg’s Asia chip gauge is trading at around 19 times forward earnings estimates while the SOX Index is now trading at 27 times earnings, approaching record highs from 2024.\n\nInvestor Scramble\n\nSince ChatGPT launched the modern AI era, investors have scrambled to get exposure to technology that has the potential to shake-up the global economy. They’ve piled into big infrastructure providers such as chip linchpins Nvidia Corp. and SK Hynix Inc., pushed up valuations of startups like OpenAI and Anthropic, and poured capital into all manner of gear suppliers to the AI boom.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/global-chipmakers-add-200-billion-073238397.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Zania Raises $18 Million for AI-Powered GRC Platform",
      "content": "AI-powered security governance, risk, and compliance (GRC) startup Zania has announced raising $18 million in a Series A funding round that brings the total raised by the company to $20 million.\n\nThe investment round was led by NEA (New Enterprise Associates), with additional support from Anthology Fund, Palm Drive Capital, and various angel investors.\n\nFounded in 2023, Palo Alto, California-based Zania has built an agentic AI platform that relies on autonomous, domain-specific AI ‘teammates’ to perform risk and compliance operations.\n\nThe AI teammates, the company explains, execute tasks based on each company’s context. They continuously collect evidence, and test controls and identify gaps against compliance frameworks.\n\nAdditionally, they can perform full-lifecycle assessment of vendors, provide evaluations of internal risk, and use these evaluations to answer incoming vendor questionnaires with precision.\n\nThe fresh investment, the company says, will help it “build AI agents that can execute the full spectrum of risk and compliance work”.\n\nAiming to automate the entire GRC lifecycle, the company will expand its agent library to cover end-to-end compliance, and will invest in proprietary models performing complex, multi-step reasoning. Additionally, it plans to triple its engineering and go‑to‑market teams.\n\n“Zania has experienced explosive growth in revenue and customers since we launched our first AI agents late last year. We’re excited to continue revolutionizing the security risk, compliance, and audit space by transforming it from tools that merely organize work into true AI teammates that execute highly complex and critical tasks from start to finish,” Zania founder and CEO Shruti Gupta said.\n\nAdvertisement. Scroll to continue reading.\n\nRelated: Descope Raises $35 Million in Seed Round Extension\n\nRelated: Mondoo Raises $17.5 Million for Vulnerability Management Platform\n\nRelated: Unit 221B Raises $5 Million for Threat Intel Aiding Hacker Arrests\n\nRelated: The Team8 Foundry Method for Selecting Investable Startups",
      "source": "Securityweek.com",
      "url": "https://www.securityweek.com/zania-raises-18-million-for-ai-powered-grc-platform/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Seamlessly transfer, back up & wipe your PC with this $35 utility bundle",
      "content": "TL;DR: For $34.99, you get three essential Windows utilities — PCmover Professional, DiskImage, and SafeErase — to transfer, back up, and securely wipe your data like a pro.\n\nUpgrading your PC doesn’t have to feel like a digital moving day gone wrong. With the PC Transfer Kit Bundle featuring PCmover Professional, DiskImage, and SafeErase, you can pack up your files, move into your new machine, and clean up the old one — all without breaking a sweat (or the proverbial bank).\n\nHere’s why this bundle is a game changer:\n\nPCmover Professional takes care of the heavy lifting by transferring your apps, files, and settings from one PC to another — even across different Windows versions. It’s the only migration software officially recommended by Microsoft, Intel, and major PC makers.\n\nSafeErase makes sure anything left behind is gone for good. Use it for everyday secure deletions or a full-system wipe before recycling or selling your old machine.\n\nDiskImage gives you peace of mind with full-system backups. If your PC ever gets hit by malware, corruption, or just bad luck, you can restore everything in a flash.\n\nUsually selling for $129.85, this bundle of powerhouse utilities is on sale for just $34.99 for a limited time — a smart move for anyone upgrading or safeguarding their PC.\n\nPC Transfer Kit Bundle feat. PCmover Professional, DiskImage, and SafeEraseSee Deal\n\nStackSocial prices subject to change.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2925339/seamlessly-transfer-back-up-wipe-your-pc-with-this-35-utility-bundle.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Analyst revamps Dell stock price target before key meeting",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/technology/analyst-revamps-dell-stock-price-target-before-key-meeting",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "US To Give Ukraine Intel for Strikes Deep Inside Russia: Report",
      "content": "The Trump administration will help Kyiv with long-range strikes, The Wall Street Journal reported.\n\nThis story appeared on newsweek.com , 2025-10-02 08:47:48.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b2b69467cecf51ae",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Ninkear A15 Air: Notebook with Ryzen APU, numpad and fingerprint sensor is now available with a different APU",
      "content": "All things considered, the Ninkear A15 Air is a fairly affordable notebook that appears to be quite portable as well. For the laptop, the company has chosen an AMD Ryzen APU over an Intel processor.\n\n4 Reviews ← exclude selected types\n\nWhilst Ninkear may not be a household name amongst laptop manufacturers, we have already had the opportunity to cover and review some of the company’s products, including the A16 Pro. The recently launched 3500U-powered Ninkear A15 Air is now available for €349 ($398) including shipping, with stocks dispatched from Europe. However, the product currently doesn’t ship to the US, and customers may encounter issues with warranty support.\n\nPerhaps unsurprisingly at its price point, the A15 Air lacks a dedicated GPU and probably can’t deliver blazingly fast performance. It is powered by an AMD Ryzen 5 3500U, a highly dated processor that we’ve seen in older laptops. That said, the system should offer enough performance for watching YouTube videos or browsing the web. The device is also equipped with 16 GB of DDR4 memory and a 512 GB SSD, providing a decent amount of RAM and storage.\n\nWeighing 1.75 kg (3.86 lb) and measuring 1.9 cm (0.75 in) thick, the Ninkear A15 Air features a 15.6-inch display with a 1080p resolution, 60 Hz refresh rate, and 45% NTSC (~65% sRGB) gamut coverage. It also offers two USB-C ports (both capable of video output), an HDMI interface, an Ethernet port, and a memory card reader. Other notable features include Wi-Fi 5 support, a fingerprint sensor, and a built-in webcam.\n\nThe A15 Air was previously available with a more powerful APU, the Ryzen 5 4600H, but that SKU appears to be all sold out now.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Ninkear-A15-Air-Notebook-with-Ryzen-APU-numpad-and-fingerprint-sensor-is-now-available-with-a-different-APU.1129840.0.html",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "Trump will help Ukraine hit Putin where it hurts — to finally end his bloody war",
      "content": "President Donald Trump — after repeatedly warning the Kremlin that his patience was wearing thin over its continuing invasion of Ukraine — has begun to match words with action.\n\nAs Moscow continues to flout his efforts to broker peace, Trump has agreed to give Kyiv US intelligence to support strikes on energy infrastructure deep inside Russia, helping Ukraine take the war to President Vladimir Putin’s doorstep.\n\nTrump should now follow through by supplying Ukraine with long-range missiles to do the job — and ratcheting up the economic pressure on Russia.\n\nDespite Putin’s professed readiness for peace, his assault on Ukraine has only intensified.\n\nTrump struck a compromising stance at the two leaders’ Alaska summit, yet the Russian autocrat has since refused even to meet with his Ukrainian counterpart, President Volodymyr Zelensky.\n\nIndifferent to the death and destruction he inflicts on both Ukrainians and his own citizens with each passing day, Putin has continued to insist on maximalist demands that effectively render a settlement impossible.\n\nIt’s long past time for Moscow to face consequences for its intransigence.\n\nTrump’s decision breaks with his administration’s previous policy of blocking Ukrainian strikes inside Russia using American-supplied missiles or targeting data.\n\nIn addition to the new intelligence sharing, Trump reportedly is weighing whether to provide Ukraine with various long-range missiles.\n\nThese include the Tomahawk, which Zelensky requested during a recent meeting with the American leader.\n\nThese munitions have much longer ranges than the ATACMS ballistic missiles and Storm Shadow/SCALP cruise missiles Ukraine previously received from the United States, Britain and France, of which Kyiv has few left.\n\nAnd they pack a more powerful punch than Ukrainian-made drones, which typically carry relatively small warheads.\n\nThese new missiles would likewise add capacity and capability to Ukraine’s nascent arsenal of indigenously produced long-range missiles.\n\nUS-supplied intelligence and missiles can enhance Ukraine’s ongoing drone strike campaign against the Russian energy industry.\n\nIn recent months, Ukraine has struck over 40% of Russia’s oil refineries, causing fuel shortages and price hikes and forcing Moscow to restrict gasoline and diesel exports.\n\nTrump should provide Ukraine with as many missiles as possible, both long-range munitions as well as additional ATACMS.\n\nIn addition, Ukraine should be permitted to use American missiles, targeting data and mission planning support for strikes on not only energy infrastructure but on other targets as well, including key military-industrial sites.\n\nGet opinions and commentary from our columnists Subscribe to our daily Post Opinion newsletter! Thanks for signing up! Enter your email address Please provide a valid email. By clicking above you agree to the Terms of Use and Privacy Policy. Never miss a story. Check out more newsletters\n\nFor example, Kyiv could employ the Tomahawk or another missile with similar range to strike the Russian plants making the Geran and Gerbera drones that bombard Ukrainian cities and critical infrastructure night after night.\n\nIn concert, Trump should work with European and G7 allies to tighten the screws on Russia’s economy.\n\nThis effort should include an aggressive application of so-called secondary sanctions aimed at denying Moscow revenue from oil exports.\n\nWhile Trump has threatened tariffs on Russian oil customers such as China, sanctions are the better option.\n\nHarsh US tariffs have failed to convince India to ditch Russian oil — and tariffs are incompatible with Washington’s goals of securing trade deals with New Delhi and Beijing.\n\nWhen it comes to economic pressure, Trump should not let the perfect be the enemy of the good.\n\nHe is right to push Europe to end its remaining imports of Russian energy, which have already declined dramatically since 2022.\n\nBut even though some European countries — mainly Hungary and Slovakia — continue to buy some Russian oil and gas, that is no excuse for US inaction.\n\nIf Trump refuses to sanction Russia until Europe ceases buying any Russian hydrocarbons, it’ll effectively be giving Moscow a pass to continue the killing in Ukraine.\n\nTo be sure, Putin will never abandon his decades-long obsession with making Ukraine a Russian vassal.\n\nBut over time, he perhaps could be convinced to stop shooting, at least for now, on terms Kyiv can live with.\n\nThat will require putting further military and economic pressure on Russia — and proving to Putin that neither Ukrainian forces nor Western resolve will break.\n\nJohn Hardie is deputy director of the Russia program at the Foundation for Defense of Democracies.",
      "source": "New York Post",
      "url": "https://nypost.com/2025/10/02/opinion/trump-helps-ukraine-hit-putin-where-it-hurts-to-end-his-bloody-war/",
      "timestamp": "2025-10-02"
    },
    {
      "headline": "$200 Billion Chip Frenzy: AI Mania Sends Stocks Into Overdrive",
      "content": "This article first appeared on GuruFocus.\n\nGlobal chipmakers have ignited a fresh wave of investor euphoria, with more than $200 billion added to their combined market value in just one session. The latest surge came as OpenAI secured a record $500 billion valuation through an employee share sale, alongside agreements with South Korean semiconductor producers. Reports that Intel (NASDAQ:INTC) may look to Advanced Micro Devices (NASDAQ:AMD) as a customer added further fuel, underscoring how deeply artificial intelligence has embedded itself into the sector's growth narrative. Investors continue to chase exposure to chip leaders such as Nvidia, SK Hynix, and Samsung, sending both the Philadelphia Semiconductor Index and Asia's chip benchmark toward historic highs.\n\nThe rally has been particularly striking in Asia and Europe. SK Hynix (HXSCL) shares soared 10% while Samsung Electronics advanced 3.5%, pushing South Korea's Kospi Index to record levels. In Europe, ASML gained nearly 5% on Thursday, extending a rebound that now totals almost 50% since August. Analysts suggest the current pace is being driven less by fundamentals and more by fear of missing out, with valuations reflecting the frenzyBloomberg's Asia chip gauge now trades at 19 times forward earnings while the SOX Index stands at 27 times, approaching peaks seen in 2024. Market strategists note that upcoming fourth-quarter results could act as a turning point, forcing investors to reassess whether the momentum can hold.\n\nChina has added its own layer of strength to the rally, with government support, Alibaba's (NYSE:BABA) stepped-up AI spending, and Huawei's three-year plan to erode Nvidia's (NASDAQ:NVDA) dominance all boosting sentiment. The Hang Seng Tech Index has surged nearly 50% year-to-date on the back of these developments. OpenAI's Sam Altman is expected in Taipei for meetings with Taiwan Semiconductor Manufacturing Co. (NYSE:TSM) and Hon Hai, lifting their shares further. While concerns linger that revenues have yet to catch up with the extraordinary capital deployed into AI infrastructure, many investors remain convinced that the sector's upside could extend into next year, with momentum still firmly in place.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/200-billion-chip-frenzy-ai-051826508.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Enterprise IT Reinvented: Powering Intelligence with AI and Hybrid Cloud",
      "content": "The appeal of hybrid cloud was just one topic of discussion at Tech Monitor’s latest roundtable, held in association with Lenovo and Intel. (Image: Shutterstock)\n\nTwo interlocking technologies formed the basis of the latest Tech Monitor executive roundtable event, put together in partnership with Lenovo and Intel. In late September, senior technologists convened in central London to discuss the merits of artificial intelligence (AI) and hybrid cloud, both independently and working together.\n\nAI – particularly generative AI (GenAI) – has the potential to transform how businesses operate, unlocking new levels of productivity, automation, and insight. At the same time, hybrid cloud is emerging as the foundational infrastructure needed to support these compute-intensive workloads. It promises the scalability of public cloud alongside the control and performance of on-premise environments. But while the potential is clear, the path forward isn’t always straightforward. From cultural resistance and skills gaps to cost pressures, regulatory demands, and legacy constraints — the challenges are real.\n\nCloud adoption? It’s a long story\n\nTo understand the emergence of hybrid cloud, first you must recall the two-decade tale of cloud adoption. Go back twenty years or so, and the promise of a scalable, pay-as-you-go infrastructure solution that was quick to set up and avoided expensive capital costs proved so attractive that many organisations committed to an “everything to the cloud” approach.\n\nOnly later did businesses appreciate some of the challenges such an approach presented, including excessive latency, escalating costs, and concerns about data residency. On the last of these challenges, recent regulatory changes in the United States – notably the US Cloud Act, which allows for the possibility of US authorities accessing personal data stored in overseas data centres without prior approval – have focused minds. UK-based firms are concluding that sovereignty means not just assuring that cloud data centres are regionally located but also that those who process and manage the data work within the laws of the jurisdiction, too.\n\nThe merits of hybrid cloud\n\nThe choice between on-premises and cloud, said one voice around the table, comes down to three factors: “cost, risk, and time”. Weighing up all three, there is an identifiable trend of repatriation where workloads initially spun into the cloud are now returning to on-premise. But, as one voice cautioned, repatriation shouldn’t be confused with the demise of public cloud. One only needs to look at the ever-growing profits of the hyperscalers – AWS, Microsoft Azure, and Google Cloud, among them – to note the ongoing health of public cloud. Hybrid cloud – mixing private provision with public cloud across a single interface – has emerged as the pragmatic solution.\n\nOn cloud costs, one speaker around the table shared a cautionary tale. He recalled the story of a senior technologist who had fully committed his firm to the cloud, overseeing 100% of workloads switching to virtual infrastructure. Rather than expressing pride in his achievement, the IT leader was instead exploring ways to reverse his decision. At least partially. Why? Because once made aware of a “cloud-only” approach, which would see IT costs rise every year, his CFO pointed out that this would necessitate that the business grow every year, too, without fail. He could give no guarantee and had no desire to commit to these spending increases. So while the cloud-only move made perfect sense from a technical point of view, from a financial point of view, it looked a little different.\n\nBalancing AI workloads\n\nAI provides the perfect prism to look at the merits of hybrid cloud. For the most part, the public cloud provides an excellent environment for experimentation. Working with relatively small data sets, businesses can spin up proofs of concept at speed before deciding whether to pursue an AI initiative. The move from experimentation to deployment often sees organisations switching from cloud to on-premise for greater control of costs and of the data under their supervision.\n\nThose who take this path reflect the thinking behind “The Trillion Dollar Paradox”, a term coined by the venture capital group Andreesen Horowitz in 2021 to describe the contraction in cloud computing. In words that capture the essence of the paradox, authors Sarah Wang and Martin Casado wrote: “You’re crazy if you don’t start in the cloud; you’re crazy if you stay on it.”\n\nHere come hybrid AI\n\nDuring his opening remarks, Lenovo’s Tikiri Wanduragala drew a direct parallel between hybrid cloud and AI, coining the notion of hybrid AI. According to Wanduragala – Technology Leader UKI for the Infrastructure Solutions Group (ISG) at Lenovo – three flavours of artificial intelligence will emerge. First, he said, there are going to be some elements of AI that are automatically available, that are embedded in your device. Think of a translation app, for example. Second, there will be the applications provided by third-party providers that will include AI-driven functionality. Some of these apps will be new, many will be based on pre-existing solutions, and others will be developed in partnership with the customer.\n\nFinally, there is the “do it yourself” model, where organisations will build their own, bespoke AI applications that fill an unmet need and/or provide a competitive advantage. Organisations will choose the AI models that best suit them, most likely in combination. “If you want to know what’s going to happen in AI,” said Wanduragala, “think of the cloud story. It’s going to feel very, very similar.”\n\nWatch the video above to learn more from Lenovo’s Tikiri Wanduragala, and to hear how AI adoption is changing enterprise IT.\n\n‘How AI and Hybrid Cloud are Reshaping Enterprise IT’ – a Tech Monitor executive roundtable in association with Lenovo – took place on Tuesday, 23 September at the South Place Hotel, London",
      "source": "Techmonitor.ai",
      "url": "https://www.techmonitor.ai/sponsored/enterprise-it-reinvented-lenovo-intel-hybrid-cloud/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "NFL Trade Deadline Buzz: Biggest Sellers, Potential QB Additions, Latest Rumors",
      "content": "National Football League NFL Trade Deadline Buzz: Biggest Sellers, Potential QB Additions, Latest Rumors Published Oct. 3, 2025 2:49 p.m. ET share facebook x reddit link\n\nThe NFL trade deadline is Nov. 4, which comes after Week 9. After this coming Sunday, we'll be more than halfway there.\n\nIn MLB and the NBA, new players get about two months of the season with their new team. In the NFL, any deadline acquisitions will get half of the regular season to acclimate and make a big impact.\n\nSome teams need quarterbacks, while others appear to be on a downward trajectory and destined to be sellers. Our NFL reporters asked around the league and got valuable intel on what to expect.\n\nJaguars, 49ers Expected to Be Active; Is Mark Andrews Available?\n\nEric D. Williams: League sources I spoke with pointed to the Jacksonville Jaguars, San Francisco 49ers, Los Angeles Rams, Buffalo Bills, Seattle Seahawks, New England Patriots and Philadelphia Eagles as possible teams who will be active at November’s trade deadline.\n\nTeams like the Eagles, Rams, 49ers and Seahawks have shown a willingness to be aggressive in previous years at the deadline. Those teams are also in the top half of the league in terms of salary cap space.\n\nADVERTISEMENT\n\nAnother team to look for to be aggressive is Jacksonville. General manager James Gladstone and head coach Liam Coen both came from the Rams, a team known to take calculated risks with general manager Les Snead and head coach Sean McVay.\n\nJames Gladstone, Liam Coen and Tony Boselli have already shown they will be aggressive by trading up for Travis Hunter in this year's draft. (Logan Bowles/Getty Images)\n\nIn terms of potential players who could be on the move at the trade deadline, another league source pointed to Baltimore Ravens tight end Mark Andrews and New York Jets offensive lineman Alijah Vera-Tucker as two players who could command some interest around the league.\n\nAt 30 years old, Andrews is in the final year of a four-year, $56 million deal that will pay him $11 million in total compensation this season. With the Ravens scuffling at 1-3 and Baltimore already having a talented younger tight end on the roster in Isaiah Likely, Andrews could be an appealing trade candidate for a contender in need of a quality tight end.\n\nWith the Jets struggling at 0-4 and in full rebuilding mode, the 26-year-old Vera-Tucker is scheduled to make $15.3 million in total compensation in the final year of his rookie contract. However, Vera-Tucker’s future with the team is cloudy after he suffered a season-ending torn triceps injury in September and has had trouble staying on the field during his time in New York.\n\nWith New York more focused on the future, the Jets could seek to get draft compensation in the form of 2026 picks now instead of waiting to move on from him at the end of the season and potentially receiving a 2027 compensatory pick once he moves on in free agency.\n\nWhat Does the QB Market Look Like?\n\nRalph Vacchiano: A flurry of early-season injuries may have forced several teams to play their backup quarterbacks, but that doesn’t mean any of them will be scouring the trade market for veteran quarterback help.\n\nIn fact, multiple NFL sources said they’d be surprised if there were any quarterback trades at all, even though several, somewhat attractive veteran starters are currently sitting on their team’s bench. That means players like Russell Wilson, Kirk Cousins, Jameis Winston and Joe Flacco are likely stuck right where they are, possibly for the rest of the year.\n\n\"It’s hard to trade for a quarterback midseason,\" an assistant general manager told FOX Sports. \"Even the best ones need time to learn an offense, develop chemistry with their receivers. … The only team I could see even thinking about it is Cincinnati. (Jake) Browning looks terrible and they’re just trying to stay afloat until Joe (Burrow) returns.\"\n\nJameis Winston has been the No. 3 quarterback for the Giants all season. (Cooper Neill/Getty Images)\n\nThe Bengals, at 2-2, are the one team several sources said could be a wild card in any quarterback market, with Burrow not expected to return from a toe injury until December and Browning struggling so far. But all of the other teams who lost their starting quarterbacks, like the Vikings, Jets, 49ers, Ravens and Commanders, are expecting their starters back relatively soon.\n\nSo far, though, there’s no indication that the Bengals have even tried to see if any veteran quarterbacks are available. The Atlanta Falcons have reportedly received no interest from anyone in Cousins, and according to an NFL source, the Giants have no interest in shopping either Wilson or Winston around, even though both are now behind rookie quarterback Jaxson Dart.\n\n\"I know the Giants don’t want to trade their quarterbacks, but how can they not listen to offers?\" asked another NFL executive. \"If they’re committed to Dart they don’t need both Russ Wilson and Jameis (Winston). They can talk about their great quarterback room all they want, and I know they need protection in case the kid stumbles, but if they can get a draft pick for one of them, they have to do it.\"\n\nWho Will Be Selling at the Deadline?\n\nRalph Vacchiano: Which NFL teams will be the biggest sellers at the trading deadline? That’s easy: Just look at who sits at the bottom of the standings.\n\nMultiple NFL sources predicted the 0-4 New Orleans Saints, the 0-4 New York Jets and the 1-3 Cleveland Browns will be the teams most willing to ship out players between now and the deadline on Nov. 4. And each team has some interesting pieces that could attract interest to some of the contenders around the league.\n\n\"They need a complete reboot in Cleveland, though who knows if the current group (general manager Andrew Berry and head coach Kevin Stefanski) will be the ones who get to do it? \" an NFL executive told me. \"And the Jets are loaded with too many of (ex-general manager) Joe Douglas’ players. (New general manager Darren Mougey and coach Aaron Glenn) are going to want to purge that organization and rebuild it with their guys. They look like a mess right now, so I think they’d be open to trading almost anybody.\"\n\nAs for the Saints, they are facing \"a multi-year rebuilding project,\" the executive said, and they could get a strong return if they’re willing to trade running back Alvin Kamara or receiver Chris Olave.\n\n\"(Saints coach Kellen Moore) is an offensive guy, so I’m sure he doesn’t want to get rid of them,\" the executive said. \"But for the good of the franchise, they’ve got to consider it. I doubt either of them will still be there when the Saints are good again. They should just completely start over.\"\n\nAlvin Kamara will be a potentially valuable addition at running back ahead of the deadline. (Jane Gershovich/Getty Images)\n\nAdded an assistant general manager: \"Alvin Kamara is getting a little old (30), but he can still play if he can stay healthy and he’s just wasting away on that team.\"\n\nThey won’t be the only teams selling, of course. Among the other names several NFL sources said could be players to watch at the trading deadline are cornerback Greg Newsom and tight end David Njoku of the Browns, linebacker Jaelen Phillips of the Dolphins, and receiver Jakobi Meyers of the Raiders.\n\nMultiple sources also said the Jets might have been willing to part with running back Breece Hall, whom they reportedly tried to trade during the offseason. But that might not be possible after the Jets placed their other running back, Braelon Allen, on injured reserve with a sprained knee on Tuesday.\n\nAnother Potential Dolphins Departure\n\nGreg Auman: Miami finally has a win on the board, but losing Tyreek Hill for the season makes it that much harder for it to compete at all. It's more likely the Dolphins will sell off short-term assets before the trade deadline.\n\nOne name to watch is edge rusher Jaelan Phillips, who's playing on his fifth-year option right now and will be an unrestricted free agent in March. He has no sacks in four games this year and was limited by injury last year but could be enticing for a team looking for pass-rush depth. Phillips had 22 sacks in his first three years in the league. Taking on half of his base salary is over $6 million, but that’s less than he’ll command on the open market.\n\nNFL.com listed Phillips as the No. 2 overall free agent in the 2026 class, so the team signing him could be in line for a decent compensatory pick if they don’t keep him around past this season. Miami knows this, as well, so it raises the cost of acquiring him – the Dolphins would like to get a 2026 draft pick instead of waiting for his comp pick in 2027.\n\nWant great stories delivered right to your inbox? Create or log in to your FOX Sports account , and follow leagues, teams and players to receive a personalized newsletter daily!\n\nWhat did you think of this story?\n\nshare",
      "source": "Fox Sports",
      "url": "https://www.foxsports.com/stories/nfl/nfl-trade-deadline-buzz-biggest-sellers-potential-qb-additions-latest-rumors",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "AMD not going to fab chips at Intel Foundry, SemiAccurate reports",
      "content": "We use cookies to improve user experience, and analyze website traffic.\n\nFor these reasons, we may share your site usage data with our analytics partners. By clicking \"Accept Cookies\" you consent to store on your device all the technologies described in our Cookie Policy.",
      "source": "Thefly.com",
      "url": "https://thefly.com/permalinks/entry.php/id4207611/AMD;INTC-AMD-not-going-to-fab-chips-at-Intel-Foundry-SemiAccurate-reports",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Trump’s $100,000 H-1B Fee Draws Rare Rebuke From Business Groups",
      "content": null,
      "source": "Financial Post",
      "url": "https://financialpost.com/pmn/business-pmn/trumps-100000-h-1b-fee-draws-rare-rebuke-from-business-groups",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Police race to save murder evidence from being turned into scrap metal",
      "content": "Detective Devin Rigo knew the clock was ticking as he raced to a metal scrapyard just north of Portland, Oregon. Rigo, with the Hillsboro Police Department, had just learned about the discovery of a maroon minivan he believed contained evidence connected to the murder of 56-year-old Kenneth \"Kenny\" Fandrich, a contract pipe fitter.\n\nOn Jan. 27, 2023, Kenny Fandrich was discovered in a parking garage at the Intel campus in Hillsboro. Police reviewed surveillance camera images and determined that Fandrich had been dragged into the minivan by a masked man. Police believed the killer had broken Fandrich's neck and killed him inside the minivan, before staging his body back in the driver's seat of his own vehicle.\n\nFrom evidence found at the scene, investigators believed the murder suspect tried to cover his crime by spray-painting multiple security cameras in the parking garage with blue spray paint. Correspondent Natalie Morales covers the investigation into Kenny Fandrich's murder and the hunt for the killer in \"Murder in the Parking Garage,\" now streaming on Paramount+.\n\nA suspect wearing a hard hat, tinted glasses and a face mask is captured spray-painting the security cameras around Kenny Fandrich's car the morning of his murder to apparently conceal the crime Washington County District Attorney's Office\n\nSoon after police arrived on the scene, Intel security personnel provided investigators with recordings from their hundreds of security cameras in the parking garage. Police soon had images of a suspect – wearing a hard hat, tinted glasses and a face mask – spray-painting the security cameras around Fandrich's car early that morning, to apparently conceal the crime. At the time, the suspect had not been detected by Intel. But when police looked at the footage, they discovered that the spray paint didn't cover everything the cameras recorded.\n\nKenny Fandrich, left, and Dr. Steven Milner. Washington County District Attorney's Office\n\nPolice believed that whoever had killed Fandrich waited for him inside that minivan, then attacked Fandrich when he returned to his car after his shift. The killer left the garage in the maroon minivan soon after.\n\nThe night that Fandrich's body was found, his wife, Tanya Fandrich, told investigators Kenny had a stalker: a well-off former veterinarian named Dr. Steven Milner. Tanya Fandrich had worked for Milner at his vet clinic for years, and they had an affair, which Tanya Fandrich said was long over. Police found that Kenny Fandrich had filed several orders for protection against Milner, and that Milner had been warned by Hillsboro police officers to stop following Kenny Fandrich. Just months before Kenny Fandrich's murder, Milner had been caught placing a tracking device on one of the Fandrichs' vehicles and was criminally charged. After several days of investigation, police arrested Milner and charged him with the murder of Kenny Fandrich.\n\nOnce in custody, police were able to connect the minivan, and another vehicle, to Milner, who had left them at a Home Depot parking lot for long periods of time.\n\nTo prove the case against Milner, investigators felt they had to find that minivan. \"Because it's the minivan that we believe was really our main crime scene …\" said Rigo. \"We thought there was going to be forensic evidence … in that minivan.\"\n\nRigo and his partner, Detective Stephanie Winter, called the vehicles \"burner cars.\"\n\n\"Everybody kind of is more familiar with like a burner phone …\" said Rigo, \"where you have a phone that's not … traced to you but, you know, you can use it for what you need, get rid of it … Essentially, he did the same thing, but with a car.\"\n\nThe maroon minivan had been flagged at the Home Depot parking lot and the VIN number had been recorded. Security footage showed the van leaving the Home Depot parking lot shortly before Fandrich was murdered.\n\n\"We are sending flyers to every agency in the area,\" said Rigo about the minivan's VIN number.\n\nThe maroon minivan, pictured left, moments before it was crushed. Hillsboro, Oregon, police believed the vehicle contained evidence connected to the murder of 56-year-old Kenneth \"Kenny\" Fandrich. Washington County District Attorney's Office\n\nThe first alert they got was from the Oregon Department of Transportation. The minivan had been towed off the side of the busy I-5 highway in North Portland just days after Fandrich was murdered. Detectives believe it had been dumped there by Milner. Rigo called the tow company and found out the minivan had been sold to a scrap metal company. That's when he started racing to the scrapyard to see if they could retrieve the minivan, and the key crime scene evidence it may have held. But he was too late. When Rigo arrived and asked about the minivan, he was shown a video of the crime scene being picked up and smashed to pieces. \"I was able to watch one of my key pieces of evidence be crushed and taken away,\" said Rigo, \"before my very eyes … exactly a week too late.\"\n\nDiscover how the investigation unfolded, and Milner's defense at trial, on this week's \"48 Hours,\" \"Murder in the Parking Garage.\"",
      "source": "CBS News",
      "url": "https://www.cbsnews.com/news/kenneth-fandrich-steven-milner-oregon-murder-junkyard-evidence-48-hours/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Intel Stock Has Doubled Since April 8. Here Is Where the Stock Could Be at the End of 2025",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/2b5364123fd6a0ae",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "CNBC Daily Open: No signs of U.S. stocks' bull run slowing for now",
      "content": "A bronze sculpture of a bull is displayed on Broadway in the financial district November 14, 2000 in New York City.\n\nInvestors continue to pile into stocks, undeterred by a government shutdown or shaky jobs data, with all three benchmarks hitting record highs Thursday.\n\nWith the Senate not meeting yesterday because of Yom Kippur, the U.S. government stayed shut for a second day. Treasury Secretary Scott Bessent told CNBC on Thursday that economic growth could take \"a hit\" because of the shutdown. Investors seem to have dismissed those concerns.\n\nThe jobs market already seems quite battered, at least in terms of new hirings.\n\nYear-to-date hiring is down 58% from the same period a year ago, to hit its lowest level since 2009, based on data from outplacement firm Challenger, Gray & Christmas.\n\nBut the jobless level has stayed at 4.34%, according to a relatively new set of data indicators compiled by the Chicago Federal Reserve. This echoes Fed Chair Jerome Powell's description of the economy as one that is \"low fire, low hire.\"\n\nGranted, those numbers are not from the Labor Department. We're patching together a picture from different sources. That's like trying to recreate New York food truck Halal Guys' famous white sauce but ending up with an ordinary mayonnaise — but it is still a spread that adds some value in the absence of the real thing.\n\nMarkets are taking all that in their stride as they scale new peaks. Joining the party was the world's most valuable company, Nvidia , which hit an all-time. Intel — though it is still far from its high in 2021, also rose to deliver 50% gains to investors over the last month amid a series of successful tie-ups.\n\nTom Lee, head of research at Fundstrat, predicts that the S&P 500 could reach 7,000 by year-end. With markets looking unperturbed, that might turn out true sooner if nothing serious comes in the way of the bulls.",
      "source": "CNBC",
      "url": "https://www.cnbc.com/2025/10/03/cnbc-daily-open-no-signs-of-us-stocks-bull-run-slowing-for-now.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Two Delta Jets Collide While Taxiing at New York’s LaGuardia Airport",
      "content": "Two Delta Air Lines Inc. regional jets collided at low speed while taxiing at New York’s LaGuardia Airport on Wednesday night, causing minor injuries to one flight attendant and prompting regulators to open an investigation.\n\nBoth planes were CRJ-900 aircraft operated by Endeavor Air. Endeavor Air Flight 5047 was heading to its gate at the airport when it struck Endeavor Air Flight 5155 around 10 p.m. local time, the US Federal Aviation Administration, which is probing the incident, said in a statement Thursday. According to the regulator, air traffic control had instructed flight 5155 to hold short and yield to the other aircraft.\n\nThe National Transportation Safety Board said in a social media post Thursday that it’s also investigating the collision and that it had dispatched a team of 10 people to LaGuardia. The agency said the flight recorders from both planes have been recovered and are being analyzed at NTSB headquarters in Washington.\n\nVideo footage posted on X that appeared to be taken from inside a neighboring plane showed flashing emergency vehicle lights on the tarmac and damage to a jet’s wing.\n\nAccording to Delta, preliminary information indicates the wing of flight 5155, while taxiing for departure to Roanoke, Va., made contact with the body of the other aircraft, which was arriving from Charlotte, N.C. The airline said one flight attendant was treated for minor injuries but there were no reported passenger injuries.\n\n“Delta will work with all relevant authorities to review what occurred as safety of our customers and people comes before all else,” the carrier said in a statement.\n\nABC News spoke to someone who was on the plane that had just landed from Charlotte and said the aircraft was turning right off the main runway when the pilot slammed on the brakes. Passengers could feel the plane getting dragged as it made contact with the other aircraft, he said in a TV interview.\n\nBREAKING: Two Delta Airlines aircraft collide while taxiing at LaGuardia International in New York pic.twitter.com/Bzd33IAvlN\n\n— Intel Point Alert (@IntelPointAlert) October 2, 2025\n\nIt’s the latest in several incidents at LaGuardia in recent months that have raised safety concerns. In March, a Delta jet’s wing struck the runway while the pilot was executing a maneuver known as a go-around, prompting an FAA investigation.\n\nRead More: Trump Plans to Use Shutdown to Fire Federal Workers This Week\n\nFederal investigators are also probing a May runway close call in which a Republic Airways jet aborted takeoff to avoid a collision with another aircraft on the same runway.\n\nThe latest mishap involving the two Endeavor Air aircraft comes just days after a letter signed by more than 50 industry and labor groups including the International Air Transport Association warned that a US government shutdown — now in its second day — would threaten aviation safety.\n\nPhoto: Delta airlines passengers planes at LaGuardia airport in New York City. Photographer: Daniel Slim/AFP/Getty Images\n\nCopyright 2025 Bloomberg.\n\nTopics New York Aviation Numbers",
      "source": "Insurance Journal",
      "url": "https://www.insurancejournal.com/news/east/2025/10/03/842373.htm",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Growth Minded – Inside Amazon RelayCon 2025 and the Small Carrier Surge",
      "content": "The room felt different. You could see it in the faces. These weren’t desperate carriers chasing survival — they were business owners plotting their next move. Amazon RelayCon 2025 wasn’t just another conference. It was a signal to the industry that small fleets aren’t giving up. In fact, many are gearing up.\n\nI had the chance to attend RelayCon this year — both as a vendor and as a keen observer of what’s moving the needle for small carriers right now. And what I saw wasn’t a group stuck in market pessimism. It was the opposite.\n\nFrom the moment the doors opened at the welcome reception — with people literally herding in together — the energy was undeniable. Carriers lined up to meet vendors, swap notes, and dig into what Amazon’s Relay program is really offering. And behind all the booths and breakout sessions was a simple message: if you’re operating smart, there’s room to grow.\n\nThe Rise of the Growth-Minded Small Fleet\n\nLet’s get one thing straight: this wasn’t a room full of solo operators looking for a miracle. These were mostly 1–50 truck fleets, already moving decent volume — and looking for ways to do more. And the optimism wasn’t baseless.\n\nAmazon revealed that freight volumes for Relay carriers are up 15%, even as the rest of the market struggles with rate compression and declining spot activity. That’s not a small number. That’s insulation. And insulation in this environment is currency.\n\nWhat stood out most was the mindset shift. RelayCon wasn’t about complaints or freight recession talk. It was about tactical growth. The majority of attendees weren’t there to ask if they should scale — they came to find out how.\n\nEducation, Efficiency, and Deals That Make a Difference\n\nAmazon didn’t hold back on the support. The event was structured to make sure every carrier left smarter than they came.\n\nThere were multiple breakout sessions, including one on supplier diversity that pushed carriers to explore certifications like MBE (Minority Business Enterprise) and Veteran-Owned business designations. For small fleets looking to go after contracts or deeper relationships, this was critical intel.\n\nThen came the operations support. Amazon had a dedicated station for safety coaching, where carriers could get real-time insights into their safety scores, understand what’s hurting them, and develop a roadmap to improve. That kind of transparency is rare — and invaluable.\n\nOn top of that, Amazon showed how to leverage their “Deals and Discounts” portal — a perk most carriers underuse. From fuel and tires to insurance and services, vendors inside the Relay network offer deep discounts. For carriers managing narrow margins, that adds up fast.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/growth-minded-inside-amazon-relaycon-193723948.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "BC-Most Active Stocks",
      "content": "There are no important events for this country at this time. Select \"All\" to see top events in other countries or view all events.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/bc-most-active-stocks-143018325.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Google Drive for Desktop Adds AI to Spot Ransomware Attacks",
      "content": "Key Takeaways AI ransomware defense in Drive for Desktop — Detects mass encryption/corruption, automatically pauses sync to prevent spread, and alerts users.\n\n— Detects mass encryption/corruption, automatically pauses sync to prevent spread, and alerts users. One-click recovery — Quickly restore Docs, Sheets, Slides, PDFs, and more to a healthy state after removing the infection.\n\n— Quickly restore Docs, Sheets, Slides, PDFs, and more to a healthy state after removing the infection. Wide, default rollout — Open beta; free for most Workspace plans; enabled by default (admins can disable); requires Drive for Desktop v114+.\n\n— Open beta; free for most Workspace plans; enabled by default (admins can disable); requires Drive for Desktop v114+. Privacy + intel — Google says customer data isn’t used to train AI without permission; detection leverages VirusTotal and aims to cut downtime amid rising attacks.\n\nGoogle Drive for Desktop users can now restore their important data if they fall victim to a ransomware attack.\n\nAccording to the recent Google Workspace update, your Drive for Desktop will now feature AI-powered ransomware detection, which will halt syncing if it detects a ransomware attack.\n\nAs a result, ransomware won’t affect your documents saved in Google Drive or in Drive for Desktop on another device. Once you’ve removed the infection, you can easily restore files on the compromised computer from your unaffected Google Drive.\n\nThis helpful feature comes at a crucial time, as ransomware incidents are increasing rapidly.\n\nThe Rise of Ransomware\n\nRansomware groups are on the rise. The Searchlight Cyber report revealed that there were 73 ransomware groups in the first half of 2024, representing a 56% increase from the 46 groups identified in the first half of 2023.\n\nAs more ransomware groups appear, it’s no surprise that attacks are happening more often. The data clearly shows this upward trend.\n\nAccording to the Ransomware Impact report, which surveyed 386 IT professionals, 24% of organizations experienced a ransomware attack in 2025. This marks a significant rise from 2024, when only 18.6% of incidents were reported.\n\nContributing to this trend, BlackFog, a leading security firm, also reported a record-breaking number of ransomware attacks in the first quarter of 2025. The company actually saw a 45% increase in ransomware attacks compared to Q1 2024.\n\nWith the rapid increase in ransomware attacks, the expenses for mitigation and damage control have also grown. Global ransomware damage costs have risen to $57 billion annually this year, up from $20 billion in 2021, according to an estimate from Cybersecurity Ventures.\n\nAs ransomware attacks grow and become more damaging, Google’s latest Drive for Desktop update is designed to offer users quicker recovery and enhanced protection. Let’s see how.\n\nHow Drive for Desktop Ransomware Detection Works\n\nThe new ransomware detection feature in Drive for Desktop uses AI trained on millions of real-world ransomware samples to identify key ransomware signatures. This includes detecting a large volume of encrypted or corrupted files.\n\nNow, you may wonder how this feature can catch a novel ransomware attack that uses new techniques to evade detection, especially if the AI model hasn’t been trained on that strain.\n\nTo address this challenge, the ransomware detection engine has integrated threat intelligence from VirusTotal, a prominent online malware scanner.\n\nIf there’s a sign of a ransomware attack, it will automatically stop syncing affected files in your Drive for Desktop. This helps prevent ransomware from spreading within an organization’s drive. This layered approach ensures not just early detection, but also quick recovery options for users.\n\nFurthermore, you’ll receive an alert on your desktop and via email, with details on how to restore files. Google Drive allows you to restore multiple files to their previous healthy state in just a few clicks.\n\nThe ransomware protection feature supports multiple file formats, including Sheets, Docs, PDFs, Slides, and more. It is rolling out in an open beta.\n\nAs part of this rollout, most Google Workspace commercial plans will receive the ransomware detection, alerting, and restoration feature at no additional cost. If you’re a standard Drive for Desktop user, you get file restoration capability at no cost.\n\nWhat’s more, the ransomware detection and file restoration features will be toggled on for Workspace users by default. The admin will have the right to turn them off. You’ll need to install the latest version of Drive for Desktop (v.114 or later) to enable detection alerts.\n\nIn case you’re concerned that Google Drive for Desktop might use your data to train its AI for ransomware detection, Google has assured that it does not.\n\nIts official blog reads:\n\nGoogle does not use customer data, including prompts and generated outputs, for advertising purposes or to train or fine-tune any of its generative AI models without customer permission or instruction.\n\nGoogle isn’t alone in tackling ransomware. Other cloud providers, such as OneDrive and Dropbox, also offer a ransomware protection feature similar to Drive for Desktop.\n\nImpact and Industry Reactions\n\nRansomware attacks are not only increasing but also growing more dangerous each year.\n\nWith Google Workspace having more than 3 billion users, ransomware detection in Drive for Desktop is a significant step forward in enhancing data security.\n\nEssentially, it provides Drive for Desktop users with a built-in safety layer against one of today’s most disruptive cyber threats.\n\nIndustry experts see this as a timely move. Security analysts highlight that while the feature won’t eliminate ransomware infections themselves, it can dramatically reduce downtime and data loss.\n\nBob O’Donnell, President and Chief Analyst, TECHnalysis Research, said in a prepared statement,\n\nBy seamlessly integrating AI-powered ransomware detection and restore capabilities into Drive, Google is helping organizations with an innovative way to avoid an increasingly common and increasingly dangerous threat while also giving end users the ability to continue working…\n\nGoogle’s update makes Drive for Desktop more than just a storage solution. It’s now an active defense against the rising tide of ransomware.\n\nMakeUseOf, Cloudwards, Cheers, Seinfeld, Still Game, or The Big Bang Theory. Sandeep Babu is a cybersecurity writer with over four years of hands-on experience. He has reviewed password managers, VPNs, cloud storage services, antivirus software, and other security tools that people use every day. He follows a strict testing process—installing each tool on his system and using it extensively for at least seven days before writing about it. His reviews are always based on real-world testing, not assumptions. Sandeep's work has appeared on well-known tech platforms like Geekflare PrivacyJournal , and more. He holds an MA in English Literature from Jamia Millia Islamia, New Delhi. He has also earned industry-recognized credentials like the Google Cybersecurity Professional Certificate and ISC2’s Certified in Cybersecurity. When he's not writing, he’s usually testing security tools or rewatching comedy shows like, or View all articles by Sandeep Babu\n\nRelated Articles",
      "source": "Techreport.com",
      "url": "https://techreport.com/news/drive-for-desktop-ransomware-detection/",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Lenovo IdeaPad Slim 3i: 15.6\" FHD IPS, i5-1334U, 8GB LPDDR5, 512GB SSD $375",
      "content": "Product Description:\n\nAvailable in Arctic Grey, the IdeaPad Slim 3i is smart and made for heavy on-the-go users from libraries and cafes to airport terminals, with a lightweight and thin profile that's 10% slimmer than the previous generation yet still military-grade rugged. Get the important stuff done on the go with powerful latest 13th Gen Intel® Core™ i5 processor, the adaptive performance of Smart Power, and full-function Type-C™ port while you learn, work, and stream on a FHD IPS display. Harness smart power and multitasking on the go with the latest Intel® Core™ i5-1334U processor and LPDDR5 8 GB RAM, enhanced by the adaptive performance of Smart Power. Store your entire multimedia and show library with 512GB SSD of storage. Designed for those who are constantly on the go and impacting their lives, the IdeaPad Slim 3i is built for lightness and thinness -up to 10% slimmer than the last generation. Available in Arctic Grey, this sturdy build is military-grade quality, withstanding shocks, dust, and extremes of travel in more hostile conditions. You can’t ask for a better screen to soak up knowledge and soak in entertainment than the 4-sided narrow bezels on the IdeaPad Slim 3i’s FHD IPS display. Keep your eyes safe from strain with a TÜV-certified low blue ight display and listen to immerse Dolby® audio out of user-facing speakers. Enhance and accelerate your study and work experience with full-function Type-C™ ports for faster power delivery, display output, and data transfer, larger touchpad, 2-in-1 fingerprint sensor, 720p camera. Go farther and for longer with a larger battery and Rapid Charge Boost, with gives you two hours of use on a 15-minute charge.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18658264-lenovo-ideapad-slim-3i-15-6-fhd-ips-i5-1334u-8gb-lpddr5-512gb-ssd-375",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "AMD Gains CPU Share as Intel Hits Record Low on Steam September Hardware Survey",
      "content": "A new month has started, meaning that the Steam Hardware and Software Survey has just finished collecting data for September 2025. And there was a subtle, yet clear message about the CPU market: Intel has slipped to its lowest share on record among Steam users, while AMD continues to close the gap. Valve's monthly snapshot shows Intel at about 58.61% and AMD around 41.31%. That shift is the main story this month and suggests a significant change in gamer preferences that warrants a closer examination. The recent movements are not massive, but they are consistent from one month to the next. AMD added roughly 2% points since June, continuing a pattern that started last year, while Intel has been losing ground month after month. A significant part of AMD's momentum stems from its gaming-focused X3D chips and the strong reception they have received in benchmark and real-world tests.Pricing and aggressive promotions for AMD-based systems have also helped. Intel's share is falling even though it remains the largest single vendor, and recent CPU launches have failed to halt the downward trend among Steam users. If both companies continue at their current rates, AMD could become the more common choice among Steam players within a year, marking the first time this has happened in the survey's history. What this means in practice is important for gamers, builders, and the wider PC supply chain. Hardware makers and retailers may shift their inventory and marketing strategies to meet the rising demand for AMD. Game developers are also taking notice. For Intel, the path back will require more compelling launches, clearer messaging, and competitive pricing. The company recently advertised gaming parity with top AMD SKUs and offered better content creation results. For AMD, the challenge will be to turn momentum into sustained leadership without sacrificing margins or running into supply constraints. Either way, the CPU rivalry is no longer a background story. It is directly \"streamed\" on Steam.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341589/amd-gains-cpu-share-as-intel-hits-record-low-on-steam-september-hardware-survey",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Trump’s $100,000 H-1B Fee Draws Rare Rebuke From US Business",
      "content": "A coalition of business groups warned President Donald Trump that a newly announced $100,000 fee for H-1B visa applications risks harming the US economy and urged the administration to avoid changes to the skilled worker program that impose added burdens on companies.\n\nMost Read from Bloomberg\n\nIn a letter sent Friday to Trump, roughly a dozen industry organizations representing chipmakers, software companies and retailers said the new fee threatens to crimp a crucial talent pipeline of foreign skilled workers and leave critical jobs unfilled.\n\n“We ask the administration to work with industry on necessary reforms to the H-1B visa program without increasing the significant challenges US employers face recruiting, training, and retaining top talent,” the groups wrote.\n\nThe letter, sent two weeks after the president’s H-1B proclamation, was careful to laud Trump’s efforts to bring investment to the US. Signers included the Business Software Alliance, the semiconductor industry’s SEMI, the National Retail Federation, the Entertainment Software Association and the Information Technology Industry Council, according to a copy seen by Bloomberg News.\n\nThe industry groups’ objections marked a rare rebuke from the business community of US policy under the new administration. Trump announced the H-1B changes at the White House last month, heralding the $100,000 fee as a way to rein in abuses in the skilled worker program while pushing US companies to turn more to domestic talent to fill jobs.\n\nA White House spokesperson defended the new H-1B policy, saying it would help US companies access top talent while reducing fallout from “fraudulent practices by bad-faith actors.”\n\n“Widespread visa abuse not only undermines American workers, but undermines the companies” that need to recruit first-class talent, White House spokesman Kush Desai said in a statement.\n\nHigher costs from the new H-1B fees threaten to hammer a wide range of industries, from technology to health care to finance. Companies including Microsoft Corp., Amazon.com Inc. and Walmart Inc. have relied for years on the skilled worker program to bolster their ranks, and changes to the program put their talent pipelines at risk.\n\nCutting-edge sectors like artificial intelligence and biomedical engineering will need a high-skilled workforce to sustain their pace of growth in the US, the groups wrote. The H-1B changes risk hurting progress in those key areas, the groups said. Intel Corp., Taiwan Semiconductor Manufacturing Co., Samsung Electronics Co., Applied Materials Inc. and KLA Corp. all have members on SEMI’s board.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/trump-100-000-h-1b-205302951.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Intel CEO Lip-Bu Tan Backs $24M Corintis Board As Startup Solves AI's Biggest Bottleneck Problem",
      "content": "Semiconductor cooling startup Corintis announced on Sept. 25 that it closed a $24 million Series A funding round and a collaboration with Microsoft (NASDAQ:MSFT) that achieved a breakthrough chip cooling system three times more effective than current technology.\n\nLip-Bu Tan became a board director and investor at Corintis prior to his appointment as Intel (NASDAQ:INTC) CEO, Corintis said.\n\nAccording to Corintis, BlueYard Capital led the round, with participation from Founderful, Acequia Capital, Celsius Industries, and XTX Ventures. To date, Corintis has raised $33.4 million.\n\nDon't Miss:\n\nIntel CEO Tan Says Corintis Is Becoming Industry Leader With 10,000 Systems Deployed\n\nThe Switzerland-based company emerged from stealth with a solution to one of AI's most pressing limitations: heat. Corintis says it has already manufactured over 10,000 cooling systems with deployments running in data centers on leading-edge AI chips.\n\nNvidia’s (NASDAQ:NVDA) recent adoption of liquid cooling for its latest generations of data center graphics processing units highlighted this key demand.\n\n“Cooling is one of the biggest challenges for next-generation chips,” Tan said in the statement. “Corintis is fast becoming the industry leader in advanced semiconductor cooling solutions to address the thermal bottleneck, as made evident by its growing customer list.”\n\nMicrosoft Collaboration Proves 3X Cooling Performance Gain Works at Scale\n\nMicrosoft announced on Sept. 23 that it successfully developed an in-chip microfluidic cooling system for servers running core services in collaboration with Corintis. Tests showed microfluidic cooling embedded inside the chip removed heat three times better than the most advanced technology commonly used today.\n\nTrending: Microsoft's Climate Innovation Fund Just Backed This Farmland Manager — Accredited Investors Can Join the Same Fund\n\n“Every chip is unique,\" Corintis co-founder and CEO Remco van Erp described the challenge in the startup's statement. \" It’s like a cityscape with hundreds of billions of transistors, connected by countless wires. Cooling today is not adapted to the chip, relying on simplistic designs where several parallel fins are carved into a block of copper with a blade.”\n\nVan Erp added: \"Thermal engineers need to pull a rabbit out of a hat on a daily basis to make sure chips don’t overheat and break, and that’s where Corintis comes in. Our mission is to unlock 10x better cooling to enable the future of compute, in a short cycle time, and while leveraging the existing infrastructure investments in a data center today.”",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/intel-ceo-lip-bu-tan-010124025.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Minisforum releases M1-1295 mini-PC with Intel Core i9-12950HX and up to 64 GB RAM",
      "content": "Minisforum has released a new mini-PC that is selling globally as the M1-1295. Available with an Intel Core i9-12950HX processor and numerous ports, the Minisforum M1-1295 mirrors AMD Ryzen AI 9 HX 370-based alternatives when it comes to CPU performance.\n\n4 Reviews ← exclude selected types\n\nMinisforum has just released the MS-S1 Max with AMD's Ryzen AI Max+ 395 APU. Silently, it has also introduced the M1-1295, an Intel Alder Lake-based system with relatively stripped-back styling. A simple silver box, the M1-1295 lacks any ports on its front side that usually adorn modern mini-PCs.\n\nInstead, Minisforum has included a small power button with all ports pushed to the rear of the device. As the image below shows, Minisforum has packed in four USB ports, 2.5 Gigabit LAN, three display outputs and even dedicated microphone and line-in and line-out inputs within a housing that measures 195 x 193 x 52 mm and weighs 1.12 kg.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Minisforum-releases-M1-1295-mini-PC-with-Intel-Core-i9-12950HX-and-up-to-64-GB-RAM.1130797.0.html",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Our guide to every Week 5 NFL game: Matchup previews, predictions, picks and nuggets",
      "content": "Open Extended Reactions\n\nThe Week 5 NFL schedule for the 2025 season brings some exciting matchups.\n\nBrowns rookie QB Dillon Gabriel is making his NFL debut in London against the Vikings. Old teammates in Carolina, QBs Baker Mayfield and Sam Darnold, will face off again in the Bucs-Seahawks matchup. And Commanders QB Jayden Daniels makes his return from injury against the Chargers.\n\nWe have you covered with everything you need to know. Our NFL Nation reporters take you inside the locker room with the best thing they heard this week, and ESPN Research provides a key stat to know and a betting nugget for each contest. Plus, analytics writer Seth Walder makes a bold prediction for each matchup, and fantasy analyst Eric Moody shares fantasy football intel. We also have Football Power Index (FPI) matchup quality ratings (out of 100) and game projections, and three analysts -- Pamela Maldonado, Moody and Walder -- give us final score picks for every game.\n\nLet's get into the full Week 5 slate, which culminates with a \"Monday Night Football\" matchup between the Chiefs and Jaguars on ESPN. (Game times are Sunday unless otherwise noted.)\n\nJump to a matchup:\n\nCLE-MIN | DEN-PHI | HOU-BAL\n\nLV-IND | DAL-NYJ | MIA-CAR\n\nNYG-NO | TB-SEA | TEN-ARI\n\nWSH-LAC | DET-CIN | NE-BUF\n\nKC-JAX\n\nThursday: SF 26, LAR 23 (OT)\n\nBye: ATL, CHI, GB, PIT\n\n9:30 a.m. ET | NFL Network | Matchup rating: 35.2/100\n\nESPN BET: MIN -3.5 (35.5 O/U)\n\nWhat we're hearing on the Browns: The Browns are turning to rookie QB Dillon Gabriel in hopes of jump-starting the league's second-lowest-scoring offense (14 points per game). Gabriel's first start comes in a bit of an unusual spot -- he will become the first quarterback to make his first start in an international game -- but Cleveland believes the third-round pick has prepared well for the moment. Expect the Browns to increase their use of rollouts and RPOs to take advantage of Gabriel's mobility and accuracy. \"[Gabriel] knows where to go with the ball. He knows what the coaching staff wants within the offense,\" wide receiver Jerry Jeudy said. -- Daniel Oyefusi\n\nWhat we're hearing on the Vikings: The Vikings spent their week in London sorting through options for an injury-ravaged offensive line, a particularly concerning development given the strength of the Browns' defensive front. At the very least, the Vikings will be without RT Brian O'Neill (right knee), C Ryan Kelly (concussion) and LG Donovan Jackson (left wrist). Backup C Michael Jurgens (hamstring) sat out practice Wednesday and Thursday, making him very questionable for Sunday's game. In a worst-case scenario, the Vikings could be left with their No. 3 center, their No. 3 left guard and their No. 2 right tackle against a defense that leads the NFL in pass rush win rate (56%) and run stop win rate (37.7%). -- Kevin Seifert\n\nStat to know: The Browns have scored 17 or fewer points in nine straight games dating to last season, which is tied for the longest streak in franchise history. -- ESPN Research\n\nBold prediction: Browns DT Mason Graham will record his first full sack as a pro. It's hard to get a better opportunity than this, as QB Carson Wentz has taken sacks at a massive 11.5% clip so far this season. -- Walder\n\nInjuries: Browns | Vikings\n\nFantasy nugget: Vikings RB Jordan Mason has had 16 or more touches in consecutive games with Aaron Jones Sr. (hamstring) out. The good news: He's seeing heavy usage. The bad news: The Vikings' offensive line has been devastated by injuries and faces a Browns defensive front that previously shut down the Ravens' Derrick Henry and the Packers' Josh Jacobs. Cleveland's defense has allowed just 2.9 yards per carry and the second-fewest rushing yards to backs. See Week 5 rankings. -- Moody\n\nBetting nugget: The Vikings are 14-7 ATS (against the spread) in their past 21 road/neutral games. Read more. -- ESPN Research\n\nMaldonado's pick: Browns 24, Vikings 19\n\nMoody's pick: Vikings 20, Browns 14\n\nWalder's pick: Browns 18, Vikings 15\n\nFPI prediction: MIN, 62.9% (by an average of 4.8 points)\n\nMatchup must-reads: Browns bench Flacco, turn to Gabriel as starting QB ... Vikings' plan for week between Dublin and London ... Vikings' O'Neill, Kelly injured against Steelers\n\n1 p.m. ET | CBS | Matchup rating: 77.8/100\n\nESPN BET: PHI -3.5 (43.5 O/U)\n\nWhat we're hearing on the Broncos: QB Bo Nix has had many weekly exams in his time as the starter. And this week Nix's patience will be tested as much as it ever has against an Eagles defense directed by coordinator Vic Fangio. Fangio, who again has two rookie starters on defense (LB Jihaad Campbell and S Andrew Mukuba), will force Nix to live with the underneath throws. Before last week's win, Nix had not found much success pushing the ball downfield to kick-start the offense. Nix was more settled Monday night, with better footwork and more patience. That will be a necessity in this one as well, given Fangio figures to give Nix a steady diet of simulated pressures and coverage looks that morph after the snap. Fangio has been a particular challenge to quarterbacks in the red zone. -- Jeff Legwold\n\nWhat we're hearing on the Eagles: The Eagles need to get WR A.J. Brown going. He was held to two catches for 7 yards on nine targets last week and created a stir with a cryptic tweet postgame. Brown has been held to 27 or fewer yards in three of four games. Unsurprisingly, the passing game ranks 31st in the NFL. \"I see that we're struggling and I'm a guy that wants the ball in those times when we can't find a way. Give it to me,\" Brown said Wednesday. -- Tim McManus\n\nStat to know: The Broncos' defense ranks first in QBR (40.5) and sacks (15), as well as second in pressures (62). -- ESPN Research\n\nBold prediction: Broncos edge Jonathon Cooper will record a sack against Eagles RT Lane Johnson. That's a tall task considering the opposition, but Cooper has the fastest pass rush get-off in the NFL (among those with at least 50 pass rushes), crossing the line of scrimmage in 0.69 seconds, per NFL Next Gen Stats. -- Walder\n\nplay 3:11 Inside the anatomy of Tyreek Hill's knee injury with Stephania Bell Using Virtual Medicine, Stephania Bell examines Tyreek Hill's season-ending knee injury from an anatomical perspective.\n\nInjuries: Broncos | Eagles\n\nFantasy nugget: Eagles TE Dallas Goedert posted a season-high 19.7 fantasy points in Week 4, despite seeing just four targets. He had only two targets in Week 1, missed Week 2 and saw just two in Week 3, yet he has totaled 41.4 fantasy points. Even though the Broncos' defense is tough, Denver has allowed at least 10 fantasy points to tight ends in two of its past three games. See Week 5 rankings. -- Moody\n\nBetting nugget: The Eagles are 9-3 ATS in their past 12 games as favorites. Read more. -- ESPN Research\n\nMaldonado's pick: Eagles 13, Broncos 10\n\nMoody's pick: Eagles 27, Broncos 23\n\nWalder's pick: Broncos 23, Eagles 21\n\nFPI prediction: PHI, 61.2% (by an average of 4.2 points)\n\nMatchup must-reads: Jones' endless energy catalyst for Broncos' defense ... Inside the champagne problems of the Eagles offense\n\n1 p.m. ET | CBS | Matchup rating: 64.9/100\n\nESPN BET: HOU -2.5 (40.5 O/U)\n\nWhat we're hearing on the Texans: The Texans know they're going against a foe that they've struggled with. The Ravens have a 13-2 record against Houston, but coach DeMeco Ryans said, \"The past is the past.\" Wideout Nico Collins acknowledged the 31-2 blowout loss they suffered on Christmas to Baltimore but said it's time to \"turn the page.\" -- DJ Bien-Aime\n\nWhat we're hearing on the Ravens: The Ravens are 3-0 against Texans QB C.J. Stroud, holding him to an average of seven points per game. But this is expected to be a much different Baltimore defense Sunday. The Ravens have six defensive starters dealing with injuries, including Pro Bowlers in S Kyle Hamilton (groin), MLB Roquan Smith (hamstring) and CB Marlon Humphrey (calf). With all the new players filling in on defense, OLB Tavius Robinson said, \"It's just about doing a little extra in communication.\" -- Jamison Hensley\n\nStat to know: The Ravens have allowed 35 points in three of four games this season, tied for the most such games in a season in franchise history (1996 and 2021). -- ESPN Research\n\nBold prediction: Ravens RB Derrick Henry will record a season-high 22-plus rush attempts. The Texans have a ferocious pass rush but struggle to stop the run. QB Lamar Jackson (hamstring) could be out, so the Ravens are going to want to lean on the ground game. -- Walder\n\nplay 1:20 Smith-Njigba on Seattle's offense: Darnold has been next level Seahawks WR Jaxon Smith-Njigba joins \"The Rich Eisen Show\" to explain why Seattle's offense has started to click this season.\n\nInjuries: Texans | Ravens\n\nFantasy nugget: Texans RB Woody Marks capitalized on a favorable matchup against Tennessee last week, finishing with 21 touches and 27.9 fantasy points. It was the first game in which he out-touched Nick Chubb. He made it count, putting up an outstanding performance despite a Texans offensive line that ranks 24th in run block win rate (68.8%). The good news? Marks has another favorable matchup this week against a Ravens defense that has allowed the sixth-most rushing yards per game to backs (141.3). See Week 5 rankings. -- Moody\n\nBetting nugget: The Texans are the only team to go under the total in all four games this season, and the Ravens are the only team to go over the total in every game. Read more. -- ESPN Research\n\nMaldonado's pick: Ravens 23, Texans 14\n\nMoody's pick: Ravens 23, Texans 20\n\nWalder's pick: Ravens 20, Texans 17\n\nFPI prediction: BAL, 56.0% (by an average of 2.2 points)\n\nMatchup must-reads: Emergence of rookie RB Marks gives spark to Texans ... How the Ravens got to 1-3 and where they go from here ... Texans look to beat Ravens for first time since 2014 ... What's wrong with the 1-3 Ravens? Injuries, consistency, more\n\n1 p.m. ET | Fox | Matchup rating: 48.6/100\n\nESPN BET: IND -6.5 (47.5 O/U)\n\nWhat we're hearing on the Raiders: The offensive line is coming off its best performance of the season, but it took a big hit in the process. After the unit allowed just three pressures while paving the way for rookie RB Ashton Jeanty to record 138 yards, it lost starting LT Kolton Miller to a high ankle sprain. Miller's absence is untimely since the Colts are ranked eight in rushing yards allowed per game (96). Coach Pete Carroll is confident that backup OT Stone Forsythe can step up. \"He started 14 games ... and started on the left side four or five times. So, we're confident that he can do the job,\" Carroll said. \"That's why we went after him.\" -- Ryan McFadden\n\nWhat we're hearing on the Colts: Indianapolis has had one of the most efficient offenses this season, ranking fourth in scoring at 30.8 points per game. But that comes in spite of its concerning performance in the red zone, where the Colts have managed to score touchdowns only 47.4% of the time (25th in the NFL). They've had a rash of ill-timed penalties when in scoring position, and that has led to difficult down-and-distance situations. \"We've got to get that cleaned up, and it's just fundamentals and technique,\" coach Shane Steichen said. \"We'll address it through practice this week.\" -- Stephen Holder\n\nStat to know: Colts rookie Tyler Warren leads all tight ends in receiving yards this season (263), which is the most for the position through four career games in the Super Bowl era. -- ESPN Research\n\nBold prediction: Raiders TE Brock Bowers will record under 30 receiving yards. Bowers hasn't put up big numbers since injuring his knee in Week 1, and the Colts look like a particularly tough opponent. Only 14% of targets against Indianapolis have gone to tight ends, the fourth-lowest rate in the league. -- Walder\n\nAll of ESPN. All in one place. Watch your favorite events in the newly enhanced ESPN App. Learn more about what plan is right for you. Sign Up Now\n\nInjuries: Raiders | Colts\n\nFantasy nugget: Colts WR Michael Pittman Jr. has scored 15 or more fantasy points in three of four games this season while averaging 7.2 targets. He's set up for a huge performance against a defense that has allowed the third-most fantasy points per game to wide receivers. See Week 5 rankings. -- Moody\n\nBetting nugget: The Raiders are 0-3 ATS in their past three games. Read more. -- ESPN Research\n\nMaldonado's pick: Colts 34, Raiders 28\n\nMoody's pick: Colts 34, Raiders 24\n\nWalder's pick: Colts 26, Raiders 21\n\nFPI prediction: IND, 63.9% (by an average of 5.3 points)\n\nMatchup must-reads: Why Booker IV and the Raiders' D-line will be critical to a win in Indianapolis ... Howard abruptly retires, citing 'family first'\n\n1 p.m. ET | Fox | Matchup rating: 39.7/100\n\nESPN BET: DAL -2.5 (47.5 O/U)\n\nWhat we're hearing on the Cowboys: Didn't the Cowboys come off a 40-point performance at home, playing at a winless team just two weeks ago? They did. And lost to the Bears in a listless performance. Now coming off a 40-point performance against the Packers, they face the winless Jets. In 2019, the Jets were also 0-4 when facing the Cowboys, and Dallas lost 24-22. The Cowboys can't repeat what happened to the Bears or what happened in 2019. \"We're judged on wins. I'd say the consistency's not been there,\" coach Brian Schottenheimer said. \"The thing we've got to do, we've got to learn how to finish and how to win.\" -- Todd Archer\n\nWhat we're hearing on the Jets: The gloves are going on -- literally. On Thursday, coach Aaron Glenn wore a boxing glove during a ball-security drill, trying to punch out the ball. The Jets have lost a league-high six fumbles, which explains the emphasis in practice. The Jets are a mistake-prone team -- minus-seven turnover differential and 40 penalties (tied-seventh most). They're seeking to avoid their third 0-5 start in the past 30 years. -- Rich Cimini\n\nStat to know: The Jets have allowed 25-plus points in every game this season (the only team in the NFL to do so). Another such game will be tied for the longest streak of allowing 25-plus points in a season in franchise history. -- ESPN Research\n\nBold prediction: Cowboys LB Jack Sanborn will lead the league in tackles this week. The Jets are running at an outrageous clip and are currently sporting a league-low minus-12% pass rate over expectation. As only light underdogs to Dallas, they very well could stick with the ground game for 60 minutes, inducing tons of tackling opportunities for Cowboys linebackers. -- Walder\n\nInjuries: Cowboys | Jets\n\nFantasy nugget: Jets QB Justin Fields finished with 27.1 fantasy points last week and now faces a defense that has allowed the most fantasy points per game to quarterbacks. Dallas has also given up the most rushing attempts and the fifth-highest rushing yards per game to opposing quarterbacks. See Week 5 rankings. -- Moody\n\nBetting nugget: Cowboys QB Dak Prescott is 21-14-1 ATS in his career as a road favorite (49-36-2 ATS overall as the favorite). Read more. -- ESPN Research\n\nMaldonado's pick: Jets 24, Cowboys 21\n\nMoody's pick: Jets 24, Cowboys 23\n\nWalder's pick: Cowboys 30, Jets 23\n\nFPI prediction: DAL, 63.9% (by an average of 3.5 points)\n\nMatchup must-reads: Pickens keeps impressing Cowboys on, off the field ... Jets RB Allen out indefinitely with knee injury ... Prescott set Cowboys records but is unsatisfied with tie ... Glenn hoping to avoid being first 0-5 Jets coach in Year 1\n\n1 p.m. ET | Fox | Matchup rating: 24.6/100\n\nESPN BET: MIA -1.5 (44.5 O/U)\n\nWhat we're hearing on the Dolphins: Tyreek Hill (knee) will not return this season, but the Dolphins believe they still have a No. 1 receiver in Jaylen Waddle -- who returns to that unquestioned role in Hill's absence. Waddle was Miami's leading receiver as a rookie in 2021, when he caught 104 passes for 1,015 yards and six touchdowns. Coach Mike McDaniel said the view of Waddle doesn't change despite Hill's injury. \"I think we've looked at him as a wide receiver one,\" McDaniel said. \"I think that it's not necessarily a change from the way we approach it the way we see it.\" -- Marcel Louis-Jacques\n\nWhat we're hearing on the Panthers: Coach Dave Canales likes to look at the rash of injuries that have contributed to a 1-3 record as an opportunity for someone else to step up. Unfortunately for him, nobody has. Perhaps it will be rookie WR Jimmy Horn Jr., who will play for the first time after being a healthy scratch the first four games. He brings speed. Or maybe it will be starting WR Xavier Legette, returning after missing two games with a hamstring injury, even though he struggled before the injury. There are plenty of opportunities around. -- David Newton\n\nStat to know: Dolphins QB Tua Tagovailoa has a Total QBR of 19 (33rd) and averages 6.3 yards per attempt (25th) when facing zone coverage this season. The Panthers use zone coverage 68.8% of the time, the seventh-highest rate in the league this season. -- ESPN Research\n\nBold prediction: Panthers WR Tetairoa McMillan will catch multiple passes of 15 air yards or more after having caught exactly one such pass in each of his first four games. The Dolphins' defense is allowing 9.6 air yards per attempt, second most in the league. -- Walder\n\nplay 1:49 Stephen A.: Bengals' season is a 'wash' without Burrow Stephen A. Smith breaks down the struggles facing the Bengals with star quarterback Joe Burrow injured.\n\nInjuries: Dolphins | Panthers\n\nFantasy nugget: Since the Dolphins acquired Hill in 2022, 76% of QB Tagovailoa's completions and 82% of his wide receiver yards have gone to Hill or Waddle. In the only game Miami has played without Hill during that span, Waddle caught eight passes for 142 yards and a touchdown. He should once again see plenty of targets against the Panthers. See Week 5 rankings. -- Moody\n\nBetting nugget: The Panthers have covered four straight games following a loss (2-0 ATS this season). They are 7-1 ATS in their past eight games following a loss. Read more. -- ESPN Research\n\nMaldonado's pick: Panthers 33, Dolphins 27\n\nMoody's pick: Panthers 31, Dolphins 28\n\nWalder's pick: Panthers 23, Dolphins 20\n\nFPI prediction: CAR, 51.3% (by an average of 0.5 points)\n\nMatchup must-reads: WR Hill dislocates knee in win against Jets ... Panthers seek answers after embarrassing loss to Patriots ... Hill injury FAQ: Recovery timetable, his NFL future, how Miami will adapt\n\n1 p.m. ET | CBS | Matchup rating: 19.6/100\n\nESPN BET: NO -1.5 (41.5 O/U)\n\nWhat we're hearing on the Giants: The Giants are pumping in crowd noise and working on communication at practice throughout the week, especially with this being rookie QB Jaxson Dart's first career road game. But Dart noted he played in the SEC and has played in a dome before. He's not looking at the Superdome as any kind of special challenge. He's more concerned with getting the ball out quicker, getting through his progressions better and avoiding sacks against a Saints defense that has gotten home on a respectable 10% of dropbacks. -- Jordan Raanan\n\nWhat we're hearing on the Saints: Saints TEs Foster Moreau and Taysom Hill returned to practice this week for the first time since last season, when both sustained serious knee injuries. Though it's unlikely either will play this weekend, coach Kellen Moore didn't rule it out completely. Getting both players back will be a big boost to the offense. \"With 108 seconds left in the 2024 season, I got a helmet to the outside of the knee on a five-step out route, and my offseason is canceled,\" Moreau said. \"It's brutal, and that part of sports is one of the hardest parts. But what doesn't kill you makes you stronger. And I've had a hell of an offseason.\" -- Katherine Terrell\n\nStat to know: Giants RB Cam Skattebo has 181 rushing yards and 98 receiving yards through four career games. If he has a productive day Sunday, Skattebo would be the fourth Giants rookie since the 1970 merger with 200 rushing yards and 100 receiving yards through five career games. -- ESPN Research\n\nBold prediction: The Giants will deliver double-digit quarterback hits in a win Sunday. After a bit of a slow start, edge rusher Abdul Carter looked dominant last week, and now the Giants face a Saints team that ranks 29th in pass block win rate (51.9%). -- Walder\n\nInjuries: Giants | Saints\n\nFantasy nugget: Dart finished with 19.8 fantasy points last week, with 11.4 of those points coming from rushing. This is a great matchup for Dart, Wan'Dale Robinson and Darius Slayton against a defense that has allowed the fifth-most fantasy points per game to quarterbacks. See Week 5 rankings. -- Moody\n\nBetting nugget: Saints QB Spencer Rattler is 0-10 outright and 2-8 ATS in his career as a starter. Read more. -- ESPN Research\n\nMaldonado's pick: Saints 23, Giants 20\n\nMoody's pick: Saints 20, Giants 18\n\nWalder's pick: Giants 23, Saints 16\n\nFPI prediction: NO, 53.5% (by an average of 1.4 points)\n\nMatchup must-reads: Dart on Saints draft snub: 'Always a chip on your shoulder' ... Saints 'got to find a way to get a win' with Giants looming\n\n4:05 p.m. ET | CBS | Matchup rating: 57.7/100\n\nESPN BET: SEA -3.5 (45.5 O/U)\n\nWhat we're hearing on the Buccaneers: The Bucs have surrendered touchdowns on the first defensive possession in three of their four games, but have only scored on the first offensive possession once. That is a big reason why they've had to come from behind in the final two minutes of their games, which have all been decided by one score or less. QB Baker Mayfield said of this week's game: \"[We've] got to start faster, [we've] got to be the aggressor, not wait [for] whether it's chippy or we get hit in the mouth once. We've got to come out swinging.\" -- Jenna Laine\n\nWhat we're hearing on the Seahawks: Coach Mike Macdonald said that by the Seahawks' in-house metrics, Mayfield is probably the best quarterback in the NFL right now in terms of extended-play situations. \"That's something you have to deal with, but he also plays on time,\" Macdonald said. \"He's extremely accurate, he's got a great arm, and then when he extends plays, obviously he's a great competitor.\" Mayfield has the eighth-fastest average time before throw at 2.68 seconds. -- Brady Henderson\n\nStat to know: The Bucs have scored and allowed an identical 97 points so far this season. -- ESPN Research\n\nBold prediction: Seahawks edge Boye Mafe will record a 25% pass rush win rate -- or better. When DeMarcus Lawrence (quadriceps) got hurt in last week's game, Mafe moved to play more opposite the right tackle. That's where you want to be against the Bucs right now, with Charlie Heck (80% pass block win rate) currently stationed there. Assuming Lawrence either misses the game or plays less, that should set up Mafe to make a pass-rushing impact. -- Walder\n\nplay 1:35 Why Worthy wants same chemistry with Mahomes as Kelce Xavier Worthy joins \"The Rich Eisen Show\" to share his favorite Patrick Mahomes moment and reflects on why playing with him is a blessing.\n\nInjuries: Buccaneers | Seahawks\n\nFantasy nugget: Seahawks QB Sam Darnold has averaged 16.2 fantasy points over his past three games in an offense that ranks fourth in rushing attempts per game. Seattle may need to lean on the passing game against a defensive front that allows the fewest rushing yards to running backs, but Tampa Bay also gives up the eighth-most fantasy points to quarterbacks. See Week 5 rankings. -- Moody\n\nBetting nugget: The Bucs are 6-1 ATS after a loss since the start of last season, and 11-4 ATS after a loss with Mayfield (since 2023). Read more. -- ESPN Research\n\nMaldonado's pick: Seahawks 35, Buccaneers 25\n\nMoody's pick: Seahawks 26, Buccaneers 24\n\nWalder's pick: Seahawks 27, Buccaneers 17\n\nFPI prediction: SEA, 53.9% (by an average of 1.5 points)\n\nMatchup must-read: Seahawks sign Darnold's praises after game-winning drive\n\n4:05 p.m. ET | CBS | Matchup rating: 25.2/100\n\nESPN BET: ARI -7.5 (42.5 O/U)\n\nWhat we're hearing on the Titans: The Titans' defense will do its best to keep Cardinals QB Kyler Murray from breaking off long runs by design or circumstance. Defensive coordinator Dennard Wilson said the pass rush has to be coordinated and disciplined to make sure the defense doesn't leave an escape lane for Murray to leak through. \"He tries to get outside the pocket, they have some options with him,\" Wilson said. \"Things like that with the run pass option and all those things, so we got to keep 'em in a well, we got to contain 'em.\" -- Turron Davenport\n\nWhat we're hearing on the Cardinals: Murray is trying to keep his head down and focus on the present with the state of the Cardinals' offense, which struggled mightily in seven of its past eight quarters. Aside from the fourth quarter in a loss to the Seahawks last Thursday night, Arizona's offense struggled to move the ball and score in Weeks 3 and 4. But Murray said it's hard and the \"human in me\" wants to look at the totality of Arizona's issues, but focusing on today takes discipline, he said. \"I try not to look at the big picture, because s--- gets you get frustrated looking at the big picture,\" Murray said. -- Josh Weinfuss\n\nStat to know: Titans QB Cam Ward has been sacked an NFL-high 17 times this season, while the Cardinals rank fifth in pass rush win rate this season (47%). -- ESPN Research\n\nBold prediction: Cardinals RB Michael Carter will record 80 or more rushing yards. It's hard to know exactly how the Cardinals' backfield work will shake out in light of Trey Benson's move to IR, but whoever gets the rush attempts should be put in a great position for success: The Titans rank fourth worst in terms of EPA allowed per opponent rush (.09). -- Walder\n\nInjuries: Titans | Cardinals\n\nFantasy nugget: The Cardinals' backfield is thin with Benson (knee) and James Conner out. Emari Demercado is now positioned to lead the Cardinals' running back committee. He's firmly on the flex radar in Week 5 against a Titans defense that allows the fourth-most fantasy points to backs. See Week 5 rankings. -- Moody\n\nBetting nugget: The Titans are 3-18 ATS under Brian Callahan, the worst record for any coach in the Super Bowl era (min. five games). Read more. -- ESPN Research\n\nMaldonado's pick: Cardinals 28, Titans 23\n\nMoody's pick: Cardinals 27, Titans 16\n\nWalder's pick: Cardinals 28, Titans 14\n\nFPI prediction: ARI, 73.4% (by an average of 9.7 points)\n\nMatchup must-reads: Despite 0-4 start, Titans still believe they can right ship ... Cardinals need to fill void in injury-depleted running back room ... Ward vents frustration after Titans blanked, fall to 0-4 ... Harrison keeping trust in self amid inconsistencies\n\n4:25 p.m. ET | Fox | Matchup rating: 71.3/100\n\nESPN BET: LAC -2.5 (48.5 O/U)\n\nWhat we're hearing on the Commanders: Washington's defense continues to be plagued by explosive plays, having allowed an NFL-worst 28 pass plays of 15 yards or more. It has been a combination of mistakes: communication and players abandoning assignments trying to make a big play. They'll have to guard Chargers QB Justin Herbert, who ranks 11th with 20 pass plays of at least 15 yards. Of those plays, he has completed seven with three touchdowns to WR Quentin Johnston. \"If we clean up the explosive passes, we're playing solid,\" said defensive coordinator Joe Whitt Jr. \"Right now we're playing sloppy. We will clean it up.\" -- John Keim\n\nWhat we're hearing on the Chargers: After a game where Herbert was hit 13 times and sacked twice, the Chargers could be without two starting offensive linemen again Sunday. LT Joe Alt (ankle) is doubtful for Sunday, and RG Mekhi Becton (concussion) didn't play last week. \"Just go out there and execute and do what you've been trained to do,\" Herbert said of his message to backups. \"They're playmakers, too.\" -- Kris Rhim\n\nStat to know: This will be a staunch matchup in the red zone. The Commanders have scored touchdowns on seven of nine such drives (78%). The Chargers have allowed touchdowns on four of 13 such drives (31%). -- ESPN Research\n\nBold prediction: Commanders QB Jayden Daniels will complete fewer than 10 passes to wide receivers. Chargers CBs Donte Jackson and Tarheeb Still both rank in the top five in lowest yards per coverage snap allowed among outside corners with at least 100 coverage snaps, per NFL Next Gen Stats. That will make throwing outside difficult in any circumstance, and even more with Washington missing WR Terry McLaurin (quadriceps) because of injury. -- Walder\n\nInjuries: Commanders | Chargers\n\nFantasy nugget: Herbert struggled to capitalize in a favorable matchup against the Giants, finishing with a season-low 12.5 fantasy points. However, his fortunes (and those of fantasy managers) could change against the Commanders, who have allowed the seventh-most fantasy points per game to quarterbacks. Herbert also has an elite trio of receivers in Johnston, Ladd McConkey and Keenan Allen, who should help him bounce back. See Week 5 rankings. -- Moody\n\nBetting nugget: Three straight Chargers games have gone under the total. Read more. -- ESPN Research\n\nMaldonado's pick: Chargers 20, Commanders 10\n\nMoody's pick: Chargers 27, Commanders 21\n\nWalder's pick: Chargers 30, Commanders 17\n\nFPI prediction: LAC, 58.2% (by an average of 3.1 points)\n\nMatchup must-reads: QB Daniels (knee) plans to play vs. Chargers ... Alt doubtful to play Sunday, Harbaugh says ... Commanders' D focused on execution after flop vs. Falcons ... Chargers' Harbaugh: Hits Herbert taking 'very concerning'\n\n4:25 p.m. ET | Fox | Matchup rating: 66.0/100\n\nESPN BET: DET -10.5 (49.5 O/U)\n\nWhat we're hearing on the Lions: It'll be an emotional homecoming for Lions RB David Montgomery as he plays in his hometown for the first time in his NFL career. He played the Bengals once in 2021 with the Bears in Chicago (20 rushes, 61 yards), but he has never had a road game against the Bengals. Montgomery attended Mount Healthy (Ohio) High School, where he earned All-State honors as a dual-threat QB. He is coming off a season-low 12 rushing yards with nine carries against Cleveland, but is looking to get back on track in a familiar setting in front of family and friends. \"He's going to kill it,\" Arvie Crouch, Montgomery's high school coach, told ESPN. -- Eric Woodyard\n\nWhat we're hearing on the Bengals: This game will be a gut check for the Bengals in every way possible. The Lions are expected to steamroller Cincinnati, which is in some of the worst form in franchise history. Detroit is second in the NFL in rate of designed rush plays, per ESPN Research. The Bengals' rush defense will have to limit big plays, and stopping those will come down to deploying basic techniques. Said defensive coordinator Al Golden: \"Just defend your gap, keep the ball on your inside pad. Play with leverage.\" -- Ben Baby\n\nStat to know: Bengals WR Ja'Marr Chase is seeking to avoid going three straight games with 50 or fewer receiving yards for the second time in his career. -- ESPN Research\n\nBold prediction: Bengals QB Jake Browning will record a 60-plus QBR. Don't get me wrong: Confidence in Browning has dropped off dramatically from where it was a few weeks ago. But then again, the two defenses he has played have been the Vikings and Broncos, and it doesn't get much tougher than that. Considering his past success, I think there's still hope for him and the Bengals. -- Walder",
      "source": "ESPN",
      "url": "https://www.espn.com/nfl/story/_/id/46436075/nfl-week-5-picks-predictions-schedule-fantasy-football-odds-injuries-stats-2025",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Science history: Invention of the transistor ushers in the computing era — Oct. 3, 1950",
      "content": "A replica of the first working transistor. The design used two thin pieces of gold, a coiled spring, and a slab of germanium. Transistors have come a long way since then, with some of the smallest measuring just an atom thick.\n\nQuick facts Milestone: Transistor patented Date: Oct. 3, 1950 Where: Bell Labs; Murray Hill, New Jersey Who: John Bardeen, Walter Brattain and William Shockley\n\nOn Oct. 3, 1950, three scientists at Bell Labs in New Jersey received a U.S. patent for what would become one of the most important inventions of the 20th century — the transistor.\n\nJohn Bardeen, Walter Brattain and William Shockley had submitted the patent application for a \"three-electrode circuit element utilizing semiconductor materials\" two years earlier, and it would be another few years before the full significance of this technology became clear.\n\nThe transistor was initially designed because AT&T wanted to improve its telephone network. At the time, AT&T amplified and transmitted phone signals using triodes. These devices encased a positive and negative terminal and a wire mesh in a vacuum tube, which ensured electrons could flow without bumping into air molecules.\n\nBut triodes were power hogs that often overheated, so by the 1930s, Bell Labs President Mervin Kelly began to look for alternatives. He was intrigued by the potential of semiconductors, which have electrical properties between those of insulators and conductors. In 1925, Julius Lilienfeld had patented a semiconductor precursor to the transistor, but it used copper sulfide, which was unreliable, and the underlying physics were poorly understood .\n\nAt the end of World War II, as the lab shifted its focus from war technology, Kelly recruited a team, led by Shockley, to find a replacement for vacuum-tube triodes. The team conducted a number of experiments, including plunging silicon into a hot thermos , with limited success. The problem was that they didn't get much amplification.\n\nThen, in 1947, Brattain and Bardeen switched from silicon to germanium and helped clarify the physics at play in the semiconductor. Their work led to a \"point-contact\" transistor that used a little spring to press two thin slips of gold foil into a germanium slab. Notably, this early transistor took some finessing to work, requiring Brattain to wiggle things \" just righ t\" to get the impressive 100-fold amplification in signal.\n\nTriode vacuum tubes from the first half of the 20th century, shown in chronological order from left (1918) to right (1949). Triodes were integral components of phone networks prior to the invention of the transistor, but they used lots of power, overheated and were unreliable, which spurred AT&T to look for alternatives. CC BY-SA 4.0) (Image credit: RJB1, via Wikimedia Commons\n\nIn 1948, Shockley iterated on that design with what would later be termed the junction transistor, the subject of the patent that would go on to form the basis of most modern transistors.\n\nSign up for the Live Science daily newsletter now Get the world’s most fascinating discoveries delivered straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe key to the technology is that when a voltage is applied to a semiconductor, electrons migrate within the material, leaving positively charged \"holes\" behind, according to the patent.\n\nThus, it's possible to create \"N-type\" or \"P-type\" semiconductors — areas that carry an excess of either negative or positive charges. When a metal electrode contacts a semiconductor, the current flow would go one way if touching an N-type material and the opposite direction in a P-type material, the patent noted.\n\nA close-up of three miniature M-1 transistors photographed against a dime. This photo was taken in 1956, and shows just how much transistors developed in the six years after Bardeen, Brattain and Shockley were awarded their patent for the first transistor. (Image credit: AFP via Getty Images)\n\nThe junction transistor takes advantage of this property with a semiconductor with three attached electrodes. By modifying the voltage applied and the properties of the electrodes and the semiconductor, it's possible to reliably amplify the current. This amplification would soon prove invaluable in radios, televisions and telephone networks.\n\nBut amplification isn't what ushered in the era of modern computing. Rather, the junction transistor was a tiny, reliable, low-power, \"on-off\" switch that didn't heat up much. Vacuum tubes were the switches in the first computers, and the transistor was just a much better on-off switch.\n\nShockley was a notoriously bad boss (and a eugenicist and racist ). The key researchers went their separate ways, with Bardeen moving to the University of Illinois and Shockley helping to found the modern Silicon Valley semiconductor industry. The trio would win the 1956 Nobel Prize in physics for their work on the \"transistor effect.\"\n\nJohn Bardeen (left), William Shockley (center) and Walter Brattain (right) pose in a laboratory in 1955. The trio would win the 1956 Nobel Prize for their work on transistors. (Image credit: Hulton Archive via Getty Images)\n\nA few years later, physical chemist Morris Tanenbaum, who worked briefly under Shockley at Bell Labs, would invent the first silicon transistor . In 1959, Jack Kilby of Texas Instruments filed a patent for the first integrated circuit , which would form the basis for the modern computer chip. And by the early 1960s, the vacuum-tube computer was functionally extinct.\n\nIn 1968, Gordon Moore, the founder of Intel, noted in a talk that transistors were being miniaturized and chips were getting twice as powerful at a predictable rate, ushering in the era of Moore's law, which would continue for another four decades.",
      "source": "Live Science",
      "url": "https://www.livescience.com/technology/computing/science-history-invention-of-the-transistor-ushers-in-the-computing-era-oct-3-1950",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "Intel May Start Making AMD CPUs at US Foundries",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_dd81d12f-f8b0-49f0-a7b3-11f47d23be12",
      "timestamp": "2025-10-03"
    },
    {
      "headline": "LLM-8850: Expansion card turns Raspberry Pi 5 into a local AI platform",
      "content": "Cloud-based AI models are quite convenient for typical users. However, some use cases may require to run these models locally in order to ensure data privacy or to work around a slow or non-existing internet connection. That said, a certain amount of performance is needed to run large language models or even AI-assisted video analysis. The latter might be useful for counting people who pass through the entrance of a building, for example.\n\nWith the M5Stack LLM-8850, another expansion card that accelerates these exact AI applications has now hit the market. It’s powered by an Axera AX8550 SoC with four Cortex-A55 cores and an NPU with a performance of 24 TOPs. By comparison, NPUs integrated into modern AMD and Intel CPUs offer roughly twice as much performance. A VPU is onboard as well and can simultaneously decode up to 16 video streams at Full HD resolution. The board further sports 8GB of RAM and comes with a heatsink and a fan.\n\nThe card is connected via an M.2 Key M slot and uses two PCIe 2.0 lanes. The board measures 1.68 x 0.94 x 0.38 inches and is compatible with the Raspberry Pi 5 and other single-board computers or even mini PCs as well as various AI frameworks. Last but not least, the M5Stack LLM-8850 is officially priced at $99, but additional shipping and import fees may apply.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/LLM-8850-Expansion-card-turns-Raspberry-Pi-5-into-a-local-AI-platform.1131787.0.html",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Trump’s $100K H-1B fee draws rare rebuke from US business",
      "content": "A coalition of business groups warned President Donald Trump that a newly announced $100,000 fee for H-1B visa applications risks harming the U.S. economy and urged the administration to avoid changes to the skilled worker program that impose added burdens on companies.\n\nIn a letter sent Friday to Trump, roughly a dozen industry organizations representing chipmakers, software companies and retailers said the new fee threatens to crimp a crucial talent pipeline of foreign skilled workers and leave critical jobs unfilled.\n\n“We ask the administration to work with industry on necessary reforms to the H-1B visa program without increasing the significant challenges U.S. employers face recruiting, training, and retaining top talent,” the groups wrote.\n\nThe letter, sent two weeks after the president’s H-1B proclamation, was careful to laud Trump’s efforts to bring investment to the U.S. Signers included the Business Software Alliance, the semiconductor industry’s SEMI, the National Retail Federation, the Entertainment Software Association and the Information Technology Industry Council, according to a copy seen by Bloomberg News.\n\nThe industry groups’ objections marked a rare rebuke from the business community of U.S. policy under the new administration. Trump announced the H-1B changes at the White House last month, heralding the $100,000 fee as a way to rein in abuses in the skilled worker program while pushing U.S. companies to turn more to domestic talent to fill jobs.\n\nA White House spokesperson defended the new H-1B policy, saying it would help U.S. companies access top talent while reducing fallout from “fraudulent practices by bad-faith actors.”\n\n“Widespread visa abuse not only undermines American workers, but undermines the companies” that need to recruit first-class talent, White House spokesman Kush Desai said in a statement.\n\nHigher costs from the new H-1B fees threaten to hammer a wide range of industries, from technology to health care to finance. Companies including Microsoft Corp., Amazon.com Inc. and Walmart Inc. have relied for years on the skilled worker program to bolster their ranks, and changes to the program put their talent pipelines at risk.\n\nCutting-edge sectors like artificial intelligence and biomedical engineering will need a high-skilled workforce to sustain their pace of growth in the U.S., the groups wrote. The H-1B changes risk hurting progress in those key areas, the groups said. Intel Corp., Taiwan Semiconductor Manufacturing Co., Samsung Electronics Co., Applied Materials Inc. and KLA Corp. all have members on SEMI’s board.\n\n“The new approach to H-1B visas, as it stands, will harm the Administration’s goals to ensure the U.S. remains a leader in AI, revitalizes manufacturing growth, and propels U.S.-developed energy,” the groups wrote.\n\nRepresentatives from Walmart, Target Corp. and Macy’s Inc. are part of the NRF’s executive committee and board. The federation didn’t immediately respond to a request for comment. Walmart is among major users of H-1B visas in the U.S. along with tech giants and consulting companies. After Trump announced the $100,000 fee, several major companies urged employees holding the visa not to leave the U.S.\n\nThe letter emphasized that each of the industries represented “stand ready to work with the administration” to change the H-1B program. Copies of the letter were also shared with Homeland Security Secretary Kristi Noem, Commerce Secretary Howard Lutnick and Secretary of State Marco Rubio.\n\nTrump’s H-1B visa changes faced their first major court challenge on Friday. A nurse-staffing agency and several unions sued the administration in federal court seeking to block the fee. For hospitals, the H-1B program is crucial to recruiting doctors in rural areas hit by shortages of health care workers. The administration said on Sept. 22 doctors could qualify for exemptions from the new fee.",
      "source": "Boston Herald",
      "url": "https://www.bostonherald.com/2025/10/04/trumps-100k-h-1b-fee-draws-rare-rebuke-from-us-business/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Startups and the U.S. government: It's getting complicated | TechCrunch",
      "content": "The tie between startups and the U.S. government have strengthened in recent years, a shift buoyed by an interest in using AI, automation, space, robotics, and climate tech for defense. And while that has provided another welcome path to capital, the relationship is getting complicated.\n\nA growing share of startups have the U.S. government as customers, or are aiming for permits and defense-related contracts. When the government is operational, that connection can provide a needed boost and revenue to startups. But when the government ceases to function, as it did starting October 1, those close ties can stifle or even halt progress for startups.\n\nThis week on Equity, Anthony Ha, Max Zeff, and I (Kirsten Korosec) talk about how a prolonged U.S. government shutdown poses more risk for startups than in the past — not to mention put a damper on an active IPO season. The three of us dug into a few other topics too, including the how AI companies are trying to monetize and the U.S. government’s latest push to take ownership stakes in the tech and industrial sectors.\n\n“This also feels like a reflection of how the startup landscape has changed in say the last decade and especially over the last few years,” Ha said during the Equity podcast, adding the focus was on consumer internet startups for a long time. “Obviously there’s a lot more going on in defense tech, a lot more in deep tech where you maybe need various kinds of regulatory approvals,” he continued. “And so, it feels like much broader swaths of the startup landscape now depend on the government in various ways, in ways that wasn’t necessarily true 10 years ago.”\n\nBut it’s not just startups. The Trump Administration has also continued to extend its reach, and ownership, into the tech industry, too.\n\nThe Trump Administration has renegotiated yet another federal loan — it’s third in recent months followed by one with Intel and rare earth miner MP Materials — and taken an equity stake as part of the newly hashed out deal.\n\nThe U.S. government took a 5% stake in Canadian miner Lithium Americas and another a 5% ownership in a Lithium Americas-GM joint venture to mine lithium in Nevada. The equity stakes will be acquired through no-cost warrants, which are financial instruments that give the government the right to purchase shares at a set price. The new terms came out of a renegotiation with the DOE’s Loan Programs Office of a $2.26 billion loan that was awarded to Lithium Americas under the Biden Administration.\n\nTechcrunch event Join 10k+ tech and VC leaders for growth and connections at Disrupt 2025 Netflix, Box, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, Vinod Khosla — just some of the 250+ heavy hitters leading 200+ sessions designed to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch, and a chance to learn from the top voices in tech. Grab your ticket before doors open to save up to $444. Join 10k+ tech and VC leaders for growth and connections at Disrupt 2025 Netflix, Box, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, Vinod Khosla — just some of the 250+ heavy hitters leading 200+ sessions designed to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss a chance to learn from the top voices in tech. Grab your ticket before doors open to save up to $444. San Francisco | REGISTER NOW\n\nWatch the full episode to hear more about the government’s relationship with startups and tech companies as well as the entertainment industry’s reaction to AI-generated actress Tilly Norwood, and an eye-popping seed round for Periodic Labs.\n\nEquity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday. Subscribe to us on Apple Podcasts, Overcast, Spotify and all the casts. You also can follow Equity on X and Threads, at @EquityPod.",
      "source": "TechCrunch",
      "url": "https://techcrunch.com/2025/10/04/startups-and-the-u-s-government-its-getting-complicated/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Sidus Space (NASDAQ:SIDU) Upgraded at Wall Street Zen",
      "content": "Wall Street Zen upgraded shares of Sidus Space (NASDAQ:SIDU – Free Report) from a sell rating to a hold rating in a research report report published on Friday morning.\n\nSeparately, Weiss Ratings reiterated a “sell (e+)” rating on shares of Sidus Space in a research report on Saturday, September 27th. One investment analyst has rated the stock with a Sell rating, According to MarketBeat, the company presently has a consensus rating of “Sell”.\n\nGet Sidus Space alerts:\n\nRead Our Latest Stock Analysis on SIDU\n\nSidus Space Stock Down 0.9%\n\nSidus Space stock opened at $1.10 on Friday. Sidus Space has a 12-month low of $0.93 and a 12-month high of $7.65. The business’s 50-day moving average price is $1.15 and its two-hundred day moving average price is $1.44. The stock has a market cap of $28.00 million, a PE ratio of -0.56 and a beta of -1.35.\n\nSidus Space (NASDAQ:SIDU – Get Free Report) last released its earnings results on Thursday, August 14th. The company reported ($0.31) earnings per share (EPS) for the quarter. Sidus Space had a negative net margin of 515.33% and a negative return on equity of 129.29%. The business had revenue of $1.26 million during the quarter.\n\nInstitutional Trading of Sidus Space\n\nHedge funds have recently made changes to their positions in the company. Essex Investment Management Co. LLC acquired a new stake in shares of Sidus Space during the first quarter valued at about $45,000. Millennium Management LLC acquired a new stake in shares of Sidus Space during the fourth quarter valued at about $89,000. Jane Street Group LLC acquired a new stake in shares of Sidus Space during the second quarter valued at about $95,000. FNY Investment Advisers LLC acquired a new stake in shares of Sidus Space during the first quarter valued at about $107,000. Finally, XTX Topco Ltd acquired a new position in shares of Sidus Space in the second quarter worth approximately $168,000. 17.91% of the stock is owned by institutional investors and hedge funds.\n\nSidus Space Company Profile\n\n(Get Free Report)\n\nSidus Space, Inc, a space-as-a-service company, engages in the design, manufacture, launch, and data collection of commercial satellite worldwide. Its space services include satellite/space hardware manufacturing; Low Earth Orbit (LEO) launch and deployment services; and space-based geospatial intel, imagery, and data analytics.\n\nFeatured Articles\n\nReceive News & Ratings for Sidus Space Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Sidus Space and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/04/sidus-space-nasdaqsidu-upgraded-at-wall-street-zen/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Maxsun Intros Powerful AI Workstation PC, Featuring Up To Four Intel Arc Pro B60 48G Turbo GPUs, Bringing A Massive 192 GB VRAM Capacity",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/maxsun-intros-powerful-ai-workstation-pc-featuring-up-to-four-intel-arc-pro-b60-48g-turbo-gpus/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "7 reasons Proxmox is the best OS for your homelab",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/reasons-proxmox-best-os-for-your-homelab/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Your RAM has more than one XMP profile, and here's when to use the others",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/your-ram-has-more-than-one-xmp-profile-and-heres-when-to-use-the-others/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "The War Over Defense Tech",
      "content": "1.\n\nLast October, on a Martin Luther–inspired website called www.18theses.com, a software executive named Shyam Sankar published a four-thousand-word polemic with the title “The Defense Reformation.” “As a nation, we are in an undeclared state of emergency,” it begins. There follows a litany of provocations: Chinese escalation in the South China Sea, Iranian attacks on US military bases, the October 7 attacks in Israel, “an estimated 1 million casualties in brutal combat in Ukraine.” All this, Sankar writes, amounts to “a hot Cold War II.”\n\nIt is a war, he argues, for which the US is catastrophically underprepared: “In the current environment, American industries can’t produce a minimum line of ships, subs, munitions, aircraft, and more.” The problem lies with American capitalism in its present form, which—as Sankar lamented last year on a military podcast called The Merge—has left legacy defense firms like Lockheed Martin dominated by “fifth-generation MBA cadre[s]” who care more “about cash flow and buybacks and dividends than…about the honest hard work of engineering innovation.” Under these conditions the defense department’s subsidies for private business, he writes in “The Defense Reformation,” have neither “the supposed advantages of a planned economy nor the (far superior) advantages of a free market.”\n\nSankar is the CTO and executive vice-president of Palantir, the start-up cofounded in 2003 by Peter Thiel that specializes in a peculiar hybrid of big-data manipulation and McKinsey-style consulting work. Many of Sankar’s Palantir colleagues and peers at other Thielworld start-ups—notably Anduril, which bills itself as a pioneering disruptor in software-heavy military hardware—have advanced a similar criticism of the neoliberal state, bemoaning its declining interventions in manufacturing and research and lambasting the legacy defense firms, often nicknamed “primes,” for their sclerosis, inefficiency, and alleged monopolistic behavior. The innovative, capitalist spirit and manly vitalism that defined the defense department through the cold war is, for this group, long gone. The task of the hour, as Sankar writes in “The Defense Reformation,” is therefore nothing less than “to resurrect the American Industrial Base.”\n\nYou might think this would mean something like what, under the previous administration, went by the name Bidenomics: initiatives such as the CHIPS Act or the Inflation Reduction Act, which paled in comparison to total federal defense spending—the combined estimated cost of those two bills, which would be spread over a number of years, was about half the annual defense bill—but nonetheless aimed to bring high-tech manufacturing back to US shores. You would be wrong. “The most important and malleable weapons system,” Sankar writes, is not missiles or other military hardware but software, by which he presumably means technologies like large-scale data manipulation, narrow forms of computerized optimization applied to “smart” weapons systems and robotics, sensors, autonomous weapons systems, and artificial intelligence.\n\nInvesting lavishly in such technology and teaching “our warriors…to wield the software industrial base to maximize lethality” will catalyze what Sankar has elsewhere called a “software-driven reindustrialization” akin to previous industrial revolutions based around water, steam, coal, or oil. For a range of figures in the emergent defense-tech sector to which Palantir and Anduril belong, this will require wrenching guaranteed contracts from the bloated primes and promoting competition by having branches of the armed services bid against one another, not to mention allowing even more sales elsewhere. It will also require binding the state closer to a range of tech giants—especially firms like Meta, Amazon, and Microsoft­—that have thus far, on this view, neglected their patriotic duty to engage in defense work and profited from feminized “ad-tech” instead.\n\nThese arguments have found a broad and receptive audience. In recent years a range of politicians have aligned themselves with the priorities of defense-tech firms, especially as successive White Houses worry about a belligerent Russia, a rising China, and the vulnerabilities exposed by Covid-induced supply shocks—all of which have reenergized a longstanding criticism of Reagan-era political-economic shifts that hobbled productive industries. The Obama and Biden administrations both empowered tech companies at the expense of the primes; Biden, skeptical of free trade and hawkish on China, courted Silicon Valley firms that promised to bring back domestic manufacturing and reindustrialize the rust belt and former defense hubs. But in recent years talk about “software-driven reindustrialization” has become especially widespread on a faction of the new right. That the Trump adviser and conspiracy theorist Laura Loomer could rail on X against Lockheed Martin, with its “woke agenda,” for “delivering F-35 fighter jets that are simply not ready for combat”—and that Elon Musk could respond to her that, in any case, “crewed aircraft will be destroyed instantly by cheap drone swarms”—owes much to the rhetoric of Sankar and his peers.\n\nThis new Silicon Valley defense-tech and finance group—their grievances, ideology, and policy visions—has become central to Trump’s second term. Several defense-tech boosters have assumed powerful positions in the administration, most notably one of Anduril’s former senior directors, Michael Obadal, who was just confirmed as Army under secretary, the second-highest ranking civilian official in the Army. Since January Palantir and Anduril have received many billions in contracts, with more on the way. ICE has contracted Palantir since 2011 for software it uses to enforce sanctions and make arrests, and in April signed a new $30 million contract with the company to, in The New York Times’s words, “build a platform to track migrant movements in real time.” Presumably the deal will help ICE’s director, Todd Lyons, realize a vision he laid out that same month at the Border Security Expo in Phoenix, where he said that he wants his agency to run like Amazon Prime, “but with human beings.”\n\nAdvertisement\n\nThese trends show no signs of stopping. Defense Secretary Pete Hegseth has directed the Department of Defense—now calling itself the Department of War—to increase its spending on software, which, he stresses, is “at the core of every weapon and supporting system we field to remain the strongest, most lethal fighting force in the world.” Trump has signed executive orders designed to ease restrictions on defense exports and speed up and reduce oversight of the DoD’s acquisition process. In September the army announced a new venture-capital-style model for procurement called “Fuze.” Firms like Palantir and their new constellation of Silicon Valley funders stand to benefit handsomely from these developments. “We’re moving to a software-driven, autonomous…battlefield,” the managing director for a prominent private equity firm said at a defense summit earlier this year. “Well, if you want daily software upgrades, you gotta pay software margins.”\n\n*\n\nFew would contest that the political economy of American defense is troubled. Defense monopolies have stifled competition; companies have slowed their investment in production and concentrated instead on payouts to themselves and shareholders; costs and schedules have spun out of control. By now, as the scholar William Hartung has written, the federal government’s ballooning defense budget goes increasingly to “costly, dysfunctional weapons systems that are ill-suited to addressing current challenges.” Yet venture-funded defense-tech firms like Palantir and Anduril have positioned themselves as the solution to these ills without any clear evidence that they can deliver on that promise. The problem, put simply, is that they don’t have expertise in building things. Because they are above all instruments of financialization, designed to bring future values into the present, they tend to be better at generating short-term profits and juicing shareholder value than at creating durable, high-performing software or hardware systems.\n\nAnduril and other companies that offer “autonomous,” AI-enhanced hardware, for instance, have by now attracted criticism from a range of commentators: the evidence indicates that, despite their claims to the contrary, Silicon Valley drones and counterdrones have underperformed in Ukraine, where fighters have tended to prefer cheaper, hardier Chinese and homegrown drones instead. Adopting Palantir’s signature data-organizing software, too, could have significant problems for companies and government agencies in the long term. The software’s code is closed-source and privately hosted by Palantir, which retains the power—subject to the terms of its contracts and to the extent they prove enforceable—to change, update, or terminate it. Using it as the “data backbone” for a vast and complicated system makes it distinctly costly and burdensome to switch software in the future, not to mention to train and retrain its users.\n\nMeanwhile, as several critics have argued, the user loses a significant measure of control over the system itself. “The single fundamental problem with the Palantir contract is that the government is outsourcing all of the work to one company in one go,” a data expert told the New Statesman earlier this year, “and what you get is vendor lock-in. The state doesn’t understand the work, they can’t see the work…. You develop no knowledge, no understanding of it.” On the podcast Second Breakfast, the lawyer and former Army officer Eric Robinson related that, when he used Palantir’s software in the 2010s, “they would recode your data ingest so you couldn’t export it again,” with the result that “you had to pay for their tech to effectively be part of your order of battle…. It often seems like a form of long-term rent seeking.”\n\nIn the telling of companies like Palantir and Anduril, their innovation, efficiency, and software expertise qualify them to jump-start a new era of American industrial policy. But not only do they seem ill-suited for such a task, they have publicly backed the Trump administration as it destroys the foundations of what industrial policy the country has. Alex Karp, the CEO of Palantir, has, for instance, denounced “wokeness” for “corrupting and corroding our institutions,” echoing the rhetoric that Trump and other Republicans have used to attack measures like the CHIPS Act for including some redistributive initiatives and giving workers benefits like child care. We are now in a situation, in other words, where an array of right-wing firms and think tanks perversely extol the virtues of industrial policy and American renewal even as they support politicians and financial institutions that are currently dismantling the infrastructure to actually do industrial policy.\n\nAdvertisement\n\nHow did we get here? The answer lies, in part, in the fact that defense-related industries like the semiconductor sector have themselves long obscured their real relationship to industrial policy. It is a central tragedy of the long US century that military Keynesianism—the use of military spending to spur economic growth and enable spending on welfare and other public goods—has been the organizing principle for the country’s economy and social life since World War II. The defense budget—last year’s allocation was close to $900 billion—goes not just to weapons construction but also to a welfare state within a state: housing, health care, and social services. It funds a great deal of civilian industry, from wooden pallets to satellites and smartphones, not to mention research fundamental to the US economy and some degree of economic redistribution. Because of its sheer scale and reach, defense spending is unique in its ability to facilitate regional coalitions across party lines by directing funding to specific geographical targets: state-specific projects, bases, consortia, and so on.\n\nNational Archives and Records Administration/Wikimedia Commons An armorer’s assistant installing a machine gun in a Lockheed P-38 plane at an aircraft plant in the Western US, circa November 1942\n\nBy forcing policymakers to appeal to “national security” (which since the 1980s has expanded to encompass “economic security”)1 to justify any efforts at industrial policy or social welfare, this system has long hobbled our ability to build a better world. But during the 1970s and 1980s, when a newly organized right wing took aim at state spending and capacity across the board, even the essential national-security fields of electronics and defense found their access to long-term government support under threat. To retain it, they arrived at a kind of truce. In public, these firms would happily chalk their success up to their own entrepreneurial genius. Under the radar, however, a range of policymakers and industry leaders worked to patch together a precarious, largely hidden system of government support that allowed the businesses—albeit in compromised form—to keep relying on federal planning, funding, and stewardship.\n\nNow the new Silicon Valley defense firms are taking advantage of this state of affairs to press their own interests. Rather than downplaying their reliance on the government in public while reaping the benefits of industrial policy in practice, though, they have done just the opposite, indulging in rhetoric about the return of the strong state and “reindustrialization” even as they help dismantle the state in the service of financial capital. Understanding the implications of this shift requires grasping the complexities of the relationship that tech and defense firms have long enjoyed with US state power.\n\n2.\n\nIn moments of “revolutionary crisis,” Karl Marx wrote, men “anxiously conjure up the spirits of the past to their service, borrowing from them names, battle slogans, and costumes in order to present this new scene in world history in time-honored disguise and borrowed language.” The defense-tech elite are no exception: they talk obsessively about the past, transmuting political-economic reality into a story of great-men-as-founders. Karp praises the Manhattan Project and welcomes comparisons to Oppenheimer. A Los Angeles Times piece from last year discovered that Palmer Luckey, the much-profiled founder of Anduril, has a preoccupation with purchasing cold war military relics: the red nuclear phone, “a couple of submarines,” at least one ICBM site. He hopes one day, the profile notes, to acquire “the entire US ground-based nuclear deterrent system…to turn it into a vast museum.”\n\nTheir account of twentieth-century military-economic history is distinctly revisionist. In his appearance last year on The Merge, Sankar explained how to fix the defense-industrial base. “The reality is you focus on winning,” he said:\n\nI’m not a founder of Palantir, but I think about going back to that World War II–era period and the immediate cold war, it was founders. We think of it as Northrop Grumman and Martin Marietta, but it was Jack Northrop and Glenn Martin and Howard Hughes and Henry Kaiser, and even inside of government, the Kelly Johnsons, the John Boyds. These are uniquely hardheaded, creative, difficult people that are required to win. And I think every start-up understands that. That’s what a start-up looks like.\n\nThe truth is dramatically different. The two world wars turned industrial power into US military dominance not because they empowered the genius of individuals but because they built a new and formidable state.2 Industrial and state capacity—not to mention the relationship between industry and government—were forever transformed. World War I inaugurated the use of cost-plus contracts, which stipulate that the government pay for all the costs of development and production plus a set profit. World War II offered the US a taste of a centralized planned economy: the war effort consumed 57 percent of the national income, and the government itself converted all the plants it needed to manufacture war material.3 In 1942, for instance, the War Production Board—which centralized control of investment and production—forced the whiskey industry to divert 60 percent of its production to industrial alcohol and modernized productive processes.\n\nIt would not be an exaggeration to attribute the many new industries that emerged, modernized, or accelerated in the postwar years—aeronautics, vastly improved automobiles and motors, chemical and especially petrochemical firms, modern shipbuilding, electronics, atomic energy, logistics—to centralized government planning and funding. With government help, as Hartung notes in his study Prophets of War, the aviation industry’s production increased by 13,500 percent.4 New plants cropped up across the country, especially in the South and West, inaugurating the long-term industrialization of those regions. Cooperative large-scale applied research proliferated through the National Defense Research Committee, which commandeered both industry and academic resources and personnel. In his 1992 study of US industrial policy, the historian Otis Graham noted that the Defense Plant Corporation built “some 30 percent of the plant capacity on which American mobilization depended,” which was crucial to the postwar aircraft industry.5 Business leaders resisted their subjection to government administrators, and as soon as the war was over they sought to erase these years from public memory. But the fact remained that US defense contractors and technology firms owed their existence to extensive, heavy-handed government planning.\n\n*\n\nGovernment support, oversight, and coordination of important industries largely persisted throughout the cold war. In the immediate postwar period military contracts slowed, but the Korean War ensured another boom that lasted until the wind down of the Vietnam War two decades later. The Department of Defense “directed a large portion of the nation’s scientific and engineering resources throughout the postwar era,” Graham wrote, “frequently picking winning technologies and products by supplying the military’s clients—chiefly the weapons, aerospace, telecommunications, and data processing industries—with R&D support and purchasing of output.” The government covered nearly all basic research (which mostly occurs at government labs and universities), and much of the research and development conducted by private industry. Companies had plenty of money to invest and reinvest in production—and the DoD pressured them to do just that.\n\nScience History Institute An employee inspecting the control board for a solvent recovery system at the Hercules Powder Company plant in Hopewell, Virginia, 1940s\n\nAs the scholar Christophe Lécuyer shows in his study Making Silicon Valley, all this investment made the US semiconductor industry possible.6 DoD contracts remade Fairchild, the industry’s pioneering firm, into a major company, and Fairchild in turn brought suppliers and equipment-makers to the Bay Area. The DoD not only funded the development of microelectronics but prioritized incorporating them into military systems; starting in 1963, Lécuyer notes, proposals had to include them for the projects to receive funding.\n\nDefense Secretary Robert McNamara’s initiatives before and especially during the Vietnam War transformed defense spending and the industrial policy associated with it. Much was made by General Westmoreland, starting in the late 1960s, of the promise that war would become an “electronic battlefield,” with armies taking advantage of all “the advanced technology of communications, sensors, fire direction, and the required automatic data processing” to control the fighting from afar.7 That this vision failed to materialize and cost the US dearly—in lives, reputation, and resources—doesn’t seem to have led anyone to rethink its premises.\n\nIn the late 1960s disenchanted defense workers organized to shift industries such as chemicals and electronics away from war and toward the public good, or at least toward private consumption—an effort known as “civilianization.” At the same time, a civilian market for computer chips was exploding. Those initiatives, the planned Vietnam wind down, and détente with the USSR all helped shrink the federal government’s spending on defense in general and military R&D in particular. But it was a brief experiment that came with significant backlash, helping propel Reagan to the presidency and shaping his industrial policy. The federal share of research dollars remained high for much of the cold war, funding the development of lasers, nuclear energy, rockets, aerospace, computers, scientific instruments, data processing, and telecommunications while neglecting automobiles, steel, pharmaceuticals, and textiles—all of which moved offshore to a greater degree than they already had.\n\n3.\n\nThe first major political-economic changes after World War II came with the neoliberal turn of the 1980s and 1990s. During these years several crises descended upon a range of productive sectors that had historically relied on federal industrial policy. Internationally, Japan perfected production techniques in high-tech manufacturing—of cars, machine tools, memory chips, and other electronics—and quickly approached dominance in many areas considered central to “national security,” like semiconductors and supercomputing. American pundits at the time identified this trend as a direct threat to American-style capitalism and US power.8 The period’s neoliberal economic reforms—which reduced and limited the nature of government spending while demonizing the most basic forms of long-term planning—weakened productive industries still further, leaving manufacturers beholden to shareholder demands for ever more profits and vulnerable to new threats from financial institutions.\n\nThese conditions posed a distinct threat to productive sectors like the semiconductor industry. And yet Intel, which by 1992 was leading the industry in cutting-edge chips, managed to thrive nonetheless. When reporters asked how they did it, the company’s executives pointed to what they called “Moore’s Law,” the idea, named after Intel cofounder Gordon Moore, that chips regularly became smaller and more powerful according to something like a natural principle. Moore’s Law became a fixture of the industry’s marketing presentations, press releases, and internal conferences.9 Over the years it helped convince defense leaders like Clinton’s secretary of defense, William Perry, and his protégée Ash Carter that technological solutions could eventually be found for their most pressing and difficult political problems. Moore’s Law remains an unquestioned assumption of scientific, military and national security state discourse and policy, undergirding the entire political-economic imagination of the post–cold war United States. Just as intellectuals started worrying that there might be fundamental limits to capitalist growth, it posited a horizon of infinite progress.\n\nThe truth was more complicated. Intel, founded in 1968 by Moore and Robert Noyce, came to prominence by developing some of the first commercial metal-oxide semiconductor chips. Those semiconductors had immediate, tangible benefits, including low power consumption, high noise immunity, and cost efficiency. Working from that basis, the company did regularly improve its output with a kind of lawlike consistency in this era. But it wasn’t Moore’s Law that won the battle with the Japanese. Instead, Intel and others in the semiconductor industry built coalitions to carve out exceptions to many of the period’s neoliberal reforms, reaping the benefits of extraordinary state support. Among other things, the Reagan administration offered tax incentives to subsidize factory construction and investment in manufacturing, encouraged coordination and cartelization by offering antimonopoly relief and state planning, and used economic sanctions and diplomatic pressure to force concessions from Japan, such as giving foreign—which in effect meant US—chip manufacturers 20 percent of their market share and sharing significant manufacturing knowledge.\n\nIntel Free Press/Wikimedia Commons Andy Grove (left), the longtime head of Intel, sitting with the company’s founders, Robert Noyce and Gordon Moore, 1978\n\nUnder Reagan it was an open secret that the government’s treatment of the semiconductor industry, among others, amounted to a form of industrial policy. These measures had the backing of a powerful—if peculiar—bipartisan coalition that was preoccupied with sustaining American hegemony: national security and foreign policy hawks, factions in the business world, and a group of tech-friendly liberals, like Massachusetts senator Paul Tsongas and Tennessee senator Al Gore, who became known as the “Atari Democrats.” They were reacting to a new right that objected to industrial policy as such, on the grounds that any government planning and economic intervention smacked of communism: in late 1980 the first installment of the Heritage Foundation’s Mandate for Leadership—like its successor, Project 2025—called for destroying large swaths of government by loosening regulations and oversight, centralizing power in the executive, demolishing state capacity, and eliminating or significantly cutting funding for many programs and agencies.\n\nThe new right lacked the political leverage to end industrial policy entirely. But between 1980 and 1993 they succeeded at making it politically toxic, forcing the industry and its allies to adjust their tactics. Bill Clinton, an Atari Democrat, took office hoping to build the US’s own version of Japan’s powerful Ministry of International Trade and Industry; however hostile he was to labor, he implemented significant industrial policy for semiconductors immediately after his election. After Newt Gingrich’s Contract for America coalition swept Congress in 1994, however, the administration’s room for maneuver narrowed. It was still able to ensure some level of subsidies and planning for semiconductor firms like Intel. But it came to rely heavily on foreign policy measures—like sanctions, trade deals, diplomatic pressure, and throwing around US power to shape new international economic organizations like the World Trade Organization—to open new markets and ensure other benefits for tech companies. By the end of Clinton’s second term, a kind of tacit settlement had locked into place. Even as they continued to depend on these various forms of state support, semiconductor companies, tech entrepreneurs who relied on ever-improving semiconductors, and politicians on both sides of the aisle would insist they owed their success to the information-tech revolution, with its promise of infinite growth and cheap consumer goods, all predicated on the work of individual entrepreneurial geniuses.\n\nThis rift between rhetoric and reality has only grown since. Today’s executives hardly seem to understand the conditions of their own industries; it is as if, on some level, they believe the flattering public narrative their predecessors spun. During his interview on The Merge, Sankar remarked that he and his peers are “children…of a Noycean culture.” In a sense this is not untrue. Intel’s Noyce and Sankar both downplay their industry’s debt to industrial policy; Palantir, not unlike Intel before it, is in part in the business of selling what Wired recently called “a seamless, almost magical solution to complex problems.” But Sankar clearly meant the analogy in a different sense: to lay claim to Noyce’s record of success, to brandish his legacy of American entrepreneurial technological genius, and to insist that Silicon Valley firms’ track record of such triumphs should entitle them to remake government in their own image.\n\n*\n\nThe defense industry faced the same pressures that nearly destroyed US semiconductor firms at the dawn of the post–cold war era. In his last year in office Jimmy Carter reversed the cuts that had depressed the industry for much of the 1970s, and in his first term Reagan initiated an enormous military buildup. All this, Graham writes, strengthened the military’s claim on “the nation’s scientific and engineering resources, and thus its influence on industrial structure.”\n\nBut other developments spelled trouble. By the early 1980s financial regulations were being loosened, and corporations were under increasing pressure—legal, managerial, and structural—to secure shareholder profits in the short term at the expense of long-term health. A low-margin productive industry like defense was badly suited to the era. By the mid-1980s firms were focusing on increasing their financial performance by using stock buybacks and cost-reduction strategies like just-in-time inventory management—ordering only enough resources to cover immediate needs. All this compromised their ability to respond flexibly to crises and to make high-quality products.\n\nIn 1985 the Reagan administration started reducing defense spending again and limited other avenues for profit. Facing increased political scrutiny, Reagan officials had recently made a big show of auditing firms for the appearance of wasteful spending, introducing policies that tightened defense profits and increased accounting paperwork. Many companies, like GE, curtailed their defense wings or left the sector entirely to boost their stock values for an increasingly defense-skeptical Wall Street. The 1980s also saw the rise of corporate raiders, later known as private equity firms, which would acquire a majority share of a company’s stock, take control of its operations, and then “restructure” it, which usually meant stripping it for parts and paying themselves astronomical sums of money. Between 1982 and 1990 such outfits nearly destroyed several defense firms, including Martin Marietta and Lockheed, and left them weakened with large debt-to-equity ratios. With loosened financial rules and low margins came consolidation: between 1985 and 1988 ten of the top sixty defense firms acquired or were acquired by others.\n\nPerhaps no person’s career tracks how the defense industry navigated these changes more clearly than that of Norm Augustine. Born in 1935, Augustine got his start in defense at the Douglas Aircraft Company in 1958. His first foray into government came in 1965 as one of McNamara’s young hires, brought in from the private sector to cut waste using “economic efficiency” measures like cost-benefit analysis. He then ping-ponged between the public and private defense sectors: after serving as the under secretary of the Army he joined Martin Marietta, then one of the country’s largest defense firms. Between 1980 and 1982, meanwhile, he chaired the Defense Science Board, authoring reports on threats to the defense industrial base and its dependence on the troubled semiconductor sector. Rising in the ranks of Martin Marietta over the 1980s, Augustine saw that defense was in turmoil; he later referred to the decade as the industry’s “dark ages.”\n\nDenver Post/Getty Images Martin Marietta CEO Thomas G. Pownall (center) and Norman Augustine (right) talking with a shareholder, 1983\n\nThe fall of the USSR and Clinton’s electoral victory brought a new existential threat. Federal defense funding plummeted: between 1989 and 1997 procurement declined by 60 percent. The result was something like the industry’s Great Depression; in 1995 Augustine told a House committee that an estimated three quarters of the sector, about 90,000 firms, had evaporated in the span of a decade. As defense programs became fewer and more expensive, the remaining firms started making riskier bids, overpromising on cost, time, and quality.\n\nIn 1993 Clinton’s defense secretary, Les Aspin, invited the CEOs of major defense firms to the Pentagon for a dinner that would become known as the “last supper.” The then-deputy defense secretary, William Perry, showed them a slideshow of necessary defense capacity: “We expect defense companies to go out of business,” he told them. When we talked in a recent interview, Augustine told me he feared the administration would nationalize at least significant parts of the industry. They were faced with either entering new markets, consolidating, or downsizing. In the five years that followed, Augustine consolidated many firms under Lockheed Martin, itself the product of the merger of Lockeed and Martin Marietta, forming the country’s largest defense firm. In 1995 the new company went public, at which point it started prioritizing stock prices and other contemporary markers of financial health.\n\nIt worked: in 1997 Augustine wrote that the company’s share price had nearly doubled in two years. And yet in the process Lockheed Martin closed a quarter of its plants and laid off 100,000 workers, vastly paring down management and labor in the name of efficiency. The benefits of all this cost-cutting rarely went to the government. Nor were many of the gains reinvested in production. Lockheed Martin had become good at getting contracts; Augustine wrote in the Harvard Business Review about harnessing the “natural competitive instincts in human beings.” But the products themselves suffered: they were more expensive, slower to deliver, and of lower quality.\n\n*\n\nThe state’s priorities were also changing. The Gulf War seemed to vindicate Westmoreland’s Vietnam-era dreams of an “electronic battlefield.” William Perry, soon elevated to defense secretary, became a firm believer that the US was on the cusp of a “revolution in military affairs”—the idea, as the RAND analyst Paul K. Davis has summarized it, that “technological developments sometimes make possible a qualitative change in the nature of warfare.” That conviction moved him to prioritize funding, developing, and promoting “dual-use” technologies that could be applied to both commercial and military settings. He and Clinton built closer relationships with technology firms, offering them greater access to government and policymaking.10 In the late 1990s, as the researcher Barry D. Watts notes in a 2008 report, the Pentagon encouraged defense companies to “act more like commercial firms.”\n\nAugustine was well-positioned to adapt to these conditions. He had advocated for government support for the semiconductor industry during its crisis: asking “why DoD or the government should provide support for the semiconductor industry,” he testified to the Senate in 1987, “would be much like asking at the outset of World War II why we should buy ships and airplanes because it might help the shipbuilding and the aircraft industries.” From his perch on initiatives like the Defense Science Board, he not only observed but shaped how Intel and others had navigated the changing political-economic waters; now he hoped to replicate their accomplishments.\n\nBetween 1993 and 1998, as Hartung has shown, Augustine lobbied intensely—and successfully—for immense government subsidies for defense in general and the new Lockheed Martin in particular. Those subsidies came in many forms, from aid for mergers—“closing plants, relocating equipment, paying severance to laid-off workers, and providing ‘golden parachutes’ to board members and executives,” as Hartung puts it—to antitrust exemptions and subsidies for arms exports (especially to new NATO countries). “To say that Augustine is wired into the Washington policy-making process is an understatement,” Hartung noted in 1996. “For most of his career, he has been one of a handful of people drawing up the blueprints for American defense policies and deciding where the wiring should be placed.”\n\nIn the 1990s companies like Intel experimented with setting up their own venture capital arms, government-backed consortia, and new institutions whose purpose was to plan and shape the markets around them. Augustine followed their lead: he and other defense industry leaders managed to insulate themselves both from democratic accountability and from the vagaries of anti-statist politics by creating experimental public institutions. In 1998 George Tenet’s CIA enlisted Augustine to help found a nonprofit venture capital firm called In-Q-Tel that gives start-ups long-term guidance and directs them to lucrative, stable government contracts. Unlike traditional VCs, In-Q-Tel claims to focus more on technology and less on profits, though over the years it seems to have helped these new companies make money more than it has helped the government acquire important technology. It was In-Q-Tel that assured the success of, among others, Palantir, Anduril, and the drone company Skydio.\n\nAugustine, who turned ninety this July, hardly ever uses words like “industrial policy” or “neoliberalism,” but in practice he and his peers became influential critics of the neoliberal turn. He has argued that, in the financialized economy, “the tax structure discourages long-term investments” and lamented that shareholders hoping for short-range profit want Lockheed Martin not to “invest in research.” Elsewhere, he has called for renewed federal funding for public education and criticized US companies for moving “much of their manufacturing capability abroad.” In an influential 2005 report called Rising Above the Gathering Storm, he and his colleagues argued that “the prosperity the United States enjoys today is due in no small part to investments the nation has made in research and development at universities, corporations, and national laboratories over the last fifty years.” The “pressures” on that sector, they warned, “could seriously erode this past success.”\n\nIn such moments, Augustine sounds uncannily both like architects of Bidenomics such as Jake Sullivan and Jennifer Harris and like right-wing tech-defense figures such as Sankar, who has similarly criticized “the financialization of the defense industrial base.” There is a certain irony here: by founding In-Q-Tel and seeding a bipartisan consensus around what plagued America’s political economy, Augustine—perhaps inadvertently—helped create the coalition now hoping to displace the company he has spent much of his life running.\n\n4.\n\nDefense stocks tanked in 1998 and 1999, and credit agencies downgraded their debt to nearly “uninvestable” levels. As the industry consolidated, firms got even bigger, more complex, and, via joint contracts, increasingly linked to one another. By 2000 they were in a delicate position. With relatively low profits and cash flow but high debt-to-equity ratios, they increasingly focused less on investing in essential R&D than on trying to grow in the short term by competing recklessly for contracts.\n\nLibrary of Congress Prints and Photographs Division A pilot operating the instrument panel of the Lockheed Martin C-130J-30 Hercules cargo plane during a demonstration flight for Pentagon personnel and press over Andrews Air Force Base, Maryland, 1998\n\nThen came the wars in Iraq and Afghanistan, which, as Hartung has shown in Prophets of War, inaugurated an industry-wide bonanza. Companies like Lockheed Martin entered new markets: “enhanced interrogation,” translation, dubiously legal surveillance. The Bush administration was full of defense monopoly affiliates, among them Secretary of the Air Force James Roche, a former vice president at Northrop Grumman; Secretary of the Navy Gordon England, a former executive at General Dynamics; and Edward Aldridge, who was a member of Lockheed Martin’s board of directors while serving on the president’s commission on space.\n\nCongress subsidized Lockheed Martin for arming new Eastern European NATO members; in 2008 US companies accounted for two thirds of the world’s new arms sales. At the same time, the DoD came to focus on counterinsurgency and counterterrorism techniques that relied heavily on information technology, like cyberwar and “network-centric warfare.” Defense Secretary Donald Rumsfeld wanted to make “the leap into the information age” by pursuing drones and surveillance.\n\nNone of this meant that the trend toward military privatization slowed. It continued apace through the Iraq War, from the US military’s contracts with mercenaries like Blackwater to private contracts for hardware. On Second Breakfast, the former Green Beret Justin McIntosh describes how outsourcing military functions to contractors during the Syrian conflict forced him into a situation not unlike The Wages of Fear:\n\nI had a truck that had a bent rod. These trucks that we’re driving around in, these MRAPs and these large RG-33s…[require] a contractor [to] come in and work on it. We were in an area where we had been shot at. I had to medically evacuate some guys. The contractors did not want to travel. They wanted me to drive this truck hundreds of kilometers to the safe base where they could then repair it.\n\nThe problem, McIntosh continued, was that “we had already taken all of that capability that existed within the United States military”—for instance, the ability to repair its own equipment—and “shifted it over to the private sector. It gave them control.”\n\n*\n\nThis tendency toward privatization continued through the Obama administration, during which defense officials started to fixate on reducing costs. (“The gusher has been turned off,” Defense Secretary Robert Gates announced in 2010.) Obama saw bloated defense monopolies as an obstacle to this goal. But rather than addressing the structure of the industry or its political economy, the administration focused on improving its topline numbers by switching out the supposedly corrupt, atrophied defense giants for new firms from the Democrat-friendly tech sector, which promised to replace the functions of the legacy firms more cheaply.\n\nAn influential proponent of this turn was Ash Carter, whom Obama nominated as his defense secretary in 2014. Carter and his deputy, Robert Work, had a “simple but ambitious” agenda, as the anthropologist Roberto González has written: “to harness the best and brightest ideas from the tech industry for Pentagon use.”11 Carter’s emphasis would be not on training soldiers but on developing drones, automation, satellites, and other cutting-edge defense technologies sourced from Silicon Valley.\n\nCarter’s focus on unmanned tech was not exactly a break from the Bush era, but the shift to the Valley was. Fueled by experiments like In-Q-Tel, the tech-defense coalition was already looking to gain market share: in 2014, nearly a year before Carter took office, SpaceX sued the Air Force for preferring the primes; in 2016 Palantir filed a lawsuit against the Army for allegedly trying to develop internal intelligence software without adequately considering commercial options. (One of Anduril’s founders, Trae Stephens, has claimed that these lawsuits helped Anduril win defense department contracts.)12 Obama and then Trump both also expanded the department’s ability to use its “other transaction authority,” which allows the government to do business more easily with commercial entities, for example by letting it sign contracts faster and with less oversight.\n\nThe defense start-ups that successfully attracted Silicon Valley financing relied on the extraordinary wealth and political lobbying connections of their founders. “Every defense company that had been founded by a billionaire was a success,” as Luckey—who sold his VR company, Oculus, to Facebook in 2014 for $2 billion—noted in 2024. “I hate that we live in a country where that’s the case,” he added. “But I realized that I had a unique responsibility as one of the very few people who was willing to work on national security and blessed with the resources to actually make a real go at it.”\n\nObama officials proved receptive to such lobbying. During his tenure Carter set up an In-Q-Tel-inspired program called Defense Innovation Unit—Experimental (DIUx), which worked closely with a new Defense Innovation Board, chaired by the former Google CEO Eric Schmidt, to determine the government’s investments in emerging technology, from drones to AI. It encouraged Silicon Valley firms and funders with the promise of long-term contracts for defense tech, as well as evaluation and testing—in effect ensuring their success in advance. Carter also laid the foundations for projects that came to fruition under the first Trump administration: between 2017 and 2019 the Army, the Air Force, and the Navy all launched their own experimental institutions designed to set up tech start-ups with military contracts.\n\nPrivate equity and venture capital saw an opportunity to make nearly guaranteed profits off the government’s investments. Between 2021 and 2024, VCs poured $130 billion into defense. In their book Unit X (2024), two of DIUx’s early directors, Raj M. Shah and Christopher Kirchhoff, claim that by 2017 their work had excited “investors and entrepreneurs in Silicon Valley” about working with the Pentagon by lowering “barriers to entry.” (They decline to specify which ones.) When James Mattis visited DIUx under the first Trump administration, in 2017, Shah and Kirchhoff arranged for him to have dinner with the tech investor Sam Altman (then at Y-Combinator) and the venture capitalist Marc Andreessen, who insisted that the Valley was interested in the defense industry and implored him to support the project. Mattis was enticed by the work they were doing on drones—a later fixation of Andreessen’s.\n\nEmployees at Google expressed discontent with the company’s defense contracts, organizing to block initiatives like Project Maven, a machine learning program for the Pentagon. The project was hardly promising: as Alexander Cockburn wrote last year in Harper’s, an Air Force testing unit found in 2011 that, “among numerous other deficiencies,” the drone-mounted cameras on which it relied “could not ‘readily find and identify targets,’ and its transmission rate was too slow.” But DoD funders were eager to collaborate with Silicon Valley all the same. (According to Cockburn, Amazon, Microsoft, and Palantir were among the subcontractors who joined the Maven project after Google declined to renew the contract in 2018.) Since then employers have used the threat of AI to shrink the pool of tech jobs, costing the workers leverage. By 2022 employee dissent had been largely squashed: Google and other major defense firms all but declared that they were happy to work with the military. Now executives at tech and tech-defense firms brag about joining the army reserves to help with the design and purchase of their products—an arrangement that seems rife with potential conflicts of interest.\n\nThe Biden administration continued many of these Obama-Trump trends. Defense Secretary Lloyd Austin appointed Apple’s Doug Beck to direct DIU—as it was by now simply called—and empowered him to report directly to Austin. Congress gave the program nearly $1 billion for the 2024 financial year, and Biden awarded important hardware contracts to Palantir and Anduril. SpaceX doubled its federal contracts at the beginning of the Biden administration; they had practically doubled again by the end. In late 2022 Austin established the Office of Strategic Capital (OSC) to push investment in defense-oriented small businesses and tech start-ups; under the One Big Beautiful Bill Act, it will have $200 billion to spend, and likely more in the 2026 National Defense Authorization Act. Perhaps most visibly, Deputy Defense Secretary Kathleen Hicks enthusiastically embraced all things tech: at a 2024 event organized by Andreessen’s VC firm, she emphasized that “moving fast and breaking things is necessary to win wars.”\n\nNonetheless DIU’s leaders and their Silicon Valley allies felt that the Biden Department of Defense wasn’t friendly enough. By 2023, Shah and Kirchhoff complain, it still awarded most of its contracts to the primes. “It seemed as if the whole Biden team had forgotten about DIU and Silicon Valley,” they write, “even as Ukraine was aggressively deploying DIU technologies on the battlefield.” Their vision for the department is blunt: “All the Pentagon needs to do is be a great customer. Buy products, and trust that good venture capitalists will pour money into the companies building those products.”\n\n*\n\nAll this support for the tech-defense sector has so far had disappointing results. A congressionally mandated report produced this year by the Government Accountability Office suggests that there were no metrics by which DIU could measure its success at actually bringing new technology into the military. The Biden defense department’s embrace of tech yielded such fruits as the “Replicator Initiative,” which committed in August 2023 to delivering “multiple thousands” of new autonomous systems in eighteen to twenty-four months. Hartung told me that many industry experts found that timeline hard to believe: no program had ever delivered products that fast. The deadline the initiative set has now passed, and his skepticism seems warranted. The initial delivery was said to be in the hundreds, and The Wall Street Journal recently reported that some of the program’s systems “have been unreliable, or were so expensive or slow to be manufactured they couldn’t be bought in the quantity needed.”\n\n\n\nFor many observers, the first real test of Silicon Valley defense tech is how US-made drone technology fares in Ukraine, a war often cited as a laboratory for unmanned warfare. In a speech this past August, published in the Free Press, Luckey described going to the front lines “just a few weeks” after the full-scale Russian invasion “to train Ukrainian soldiers on advanced military technology that I had developed.” He witnessed “remarkable” feats, he said: “with drones costing just a few thousand dollars each, a handful of Ukrainian pilots remotely carpeted airstrips with explosives thousands of miles into Russia.” (He seems to have been playing fast and loose with chronology: Ukrainian drones reached hundreds of miles into Russian territory that December; it would take them still longer to reach thousands.)\n\nDrone technology has indeed been crucial to the conflict, especially more recently, as troops have been harder to come by on both sides. But a range of commentators have cautioned against assuming it therefore represents “the future of war.” Prominent defense think tanks like RUSI have warned that “overreliance on uncrewed aerial systems” has created “significant problems” for Ukraine, in part because it “plays into Russia’s strengths” at short-range air defense and other antidrone capabilities. William LaPlante, Biden’s under secretary of defense for acquisition and sustainment, has echoed this view. “Don’t tell me it’s got AI and quantum in it. I don’t care,” he said at a 2022 conference. “The tech bros aren’t helping us too much in Ukraine…. It’s hardcore production of really serious weaponry. That’s what matters.” (Many drone companies, moreover, still rely on Chinese parts.) The subtext behind the flurry of puff pieces treating drone war as an inevitability is that a trough of money in the small-to-midsize drone market is up for grabs, over which various coalitions are starting to compete.\n\nSean Gallup/Getty Images A soldier in a US Army platoon specializing in unmanned aircraft systems watches an Anduril Ghost-X drone landing during an exercise at the Hohenfels Training Area, Bavaria, February 3, 2025\n\nTo the extent that drones have proven essential in Ukraine, for that matter, hardware made in the US—by firms like Microsoft, Skydio, AeroVironment, and Cyberlux—has fallen short of expectations. Ukrainians have found US-produced drones “fragile and unable to overcome Russian jamming and GPS blackout technology,” The Wall Street Journal reported last year. “At times, they couldn’t take off, complete missions or return home.” Skydio recently announced that one of its controllers was vulnerable to radio interference. The trend of connecting more devices together to create an “Internet of things” often creates new vulnerabilities in turn.\n\nAnduril’s output is no exception. The defense blogger who writes under the name Secretary of Defense Rock observed in one widely shared piece that the company’s products “often amount to little more than rebranding existing technologies with a Silicon Valley gloss.” One of their much-touted anti-drone interceptors, the essay suggests, has “the same core function” as a familiar Raytheon product, “with marginal enhancements, repackaged in a sleeker design and infused with branding language that flatters venture capital expectations more than it reflects operational novelty.” Anduril continues to contend both with high costs and with certain problems in the field: “During an exercise last year in the Pacific called Project Kahuna,” according to the Journal, “drones from different manufacturers connected by Anduril’s software struggled at times to coordinate and perform tasks when out of sight from the operator.” Last month, Reuters has reported, the Army’s chief technology officer circulated a memo identifying a “very high risk” factor in Anduril’s prototype for a “next generation command and control” battlefield communications network: “We cannot control who sees what, we cannot see what users are doing, and we cannot verify that the software itself is secure.”\n\nNone of this should be surprising. Anduril is making moves to scale up production, claiming that it plans to open a “hyperscale manufacturing facility” in Ohio next year—but VC–funded firms don’t usually have the incentives or structure to prioritize taking on high-risk hardware projects. Often such companies focus instead on acquiring other firms in areas they’d like to enter, whose “founders” and engineers tend to quickly depart. They often make cuts for “efficiency” that produce an attractive financial picture in the short term, but damage the company in the long run. “The primary product of the defense VC strategy,” the scholar Elke Schwarz has written in a recent article, “is not a defense technology as such, but financial returns achieved through growth.”\n\nWorse still, she notes, venture capital’s “mandate for hypergrowth” means that VC-funded companies feel even more pressure than regular ones to produce exponential profits; when those companies make defense products, investors stand to reap enormous windfalls if armed conflict escalates around the world. “To get the military-industrial sector to grow fast,” Schwarz writes, “perhaps the best catalyst is war, or at least the embrace of its possibility.” Indeed, in 2023 a representative of America’s Frontier Fund, a VC firm backed by Thiel and Schmidt, told investors that if “the China/Taiwan situation happens,” or more generally “if there is a kinetic event in the Pacific,” then the fund’s investments would go up ten times “overnight.”\n\n5.\n\nResisting the defense-tech sector’s great man theory of history has grown all the more urgent now, as the Trump administration seems intent on placing those “great men” at the helm of the national security state and entrusting them with reindustrializing the sectors attached to it. Michael Obadal, the former Anduril senior director who is now Army under secretary, is part of a large cohort of Silicon Valley–adjacent figures in the administration: Dan Driscoll, a onetime J.D. Vance adviser with a background in private equity and venture capital, was confirmed as Army secretary13; Steve Feinberg, founder of the notorious private equity firm Cerberus Capital Management, which in recent years has invested heavily in defense tech, is in as deputy secretary at the Department of Defense, where he is using his experience to “restructure” the Pentagon; the retired general and venture capitalist Dan Kaine is now chairman of the Joint Chiefs of Staff; the Office of Science and Technology Policy is now headed by Peter Thiel’s former chief of staff; and the assistant secretary of defense for critical technologies is now Michael Dodd, also known as “the Doddfather,” an alumnus of DIU.\n\nAt least until the administration’s recent announcement that it is seeking an equity stake in Lockheed Martin, the primes appeared mostly sanguine about their aspiring competitors. Congress—which tech-defense firms spend millions lobbying14—writes the yearly defense budget, and primes have historically wielded considerable power there; they still receive the bulk of defense spending. Among the legacy firms the prevailing consensus has been that the upstarts will not be able to replace them: their products, after all, are already battle tested.\n\nEven so, the defense-tech contracts are pouring in. The Golden Dome missile defense program—a $175 billion-plus redux of Israel’s Iron Dome and Reagan’s Star Wars missile defense program, which experts call just as unfeasible as it was in the Eighties—seems to be shaping up as a cash giveaway to the tech-defense right; a joint bid from SpaceX, Anduril, and Palantir is reportedly the front-runner for the contract. (Hegseth has ordered major cuts at the Pentagon testing and evaluation office that a congressional panel recently tasked with assessing the program.) Other start-ups hope to privatize hardware testing, and Palantir seems to be positioning itself to assume some of the same functions of the embattled National Oceanic and Atmospheric Administration. New Pentagon rules that facilitate “anything-as-a-service” contracting allow private companies to shut off or modify their products as they desire (within contractual constraints, assuming these are followed), making US arms exports considerably less appealing to other countries but allowing the companies veto power over the use of their services or weapons—and further opportunities for rent-seeking. This past May, Luckey announced that Anduril would, as 60 Minutes put it, surpass “$6 billion in government contracts worldwide” by the end of the year. “We buy a lot of things from Palantir,” Trump said at a recent White House AI summit, calling out Sankar by name.\n\nScott Legato for Palantir Technologies/Getty Images Palantir CTO Shyam Sankar giving a keynote speech at the Inaugural Reindustrialize Conference in front of a projection of Intel cofounder Robert Noyce, Detroit, Michigan, June 26, 2024\n\nDefense-tech executives clearly hope to take advantage of the post-Covid surge of interest in industrial policy. There has been a great deal of chatter in right-wing circles, from Oren Cass’s American Compass to the Heritage Foundation, about the prospect that the US could move from a supposedly feminized service-based economy to a masculine-coded, producerist one organized around defense manufacturing. (In April, Fox News ran the chyron “TRUMP’S MANLY TARIFFS: PUNDIT BELIEVES IT COULD REVERSE CRISIS IN MASCULINITY.”) Even institutions like the American Enterprise Institute, which have historically reviled industrial policy in any form, have jumped on board, publishing papers endorsing industrial policies of different kinds tied to “national security.”\n\nPalantir’s leaders have echoed this rhetoric for their own purposes: Sankar lamented on The Merge that the best minds have gone into fields like ad-tech rather than defense engineering; Karp has declared that US industry has degenerated in the past fifty years to focus on “the consumer market” rather than using technology to “address challenges of industrial and national significance.” Trump himself seems to alternately contradict and endorse this agenda. He has been especially critical of CHIPS, accusing it of offering companies money they didn’t need and requiring them to hire “woke people” that hampered their success; at a recent AI summit he encouraged “all American companies to join us in rejecting poisonous Marxism in our technology.” It is as if he thinks that chip manufacturing can be brought back to the US through permitting reform and tariffs alone. Appalling immigration raids like the recent one on a Hyundai factory in Georgia have conflicted with the administration’s aim to learn from foreign expertise, producing extreme international backlash.\n\nMost recently, under Feinberg’s aegis at the DoD, the administration has pioneered an entirely new form of statecraft: running the Pentagon like a private equity firm. In the past two months the government has made a slew of one-off deals with companies like NVIDIA, AMD, Intel, and a rare earth mineral company called MP Materials. At the center of some of these agreements is a novel reading of the Defense Production Act, which the Senate Armed Services Committee is trying to formalize via a new provision allowing the government to make equity purchases in private firms. The provision has yet to pass—which has not stopped the administration from going ahead anyway.\n\nThe MP Materials agreement is instructive. Feinberg, no stranger to investing in the defense world, reportedly negotiated the deal, which includes a provision to buy magnets from the company despite the fact that they only started manufacturing magnets last year. By offering a price floor and production guarantees, the Department of Defense made it possible for Goldman Sachs and JP Morgan to finance the issuance of equity in the firm—at which point, seemingly for the first time in US history, the DoD itself bought enough equity to become the company’s largest single shareholder and provided a $150 million loan for the company’s California mine.15\n\nEach of these deals works a bit differently. CHIPS had promised Intel $11 billion on the condition that it met certain milestones, including building an arguably unnecessary Ohio megafactory; when the firm appeared unlikely to meet those conditions, the Trump administration exchanged the remaining money for roughly 10 percent equity in the company. With AMD and NVIDIA, the mechanism looked more like a straightforward shakedown: Trump announced that if NVIDIA wants to continue selling AI chips to China, it has to fork over 15 percent of the profits.\n\nThese moves hardly amount to a real industrial strategy. One-off coercive deals with individual companies already seem unlikely to reindustrialize the country, and it remains unclear what the administration will do with its new assets. But that outcome seems even less plausible as the Trump administration takes a sledgehammer to the government’s capacity, oversight, and industrial policy. In a mere nine months the administration has destroyed the infrastructure of research and development on which the semiconductor industry and many others rely; done its best to “get rid of” the “horrible, horrible” CHIPS Act, including the new research infrastructure it created; threatened to arbitrarily revoke awards and enacted swiftly changing tariffs that damage industries; behaved so erratically toward the US’s longtime allies that the EU and others have started looking elsewhere to buy weapons; erased the nonpartisan image on which the military depends for its continued funding and ability to operate; decimated the Pentagon’s civilian staff; devastated green industries while simultaneously promising to drive the price of oil so far down that the industry believes it will cause significant bankruptcies; and curtailed the Department of Defense’s product testing, among much else. None of the defense-tech firms that praise industrial policy in theory have launched any serious public protest against these decisions. The more contracts they get, meanwhile, the more government resources they will siphon away from investing in fields—like climate technologies, welfare, or alternatives to plastics—that would benefit the US’s economy or security.\n\nBigger tech companies such as Meta, Amazon, and Google have, for their part, also moved much closer to the Trump administration. They seem indifferent about the destruction of the infrastructures of research and support upon which they previously relied, perhaps because they believe they can hire researchers on a mercenary basis, outsource research and development to AI, or replace government functions with private ones—a doubtful prospect, since the government’s function as a neutral evaluator and standard-setter seems impossible to replace.16\n\nThe practical problem with this vision, to say nothing of its moral and ethical failings, is that it can only deal with the short term. “We love disruption,” Karp said during the company’s quarterly earnings call in February. “Disruption, at the end of the day, exposes things that aren’t working. There will be ups and downs. There’s a revolution. Some people are going to get their heads cut off. We’re expecting to see really unexpected things and to win.” Tech companies and venture-capital firms have become experts at leveraging this sort of “disruption” to generate value for their shareholders on the basis of imagined future profits, and firms like Palantir and Anduril are no exception. But now they have become so voracious, so all-consuming, that they are putting the country’s productive industries at risk. In the process, they threaten to destroy not just the source of their own profits but the spending and investment that lie at the foundation of the US economy. We may all end up with our heads cut off.",
      "source": "The New York Review of Books",
      "url": "http://www.nybooks.com/online/2025/10/04/the-war-over-defense-tech/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "arango-cve-processor 1.2.7",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/arango-cve-processor/1.2.7/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Can a Cultured Mushroom Extract *REALLY* Shrink Tumors, Clear HPV & Supercharge Immunity?, with Meagan Lindquist",
      "content": "Ben Greenfield [00:00:00]: My name is Ben Greenfield, and on this episode of the Boundless Life podcast...\n\nMeagan Lindquist [00:00:05]: So they gave these 195 participants about 6 grams of AHCC per day for six months. And they were measuring the tumor size, the tumor mass, and also NK cell activation and some other anti cancer cytokines, these chemical messengers that start to tell the body to break this tumor down. They were measuring all of this. The results were absolutely astounding.\n\nBen Greenfield [00:00:30]: Welcome to the Boundless Life with me, your host, Ben Greenfield. I'm a personal trainer, exercise physiologist, and nutritionist. And I'm passionate about helping you discover unparalleled levels of health, fitness, longevity, and beyond. Hey. So for today's podcast, I interviewed this woman who's an expert in something never heard of before. It's called AHCC. It's this weird mushroom extract stuff that just blows up your immune system in a good way and has all these other effects. Some of the stuff she talks about with cancer and HPV and autoimmune stuff is pretty mind blowing and it's pretty rare I come across something I haven't heard of before until now.\n\nBen Greenfield [00:01:17]: So check the audio and the video out. Shownotes are at BenGreenfieldLife.com/AHCCpodcast let's, let's tune in with Meagan Lindquist. I'm always on the lookout for cool new compounds that I haven't heard of before. And one of my buddies, he's known as like the world's greatest formulator, Sean Wells. He and I were talking about immunity and he's like, you gotta check out this stuff called AHCC. And he's been on the podcast a few times and I usually generally trust what he says or at least trust enough to look into it. And apparently it's like this immunity powerhouse mushroom extract stuff. I'd never heard of it before.\n\nBen Greenfield [00:01:56]: And, and so I started digging into it and Meagan Lindquist, it appears that you are like the world's leading authority on this stuff, but you were like a dental hygienist before that. So I'm sure you have an interesting story about this. It's one of those situations in which I just come across this fringe thing I've never heard of before. And then you sent me this stuff, which tastes incredible. It's like cinnamon swirl latte. And it's always good when stuff doesn't taste like, pardon the expression, ass, and then you got the capsules here. And I'm super interested in this stuff because I get a lot of questions from people about, you know, this time of season, going into cold and flu season and travel and immunity. And a lot of people know that mushrooms are good for immunity and they've heard about Chaga and stuff like that.\n\nBen Greenfield [00:02:45]: But this is kind of a new kid on the block. So if you are listening or watching all the shownotes gonna be bengreenfieldlife.com /AHCCpodcast I said that right? Ahcc. Ahcc podcast. I don't even remember what it stands for, but you can get into that. So what is it?\n\nMeagan Lindquist [00:03:09]: Yeah, it's a good place to start. First, I just wanna say thank you for allowing me into your beautiful home and allowing me to share this with your audience. It's helping me like fulfill one of my dreams and one of my purposes, I believe on this earth is to, is to help share this.\n\nBen Greenfield [00:03:26]: Yeah, well, it was kind of random by the way, because I was going to interview you today and then I found out like last week that you guys were in town.\n\nMeagan Lindquist [00:03:32]: Yeah, it worked out perfect. But yeah. So AHCC is a cultured mycelial product that comes from the mycelia of several different species of mushrooms, including shiitake. So it's classified as a functional health food, but that really doesn't reflect the vast nature of use that we see for so many different diseases and conditions.\n\nBen Greenfield [00:04:07]: What's that mean by that? It's classified as a food. Does that mean by the FDA is something different than.\n\nMeagan Lindquist [00:04:13]: Well, it's not regulated by the FDA, but it is. Mushrooms in general are considered health foods, functional foods. So because it's derived from mushrooms, it's not a mushroom in and of itself. You wouldn't go out to the forest and find an AHCC mushroom, but it's derived from the mycelia of several super potent hybridized mushroom strains, including shiitake.\n\nBen Greenfield [00:04:39]: That's great. So the people who are taking like 70 different supplements are embarrassed about that. Don't have to make this 71 because this just counts as food.\n\nMeagan Lindquist [00:04:46]: Yeah, yeah, it's a functional food. So we know with health supplements in general, they're generally very safe. So it has an extremely high, robust safety profile. But it also has really impressive clinical and medical indication of use for things ranging from HPV to cancerous tumors, to lyme to all sorts of different chronic issues, skin issues like hydrogenitis, supportiva, herpes, warts.\n\nBen Greenfield [00:05:21]: No clue what that is but it sounds horrible.\n\nMeagan Lindquist [00:05:22]: It is, yes.\n\nBen Greenfield [00:05:23]: Any disease that's hard to pronouce.\n\nMeagan Lindquist [00:05:24]: Right. It is not a fun condition to live with. They think it has an autoimmune link. So AHCC is, you know, classified as this, which I'm sure we'll get deeper into. But it's actually an immunomodulator, so it's able to modulate the immune system, not just boost it, not just, you know, suppress it. Like, you know, someone would take a medication for autoimmune that's suppressing their immune system. It really can do both and both at the same time, which is very unique.\n\nBen Greenfield [00:05:52]: So like some of the stuff you listed off, you know, skin issues, Lyme to a certain extent, a lot of these are not considered. I got sick issues, but more, you know, because there was something going around, but more like actual autoimmune body attacking itself issues. So you're saying it can also help with that kind of stuff?\n\nMeagan Lindquist [00:06:07]: Absolutely.\n\nBen Greenfield [00:06:07]: How'd you find out about this?\n\nMeagan Lindquist [00:06:10]: So I. My love affair slash obsession with AHCC began where all many, many good stories start, which is at my rock bottom of my health hell hole. I was recently divorced in 2018. I was really sick, kind of like self induced orthorexic exercising too much.\n\nBen Greenfield [00:06:32]: Was that when you were a dental hygienist?\n\nMeagan Lindquist [00:06:34]: Yeah, I was a dental hygienist and I loved it. Loved being a dental hygienist. I'm still a dental nerd at heart. And actually it was in the dental office that I learned about AHCC. In our office, one of the, one of the women, one of the patients that we worked with, she got diagnosed with HPV in her 50s. And her naturopath recommended this quote unquote mushroom supplement to help clear her HPV. And it worked. And I was astounded.\n\nMeagan Lindquist [00:06:59]: I was like, what is this stuff? I need to learn more about it. I got on the Internet, looked up Dr. Google and found out that it had its own research organization. And I was blown away. I dove down the rabbit hole and.\n\nBen Greenfield [00:07:14]: I AHCC had not HPV, but AHCC.\n\nMeagan Lindquist [00:07:16]: Has its own AHCC has its own research organization. And I dove down this rabbit hole and I've never come out. As I learned more and more about it, I just kept telling myself, you know, there was this nudge from inside, like I need to tell more people about this. I need to keep talking to people about this. And then I used it on myself. I started taking it and along with other mushrooms, listening to podcasts like yours and others, like really diving into like, what is holistic health really? It's not over exercising, it's not under eating, it's not just being skinny. It's more than that. It's really like coming from the inside out.\n\nMeagan Lindquist [00:07:52]: And it really Helped me break through some of the issues that I was having. And then I started sharing it with my patients. I started sharing about it on Instagram. My account kept growing and growing. Then in 2019, I went to the ICNIM, which is the International Congress on Nutrition and Integrative Medicine in Japan, where all AHCC comes from.\n\nBen Greenfield [00:08:15]: All the crazy stuff comes out of.\n\nMeagan Lindquist [00:08:16]: Japan and that's where AHCC originates.\n\nBen Greenfield [00:08:18]: Are one of those three.\n\nMeagan Lindquist [00:08:20]: So I went to Japan with a group of people and I attended this congress which was really kind of researchers and doctors, physicians from all over the world studying AHCC and presenting their research. It was like a three day red carpet event for me, you know, learning more about AHCC.\n\nBen Greenfield [00:08:36]: Very small leech area of the world.\n\nMeagan Lindquist [00:08:39]: I mean, there was five, over 500 people there. Yeah, it was. It was incredible. I mean, it is.\n\nBen Greenfield [00:08:44]: Were they mostly Japanese people?\n\nMeagan Lindquist [00:08:45]: No, they were from Italy, from Brazil, Definitely from America as well. I mean, all over the place. This is studied all over the world. It's the most clinically researched specialty immune supplement in the world.\n\nBen Greenfield [00:08:57]: I mean, I talk to a lot of people and kind of sort of fancy myself as somebody who likes to stay on the bleeding edge, but I'd never heard of it until like three months ago. Is this new or something that's been used for a long time?\n\nMeagan Lindquist [00:09:11]: It's. It. It was created in 1986. So it started in Japan and...\n\nBen Greenfield [00:09:17]: It was created? You mean that the mushroom was created by way to get it out of the mushroom.\n\nMeagan Lindquist [00:09:23]: So I'll pull on that thread a little bit. So in 1986, a group of doctors led by Dr. Toshihiko Okamoto in Japan at the. At Tokyo University, they were studying a bunch of different species of mushroom mycelia and how they affected NK cells. And they really wanted to find the most robust activation of NK cells.\n\nBen Greenfield [00:09:44]: NK is like the killer cells\n\nMeagan Lindquist [00:09:46]: Natural killer cells.\n\nBen Greenfield [00:09:47]: Natural killer.\n\nMeagan Lindquist [00:09:47]: These are like these silent assassins that they don't need permission from anybody in the immune system to take out a cancer cell, to take out, you know, viral replication. So these are. If your NK cells are down to zero, you're dead. We saw it during COVID NK cells were very, very important. People with low NK cell counts usually struggled really horribly with.\n\nBen Greenfield [00:10:08]: Does that happen with AIDS too?\n\nMeagan Lindquist [00:10:10]: AIDS, I think is a cluster. Yeah, it's a cluster of things happening there. But so these doctors were studying this mycelia. They found a group, you know, that they felt comfortable with. They saw really robust activation of NK cells. They created a mass sample of this AHCC put it in an ISO certified deep freezer. And so every sample, every, every batch of AHCC, every capsule is absolutely identical because it comes from this one super sample in the same place.\n\nBen Greenfield [00:10:43]: Like still the same place?\n\nMeagan Lindquist [00:10:44]: Yes.\n\nBen Greenfield [00:10:45]: Since 1986.\n\nMeagan Lindquist [00:10:46]: Yes.\n\nBen Greenfield [00:10:47]: My gosh.\n\nMeagan Lindquist [00:10:47]: Yeah.\n\nBen Greenfield [00:10:48]: How's that like sustain? Is it a really big freezer?\n\nMeagan Lindquist [00:10:51]: So you only need a tiny size.\n\nBen Greenfield [00:10:53]: I mean like a million people buy this stuff?\n\nMeagan Lindquist [00:10:54]: Yeah, you only need a tiny sample for it then to grow and to culture. So it's cultured over 45 days.\n\nBen Greenfield [00:11:00]: Like from a business standpoint, would a supplement company like use this as their contract manufacturer, get a small batch, then they could grow it themselves.\n\nMeagan Lindquist [00:11:10]: No, the process, the manufacturing process is completely patented. All AHCC comes out of one source in Japan, in Sapporo, Japan, which is where I visited, saw the whole manufacturing process.\n\nBen Greenfield [00:11:21]: Hope that place doesn't burn down.\n\nMeagan Lindquist [00:11:23]: Fingers crossed. And so that's one of the many reasons why AHCC is so unique, why it's so different than any other mushroom supplement, but also any other supplement at large. Because of the culturing process and the way that it cultures for about 45 to 60 days. And there's a very specific enzyme reaction that breaks down the molecules so that they are better absorbed by the human body. So they're more bioavailable, it's more potent than your run of the mill mushroom supplement.\n\nBen Greenfield [00:11:58]: Do you know, if you like. So the culturing thing, do you like take certain mushrooms and then mix them with something like. Hopefully. This is a stupid question.\n\nMeagan Lindquist [00:12:07]: No, it's not a stupid question. Yeah. So it's a liquid tank. So they take this sample of mycelia. They. And I don't know every single detail of the proprietary process because it's proprietary. They don't really like let out every single step of the process to just anyone, but they're basically taking a small sample and that they, the, basically the mycelial mass grows and then they're putting it in a liquid tank for up to 60 days. Then it goes through a concentration and freezing process and then it's encapsulated.\n\nMeagan Lindquist [00:12:38]: So it's a very long, very specific process that's different than any real, any other product out there.\n\nBen Greenfield [00:12:47]: Totally random question because you brought capsules a few times. So like this stuff, this powder, do you just take the capsules and break them open?\n\nMeagan Lindquist [00:12:54]: It's, it's. Yeah, yeah. So we use a manufacturer where they're using Chaga and Tremella and this is the fruiting body. So if you go back to seventh grade, you know, biology class, you're Looking. If you're looking at the fungal organism, the fruiting body is what sprouts out above the ground. That's what many different mushroom products are made of. That's what Mushy Love is included.\n\nBen Greenfield [00:13:13]: Oh, so this is not AHCC.\n\nMeagan Lindquist [00:13:14]: Nope.\n\nBen Greenfield [00:13:16]: Gotcha. That's what I was confused. So these are different ones?\n\nMeagan Lindquist [00:13:19]: Yes.\n\nBen Greenfield [00:13:19]: What does the AHCC taste like?\n\nMeagan Lindquist [00:13:21]: It's just earthy. It's just earthy. It's not too bad, honestly. We have people that just put it in water and drink it down, but it's really not too bad. But, yeah, Mushy Love is a completely different product. AHCC is in a class of its own.\n\nBen Greenfield [00:13:33]: So if Mushy Love is Chaga and Tremella, I'm assuming, like, you're like, you got. What's your website? The medicine. So you guys make and sell the Mushy Love, but then you also have your own version of AHCC.\n\nMeagan Lindquist [00:13:44]: Yes.\n\nBen Greenfield [00:13:45]: Yeah. So the Chaga and Tremella in that, how would you compare that to whatever they're using as the mushrooms in this one?\n\nMeagan Lindquist [00:13:54]: Yeah. So basically we're using the fruiting body mushrooms of Chaga and Tremella and it's just a different molecular structure. So although I love our product, it's amazing. I love using fruiting body products. It's just not the same because of. When you look at the molecular structure of what's in here is mostly beta glucans, which you've probably heard of before. What's in what's most powerful in the AHCC is called alpha glucans. And they go through this enzyme process that basically changes the alpha glucans even more.\n\nMeagan Lindquist [00:14:26]: So they're much smaller on a molecular level, going from 200,000 Daltons, which is what beta glucans are, to about 5,000 Daltons, which is what...\n\nBen Greenfield [00:14:35]: Yeah, dalton is like the measurement, the unit of measure for a molecule.\n\nMeagan Lindquist [00:14:38]: And so the smaller the molecule, the easier. Easier it is for you to absorb. That's why just eating a bunch of shiitake mushrooms is absolutely not the same.\n\nBen Greenfield [00:14:46]: That's what I was going to ask. Okay, so they are using shiitake for this one.\n\nMeagan Lindquist [00:14:49]: Yeah, it's shiitake and a couple other.\n\nBen Greenfield [00:14:51]: I was going to ask you, like, why couldn't I just go get it because they taste delicious.\n\nMeagan Lindquist [00:14:54]: And I get that question all the time. And you should, you should throw them in your stir fry or whatever, but it's not going to. It's not going to yield the same result as having AHCC in your body because of that. Molecular structure, the bioavailability. Bioavailability and the potency of AHCC that's unlike any other mushroom supplement.\n\nBen Greenfield [00:15:11]: I'm going to try to spit this out because you corrected me. I think it was Sean who got me interested in this. He said, you got to check out this AHCC stuff. It's like active hexose correlated compound. I get that. Active hexose correlated.\n\nMeagan Lindquist [00:15:25]: Yeah. That's what people.\n\nBen Greenfield [00:15:26]: And you're like, no, it doesn't really stand for that.\n\nMeagan Lindquist [00:15:27]: Yeah, yeah. So this is a big misunderstanding that the manufacturers and we are trying to kind of correct as we go along, because way back many years ago, during the many different research studies that have come out, one of the researchers basically coined this term, this active hexose correlated compound. He started calling AHCC this, and you see it a lot in different studies. So if someone looks it up on Google, they're going to see active hexose correlated compound. How I explain it is like, Organifi green juice has ashwagandha in it, but it's not Ashwagandha. Ashwagandha is one of the components of Organifi green juice. And you're drinking Organifi green juice with the many constituents. AHCC has active hexose correlated compound as one of the fractions, but it's not the entire thing.\n\nMeagan Lindquist [00:16:19]: There's other parts to it. So he pulled out this acronym, put it in a study, and then it kind of snowballed from there.\n\nBen Greenfield [00:16:26]: So what's AHCC stand for?\n\nMeagan Lindquist [00:16:28]: The manufacturers never intended it to be an acronym. I know it's kind of confusing because it sounds like it's confusing because there's.\n\nBen Greenfield [00:16:35]: Something in it that is an acronym for active hexose correlate compound. But then AHCC itself is not an acronym.\n\nMeagan Lindquist [00:16:40]: It's just like, very confusing.\n\nBen Greenfield [00:16:41]: Yeah, this is like the fault of the Japanese lab.\n\nMeagan Lindquist [00:16:45]: You'll even hear me on very early podcasts, you know, talking about, oh, it stands for active hexose because it's in the research. You think if it's in research, this has got to be right? Yeah, but, you know, I just had a call with the manufacturers last week and, you know, we. We continued to talk about, okay, how do we explain this in a way that's. That's graspable for people?\n\nBen Greenfield [00:17:03]: Yeah, yeah.\n\nMeagan Lindquist [00:17:04]: So it's very confusing, but it's just AHCC.\n\nBen Greenfield [00:17:06]: Okay, so you said the research, and then this is always the kicker. You know, whenever we're talking about a supplement, there's all these little like, okay, was it done? In rodents? Was it done in humans? Is this the amount that they actually use in the study or do I have to take 10 times more? So what, what is the actual research and relevance of the research for? I realize this is kind of like a potentially rabbit-holey question, but like for different conditions.\n\nMeagan Lindquist [00:17:29]: Yeah, I would love to dive into the research. There's over 100 different studies that have been published, probably even more at this point. And then over 30 human clinical trials for all different things from cancer to liver disease to autoimmune to HPV to medication resistant epilepsy. Like a whole slew of things. So when we talk about research I usually try to pull out the most relevant and the studies that are, you know, that are going to resonate most for people like pretty much all of us have either been directly or indirectly affected by cancer. And that's one of, that's really where AHCC shined initially. Again, NK cell activation...\n\nBen Greenfield [00:18:27]: Prevention? or if somebody has cancer?\n\nMeagan Lindquist [00:18:27]: Somebody has cancer using this alongside whatever treatment they're using, whether that's chemo or. There also have been studies where people are using this alone to shrink their tumor. So one of the. Absolutely. Jaw dropping studies that's in this book.\n\nBen Greenfield [00:18:31]: Did you write this?\n\nMeagan Lindquist [00:18:32]: No, I didn't. This is Fred Pescatore.\n\nBen Greenfield [00:18:35]: That's not your pen name, Fred.\n\nMeagan Lindquist [00:18:36]: Possibly an AHCC book coming for me in the future we'll see how that goes.\n\nBen Greenfield [00:18:39]: A unique compound from Japanese medicinal mushrooms being used for prevention and complementary treatment of infections, liver disease, cancer and other conditions. Kind of looks like it was written in the 80s.\n\nMeagan Lindquist [00:18:48]: Yeah, it's small but potent. So one of the studies in there was an in hospital study published in this book and it was a group of Doctors led by Dr. Katsuaki Uno at Comfort Hospital in Japan.\n\nBen Greenfield [00:19:02]: I don't know how you remember that. Roll off your tongue.\n\nMeagan Lindquist [00:19:05]: Yeah, this was about 1998 to 2000 and this is incredible. So they had 195 stage 4 cancer patients that had very poor prognosis. So their cancer tumors ranged from ovarian to breast to prostate to liver, all over the place. This was a widespread of cancerous tumors and these people have like I said, no good options as it comes to conventional treatment. They gave these 195 participants about 6 grams of AHCC per day for six months. And they were measuring cancer, the tumor size, the tumor mass and also NK cell activation and some other anti-cancer cytokines, these chemical messengers that start to tell the body to break this tumor down. They were measuring all of this. And so okay, six grams of AHCC for six months to 195 stage four cancer patients.\n\nMeagan Lindquist [00:20:07]: The results were absolutely astounding. So out of 195, 114 people had a 50% or more reduction in the size of their tumor in four weeks or less.\n\nBen Greenfield [00:20:22]: And the only thing they changed was introducing AHCC.\n\nMeagan Lindquist [00:20:26]: They said AHCC and other immune system immune stimulants, so other health foods.\n\nBen Greenfield [00:20:30]: Okay.\n\nMeagan Lindquist [00:20:31]: And this is after they've already been given the prognosis of like, surgery's not an option or chemo didn't work for you. So this is like their last effort. So 50%, more than 50%. So 114 out of 195 people, that's like 60% or something, they had a 50% or more reduction in their cancer, in their tumor mass in four weeks or less. Seventeen of those patients, their tumor disappeared in four weeks or less.\n\nBen Greenfield [00:21:00]: Wow.\n\nMeagan Lindquist [00:21:00]: And again, it comes back to this NK cell activation. Right. Because these are the signs people will.\n\nBen Greenfield [00:21:06]: Go to Mexico and get NK cell infusions. And what you're saying is like this what you call the alpha glucan that's triggering your body's own production or something?\n\nMeagan Lindquist [00:21:18]: Yeah, it's kind of a slew of mechanism of action. It's not just one, one thing, but this is just one study that's showing like there's like real potential and sometimes even more potential, the sicker the person is. Because the sicker the person is, the more activation and the more response AHCC gives to that person. It's not just going in. Like for you, if you started taking AHCC, you probably don't have any systemic issues. I don't have any systemic issues. It's just going to keep us maintained. It's just gonna keep us, you know, maintained.\n\nMeagan Lindquist [00:21:51]: For someone who's battling a cancerous tumor, they need a lot of activation. And AHCC in all of its intelligence is able to somehow, which we don't even fully understand how exactly we can measure, like, okay, this cell is signaling this, and these two cells are communicating, and this is activated over here. But like, the how is kind of still a mystery.\n\nBen Greenfield [00:22:12]: Have they ever looked at just like, like how often you get sick versus you don't get sick if you're taking it just like a healthy person who doesn't want to get sick. That's what I'm super interested in.\n\nMeagan Lindquist [00:22:23]: This is the number one piece of feedback that we get from our customers and users. And I take it every day, have for six years, and I haven't been sick in Two and a half.\n\nBen Greenfield [00:22:31]: How much do you take?\n\nMeagan Lindquist [00:22:32]: I haven't been sick in two and a half years. I take two capsules a day.\n\nBen Greenfield [00:22:34]: Okay.\n\nMeagan Lindquist [00:22:35]: If I. So this is about, excuse me, 1.5 grams, which would be two of our capsules per day.\n\nBen Greenfield [00:22:42]: Empty stomach with food, does that work?\n\nMeagan Lindquist [00:22:43]: Empty stomach is fine. With food. Is fine. Because it's a health food. There's not really strict recommendations on exactly when you need to take it. I usually tell people like right before a meal, right before breakfast, right before dinner. But really, anytime is fine. They've studied that too in different studies and they really find that it doesn't matter a whole lot as long as it's getting in your body.\n\nBen Greenfield [00:23:06]: So.\n\nMeagan Lindquist [00:23:07]: So that is the number one piece of feedback that we hear from people. Teachers love it. They're exposed to little snotty kids all day, every day. And they really love it for protecting their immune system, optimizing these very specific important cells within both branches of the immune system. That's another way that this is very unique is that it's not just supporting one thing. It's not just supporting one branch of the immune system. It's supporting.\n\nBen Greenfield [00:23:31]: You mean like the waste it called the innate and adaptive.\n\nMeagan Lindquist [00:23:35]: Yes, exactly. Innate and adaptive. And they have these different cells within each branch. And NK cells are part of the innate immune system, the branch. But things like T cells and B cells that are really important for long term immunity your body, you know, being able to formulate an antibody to an antigen to a pathogen. Right. It's the T cell and B cell, active innovation. But on the innate side, we have the NK cells that are.\n\nMeagan Lindquist [00:24:02]: We've already talked about. We also have dendritic cells that are.\n\nBen Greenfield [00:24:06]: Really the immediate response, the adaptive. It's kind of like how you build a memory and fight something off in the future.\n\nMeagan Lindquist [00:24:11]: So AHCC really supports both branches and they see an activation and amplification of the intelligence of both branches of the immune system. That's why I think it's so powerful for people who are healthy that just want to stay healthy.\n\nBen Greenfield [00:24:25]: So you said HPV like three times already. That's human papilloma virus. I don't know that much about it, but. But is it a really big issue for people?\n\nMeagan Lindquist [00:24:37]: Yeah. Oh, it's a huge issue. Mostly for women because we are the ones that get Pap smears. There's no equivalent of men getting.\n\nBen Greenfield [00:24:43]: Oh, is that what the part of Pap smear stands for? Papilloma?\n\nMeagan Lindquist [00:24:47]: No, it's a. It's a person's Last name, it's Papillomao or something like that, but you would think it was that.\n\nBen Greenfield [00:24:53]: Some Greek, some Greek dude. Papalophus.\n\nMeagan Lindquist [00:24:55]: Yeah, it's something like that, but. But no. HPV stands for human papillomavirus. It is the virus that is said to, you know, there's different strains, but can lead to cervical cancer for women. If you have a high risk strain of HPV, there's low risk strains that cause genital warts. They're not very fun or cute, but like, you're not gonna die from it, right? And so there are these other high risk strains that can be dangerous. And I know right now there's someone listening, there's a woman listening that just got diagnosed recently, or maybe she's been dealing with it for years and feels pretty desperate. So I hope she hears this part of the podcast because AHCC has been shown to be a very non invasive, low hanging fruit to support the body in dealing with HPV the way that it should.\n\nMeagan Lindquist [00:25:47]: So one study that is, I think was published in 2022 in Frontiers in Oncology, was a phase 2 clinical trial, double blind, placebo controlled. They had 50 participants with high risk persistent HPV. This means high risk meaning it can lead to cancer. Persistent, meaning they haven't been able to clear it for over two years. Their body's having a hard time. For whatever reason, they split these two into treatment and placebo. And the treatment group received three grams a day of AHCC for six months. And again, the results were astounding.\n\nBen Greenfield [00:26:25]: Three grams? Oh, one. So two. So it'd be like four capsules?\n\nMeagan Lindquist [00:26:30]: Yeah, four capsules. You can split it up morning and evening. So what they saw was a clearance of 63.6% of the women were testing negative at 6 months or less after that, 6. Since all the women in the treatment group handled it very well, there were no adverse reactions. They unblinded the study and then they offered it to the placebo group. And 50%, another 50% of those women were able to clear in six months of AHCC use. So, like, this is a huge, huge thing for women. It affects men too.\n\nMeagan Lindquist [00:27:06]: But like, again, most guys have no idea that they are spreading HPV. And it's kind of a burden that sits on the woman's shoulders, unfortunately. And we're really not given a lot of good options, meaning zero good, non invasive options. It's usually like, all right, get the vaccine or we're going to cut away part of your cervix or we're going to do more biopsies. Doctors, I have so much respect for many of them, but they're not taught how to counsel a woman on like how to support your immune system. Them, they usually say something like, just be healthy and don't smoke, don't drink.\n\nBen Greenfield [00:27:44]: Yeah.\n\nMeagan Lindquist [00:27:44]: And that's not really that helpful.\n\nBen Greenfield [00:27:46]: Take some vitamin C.\n\nMeagan Lindquist [00:27:48]: Right, and so they're not really giving that great of advice, you know. But this is very, this is very close to my heart because I work with a lot of women who are navigating HPV. I actually work with Dr. Nathan Riley, who I think you've had on his, on your podcast.\n\nBen Greenfield [00:28:04]: He's like the holistic OBGYN. Who has been on the show before. I think he's been on the show.\n\nMeagan Lindquist [00:28:09]: Yeah, I listen to it. Yeah.\n\nBen Greenfield [00:28:11]: Okay.\n\nMeagan Lindquist [00:28:12]: And so we teamed up and we created this, this program for women who are trying to clear HPV. AHCC is a big cornerstone piece of that because it's so powerful. Like overnight you're supporting your immune system. But then we also look at the lifestyle factors like what are you eating, how much are you working out, like what are your relationships look like? So we go through, you go very deep. And it's a big help to women who are kind of on an island trying to figure this out.\n\nBen Greenfield [00:28:37]: Speaking of women, I'm assuming healthy for pregnancy. You're pregnant?\n\nMeagan Lindquist [00:28:40]: Yes. Yeah. So I take it every day. I would never tell a woman like what she puts in her body is up to her. It's really what you're comfortable with. I've been studying AHCC for many years. I'm very familiar with the safety profile there literally is. They've never been able to find a toxic dose, surprisingly so.\n\nMeagan Lindquist [00:29:01]: In the safety studies, they gave these poor little rats an equivalent of a 600 gram megadose. What would be equivalent to 600 gram of AHC? 600 gram. I take 1.5 every day.\n\nBen Greenfield [00:29:13]: Oh, 1.5 grams. Okay, that's awesome.\n\nMeagan Lindquist [00:29:15]: I take a gram and a half a day just for general health. They gave these little rats the equivalent of 600 grams. None of them died, none of them had any sort of horrible reaction. So they had to basically estimate the toxic dose. So all that to say it has an extremely high safety profile.\n\nBen Greenfield [00:29:33]: You talked about the liver and you said liver disease. Is that like non alcoholic fatty liver disease or something else?\n\nMeagan Lindquist [00:29:41]: Yeah, I think it could be. It's both. I mean, it's people that have, you know, what you just mentioned, but also, you know, people have been drinking for a while and their liver is not in tip top shape.\n\nBen Greenfield [00:29:51]: So, like, if I had elevated liver enzymes, is that something that you could try?\n\nMeagan Lindquist [00:29:56]: Yes, absolutely. We've received quite a few testimonials from people who have had different stages of liver disease. Or like, hey, my doctor says my liver enzymes are way off. AHCC is very supportive of the liver. Like I mentioned the Fred Pescatore book, the author, he was one of the first physicians in the United States to use AHCC. And he started with his hardest liver disease patients that he couldn't really get under control. He started giving AHCC. I've interviewed him on our podcast.\n\nBen Greenfield [00:30:28]: What's your podcast?\n\nMeagan Lindquist [00:30:29]: TheMedicin podcast.\n\nBen Greenfield [00:30:30]: Like medicine without an E?\n\nMeagan Lindquist [00:30:31]: Yes, like our brand. So all that to say, yes, it is very, very supportive of liver health. There was actually a study in 2002 in the journal of Hepatitis that looked at how basically how AHCC could support people with liver disease who had had surgery and basically preventing reoccurrence and death after surgery.\n\nBen Greenfield [00:30:55]: A decrease in the detoxification metabolic enzyme glutathione S transferase in the liver. So it would like, improve your ability to detox, basically.\n\nMeagan Lindquist [00:31:04]: Yes, absolutely.\n\nBen Greenfield [00:31:05]: He says infections on her. Are there other infections? Because, I mean, you said Lyme.\n\nMeagan Lindquist [00:31:09]: Yes. Yeah. So we see it with things like just simple cold and flu. You know, the infections that everyone gets. HPV obviously is considered an sti. It's a sexually transmitted infection. You know, oh, Lyme. Like I mentioned, really, really cool data coming out around Lyme.\n\nMeagan Lindquist [00:31:28]: People who struggle with Lyme basically have like, you know, the flu year round is what it feels like. You're just like, you know, it's miserable. And so there was a pilot study, so it was small, but they had 12 participants ranging from 20 years old to 80 years old with stage one to stage three Lyme disease. They gave three grams of AHCC for eight weeks to all of the participants. Three grams, that's like four capsules. Four capsules for eight weeks. And they were measuring things like joint pain, eye health card, cardiovascular health, fatigue, just quality of life in general. And they had a hundred percent of the participants.\n\nMeagan Lindquist [00:32:08]: So every participant was helped in some way, whether partially, yeah, I feel a lot better or completely like, I feel normal.\n\nBen Greenfield [00:32:15]: Yeah.\n\nMeagan Lindquist [00:32:16]: So we see just incredible results ranging again from so many different diseases and conditions. And it's, I think it comes down to, you know, I'm still learning about this all the time. I would never complain myself an expert, because I'm constantly learning and understanding deeper about how this works in the body.\n\nBen Greenfield [00:32:33]: Yet you're the only person I know of who went to the Japanese event, congress thing.\n\nMeagan Lindquist [00:32:39]: But it has various mechanisms of action. We mentioned that a few minutes ago. There's really like four that I like to talk about. That really puts it into perspective of like, oh, I see how these puzzle pieces are coming together. Because when I talk about it, there's someone listening right now. That's doubtful. That's like, this sounds like a freaking miracle. Like one size fits all miracle, whatever.\n\nMeagan Lindquist [00:32:59]: I totally get that. But when you look at the mechanism of action that they're able to prove within the research, one is the immune modulation, which is helping both branches of the immune system have more, you know, amplifying your innate intelligence, basically. And it's, it's both boosting and able to suppress and at the same time. So like if a person, if a woman has an autoimmune condition condition, but then gets diagnosed with hpv, does she need her immune system to calm down or does she need it to be boosted? And AHCC has the ability to do both at the same time via these different cells that do different things within the body. So it doesn't just activate haphazardly. It's not just arbitrarily raising your NK cells. If you don't need it, it's able to like.\n\nBen Greenfield [00:33:41]: It's like an adaptogen.\n\nMeagan Lindquist [00:33:42]: Exactly.\n\nBen Greenfield [00:33:42]: Yeah. Which a lot of mushrooms are.\n\nMeagan Lindquist [00:33:44]: Yes. But this is amplified again because of the bioavailability and the potency of those small alpha glucans. That's unique to AHCC because of the culturing process. So we have the immune modulation. It's also a very powerful antioxidant. So both direct and indirect.\n\nBen Greenfield [00:34:01]: Probably because of that liver glutathione thing.\n\nMeagan Lindquist [00:34:03]: Yes. So direct meaning, like this is why it's so helpful for people going through chemotherapy. Because chemotherapy is a very powerful oxidant. It's kind of taking out everything in its path. AHCC is able to offset that because it's acting as an antioxidant. So it's decreasing the negative side effects of chemotherapy while...\n\nBen Greenfield [00:34:23]: It's not like blocking The cytotoxicity of it.\n\nMeagan Lindquist [00:34:26]: No, it's increasing the anti cancer effects and decreasing the negative side effects like liver damage, hair loss, digestive issues, things like that.\n\nBen Greenfield [00:34:36]: Good luck convincing your doctor. Like I know some, so many people whose doctors have them on chemo and they're just like, no, don't take anything because they just, they play it super safe.\n\nMeagan Lindquist [00:34:44]: Yeah.\n\nBen Greenfield [00:34:44]: But especially antioxidants like don't take any antioxidants because we're actually trying to oxidize.\n\nMeagan Lindquist [00:34:49]: Yeah, I get that. I would. If there's someone listening right now who's, you know, moving through this, navigating, you know, treatment for cancer or your dad or your mom or whoever, like, talk to your doctor, print out some of the studies, the many studies that have been done on cancer and chemotherapy, and physically hand them to your doctor. Because, like, there's one study here, it talks about the improved quality of life with chemo and AHCC. So this was the International Journal of clinical medicine in 2011, and they had 25 patients with advanced stages of head and neck cancer. And the aim of the study was to see how AHCC paired with chemo. Was it safe? Did it amplify things? What's the reaction here? So 25 patients received 3 grams a day of AHCC before, during and after treatment of chemotherapy. And what they saw was all of the patients tolerated AHCC well, with no new side effects.\n\nMeagan Lindquist [00:35:46]: 20 of the 25 patients reported better, significantly improved quality of life, six hours a day average, on average, less in bed. So they're able to be about, you know, enjoy life more, which is huge. Almost every single patient reported higher levels of appetite, which is really important.\n\nBen Greenfield [00:36:08]: Staving off like cancer, cachexia, muscle loss.\n\nMeagan Lindquist [00:36:10]: Yeah, you just lose everything. And so 16 of the 25 patients actually needed a blood transfusion before using AHCC and only three of them needed a blood transfusion after using AHCC. 22 of the 25 patients reported definite reduction in the chemotherapy side effects like digestive issues, hair loss and nausea, vomiting, all these things. And so they actually shortened their stay in the hospital because they just felt better.\n\nBen Greenfield [00:36:41]: Yeah.\n\nMeagan Lindquist [00:36:42]: So from that, these researchers concluded that like AHCC seems to be totally stuck. Safe to take. Obviously. I still have to say, talk to your doctor, I'm not a medical professional, but like, it's in your best interest to at least look into this and see if it could be a possibility.\n\nBen Greenfield [00:36:58]: Yeah. Okay, so you've got the double whammy and the immune system, you've got the detox. What are the other two?\n\nMeagan Lindquist [00:37:03]: Yeah, thank you for bringing me back to that. Yeah. So the. It has a really powerful anti inflammatory effect in the body as well. So when you look at CRP, C reactive protein in the body, which is. I know you know this, but the blood marker that your doctor might look at if he wants to see, like how inflamed is this person, we see it, we see high levels of CRP with active infections and things like cardiovascular disease. So if, you know, if we see CRP going down, generally that means your systemic inflammation is going down. And what they see is that AHCC is able to lower CRP in the body, therefore reducing systemic inflammation.\n\nMeagan Lindquist [00:37:41]: So it's really, really helpful for.\n\nBen Greenfield [00:37:42]: Related to the antioxidant effect.\n\nMeagan Lindquist [00:37:44]: Yeah, yeah, I think it's all synergistic together so it's really helpful for people with arthritis. My sister has rheumatoid arthritis and it's the only non pharmaceutical that has ever worked for her.\n\nBen Greenfield [00:37:54]: I wonder if it'd work for like a non autoimmune form of arthritis, just like osteoarthritis, beat up joints.\n\nMeagan Lindquist [00:38:00]: I mean, I don't make claims that, oh, every single person you're going to have this exact outcome with AHCC because everyone's so different as far as your own individuality. But we've received many, many, oh my gosh, my joints feel so much better, you know, less inflamed, you know, all over the board. Not just arthritis, but just in general the inflammation that can, that can happen with so many different diseases and conditions. And so the last MOA, the last mechanism of action is the healthier response, response to stress. So when we get stressed, our immune system tanks, our NK cells tank, which is a real problem. Yeah, you can get through a really stressful time and then usually like you.\n\nBen Greenfield [00:38:43]: Get sick because it's weird. It's like acute stress could technically like if you're doing like a quick cold bath every day or like a sauna, like makes the immune system stronger. But then if you're just like fighting the lion in your email inbox for eight hours a day. Yeah, you're going through, you know, something diverts resources.\n\nMeagan Lindquist [00:38:58]: Yeah, exactly. So it's not functioning properly. And we see this really intimately with HPV and stress. Usually women get diagnosed. From my experience working with women after having a really stressful year, like, oh, I got divorced or we moved or my husband lost his job or I'm starting a new business or I'm planning a wedding. All of these things are very high stress and can be chronic. And so basically what AHCC is able to do is regulate your response to stress. So they actually see, you know, when you get stressed, your blood sugar can rise, you have a rise in adrenaline, which can be good sometimes but not chronically.\n\nMeagan Lindquist [00:39:39]: And then also the immune function, immune dysfunction is what we see. So AHCC is able to, if you could like take it, alter that, track.\n\nBen Greenfield [00:39:46]: Your HRV and just kind of. Because HRV is kind of like without Getting a blood test or a salivary test. Just a little bit of a proxy.\n\nMeagan Lindquist [00:39:53]: I'd be curious. You know, I know you have all the gadgets.\n\nBen Greenfield [00:39:56]: You sent me a bottle and I took it for a little but I didn't really know much about it. I was just kind of messing around with it and didn't measure that much. Now that I'm learning more. So how long does it take to kick in? Like it like I'm flying to London. Was it Monday on Wednesday. Right. If I took AHCC for the next couple of of days, would I already get some shields activated?\n\nMeagan Lindquist [00:40:16]: Yes, absolutely. It's basically overnight your immune system starts to activate in a more intelligent way. So take this bottle. Take four capsules a day. So what I recommend for people generally, and this isn't my recommendation, this is based off the research. So for general health, two capsules a day is great. That's what I take from day to day basis. Haven't been sick in two and a half years.\n\nMeagan Lindquist [00:40:40]: But when I travel, especially internationally.\n\nBen Greenfield [00:40:42]: Like morning sickness from being pregnant? Or is that different?\n\nMeagan Lindquist [00:40:46]: It hasn't blocked that unfortunately. But when I travel or if I'm around someone who's sick, even just in the same room or like whatever, or if I start to feel, you know that feeling when you're like, I think my body's kind of starting to fight something a little bit, I will amp it up big time.\n\nBen Greenfield [00:41:03]: Okay.\n\nMeagan Lindquist [00:41:03]: So for you could even take up to, you know, eight capsules. When my husband and I had Covid in 2021 or whatever it was, we were taking eight to 10 capsules a day and our body handled it like a cold. It was not a big deal for us, but we were also taking it before that too.\n\nBen Greenfield [00:41:21]: You think if you combine it with this that you get better effects. I mean I'm assuming you haven't done research to see what happens.\n\nMeagan Lindquist [00:41:28]: No, I haven't done a combined know mushroom product study here, but I do use Mushy Love every day. It does have 500 milligrams of chaga in every scoop which is a hefty dose.\n\nBen Greenfield [00:41:41]: Yeah. So hold this up to the camera. Cinnamon swirl latte.\n\nMeagan Lindquist [00:41:45]: Yeah, it's a super delicious.\n\nBen Greenfield [00:41:46]: You sent me a bag of this too. It was good. I like put it made my coffee taste like a cinnamon roll.\n\nMeagan Lindquist [00:41:50]: Yeah, it's very, very good. It's very versatile. You can have it on its own.\n\nBen Greenfield [00:41:54]: Bread or anything out of it.\n\nMeagan Lindquist [00:41:55]: Oh yeah. You can add it to muffins, you can add it to pancakes. So AHCC was our flagship product. This was our hero product. And then we made mushy love because we were kind of disappointed with other mushroom supplements out there. Mushroom drinks, mushroom elixirs. Because they're either not organic, they're not using high quality mushrooms, or they're using, they're using.\n\nBen Greenfield [00:42:16]: Everything on here says organic.\n\nMeagan Lindquist [00:42:18]: Yeah, they're using mostly the myceliated grain. There's a lot of grain.\n\nBen Greenfield [00:42:24]: Yeah, I've heard that. Like what you grow the mushroom on. Yeah, yeah.\n\nMeagan Lindquist [00:42:27]: So different than AHCC, which is a mycelial product, but it's not grown on a grain mass. It's cultured in a liquid tank and they're able to extract it. So it's pure. It's not my ciliated grain. It's completely different.\n\nBen Greenfield [00:42:40]: I'm reading your story on the back here. This is a total rabbit hole. But so Chase, she's actually here. He's in the other room. He's your husband, right?\n\nMeagan Lindquist [00:42:47]: Yes. Yeah, yeah.\n\nBen Greenfield [00:42:47]: Childhood sweethearts. You married very young, but then you divorced and never thought you would see each other again and then you just like hooked up again.\n\nMeagan Lindquist [00:42:54]: Yeah, yeah. Mushrooms literally like connected us together. Yes. Oh, absolutely. I would not be here without Chase. He's, I'm, you know, sort of the talking head on podcasts and we, we have a podcast together, but he is all things finance business. You know, he. He's my rock and I, I would definitely not be here talking to you if it wasn't for him.\n\nBen Greenfield [00:43:17]: Yeah. Incredible. Besides this, do you know of anything? Because a lot of my listeners like to stack stuff, you know, hack stuff that you can take this with to either like increase the absorption or that you could take to increase the efficacy.\n\nMeagan Lindquist [00:43:32]: Or anything like that kind of some synergistic effects.\n\nBen Greenfield [00:43:35]: Yeah, synergistic.\n\nMeagan Lindquist [00:43:36]: The absorption is already top notch. Like we talked about with the alpha glucans. You don't really have to worry about the absorption. I suppose you. You could take it on an empty stomach to increase that just a little bit more. But yeah, so with, we see really good effects with vitamin C. Obviously, the antioxidant and immune boosting effects of vitamin C are really great. Other mushrooms, which we've talked about, high quality mushrooms, not just any mushroom supplement that you get on Amazon for nine bucks.\n\nMeagan Lindquist [00:44:05]: Like I'm talking about like organic, high quality tested, third party tested, you know, high quality mushrooms. Yeah, you can't really take too many.\n\nBen Greenfield [00:44:13]: Medicinal mushrooms because I Google or I didn't google, I think Amazon, the AHCC, and there's, there is some, I Don't want you like have to throw people under the bus. But like does. Do they all. If they all come from the same place, does it matter?\n\nMeagan Lindquist [00:44:26]: Yes. So this is very, very important. Do you want me to answer the first question first and then come back to this?\n\nBen Greenfield [00:44:31]: Yeah, finish and then come back.\n\nMeagan Lindquist [00:44:32]: I'll come back to that because it's very important. So for the other center, just probably a lot of your audience is already taking glutathione or nac and it really synergizes well because of the liver benefits. And then the other one would be ETAs, which I don't know if you've heard of ETAs, but it's an asparagus extract that amplifies the heat shock protein response.\n\nMeagan Lindquist [00:44:54]: No, it's different. It's different. It's its own thing. But it's most beneficial result is the heat shock protein activation, which synergizes very. And they have done a study with ETAs and AHCC showing cellular resilience and lack of fatigue after, you know, hard workouts, things like that.\n\nBen Greenfield [00:45:15]: Remember doing a sauna for heat shock proteins that might help out more.\n\nMeagan Lindquist [00:45:18]: Yeah.\n\nBen Greenfield [00:45:18]: And the glutathione makes sense because that little clip I read in there said it like keeps the. What was it? The glutathione transferase and like the enzyme that breaks down glutathione from degrading. So you took glutathione and stay in your body for a longer period of time if you were taking that?\n\nMeagan Lindquist [00:45:33]: Yeah, I mean, I haven't, I haven't seen specific studies showing that. But like, just using your logic. Yeah, it seems like that would make sense. Okay, back to authentic AHCC. This is very important. So when we're talking about the quality of AHCC, it really shouldn't differ because again, it's patented from one source in Japan. But. But it unfortunately does because you know this.\n\nMeagan Lindquist [00:45:57]: There's so many fake and phony brands on Amazon out there in the world. AHCC is a very expensive product to manufacture. It's very expensive for us to even hold in our warehouse. Like, you know, kind of a side note, but Chase is my like business mind CFO at Organifi. He knows numbers in and out. When I brought this to him and I was like, I want to, I want to have this supplement. I can do this. You know, I want to talk about this.\n\nMeagan Lindquist [00:46:24]: I want to have our immune intel AHCC. He was like looking at the cogs and the numbers because it's so expensive to manufacture. He was like, this is Going to be really challenging. But we made it work and my passion kind of shined through I guess and pulled us forward. But all that to say it's not really that smart of a business decision for a bunch of brands to just start carrying AHCC because of the cost. You know, people are trying to make the most profit possible.\n\nBen Greenfield [00:46:51]: You mean it'd be kind of like sort of like a luxury car company.\n\nMeagan Lindquist [00:46:53]: Yeah, exactly. It's expensive. And so what they, what they do is they slap a, you know, random label on a bottle. They might use a tiny sprinkle of AHCC that's not going to do anything in your body. Like 50 milligrams. That's not going to do anything. Or they don't even use authentic AHCC. What they're doing is, you know, slapping a label on and calling it AHCC or calling it active hexose correlated compound.\n\nBen Greenfield [00:47:19]: Back to that thing. Yeah, they could just.\n\nMeagan Lindquist [00:47:20]: So they put that on there and they might, you can, you can create just active hexose correlated compound, but it's not the same as the full spectrum of AHCC, all of the components. So this is why we have a certification seal on our bottle.\n\nBen Greenfield [00:47:36]: Amazon is so sketch. Like, like the one thing I pay attention to, I'm gonna order someone on Amazon is, is it from that company's actual like official store?\n\nMeagan Lindquist [00:47:43]: Yeah.\n\nBen Greenfield [00:47:44]: And if you don't like, it might not even be that company's product.\n\nMeagan Lindquist [00:47:46]: Well now Amazon, I don't know if you've seen, but even if they do have the, the store that sells on Amazon and these other people that sell on Amazon, they put them into one bin together so they're grabbing and they don't know what they're grabbing, whether it's legit or not. So you know, our AHCC is the highest quality you can get. It's 750 milligrams per capsule. There's nothing else in, in there, it's just AHCC. So we're not cutting any corners. 750 milligrams is the max that you can put in one of those capsules.\n\nBen Greenfield [00:48:14]: One and a half milligrams is a dose of two capsules.\n\nMeagan Lindquist [00:48:16]: So you're having less capsules so it's a better value. So yeah, it's very important. I'm glad you asked about that because it's something that the manufacturers are dealing with on a constant basis trying to peel back these inauthentic AHCC.\n\nBen Greenfield [00:48:33]: Yeah, well, hopefully after hearing this a lot of people are gonna wanna try it. Like I don't think I could listen to this podcast and not want to try it.\n\nMeagan Lindquist [00:48:41]: I mean, even if you're healthy!\n\nBen Greenfield [00:48:42]: There's A good case for it.\n\nMeagan Lindquist [00:48:43]: Yeah, even if you're healthy, you just wanna stay that way.\n\nBen Greenfield [00:48:45]: So if people want to look at the actual research for themselves, do you have it published on your website or should they buy Fred's like 30 year old book?\n\nMeagan Lindquist [00:48:57]: Yeah, this book is actually. I know it looks kind of janky. It is amazing. It's awesome. Like, I might just leave it. I might just leave it.\n\nBen Greenfield [00:49:05]: Break through in immune therapy sections. Underlined.\n\nMeagan Lindquist [00:49:08]: Yeah. Oh, yeah, I've. This is. I call it my AHCC bible. You know, it is. It is. I've read it through probably 10 times. But yeah, you can grab this book.\n\nMeagan Lindquist [00:49:17]: It's like $12. It's like $12 on Amazon. But yeah, we do have some of the research. I've written a bunch of blog posts about AHCC. You know, if you're interested in AHCC for HPV, we also have our clear and free program that helps women, you know, really get to the bottom of. Like, why is your body having a hard time clearing hpv? There's a reason why your stress buckets are overflowing for some reason. Let's get to the bottom of that. So we, we.\n\nMeagan Lindquist [00:49:44]: That's our clear and free program at clearhpv.com but yeah, we have a lot of the studies on our. On our website, TheMedicine.com you can also check out the AHCC Research Organization, which is AHCC.net okay, and then I'm going.\n\nBen Greenfield [00:49:59]: To put links to all this stuff. And then yesterday I got an email that you guys made us like a discount code and everything. knock a few bucks off. So it's the show. Notes are BenGreenfieldLife.com/AHCCpodcast and I'll put all this stuff in there. So you just have one source so... BenGreenForLife.com/AHCCpodcast.\n\nBen Greenfield [00:50:21]: Meagan, this is incredible. I love finding new, new stuff.\n\nMeagan Lindquist [00:50:24]: Thanks for having me.\n\nBen Greenfield [00:50:24]: I haven't heard of before.\n\nMeagan Lindquist [00:50:25]: Yeah, I love it. It was an absolute pleasure.\n\nBen Greenfield [00:50:27]: And oh, and if you get AHCC, try the mushy love too. It's not AHCC, but it tastes.\n\nMeagan Lindquist [00:50:32]: It is really delicious.\n\nBen Greenfield [00:50:33]: We'll reinvent your morning with a liquid cinnamon roll like it says on there.\n\nMeagan Lindquist [00:50:36]: Yep.\n\nBen Greenfield [00:50:37]: Yeah, you had me at liquid cinnamon roll. All right. Thanks, Meagan.\n\nMeagan Lindquist [00:50:40]: Thank you.\n\nBen Greenfield [00:50:41]: To discover even more tips, tricks, hacks and content to become the most complete, boundless version of you, visit BenGreenfieldLife.com in compliance with the FTC guidelines, please assume the following about links and posts on this site. Most of the links going to products are often affiliate links, of which I receive a small commission from sales of certain items. But the price is the same for you, and sometimes I even get to share a unique and somewhat significant discount with you. In some cases, I might also be an investor in a company I mentioned. I'm the founder, for example, of Kion llc, the makers of Kion branded supplements and products, which I talk about quite a bit. Regardless of the relationship, if I post or talk about an affiliate link to a product, it is indeed something I personally use, support and with full authenticity and transparency recommend. In good conscience, I personally vet each and every product that I talk about. My first priority is providing valuable information and resources to you that help you positively optimize your mind, body and spirit.\n\nBen Greenfield [00:51:50]: And I'll only ever link to products or resources, affiliate or otherwise, that fit within this purpose. So there's your fancy legal disclaimer.",
      "source": "Bengreenfieldlife.com",
      "url": "https://bengreenfieldlife.com/podcast/ahccpodcast/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Sidus Space, Inc. (NASDAQ:SIDU) Sees Significant Growth in Short Interest",
      "content": "Sidus Space, Inc. (NASDAQ:SIDU – Get Free Report) was the recipient of a large increase in short interest in September. As of September 15th, there was short interest totaling 4,350,000 shares, an increase of 306.5% from the August 31st total of 1,070,000 shares. Based on an average daily volume of 1,710,000 shares, the days-to-cover ratio is currently 2.5 days. Currently, 12.4% of the company’s stock are sold short. Currently, 12.4% of the company’s stock are sold short. Based on an average daily volume of 1,710,000 shares, the days-to-cover ratio is currently 2.5 days.\n\nSidus Space Stock Performance\n\nSIDU stock opened at $1.10 on Friday. The stock has a market capitalization of $28.00 million, a price-to-earnings ratio of -0.56 and a beta of -1.35. Sidus Space has a 1 year low of $0.93 and a 1 year high of $7.65. The stock’s fifty day moving average is $1.15 and its two-hundred day moving average is $1.44.\n\nGet Sidus Space alerts:\n\nSidus Space (NASDAQ:SIDU – Get Free Report) last posted its earnings results on Thursday, August 14th. The company reported ($0.31) earnings per share (EPS) for the quarter. The company had revenue of $1.26 million during the quarter. Sidus Space had a negative net margin of 515.33% and a negative return on equity of 129.29%.\n\nAnalyst Upgrades and Downgrades\n\nA number of brokerages have weighed in on SIDU. Wall Street Zen upgraded Sidus Space from a “sell” rating to a “hold” rating in a research note on Friday. Weiss Ratings reiterated a “sell (e+)” rating on shares of Sidus Space in a research report on Saturday, September 27th. One research analyst has rated the stock with a Sell rating, Based on data from MarketBeat, the company has an average rating of “Sell”.\n\nView Our Latest Stock Analysis on Sidus Space\n\nInstitutional Investors Weigh In On Sidus Space\n\nHedge funds have recently added to or reduced their stakes in the stock. Millennium Management LLC bought a new stake in Sidus Space in the fourth quarter valued at $89,000. Northern Trust Corp bought a new stake in Sidus Space during the 4th quarter valued at $111,000. Jane Street Group LLC acquired a new position in Sidus Space during the 4th quarter worth $118,000. Essex Investment Management Co. LLC acquired a new position in Sidus Space during the 1st quarter worth $45,000. Finally, FNY Investment Advisers LLC acquired a new position in Sidus Space during the 1st quarter worth $107,000. 17.91% of the stock is currently owned by institutional investors.\n\nAbout Sidus Space\n\n(Get Free Report)\n\nSidus Space, Inc, a space-as-a-service company, engages in the design, manufacture, launch, and data collection of commercial satellite worldwide. Its space services include satellite/space hardware manufacturing; Low Earth Orbit (LEO) launch and deployment services; and space-based geospatial intel, imagery, and data analytics.\n\nFeatured Articles\n\nReceive News & Ratings for Sidus Space Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Sidus Space and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/10/04/sidus-space-inc-nasdaqsidu-sees-significant-growth-in-short-interest/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "I reviewed the ZBook Ultra G1a 14 - and somehow HP forced a mobile workstation into an ultrabook chassis",
      "content": "A great demonstration of what Ryzen AI 395 Max+ machines can offer. Remarkably powerful, yet it can still last a long working day on a single battery charge. Makes Intel Core Ultra 200 machines look like they’re running on economy gasoline.\n\nWhy you can trust TechRadar We spend hours testing every product or service we review, so you can be sure you're buying the best. Find out more about how we test.\n\nHP ZBook Ultra G1a 14: 30-second review\n\nExternally, this machine bears an uncanny resemblance to HP’s EliteBook X G1a, and while there are differences on the underside, the whole top of this machine, including the screen, keyboard and ports, is identical.\n\nHowever, inside this machine is a radical departure, as it uses the AMD Ryzen AI 395 Max+ processor, a full-blown Strix Halo chip. Therefore, HP has given it the title of Mobile Workstation PC, and it fully justifies that moniker.\n\nTypically, mobile workstations require mains power and have a display larger than 14 inches, but this one does not need either of those things to deliver impressive results.\n\nOn the outside, it’s a gun-metal ultrabook, and on the inside, it’s a sixteen-core and thirty-two-thread monster that can blitz a vast array of intense computing challenges.\n\nNot that it can defy gravity entirely, since the 74.5Wh battery on this machine will only sustain it for around 13 hours at most when used constantly.\n\nIn addition to the powerful CPU, the Ryzen AI 395 Max also includes a new integrated GPU, the Radeon 8060s and an enhanced AI experience that combines the CPU and NPU for up to 126 TOPS of neural processing.\n\nTherefore, it can be used for video editing, AI local models, CAD work, whatever. In short, it's ready for most eventualities, and frankly, running Microsoft Office is beneath it.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nIf you are looking for a highly potent and portable solution, then the HP ZBook Ultra G1a 14 should be one to consider if you’re accounts department isn’t squeamish about the cost of cutting-edge technology. Probably one of the best mobile workstations - and certainly one of the best business laptops - you can get for those who can afford one.\n\nHP ZBook Ultra G1a 14: Price and availability\n\n(Image credit: Mark Pickavance)\n\nHow much does it cost? From $1890/£1500/€1,699\n\nFrom $1890/£1500/€1,699 When is it out? Available now\n\nAvailable now Where can you get it? Direct from HP or via Amazon\n\nAs you would probably expect, HP makes many different SKUs of the HP Zbook Ultra G1a, starting from those that have the Ryzen AI Max PRO 385 CPU and 8050S GPU.\n\nThese start at around $1889 in the UK, for a machine with 32GB of RAM and 512GB of storage. That doesn’t seem too crazy, but then that SKU doesn’t have a touch screen and only a WUXGA (1920 x 1200) IPS panel.\n\nThose wanting a machine like the review hardware, with the top processor, OLED touchscreen, and larger amounts of RAM and storage, need to buckle up.\n\nThe closest SKU I could find to the review hardware, which features the Ryzen AI Max+ PRO 395 processor, 64GB of RAM, 2TB of storage, and a 2.8K touch OLED display, is priced at $3,079.\n\nIn the UK, an entry-level HP Zbook Ultra G1a will cost you £1,499.99, and one with the review spec is £2,111.99 from HP. However, I was able to find the exact model (A3ZH3ET#ABU) from a laptop retailer for only £ 1,817.\n\nThe most expensive option is a model with the top processor, 128GB of RAM, and 2TB of storage, which could easily cost you over $3000, or more.\n\nMost models on offer are all pre-defined SKUs, but you can entirely customise the machine to have whatever you want. I would warn against doing this, since the prices for memory and storage upgrades are frankly outrageous.\n\nThe trouble with the technology in the Zbook is that it's so new that relatively few brands have products out that use it. Lenovo, for example, hasn’t got this platform in its ThinkPad range yet. Dell has nothing available with a Ryzen AI Max+ PRO 395 in it, and neither does Acer.\n\nAsus has the ROG Flow Z13, a gaming laptop, if you can find one. And, it's in a similar price range, if not even more expensive.\n\nWhere this silicon is more accessible is in a Mini PC from the likes of GMKtec, Beelink, Minisforum and others. But obviously, those aren’t laptops.\n\nThe brutal reality is that if you want one of these made to the standards of HP, then it's going to be expensive until other brands get their act together.\n\nBut the number of SKUs that are sold out suggests companies are willing to pay for this performance level.\n\nValue: 3 / 5\n\nHP ZBook Ultra G1a 14: Specs\n\nSwipe to scroll horizontally Category Item Processor AMD Ryzen AI Max+ PRO 395 (up to 5.1 GHz max boost clock, 64 MB L3 cache, 16 cores, 32 threads) NPU Performance 55 TOPS (Neural Processing Unit for local AI tasks) Total TOPS 126TOPS (NPU and CPU combined) Memory 64 GB LPDDR5x-8533 MT/s (soldered, non-upgradable) Storage 1TB PCIe Gen4 NVMe SSD Graphics AMD Radeon 8060s Graphics Display 14-inch diagonal 2.8K OLED touch display Camera 5 MP IR AI camera Audio Quad stereo speakers, dual microphones, Poly Studio tuning, AI noise reduction Ports Right 1x Thunderbolt 4 (USB-C), 1x USB-A, Security cable slot Ports Left 1x HDMI, 1x Thunderbolt 4 (USB-C), 1x USB-C (10Gbps charging), 1x headphone/mic combo Wireless MediaTek Wi-Fi 7 MT7925 (2x2) and Bluetooth 5.4 wireless card Battery HP XL-Long Life 4-cell, 74.5 Wh Li-ion polymer Operating System Windows 11 Pro Security HP Wolf Security, TPM 2.0, fingerprint sensor, auto lock/awake, onlook detector Size 31.22 x 21.46 x 0.92 cm (front); 31.22 x 21.46 x 1.31 cm (rear) Weight 1.49 kg Sustainability Up to 90% recycled magnesium, 50% recycled plastic in keycaps, recyclable packaging Warranty 3-year limited warranty with HP Wolf Pro Security Edition Colour Meteor Silver Aluminium or Eclipse Gray Aluminium\n\nHP ZBook Ultra G1a 14: Design\n\n(Image credit: Mark Pickavance)\n\nThin and elegant\n\nLots of USB and Thunderbolt\n\nStunning OLED screen\n\nAlmost no upgrades\n\nThis machine appears to borrow much of its chassis from the current EliteBook series, and if you put them together, they’re practically identical, including the port arrangement.\n\nThis is a compact design with an aluminium skin that feels solid and robust. As I’ve mentioned elsewhere, I’m not a massive fan of the way cursor keys are implemented on these HP keyboards, but the keys are at least large and well spaced.\n\nHP didn’t take the MacBook approach to this machine, and it has plenty of USB and Thunderbolt ports that avoid making a docking station a necessity. If you do go down that path, maybe to have more than two screens, it’s worth noting that the PSU that HP includes is rated for 140W, and only a few docks deliver that much power to their host system.\n\n(Image credit: Mark Pickavance)\n\nThe standout feature of this machine from the outside is undoubtedly the 2.8k OLED touch-enabled display, which has an excellent colour gamut and epic contrast levels. This is a significant upgrade over the IPS 1920 x 1080 resolution screen that HP is using on its cheaper machines, and creatives will love it.\n\nHowever, the caveat to that display is that it has a glass coating to protect it from oily fingers, and this is highly reflective when used outside or with strong sunlight coming through the windows.\n\nAccess to the interior is relatively easy, requiring only the loosening of four retained screws and the subtle use of a plastic spudger to spring a few latches. Given how easy it was, it follows that when a hardware maker doesn’t make entry a challenge, there are almost no options inside. You could replace the battery and swap the M.2 storage, but there is no second M.2 slot, and the memory is soldered to the mainboard. Therefore, from an upgrade perspective, this well is almost dry.\n\nIn this context, I have some sympathy for HP, because getting this platform into a chassis so compact didn’t allow space for any future proofing, regrettably. It borrows enough from the EliteBook machines to make replacement parts for the screen and keyboard easy enough to find, though any work fixing the motherboard could be challenging, considering how little room is left inside this chassis.\n\nIt looks like, and mostly is, an Ultrabook, but with workstation components under the skin.\n\nDesign: 4 / 5\n\nHP ZBook Ultra G1a 14: Hardware\n\nAMD Ryzen AI 395 Max+\n\nRadeon 8060s GPU\n\nAmazing bandwidth of LPDDR5x-8533\n\nThe AMD Ryzen AI Max+ 395 is a robust processor engineered to cater to the needs of contemporary computing, especially in the fields of AI, gaming, and professional tasks. Featuring 16 cores and 32 threads, it operates at a base clock speed of 3GHz, with the capability to turbo boost up to 5.1GHz.\n\nThis high core and thread count makes it particularly well-suited for multitasking, executing complex simulations, and managing extensive datasets. Furthermore, the Ryzen AI Max+ 395 goes beyond mere performance by incorporating advanced AI features, making it an excellent option for developers and researchers engaged in machine learning and AI initiatives.\n\nWhen comparing it to Intel’s leading offering, the Core Ultra 200 series, notable differences arise. While the Arrow Lake-H generation from Intel also possesses sixteen cores and threads, AMD’s sixteen Zen 5 cores can handle thirty-two threads concurrently. Intel’s design incorporates only six performance cores, while the majority serve efficiency purposes; in contrast, all of AMD’s cores are geared towards raw performance.\n\nThe trade-off here is battery life against performance, as the Arrow Lake-H chips will offer better longevity but can’t match the performance.\n\n(Image credit: Mark Pickavance)\n\nOne aspect where Intel is significantly outgunned is in graphics, as the new Radeon 8060s are at least twice as fast as their 890M predecessor, and much better than Intel’s ARC 140 series.\n\nSome of that performance boost comes from the increased number of shaders and clock speeds, but it also sees a significant improvement from the LPDDR5x-8533 memory on this system. With an ECC quad-channel configuration and a rated speed of 8000 MT/s, the quoted memory bandwidth is an incredible 256 GB/s.\n\nWith the 8060s GPU sharing main memory with the CPU, it achieves a bandwidth level that was previously only expected from the use of GDDR5 memory on discrete video cards a few years ago.\n\n(Image credit: Mark Pickavance)\n\nThese advantages extend to the AI component of this offering, with the NPU delivering 55 TOPS and the CPU contributing to a combined performance of 126 TOPS. While we might end up laughing at these numbers a few years down the line, right now, this is much more powerful than anything Intel has for mobile or even desktop use.\n\nFor comparison, a discrete video card such as the Nvidia RTX 4090 might exceed 1300 TOPS. However, that’s not a practical piece of hardware to put inside a laptop due to space, power demands, and heat generation. For an APU, the AMD Ryzen AI 395 Max+ is in a class of its own.\n\n(Image credit: Mark Pickavance)\n\nHardware: 5 / 5\n\nHP ZBook Ultra G1a 14: Performance\n\nSwipe to scroll horizontally Laptops Header Cell - Column 1 HP Zbook Ultra G1a 14 Dell Precision 7780 CPU Row 0 - Cell 1 AMD Ryzen AI 395 Max+ Intel Core i9-13950HX Cores/Threads Row 1 - Cell 1 16C 32T 24C 32T TPD Row 2 - Cell 1 45-120W(55W) 55W RAM Row 3 - Cell 1 64GB LPDDR5-8000 32GB DDR5 (2x16GB) SSD Row 4 - Cell 1 2TB Kingston OM8PGP42048N SK Hynix 801 1TB Graphics Row 5 - Cell 1 AMD Radeon 8060S Nvidia RTX 3500 NPU Row 6 - Cell 1 AMD Ryzen AI (50/126 TOPS) N/A 3DMark WildLife 49780 73,250 Row 8 - Cell 0 FireStrike 19558 27,832 Row 9 - Cell 0 TimeSpy 8506 13415 Row 10 - Cell 0 Steel Nomad Lite 7968 14125 CineBench24 Single 114 58 Row 12 - Cell 0 Multi 1244 876 Row 13 - Cell 0 Ratio 10.95 15.06 GeekBench 6 Single 2876 1770 Row 15 - Cell 0 Multi 16747 16704 Row 16 - Cell 0 OpenCL 78855 145921 Row 17 - Cell 0 Vulkan 74848 9680 CrystalDIsk Read MB/s 6683 7156 Row 19 - Cell 0 Write MB/s 4937 6439 PCMark 10 Office 7919 7803 Row 21 - Cell 0 Battery 10h 48m 7h 40m Battery Whr 74.5 93 Row 23 - Cell 0 PSU 140W 240W WEI Score 9.5 8.2\n\nI mulled over what machine I’d use to compare, since none of the recent Intel 200 series machines I’ve seen are classed as mobile workstations.\n\nIn the end, I went with the Dell Precision 7780, a heavy-duty mobile workstation that cost even more than the ZBook.\n\nAs you can see, considering that it's the cutting-edge of mobile hardware in the HP, it still can’t go faster than the Dell in the graphics tests.\n\nHowever, this isn’t a fair fight, as the AMD machine utilises an integrated GPU, while the Dell machine features an Nvidia RTX 3500 mobile discrete video card. The RTX 3500 Ada Generation is a professional mobile GPU featuring the 5nm Ada Lovelace architecture (AD104), with 5120 CUDA cores, 12 GB of GDDR6 memory on a 192-bit bus, and a 100W TDP.\n\nWith all those shaders and its own independent GDDR6 memory, it should win, and possibly by a bigger margin than these benches reveal.\n\nAs a computing platform, the 13th Generation Intel Core i9-13950HX performed poorly, and even with 24 cores, it struggled in both the CineBench 24 and GeekBench 6 tests.\n\nThe power consumption of the Intel Core i9-13950HX and RTX 3500 delivers a running time of less than a working day, even with a 93Wh battery.\n\nIt should also be noted that the ZBook recovered almost half its battery capacity in thirty minutes, whereas the Dell took over an hour to hit a 50% recharge.\n\nHad I chosen a more concurrent Intel system, perhaps using the Intel Core Ultra 7 268V and the Intel Arc 140V GPU, it would have been soundly thrashed in almost every test.\n\nWhile I didn't run any AI tests, it would have been a victory for the ZBook, as Intel had no AI technology in 13th-generation processors.\n\nIgnoring workstations with discrete video technology that don’t work well on battery power, the HP ZBook Ultra G1a 14 demonstrates the power of an Ultrabook-sized machine with the latest AMD silicon onboard.\n\n(Image credit: Mark Pickavance)\n\nPerformance: 5 / 5\n\nHP ZBook Ultra G1a 14: Final verdict\n\nLet’s be brutally honest, this is a fantastic laptop that takes Intel’s best silicon and pushes past it effortlessly, but the price HP chose is somewhat of a gouge.\n\nMost managers find it challenging enough to get a $2,000 laptop approved, but this one could easily exceed $4,000 or more, depending on options.\n\nRecently, I reviewed the Bossgame M5 AI, a mini PC that uses the same AI 395 platform, which comes with 128GB of memory and 2TB of Kingston-branded storage. That costs about $1800, meaning you could have two of them for the price of one ZBook.\n\nYes, you would need monitors, keyboards and mice, but that’s a huge difference, and entirely rebuffs the notion that this is expensive because AMD is asking too much for its latest chips. But without competition, it can. HP has given this machine a flagship price because it knows that some corporate customers will be willing to pay it.\n\nThis is a huge shame, because many hard-working people deserve this level of performance to maximise their productivity, but fewer are likely to have a boss who will provide them with a system to deliver it.\n\nHowever, history tells us that within six months or more, when many brands have laptops utilising this exciting platform, the price will become much more realistic.\n\nShould you buy a HP ZBook Ultra G1a 14?\n\nSwipe to scroll horizontally Value When you are first, you can ask whatever price you like 3 / 5 Design Borrows from the EliteBook series on the outside 4 / 5 Hardware AI 300 series AI CPU, DDR5 and new 8060s Radeon make it amazingly powerful 5 / 5 Performance Incredible performance that is only beaten by discrete video cards 5 / 5 Overall Incredibly powerful and stupidly expensive 4.5 / 5\n\nBuy it if...\n\nYou need AI performance\n\nWhile not on the level of a discrete video card, the TOPS performance of this platform is exceptional, and way above the minimum requirement to run CoPilot locally.\n\nYou want an excellent OLED Display\n\nThe 14-inch 2.8K OLED screen offers superb colour accuracy, deep contrast, and a smooth 120Hz refresh rate. Ideal for presentations, creative work, and video calls, it elevates the visual experience far beyond typical business panels.\n\nDon't buy it if...\n\nYou need exceptional battery life\n\nAccording to HP, this machine should last more than 14 hours, but it only lasted nearly 11 hours in my test. That’s respectable, but other machines that use the latest Intel Ultra 200 processors or the Qualcomm Snapdragon X series can last longer.\n\nYou are on a tight budget\n\nFor the money, this is a decent laptop with plenty of nice features and a good hardware platform, but it’s hardly cheap. There are less expensive AMD Ryzen AI processors, but they don't have this sort of performance.\n\nFor more options for professionals, we reviewed the best laptops for work and gaming and the best laptops for working from home.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/hp-zbook-ultra-g1a-14-mobile-workstation-review",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "with-respect-to added to PyPI",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/with-respect-to/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Gunfire Erupts in Broadview: Armed Woman Targets DHS Agents",
      "content": "Skip to comments.\n\nGunfire Erupts in Broadview: Armed Woman Targets DHS Agents\n\nTownhall.com ^ | 4 October A.D. 2025 | Scott McClallen\n\nPosted on by lightman\n\nPeople are ramming federal officials near Chicago, according to Assistant Secretary Dept. of Homeland Security Tricia McLaughlin.\n\nDepartment of Homeland Security employees reporting being rammed and boxed in by 10 cars in Broadview, about 13 miles from Chicago.\n\nMcLaughlin posted on X.\n\n“This morning, during routine patrolling in Broadview, in the same area of Chicago that law enforcement were assaulted yesterday, our brave law enforcement officers were rammed by vehicles and boxed in by 10 cars.\n\nAgents were unable to move their vehicles and exited the car. One of the drivers who rammed the law enforcement vehicle was armed with a semi-automatic weapon. Law enforcement was forced to deploy their weapons and fire defensive shots at an armed US citizen who drove herself to the hospital to get care for wounds.\n\nThe armed woman was named in a @CBP intelligence bulletin last week for doxing agents and posting online ‘Hey to all my gang let’s fuck those mother fuckers up, don’t let them take anyone.’\n\nThankfully, no law enforcement officers were seriously injured in this attack.\n\nPritzker’s Chicago Police Department is leaving the shooting scene and refuses to assist us in securing the area. There is a growing crowd and we are deploying special operations to control the scene.\n\nThis is an evolving situation and we will give more information as soon as it becomes available.”\n\nThis morning, during routine patrolling in Broadview, in the same area of Chicago that law enforcement were assaulted yesterday, our brave law enforcement officers were rammed by vehicles and boxed in by 10 cars.\n\nAgents were unable to move their vehicles and exited the car. One… — Tricia McLaughlin (@TriciaOhio) October 4, 2025\n\nFox News’ Bill Melugin posted on X:\n\nBREAKING: DHS announces federal agents in Broadview, IL were rammed & boxed in by 10 cars, including a woman armed w/ a semi-automatic gun who had posted online threats to “fuck up” ICE & was flagged in a CBP intel bulletin. DHS says feds fired on her defensively.\n\nDHS: “Pritzker’s Chicago Police Department is leaving the shooting scene and refuses to assist us in securing the area. There is a crowd growing and we are deploying special operations to control a growing crowd.”\n\nBREAKING: DHS announces federal agents in Broadview, IL were rammed & boxed in by 10 cars, including a woman armed w/ a semi-automatic gun who had posted online threats to “fuck up” ICE & was flagged in a CBP intel bulletin. DHS says feds fired on her defensively.\n\nBREAKING: DHS announces federal agents in Broadview, IL were rammed & boxed in by 10 cars, including a woman armed w/ a semi-automatic gun who had posted online threats to “fuck up” ICE & was flagged in a CBP intel bulletin. DHS says feds fired on her defensively.\n\nDHS:… https://t.co/wQ8HcrIvIS — Bill Melugin (@BillMelugin_) October 4, 2025\n\nIllinois Gov. J.B. Pritzker’s office hasn’t responded to a request for comment.\n\nHomeland Security Secretary Kristi Noem said that reinforcements are on their way.\n\nToday in Chicago, members of our brave law enforcement were attacked—rammed and boxed in by ten vehicles, including an attacker with a semi-automatic weapon.\n\nI am deploying more special operations to control the scene. Reinforcements are on their way.\n\nIf you see a law… — Secretary Kristi Noem (@Sec_Noem) October 4, 2025\n\nChicago is a sanctuary city.\n\nThe Chicago shooting follows a man shooting up an ICE facility and killing two detainees. The shooter apparently wrote “anti-ICE” on his ammunition found at the scene.\n\n\n\nTOPICS:\n\nCrime/Corruption\n\nGovernment\n\nNews/Current Events\n\nUS: Illinois\n\nKEYWORDS:\n\nantifa\n\nbanglist\n\nchicago\n\ncrime\n\ndomesticenemies\n\nhabitualcomplainers\n\nic\n\nice\n\njimmykimmel\n\nmalcontentsoffr\n\nperpetualcarping\n\nsurrendermonkeysoffr\n\nviolence\n\nClick here: to donate by Credit Card Or here: to donate by PayPal Or by mail to: Free Republic, LLC - PO Box 9771 - Fresno, CA 93794 Thank you very much and God bless you.\n\nBroadway Illinois.\n\n\n\nTo: lightman\n\nBroadview ≠ Broadway\n\n\n\nby 2 posted onby lightman (Beat the Philly fraud machine the Amish did onest, ja? Nein, zweimal they did already!)\n\nTo: lightman\n\nSounds like a job for Mr. Grenade. Perhaps Mr. Gunship.\n\n\n\nby 3 posted onby larrytown (A Cadet will not lie, cheat, steal, or tolerate those who do. Then they graduate...)\n\nTo: lightman\n\nIs the Broad dead?\n\n\n\nby 4 posted onby ConservativeMind (Trump: Befuddling Democrats, Republicans, and the Media for the benefit of the US and all mankind.)\n\nTo: larrytown\n\nMr. Fogger and Mr. Water Cannon.\n\n\n\nby 5 posted onby lightman (Beat the Philly fraud machine the Amish did onest, ja? Nein, zweimal they did already!)\n\nTo: lightman\n\nBoxed in by 10 cars? Looks like organized crime to me. Build more prisons. Put the criminals in them.\n\n\n\nby 6 posted onby blueunicorn6 (\"A crack shot and a good dancer” )\n\nTo: lightman\n\n“… was armed with a semi-automatic weapon….”\n\n************************************************ Not very descriptive…. it could be anything from a 22 caliber handgun on up.\n\n\n\nTo: ConservativeMind\n\nHospitalized...she drove herself...with multiple gunshot wounds, I heard.\n\n\n\nby 8 posted onby gundog (The ends justify the mean tweets. )\n\nTo: larrytown\n\nDefinitely a Gunship.\n\n\n\nTo: House Atreides\n\nBelt fed Raven .25 caliber...\n\n\n\nby 10 posted onby Right Brigade (A new commandment I give unto you, That ye love one another; as I have loved you,)\n\nTo: gundog\n\n“..Hospitalized...she drove herself...with multiple gunshot wounds, I heard....” Heard she was shot 6 times. Somebody needs more range time.\n\n\n\nby 11 posted onby lgjhn23 (\"On the 8th day, Satan created the progressive liberal to destroy all the good that God created...\")\n\nTo: lightman\n\nShoot them. Shoot them dead. Shoot them dead on the spot.\n\n\n\nby 12 posted onby JimRed (TERM LIMITS, NOW! Finish the damned WALL! TRUTH is the new HATE SPEECH! )\n\nTo: lightman\n\nI read earlier she was huge and was hit 6 times.\n\n\n\nTo: JimRed\n\nShoot them. Shoot them dead. Shoot them dead on the spot. That's the only thing these loons will understand.\n\n\n\nby 14 posted onby Rummyfan (Ok In any war between the civilized man and the savage, support the civilized man.👨 )\n\nTo: lightman\n\nYou mean VX gas (used on North Vietnamese tinnels) and 3,000 psi material cutting water jets.\n\n\n\nTo: lightman\n\n\n\n@StephenM\n\n·\n\nFollow\n\nThis is domestic terrorism and seditious insurrection. Stephen Miller@StephenMFollowThis is domestic terrorism and seditious insurrection. Bill Melugin\n\n@BillMelugin_\n\nBREAKING: DHS announces federal agents in Broadview, IL were rammed & boxed in by 10 cars, including a woman armed w/ a semi-automatic gun who had posted online threats to “fuck up” ICE & was flagged in a CBP intel bulletin. DHS says feds fired on her defensively. Yes.....\n\n\n\nby 16 posted onby Rummyfan (Ok In any war between the civilized man and the savage, support the civilized man.👨 )\n\nTo: lightman\n\n\n\n@willchamberlain\n\n·\n\nFollow\n\nThe City of Chicago is in open rebellion against the Federal Government Will Chamberlain@willchamberlainFollowThe City of Chicago is in open rebellion against the Federal Government Cut off all federal funds to Chicago.\n\n\n\nby 17 posted onby Rummyfan (Ok In any war between the civilized man and the savage, support the civilized man.👨 )\n\nTo: lightman\n\nI want to know who supplied her with the firearm. Who paid for it? If this links back to an Soros organization, then Trump has even more justification to go after him.\n\n\n\nby 18 posted onby ducttape45 (Jeremiah 17:9, \"The heart is deceitful above all things, and desperately wicked: who can know it?\")\n\nTo: lgjhn23\n\nProbably shot through auto glass, and maybe steel, by multiple agents.\n\n\n\nby 19 posted onby gundog (The ends justify the mean tweets. )\n\nTo: alternatives?\n\nI shot him 6 times.\n\n\n\nDisclaimer: Opinions posted on Free Republic are those of the individual posters and do not necessarily represent the opinion of Free Republic or its management. All materials posted herein are protected by copyright law and the exemption for fair use of copyrighted works.\n\nFreeRepublic , LLC, PO BOX 9771, FRESNO, CA 93794\n\nFreeRepublic.com is powered by software copyright 2000-2008 John Robinson",
      "source": "Freerepublic.com",
      "url": "https://freerepublic.com/focus/f-news/4344389/posts",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Trump's $100,000 H-1B Fee Draws Rare Rebuke From US Business",
      "content": "A coalition of business groups warned President Donald Trump that a newly announced $100,000 fee for H-1B visa applications risks harming the US economy and urged the administration to avoid changes to the skilled worker program that impose added burdens on companies.\n\nIn a letter sent Friday to Trump, roughly a dozen industry organizations representing chipmakers, software companies and retailers said the new fee threatens to crimp a crucial talent pipeline of foreign skilled workers and leave critical jobs unfilled.\n\n“We ask the administration to work with industry on necessary reforms to the H-1B visa program without increasing the significant challenges US employers face recruiting, training, and retaining top talent,” the groups wrote.\n\nThe letter, sent two weeks after the president’s H-1B proclamation, was careful to laud Trump’s efforts to bring investment to the US. Signers included the Business Software Alliance, the semiconductor industry’s SEMI, the National Retail Federation, the Entertainment Software Association and the Information Technology Industry Council, according to a copy seen by Bloomberg News.\n\nThe industry groups’ objections marked a rare rebuke from the business community of US policy under the new administration. Trump announced the H-1B changes at the White House last month, heralding the $100,000 fee as a way to rein in abuses in the skilled worker program while pushing US companies to turn more to domestic talent to fill jobs.\n\nA White House spokesperson defended the new H-1B policy, saying it would help US companies access top talent while reducing fallout from “fraudulent practices by bad-faith actors.”\n\n“Widespread visa abuse not only undermines American workers, but undermines the companies” that need to recruit first-class talent, White House spokesman Kush Desai said in a statement.\n\nHigher costs from the new H-1B fees threaten to hammer a wide range of industries, from technology to health care to finance. Companies including Microsoft Corp., Amazon.com Inc. and Walmart Inc. have relied for years on the skilled worker program to bolster their ranks, and changes to the program put their talent pipelines at risk.\n\nCutting-edge sectors like artificial intelligence and biomedical engineering will need a high-skilled workforce to sustain their pace of growth in the US, the groups wrote. The H-1B changes risk hurting progress in those key areas, the groups said. Intel Corp., Taiwan Semiconductor Manufacturing Co., Samsung Electronics Co., Applied Materials Inc. and KLA Corp. all have members on SEMI’s board.\n\n“The new approach to H-1B visas, as it stands, will harm the Administration’s goals to ensure the US remains a leader in AI, revitalizes manufacturing growth, and propels US-developed energy,” the groups wrote.\n\nRepresentatives from Walmart, Target Corp. and Macy’s Inc. are part of the NRF’s executive committee and board. The federation didn’t immediately respond to a request for comment. Walmart is among major users of H-1B visas in the US along with tech giants and consulting companies. After Trump announced the $100,000 fee, several major companies urged employees holding the visa not to leave the US.\n\nThe letter emphasized that each of the industries represented “stand ready to work with the administration” to change the H-1B program. Copies of the letter were also shared with Homeland Security Secretary Kristi Noem, Commerce Secretary Howard Lutnick and Secretary of State Marco Rubio.\n\nTrump’s H-1B visa changes faced their first major court challenge on Friday. A nurse-staffing agency and several unions sued the administration in federal court seeking to block the fee. For hospitals, the H-1B program is crucial to recruiting doctors in rural areas hit by shortages of health care workers. The administration said on Sept. 22 doctors could qualify for exemptions from the new fee.",
      "source": "Ndtvprofit.com",
      "url": "https://www.ndtvprofit.com/business/trumps-100000-h-1b-fee-draws-rare-rebuke-from-us-business",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "How to Check CPU Temperature – A Practical Guide for Windows, macOS, Linux & BIOS",
      "content": "Click here to buy secure, speedy, and reliable Web hosting, Cloud hosting, Agency hosting, VPS hosting, Website builder, Business email, Reach email marketing at 20% discount from our Gold Partner Hostinger You can also read 12 Top Reasons to Choose Hostinger’s Best Web Hosting\n\nYou suspect your PC is running hotter than it used to — fans sound louder, battery life is shorter, games stutter. That nagging worry (“is my CPU cooking itself?”) grows when temperatures spike under load. Left unchecked, sustained high temps can cause throttling, instability, and shorter hardware lifespan. The good news: checking CPU temperature is fast and repeatable. In this guide I’ll show how to check CPU temperature across Windows, macOS, Linux and BIOS, explain what numbers actually matter, and give a simple troubleshooting checklist so you can fix the cause — not just the symptom.\n\nIntel® DSA is a free tool from Intel that keeps your drivers up to date. It scans your computer, finds outdated or missing drivers for Intel hardware, and helps you install the latest ones. This makes sure your system stays stable and performs well.\n\nWhy monitoring CPU temperature matters\n\nProtect performance: Modern CPUs throttle clocks under high temperatures to avoid damage — which reduces performance.\n\nCatch failures early: A rising idle temperature over weeks or months often means a failing cooler, clogged vents, or dried thermal paste.\n\nPeace of mind: Knowing normal idle and load ranges for your CPU helps you distinguish “normal” from “problem”.\n\nQuick fact: CPU manufacturers publish maximum operating thresholds (Tjunction/Tcase) and internal protections — CPUs will throttle or shut down near those limits to protect silicon. See Intel and AMD documentation for how to find your processor’s exact spec.\n\nHow to check CPU temperature\n\nBIOS/UEFI — best for baseline (before OS drivers). Built-in OS tools — some platforms expose temps natively. Third-party monitoring apps — detailed, real-time graphs and logging. Command-line tools — ideal for Linux or automation.\n\nBelow I walk through each method with step-by-step instructions.\n\nWindows Memory Diagnostic is a built-in tool for checking potential issues with your computer’s RAM (Random Access Memory). Faulty RAM can cause crashes, slow performance, or unexpected restarts. This guide will walk you through how to use this tool effectively, along with additional tips for troubleshooting and improving memory performance.\n\n1) Check CPU temperature in BIOS / UEFI (works on all PCs)\n\nWhy use BIOS? It shows temperatures before the OS loads — good baseline for idle temps.\n\nSteps:\n\nRestart PC and press the BIOS/UEFI key (common keys: Delete, F2, F10 — check your motherboard manual).\n\nNavigate to Hardware Monitor , PC Health , or H/W Status .\n\nLook for CPU Temperature, Core Temp, or similar. Note idle reading (room temp ~22°C gives typical idle 30–40°C on desktops; laptops run higher).\n\nTip: If BIOS reports much higher idle than expected, suspect cooling or thermal contact problems.\n\n2) Windows — built-in and third-party options\n\nBuilt-in: Windows 11 (newer builds) exposes CPU temperature in Task Manager for supported hardware; however coverage depends on OEM drivers and sensor support. Where available, Task Manager gives a quick check but is limited.\n\nBest third-party tools (Windows):\n\nHWiNFO — detailed sensor reporting, per-core temps, logging, and real-time graphs.\n\nCore Temp — lightweight, per-core temperature reporting and TjMax comparison.\n\nHWMonitor — simple list of sensors (temps, voltages, fan speeds).\n\nHow to use (example with HWiNFO):\n\nDownload HWiNFO (portable) and run Sensors-only. Watch Core # and Package temperatures; enable logging if you want a record. Stress-test with a tool (Cinebench, Prime95) while monitoring to see load temps.\n\nPractical note: Windows tools may report per-core and package temps differently — package temp is often the best single-number indicator for the whole CPU.\n\n3) macOS — simple options\n\niStat Menus (paid) — system-wide sensors including CPU package temps and historical charts.\n\nIntel Power Gadget (Intel Macs) — shows package power/temperature (for Intel-based Macs).\n\nApple Silicon: macOS limits direct sensor exposure for Apple Silicon; rely on Activity Monitor + manufacturer info for behavior; third-party tools are limited.\n\n4) Linux — command-line and GUI\n\nlm-sensors : sudo apt install lm-sensors → sudo sensors-detect → sensors to read temps.\n\npsensor: GUI that graphs temps and fan speeds, built on lm-sensors.\n\nPro tip: Use watch -n 1 sensors to monitor temps in a terminal during stress tests.\n\n5) Interpreting numbers — what’s safe and what’s not\n\nIdle temps: Desktop CPUs: ~30–45°C typical; laptops: 40–60°C typical (depends on design).\n\nLoad temps: Many modern desktop CPUs commonly run 70–85°C under sustained heavy loads with stock cooling; short spikes into 90°C may occur.\n\nManufacturer limits: Intel/AMD list maximum operating (junction) temperatures in official specs — often around 95–110°C, varying by model. Rely on the product page/spec sheet for your exact CPU.\n\nRule of thumb: sustained temps above 90–95°C deserve investigation. Temperatures near the documented max trigger throttling and increase wear.\n\nUse temperature trends as predictive maintenance\n\nMost guides tell you how to check a temperature now. Here’s a practical extension: log daily idle temps for 2–4 weeks to build a baseline. If your idle temp increases steadily (for example, 5–10°C over a month), that often signals:\n\nDust-clogged heatsink or fans\n\nDrying/deteriorating thermal paste\n\nNew background process or driver misbehavior\n\nHow to implement a simple trend: set HWiNFO or lm-sensors to log a timestamped idle temp once per day (or at boot). Plot or inspect values weekly. If average idle rises beyond a comfortable delta (e.g., +5°C month-over-month), schedule a cleaning or thermal service. This predictive approach prevents sudden failures and keeps performance consistent.\n\nIntel®-Based Systems for Everything You Do\n\n\n\nClick here to find out what’s for you\n\nIntel-based systems are used in a variety of devices, including desktop PCs, laptops, servers, and more. Intel processors are available in many different models and generations, and are designed for a range of tasks.\n\nMini-case study — laptop that got hotter after 12 months\n\nScenario: A user reported idle temps rising from 45°C to 62°C across 12 months.\n\nInvestigation: Logs (HWiNFO) showed steps up after a Windows update and after heavy browsing sessions. Physical check found dust buildup and a partially blocked fan intake. After cleaning vents and reapplying thermal paste, idle temps returned to ~46°C and load temps dropped ~8°C.\n\nLesson: Combine software monitoring with simple physical maintenance — logs point to “when” and inspection fixes the “why”.\n\nTroubleshooting checklist\n\nCheck background processes (Task Manager / top). Clean dust & improve airflow — especially laptops. Check cooler seating / reapply thermal paste (desktop CPU cooler reseat often helps). Update BIOS/firmware and chipset drivers. Improve case airflow (add/reposition fans, use mesh panels). Consider a better cooler — aftermarket air or AIO liquid for high-TDP chips. Throttle profiles / power plans — set balanced or custom profiles if needed. If temps exceed spec despite fixes, contact manufacturer.\n\nKey Takeaways\n\nHow to Check CPU Temperature: use BIOS for baseline, OS tools for quick checks, and third-party apps for deep monitoring.\n\nKnow your CPU’s spec: maximum operating temperatures vary by model — consult the manufacturer. Intel\n\nTrend logging is powerful: daily idle temperature trends can predict cooling degradation before it becomes critical.\n\nSustained temps above ~90°C generally need action.\n\nFixes are often simple: cleaning, reseating cooler, or reapplying thermal paste frequently solve rising temps.\n\nDo You Know the 7 Potential Disadvantages of Artificial Intelligence (AI)\n\nFAQs (People Also Ask)\n\nQ: What is a normal CPU temperature at idle?\n\nA: For desktops ~30–45°C is common; laptops typically run higher (40–60°C) depending on chassis and cooling.\n\nQ: Can CPUs be damaged by high temperature?\n\nA: Modern CPUs have thermal protections (throttling, shutdown). Repeated sustained overheating can shorten lifespan, so address sustained temps near spec limits.\n\nQ: Which tool is best to monitor CPU temperature on Windows?\n\nA: HWiNFO is widely recommended for detail and logging; Core Temp and HWMonitor are simpler alternatives.\n\nQ: Should I rely on Task Manager for CPU temperature?\n\nA: Task Manager (Windows 11) can show temps on supported systems, but it’s not as detailed as dedicated sensor tools and depends on driver support.\n\nConclusion\n\nYou don’t need to be a technician to know how to check CPU temperature — a few clicks or a quick BIOS visit gives you the numbers, and simple logs reveal trends. Once you can measure reliably, you can prevent throttling, extend hardware life, and keep performance predictable. Try one monitoring tool today, take a baseline reading, and add simple logging — that small habit pays off fast.\n\nStart by checking your CPU temperature now (BIOS or HWiNFO). If you found abnormal numbers, follow the troubleshooting checklist above — and subscribe to SmashingApps for more practical hardware guides and step-by-step fixes.",
      "source": "Smashingapps.com",
      "url": "https://www.smashingapps.com/how-to-check-cpu-temperature/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Samsung Galaxy Book5",
      "content": "What is Gadget Flow? Gadget Flow is the original product discovery platform that keeps you up to date with the latest tech , gear, and most incredible crowdfunding campaigns. Reaching over 31 million people per month, we also have iOS and Android apps that support AR and VR for next-level product exploration.\n\nWhy Use Gadget Flow? We keep you updated with the latest tech product announcements for everything from the newest drones to obscure gaming gadgets . Our team discovers unique products and covers the latest crowdfunding campaigns. Save gadgets to your private or public wish lists, check out our team’s expert reviews, and purchase products directly from trusted sellers.\n\nMeet the Team Gadget Flow is headquartered in New York City, and most of our team works remotely from the US and Europe. We are tech enthusiasts who love to learn about new technologies and the latest innovations. Talented individuals who are passionate about the future, we work tirelessly and love to excite you and teach you about advancements in our field.\n\nJoin Gadget Flow Today\n\nExplore the world of Gadget Flow so you know when any new tech launches—anywhere. Create your account using your email or any of our supported third-party logins, such as Google, Apple, and Facebook.\n\n1 Create Wish Lists Sign up to create private and public wish lists that you can share with family and friends. It’s also easy to organize your favorite gadgets into different collections, like gift guides, smart home products you love, and more. 2 Get Product Notifications What do you do when you find a product that you love but aren’t ready to buy? Simply create a notification! Click the three little dots by the buy now button and select Add Reminder to get notified. Receive a reminder when it’s discounted, Black Friday, the next season, or any date you choose. 3 Discover with Watch Now you can discover new products through our video feed. With Gadget Flow Watch, browse through your favorite categories and create playlists. Our endless selection of videos will have you discovering gadgets for hours.\n\nSee all of our features:\n\nCollections Create public or private collections My Feed Create your custom product feed AR/VR/3D Discover our products in VR, AR, and 3D Exlusive Deals New Discounts and deals, daily Watch Find new products through video Brand Pages Follow your favorite brands Notify Me Product reminders or sale reminders Multiple Currencies Browse using your local currency Tech News Stay updated with the latest tech news\n\nOur Mission: Help You Find the Best Gadgets\n\nWe simplify product discovery. This means you can find all the greatest gadgets in record time. As a technology company, our mission since 2012 has been to make it easy for you to discover quality products and stay updated with the latest trends.",
      "source": "Gadget Flow",
      "url": "https://thegadgetflow.com/?p=703467",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Show HN: Run – a CLI universal code runner I built while learning Rust",
      "content": "run\n\nPolyglot command runner & smart REPL that lets you script, compile, and iterate in 25+ languages without touching another CLI.\n\nWebsite • Docs Overview\n\nBuilt in Rust for developers who live in multiple runtimes. run gives you a consistent CLI, persistent REPLs, and batteries-included examples for your favorite languages.\n\nWebsite and Docs\n\nThe official website and full documentation are available here:\n\nUse these links to explore features, language guides, and detailed examples.\n\nOverview - Universal Multi-Language Runner\n\nA powerful command-line tool for executing code in 25 programming languages\n\nWhat is run?\n\nrun is a universal multi-language runner and smart REPL (Read-Eval-Print Loop) written in Rust. It provides a unified interface for executing code across 25 programming languages without the hassle of managing multiple compilers, interpreters, or build tools.\n\nWhether you're a beginner learning your first programming language or an experienced polyglot developer, run streamlines your workflow by providing consistent commands and behavior across all supported languages.\n\nWho is this for?\n\n• Beginners: Learn programming without worrying about complex setup procedures. Just install run and start coding in any language.\n\n• Students: Quickly test code snippets and experiment with different programming paradigms across multiple languages.\n\n• Developers: Prototype ideas rapidly, test algorithms, and switch between languages seamlessly without context switching.\n\n• DevOps Engineers: Write and test automation scripts in various languages from a single tool.\n\n• Educators: Teach programming concepts across multiple languages with a consistent interface.\n\nWhy was run created?\n\nTraditional development workflows require installing and configuring separate tools for each programming language. This creates several problems:\n\n• Time-consuming setup: Installing compilers, interpreters, package managers, and configuring environments for each language.\n\n• Inconsistent interfaces: Each language has different commands and flags for compilation and execution.\n\n• Cognitive overhead: Remembering different commands and workflows for each language.\n\n• Barrier to entry: Beginners struggle with setup before writing their first line of code.\n\nrun solves these problems by providing a single, unified interface that handles all the complexity behind the scenes. You focus on writing code, and run takes care of the rest.\n\nWhy Rust?\n\nrun is built with Rust for several compelling reasons:\n\n• Performance: Rust's zero-cost abstractions and efficient memory management ensure run starts instantly and executes with minimal overhead.\n\n• Reliability: Rust's strong type system and ownership model prevent common bugs like null pointer dereferences and data races, making run stable and crash-resistant.\n\n• Cross-platform: Rust compiles to native code for Windows, macOS, and Linux, providing consistent behavior across all platforms.\n\n• Memory safety: No garbage collector means predictable performance without unexpected pauses.\n\n• Modern tooling: Cargo (Rust's package manager) makes building and distributing run straightforward.\n\n• Future-proof: Rust's growing ecosystem and industry adoption ensure long-term maintainability.\n\nQuickstart\n\n# Show build metadata for the current binary run --version # Execute a snippet explicitly run --lang python --code \" print('hello, polyglot world!') \" # Let run detect language from the file extension run examples/go/hello/main.go # Drop into the interactive REPL (type :help inside) run # Pipe stdin (here: JSON) into Node.js echo ' {\"name\":\"Ada\"} ' | run js --code \" const data = JSON.parse(require('fs').readFileSync(0, 'utf8')); console.log( ` hi ${data.name} ` ) \" # Pipe stdin into Python echo \" Hello from stdin \" | run python --code \" import sys; print(sys.stdin.read().strip().upper()) \" # Pipe stdin into Go echo \" world \" | run go --code ' import \"fmt\"; import \"bufio\"; import \"os\"; scanner := bufio.NewScanner(os.Stdin); scanner.Scan(); fmt.Printf(\"Hello, %s!\n\n\", scanner.Text()) '\n\nInstallation\n\nAll release assets are published on the GitHub Releases page, including macOS builds for both Apple Silicon (arm64) and Intel (x86_64). Pick the method that fits your platform:\n\nInstalling run is straightforward. Choose the method that works best for your system:\n\nCargo (Rust) cargo install run-kit Installs the run binary from the run-kit crate. Updating? Run cargo install run-kit --force . # Or build from source git clone https://github.com/Esubaalew/run.git cd run cargo install --path . This builds the run binary using your active Rust toolchain. The project targets Rust 1.70 or newer.\n\nHomebrew (macOS) brew install --formula https://github.com/Esubaalew/run/releases/latest/download/homebrew-run.rb This formula is published as a standalone file on each release; it isn’t part of the default Homebrew taps. Installing by name ( brew install homebrew-run ) will fail—always point Homebrew to the release URL above (or download the file and run brew install ./homebrew-run.rb ). Once the latest release artifacts are published, Homebrew automatically selects the correct macOS binary for your CPU (Intel or Apple Silicon) based on this formula.\n\nDebian / Ubuntu curl -LO https://github.com/Esubaalew/run/releases/latest/download/run-deb.sha256 DEB_FILE= $( awk ' {print $2} ' run-deb.sha256 ) curl -LO \" https://github.com/Esubaalew/run/releases/latest/download/ ${DEB_FILE} \" sha256sum --check run-deb.sha256 sudo apt install \" ./ ${DEB_FILE} \"\n\nWindows (Scoop) scoop install https: // github.com / Esubaalew / run / releases / latest / download / run - scoop.json\n\nInstall script (macOS / Linux) curl -fsSLO https://raw.githubusercontent.com/Esubaalew/run/master/scripts/install.sh chmod +x install.sh ./install.sh --add-path # optional: append ~/.local/bin to PATH Pass --version v0.2.0 , --prefix /usr/local/bin , or --repo yourname/run to customize the install.\n\nDownload the archive directly Grab the tar.gz (macOS/Linux) or zip (Windows) from the latest release. Extract it and copy run / run.exe onto your PATH . Optionally execute the bundled install.sh to handle the copy for you.\n\nBuild from source cargo install run-kit The project targets Rust 1.70+. Installing from crates.io gives you the same run binary that CI publishes; use --force when upgrading to a newer release.\n\nVerify installation:\n\n# Verify installation run --version\n\nOutput:\n\nrun 0.2.0\n\nHow it works\n\nrun shells out to real toolchains under the hood. Each LanguageEngine implements a small trait that knows how to:\n\nDetect whether the toolchain is available (e.g. python3 , go , rustc ). Prepare a temporary workspace (compilation for compiled languages, transient scripts for interpreters). Execute snippets, files, or stdin streams and surface stdout/stderr consistently. Manage session state for the interactive REPL (persistent modules, stateful scripts, or regenerated translation units).\n\nThis architecture keeps the core lightweight while making it easy to add new runtimes or swap implementations.\n\nSupported languages\n\nrun supports 25+ languages:\n\nrun supports 25 programming languages out of the box, covering a wide range of paradigms and use cases:\n\n# Scripting Languages Python, JavaScript, Ruby, Bash, Lua, Perl, PHP # Compiled Languages Rust, Go, C, C++, Java, C#, Swift, Kotlin, Crystal, Zig, Nim # Typed & Functional Languages TypeScript, Haskell, Elixir, Julia # Specialized Languages R (Statistical computing) Dart (Mobile development)\n\nCategory Languages & aliases Toolchain expectations Scripting & shells Bash ( bash ), Python ( py , python ), Ruby ( rb , ruby ), PHP ( php ), Perl ( perl ), Lua ( lua ), R ( r ), Elixir ( ex , elixir ) Matching interpreter on PATH Web & typed scripting JavaScript ( js , node ), TypeScript ( ts , deno ), Dart ( dart ), Kotlin ( kt , kotlin ) node , deno , dart , kotlinc + JRE Systems & compiled C ( c ), C++ ( cpp , cxx ), Rust ( rs , rust ), Go ( go ), Swift ( swift ), Zig ( zig ), Nim ( nim ), Haskell ( hs , haskell ), Crystal ( cr , crystal ), C# ( cs , csharp ), Java ( java ), Julia ( jl , julia ) Respective compiler / toolchain\n\nCategorization notes\n\nThe categories above are usage-based to match how you’ll likely run code with run rather than strict language taxonomies. Examples:\n\nKotlin can target the JVM, Native, or JavaScript. If you’re using Kotlin/JS, it behaves closer to the “Web & typed scripting” workflow, while Kotlin/JVM fits “Systems & compiled” (with a JRE).\n\nSwift is listed under “Systems & compiled” because swiftc produces native binaries; however, you can still use it interactively via run for scripting-like workflows.\n\nproduces native binaries; however, you can still use it interactively via for scripting-like workflows. TypeScript typically runs via Node or Deno at runtime (transpiled), which is why it appears under “Web & typed scripting.”\n\nThese groupings optimize for how commands are invoked and which toolchains run detects and orchestrates.\n\nComplete Language Aliases Reference\n\nEvery language in run has multiple aliases for convenience. Use whichever feels most natural to you:\n\nAlias Description python, py, py3, python3 Python programming language javascript, js, node, nodejs JavaScript (Node.js runtime) typescript, ts, ts-node, deno TypeScript with type checking rust, rs Rust systems programming language go, golang Go programming language c, gcc, clang C programming language cpp, c++, g++ C++ programming language java Java programming language csharp, cs, dotnet C# (.NET) ruby, rb, irb Ruby programming language bash, sh, shell, zsh Bash shell scripting lua, luajit Lua scripting language perl, pl Perl programming language php, php-cli PHP scripting language haskell, hs, ghci Haskell functional language elixir, ex, exs, iex Elixir functional language julia, jl Julia scientific computing dart, dartlang, flutter Dart language (Flutter) swift, swiftlang Swift programming language kotlin, kt, kts Kotlin (JVM/Native) r, rscript, cran R statistical computing crystal, cr, crystal-lang Crystal language zig, ziglang Zig systems language nim, nimlang Nim programming language ocaml OCaml functional language clojure, clj Clojure Lisp dialect\n\nCommand Variations - Flexible Syntax\n\nrun supports multiple command formats to fit your workflow. You can be explicit with --lang or let run auto-detect the language:\n\nFull syntax with --lang and --code\n\nrun --lang rust --code \" fn main() { println!( \\\" hello from rust \\\" ); } \"\n\nOutput:\n\nhello from rust\n\nShorthand flags (-l for --lang, -c for --code)\n\nrun -l rust -c \" fn main() { println!( \\\" hello from rust \\\" ); } \"\n\nOmit --code flag (auto-detected)\n\nrun --code \" fn main() { println!( \\\" hello from rust \\\" ); } \"\n\nOutput:\n\nhello from rust\n\nShorthand - just the code\n\nrun \" fn main() { println!( \\\" hello from rust \\\" ); } \"\n\nOutput:\n\nhello from rust\n\nLanguage first, then code\n\nrun rust \" fn main() { println!( \\\" hello from rust \\\" ); } \"\n\nOutput:\n\nhello from rust\n\nCommand-Line Flags Reference\n\nrun provides both long-form and short-form flags for convenience:\n\n# Language specification --lang, -l Specify the programming language run --lang python \" print('hello') \" run -l python \" print('hello') \" # Code input --code, -c Provide code as a string run --code \" print('hello') \" run -c \" print('hello') \" # Combined usage run -l python -c \" print('hello') \" run --lang python --code \" print('hello') \"\n\n⚠️ When to Use --lang (Important!)\n\nWhile run can auto-detect languages, ambiguous syntax can cause confusion. For example, print('hello') looks similar in Python, Ruby, Lua, and other languages. Always use --lang for correctness when the syntax is ambiguous or when you need deterministic behavior.\n\n# ❌ Ambiguous - may choose wrong language run \" print('hello') \"\n\nOutput:\n\nhello # But which language was used?\n\n# ✅ Explicit - always correct run --lang python \" print('hello') \"\n\nOutput:\n\nhello # Guaranteed to use Python\n\nRECOMMENDATION: Always use --lang for correctness when:\n\n• The syntax is ambiguous across multiple languages\n\n• You want to ensure the exact language is used\n\n• You're writing scripts or automation that must be deterministic\n\nMain Function Flexibility\n\nFor compiled languages (Rust, Go, C, C++, Java, etc.), run is smart about main functions:\n\n• Write complete programs with main functions\n\n• Write code without main functions (run wraps it automatically)\n\n• Both approaches work in REPL mode and inline execution\n\nGo Example - With main function\n\n$ run go run universal REPL. Type :help for commands. go>>> package main import \" fmt \" func main () { fmt.Println( \" Hello, world! \" ) } Hello, world !\n\nGo Example - Without main function\n\ngo>>> fmt.Println(\"Hello, world!\") Hello, world!\n\nExamples\n\nReal programs live under the examples/ tree—each language has a hello and a progress scenario. The headers document expected output so you can diff your toolchain.\n\nrun examples/rust/hello.rs run examples/typescript/progress.ts run examples/python/counter.py\n\nREPL\n\nBeing inside REPL we can use the ff commands\n\nThe REPL supports several built-in commands for managing your session:\n\nCommand Purpose :help List available meta commands :languages Show detected engines and status :lang <id> or :<alias> Switch the active language ( :py , :go , …) :detect on/off/toggle Control snippet language auto-detection :load path/to/file Execute a file inside the current session :reset Clear the accumulated session state :exit / :quit Leave the REPL\n\nAlias Description :help Show available REPL commands :quit or :q Exit the REPL :clear or :c Clear the screen :reset Reset the session (clear all variables) :lang <language> Switch to a different language :py, :js, :go, etc. Quick language switch shortcuts\n\nInteractive REPL - Line by Line or Paste All\n\nThe REPL mode is incredibly flexible. You can:\n\n• Type code line by line interactively\n\n• Paste entire programs at once\n\n• Mix both approaches in the same session\n\nThis works for ALL supported languages!\n\nPython Example - Paste entire program\n\n$ run python python>>> def fibonacci(n): if n < = 1: return n return fibonacci(n-1) + fibonacci(n-2) for i in range(10): print(f \" F({i}) = {fibonacci(i)} \" ) F(0) = 0 F(1) = 1 F(2) = 1 F(3) = 2 F(4) = 3 F(5) = 5 F(6) = 8 F(7) = 13 F(8) = 21 F(9) = 34\n\nPython Example - Line by line\n\npython>>> x = 10 python>>> y = 20 python>>> print(x + y) 30\n\nVariable Persistence & Language Switching\n\nVariables persist across REPL commands within the same session. You can also switch languages on the fly using the :lang command (e.g., :c, :py, :go):\n\nIn REPL mode, variables persist across commands within the same language session. You can also switch languages on the fly using :lang commands.\n\nWhen you switch languages, variables from the previous language do NOT carry over (each language has its own isolated session).\n\nVariable Persistence Example\n\n$ run go go>>> x := 10 go>>> x 10 go>>> :c switched to c c>>> int x = 10; c>>> x 10 c>>> 10 + 10 20 c>>> :py switched to python python>>> y = 10 python>>> y 10 python>>> print(y) 10 python>>> z = 4 python>>> z is y False python>>> z == y False\n\nLanguage Switching Commands\n\nSwitch between languages instantly in REPL mode using colon commands\n\nBuilt-in REPL Commands\n\n:help → Show help and available commands :languages → List all supported languages :clear → Clear the screen :exit or :quit → Exit the REPL :lang <language> → Switch to a different language Ctrl+D → Exit the REPL\n\nStdin Piping Examples\n\nrun supports piping input from stdin to your code snippets across all languages. Here are more examples for different languages:\n\necho ' {\"name\":\"Ada\"} ' | run js --code \" const data = JSON.parse(require('fs').readFileSync(0, 'utf8')); console.log( ` hi ${data.name} ` ) \"\n\nOutput:\n\nhi Ada\n\nPython (Uppercase Conversion)\n\necho \" Hello from stdin \" | run python --code \" import sys; print(sys.stdin.read().strip().upper()) \"\n\nOutput:\n\nHELLO FROM STDIN\n\nGo (Greeting)\n\necho \" world \" | run go --code ' import \"fmt\"; import \"bufio\"; import \"os\"; scanner := bufio.NewScanner(os.Stdin); scanner.Scan(); fmt.Printf(\"Hello, %s!\n\n\", scanner.Text()) '\n\nOutput:\n\nHello, world!\n\nRuby (Line Counting)\n\necho -e \" line1\n\nline2\n\nline3 \" | run ruby --code \" puts gets(nil).lines.count \"\n\nOutput:\n\n3\n\nBash (Echo with Prefix)\n\necho \" input text \" | run bash --code ' read line; echo \"Processed: $line\" '\n\nOutput:\n\nProcessed: input text\n\nLanguage-Specific Notes\n\nFor detailed usage, quirks, and best practices for each language, visit the dedicated documentation:\n\nPython: Tips for scripting, data processing, and REPL persistence.\n\nJavaScript/Node.js: Async code, modules, and stdin handling.\n\nRust: Compilation flags, error handling, and workspace management.\n\nGo: Package imports, build optimizations, and concurrency examples.\n\nC/C++: Compiler selection, linking, and multi-file support.\n\nJava: Classpath management, JVM args, and enterprise patterns.\n\nTypeScript: Type checking, Deno vs Node, and transpilation.\n\nAnd more... for all 25+ languages including Ruby, PHP, Haskell, Elixir, and specialized ones like R and Julia.\n\nEach language doc covers:\n\nToolchain requirements and detection\n\nREPL-specific features (e.g., persistent state)\n\nCommon pitfalls and workarounds\n\nAdvanced examples (e.g., file I/O, networking)\n\nLicense\n\nApache 2.0. See LICENSE for details.",
      "source": "Github.com",
      "url": "https://github.com/Esubaalew/run",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "DHS announces federal agents in Broadview, IL were rammed & boxed in by 10 cars, including a woman armed w/ a semi-automatic gun (Feds fired gun in defense)",
      "content": "Skip to comments.\n\nDHS announces federal agents in Broadview, IL were rammed & boxed in by 10 cars, including a woman armed w/ a semi-automatic gun (Feds fired gun in defense)\n\nPosted on by janetjanet998\n\nEdited on by Sidebar Moderator. [history]\n\nBREAKING: DHS announces federal agents in Broadview, IL were rammed & boxed in by 10 cars, including a woman armed w/ a semi-automatic gun who had posted online threats to “fuck up” ICE & was flagged in a CBP intel bulletin. DHS says feds fired on her defensively.\n\n(Excerpt) Read more at x.com ...\n\nTOPICS:\n\nNews/Current Events\n\nKEYWORDS:\n\nantifa\n\nblm\n\ndemocratterrorism\n\ndemocratterrorists\n\nClick here: to donate by Credit Card Or here: to donate by PayPal Or by mail to: Free Republic, LLC - PO Box 9771 - Fresno, CA 93794 Thank you very much and God bless you.\n\n\n\n\n\nComment #2 Removed by Moderator\n\nTo: janetjanet998\n\nTime to call in a AC130.\n\n\n\nTo: janetjanet998\n\nThey want war.\n\n\n\nTo: janetjanet998\n\nChicago Police Department is leaving the shooting scene and refuses to assist us ChiCongo \"cops\" are a part of the problem and it is stupid to think any of those oinkers are going to uphold the law.\n\n\n\nby 5 posted onby LouAvul (Galatians: proof that \"dispensationalism\" in any form is false doctrine. Salvation is only in Jesus.)\n\nTo: janetjanet998\n\nOnly one wounded. There were ten cars. Should be ten dead.\n\n\n\nTo: janetjanet998\n\nPritzker is leading an insurrection. I hope Trump arrests him.\n\n\n\nTo: janetjanet998\n\nSounds like it’s on like Donkey Kong.\n\n\n\nby 8 posted onby gundog (The ends justify the mean tweets. )\n\nTo: janetjanet998\n\nI voted for obliteration and draining, not allowing domestic enemies to drive themselves to the hospital..\n\n\n\nTo: janetjanet998\n\nFor cryin’ out loud, break out the national guard to help ICE and law enforcement. The control of the city should be taken out of the hands of the incompetent politicos.\n\n\n\nby 10 posted onby gildafarrell (\"No free man shall ever be debarred the use of arms.\")\n\nTo: janetjanet998\n\nWhat’s her NAME and WHERE is her PICTURE????? WTH hasn’t she been ARRESTED??\n\n\n\nTo: janetjanet998\n\nYou’d think federal agencies could come up with a maneuver behind the rioters blocking off all exits and then coral in force and arrest everyone of them on numerous charges, obstruction being the main one but at a minimum disturbing the peace.\n\n\n\nby 12 posted onby maddog55 (The only thing systemic in America is the left's hatred of it!)\n\nTo: janetjanet998\n\nGovernor lard ass wont be satisfied til ICE agents are murdered, he thinks by killing ICE agents it will give him street cred in the 2028 election\n\n\n\nTo: DeplorablePaul\n\nYou’d need 20 handcuffs for that lard ass alone\n\n\n\nTo: Ann Archy\n\nWhat’s her NAME and WHERE is her PICTURE????? WTH hasn’t she been ARRESTED?? —- She’s at the hospital\n\nMultiple wounds Live Chicago scanner thread\n\ntalking to the agents over here, that individual was the lone driver of that vehicle and was part of a caravan that were trying to interrupt ICE operations at the time of this shooting. she’s potentially going to be an offender at this point. let’s make sure we keep an officer with her. Ambo 34 to Mt. Sinai.\n\nhttps://x.com/LoveyPuffyPants/status/1974518556726624587\n\n\n\nby 15 posted onby janetjanet998 (Please don’t use google products, especially YouTube )\n\nTo: Sarah Barracuda\n\nGovernor lard ass wont be satisfied til ICE agents are murdered, he thinks by killing ICE agents it will give him street cred in the 2028 election ICE should go \"thin mint\" on Governor Creosote...\n\n\n\nby 16 posted onby kiryandil (No one in AZ that voted for Trump voted for Gallego )\n\nTo: janetjanet998\n\nThis happens when you are weak and only take a defensive posture at the building. No effort to kettle and conduct mass arrests, no raids on the organizing and funding nodes. Soldiers ringing a building a pure stupidity and encourages boldness in the enemy.\n\n\n\nby 17 posted onby DesertRhino (When men on the chessboard, get up and tell you where to go…)\n\nTo: janetjanet998\n\nHose down the crowd with machine guns. Flood the city with national guard and declare martial law.\n\n\n\nTo: janetjanet998\n\nGive 'em a whiff of the grape ...\n\n\n\nby 19 posted onby BlueLancer (\"It's very dangerous to believe people. I haven't for years.\" Miss Marple - Sleeping Murder)\n\nTo: janetjanet998\n\nTrump needs to send help to deal with crowds and declare marshall law.\n\n\n\nDisclaimer: Opinions posted on Free Republic are those of the individual posters and do not necessarily represent the opinion of Free Republic or its management. All materials posted herein are protected by copyright law and the exemption for fair use of copyrighted works.\n\nFreeRepublic , LLC, PO BOX 9771, FRESNO, CA 93794\n\nFreeRepublic.com is powered by software copyright 2000-2008 John Robinson",
      "source": "Freerepublic.com",
      "url": "https://freerepublic.com/focus/f-news/4344343/posts",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "arango-cve-processor 1.2.8",
      "content": "Arango CVE Processor\n\nBefore you get started\n\nArango CVE Processor is built into Vulmatch which also handles the download of CVE objects (what you need for ACVEP to work). As such, Vulmatch is probably better suited to what you're looking for.\n\ntl;dr\n\nA small script that enriches CVEs to other sources with all data stored as STIX 2.1 objects.\n\nOverview\n\nHere at DOGESEC we work with a lot of CVE data across our products. cve2stix generates core STIX 2.1 Vulnerability objects from CVE data.\n\nHowever, we have lots of other sources (EPSS, KEV, ATT&CK...) that we want to enrich this data with.\n\nWe built Arango CVE Processor to handle the generation and maintenance of these enrichments.\n\nIn short, Arango CVE Processor is a script that;\n\nreads the ingested CVE STIX data in ArangoDB creates STIX objects to represent the relationships between CVE and other datasets\n\nSource\n\nUsage\n\nInstall the script\n\n# clone the latest code git clone https://github.com/muchdogesec/arango_cve_processor # create a venv cd arango_cve_processor python3 -m venv arango_cve_processor-venv source arango_cve_processor-venv/bin/activate # install requirements pip3 install -r requirements.txt\n\nConfiguration options\n\nArango CVE Processor has various settings that are defined in an .env file.\n\nTo create a template for the file:\n\ncp .env.example .env\n\nTo see more information about how to set the variables, and what they do, read the .env.markdown file.\n\nRun\n\npython3 arango_cve_processor.py \\ MODE \\ -- MODE OPTIONS\n\nThe following modes are available;\n\ncve-cwe links vulnerability objects to CWE objects\n\ncve-capec (relies on cve-cwe run first) links vulnerability objects to CAPEC objects\n\n(relies on run first) cve-attack (relies on cve-capec run first) links vulnerability objects to ATT&CK objects\n\n(relies on run first) cve-epss creates/updates report objects linked to CVE representing one of more EPSS score for the time range run\n\ncve-kev (relies on cve-cwe run first) creates/updates report objects linked to CVE representing CISA KEV data\n\n(relies on run first) cve-vulncheck-kev (relies on cve-cwe run first) creates/updates report objects linked to CVE representing Vulncheck KEV data\n\n(relies on run first) cpematch creates/updates grouping objects (and linked software objects) representing CPE Matches tied to CPEs.\n\n\n\nAll modes have varying options, however, the following are available in all modes\n\n--database (required): the arangoDB database name where the objects you want to link are found. It must contain the collections nvd_cve_vertex_collection and nvd_cve_edge_collection\n\n(required): the arangoDB database name where the objects you want to link are found. It must contain the collections and --ignore_embedded_relationships (optional, boolean). Default is false . if true passed, this will stop any embedded relationships from being generated. This is a stix2arango feature where STIX SROs will also be created for _ref and _refs properties inside each object (e.g. if _ref property = identity--1234 and SRO between the object with the _ref property and identity--1234 will be created). See stix2arango docs for more detail if required, essentially this a wrapper for the same --ignore_embedded_relationships setting implemented by stix2arango\n\n(optional, boolean). Default is . if passed, this will stop any embedded relationships from being generated. This is a stix2arango feature where STIX SROs will also be created for and properties inside each object (e.g. if property = and SRO between the object with the property and will be created). See stix2arango docs for more detail if required, essentially this a wrapper for the same setting implemented by stix2arango --ignore_embedded_relationships_sro (optional): boolean, if true passed, will stop any embedded relationships from being generated from SRO objects ( type = relationship ). Default is false\n\n(optional): boolean, if passed, will stop any embedded relationships from being generated from SRO objects ( = ). Default is --ignore_embedded_relationships_smo (optional): boolean, if true passed, will stop any embedded relationships from being generated from SMO objects ( type = marking-definition , extension-definition , language-content ). Default is false\n\nTo see the options available for each mode you can run with the help flag ( -h ), e.g.,\n\npython3 arango_cve_processor.py \\ cve-epss -h\n\npython3 arango_cve_processor.py \\ cve-cwe -h\n\nExamples\n\nProcess CVE -> CWE relationships for all CVEs modified after 2024-02-01\n\npython3 arango_cve_processor.py \\ cve-cwe \\ --database vulmatch_database \\ --modified_min 2024 -02-01 \\ --ignore_embedded_relationships true \\ --ignore_embedded_relationships_sro true \\ --ignore_embedded_relationships_smo true\n\nGet all EPSS scores for CVEs for each day in 2024\n\npython3 arango_cve_processor.py \\ cve-epss \\ --database vulmatch_database \\ --start_date 2024 -01-01 \\ --end_date 2024 -12-31 \\ --ignore_embedded_relationships true \\ --ignore_embedded_relationships_sro true \\ --ignore_embedded_relationships_smo true\n\nUpdate all CPE Matches modified after 2024-02-01\n\npython3 arango_cve_processor.py \\ cpematch \\ --database vulmatch_database \\ --updated_after 2024 -02-01 \\ --ignore_embedded_relationships true \\ --ignore_embedded_relationships_sro true \\ --ignore_embedded_relationships_smo true\n\nBackfilling data\n\nstix2arango contains a set of utility scripts that can be used to backfill all the datasources required for this test.\n\nHow it works\n\nIf you would like to know how the logic of this script works in detail, please consult the /docs directory.\n\nUseful supporting tools\n\nSupport\n\nMinimal support provided via the DOGESEC community.\n\nLicense\n\nApache 2.0.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/arango-cve-processor/1.2.8/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Alleged Intel Panther Lake Lineup And Configurations Leaked: Total Of 12 SKUs, Including Four From PTL-U Series",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/alleged-intel-panther-lake-lineup-and-configurations-leaked/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Win a Terramaster F4-425 Intel X86 Home NAS or D1 SSD Plus Portable SSD from Terramaster",
      "content": "Win F4-425 & D1 SSD Plus + Prime Day 30% OFF!\n\nWe are giving 1 F4-425 + 1 D1 SSD Plus to TWO lucky winners! Follow to get FIRST ACCESS before anyone else! ✨\n\nPRIZES:\n\n🎁 GRAND PRIZE: F4-425 - Intel x86 Home NAS\n\n🎁 2nd PRIZE: D1 SSD Plus - YOUR 40Gbps SPEED BEAST!\n\n✅ TO ENTER:\n\n1️⃣FOLLOW\n\n2️⃣ LIKE & SHARE\n\n⏰ ENDS: October 8\n\n🏆 WINNERS ANNOUNCED: October 10\n\n🔥 PRIME DAY Deals:\n\nSave Up To 30% OFF ALL TerraMaster storage during Prime Day!\n\nPerfect time to upgrade your NAS & DAS:\n\nOfficial Store, Amazon US, Amazon UK, Amazon DE, Amazon FR, Amazon IT, Amazon ES, Amazon JP, Amazon CA, Amazon AU, Amazon NL, Amazon PL, Amazon SE, AliExpress, Newegg, Walmart, B&H",
      "source": "Ozbargain.com.au",
      "url": "https://www.ozbargain.com.au/node/927110",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Why I recommend this $299 Windows laptops to most students with confidence",
      "content": "'ZDNET Recommends': What exactly does it mean?\n\nZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we’re assessing.\n\nWhen you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.\n\nZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.",
      "source": "ZDNet",
      "url": "https://www.zdnet.com/article/why-i-recommend-this-299-windows-laptops-to-most-students-with-confidence/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "ARM CEO Rene Haas Claims That Time Has Punished Intel For Falling Behind the Chip Race & Now Catching Up To TSMC Is “Very Hard”",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/arm-ceo-claims-time-has-punished-intel-for-falling-behind-the-chip-race/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Week 5 Booms and Busts: The Ravens' fantasy football juggernaut bottoms out — is there reason for hope?",
      "content": "Success in fantasy football takes more than instincts — it takes insight. Just like SurveyMonkey AI helps you transform insights into action, these Booms & Busts give you fantasy intel and help you adjust your lineup and strategy to take control of your season.\n\nThe Baltimore Ravens were dreaming big all summer. They were one of the Super Bowl favorites and one of the fantasy football darling teams. A juggernaut just waiting for gas and the open road.\n\nAdvertisement\n\nAdvertisement Advertisement\n\nBut sometimes, reality bites. As we get ready for the second week of October, Baltimore is 1-4 — and looking like a scary fantasy investment.\n\nHopefully, Week 5 was a bottoming out of sorts. An equally desperate Houston team came to Baltimore on Sunday and took the Ravens behind the woodshed. The final score was 44-10, Texans, and that might not be descriptive enough. The Texans had 27 first downs, the Ravens just 10. Houston rolled up 417 yards of offense, Baltimore managed just 207.\n\nOf course, Baltimore is missing all sorts of key personnel, starting with QB Lamar Jackson (hamstring). Backup QB Cooper Rush was harried into three picks, while Derrick Henry (15 carries, 33 yards) couldn’t find lanes behind a patchwork offensive line. Henry did find the end zone late in the third quarter, when the score was already out of hand.\n\nWith Henry struggling and the Ravens reluctant to let Rush dominate the offense, the Baltimore pass-catchers were forced to work on limited volume. Zay Flowers at least caught all of his targets and salvaged a 5-72-0 line, with 56 of the yards on one fortuitous play. Mark Andrews (2-22-0) was only targeted twice. All three of Rashod Bateman’s targets were incomplete.\n\nAdvertisement\n\nAdvertisement Advertisement\n\nThings might not get better immediately. Baltimore hosts the Rams next week, with Jackson no sure thing to return. Then it’s a Week 7 bye — a well-timed break, all things considered. The Ravens defense is even more injury-riddled than the offense. That’s a big reason why the Houston offense finally let its hair down.\n\nJackson and Flowers are the type of fantasy trade targets that a winning roster might consider — players you can wait for if you’re probably going to be 5-0 or 4-1 after his week. Their managers might need to liquidate immediately, but others could have the benefit of patience.\n\nHenry is a tougher call. He’s navigating his age-31 season, his 10th year in the NFL. He’s dealt with fumbles and he’s been at 50 rushing yards or fewer in four straight weeks. We know he’s never going to be a big part of the passing game.\n\n[Yahoo Sports TV is here! Watch live shows and highlights 24/7]\n\nAndrews also needs Jackson back in the worst way. He’s been held under seven fantasy points in four of his five starts this year, and like Henry, it’s the back nine for Andrews. He’s now in his age-30 season, and it’s possible Isaiah Likely could cut into the Andrews workload in the second half of the year. (Likely has been slow to onboard this year, dealing with his own injury issues.)\n\nAdvertisement\n\nAdvertisement Advertisement\n\nThe funky thing about Houston’s offensive explosion was that most of it was steered at players you couldn’t have trusted for fantasy. C.J. Stroud did toss four touchdown passes, but two of them went to Xavier Hutchinson (3-18-2) and a third went to Jaylin Noel (2-13-1). The passing game targeted 10 players in all, too wide for our taste.\n\nAt least Nico Collins (4-52-1) had one of the scores, though he always deserves more than five targets. Christian Kirk (4-64-0) and Dalton Shultz (5-60-0) were respectable.\n\nThe Houston backfield was a curveball, too. Waiver darling Woody Marks only made 24 yards on his seven carries, while veteran Nick Chubb grinded out 11 carries for 61 yards and a touchdown. Neither had a reception. The snap count was fairly even and we have to take both players seriously with Joe Mixon likely not returning this year, but it was pesky to see Marks do so little on a day where Houston won easily. Dameon Pierce was the clean-up man late, rushing seven times for 21 unimpressive yards.\n\nAdvertisement\n\nAdvertisement Advertisement\n\nCowboys continue to deliver\n\nMaybe we can cleanse the palate with the Cowboys and Jets.\n\nMost of the primary fantasy angles came in while Dallas scored a 37-22 victory. The Cowboys opened up a 30-3 lead late in the third period, then let the Jets dominate in garbage time. But hey, we just want the points.\n\nDak Prescott continues to thrive despite the absence of alpha WR CeeDee Lamb. Prescott threw for 237 yards and four touchdowns, with no turnovers and just one sack. That’s a 127.4 rating and 8.2 YPA despite Lamb on the sidelines. Snappy stuff.\n\nGeorge Pickens (2-57-1) bailed out his day with a late 43-yard touchdown (Sauce Gardner mostly marked him well), and Javonte Williams (139 total yards, two touchdowns) has been the late-round steal of the fantasy season. Jake Ferguson (7-49-2) continued his touchdown-correction tour, working the short areas well. Prescott especially trusts him on third down.\n\nAdvertisement\n\nAdvertisement Advertisement\n\nBut did anyone see Ryan Flournoy coming? A sixth-round pick from the 2024 draft, Flournoy had just 14 career catches before Sunday. But Prescott looked his way early and often at New York, leading to a 6-114-0 explosion. It goes to show you how talented the league is, where virtual unknowns can sometimes just be waiting for an opportunity. Maybe Flournoy can offer flex-league juice until Lamb comes back.\n\nIt’s miraculous that the Jets bailed out their fantasy day, because they were awful for about 40 minutes in this game. But Justin Fields kept battling and competing, and eventually landed on 283 passing yards and two touchdowns. He also took five sacks, a return to the problem that’s held back most of his career. But at least he kept the ball going where we want, liberally targeting Garrett Wilson (6-71-1) and Mason Taylor (9-67-0) on about half of his attempts. Fields also scrambled for 26 yards and clicked on a couple of two-point conversions.\n\nFields might need to go on ice for Week 6, hosting the nasty Denver defense. But the Panthers and Bengals are fun matchups after that.\n\nIn Other Week 5 Booms\n\n— Chuba Hubbard managers, you might want to leave the room. Hubbard (calf) couldn’t play against Miami, enabling Rico Dowdle to explode on the scene — 206 rushing yards, 234 total yards, over 30 fantasy points. Dowdle would have been even better if not for some second-half cramping, which allowed Trevor Etienne to steal a few carries. There hasn’t been a smash game yet for Tetairoa McMillan (6-73-0), but at least he drew eight targets. He’s gaining steam with Bryce Young. Be patient there.\n\nAdvertisement\n\nAdvertisement Advertisement\n\n— As is often the case, Tua Tagovailoa was just good enough to lose with. But 256 passing yards, three touchdowns, no turnovers, we’ll certainly take that. Jaylen Waddle (6-110-1) smashed without Tyreek Hill, as expected. Tagovailoa missed him on at least one more deep opportunity. Darren Waller (5-78-1) had a monster first half, then didn’t draw a second-half target. It’s hard to say if that’s on Tagovailoa, Waller or head coach Mike McDaniel. Success has many parents, but so does failure. The 1-4 Dolphins host the Chargers next week.\n\n— The Raiders actually defended Jonathan Taylor fairly well, holding him to 66 yards on 17 attempts. But the Colts were constantly in the red zone and Taylor was often the finisher, punching in three touchdowns. Mix in a 3-20-0 day receiving and a two-point conversion and Taylor sailed over 28 points for the third time this year. I can’t see how the Cardinals will hold back the Colts next week, especially with Daniel Jones (113.0 rating, no turnovers or sacks) playing so crisply.\n\nIn Week 5 Busts ...\n\n— Jaxson Dart is confident, competitive, scrappy. He’s also a work in progress as a passer. He managed just 5.1 YPA against the pedestrian Saints defense, with most of the connections coming to backs and tight ends. As for the wideouts we wanted to trust, Darius Slayton (3-31-0) and Wan’Dale Robinson (5-30-0) didn’t do much. Slayton, Dart and Cam Skattebo (104 total yards) all lost key fumbles in the loss. It won’t get easier against the Eagles next week.\n\nAdvertisement\n\nAdvertisement Advertisement\n\n— Given that Denver’s win over Philadelphia was close throughout, it was strange to see Saquon Barkley land on just six carries for 30 yards. Barkley bailed out his day with a 47-yard touchdown catch. Perhaps a couple of revenge games against the Giants (Week 6, Week 8) will return Barkley to his fantasy perch. DeVonta Smith (8-114-0) was active against the Broncos, but A.J. Brown (5-43-0) didn’t get much out of eight targets.\n\n— I’ve been a Geno Smith believer for most of the past few years, but it’s getting difficult to stay the course. Smith threw two more picks and took four sacks at Indianapolis in the 40-6 blowout. It didn’t help to be without Brock Bowers, of course, but Smith couldn’t get anything going with Jakobi Meyers (4-32-0, six targets). Ashton Jeanty’s day survived on volume — 19 touches, five receptions, 109 total yards. At least a dreamy Week 6 home game against Tennessee is on the way.",
      "source": "Yahoo Entertainment",
      "url": "https://sports.yahoo.com/fantasy/article/week-5-booms-and-busts-the-ravens-fantasy-football-juggernaut-bottoms-out--is-there-reason-for-hope-221452989.html",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Would Patriots pursue an A.J. Brown trade? Breer shares important context",
      "content": "The Philadelphia Eagles say they have no plans to trade A.J. Brown. But when there's smoke, there's often fire.\n\nBrown has gotten off to a slow start in Philly this season, with just 19 catches on 36 targets for 194 yards and a touchdown through five games. After a two-catch, seven-yard showing against the Tampa Bay Buccaneers in Week 4, the Pro Bowl wide receiver shared a cryptic post on X, writing, \"If you’re not welcomed, not listened to, quietly withdraw. Don’t make a scene. Shrug your shoulders and be on your way.\"\n\nWhile Brown later downplayed his post, it's hard not to infer that he's disappointed in his role in the Eagles' offense. So, what are the odds that Philly parts ways with its star wide receiver?\n\nSubscribe to NBC Sports Boston's podcast network to hear our Insiders bring you the latest insights on your favorite teams! PODCASTS\n\nSports Illustrated's Albert Breer joined Patriots Pregame Live on Sunday to share his intel, noting that an in-season trade of Brown seems unlikely given Philly's status as a legitimate Super Bowl contender -- but that an offseason trade could be on the table.\n\n\"I don't think it'll happen in-season,\" Breer said. \"I think the Eagles have sort of chalked this up to part of the deal with A.J. Brown. When you have a receiver of that stature, sometimes you're going to deal with some of these things, which they are.\n\n\"They're very clearly in a championship window. So, the idea of peeling a guy like this off at a juncture in the calendar when you're not going to be able to properly replace him while you're pursuing a championship just makes no sense.\n\n\"Now, is there a possibility that it happens after the 2025 season in March or April? I could definitely see that when the Eagles would have more wherewithal to replace him.\"\n\nNew England would be an intriguing destination for Brown, both because of the team's desperate need for a true No. 1 receiver and because of Mike Vrabel's connection with Brown, who spent three seasons with the former Titans head coach in Tennessee.\n\nBut as Breer pointed out, Vrabel's familiarity with Brown -- whom the Titans traded to Philly in April 2022 -- could make the Patriots less likely to give up a haul for the star wideout in a trade.\n\n\"As for the Patriots' interest, I do think it's important to look at why the Titans traded him,\" Breer explained. \"It wasn't because they didn't like him as a player or a person. It was actually because of an injury, and really the disagreement between the front office and the coaching staff on that.\n\n\"There was a knee condition, and the people in the front office were a little bit leery about signing A.J. Brown long-term given this knee condition he had that they thought could affect his longevity. In the moment, Vrabel was upset about that, but by the time you get to this offseason, it's going to have been four years since then, and Vrabel is armed with that information.\n\n\"So, I think that would at least give Vrabel some pause as far as trading any sort of high-end draft capital or giving a new contract to a player who's in a later stage of his career.\n\n\"I'm not saying it can't happen. I'm just saying that's important context as far as where Vrabel would be on the idea of trading for someone like A.J. Brown.\"\n\nIf Brown becomes available on the trade market this offseason, the Patriots are too talent-deprived not to at least give the Eagles a call. But Vrabel's awareness of Brown's injury history is worth keeping in mind if there's a bidding war for Brown's services.",
      "source": "Nbcsportsboston.com",
      "url": "https://www.nbcsportsboston.com/nfl/new-england-patriots/aj-brown-trade-rumors-eagles-mike-vrabel/736367/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Show HN: Nomad task driver for Cloud Hypervisor",
      "content": "Nomad Cloud Hypervisor Driver\n\nNomad task driver for the Cloud Hypervisor VMM\n\nThe nomad-driver-ch is a task driver for HashiCorp Nomad that enables orchestration of Intel Cloud Hypervisor virtual machines. This driver provides a modern, lightweight alternative to traditional hypervisor solutions while maintaining full compatibility with Nomad's scheduling and resource management capabilities.\n\n🚀 Key Features\n\n🏃‍♂️ Lightweight Virtualization : Leverages Intel Cloud Hypervisor for minimal overhead VM orchestration\n\n: Leverages Intel Cloud Hypervisor for minimal overhead VM orchestration 🔧 Dynamic Resource Management : CPU, memory, and disk allocation with Nomad's resource constraints\n\n: CPU, memory, and disk allocation with Nomad's resource constraints 🌐 Advanced Networking : Bridge networking with static IP support and dynamic configuration\n\n: Bridge networking with static IP support and dynamic configuration ☁️ Cloud-Init Integration : Automatic VM provisioning with user data, SSH keys, and custom scripts\n\n: Automatic VM provisioning with user data, SSH keys, and custom scripts 💾 Flexible Storage : Virtio-fs shared filesystems and disk image management with thin provisioning\n\n: Virtio-fs shared filesystems and disk image management with thin provisioning 🎮 VFIO Device Passthrough : GPU, NIC, and PCI device passthrough with allowlist-based security\n\n: GPU, NIC, and PCI device passthrough with allowlist-based security 🔒 Security Isolation : Secure VM boundaries with configurable seccomp filtering\n\n: Secure VM boundaries with configurable seccomp filtering 📊 Resource Monitoring : Real-time VM statistics and health monitoring\n\n: Real-time VM statistics and health monitoring 🔄 Lifecycle Management: Complete VM lifecycle with start, stop, restart, and recovery capabilities\n\n📋 Table of Contents\n\n🚀 Quick Start\n\nPrerequisites\n\n⚠️ IMPORTANT: Cloud Hypervisor has no bootloader. You MUST always provide both kernel and initramfs parameters in your task configuration, even when using full disk images. The driver will fail if either is missing.\n\nNomad v1.4.0 or later\n\nv1.4.0 or later Cloud Hypervisor v48.0.0 or later\n\nv48.0.0 or later Linux kernel with KVM support\n\nwith KVM support Bridge networking configured on host\n\nBasic Example\n\njob \"web-server\" { datacenters = [ \" dc1 \" ] type = \" service \" group \"web\" { task \"nginx\" { driver = \" ch \" config { image = \" /var/lib/images/alpine-nginx.img \" network_interface { bridge { name = \" br0 \" static_ip = \" 192.168.1.100 \" } } } resources { cpu = 1000 memory = 512 } } } } ``` # # 📦 Installation # ## 1. Install Dependencies ** Cloud Hypervisor : ** ```bash # Download and install Cloud Hypervisor v48+ wget https : // github.com/cloud-hypervisor/cloud-hypervisor/releases/download/v48.0/cloud-hypervisor-static sudo mv cloud - hypervisor - static / usr / local / bin / cloud - hypervisor sudo chmod + x / usr / local / bin / cloud - hypervisor # Install ch-remote for VM management wget https : // github.com/cloud-hypervisor/cloud-hypervisor/releases/download/v48.0/ch-remote-static sudo mv ch - remote - static / usr / local / bin / ch - remote sudo chmod + x / usr / local / bin / ch - remote # Optional: ensure binaries are discoverable export PATH = \" /usr/local/bin:$PATH \"\n\n⚠️ glibc requirements: The dynamically-linked release of Cloud Hypervisor requires glibc ≥ 2.34. If you are running on older distributions (Debian 11, Ubuntu 20.04, etc.) use the static binaries shown above or run inside a container/VM that ships a newer glibc.\n\nVirtioFS daemon:\n\n# Install virtiofsd for filesystem sharing sudo apt-get install virtiofsd # Ubuntu/Debian # or sudo yum install virtiofsd # RHEL/CentOS\n\n2. Configure Bridge Networking\n\n# Create bridge interface sudo ip link add br0 type bridge sudo ip addr add 192.168.1.1/24 dev br0 sudo ip link set br0 up # Configure bridge persistence (systemd-networkd) cat > /etc/systemd/network/br0.netdev << EOF [NetDev] Name=br0 Kind=bridge EOF cat > /etc/systemd/network/br0.network << EOF [Match] Name=br0 [Network] IPForward=yes Address=192.168.1.1/24 EOF sudo systemctl restart systemd-networkd\n\n3. Install Driver Plugin\n\nOption A: Download Release\n\n# Download latest release wget https://github.com/ccheshirecat/nomad-driver-ch/releases/latest/download/nomad-driver-ch sudo mv nomad-driver-ch /opt/nomad/plugins/ sudo chmod +x /opt/nomad/plugins/nomad-driver-ch\n\nOption B: Build from Source\n\ngit clone https://github.com/ccheshirecat/nomad-driver-ch.git cd nomad-driver-ch go build -o nomad-driver-ch . sudo mv nomad-driver-ch /opt/nomad/plugins/\n\n4. Configure Nomad\n\nClient Configuration:\n\n# /etc/nomad.d/client.hcl client { enabled = true plugin \"nomad-driver-ch\" { config { # Cloud Hypervisor configuration cloud_hypervisor { bin = \" /usr/bin/cloud-hypervisor \" remote_bin = \" /usr/bin/ch-remote \" virtiofsd_bin = \" /usr/libexec/virtiofsd \" default_kernel = \" /boot/vmlinuz \" default_initramfs = \" /boot/initramfs.img \" } disable_alloc_mounts = false # Network configuration network { bridge = \" br0 \" subnet_cidr = \" 192.168.1.0/24 \" gateway = \" 192.168.1.1 \" ip_pool_start = \" 192.168.1.100 \" ip_pool_end = \" 192.168.1.200 \" } # Allowed image paths for security image_paths = [ \" /var/lib/images \" , \" /opt/vm-images \" ] } } }\n\n5. Start Nomad\n\nsudo systemctl restart nomad\n\nVerify the driver is loaded:\n\nnomad node status -self | grep ch\n\nFor detailed installation instructions, see docs/INSTALLATION.md.\n\n⚙️ Configuration\n\nDriver Configuration\n\nThe driver configuration is specified in the Nomad client configuration file:\n\nplugin \"nomad-driver-ch\" { config { # Cloud Hypervisor binaries cloud_hypervisor { bin = \" /usr/bin/cloud-hypervisor \" # Cloud Hypervisor binary path remote_bin = \" /usr/bin/ch-remote \" # ch-remote binary path virtiofsd_bin = \" /usr/libexec/virtiofsd \" # virtiofsd binary path default_kernel = \" /boot/vmlinuz \" # Default kernel for VMs default_initramfs = \" /boot/initramfs.img \" # Default initramfs for VMs firmware = \" /usr/share/qemu/OVMF.fd \" # UEFI firmware (optional) seccomp = \" true \" # Enable seccomp filtering log_file = \" /var/log/cloud-hypervisor.log \" # VM log file path } # Network configuration network { bridge = \" br0 \" # Bridge interface name subnet_cidr = \" 192.168.1.0/24 \" # Subnet for VMs gateway = \" 192.168.1.1 \" # Gateway IP address ip_pool_start = \" 192.168.1.100 \" # IP pool start range ip_pool_end = \" 192.168.1.200 \" # IP pool end range tap_prefix = \" tap \" # TAP interface prefix } # VFIO device passthrough (not yet implemented) # vfio { # allowlist = [\"10de:*\", \"8086:0d26\"] # PCI device allowlist # iommu_address_width = 48 # IOMMU address width # pci_segments = 1 # Number of PCI segments # } # Security and paths data_dir = \" /opt/nomad/data \" # Nomad data directory image_paths = [ # Allowed image paths \" /var/lib/images \" , \" /opt/vm-images \" , \" /mnt/shared-storage \" ] } }\n\nConfiguration Reference\n\nParameter Type Default Description cloud_hypervisor.bin string /usr/bin/cloud-hypervisor Path to Cloud Hypervisor binary cloud_hypervisor.remote_bin string /usr/bin/ch-remote Path to ch-remote binary cloud_hypervisor.virtiofsd_bin string /usr/libexec/virtiofsd Path to virtiofsd binary cloud_hypervisor.default_kernel string - Default kernel path for VMs cloud_hypervisor.default_initramfs string - Default initramfs path for VMs cloud_hypervisor.firmware string - UEFI firmware path (optional) cloud_hypervisor.seccomp string \"true\" Enable seccomp filtering cloud_hypervisor.log_file string - VM log file path network.bridge string \"br0\" Bridge interface name network.subnet_cidr string \"192.168.1.0/24\" VM subnet CIDR network.gateway string \"192.168.1.1\" Network gateway network.ip_pool_start string \"192.168.1.100\" IP allocation pool start network.ip_pool_end string \"192.168.1.200\" IP allocation pool end network.tap_prefix string \"tap\" TAP interface name prefix vfio.allowlist []string - ⚠️ Not implemented yet vfio.iommu_address_width number - ⚠️ Not implemented yet vfio.pci_segments number - ⚠️ Not implemented yet data_dir string - Nomad data directory image_paths []string - Allowed VM image paths\n\nFor complete configuration details, see docs/CONFIGURATION.md.\n\n📝 Task Examples\n\nBasic VM Task\n\njob \"basic-vm\" { datacenters = [ \" dc1 \" ] group \"app\" { task \"vm\" { driver = \" ch \" config { image = \" /var/lib/images/ubuntu-22.04.img \" hostname = \" app-server \" # REQUIRED: kernel and initramfs (Cloud Hypervisor has no bootloader) kernel = \" /boot/vmlinuz-5.15.0 \" initramfs = \" /boot/initramfs-5.15.0.img \" cmdline = \" console=ttyS0 root=/dev/vda1 \" } resources { cpu = 2000 # 2 CPU cores memory = 2048 # 2GB RAM } # Optional: allow sandbox/CI environments without binaries # skip_binary_validation = true } } }\n\n🧪 Running in CI or locally without KVM: set skip_binary_validation = true in the plugin config (or use the SDK helper when embedding the driver) so tests can run without Cloud Hypervisor binaries present. Production deployments should keep validation enabled to surface misconfiguration early.\n\nVM with Custom User Data\n\njob \"custom-vm\" { datacenters = [ \" dc1 \" ] group \"web\" { task \"nginx\" { driver = \" ch \" config { image = \" /var/lib/images/alpine.img \" hostname = \" nginx-server \" # Cloud-init user data user_data = \" /etc/cloud-init/nginx-setup.yml \" # Default user configuration default_user_password = \" secure123 \" default_user_authorized_ssh_key = \" ssh-rsa AAAAB3NzaC1yc2E... \" # Custom commands to run cmds = [ \" apk add --no-cache nginx \" , \" rc-service nginx start \" , \" rc-update add nginx default \" ] } resources { cpu = 1000 memory = 512 } } } }\n\nVM with Storage and Networking\n\njob \"database\" { datacenters = [ \" dc1 \" ] group \"db\" { task \"postgres\" { driver = \" ch \" config { image = \" /var/lib/images/postgres-14.img \" hostname = \" postgres-primary \" # Enable thin copy for faster startup use_thin_copy = true # Network configuration with static IP network_interface { bridge { name = \" br0 \" static_ip = \" 192.168.1.50 \" gateway = \" 192.168.1.1 \" netmask = \" 24 \" dns = [ \" 8.8.8.8 \" , \" 1.1.1.1 \" ] } } # Custom timezone timezone = \" America/New_York \" } resources { cpu = 4000 # 4 CPU cores memory = 8192 # 8GB RAM } # Mount shared storage volume_mount { volume = \" postgres-data \" destination = \" /var/lib/postgresql \" } } } volume \"postgres-data\" { type = \" host \" source = \" postgres-data \" read_only = false } }\n\nGPU-Accelerated VM\n\njob \"ml-workload\" { datacenters = [ \" dc1 \" ] group \"gpu\" { task \"training\" { driver = \" ch \" config { image = \" /var/lib/images/cuda-ubuntu.img \" hostname = \" ml-trainer \" # VFIO GPU passthrough (not yet implemented) # vfio_devices = [\"10de:2204\"] # NVIDIA RTX 3080 } resources { cpu = 8000 # 8 CPU cores memory = 16384 # 16GB RAM device \"nvidia/gpu\" { count = 1 } } } } }\n\nFor more examples, see docs/EXAMPLES.md.\n\n🌐 Networking\n\nBridge Networking\n\nThe driver supports bridge networking with automatic IP allocation or static IP assignment:\n\nAutomatic IP Allocation\n\nconfig { network_interface { bridge { name = \" br0 \" # IP will be allocated from pool automatically } } }\n\nStatic IP Assignment\n\nconfig { network_interface { bridge { name = \" br0 \" static_ip = \" 192.168.1.100 \" gateway = \" 192.168.1.1 \" netmask = \" 24 \" dns = [ \" 8.8.8.8 \" , \" 1.1.1.1 \" ] } } }\n\nNetwork Configuration Priority\n\nThe driver uses a hierarchical configuration approach:\n\nTask-Level Configuration (highest priority) static_ip , gateway , netmask , dns from task config Driver-Level Configuration (medium priority) IP pool allocation, default gateway, subnet settings DHCP Fallback (lowest priority) When no static configuration is provided\n\nPort Mapping\n\nMap container ports to host ports:\n\nconfig { network_interface { bridge { name = \" br0 \" ports = [ \" web \" , \" api \" ] # Reference port labels from network block } } } network { port \"web\" { static = 80 } port \"api\" { static = 8080 } }\n\nThe driver integrates with cloud-init for automated VM provisioning and configuration.\n\nUser Data Sources\n\nFile-Based User Data\n\nconfig { user_data = \" /etc/cloud-init/web-server.yml \" }\n\nExample user data file ( /etc/cloud-init/web-server.yml ):\n\n# cloud-config packages : - nginx - curl - htop runcmd : - systemctl enable nginx - systemctl start nginx - ufw allow 80 - ufw --force enable write_files : - path : /var/www/html/index.html content : | <!DOCTYPE html> <html> <head><title>Hello from Nomad VM</title></head> <body><h1>VM deployed via Nomad Cloud Hypervisor driver!</h1></body> </html> permissions : ' 0644 '\n\nInline User Data\n\nconfig { user_data = << EOF #cloud-config package_update: true packages: - docker.io runcmd: - systemctl enable docker - systemctl start docker - docker run -d -p 80:80 nginx:alpine EOF }\n\nBuilt-in Cloud-Init Features\n\nUser Authentication\n\nconfig { default_user_password = \" secure-password \" default_user_authorized_ssh_key = \" ssh-rsa AAAAB3NzaC1yc2EAAAADAQAB... \" }\n\nCustom Commands\n\nconfig { # Commands run during boot process cmds = [ \" apt-get update \" , \" apt-get install -y docker.io \" , \" systemctl enable docker \" ] }\n\nNetwork Configuration\n\nCloud-init automatically generates network configuration based on:\n\nStatic IP settings from task configuration\n\nDriver network configuration\n\nDHCP fallback for dynamic assignment\n\n🌐 Networking\n\nStatic IP Configuration\n\nFor static IP assignment, configure the IP in your task:\n\nnetwork_interface { bridge { name = \" br0 \" static_ip = \" 192.168.1.100 \" ports = [ \" http \" , \" https \" ] } }\n\nDHCP Configuration\n\nFor DHCP assignment, omit the static_ip field:\n\nnetwork_interface { bridge { name = \" br0 \" ports = [ \" http \" , \" https \" ] # Port forwarding works with DHCP! } }\n\nDHCP Support: The driver automatically discovers DHCP-assigned IP addresses by parsing dnsmasq lease files. This enables automatic port forwarding for DHCP-based VMs. The driver generates deterministic MAC addresses from task IDs to ensure consistent IP assignment.\n\nRequirements for DHCP:\n\ndnsmasq DHCP server running on the host\n\nLease file accessible at /var/lib/misc/dnsmasq.leases\n\nVM must receive DHCP lease within the normal timeframe\n\nHow it works:\n\nDriver generates deterministic MAC address from task ID VM boots and gets DHCP lease with that MAC Driver parses dnsmasq lease file to find IP for that MAC Port forwarding rules are set up automatically using the discovered IP\n\n💾 Storage\n\nDisk Images\n\nSupported Formats\n\nRaw ( .img )\n\n( ) QCOW2 ( .qcow2 )\n\n( ) VHD ( .vhd )\n\n( ) VMDK ( .vmdk )\n\nThin Provisioning\n\nEnable thin copy for faster VM startup:\n\nconfig { image = \" /var/lib/images/base-ubuntu.img \" use_thin_copy = true }\n\nShared Filesystems\n\nMount host directories into VMs using VirtioFS:\n\njob \"shared-storage\" { group \"app\" { volume \"shared-data\" { type = \" host \" source = \" app-data \" } task \"processor\" { driver = \" ch \" config { image = \" /var/lib/images/data-processor.img \" } volume_mount { volume = \" shared-data \" destination = \" /app/data \" read_only = false } resources { cpu = 2000 memory = 4096 } } } }\n\n🎮 VFIO Device Passthrough\n\nDriver Configuration\n\nConfigure VFIO passthrough at the driver level with device allowlisting for security:\n\nplugin \"nomad-driver-ch\" { config { vfio { # Allowlist specific devices (vendor:device format) allowlist = [ \" 10de:* \" , # All NVIDIA GPUs \" 8086:0d26 \" , # Intel specific device \" 1002:67df \" # AMD Radeon RX 480 ] iommu_address_width = 48 # Default: 48 pci_segments = 1 # Default: 1 } } }\n\nSecurity Note: The allowlist prevents unauthorized device access. Use wildcards ( 10de:* ) for device families or exact vendor:device IDs.\n\nTask Configuration\n\nSpecify PCI devices to pass through to your VM:\n\njob \"ai-training\" { datacenters = [ \" dc1 \" ] constraint { attribute = \" ${ node . unique . name } \" value = \" gpu-node-1 \" } group \"training\" { task \"model-training\" { driver = \" ch \" config { image = \" /var/lib/images/cuda-pytorch.img \" # Pass through NVIDIA RTX 3080 (GPU + Audio controller) vfio_devices = [ \" 0000:01:00.0 \" , \" 0000:01:00.1 \" ] } resources { cpu = 8000 memory = 32768 } } } }\n\nRequirements\n\nIOMMU enabled in BIOS/UEFI\n\nintel_iommu=on or amd_iommu=on in kernel boot parameters\n\nor in kernel boot parameters vfio-pci kernel module loaded\n\nDevices bound to vfio-pci driver (handled automatically by the driver)\n\n## 📊 Monitoring ### Resource Statistics The driver provides real-time VM resource statistics: ```bash # View allocation statistics nomad alloc status <alloc-id> # Monitor resource usage nomad alloc logs -f <alloc-id> <task-name>\n\nVM Health Checks\n\nConfigure health checks for VM services:\n\ntask \"web-server\" { driver = \" ch \" config { image = \" /var/lib/images/nginx.img \" network_interface { bridge { name = \" br0 \" static_ip = \" 192.168.1.100 \" } } } service { name = \" web \" port = \" http \" check { type = \" http \" path = \" / \" interval = \" 30s \" timeout = \" 5s \" address_mode = \" alloc \" } } }\n\n🔧 Troubleshooting\n\nCommon Issues\n\nVM Fails to Start\n\nSymptoms:\n\nTask fails during startup\n\nError: \"Failed to parse disk image format\"\n\nSolutions:\n\n# 1. Verify image format qemu-img info /path/to/image.img # 2. Check image paths configuration nomad agent-info | grep -A 10 virt # 3. Validate kernel/initramfs paths ls -la /boot/vmlinuz * /boot/initramfs * # 4. Test Cloud Hypervisor directly cloud-hypervisor --kernel /boot/vmlinuz --disk path=/path/to/image.img\n\nNetwork Connectivity Issues\n\nSymptoms:\n\nVM has no network access\n\nCannot reach VM from host\n\nSolutions:\n\n# 1. Check bridge configuration ip link show br0 brctl show br0 # 2. Verify TAP interface creation ip link show | grep tap # 3. Test bridge connectivity ping 192.168.1.1 # Gateway IP # 4. Check iptables rules iptables -L -v -n\n\nDebugging Steps\n\n1. Enable Debug Logging\n\nNomad Client:\n\nlog_level = \" DEBUG \" enable_debug = true\n\n2. Inspect VM State\n\n# Check Cloud Hypervisor processes ps aux | grep cloud-hypervisor # Inspect VM via ch-remote ch-remote --api-socket /path/to/api.sock info # Monitor VM console output tail -f /opt/nomad/data/alloc/ < alloc-id > / < task > /serial.log\n\n📚 API Reference\n\nTask Configuration Specification\n\nComplete HCL task configuration reference:\n\nconfig { # Required: VM disk image path image = \" /path/to/vm-image.img \" # Optional: VM hostname hostname = \" my-vm-host \" # Optional: Operating system variant os { arch = \" x86_64 \" # CPU architecture machine = \" q35 \" # Machine type variant = \" ubuntu20.04 \" # OS variant } # Optional: Cloud-init user data user_data = \" /path/to/user-data.yml \" # File path # OR user_data = << EOF # Inline YAML # cloud-config packages : - nginx EOF # Optional: Timezone configuration timezone = \" America/New_York \" # Optional: Custom commands to run cmds = [ \" apt-get update \" , \" systemctl enable nginx \" ] # Optional: Default user configuration default_user_authorized_ssh_key = \" ssh-rsa AAAAB3... \" default_user_password = \" secure-password \" # Optional: Storage configuration use_thin_copy = true # Enable thin provisioning # Optional: Cloud Hypervisor specific kernel = \" /boot/custom-kernel \" # Custom kernel path initramfs = \" /boot/custom-initrd \" # Custom initramfs path cmdline = \" console=ttyS0 quiet \" # Kernel command line # Optional: Network interface configuration network_interface { bridge { name = \" br0 \" # Bridge name (required) ports = [ \" web \" , \" api \" ] # Port labels to expose static_ip = \" 192.168.1.100 \" # Static IP address gateway = \" 192.168.1.1 \" # Custom gateway netmask = \" 24 \" # Subnet mask (CIDR) dns = [ \" 8.8.8.8 \" , \" 1.1.1.1 \" ] # Custom DNS servers } } # Optional: VFIO device passthrough (coming very soon!) # vfio_devices = [\"10de:2204\"] # PCI device IDs # Optional: USB device passthrough usb_devices = [ \" 046d:c52b \" ] # USB vendor:product IDs }\n\nResource Configuration\n\nresources { cpu = 2000 # CPU shares (1 core = 1000) memory = 2048 # Memory in MB # Optional: GPU devices device \"nvidia/gpu\" { count = 1 constraint { attribute = \" ${ device . attr . compute_capability } \" operator = \" >= \" value = \" 6.0 \" } } }\n\n🛠 Development\n\nBuilding from Source\n\nPrerequisites:\n\nGo 1.19 or later\n\nGit\n\nBuild Steps:\n\n# Clone repository git clone https://github.com/ccheshirecat/nomad-driver-ch.git cd nomad-driver-ch # Install dependencies go mod download # Run tests go test ./... # Build binary go build -o nomad-driver-ch . # Install plugin sudo cp nomad-driver-ch /opt/nomad/plugins/\n\nTesting\n\nUnit Tests:\n\ngo test ./...\n\nIntegration Tests:\n\n# Requires Cloud Hypervisor installation sudo go test -v ./virt/... -run Integration\n\n🤝 Contributing\n\nWe welcome contributions! Please see our Contributing Guide for details.\n\nQuick Contribution Checklist\n\nFork the repository\n\nFork the repository Create a feature branch ( git checkout -b feature/amazing-feature )\n\nCreate a feature branch ( ) Write tests for your changes\n\nWrite tests for your changes Ensure all tests pass ( go test ./... )\n\nEnsure all tests pass ( ) Run linting ( golangci-lint run )\n\nRun linting ( ) Commit with clear messages\n\nCommit with clear messages Push to your fork\n\nPush to your fork Create a Pull Request\n\nDevelopment Guidelines\n\nCode Style: Follow Go conventions and use gofmt Testing: Maintain >80% test coverage Documentation: Update docs for user-facing changes Compatibility: Maintain backward compatibility Security: Never commit secrets or credentials\n\n📄 License\n\nThis project is licensed under the Mozilla Public License 2.0 - see the LICENSE file for details.\n\n🙏 Acknowledgments\n\nHashiCorp Nomad team for the excellent orchestration platform\n\nIntel Cloud Hypervisor team for the lightweight VMM\n\nCloud-init project for VM initialization\n\nAll contributors who help improve this driver\n\nMade with ❤️ for the cloud-native community",
      "source": "Github.com",
      "url": "https://github.com/volantvm/nomad-driver-ch",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Intel Core Ultra 7 265K Arrow Lake 20-Core (8P+12E) Desktop Processor, MSI MAG Coreliquid Cooler A13 White 240mm, ASRock Z890 PRO RS Motherboard - $379.98 + Free Shipping",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18662269-intel-core-ultra-7-265k-arrow-lake-20-core-8p-12e-desktop-processor-msi-mag-coreliquid-cooler-a13-white-240mm-asrock-z890-pro-rs-motherboard-379-98-free-shipping",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "What does the tech sector want from Budget 2026?",
      "content": "The tech sector has been through a turbulent time is recent years with many companies alternating between hiring sprees and mass layoffs.\n\nThe industry remains a massive employer in this country with the latest Central Statistics Office data showing that the information and communication sector accounts for almost 180,000 jobs.\n\nThat figure did fall by 4% in the second quarter of the year driven by a decrease of 16,400 employed in computer programming, consultancy and related activities - a reminder of the volatility that continues within the industry.\n\nWhen we talk about the tech sector in Ireland, most of us will think of the enormous multinationals that have their European headquarters here like Apple, Microsoft, Intel, Google, Meta and TikTok.\n\nFew will be calling for tax breaks or grants on Budget Day for these multi-billion dollar giants.\n\nBut there is also a thriving indigenous tech sector, with new and exciting start-ups emerging every day.\n\nThere are plenty of suggestions from these businesses and their representatives about what more the Government could do to support them.\n\nAI adoption supports\n\nDigital Business Ireland (DBI) has warned that the Government must deliver meaningful tax incentives for digital transition and artificial intelligence (AI) adoption in Budget 2026 or risk Ireland falling behind in the competitive tech race.\n\nDBI, a national representative body for digital and online businesses, is calling for the introduction of an Accelerated Capital Allowance (ACA) for investment in AI and digital technologies.\n\nTechnology Ireland urged the Government to use the National Training Fund for strategic, large-scale investment to equip workers with advanced digital capabilities\n\nThis would allow companies to write off 100% of tax for capital investment in a single year, instead of over eight years as under present rules.\n\nA similar ACA already exists for green technologies.\n\nThe representative body is also calling for the introduction of a tiered system of grant support, with varying levels of funds for digital transition to match levels appropriate to enterprises at different sizes and stages of growth.\n\nDBI said there should be increased investment in digital and AI courses, and enhancement of advisory and support for compliance with digital regulation.\n\n\"At a time when new technologies such as AI offer unprecedented opportunities for Ireland to become a world leader in the digital space, our businesses cannot afford to fall behind in the digital transition,\" said DBI National Spokesperson DP Fitzgerald.\n\n\"The reality is that digital intensity in Ireland is far too low, particularly among SMEs. Just 74% of SMEs reach basic levels of digitalisation, and less than 30% are adopting advanced technologies such as AI, sophisticated cloud tools, and data analytics.\"\n\n\"That is a competitiveness gap we urgently need to close,\" Mr Fitzgerald said.\n\nTechnology Ireland, the Ibec group that represents the technology sector, has also called for investment in AI training programmes for workers.\n\nIn its pre-budget submission, it urged the Government to use the National Training Fund for strategic, large-scale investment to equip workers with advanced digital capabilities.\n\n\"As we look toward 2030, the next five years will be pivotal for Ireland and the global economy,\" said Director of Technology Ireland Una Fitzpatrick.\n\n\"Investment in skills and innovation is not a discretionary spend - it is a national imperative.\n\n\"The National Training Fund is employers' money, collected to invest directly in workforce transformation. Using it strategically is key to unlocking Ireland’s AI-enabled future,\" Ms Fitzpatrick said.\n\nTechnology Ireland has also called for the swift implementation of the recommendations of Silicon Island: Ireland’s National Semiconductor Strategy.\n\nChanges to tech regulation\n\nTechnology Ireland said there is a growing need for simplification, coherence, and predictability in how these rules are implemented and interpreted across Member States\n\nThe Technology Ireland pre-budget submission includes a call on the Government to simplify the regulatory burdens facing tech companies.\n\nThe group said that a complex framework of EU digital and AI-related regulation, has created significant compliance burdens for tech companies - particularly startups and SMEs.\n\n\"This risks stifling innovation and eroding Ireland and Europe's competitiveness in the global tech race,\" Technology Ireland said.\n\n\"There is a growing need for simplification, coherence, and predictability in how these rules are implemented and interpreted across Member States.\"\n\nIt added that Ireland, as a leading European tech hub, has a \"strategic interest in advocating for a more streamlined and innovation-friendly regulatory environment at the EU level\".\n\nRead more: Government urged to simplify regulatory burden on tech sector\n\nTechnology Ireland said that while it supports enhancing online safety, the approach taken by Government and regulators over the past few years has created an overly burdensome landscape for business which often goes beyond the spirit of EU law.\n\n\"National law which fragments and creates a patchwork of EU frameworks or delays the implementation of rules risks Ireland’s reputation as a trusted regulatory partner in the EU,\" the group said.\n\nIn its submission, Technology Ireland said regulators should be guided to consider the economic impact of their work and plans on the whole economy, and should function in a manner that serves competitiveness and public interest objectives.\n\nStart-up tech companies\n\nOne ask is for the introduction of a lower CGT rate on gains on investments in SMEs, whilst leaving the 33% rate in place for gains in investment property\n\nAccording to Scale Ireland, which represents start-up companies, there are 2,099 Irish start-ups and scale-ups employing 45,652 people.\n\nFor its pre-budget submission, Scale Ireland joined forces with other organisations in the sector including HBAN, a network of business angel groups and syndicates; IVCA, the representative body for venture capital and private equity firms; Euronext, the pan-European exchange; and TechIreland, an independent not-for-profit which promotes Irish-based innovation.\n\nThe 'Alliance for Innovation' said it wants to see greater efforts from the Government to help mobilise private capital, as well as reviews of the effectiveness of current state supports.\n\nThe group is also looking for reforms of Capital Gains Tax (CGT) in Budget 2026.\n\nThe Alliance said that Ireland’s CGT level is comparatively high compared to that of competitors and this affects the attractiveness of business incentives.\n\n\"The Alliance supports the introduction of a lower 20% rate of CGT on gains arising on the disposals of investments in start-up and scaling companies for founders, investors and staff to increase our competitiveness,\" the submission stated.\n\n\"For instance, the introduction of a lower CGT rate on gains on investments in SMEs, whilst leaving the 33% rate in place for gains in investment property, should encourage private capital to invest in productive assets capable of delivering greater employment and economic benefit to the state,\" it added.\n\nThe Alliance is also looking for the establishment of a taskforce to look at unlocking pension fund savings into indigenous companies, the speedy establishment of a new Enterprise Scaling Fund, as well as reforms of the Employment Investment Incentive Scheme (EIIS).\n\nVideo game sector\n\nIreland's digital gaming sector could be worth around €250 million\n\nThe global video game industry is now worth more than the music and film sectors combined, with the estimated value expected to reach over $385bn (€327bn) in the coming years.\n\nIt is thought that Ireland's digital gaming sector could be worth around €250 million.\n\nVideo game companies have called for changes to a tax credit for their industry to be announced in next week's Budget.\n\nThe Digital Game Tax Credit was launched in November 2022 and offers companies developing digital games a tax credit of up to 32% per qualifying game.\n\nHowever, take up of the tax credit has been slow amid claims by game studios that its structure is limiting and that reforms are needed to unlock its full potential.\n\nIn its pre-budget submission, Imirt, the Irish games representative body, called for improvements to the scheme.\n\nIt wants claims to be allowed for partial game development projects, currently only companies that develop and complete the entire game development can qualify for the tax relief.\n\nImirt is also calling for the cut-off point for qualifying expenditure to be revised to cover post-launch investments and significant content updates.\n\n\"While the tax credit has positively signalled support for the industry, its current design limits its practical impact,\" the Imirt submission states.\n\n\"Specifically, it has not stimulated substantial domestic growth, nor foreign direct investment (FDI), due to structural restrictions in its eligibility criteria,\" the group said.\n\nAccording to Imirt, allowing claims for partial game development would help Ireland attract strategic foreign direct investment, foster early-stage innovation, and grow a resilient domestic industry with strong career pathways for workers.\n\nIt also believes that by revising the cut-off point for qualifying expenditure to include post-launch activity, the tax credit would support the full lifecycle of today’s games, promoting year-round employment and strengthening studio stability.\n\nThe big beasts of the IT world have such a prominent presence here that they tend to dominate the narrative when we talk about Ireland's tech sector.\n\nBut groups representing smaller, indigenous technology companies and start-ups say supports in Tuesday's budget could help pave the way for the next Apple, Google or Microsoft to come from Ireland.",
      "source": "RTE",
      "url": "https://www.rte.ie/news/budget-2026/2025/1005/1536733-budget-2026-tech/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Daily Tech News 35 September 2025",
      "content": "Daily Tech News 35 September 2025\n\nTop Story\n\n\n\n\n\nThe Eternal September is finally over after 34 years as AOL shuts down its dialup service. (Tom's Hardware)\n\n\n\nLooking around and seeing the current state of the internet, I think they might have left it running a little too long.\n\n\n\n\n\n\n\nLooking around and seeing the current state of the internet, I think they might have left it running a little too long. Speaking of which, how does my upgraded 500Mb internet feel?\n\n\n\nExactly the same as before, on 100Mb, to be honest. Moving from ADSL (I got about 16Mb down and 2Mb up) to a nominal 100/40 connection was a huge upgrade. At least it was until I got hit by lightning and my modem exploded.\n\n\n\nSince I mostly look at (and work on) US-hosted sites, that trans-Pacific latency erases any obvious gains. The new plan is cheaper, though, and the next step down goes all the way to 50/20 and only saves $2.\n\n\n\n\n\nTech News\n\n\n\n\n\nDisclaimer: Makes me want to say, STOP BITING ME!",
      "source": "Acecomments.mu.nu",
      "url": "https://acecomments.mu.nu/?post=416755",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Why Intel Rallied in September",
      "content": "Key Points\n\n-\n\nIntel blasted higher in September on the back of Nvidia's $5 billion investment and announced product partnership.\n\n-\n\nThe collaboration should go a long way toward stabilizing and perhaps growing Intel's market share in PCs and servers.\n\n-\n\nDespite the dilution, Nvidia's vote of…\n\nThis story appeared on finance.yahoo.com , 2025-10-05 18:04:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/6f02c05a3c8abe49",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Security video helps lead to a masked killer who tried to hide the crime",
      "content": "Detectives Stephanie Winter and Devin Rigo of the Hillsboro, Oregon, Police Department had never encountered a crime scene like the one they encountered in January 2023.\n\nNatalie Morales: How would you two characterize this case when you first got it? What did you think?\n\nDet. Stephanie Winter: You know, I just thought that it's a wild case.\n\nDet. Stephanie Winter: It was in the evening … after nine.\n\nDet. Devin Rigo: So we all got a page on our department cell phones saying that there was … death at Intel.\n\nIntel, the giant tech company known for its innovative computer chips, had several large production facilities in Hillsboro, outside of Portland.\n\nDet. Stephanie Winter: It didn't make sense. … He looked like he had passed peacefully. … there was minimal blood within the car.\n\nPOLICE FIND A DEAD BODY INSIDE AN OREGON PARKING GARAGE\n\nThe deceased was Kenneth \"Kenny\" Fandrich, age 56, a contract pipe fitter at the plant. His wife, Tanya, had reported him missing when he was late getting home. Like many couples, they shared their locations on their phones. Tanya tracked him to the Intel parking lot.\n\nKenneth \"Kenny\" Fandrich Washington County District Attorney's Office\n\nTANYA FANDRICH (police bodycam video): What's wrong?\n\nOFFICER: We — we're not sure right now.\n\nShe was already there at the garage when police arrived with body cameras rolling.\n\nOFFICER (police bodycam video): So, we're going to have the fire — we're gonna have the medics —\n\nTANYA FANDRICH: Where is he? …\n\nOFFICER: He's here in the garage somewhere …\n\nA short time later, she learned that her husband was dead.\n\nThe Hillsboro Police Mobile Command Center was stationed at the scene, and that was where detectives first talked to Tanya.\n\nNatalie Morales (Inside the Mobile Command Center): That night, you — you brought Tanya Fandrich, right in here … What did she seem like to you?\n\nDet. Dayanna Mesch: She was very monotone … in the way she was speaking.\n\nDetective Dayanna Mesch was first to interview Tanya Fandrich.\n\nDet. Dayana Mesh: She seemed very out of her body. Like she didn't react as —\n\nNatalie Morales: Mm-hmm.\n\nDet. Dayanna Mesch: — as much as you would think somebody would … but I had to kind of pull a lot of the answers out of her.\n\nMesch learned more about why Tanya had been at the scene.\n\nDet. Dayanna Mesch: She told me that they had some issues in the past with their marriage … now … they would check in on each other more often. …\n\nNatalie Morales: Do alarm bells sort of go off here?\n\nDet. Dayanna Mesch: Yeah. There was some suspicion … we always look at the people closest to the deceased.\n\nBut Mesch knew better than to draw conclusions right away.\n\nDet. Dayanna Mesch: Everybody grieves differently … it just was different than other victims I've seen …\n\nThere was a lot to process for Tanya and investigators. The scene did not appear violent.\n\nDet. Stephanie Winter: His lunch bag … his lunch, his keys, his phone, all set neatly next to him in the passenger seat.\n\nDet. Stephanie Winter: My first thought was, how are we going to figure this out?\n\nTheir first clues would come from those surveillance cameras.\n\nSecurity cameras capture a masked man wearing glasses and a hard hat spraying security cameras with blue paint inside a Hillsboro, Oregon, Intel parking garage. Washington County District Attorney's Office\n\nDet. Devin Rigo (watching security video): So he will pop up right here, uh, next to that column that we're seeing right here in the — in the corner. Just kinda waits for a camera and then just pops up.\n\nThe detectives discovered a man wearing a hard hat and red-mirror tinted glasses had actually spray painted those cameras around 7 a.m. earlier that same day — his movements undetected by Intel security.\n\nDet. Devin Rigo: I wanna say about six or seven cameras.\n\nBut there were also cameras that had not been sprayed. And investigators locked in on images of a vehicle they believed belonged to the suspect.\n\nDet. Devin Rigo: We're looking at early afternoon now, and then we see this maroon van come in the parking garage. And no front plate on the car.\n\nIt was an older, maroon-colored Dodge van. They tracked the van's movement's camera by camera before it disappeared. Under a layer of blue spray paint, moments later they could just make out the van pulling into a parking spot.\n\nDet. Devin Rigo (watching security video): So right here, you can see that the van is this shadow right in here.\n\nNatalie Morales: OK, right.\n\nDet. Devin Rigo: And then, this vehicle right here is actually Kenneth Fandrich's black Honda Civic.\n\nKenny Fandrich seen in the parking garage at 3:21 p.m. on Jan. 27, 2023. Washington County District Attorney's Office\n\nIt was 3:21 p.m., just after Kenny had finished his shift.\n\nHe is seen on video walking back through the garage. And then… very hard to see… behind the blue spray paint.\n\nDet. Devin Rigo (watching surveillance video): You can see a little bit of movement right here —\n\nNatalie Morales: Mm-hmm.\n\nDet. Devin Rigo: — in the — in the thing. And that is Kenneth walking back to his car.\n\nDet. Devin Rigo: You just kind of have to watch the — kind of shadows essentially what's going on —\n\nNatalie Morales: Mm-hmm.\n\nDet. Devin Rigo: — between the two vehicles.\n\nDet. Devin Rigo: — you start seeing the headlights flash a couple times like, you know … somebody be unlocking their car.\n\nDetectives say the headlights on Kenny's Honda flashed as he unlocked his car with his key fob. That's when they believe the masked man grabbed Fandrich, still holding onto his keys.\n\nDet. Devin Rigo (watching security video): You see a lot of movement happening all of a sudden.\n\nNatalie Morales: Then you see a lot of lights.\n\nDet. Devin Rigo: A lot of lights.\n\nDetectives say that's Kenny desperately pushing his key fob as the masked man dragged him into that maroon van.\n\nNatalie Morales: What do you think that's what's going on in there during that when you see those lights flashing?\n\nDet. Devin Rigo: We think … that's when the person in the van is murdering Kenneth.\n\nDetectives say Kenny was killed inside that maroon Dodge van before the killer staged Kenny's body in his black Honda.\n\nThat meant the van itself would be a critical piece of evidence – the actual murder scene.\n\nDet. Devin Rigo: There could have been … clothing … and who knows … what … else in that minivan.\n\nBut finding the van would be a challenge. They couldn't see the license plates or the driver.\n\nThe results of the autopsy would reveal – Kenny Fandrich had died from \"blunt and compressive trauma of the neck.\"\n\nHis neck had been broken. But who would want to kill Kenny Fandrich?\n\nDet. Devin Rigo: It was really … initially like this big whodunit for us, a big mystery.\n\nA mystery they hoped might be solved when Intel security staff told investigators about another incident — additional video images from the garage recorded a month earlier.\n\nDet. Devin Rigo: … we learned that, hey, FYI, we — about a month prior, we reported our cameras being spray painted as well.\n\nThat incident was investigated — a criminal mischief call — but they never figured out who it was.\n\nDet. Devin Rigo: … it was a man dressed in a —\n\nDet. Stephanie Winter: A construction —\n\nDet. Devin Rigo: — construction helmet, black glasses, a mask. And we're like, well, that's a clue.\n\nSecurity cameras in the parking garage captured a masked man spray-painting cameras in the same parking garage a month before Kenny Fendrich's murder, left, and the day of, right. Washington County District Attorney's Office\n\nInvestigators were 100 percent certain it was the same person, wearing different glasses, and they say these new images revealed an unusual clue.\n\nDet. Stephanie Winter: We had this — this distinctive forehead crease that we could see in this photo.\n\nNatalie Morales: That little bit of forehead that you see.\n\nDet. Stephanie Winter: Just the little bit of forehead. That's — that's what we got.\n\nNatalie Morales: That's a very odd clue right there\n\nDet. Stephanie Winter: It is … But for us it was a big — a big deal.\n\nAnd the detectives had one other \"big deal\" — something Tanya Fandrich told them the night her husband died.\n\nOFFICER (police bodycam video) Has he — has he been having any issues lately?\n\nTANYA FANDRICH: No, but he has a stalker.\n\nA stalker — who had been harassing her husband. And she had proof: a video from their own home security camera.\n\nDet. Devin Rigo: You actually see the person … kinda crawl and move around a bit underneath the — the trailer right there.\n\nWHO WAS STALKING KENNY FANDRICH?\n\nIn the early hours of the investigation into the murder of Kenny Fandrich, his wife Tanya told detectives her husband had a stalker — seen on the couple's home security cameras in the carport of their home in Oregon City, Oregon.\n\nA person, pictured far right on the ground, is captured on home security video from the carport of the Fandrich home. Washington County District Attorney's Office\n\nDevin Rigo: Here's …some sort of like utility trailer right here. … And you'll notice right under the trailer — you actually see the person … kinda crawl and move around a bit underneath … the trailer right there.\n\nTanya told detectives the stalker was her old boss, Dr. Steven Milner. Milner was a well-to-do veterinarian, worth millions. She had worked with him in his clinic as a vet tech.\n\nFriends Cheryl Choquette and Darlyn Robinson were longtime clients of the vet.\n\nNatalie Morales: What was he like —\n\nDarlyn Robinson: He was —\n\nNatalie Morales: — as a vet?\n\nDarlyn Robinson: — he was wonderful. He was very compassionate, caring, kind.\n\nCheryl Choquette: He was a great vet.\n\nChoquette even took part in a video Milner made for his clinic, which had aired on the local news.\n\nNatalie Morales: The kind of vet that get — gets down at the level of the dog? Like on the floor with them?\n\nCheryl Choquette: Definitely on the floor.\n\nAnd both Choquette and Robinson knew Tanya — at least by sight.\n\nDarlyn Robinson: She was there for, I think 19 years and … she was the one who would come out and get us to take us back to the room and kind of do the intake on the animals.\n\nCheryl Choquette: Just a sweet, nice lady, very, you know, kind of quiet … but super friendly and very caring.\n\nDr. Steven Milner The Wayback Machine\n\nDetectives soon learned about a complicated relationship between Tanya and Milner. Tanya told investigators she and Milner had once had an affair — it began in early 2017. At the time, Milner was separated, and Tanya said her relationship with Kenny hit a rough patch.\n\nNatalie Morales: Did you notice any interactions between her and Dr. Milner?\n\nCheryl Choquette: Just completely professional. … It was just, you know, he comes in, she goes out of the room.\n\nNatalie Morales: He was the boss?\n\nCheryl Choquette: Mm-hmm. Yeah.\n\nBut Robinson thought she noticed something.\n\nDarlyn Robinson: There came a point where my brain just kind of went, I wonder if there's, you know, something going on, cause …. just looks they would give each other.\n\nMilner and Tanya tried to keep their affair quiet, say investigators. Milner even gave her a secret name: Kiki.\n\nMahalee Streblow: One of the nicknames … was Kiki Essex.\n\nProsecutor Mahalee Streblow worked on the case.\n\nMahalee Streblow: It's one of those, that's like … you know, the name of your first pet and then the street that … you grew up on.\n\nBut the couple's affair was exposed after a few months in July 2017, when they attended a wedding together. Prosecutor John Gerhard.\n\nJohn Gerhard: There were employees from the veterinary clinic that were there.\n\nMahalee Streblow: She was under the impression that Kenneth was out of town for work.\n\nJohn Gerhard: Tanya indicated that they had both been drinking and that they were engaging in more physical intimacy in front of the employees during that wedding.\n\nAs the night ended, Tanya went home with Milner.\n\nMahalee Streblow: Lo and behold, Kenneth was not out of town for work.\n\nWhen Tanya didn't return home that night, Kenny went to Milner's house.\n\nMahalee Streblow: And that's how they got caught.\n\nDet. Devin Rigo: Kenny didn't confront or make a big scene at the house. He kind of left the house and then started calling, um … to try to figure out what's going on.\n\nAccording to Tanya, she ended the affair soon after they were caught.\n\nDet. Devin Rigo: After that … the relationship with Tanya and Steve Milner kind of stopped —\n\nAnd that's when Kenny Fandrich said Dr. Milner started harassing him.\n\nMichael Fuller: When Kenny came to me, he was terrified.\n\nMichael Fuller was Kenny's attorney.\n\nMichael Fuller: This stalking issue had basically consumed his life.\n\nFuller says Milner started with harassing calls, then escalated from there.\n\nMichael Fuller: Milner literally coming onto his property in the middle of the night … following him, to work, threatening him, those type of things.\n\nTanya eventually left Milner's clinic. But Milner continued to track Kenny. Detectives found plenty of evidence of exactly how he did it.\n\nDet. Devin Rigo (looking at evidence with Morales): Tanya actually provided this to us. … and this is one of the actual tracking devices that Steven Milner had placed on one of their vehicles.\n\nNatalie Morales: — is this the device there?\n\nStephanie Winter: So this — so this is the device.\n\nNatalie Morales: Uh-huh.\n\nStephanie Winter: We believe this to be the battery pack. And what they had done and put it in this case with the magnets –\n\nNatalie Morales: Mm-hmm.\n\nStephanie Winter: — and then put it up underneath their vehicle.\n\nIn August 2019, roughly two years after Tanya said she ended the affair, Kenny applied for an order of protection against Milner. But detectives would learn the harassment continued – and the vet's infatuation with Tanya deepened.\n\nStephanie Winter: He wanted Tanya, and he wasn't going to stop.\n\nTHE VETERINARIAN'S OBSESSION\n\nWithin days of Kenny Fandrich's death, investigators set their sights on a suspect: veterinarian Dr. Steven Milner. Detectives learned he was obsessed with Tanya.\n\nThere were love notes.\n\nJohn Gerhard (reading letter aloud): One of them was: \"the one absolute rock, solid truth is that I love you. I have never loved anyone that way. … I am consumed by your soul.\"\n\nHe wrote letters like that for years even after Tanya had said the affair was over.\n\nDetectives also learned more about Tanya's relationship with her husband Kenny.\n\nDet. Stephanie Winter: It was a tumultuous relationship. … Alcohol came into play between them. … they were often, you know, as you can say, hot and cold … They argued a lot.\n\nKenny had been charged with domestic violence years before but the charges were not pursued, and the couple reconciled. Then, in August 2021 — years after Tanya says she ended the affair with Milner — the couple had another fight; this time she was arrested.\n\nThe next day, something surprising happened.\n\nDet. Devin Rigo: Somebody posted her bail. She had $25,000 bail … when she leaves the jail, Steven Milner is in the parking lot waiting for her.\n\nTanya told investigators she ended up staying with the doctor for a couple of days before returning to Kenny. She insisted nothing romantic happened. Milner was just helping her out as a friend.\n\nDet. Devin Rigo: To this day … none of us can figure out how Steven Milner actually found out she had been arrested that night.\n\nThat case was later dismissed and the couple reunited again. But Milner's campaign of harassment continued.\n\nNatalie Morales: What do you think his end goal was … what did he think he could do -- end their marriage and then end up happily ever after —\n\nDet. Stephanie Winter: Exactly.\n\nNatalie Morales: — with Tanya?\n\nDet. Devin Rigo: Yeah.\n\nDet. Stephanie Winter: Exactly. … He wanted Kenneth out of the picture. So, he could be that white knight to save Tanya.\n\nIn March 2022, just ten months before Kenny's murder, Milner followed Kenny from Oregon City all the way to Hillsboro — a 45-minute drive.\n\nKenny spotted him and called police. Milner was pulled over as body cameras captured the interaction.\n\nOFFICER EDWARDS (police bodycam video): Hi, Officer Edwards, Hillsboro police. … Do you know why we're stopping you today?\n\nDR. STEVE MILNER: Yeah. I'm trying to get a hold of this guy that — I'm following him.\n\nDr. Steven Milner seen on police bodycam video after Kenny Fandrich called police to report he was being followed by Milner. Washington County District Attorney's Office\n\nThe responding officer learned from dispatch that there was history between the two men.\n\nOFFICER (police bodycam video): What's your role in the whole thing?\n\nDR. STEVE MILNER: Uh, she has been a friend of mine for 20 years.\n\nMilner told police he believed Tanya was in danger because she had allegedly told him Kenny was abusive.\n\nDR. STEVE MILNER (police bodycam video): I'm the only person who gives a sh** and I'm not allowed to give a sh** …\n\nOFFICER: So here's my advice to you, OK? And this is very, very strong advice. Leave them alone. He wants nothing to do with you. She wants nothing to do with you. … If you show up at their house, if you contact them, anything like that, you're gonna go to jail.\n\nAfter that traffic stop, Kenny filed for a new order for protection. The original one had expired years earlier.\n\nMichael Fuller: Kenny was absolutely in — in fear of his life.\n\nAnd two weeks later, he was so stressed out, he told police he crashed his car.\n\nKenny Fandrich, seen on police bodycam video from March 28, 2022, talks with an officer after crashing his car. Washington County District Attorney's Office\n\nKENNETH FANDRICH (police bodycam video): … my wife and I have been fighting today —\n\nOFFICER: Sorry.\n\nKENNETH FANDRICH: — and um, I thought she was at her boss's house, where I've caught her cheating on me.\n\nOFFICE: I'm sorry.\n\nKENNETH FANDRICH: And I was driving over there, and he's just like right down at road and, I lost control on my car. I just –\n\nKenny's attorney says his client had every reason to be stressed out.\n\nMichael Fuller: Kenny told me that Milner … said, \"Hey, I'm a veterinarian. I've done surgeries and I have the tools to chop you up into little pieces.\"\n\nIn August 2022, after Kenny found another tracking device under his car, Milner was criminally charged and was awaiting trial.\n\nMichael Fuller: It was pretty clear to me that Milner was not in his right mind.\n\nJust a month later, Kenny filed a civil suit seeking hundreds of thousands of dollars for invasion of privacy and infliction of emotional distress — allegedly brought on by Milner's stalking, harassment, and trespass.\n\nFive months later Kenny Fandrich was dead.\n\nJust days after the murder, detectives were convinced that Steven Milner was that man behind the mask, but they needed more evidence.\n\nDet. Devin Rigo: We need to get eyes on Steven Milner because we know there was some sort of violent confrontation. We want to see if he had any injuries.\n\nNot wanting to tip him off – investigators asked him to come in for a check in about the stalking case.\n\nDet. Devin Rigo: So, we arranged a meeting for Steven to come in to sign some paperwork. … Detective Winter was inside at a reception desk.\n\nNatalie Morales: And your goal sitting there at the receptionist desk — sort of as an undercover, right?\n\nDet. Stephanie Winter: I wanted to see if he had any injury to himself. … He walks in. He looks extremely nervous.\n\nAnother person in the office noticed something.\n\nDet. Stephanie Winter: She says, \"Hey, he has got makeup on his face.\"\n\nMakeup, investigators say, Milner used to cover up a scratch on his nose.\n\nNatalie Morales: Bingo. You're thinking we got our guy?\n\nDet. Stephanie Winter: I — I — yep. At that point, I thought, this is him. This is our guy that — that did this.\n\nMoments later, after Milner walked out the door —\n\nDEPUTY DAVIS (police bodycam video): Hi sir, I'm Deputy Davis, the Sheriff's Office. We're being recorded by my camera. So, everything is going to be audio and visually recorded. … Do you understand that?\n\nDR. STEVE MILNER: Yes.\n\nDEPUTY DAVIS: OK, sounds good. … Right now, you're being detained.\n\nPolice noticed that the masked man and Steven Milner shared the same facial feature – a deep vertical forehead crease. Were they the same person? Washington County District Attorney's Office\n\nOn Jan. 31, 2023, four days after Kenny Fandrich was found dead, Steven Milner was taken into custody. Within days, Milner was charged with second-degree murder and stalking.\n\nWith Milner in custody, Rigo and Winter were quickly able to connect one important clue from those surveillance camera images: that unusual crease in the masked man's forehead.\n\nDet. Stephanie Winter: There's that very prominent forehead crease that I don't — he couldn't hide if he tried.\n\nNatalie Morales: There is no amount of makeup hiding that crease.\n\nDet. Stephanie Winter: No.\n\nNatalie Morales: Do you feel at this point like you've got like a pretty solid case?\n\nDet. Devin Rigo: We had a lot of circumstantial pieces, like putting the puzzle together, but we are just at the tip of the iceberg of what we still need to find out.\n\nMore puzzle pieces would be found in Milner's house.\n\nCONNECTING THE PUZZLE PIECES\n\nDet. Stephanie Winter: It was shocking that somebody this successful … a doctor … now suspect in a murder.\n\nWith Dr. Steven Milner now in police custody, Hillsboro Detectives Stephanie Winter and Devin Rigo set out to find evidence that could prove Milner was at the scene when Kenny Fandrich was murdered.\n\nDet. Devin Rigo: So, as soon as he is arrested … We're getting search warrants for his DNA to be taken … we're getting search warrants for his house as well.\n\nAnd detectives weren't quite prepared for what they found at his home.\n\nDet. Stephanie Winter: We found a cardboard cutout behind a mirror of Steven Milner's face placed on a very oiled, masculine man with a dog paw tattoo over his heart.\n\nNatalie Morales: Very odd memorabilia — to have in your bedroom.\n\nDet. Devin Rigo: Yes.\n\nDet. Stephanie Winter: I would say so.\n\nAnd there was more.\n\nDet. Devin Rigo: In the nightstand, in Steven's master bedroom, is a bunch of items that we kind of refer to as a shrine to Tanya. There was a framed picture of Tanya. There were love notes … there were women's underwear … just like very like personal keepsakes from, what — their relationship together.\n\nNatalie Morales: That's more than just collecting a few love notes and cards. …\n\nDet. Devin Rigo: Especially from … someone who hadn't been in a relationship with you for several years at this time period.\n\nPolice reviewed surveillance camera images and determined that Kenny Fandrich had been dragged into the maroon minivan, pictured, by a masked man. Police believed the masked man killed Fandrich inside the minivan, before staging his body in the driver's seat of his own vehicle. Washington County District Attorney's Office\n\nTo build their case, investigators needed to connect the maroon-colored minivan -- seen in the Intel parking garage parked next to Kenny's car -- to Milner. But as far as investigators could determine, Milner usually drove the white Toyota SUV he'd been in when he was arrested.\n\nDet. Devin Rigo: initially, we didn't know what evidence this car could provide us.\n\nSo, they ordered an FBI forensic analysis of the SUV's computer, hoping it might provide some clues about Milner's movements before and after Kenny's murder.\n\nDet. Devin Rigo (showing Milner's SUV to Morales): So essentially … the computer that's in the car retains a lot of information.\n\nNatalie Morales: Mm-hmm.\n\nDet. Devin Rigo: And luckily one of those things is like GPS data points …\n\nNatalie Morales: Where was that bit of information? … is that a computer that's pulled out on top there?\n\nDet. Stephanie Winter: Yeah. So that's part of the front dash … And then, it was just … a little … motherboard type thing that had a chip in it.\n\nWithin weeks, they got a call from their digital expert.\n\nDet. Devin Rigo: She … said, you guys need to look at the Home Depot in Oregon City … He's there a lot the day of the murder.\n\nA Home Depot just 15 minutes down the road from Milner's house.\n\nNatalie Morales (in the Home Depot parking lot with detectives): How central did this place become towards a piecing together the evidence that you had?\n\nDet. Devin Rigo: Like this was essentially like center stage of the investigation.\n\nThe detectives asked Home Depot security personnel if there had been suspicious activity in the lot recently. Amazingly, they said yes: two cars — a maroon minivan and a blue sedan — had been flagged for parking there for long periods of time with only temporary, paper license plates.\n\nDet. Devin Rigo: And we learned that there had been a lot of calls created in the past couple months with a suspicious … blue car and … maroon minivan.\n\nFor the second time in a matter of weeks, parking lot security cameras and the images they recorded, would provide investigators with key clues. In a clip from Jan. 27, 2023 – the day of Kenny's murder – detectives say you can see Milner's white SUV pull up and park. Within minutes, the driver – believed to be Steven Milner – gets into the maroon minivan. Another camera then captured the minivan exiting the parking lot.\n\nNatalie Morales: So, what was he doing with the cars?\n\nDet. Devin Rigo: So essentially this was like his staging location. So, he would drive his personal car here and then either pick up the blue sedan or the maroon minivan and then drive that out to Hillsboro. …\n\nNatalie Morales: What do you call them?\n\nDet. Devin Rigo: Burner cars.\n\nNatalie Morales: Burner cars.\n\nDet. Devin Rigo: Yeah. … everybody kind of is more familiar with like a burner phone … where you have a phone that's not … traced to you but, you know, you can use it for what you need, get rid of it. … Essentially, he did the same thing, but with a car.\n\nInvestigators believed Milner may have been using those burner cars to secretly follow Kenny to work — even after law enforcement had told him to stop.\n\nThey also learned Home Depot security cameras had images of the driver of those cars shopping in the store about a month before Kenny was murdered.\n\nDet. Stephanie Winter: he parked right in front of Home Depot …\n\nDet. Devin Rigo: He went in and … we saw him come to the self-checkout area … and he had bought a pair of like safety glasses. …\n\nNatalie Morales: Was … his face visible in that surveillance?\n\nDet. Stephanie Winter: It was.\n\nDet. Devin Rigo: Oh yeah …\n\nDr. Steven Milner is seen on security video after buying a pair of safety glasses at a Home Depot on Dec. 13, 2022 – about a month before Kenny Fandrich's murder. Washington County District Attorney's Office\n\nThere was no doubt — it was Steven Milner. And those glasses he bought? Detectives say you can see them in his right hand as he exited the store. The receipt said they had a \"red mirror\" tint. Winter had an idea.\n\nDet. Stephanie Winter: We just happened to be sitting near one of the aisles and I was like, I'm going to go see where they sell … the glasses … And then a couple boxes down was … a yellow hard hat that looked very similar to the one … that he was wearing in all of the Intel garage surveillance.\n\nThe detectives were convinced this was where Milner had gotten his disguise to kill Kenny.\n\nNatalie Morales: You have all of this, but you were missing one big piece of evidence. What was it?\n\nDet. Devin Rigo: We were, at this point, still missing … the maroon minivan. …\n\nNatalie Morales: Why is the minivan so important?\n\nDet. Devin Rigo: Because it's the minivan that we believe was really our main crime scene. … we thought there was going to be forensic evidence … in that minivan. So, we really wanted to get that minivan to help really put the icing on … this case.\n\nRigo was laser focused on tracking down that maroon minivan and he got an incredibly lucky break. When those suspicious burner cars had been flagged, the VIN number was also recorded. Rigo searched it and found out that van had been found abandoned just a few days after the murder.\n\nDet. Devin Rigo: The highway people, had … towed it off the side of the I-5 in north Portland.\n\nNatalie Morales: It had been dumped then.\n\nDet. Devin Rigo: It had been dumped there. … So, I called the tow company, \"Hey, do you have this car?\" \"No, sorry … We sold it to a scrap metal company.\"\n\nRigo knew the clock was ticking to retrieve what he believed was the crime scene and all of the key evidence it held.\n\nDet. Devin Rigo: So, me and another detective drive as quick as we can to north Portland.\n\nThe maroon minivan, pictured left, moments before it was crushed by the metal jaws of the scrapyard claw. Washington County District Attorney's Office\n\nBut they were too late. When he asked about the minivan, the scrapyard showed Rigo a video of the maroon minivan police believe Milner drove to the Intel garage to kill Kenny just moments before it was pulverized by the metal jaws of the scrapyard claw.\n\nDet. Devin Rigo: I was able to watch one of my key pieces of evidence be crushed and taken away.\n\nNatalie Morales: Before your very eyes.\n\nDet. Devin Rigo: Before my very eyes —\n\nNatalie Morales: Oh my gosh.\n\nDet. Devin Rigo: — exactly a week too late.\n\nDOCTOR MILNER ON TRIAL\n\nOn Jan. 13, 2025, Steven Milner went on trial — charged with stalking and murdering Kenny Fandrich. Washington County prosecutors John Gerhard and Mahalee Streblow knew they faced a challenge without that maroon minivan, where they believe Steven Milner murdered Kenny.\n\nJohn Gerhard: All the evidence that was inside the van was lost with it. … the biggest disappointment for us is there was likely a lot of forensic evidence …\n\nBut prosecutors had some forensic evidence they say put Steven Milner at the scene: DNA from swabs taken of Kenny Fandrich's hands.\n\nDet. Devin Rigo: I remember getting an email of the results and immediately opening it and being like, \"Oh my gosh, this is it.\" … Steven Milner's DNA was on Kenneth Fandrich's hands. …\n\nNatalie Morales: Now you really felt like you had your case made.\n\nDet. Devin Rigo: Yes, because there is no way he could explain away why his DNA would've been on Kenneth's body.\n\nSteven Milner would have an explanation for that. To everyone's surprise, Milner took the stand, admitting he did spray paint the cameras and was in the Intel garage waiting for Kenny. He presented what detectives believed was a far-fetched explanation: he was trying to save Tanya. There were no cameras in court, but there is audio of Milner telling Prosecutor John Gerhard why he was in the Intel lot that day.\n\nSTEVEN MILNER (in court): I was trying to get him arrested for driving while he was drunk, or driving without a license.\n\nJOHN GERHARD: Why was it your responsibility to enforce Oregon traffic laws?\n\nSTEVEN MILNER: I was trying to keep Tanya from getting killed.\n\nJohn Gerhard: He had this delusional belief that he needed to protect Tanya Fandrich.\n\nMahalee Streblow: The defense case, it seemed to be … to kind of get the jury to maybe feel sympathetic to Milner.\n\nAnd Milner insisted it was Kenny who attacked him after Kenny spotted Milner inside the maroon minivan.\n\nDet. Devin Rigo: Steven essentially said, well, I knew I was caught. So, I opened the door to kinda confront him. And then Kenneth attacked me.\n\nSTEVEN MILNER (in court): We basically fought for a little bit. … there was pushing and shoving … eventually I was able to kind of push him up against the car and — and then shove him into the car.\n\nGerhard challenged Milner's self-defense story.\n\nJOHN GERHARD (in court): Is that push that causes him to fall into his seat?\n\nSTEVEN MILNER: He hit up against the car and then kind of tripped at the same time. And I kept pushing.\n\nMahalee Streblow: His testimony … just didn't line up with the physical evidence at the scene …\n\nDet. Devin Rigo: To my knowledge — bumping your head on the car door is not going to break your neck.\n\nAfter six hours of deliberations, the jury found Steven Milner guilty of murdering Kenny Fandrich, and multiple stalking charges.\n\nSteven Milner at his sentencing on Feb. 18, 2025. Washington County District Attorney's Office\n\nCameras were allowed for Steven Milner's sentencing hearing, which took place on Feb. 18, 2025. Tanya, who asked not to be shown on camera, gave a powerful statement directed at Steven Milner. Prosecutor Mahalee Streblow read us her words:\n\nMahalee Streblow (reading aloud): \"All you had to do was stop … hear me clearly, when I say you are a vengeful, deceptive, manipulating, self-serving, aggressive, hateful, lying predator… and all you had to do was stop.\"\n\nMilner was sentenced to life in prison, with the possibility of parole after 25 years. Milner did not respond to \"48 Hours\"' request for an interview.\n\nMahalee Streblow: This case highlights the very worst-case scenario … take stalking seriously.\n\nKenny's attorney, Michael Fuller, says what happened highlights the limits of the system that is supposed to protect victims of stalking.\n\nMichael Fuller: Kenny … called the police. When that didn't work, he got a lawyer … Kenny did everything he could under the legal system, and it didn't help him at all.\n\nAfter Kenny's death, Fuller filed a wrongful death suit on behalf of Kenny's estate asking for damages of several million dollars. Fuller believes Milner made millions from real estate investments and the sale of his business.\n\nMichael Fuller: In the wrongful death case, my goals are to extract as much money as we can out of Milner … If the estate recovered any money for Kenny, it would go to his wife.\n\nFor Milner's former veterinary clients, it was hard to reconcile the doctor they knew, with a now-convicted murderer.\n\nCheryl Choquette: I could not believe that it was the same guy. …\n\nDarlyn Robinson: I just believe that he ended up going through some type of psychosis … And I think that … at some point he snapped …\n\nDet. Devin Rigo: I think it really gets down to, like, you never know what anybody is capable of. … you never know what monster might be inside …\n\nNatalie Morales: Almost a Dr. Jekyll and Mr. Hyde situation?\n\nDet. Devin Rigo: Yeah, absolutely.\n\nDet. Stephanie Winter: Yeah.\n\nDarlyn Robinson: He had everything to live for. You know, he … could do anything he wanted to do. … And this is where it ended up. … It's real sad.\n\n\n\n\n\nProduced by Chuck Stevenson and Lauren Clark. Greg Kaplan and Michael Baluzy are the editors. Lauren Turner Dunn is the associate producer. Cindy Cesare, Danielle Austen and Michelle Sigona are the development producers. Anthony Batson is the senior producer. Nancy Kramer is the executive story editor. Judy Tygard is the executive producer.",
      "source": "CBS News",
      "url": "https://www.cbsnews.com/news/kenneth-fandrich-oregon-murder-steven-milner-veterinarian-security-video-masked-killer/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Show HN: I made an OSS tool to remove Sora 2 Watermark in less than 72h released",
      "content": "Sweeta Remove Watermarks from SORA 2 Video Generations\n\nAbout\n\nSORA 2 is a State-of-the-art model by OpenAI and for the past few days, being on platforms like Instagram and Twitter, I've noticed how many non-technical people just assume the video is real despite the watermark.\n\nThink what would happen if there was no watermark? This is the reason that this project exists. It's not to abuse the great initiative by OpenAI to put logos onto every generation (though temporarily there's also an easy way to bypass that which I wouldn't cover), it's to hopefully encourage them to be harsher and more obvious with it in some form.\n\nSweeta is an AI-powered watermark removal tool specifically designed for SORA 2 video generations. It Uses advanced inpainting models (LaMA) and intelligent detection algorithms, it can seamlessly remove watermarks while (mostly) preserving the original image quality.\n\nRecommended Specs:\n\nOS : Windows 11, macOS 12+, or Ubuntu 20.04+\n\n: Windows 11, macOS 12+, or Ubuntu 20.04+ RAM : 16GB or more\n\n: 16GB or more Storage : 10GB free space\n\n: 10GB free space GPU : NVIDIA GPU with 4GB+ VRAM (or Apple Silicon for macOS)\n\n: NVIDIA GPU with 4GB+ VRAM (or Apple Silicon for macOS) CPU: Multi-core processor (Intel i5/AMD Ryzen 5/Apple M1 or better)\n\nInstallation\n\nPrerequisites\n\nPython & Conda: Install Miniconda (recommended) or Anaconda\n\nWindows\n\nQuick Install (Recommended)\n\nOpen Command Prompt or PowerShell as administrator Navigate to the project folder Run the installation script: cd path\\to\\Sweeta windows\\install_windows.bat Or for PowerShell: powershell - ExecutionPolicy Bypass - File windows\\install_windows.ps1 Follow the on-screen instructions\n\nManual Installation\n\n# Create the conda environment conda env create -f environment.yml # Activate the environment conda activate py312aiwatermark # Install additional dependencies pip install PyQt6 transformers iopaint opencv - python - headless # Download the LaMA model iopaint download -- model lama\n\nLinux\n\n# Navigate to the project directory cd /path/to/Sweeta # Run the setup script bash linux/setup.sh # Or manually: conda env create -f environment.yml conda activate py312aiwatermark pip install PyQt6 transformers iopaint opencv-python-headless iopaint download --model lama\n\nColab\n\nAccess the Colab notebook from here and follow the instructions.\n\nUsage\n\nLaunching the Application\n\nGUI Mode (Recommended)\n\nActivate the conda environment: conda activate py312aiwatermark Launch the GUI application: python remwmgui.py\n\n(would be happy to prepare a hugging face port for Spaces too, which would technically be better but would require community GPU access)\n\nCommand Line Mode\n\nconda activate py312aiwatermark python remwm.py < input_path > < output_path > [options]\n\nExample:\n\npython remwm.py input_video.mp4 output_video.mp4 --max-bbox-percent 15 --force-format MP4 --transparent --overwrite\n\nAvailable options:\n\n--max-bbox-percent : Detection sensitivity (default: 10.0)\n\n: Detection sensitivity (default: 10.0) --force-format : Output format (PNG, WEBP, JPG, MP4, AVI)\n\n: Output format (PNG, WEBP, JPG, MP4, AVI) --transparent : Make watermark areas transparent\n\n: Make watermark areas transparent --overwrite : Overwrite existing files\n\nConfiguration Edit\n\nRefer #ui.yml.example\n\nConfiguration Options\n\nInput Path : Select your source file or folder\n\n: Select your source file or folder Output Path : Choose where to save processed files\n\n: Choose where to save processed files Overwrite Files : Enable to replace existing output files\n\n: Enable to replace existing output files Transparent Watermarks : Make watermark areas transparent (PNG only)\n\n: Make watermark areas transparent (PNG only) Max BBox Percent : Adjust detection sensitivity (1-100%)\n\n: Adjust detection sensitivity (1-100%) Output Format: Choose PNG, WEBP, JPG, or keep original format\n\nCommon Issues\n\nImportError: cannot import name 'cached_download' from 'huggingface_hub'\n\nSolution: This is a version compatibility issue. The installation scripts now automatically install the correct version. If you installed manually, run:\n\npip install \" huggingface-hub<0.20 \" pip install --upgrade iopaint\n\n\"Conda is not recognized as an internal or external command\"\n\nSolution: Ensure Conda is properly installed and added to your system PATH environment variable.\n\nDependency Installation Failures\n\nSolution: Try installing dependencies individually:\n\npip install PyQt6 pip install transformers pip install iopaint pip install opencv-python-headless\n\nApplication Won't Start\n\nSolution: Verify the environment is activated:\n\nconda activate py312aiwatermark python --version # Should show Python 3.12.x\n\nLaMA Model Download Issues\n\nSolution: Ensure stable internet connection and retry:\n\niopaint download --model lama\n\nCUDA/GPU Issues\n\nSolution: Install PyTorch with CUDA support:\n\npip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n\nIf you run into any issues or have something to say, reach out! I'd be happy to talk :) Twitter, LinkedIn\n\nI (tired to) microblog the development process in #journal.md but uh, read it at your own risk lol Will put out a blog or something similiar too.\n\n📄 License & Disclaimer\n\nLicense\n\nThis project is licensed under the Apache License 2.0 - see the LICENSE file for details. Thanks to D-Ogi for the WatermarkRemover-AI model which was heavily modified for this project.\n\n⚠️ Important Disclaimer\n\nTHIS SOFTWARE IS PROVIDED FOR EDUCATIONAL AND RESEARCH PURPOSES ONLY. Use this tool responsibly and ethically.",
      "source": "Github.com",
      "url": "https://github.com/Kuberwastaken/sweeta",
      "timestamp": "2025-10-05"
    }
  ]
}