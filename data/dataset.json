{
  "Nvidia": [
    {
      "headline": "Nvidia’s $100 billion OpenAI investment raises eyebrows and a key question: How much of the AI boom is just Nvidia’s cash being recycled?",
      "content": "Two of the most prominent examples of Nvidia’s web of circuitous investments are OpenAI and Coreweave. In addition to the latest investment in OpenAI, Nvidia had previously participated in a $6.6 billion investment round in the fast-growing AI company in October 2024. Nvidia also has invested in CoreWeave, which supplies data center capacity to OpenAI and is also an Nvidia customer. As of the end of June, Nvidia owned about 7% of Coreweave, a stake worth about $3 billion currently. The benefits that companies get from a Nvidia investment extend beyond the cash itself. Nvidia’s equity stakes in companies such as OpenAI and Coreweave enable these companies to access debt financing for data center projects at potentially significantly lower interest rates than they would be able to access without such backing. Jay Goldberg, an analyst with Seaport Global Securities, compares such deals to someone asking their parents to be a co-signer on their mortgage. It gives lenders some assurance that they may actually get their money back.\n\nIn addition, there are so many interlocking rings of circularity—where Nvidia has invested in a company, such as OpenAI, that in turn purchases services from a cloud service provider that Nvidia has also invested in, which then also buys or leases GPUs from Nvidia—that disentangling what money is flowing where is far from easy.\n\nThe extent to which the entire AI boom is backstopped by Nvidia’s cash isn’t easy to answer precisely, which is also one of the unsettling things about it. The company has struck a number of investment and financing deals, many of which are too small individually for the company to consider “material” and report in its financial filings, even though collectively they may be significant.\n\nIn past technology bubbles, revenue “roundtripping” and tech companies financing their own customers have exacerbated the damage when those bubbles eventually popped. While the share of Nvidia’s revenues that are currently being driven by such financing appears to be relatively small, the company’s dominance as the world’s most valuable publicly-traded company means that its stock is “priced for perfection” and that even minor missteps could have outsized impact on its valuation—and on financial markets and perhaps even the wider economy.\n\nWhile Nvidia’s latest announcement is by far the largest example, the AI chipmaker has engaged in a series of “circular” deals in which it invests in, or lends money to, its own customers. Vendor financing exists to some degree in many industries, but in this case, circular transactions may give investors an inflated perception of the true demand for AI.\n\nNvidia’s announcement earlier this week that it is investing $100 billion into OpenAI to help fund its massive data center build out has added to a growing sense of unease among investors that there is a dangerous financial bubble around AI, and that the revenues and earnings math underpinning the valuations of both public and private companies in the sector just doesn’t add up.\n\nStory Continues\n\nStartups financing data centers have often had to borrow money at rates as high as 15%, compared to 6% to 9% that a large, established corporation such as Microsoft might have to pay. With Nvidia’s backing, OpenAI and Coreweave have been able to borrow at rates closer to what Microsoft or Google might pay.\n\n\n\nNvidia has also signed a $6.3 billion deal to purchase any cloud capacity that CoreWeave can’t sell to others. The chipmaker had previously agreed to spend $1.3 billion over four years on cloud computing with CoreWeave. Coreweave, meanwhile, has purchased at least 250,000 Nvidia GPUs so far—the majority of which it says are H100 Hopper models, which cost about $30,000 each—which means Coreweave has spent about $7.5 billion buying these chips from Nvidia. So in essence, all of the money Nvidia has invested in Coreweave has come back to it in the form of revenue.\n\n\n\nNvidia has struck similar cloud computing deals with other so-called “neo-cloud” companies. According to a story in The Information, Nvidia agreed this summer to spend $1.3 billion over four years renting some 10,000 of its own AI chips from Lambda, which like Coreweave runs data centers, as well as a separate $200 million deal to rent some 8,000 more over an unspecified time period.\n\nFor those who believe there’s an AI bubble, the Lambda deal is clear evidence of froth. Those Nvidia chips Lambda is renting time on back to Nvidia? It bought them with borrowed money collateralized by the value of the GPUs themselves.\n\n\n\nBesides its large investments in OpenAI and Coreweave, AI chipmaker also holds multi-million dollar stakes in several other publicly-traded companies that either purchase its GPUs or work on related chip technology. These include chip design firm Arm, high-performance computing company Applied Digital, cloud services company Nebius Group, and biotech company Recursion Pharmaceuticals. (Nvidia also recently purchased a 4% stake in Intel for $5 billion. Like Arm, Intel makes chips that in some cases are alternatives to Nvidia’s GPUs, but which for the most part are complementary to them.)\n\nEarlier this month, Nvidia also pledged to invest £2 billion ($2.7 billion) in U.K. AI startups, including at least £500 million in Nscale, a U.K.-based data center operator that will, presumably, be using some of that money to purchase Nvidia GPUs to provision the data centers it is building. Nvidia also said it would invest in a number of British startups, both directly and through local venture capital firms, and some of that money too, will likely come back to OpenAI in the form of computing purchases, either directly, or through cloud service providers, who in turn will need to buy Nvidia GPUs.\n\n\n\nIn 2024, Nvidia invested about $1 billion in AI startups globally either directly or through its corporate venture capital arm NVentures, according to data from Dealroom and The Financial Times. This amount was up significantly from what Nvidia invested in 2022, the year the generative AI boom kicked off with OpenAI’s debut of ChatGPT.\n\n\n\nHow much of this money winds up coming right back to Nvidia in the form of sales is again, difficult to determine. Wall Street research firm NewStreet Research has estimated that for every $10 billion Nvidia invests in OpenAI, it will see $35 billion worth of GPU purchases or GPU lease payments, an amount equal to about 27% of its annual revenues last fiscal year.\n\nEchoes of the dotcom era\n\nThat kind of return would certainly make this sort of customer financing worthwhile. But it does raise concerns among analysts about a bubble in AI valuations. These kinds of circular deals have been a hallmark of previous technology bubbles and have often come back to haunt investors.\n\nIn this case, the lease arrangements that Nvidia is entering into with OpenAI as part of its latest investment could prove problematic. By leasing GPUs to OpenAI, rather than requiring them to buy the chips outright, Nvidia is sparing OpenAI from having to take an accounting charge for the high depreciation rates on the chips, which will ultimately help OpenAI’s bottom line. But it means that instead Nvidia will have to bear this depreciation costs. What’s more, Nvidia will also take on the risk of being stuck with an inventory of GPUs no one wants if demand for AI workloads don’t match Nvidia CEO Jensen Huang’s rosy predictions.\n\n\n\nTo some market watchers, Nvidia’s latest deals feel all-too-similar to the excesses of past technology booms. During the dot com bubble at the turn of the 21st Century, telecom equipment makers such as Nortel, Lucent, and Cisco lent money to startups and telecom companies to purchase their equipment. Just before the bubble burst in 2001, the amount of financing Cisco and Nortel had extended to their customers exceeded 10% of annual revenues, and the amount of financing the top five telecom equipment makers had provided to customers exceeded 123% of their combined earnings.\n\n\n\nUltimately, the amount of fiber-optic cabling and switching equipment installed far exceeded demand, and when the bubble burst and many of those customers went bust, the telecom equipment makers were left holding the bad debt on their balance sheets. This contributed to a greater loss of value when the bubble burst than would have otherwise been the case, with networking equipment businesses losing more than 90% of their value over the ensuing decade.\n\n\n\nWorse yet were companies such as fiber-optic giant Global Crossing that engaged in direct “revenue roundtripping.” These companies cut deals—often at the end of a quarter in order to hit topline forecasts—in which they paid money to another company for services, and then that company agreed to purchase equipment of exactly equal value. When the bubble burst, Global Crossing went bankrupt, and its executives ultimately paid large legal settlements related to revenue roundtripping.\n\n\n\nIt is memories of these kinds of transactions that have caused analysts to at least raise an eyebrow at some of Nvidia’s circular investments. Goldberg, the Seaport Global analyst, said the deals had a whiff of circular financing and were emblematic of “bubble-like behavior.”\n\n“The action will clearly fuel ‘circular’ concerns,” Stacy Rasgon, an analyst with Bernstein Research, wrote in an investor note following Nvidia’s announcement of its blockbuster investment in OpenAI. It’s a long way from a concern to a crisis, of course, but as AI company valuations get higher, that distance is starting to close.\n\nThis story was originally featured on Fortune.com",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-100-billion-openai-investment-110000256.html",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Actual ports and NVIDIA GPUs make this laptop the practical Dell XPS and MacBook Pro alternative",
      "content": "The Lenovo Yoga Pro 9i is the premium, feature-packed 16-inch powerhouse for those who need to work, create, and even game on the go. It's an excellent, incredibly practical laptop that feels like the more reasonable alternative to the divisive Dell 16 Premium (previously the Dell XPS 16). I only wish battery life was better, but I can't say I'm shocked it's not.\n\nWhy you can trust Windows Central Our expert reviewers spend hours testing and comparing products and services so you can choose the best for you. Find out more about how we test.\n\nCreators, engineers, and other professionals the world over rely on powerful 16-inch laptops to keep them working smoothly, even while staying mobile. The Dell XPS 16 (now the Dell 16 Premium), the Apple MacBook Pro 16, the Razer Blade 16 — these are all great choices, but there's another excellent alternative on the block.\n\nThis is the Lenovo Yoga Pro 9i 16 (Gen 10) Aura Edition... which is a ridiculously long name for an incredibly capable laptop with a practical design, potent performance, and an impressive set of features that make it well-suited to almost any task.\n\nIt's also well priced compared to the aforementioned competition, making it one of the easiest to recommend. While other laptops often focus on sleek and minimalist designs (often at the expense of features or practicality), the Yoga Pro 9i doesn't cut any corners — or ports.\n\nDisclaimer This review was made possible thanks to a review sample provided by Lenovo. Lenovo had no input nor saw the contents of this review prior to publication.\n\nMy Yoga Pro 9i 16 (Gen 10) review\n\nImage 1 of 4 The clean Lenovo logo and \"communications bar\" are in full display with this laptop. (Image credit: Windows Central | Zachary Boddy) Most people would be content with just the ports on one side. (Image credit: Windows Central | Zachary Boddy) I'd prefer swapping one of those Type-A ports for a Thunderbolt 4 port on the other side, but this is a great I/O selection either way. (Image credit: Windows Central | Zachary Boddy) These aren't the slimmest bezels on the block, but the Yoga Pro 9i still feels plenty premium. (Image credit: Windows Central | Zachary Boddy)\n\nDesign ⭐⭐⭐⭐½\n\nWhere the Dell 16 Premium (2025) we recently reviewed boasts a controversial, futuristic, and minimalist design, the Lenovo Yoga Pro 9i absolutely prioritizes function over form.\n\nIt's a familiar two-tier Lenovo design with a rounded base and squared-off lid, creating a unique profile entirely constructed of high-quality aluminum. The Yoga Pro 9i isn't the most refined high-end laptop I've held in my hand and doesn't feature the slimmest display bezel, but it absolutely looks and feels like a premium product.\n\nYou can immediately tell the Yoga Pro 9i is a truly premium laptop, even if it's not the most futuristic design.\n\nAt around 17.9mm thick and 1.93kg heavy, there are certainly beefier 16-inch workstations, but the Yoga Pro 9i's design does make it seem chunkier than it actually is.\n\nAt least you get a ton of ports. There's the 170W DC power port, an HDMI 2.1 port, two full-featured Thunderbolt 4 ports with Power Delivery and DisplayPort functions, a 3.5mm audio jack, two USB Type-A (5GBps) ports, a side-mounted power button, a webcam privacy shutter, and even a full-sized SD card slot. The only things missing are an Ethernet port (Lenovo would've had to make this laptop a fair bit thicker for that) and a Kensington Nano Security Slot, which may actually disappoint some professional users.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nI really wish Lenovo had sent me a model with the Tandem OLED panel, but this is still an excellent display. (Image credit: Windows Central | Zachary Boddy)\n\nDisplay ⭐⭐⭐⭐½\n\nLenovo actually offers two OLED, touchscreen PureSight Pro display options for the Yoga Pro 9i. Both panels boast a 120Hz refresh rate, excellent color accuracy across standard and cinematic gamuts, Dolby Vision HDR and VESA DisplayHDR True Black 1000 support, and the trifecta of TÜV Rheindland Low Blue Light, TÜV Rheinland Flicker-Free, and Eyesafe certifications.\n\nFor an extra $150, though, you can upgrade to a Tandem OLED display with a higher 3.2K resolution (up from 2.8K), even greater color accuracy (especially in the AdobeRGB gamut), twice the display brightness at up to 1,000 nits (compared to 500 nits, and that's not even with HDR enabled), and greater efficiency to boot. Sadly, Lenovo didn't send me that configuration to test, so I can't tell you just how much better that panel is.\n\nThe entry-level screen is still fantastic, though. It's bright, vibrant, and responsive whether I was working, editing photos, gaming, or watching videos. If the Tandem OLED display is even better, it'll be one of the best panels you'll find on a laptop right now.\n\nPerformance ⭐⭐⭐⭐½\n\nThe Yoga Pro 9i is powered by an Intel Core Ultra 9 285H, a 16-core CPU with fantastic overall performance and solid efficiency. That's backed by up to an NVIDIA GeForce RTX 5070 (8GB) GPU, but Lenovo sent me the entry-level configuration with an RTX 5050 inside — and it seriously impressed me.\n\nThis laptop is a strong performer in general, backed by Intel Evo guarantees for responsiveness and bolstered by excellent thermal management. The Yoga Pro 9i never got too warm, never suffered from abnormal throttling, and kept quiet enough even under load.\n\nThe Yoga Pro 9i was practically guaranteed to deliver great performance, but it still managed to surprise me.\n\nAs I mentioned, though, it's the RTX 5050 that surprised me. Lenovo actually offers a GPU overclocking option, and when enabled the Yoga Pro 9i's RTX 5050 performed well beyond the level I expected, coming within a stone's throw of the far more expensive Dell 16 Premium's RTX 5070 without becoming thermally restrained.\n\nI was able to play Forza Horizon 5 with Extreme settings without any issues, either, never dipping below a stable 60 FPS.\n\nImage 1 of 3 I really like this keyboard, but I'm still not a fan of Lenovo's next key coating. (Image credit: Windows Central | Zachary Boddy) There's a lot of power packed into this chassis, but you don't feel it most of the time. (Image credit: Windows Central | Zachary Boddy) Intel Evo, NVIDIA Studio — this laptop has all the ingredients it needs to tackle any workflow or task. (Image credit: Windows Central | Zachary Boddy)\n\nBattery life ⭐⭐⭐½\n\nWith an 84Whr battery stashed away inside, the Yoga Pro 9i certainly has plenty of juice... but it's not enough to translate to true all-day battery life. In my testing, the Yoga Pro 9i can deliver around 5 hours of real-time usage — slightly better than the Dell 16 Premium and its larger 99Whr battery, but nothing too impressive.\n\nYou can use up to 100W USB Type-C chargers whenever you're in a pinch, at least. Performance when off the charger is throttled, but is still absolutely what I'd consider \"flagship\" level — especially the graphical oomph.\n\nThis laptop can't claim to boast the greatest endurance, but it's no worse than much of the competition.\n\nKeyboard & touchpad ⭐⭐⭐⭐\n\nI've historically been a huge fan of Lenovo's keyboards, and that still mostly holds true with the Yoga Pro 9i. The layout, key travel, and consistency are all top-notch, and the keyboard doesn't feel too cramped despite having a compact tenkey number pad off to one side (a feature some will love, and others will hate).\n\nAs I noted in my Lenovo Yoga Slim 7i (Gen 9) Aura Edition review, though, the new coating Lenovo puts on its keys isn't my favorite. This is a good keyboard, it's just slippery.\n\nThe touchpad is spacious and responsive with Microsoft Precision drivers, so I have little to complain about there... but I do wish Lenovo would finally embrace haptic touchpads on its premium consumer laptops.\n\nLenovo's \"Aura Edition\" branding doesn't mean anything to 99% of people... this laptop still delivers a great software experience, though. (Image credit: Windows Central | Zachary Boddy)\n\nSoftware & AI ⭐⭐⭐⭐½\n\nIt should come as no surprise that the Lenovo Yoga Pro 9i runs Windows 11, and it does so without issue. Drivers are stable and Lenovo hasn't injected an absurd amount of bloatware onto the device.\n\nLenovo didn't pour every feature imaginable into the Yoga Pro 9i, it just focused on delivering a capable, high-quality laptop.\n\nYou also get some extra features courtesy of Lenovo's \"Aura Edition\" branding, such as multi-device syncing for photos and files, \"smart\" performance and settings profiles, and Lenovo's \"AI Now\" companion, but the Yoga Pro 9i is not a Copilot+ PC thanks to the weaker NPU of its processor, so it doesn't boast all the latest and greatest artificial intelligence features in Windows.\n\nThat won't make a difference to most people, but it's worth noting this laptop technically isn't on the cutting edge for software.\n\nEverything else ⭐⭐⭐⭐½\n\nThe display isn't the only reason the Yoga Pro 9i is a monster for entertainment, as it also packs a capable six-speaker system (dual 2W tweeters and quad 2W woofers) with Dolby Atmos support.\n\nI won't go as far as claiming these are the best-sounding speakers in a laptop I've heard, but the Yoga Pro 9i does sound full, loud, and clear. You also get a quad microphone array flanking the great 5MP front-facing camera, which is supported by an IR sensor for Windows Hello facial recognition.\n\nI never had any issues with the Wi-Fi 7 or Bluetooth 5.4 connectivity, either. The Yoga Pro 9i doesn't rock any additional features like Human Presence Detection (HPD) or ambient light sensors, or a fingerprint reader, but the basics are covered and they're covered well.\n\nYoga Pro 9i (Gen 10) review: My final thoughts\n\nThe Lenovo Yoga Pro 9i isn't one of the most exciting laptops of 2025, but it is one of my favorites. (Image credit: Windows Central | Zachary Boddy)\n\n✅You should buy this if ...\n\nYou need a powerful, feature-packed 16-inch laptop for work and creation.\n\nYou also want that laptop to be good for PC gaming, too.\n\nYou want a laptop with a top-notch OLED display and speaker system.\n\n❌You should not buy this if ...\n\nYou actually care about Windows 11's Copilot+ PC-exclusive features.\n\nYou need a laptop with consistent, easy all-day battery life.\n\nThe Lenovo Yoga Pro 9i 16 (Gen 10) Aura Edition may have a slightly ridiculous name, but it's hands-down one of the greatest laptops in the category of \"powerful and premium 16-inch workstations.\"\n\nWhile Apple commits to minimalism and Dell pushes even more aggressively in that direction, Lenovo is delivering an equally capable laptop packed with features and ports — all while undercutting the competition on price. It's a shockingly practical laptop for productivity, creation, entertainment, and gaming.\n\nWhile I do wish the battery could withstand a full day's worth of work without compromise, that doesn't stop this from being one of the best Windows laptops I've tested this year. You can customize your own Lenovo Yoga Pro 9i 16 (Gen 10) Aura Edition from $1,869.99 at Lenovo.com, or pull the trigger on the configuration I most recommend for $2,149.99 at Lenovo.com, which upgrades you to that sweet Tandem OLED display and a more powerful RTX 5060 GPU.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/lenovo/lenovo-yoga-pro-9i-16-gen-10-aura-edition-review",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Why is everyone buying groceries in bulk? BI's Steve Russolillo unpacks Costco's chokehold on America.",
      "content": "lighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nWelcome back to our Sunday edition, where we round up some of our top stories and take you inside our newsroom. This week, Amazon settled with the FTC for $2.5 billion following an exclusive Business Insider investigation into the e-commerce company's misleading Prime sign-up and cancellation tactics.\n\nAlso, BI's new markets newsletter is coming to inboxes soon. Sign up for First Trade here!\n\nOn the agenda today:\n\nBut first: Where do you store all of those groceries?\n\nIf this was forwarded to you, sign up here. Download Business Insider's app here.\n\nThis week's dispatch\n\nThe Costco craze\n\nGene J. Puskar/AP Photo\n\nI've got a confession: I don't get what all the fuss is about Costco.\n\nGigantic bags of potato chips, enough ketchup to last until the end of the decade, endless rolls of toilet paper (well, maybe post-COVID I get that one).\n\nBut seriously, why does anyone need a 20-pound tub of margarine?\n\nA colleague (who may or may not be the lead weekday writer of this newsletter) wants to buy a second refrigerator for his garage just so he can store even more stuff from Costco.\n\n\"The biggest pain point in my marriage is probably Costco,\" BI's Dan DeFrancesco told me. \"Before every trip, my wife warns me not to get carried away. And then I proceed to get carried away and buy 18 pounds of chicken breasts.\"\n\nLook, I get it. Buying in bulk is very much en vogue these days. Just look at Costco's earnings report the other day.\n\nSales and profit are up. Total paid memberships are rising. More people are finding the experience so compelling that they're upgrading their memberships.\n\nCostco CEO Ron Vachris said opening early for executive members boosted weekly sales by 1%. Foot traffic data from Placer.ai indicates the adjusted hours are helping the company accomplish several key goals, namely getting shoppers to visit more quickly and more often.\n\nCostco is also set to open new locations faster than usual, particularly in areas with popular stores. The goal is to relieve some of the traffic pressure in those locations, creating a better shopping experience.\n\nPeople talk about Costco the way some talk about religion. It's an experience, a pilgrimage if you will, for hot deals and free samples. You can get everything from ever-pricey gold bars to the ultimate inflation-proof offering: the vaunted $1.50 hot dog and soda combo.\n\nMaybe I'm just a city snob who doesn't get all the finer things in life that Costco has to offer.\n\nI'll stick with Trader Joe's and my corner bodega.\n\nWhat are your thoughts on Costco and the early hours for executive members? We'd love to hear from you. Please email me at srussolillo@insider.com.\n\nKnow thine enemy\n\nGetty Images; Tyler Le/BI\n\nRoger Federer and Rafa Nadal. Taylor Swift and Kanye West. Mark Zuckerberg and Elon Musk. Having a workplace enemy isn't always the most pleasant experience, but battling them can actually push you to grow and further your career.\n\nThat's because a work nemesis is often a competitor for a boss' praise or promotion. Competition can be a driver of peak performance — as long as it stays healthy.\n\nWho's your office opp?\n\nH-1B whiplash\n\nTrump's proposed H-1B changes have sent startups scrambling. wildpixel/Getty Images\n\nStartup founders and their employees were thrown into a frenzy after President Donald Trump announced his new $100,000 H-1B visa fee. Some young companies have frozen hiring as they wait for more clarity.\n\nWhile the Big Tech companies are by far the largest beneficiaries of the H-1B visa program, the proposed changes will have an outsized impact on smaller startups, according to 10 founders and investors BI spoke with.\n\n\"Is there another shoe about to drop?\"\n\nAlso read:\n\nThe Chipotle playbook\n\nStarbucks; Getty Images; Tyler Le/BI\n\nThe company recently announced another round of corporate layoffs and an array of store closures across North America. It's part of CEO Brian Niccol's \"Back to Starbucks\" initiative, and takes a page out of his Chipotle turnaround strategy.\n\nAt Chipotle, Niccol revitalized the chain's brand after a 2015 E. coli scandal. The coffee giant is a much bigger beast, though — and his efforts haven't paid off yet.\n\nA huge undertaking.\n\nAlso read:\n\nHell for job seekers, heaven for scammers\n\nDesiree Rios for Business Insider\n\nWhile an exceptionally tight job market has made job seekers increasingly desperate, the rise of cheap generative AI tools has allowed scammers to get more sophisticated.\n\nScammers are deceiving even well-educated job seekers of any age by using LinkedIn as a launchpad for their crimes. Two people who lost thousands of dollars to these scams shared their stories with BI.\n\nAn #OpenToWork nightmare.\n\nThis week's quote:\n\n\"My friends say my homes look like serial killer homes. I like it to look like nobody lives there ever. I need you to walk into my house and be like, 'Is this a staged home?'\"\n\n— Nectir cofounder Kavitta Ghai on how she likes her apartment to be set up.\n\nAdityaman Singh\n\nThe Netherlands is the second-biggest agricultural exporter\n\nThe country is only the size of Maryland, but its research hub, Wageningen University and Research, has created a global model for farming. Here's how the Dutch are adjusting to a swath of crises plaguing the industry.\n\nMore of this week's top reads:",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/bi-today-sunday-newsletter-costco-craze-executive-membership-2025-9",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Jensen Huang says China is ‘nanoseconds behind’ the US in chipmaking, calls for reducing US export restrictions on Nvidia's AI chips",
      "content": "Nvidia CEO Jensen Huang says China is just “nanoseconds behind” the U.S. in chipmaking and that Washington should stop trying to wall off the market. Speaking on the BG2 podcast , Huang argued that allowing companies like Nvidia to sell into China would serve American interests by spreading U.S. technology and extending its geopolitical influence. “We’re up against a formidable, innovative, hungry, fast-moving, underregulated [competitor],” Huang said, talking about the pedigree of China’s engineers and controversial 9-9-6 working culture.\n\nHis comments come as Nvidia hopes to ship its H20 AI GPU to Chinese customers again, following a months-long pause tied to new U.S. export rules. The Commerce Department is understood to have begun issuing licenses for the H20 in August , and Nvidia is already working on a successor chip designed to comply with current restrictions while offering better performance. The company has not confirmed specs, but it would be Nvidia’s second attempt to tailor an AI accelerator specifically for the Chinese marke t since the original A100 and H100 bans took effect.\n\nNVIDIA: OpenAI, Future of Compute, and the American Dream | BG2 w/ Bill Gurley and Brad Gerstner - YouTube Watch On\n\nChina, meanwhile, is accelerating its own plans to become self-sufficient. Huawei’s new Atlas 900 A3 SuperPoD systems, powered by the company’s Ascend 910B chips , are now shipping in volume. The company has laid out an ambitious roadmap through 2027 with next-gen Ascend silicon that aims to match or exceed current-gen performance. These systems are CUDA-free by design and optimized for Chinese-built software stacks, a shift that puts real pressure on Nvidia’s dominance, which, according to Huang, previously held a 95% market share in China.\n\nChinese hyperscalers are backing that roadmap with capital. Baidu, Alibaba, Tencent, and ByteDance are all investing in custom silicon, either through internal chip teams or by funding startups. That includes firms like Tencent, which has announced it has fully adapted its infrastructure to support homegrown silicon. Asked what he sees in the near future, Huang said, “They [China] publicly say… they want China to be an open market, they want… companies to come to China and compete in the marketplace… and I believe and I hope that we return to that.”\n\nNvidia’s approach to that is to maintain a foothold in China and play both sides of the geopolitical divide. The H20 may be hobbled compared to the company’s leading chips, but it gives Chinese companies a path to stay within the Nvidia ecosystem — at least for now.\n\nFollow Tom's Hardware on Google News , or add us as a preferred source , to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/jensen-huang-says-china-is-nanoseconds-behind-in-chips",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Prediction: Nvidia Will Be Worth $15 Trillion by 2030 If This One Thing Happens",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/3700b5a891a3a6bc",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Trump’s tariff‑shaped stick can’t beat reality on US chip fabbing",
      "content": "Comment Ending America's reliance on foreign chip fabs remains a high priority for Uncle Sam, but the Trump administration's \"my way or the highway\" approach to the issue threatens to do more harm than good.\n\nWhere the Biden administration sought to use federal subsidies and tax breaks as a carrot to encourage investment in domestic chip production, the current administration's philosophy can best be described as a stick wielded by a capricious bully, unconcerned whether or not his demands can be met, only that concessions are made.\n\nIn some respects, it reflects a modern economic take on Roosevelt's Big Stick ideology, only Trump seems to have ignored the speaking softly bit and jumped straight to swinging his stick like every problem is a piñata with candy inside. Trump need not even swing his stick – all he has to do is make a threat, and those in its path scramble to appease him. And whether you agree with this approach, as life-alteringly disruptive as they might be, he has been effective at getting US companies to bend to his will.\n\nLast month, the US claimed a 10 percent stake in Intel. The $8.9 billion equity deal drew on previously awarded but unpaid CHIPS Act funds, along with the Secure Enclave program. The congressionally-approved funds had already been awarded to the x86 giant, but only a fraction of them had been distributed when Trump took office.\n\nIn March, the threat of massive chip tariffs drove Taiwan Semiconductor Manufacturing Co. (TSMC) to bolster its investment in US manufacturing to the tune of $165 billion. Many months later, the White House still hasn't pulled the trigger on said tariffs.\n\nHowever, as the Wall Street Journal reported on Friday, that could soon change. The Commerce Department is reportedly weighing whether to require US tech companies to manufacture one chip in the US for every chip imported, or pay a tariff. That tariff, Trump warned last month, could be as much as 100%.\n\nCommerce Secretary Howard Lutnick is said to have discussed the idea with industry executives, arguing the measures may be necessary to maintain the US' economic security.\n\nBy some estimates, 90 percent of leading-edge silicon is manufactured by TSMC. The vast majority of that comes from fabs in Taiwan, an island whose sovereignty is a controversial subject for its neighbor 80 miles to the west. US government officials have warned for years that China could exploit the world's continued reliance on Taiwan.\n\nHowever, achieving a 1:1 ratio of chip production to imports may be harder than the White House might think.\n\nTSMC's US build out won't change the calculus much — at least not before Trump's second term expires. Building a leading-edge wafer fab takes years. TSMC's first Arizona foundry site was announced amid the 2020 election, and only this year began ramping up production.\n\nIt's estimated that, when all is said and done, about 30 percent of TSMC's 2nm and smaller fab capacity will eventually be centered in the US, but it'll be years before that happens.\n\nIntel could pick up some of the slack in the meantime. Its new Arizona fabs are already in production, with its first generation of chips based on Intel 18A, a 2nm-class process node. It certainly wouldn't be surprising to see the White House drive potential foundry customers into Intel's arms now that it's a stakeholder in the company's success.\n\nThe problem is it takes years and hundreds of millions of dollars to tape out a chip on a new process node. Companies already evaluating 18A or Intel's forthcoming 14A process tech may be able to move a bit faster, but there are still a lot of ifs. Intel needs to have the capacity to take on new customers, and its fabs will need to achieve high enough yields, or a move could end up costing fab customers more than simply paying the tariffs.\n\nIntel is currently in the process of clawing back products previously outsourced to TSMC, and as such it stands to benefit the most, or perhaps suffer the least, from the reported policy change.\n\nApple, Nvidia, and AMD have insulated themselves to some degree, announcing plans to manufacture chips at TSMC's Fab 21 wafer plant in Arizona. To what extent, however, they haven't said.\n\nFor everyone else who hasn't already signed large-scale commitments with TSMC for domestic fab capacity, avoiding the semi-tariffs will be nearly impossible for the remainder of Trump's second term. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/28/trump_1_1_chip_rule_too_late/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Since 2019, Brazil's courts have developed or implemented over 140 AI projects that have helped make the country's overburdened judicial system more efficient",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/86d71ebd7dc72364",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Here are 3 planets where humans might survive (spoiler: don’t start packing yet!). #TEDTalks",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b0eff0737c93d1bd",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Algeria Set for Inaugural $2.3 Billion Sovereign Sukuk Issuance",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/40d776857efc9ab6",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "The 'Nvidia story' may be coming close to an end, strategist says",
      "content": "The AI story is starting to evolve. It may mean that the \"semis, the Nvidia (NVDA) story is probably coming close to an end,\" Rockland Trust senior vice president and director of research Doug Butler says. Find out why in the video above.\n\nTo watch more expert insights and analysis on the latest market action, check out more Market Domination Overtime.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/nvidia-story-may-coming-close-103005857.html",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Cathie Wood sells $22.3 million of popular tech stock",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/investing/cathie-wood-sells-22-3-million-of-popular-tech-stock",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Canada Joins The Global Push For Sovereign AI With TELUS AI Factory",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/ronschmelzer/2025/09/28/canada-joins-the-global-push-for-sovereign-ai-with-telus-ai-factory/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "AI stock pickers just got an important reminder",
      "content": "This is The Takeaway from today's Morning Brief, which you can sign up to receive in your inbox every morning along with:\n\nWhat we're watching\n\nWhat we're reading\n\nEconomic data releases and earnings\n\nThis has been a week of reminders for investors. There are so many to choose from, I almost don't know where to begin.\n\nFirst, this is an Nvidia (NVDA) market. It's a market that will work for the bulls for as long as Nvidia works. If Nvidia is going to chart a course for AI domination, as seen in its new $100 billion OpenAI (OPAI.PVT) deal on Monday, and the stock gets pushed higher, it's bullish for the broader market.\n\n\"I think AI is a real thing,\" Robinhood chief investment officer Stephanie Guild said on Opening Bid (video above). \"I still think there's a lot of growth in this country. And you're starting to see it in other sectors, ... in aerospace and defense, for example. So I definitely think it's something you have to pay attention to. You have to kind of be invested in whether it's Nvidia or in other kinds of smaller players that benefit.\"\n\nSign up for the Yahoo Finance Morning Brief Subscribe By subscribing, you are agreeing to Yahoo's Terms and Privacy Policy\n\nSecond, if you're a CEO who ignores the retail investor, you do so at your own risk and general foolishness.\n\nOpendoor (OPEN) and now Better Home & Finance (BETR) continue to see wild moves for the simple reason that a hedge fund manager is making strong bullish cases on X.\n\nI have known that hedge fund manager, Eric Jackson, for more than a decade; I used to edit his columns at TheStreet. I am not surprised he has gained a stock-moving following. He puts in the hard work to find undervalued names.\n\nJackson shared more about his views on Opendoor during his last appearance on Opening Bid — it's worth a watch.\n\nLastly, if you're a bear, it will be hard to stay that way as long as the Fed is cutting rates. I think Monday's commentary from new Fed member Stephen Miran on the need for a series of rate cuts is where policy may be headed. This could keep a strong buy-the-dip mentality in markets.\n\nA trader works on the floor of the New York Stock Exchange (NYSE) in New York City as a screen broadcasts a news conference by Federal Reserve Chair Jerome Powell following the Fed rate announcement on Sept. 17. (Reuters/Brendan McDermid/File Photo) · Reuters / Reuters\n\nRead more: How the Fed rate decision affects your bank accounts, loans, credit cards, and investments\n\nHaving said that, I want to get back to the AI trade.\n\nFor the better part of the summer, a black cloud was hanging over this trade, and there was a constant fear that the artificial intelligence buildup was nearing a peak. Suddenly, Wall Street profit estimates for AI companies were deemed too high, valuation multiples too lofty, and sentiment as euphoric as that first sip of coffee at work in the morning.\n\nThis entire thesis was proven to be trash throughout the summer, and even more so right now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/ai-stock-pickers-just-got-an-important-reminder-123045495.html",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "PNY NVIDIA RTX PRO 6000 Blackwell Max-Q 96GB GDDR7 with ECC AI Accelerator Cards - RTX PRO 6000 Blackwell Max-Q $8299.99 at Newegg",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18641941-pny-nvidia-rtx-pro-6000-blackwell-max-q-96gb-gddr7-with-ecc-ai-accelerator-cards-rtx-pro-6000-blackwell-max-q-8299-99-at-newegg",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Fox News AI Newsletter: Trump, Musk aim for dominance",
      "content": null,
      "source": "Fox News",
      "url": "https://www.foxnews.com/tech/ai-newsletter-trump-musk-aim-dominance",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Why Nvidia's Blueprint might be the best tool you'll use for 3D modelling",
      "content": "You may have heard of Nvidia Blueprints, but what are they exactly, and why is the latest addition, the new 3D Object Generation Blueprint, so special?\n\nIf you’ve been following NVIDIA’s AI announcements, you’ll know the company has been talking a lot about Blueprints. These are pre-built AI workflows that bundle together several advanced models into one easy-to-use package. For 3D artists, whether you’re a Blender hobbyist or a professional creating assets for games or film, the new 3D Object Generation Blueprint could be an innovative way to improve your workflow.\n\nTo understand more and why Blueprints matter, I spoke with Michael Fukuyama, Product Manager at Nvidia, who has been leading projects focused on creative, productivity, and generative AI use cases.\n\n(Image credit: Nvidia)\n\nRemoving the obstacles to 3D\n\nAccording to Fukuyama, the appeal of the Blueprint is that it can support a wide range of creators, not just studios with big budgets.\n\n“The 3D Object Generation Blueprint is designed for a wide spectrum of creators, from freelance 3D artists and indie game developers to architects and product designers,” he told me.\n\nThe biggest benefit is speed. Instead of laboriously sourcing stock assets or blocking out rough placeholders, it's possible to generate objects instantly and start refining them.\n\n“An artist working on a ‘city street’ environment could instantly generate 20 candidate objects – benches, lampposts, storefronts, cars – and then decide which to refine. Instead of spending hours searching for stock assets or roughing in placeholders, the artist starts with usable prototypes and can devote more time to creative polish,” Fukuyama explains.\n\nGet the Creative Bloq Newsletter Daily design news, reviews, how-tos and more, as picked by the editors. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFor hobbyists still learning their way around the best 3D modelling software, this can be especially helpful, as it removes the technical bottleneck and lets you focus on the creative side.\n\nThe tech, explained\n\nSo what makes this possible? Nvidia has combined several different AI tools into one streamlined pipeline.\n\n“The Blueprint stitches together several Nvidia NIM microservices and models into a single pipeline,” Fukuyama says, before explaining (deep breath, here comes the tech): “A large language model powered by the Llama 3.1 8B NIM brainstorms object ideas and prompt inputs for Nvidia SANA Sprint, which generates high-resolution preview images of those objects. From there, the Microsoft TRELLIS NIM microservice converts the chosen previews into 3D assets, now accelerated by 20% thanks to PyTorch optimisations within the NIM. By packaging these components, the Blueprint removes the need for users to wire models together themselves and ensures performance is optimised on RTX GPUs.”\n\nLet me break it down. For creators, that means you don’t need to be an AI engineer to get results. Everything runs locally on an RTX GPU, so if you’ve already been shopping around for the best Nvidia graphics cards for your PC, you’re halfway there.\n\nUsable 3D models\n\nA major selling point of the Blueprint is that the models it produces aren’t just placeholders. They’re functional 3D assets you can drop straight into your workflow.\n\n“‘Fully usable’ refers to the fact that generated assets are starting points towards production, not just rough meshes or flat previews,” Fukuyama tells me. “The Microsoft TRELLIS model creates objects with geometry, textures, and materials that can be imported directly into Blender and other 3D applications. While artists may still want to adjust topology or refine textures for final projects, the output is beyond a placeholder; it’s an asset that can immediately populate a scene, test lighting setups, or serve as a foundation for further detailing.”\n\nFor hobbyists, that could mean skipping the grey boxes and getting textured models right away. For pros, it provides a faster base to build on.\n\n(Image credit: Nvidia)\n\nSupport for all 3D software\n\nBlender is the natural starting point for integration, but Nvidia hasn’t limited the Blueprint to one tool.\n\n“Blender is the starting point because it’s free, open source, and used by a huge range of creators,” Fukuyama says. “But the Blueprint exports assets in standard formats, so artists can move them into tools like Maya, Cinema 4D, or 3ds Max without extra steps.”\n\nThat makes it a useful companion to whichever 3D modelling software you prefer to work with. With so many new generative AI tools emerging, it’s worth asking: why choose this one? For Fukuyama, the key lies in performance and ease of use.\n\n“The differentiator is twofold: performance and packaging,” he says. “Many generative 3D tools exist, but they often require heavy setup, technical know-how, or cloud access. Nvidia AI Blueprints bring together proven models, pre-tuned pipelines, and NIM microservices that are optimised to run locally on RTX GPUs. That means creators get faster iteration – 20% faster with TRELLIS on RTX 50 Series – and keep full control of their data and workflows. By combining generative AI with RTX acceleration, we’re making professional-grade 3D workflows accessible to more creators, directly on their AI PCs and workstations.”\n\nThat local-first approach is especially appealing if you’re running your setup on one of the best laptops for 3D modelling, where GPU power and portability go hand in hand.\n\n(Image credit: Nvidia)\n\nTime to try?\n\nFor anyone building 3D environments, the 3D Object Generation Blueprint is designed to take the grunt work out of the process. Whether you’re learning Blender at home or producing assets for a professional game, the promise is the same: more time for creativity, less time hunting for assets. (Read our Blender tutorials for more on how to get started.)\n\nAnd with Nvidia pushing to make its AI Blueprints run seamlessly on RTX GPUs, it’s clear the company is betting that these workflows will become essential tools for the next generation of digital artists, whether you’re experimenting with the best 3D software, starting in animation, or trying the best game development software to bring your ideas to life.\n\nVisit the Nvidia Blueprints website to learn more.",
      "source": "Creative Bloq",
      "url": "https://www.creativebloq.com/3d/why-nvidias-blueprint-might-be-the-best-tool-youll-use-for-3d-modelling",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Have We Reached Peak AI Bubble?",
      "content": "If you can't access your feeds, please contact customer support.\n\nThanks! Check your phone for a link to finish setting up your feed.\n\nPlease enter a valid phone number.\n\nListen on your phone:RECOMMENDED\n\nEnter your phone number and we'll text you a link to set up the podcast in your app:\n\nText me the link!\n\nWe'll only text you about setting up this podcast, no spam.",
      "source": "Slate Magazine",
      "url": "https://slate.com/podcasts/slate-money/2025/09/business-artificial-intelligence-bubble-trump-h-1b-visa-nvidia-openai-enron-memecoin",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "This Week’s Awesome Tech Stories From Around the Web (Through September 27)",
      "content": "Tech OpenAI and Nvidia’s $100B AI Plan Will Require Power Equal to 10 Nuclear ReactorsBenj Edwards | Ars Technica \"Nvidia CEO Jensen Huang told CNBC that the planned 10 gigawatts equals the power consumption of between 4 million and 5 million graphics processing units, which matches the company's total GPU shipments for this year and doubles last year's volume.\"\n\nARTIFICIAL INTELLIGENCE Spending on AI Is at Epic Levels. Will It Ever Pay Off?Eliot Brown and Robbie Whelan | The Wall Street Journal \"This week, consultants at Bain & Co. estimated the wave of AI infrastructure spending will require $2 trillion in annual AI revenue by 2030. By comparison, that is more than the combined 2024 revenue of Amazon, Apple, Alphabet, Microsoft, Meta, and Nvidia, and more than five times the size of the entire global subscription software market.\"\n\nRobotics There Are More Robots Working in China Than the Rest of the World CombinedMeaghan Tobin and Keith Bradsher | The New York Times \"There were more than two million robots working in Chinese factories last year, according to a report released Thursday by the International Federation of Robotics, a nonprofit trade group for makers of industrial robots. Factories in China installed nearly 300,000 new robots last year, more than the rest of the world combined, the report found.\"\n\nBiotechnology Huntington’s Disease Breakthrough: What to Know About the Gene TherapyGrace Wade | New Scientist \"An experimental gene therapy has become the first treatment to successfully slow the progression of Huntington’s disease. While the findings are still preliminary, the approach could be a major breakthrough and may even lead to new therapies for other neurodegenerative conditions, like Parkinson’s and Alzheimer’s.\"\n\nROBOTICS Google DeepMind Unveils Its First 'Thinking' Robotics AIRyan Whitwam | Ars Technica \"Generative AI systems that create text, images, audio, and even video are becoming commonplace. In the same way AI models output those data types, they can also be used to output robot actions. That's the foundation of Google DeepMind's Gemini Robotics project, which has announced a pair of new models that work together to create the first robots that 'think' before acting.\"",
      "source": "Singularity Hub",
      "url": "https://singularityhub.com/2025/09/27/this-weeks-awesome-tech-stories-from-around-the-web-through-september-27/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Nvidia RTX 5070 Ti Super and RTX 5070 Super TDP leaked — long-rumored RTX 50 Super series GPUs appear in power supply calculator",
      "content": "Nvidia's mid-gen refresh for Blackwell is currently best rumored to launch next year at CES 2026. The RTX 50 Super series was recently caught up in the rumor mill, as some current-gen FE cards were delisted from the chipmaker's website, which was later confirmed to be a stock issue. Now, the informal chatter is set to reignite as Seasonic — a leading PSU manufacturer — has just listed a few RTX 50 Super models on its website, as part of its PSU calculator.\n\nVarious PC hardware companies have power supply calculators on their websites these days to not only help customers estimate the wattage they'll be pulling, but also to pick out an appropriate model subsequently. Hence, in these PSU calculators, one of the most crucial questions is that of the GPU: which graphics card would be in your system? For Seasonic, that list of potential nominees includes the unreleased and unannounced RTX 50 Super cards, at least two of which.\n\nSeasonic doesn't list the specs of a GPU beyond its TDP. Still, the RTX 50 Super series is rumored to feature 3 GB memory modules, effectively increasing the VRAM capacity by 50% while keeping the same number of chips onboard. That means the RTX 5070 Super would potentially have 18 GB (up from 12 GB on the 5070) of memory, and the 5070 Ti Super might rock 24 GB (up from 18 GB on the 5070 Ti), which would make them notable upgrades in what is otherwise a similar spec sheet.\n\n(Image credit: Future)\n\nSeasonic states that the 5070 Super has a 275W TDP, which aligns with the leaked specs, as the additional 25W for the 6GB VRAM makes sense. The same goes for the 5070 Ti Super, which has a 350W TDP listed on the PSU calculator, a 50W increase over the standard 5070 Ti. The RTX 5080 Super is conspicuously missing from the website, but a 415W TDP has been leaked for it before. These numbers align with previous industry rumors, so Seasonic's not necessarily leaking anything new, but rather corroborating existing information.\n\nNvidia GeForce RTX 50 Super Series*\n\nSwipe to scroll horizontally Graphics Card GPU Die GPU Cores (CUDA) Memory (Capacity, bus) TDP Price RTX 5090 GB202-300 21,760 32 GB, 512-bit 575 W $2,000 RTX 5080 Super GB203-450 10,752 24 GB, 256-bit ~415 W TBD RTX 5080 GB203-400 10,752 16 GB, 256-bit 360 W $1,000 RTX 5070 Ti Super GB203-350 8,960 24 GB, 256-bit 350 W TBD RTX 5070 Ti GB203-200 8,960 16 GB, 256-bit 300 W $750 RTX 5070 Super GB205-400 6,400 18 GB, 192-bit 275 W TBD RTX 5070 GB205-300-A1 6,144 12 GB, 192-bit 250 W $550 RTX 5060 Ti GB205-300 4,608 8 / 16 GB, 128-bit 180 W $380 / $430 RTX 5060 GB206-250 3,840 8 GB, 128-bit 145 W $300\n\n*Specifications are unconfirmed.\n\nOf course, just because the RTX 50 Super series appears on a random PSU calculator doesn't mean it actually exists, but all signs do point toward it eventually being released. Unannounced GPUs appearing on PSU calculators is actually nothing new, so there's some credence to this model. Nvidia could be waiting till the first anniversary of the Blackwell launch to unveil its mid-gen refresh, which would be at CES next year. More substantial leaks from AIBs should start to emerge around that period, if such a launch is indeed planned.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/gpus/nvidia-rtx-5070-ti-super-and-rtx-5070-super-tdp-leaked-long-rumored-rtx-50-super-series-gpus-appear-in-power-supply-calculator",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "A Chinese company has launched a CUDA-compatible GPU with a RISC-V CPU and a whopping 112GB HBM RAM - I bet Nvidia lawyers won't be happy about that news",
      "content": "China’s Innosilicon launches Fenghua No.3 GPU with RISC-V CPU integration\n\nFenghua No.3 claims CUDA compatibility, 112GB HBM memory, and ray tracing\n\nNew GPU targets AI workloads, gaming, CAD, medical imaging, and 8K displays\n\nInnosilicon Technology has introduced a new GPU in China which combines a RISC-V CPU with a graphics processor claiming compatibility with Nvidia’s CUDA platform.\n\nThe Fenghua No.3 (or Fantasy III as the English translation on the chip shows), the company’s latest flagship, comes equipped with over 112GB of HBM memory and targets a wide range of computing workloads, from AI to gaming.\n\nUnlike its predecessors, which were based on PowerVR IP, the Fenghua No.3 draws on RISC-V architecture and is described by the company as a fully home-grown design.\n\nCUDA compatibility\n\nAt launch, representatives avoided giving detailed specifications, but stressed the chip's support for multiple applications, including scientific computing, CAD, and commercial entertainment.\n\nFenghua No.3 was also billed as the first GPU capable of native DICOM support for medical imaging without specialized displays.\n\nCUDA compatibility is easily the most striking claim, as the technology is proprietary to Nvidia, and few rival GPUs have attempted to replicate compatibility.\n\nIf the claims are accurate, Fenghua No.3 could prove attractive to researchers and developers already relying on Nvidia’s ecosystem, but I can’t imagine Nvidia not taking some form of action to protect its platform and intellectual property.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nIn demonstrations, the card was shown running games such as Tomb Raider and Valorant, but no performance benchmarks, resolution details, or frame rates were provided.\n\nFor professionals, the card supports modern APIs including DirectX 12, Vulkan 1.2, and OpenGL 4.6, as well as hardware-based ray tracing. It's compatible with Windows, Android, UOS, Kylin, and other operating systems.\n\nThe GPU's memory configuration is well suited to AI applications and a single card is said to handle language models of up to 72B parameters, while systems with eight cards reportedly scale to 685B.\n\nThe company also claims compatibility with several Chinese-developed AI models, pointing to ambitions in the country’s domestic AI sector.\n\nInnosilicon claimed support for 8K resolution across six monitors, along with the YUV444 color format, a feature aimed at design and video professionals.\n\nChina has been working toward self-sufficiency in semiconductor technology, and products like the Fenghua No.3 is another example of this, although the card’s real-world performance remains to be seen.\n\nVia ITHome",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/a-chinese-company-has-launched-a-cuda-compatible-gpu-with-a-risc-v-cpu-and-a-whopping-112gb-hbm-ram-i-bet-nvidia-lawyers-wont-be-happy-about-that-news",
      "timestamp": "2025-09-27"
    },
    {
      "source": "The Verge",
      "headline": "Nvidia is partnering up with OpenAI to offer compute and cash",
      "url": "https://www.theverge.com/ai-artificial-intelligence/782624/nvidia-is-partnering-up-with-openai-to-offer-compute-and-cash",
      "timestamp": "2025-09-22",
      "content": "OpenAI is teaming up with Nvidia via a “strategic partnership” that will get the ChatGPT-maker more compute and more cash to develop new models on the road to superintelligence. The partnership, announced Monday, will allow OpenAI to “build and deploy at leas…"
    },
    {
      "source": "Slashdot.org",
      "headline": "Nvidia To Invest $100 Billion in OpenAI",
      "url": "https://slashdot.org/story/25/09/22/1637225/nvidia-to-invest-100-billion-in-openai",
      "timestamp": "2025-09-22",
      "content": "Nvidia will invest up to $100 billion in OpenAI as the AI lab builds data centers requiring 10 gigawatts of power capacity. The 10-gigawatt deployment equals 4 to 5 million GPUs -- the same number Nvidia will ship globally this year. Building one gigawatt of …"
    },
    {
      "source": "Business Insider",
      "headline": "Nvidia is investing up to $100 billion in OpenAI as part of an AI data center deal",
      "url": "https://www.businessinsider.com/nvidia-investing-up-to-100-billion-openai-ai-deal-2025-9",
      "timestamp": "2025-09-22",
      "content": "The two tech titans announced a deal on Monday that will see OpenAI build out \"at least 10 gigawatts\" of AI data centers running Nvidia systems."
    },
    {
      "source": "Business Insider",
      "headline": "Nvidia plans to invest $100 billion into OpenAI. That's uh, a lot of money.",
      "url": "https://www.businessinsider.com/nvidia-100-billion-openai-data-centers-scale-2025-9",
      "timestamp": "2025-09-22",
      "content": "$100 billion is worth something like 333 AI researchers with Meta salaries."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "How to trade the AI boom beyond chips",
      "url": "https://finance.yahoo.com/video/trade-ai-boom-beyond-chips-213601170.html",
      "timestamp": "2025-09-22",
      "content": "When people talk about artificial intelligence stocks, they usually think of chip companies like Nvidia (NVDA) or companies working on large language models,..."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Super Micro (SMCI) Stock Trades Up, Here Is Why",
      "url": "https://finance.yahoo.com/news/super-micro-smci-stock-trades-204708134.html",
      "timestamp": "2025-09-22",
      "content": "Shares of server solutions provider Super Micro (NASDAQ:SMCI) jumped 3% in the afternoon session after the company unveiled a new lineup of AI-optimized..."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Analysts react to Nvidia's $100 billion investment in OpenAI",
      "url": "https://finance.yahoo.com/news/analysts-react-nvidias-100-billion-174101698.html",
      "timestamp": "2025-09-22",
      "content": "Nvidia has used its financial clout to keep its hardware central to the buildout of artificial intelligence systems.  By locking in OpenAI as a strategic..."
    },
    {
      "source": "Stratechery.com",
      "headline": "Nvidia and Intel, Tan’s Earnings Call Negotiation, Deal Specifics",
      "url": "https://stratechery.com/2025/nvidia-and-intel-tans-earnings-call-negotiation-deal-specifics/",
      "timestamp": "2025-09-22",
      "content": "Intel and Nvidia have made a historic deal; it's good for Intel (and Nvidia), but doesn't solve their — and the U.S.'s — fundamental problems."
    },
    {
      "source": "Al Jazeera English",
      "headline": "Nvidia to invest billions in OpenAI as AI race heats up",
      "url": "https://www.aljazeera.com/economy/2025/9/22/nvidia-to-invest-billions-in-openai-as-ai-race-heats-up",
      "timestamp": "2025-09-22",
      "content": "The company will also provide chips for OpenAI’s data centres."
    },
    {
      "source": "Hackaday",
      "headline": "Jenny’s Daily Drivers: KDE Linux",
      "url": "https://hackaday.com/2025/09/22/jennys-daily-drivers-kde-linux/",
      "timestamp": "2025-09-22",
      "content": "Over this series test-driving operating systems, we’ve tried to bring you the unusual, the esoteric, or the less mainstream among the world of the desktop OS. It would become very boring very…"
    },
    {
      "source": "TechRadar",
      "headline": "Nvidia and Intel’s partnership could introduce the huge performance upgrade for handheld gaming PCs I’ve been hoping for",
      "url": "https://www.techradar.com/computing/cpu/nvidia-and-intels-partnership-could-introduce-the-huge-performance-upgrade-for-handheld-gaming-pcs-ive-been-hoping-for",
      "timestamp": "2025-09-22",
      "content": "AMD is arguably running away with the crown in the handheld gaming PC space, with its most powerful SoC challenging an Nvidia RTX GPU, but it might be in trouble after Nvidia and Intel's partnership."
    },
    {
      "source": "PCWorld",
      "headline": "Nvidia and Intel’s collaborative PC chips might not happen for years",
      "url": "https://www.pcworld.com/article/2915876/nvidia-and-intels-collaborative-pc-chips-might-not-happen-for-years.html",
      "timestamp": "2025-09-22",
      "content": "Neither Intel nor Nvidia have said exactly when the first fruits of its co-designed integrated CPUs will ship. But the thinking right now seems to be that it might a take a few years.\r\n\n\n\n\nNvidia announced a $5 billion investment into Intel last week, where I…"
    },
    {
      "source": "Barchart.com",
      "headline": "This Under-the-Radar Data Center Stock Is Soaring Thanks to the AI Boom",
      "url": "https://www.barchart.com/story/news/34960304/this-under-the-radar-data-center-stock-is-soaring-thanks-to-the-ai-boom",
      "timestamp": "2025-09-22",
      "content": "With demand accelerating, Arista’s AI future looks dynamic."
    },
    {
      "source": "Biztoc.com",
      "headline": "OpenAI and NVIDIA announce strategic partnership to deploy 10 gigawatts of NVIDIA systems",
      "url": "https://biztoc.com/x/956917ac11c52198",
      "timestamp": "2025-09-22",
      "content": "News\n- Strategic partnership enables OpenAI to build and deploy at least 10 gigawatts of AI datacenters with NVIDIA systems representing millions of GPUs for OpenAI’s next-generation AI infrastructure.\n- To support the partnership, NVIDIA intends to invest up…"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Bank of America shocks with AMD stock verdict post Nvidia-Intel deal",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_90d22509-969b-469e-8e89-32a72176fc0c",
      "timestamp": "2025-09-21",
      "content": null
    },
    {
      "source": "Windows Central",
      "headline": "It's insane to me that this mini PC can outperform an NVIDIA RTX 5090 with LLMs and AI workloads",
      "url": "https://www.windowscentral.com/hardware/hp/hp-z2-mini-g1a-review",
      "timestamp": "2025-09-21",
      "content": "I've been testing the HP Z2 Mini (G1a), and it's an insanely capable PC that aims to be an all-in-one workstation for AI, LLMs, and other intense workloads."
    },
    {
      "source": "Business Insider",
      "headline": "3 tech workers on H-1B visas detail their last 36 hours: canceled trips, anxious parents, and, finally, relief",
      "url": "https://www.businessinsider.com/h1b-visa-holders-big-tech-last-anxiety-trump-eo-india-2025-9",
      "timestamp": "2025-09-21",
      "content": "Three H-1B visa holders who work in tech said their weekends were filled with panic, anxious parents' phone calls, and putting travel plans on hold."
    },
    {
      "source": "TechRadar",
      "headline": "Nvidia AI sales to reach almost $400 billion by 2028, research claims - but then things will get a bit tricky for the world's largest company",
      "url": "https://www.techradar.com/pro/nvidia-ai-sales-to-reach-almost-usd400-billion-by-2028-claims-research-and-then-things-will-get-a-bit-tricky-for-the-worlds-largest-company",
      "timestamp": "2025-09-21",
      "content": "Nvidia’s AI revenue may reach $400 billion by 2028 - yet slowing growth, rising costs, and competition could pose risks."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Nvidia and Intel's Massive Collaboration: What You Need to Know",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_8033b3a1-5d53-48ef-aefb-33c7968a86e8",
      "timestamp": "2025-09-21",
      "content": null
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Stock market today: Dow, S&P 500, Nasdaq turn higher as Nvidia surges on OpenAI deal",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-dow-sp-500-nasdaq-turn-higher-as-nvidia-surges-on-openai-deal-234423447.html",
      "timestamp": "2025-09-21",
      "content": "A parade of Fed speakers and a key inflation print are in focus for clues to further rate cuts."
    },
    {
      "source": "Biztoc.com",
      "headline": "US Steel changes course and will keep processing raw steel at Granite City plant in Illinois",
      "url": "https://biztoc.com/x/cd4d6da022535782",
      "timestamp": "2025-09-21",
      "content": ""
    },
    {
      "source": "Biztoc.com",
      "headline": "A profile of Noah Urban, who was a key member of the Scattered Spider group because of his social engineering skills and is serving a 10-year prison sentence",
      "url": "https://biztoc.com/x/0e4a790dbb4cf532",
      "timestamp": "2025-09-21",
      "content": ""
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "How Investors May Respond To BlackRock (BLK) Backing NVIDIA-Ready AI Data Centers in the UK",
      "url": "https://finance.yahoo.com/news/investors-may-respond-blackrock-blk-110935960.html",
      "timestamp": "2025-09-21",
      "content": "Earlier this week, NVIDIA announced a partnership with CoreWeave, Microsoft, Nscale, and others to accelerate the AI industrial revolution in the United..."
    },
    {
      "source": "Phoronix",
      "headline": "Linux Ready To Upstream Support For Google's PSP Encryption For TCP Connections",
      "url": "https://www.phoronix.com/news/PSP-Encryption-Linux-6.18",
      "timestamp": "2025-09-21",
      "content": "Not to be confused with AMD's Platform Security Processor (PSP), but Google's PSP Security Protocol (PSP) for encryption in-transit for TCP network connections is now ready for the mainline kernel. This initial PSP encryption support for network connections i…"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Dow, S&P 500, Nasdaq futures pull back from records as gold powers to fresh all-time high",
      "url": "https://finance.yahoo.com/news/live/dow-sp-500-nasdaq-futures-pull-back-from-records-as-gold-powers-to-fresh-all-time-high-234423591.html",
      "timestamp": "2025-09-21",
      "content": "A parade of Fed speakers and a key inflation print are in focus for clues to further rate cuts."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Stock market today: Dow, S&P 500, Nasdaq futures pull back from records as gold powers to fresh high",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-dow-sp-500-nasdaq-futures-pull-back-from-records-as-gold-powers-to-fresh-high-234423457.html",
      "timestamp": "2025-09-21",
      "content": "A parade of Fed speakers and a key inflation print are in focus for clues to further rate cuts."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Dow, S&P 500, Nasdaq futures edge lower on heels of record highs",
      "url": "https://finance.yahoo.com/news/live/dow-sp-500-nasdaq-futures-edge-lower-on-heels-of-record-highs-234423326.html",
      "timestamp": "2025-09-21",
      "content": "Wall Street is debating what's next after the Fed's shift to rate cuts."
    },
    {
      "source": "Forbes",
      "headline": "How To Fix ‘Borderlands 4’ Confirmed Console Performance Problems",
      "url": "https://www.forbes.com/sites/paultassi/2025/09/21/how-to-fix-borderlands-4-confirmed-console-performance-problems/",
      "timestamp": "2025-09-21",
      "content": "PS5 and Xbox have serious performance problems with Borderlands 4, and the way to fix them is a little goofy right now."
    },
    {
      "source": "SiliconANGLE News",
      "headline": "Intel-Nvidia: The baton passes to the CUDA era",
      "url": "https://siliconangle.com/2025/09/20/intel-nvidia-baton-passes-cuda-era/",
      "timestamp": "2025-09-21",
      "content": "In our view, the Intel–Nvidia pact further accentuates Nvidia Corp.’s dominant market position and represents a milestone in the transition to the next era of computing. Just as Intel Corp. had a lock on the market in the ’80s and ’90s, Nvidia has now extende…"
    },
    {
      "source": "Wired",
      "headline": "Distillation Can Make AI Models Smaller and Cheaper",
      "url": "https://www.wired.com/story/how-distillation-makes-ai-models-smaller-and-cheaper/",
      "timestamp": "2025-09-20",
      "content": "A fundamental technique lets researchers use a big, expensive model to train another model for less."
    },
    {
      "source": "Forbes",
      "headline": "Abilene’s Energy Setup",
      "url": "https://www.forbes.com/sites/johnwerner/2025/09/20/abilenes-energy-setup/",
      "timestamp": "2025-09-20",
      "content": "Crusoe spearheads Abilene’s Stargate buildout, financing, constructing, and harnessing renewable energy to power massive Nvidia GPU clusters for AI."
    },
    {
      "source": "Biztoc.com",
      "headline": "‘Time to Sell,’ Warns Top Citi Analyst on Intel Stock after Nvidia-Fueled Rally",
      "url": "https://biztoc.com/x/7a383d5d95a9bf6f",
      "timestamp": "2025-09-20",
      "content": "Top Citi analyst Christopher Danely downgraded Intel (INTC) to Sell from Neutral, even as he raised his price target to $29 from $24. The downgrade came after Intel surged nearly 23% on news that Nvidia (NVDA) will invest $5 billion for a 4% stake and partner…"
    },
    {
      "source": "XDA Developers",
      "headline": "6 operating system luxuries Windows users have never known about Linux",
      "url": "https://www.xda-developers.com/operating-system-luxuries-windows-users-have-never-known-about-linux/",
      "timestamp": "2025-09-20",
      "content": "Windows may seem easier, but Linux has a lot of advantages over it. You might not even know these features exist, but they're fantastic."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "CoreWeave, Inc. (CRWV)’s Deal With NVIDIA Is “Very Good,” Says Jim Cramer",
      "url": "https://finance.yahoo.com/news/coreweave-inc-crwv-deal-nvidia-190514967.html",
      "timestamp": "2025-09-20",
      "content": "We recently published 9 Stocks on Jim Cramer’s Radar. CoreWeave, Inc. (NASDAQ:CRWV) is one of the stocks Jim Cramer recently discussed. CoreWeave, Inc..."
    },
    {
      "source": "XDA Developers",
      "headline": "3 ways I benefited from overclocking my 60Hz monitor",
      "url": "https://www.xda-developers.com/how-i-benefited-from-overclocking-my-60hz-monitor/",
      "timestamp": "2025-09-20",
      "content": "Sometimes, a few extra Hz is all you need"
    },
    {
      "source": "ABC News (AU)",
      "headline": "Bejing's ban on Nvidia chips shows China is catching up, say experts",
      "url": "https://www.abc.net.au/news/2025-09-21/what-makes-china-confident-to-ban-nvdia-microchips/105795486",
      "timestamp": "2025-09-20",
      "content": "Beijing's decision this week to ban Chinese companies from using microchips made by US firm Nvidia indicates the country is increasingly confident about replacing them with domestically produced chips, experts say."
    },
    {
      "source": "Fc2.com",
      "headline": "NVIDIAとの協業後もArc GPUの開発は継続される",
      "url": "https://northwood.blog.fc2.com/blog-entry-12853.html",
      "timestamp": "2025-09-20",
      "content": "Intel Arc GPUs Remain in Development, NVIDIA RTX iGPUs Are Complementary（TechPowerUp）Intel says blockbuster Nvidia deal doesn’t change its own roadmap（PC World）先日、IntelとNVIDIAの協業が発表され、“x86 RTX SoC”の開発が行われることなどが明らかにされたが、Intelによるとこの協業はあくまでも補完的なものであり、Intel自身のGPU…"
    },
    {
      "source": "TheStreet",
      "headline": "Analysts revamp Nvidia stock outlook on its investment in Intel",
      "url": "https://www.thestreet.com/technology/analysts-revamp-nvidia-stock-outlook-on-its-investment-in-intel-",
      "timestamp": "2025-09-20",
      "content": "Analysts provided their opinion on Nvidia stock, following the company's $5 billion investment into Intel."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Daiwa Raises NVDA Target to $205, Says the Chipmaker Is Undervalued",
      "url": "https://finance.yahoo.com/news/daiwa-raises-nvda-target-205-211036995.html",
      "timestamp": "2025-09-20",
      "content": "NVIDIA Corporation (NASDAQ:NVDA) is one of the AI Stocks Analysts Are Tracking Closely. On September 17, Daiwa reiterated the stock as “Outperform” and..."
    },
    {
      "source": "Digitimes",
      "headline": "Intel-Nvidia's twin strategy faces speed test, but PC path leads, says DIGITIMES analyst",
      "url": "https://www.digitimes.com/news/a20250919VL203/nvidia-intel-gpu-cpu-packaging.html",
      "timestamp": "2025-09-20",
      "content": "Nvidia and Intel on Thursday detailed a sweeping product roadmap that links their CPU and GPU platforms, while underscoring continued collaboration with Taiwan Semiconductor Manufacturing Company (TSMC) and pointing to Intel's advanced packaging as an enabler."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Investing.com’s stocks of the week",
      "url": "https://finance.yahoo.com/news/investing-com-stocks-week-083010242.html",
      "timestamp": "2025-09-20",
      "content": "Investing.com -- U.S. stocks rose on Friday and are on track for weekly gains following the Federal Reserve rate cut on Wednesday."
    },
    {
      "source": "Digitimes",
      "headline": "TSMC, Largan, Episil push back on hype with blunt market outlooks",
      "url": "https://www.digitimes.com/news/a20250919PD226/tsmc-market-sic-episil-nvidia.html",
      "timestamp": "2025-09-20",
      "content": "SiC applications recently gained attention following reports that TSMC and Nvidia are pushing for advancements, elevating companies like Episil and its subsidiary EPI into the market limelight. Yet this enthusiasm quickly cooled when Episil chairman Jian-Hua …"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Wedbush: Nvidia–Intel (INTC) Deal Is a “Game Changer” for Struggling Chipmaker",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_8621872a-de20-4848-acaa-aa69eb9c79d6",
      "timestamp": "2025-09-20",
      "content": null
    },
    {
      "source": "Slashdot.org",
      "headline": "Intel Says Blockbuster Nvidia Deal Doesn't Change Its Own Roadmap",
      "url": "https://slashdot.org/story/25/09/19/019243/intel-says-blockbuster-nvidia-deal-doesnt-change-its-own-roadmap",
      "timestamp": "2025-09-19",
      "content": "If you're wondering what effect Intel's blockbuster deal with Nvidia will have on its existing product roadmaps, Intel has one message for you: it won't. PCWorld: \"We're not discussing specific roadmaps at this time, but the collaboration is complementary to …"
    },
    {
      "source": "BBC News",
      "headline": "Faisal Islam: Will the US tech bromance turn around the UK economy?",
      "url": "https://www.bbc.com/news/articles/cn4w7wp24llo",
      "timestamp": "2025-09-19",
      "content": "In the week the UK hosted Donald Trump for a second state visit, the country also rolled out the red carpet for US tech firms."
    },
    {
      "source": "Gizmodo.com",
      "headline": "Nvidia Wants in on the Robotaxi Race",
      "url": "https://gizmodo.com/nvidia-funds-robotaxis-self-driving-cars-wayze-2000661414",
      "timestamp": "2025-09-19",
      "content": "Nvidia is exploring $500 million investment in Wayve Technologies, a London-based AI startup."
    },
    {
      "source": "Forbes",
      "headline": "Cadence Design And Nvidia Team To Create AI Data Center Digital Twin",
      "url": "https://www.forbes.com/sites/karlfreund/2025/09/19/cadence-design-and-nvidia-team-to-create-ai-data-center-digital-twin/",
      "timestamp": "2025-09-19",
      "content": "Digital Twins will become the standard simulation platform for AI Factories. Cadence and Nvidia are working together to make Nvidia infrastructure models"
    },
    {
      "source": "XDA Developers",
      "headline": "Dangerous PC hardware myths for novice PC builders",
      "url": "https://www.xda-developers.com/most-dangerous-pc-hardware-myths-for-new-pc-builders/",
      "timestamp": "2025-09-19",
      "content": "Don't take every piece of PC building advice seriously"
    },
    {
      "source": "TechRadar",
      "headline": "Nvidia gained $150 billion on Intel announcement, more than Intel market capitalization - netting a 30x return on its investment in 24 hours with just $5 billion",
      "url": "https://www.techradar.com/pro/nvidia-gained-usd150-billion-on-intel-announcement-more-than-intel-market-capitalization-netting-a-30x-return-on-its-investment-in-24-hours-with-just-usd5-billion",
      "timestamp": "2025-09-19",
      "content": "Nvidia gained $150 billion in market value after shock Intel partnership announcement, rising to $4.28 trillion cap."
    },
    {
      "source": "Biztoc.com",
      "headline": "Intel Got $5 Billion, but Nvidia Could Be the Big Winner. Here’s Why",
      "url": "https://biztoc.com/x/0fc46dddd53f043f",
      "timestamp": "2025-09-19",
      "content": "With the Intel deal, Nvidia may have just secured its computing dominance."
    },
    {
      "source": "Forbes",
      "headline": "Forbes Daily: Intel Shares Spike After Deal With Rival Nvidia",
      "url": "https://www.forbes.com/sites/daniellechemtob/2025/09/19/forbes-daily-intel-shares-spike-after-deal-with-rival-nvidia/",
      "timestamp": "2025-09-19",
      "content": "Today’s Forbes Daily newsletter covers the fallout from Kimmel's removal, the FTC sues Ticketmaster and Live Nation, Congress alarmed over TikTok deal and more."
    },
    {
      "source": "Forbes",
      "headline": "Novice Investor’s Digest For Friday, September 19",
      "url": "https://www.forbes.com/sites/catherinebrock/2025/09/19/novice-investors-digest-for-friday-september-19/",
      "timestamp": "2025-09-19",
      "content": "Stock prices hit new record highs after interest rates decline and Nvidia announces Intel investment. Also: all-at-once rebalancing or gradual?"
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Nvidia wants 10Gbps HBM4 to blunt AMD’s MI450, report claims — company said to be pushing suppliers for more bandwidth",
      "url": "https://www.tomshardware.com/pc-components/gpus/nvidia-wants-10gbps-hbm4-to-rival-amd-mi450",
      "timestamp": "2025-09-19",
      "content": "Nvidia is reportedly pressing its memory vendors to push beyond JEDEC’s official HBM4 baseline, reportedly requesting 10Gb/s-per-pin stacks for its 2026 Vera Rubin platform."
    },
    {
      "source": "Lwn.net",
      "headline": "Security updates for Friday",
      "url": "https://lwn.net/Articles/1038802/",
      "timestamp": "2025-09-19",
      "content": "Security updates have been issued by Debian (chromium, cjson, and firefox-esr), Fedora (expat, gh, scap-security-guide, and xen), Oracle (container-tools:rhel8, firefox, grub2, and mysql:8.4), SUSE (busybox, busybox-links, element-web, kernel, shadowsocks-v2r…"
    },
    {
      "source": "Biztoc.com",
      "headline": "Asia’s Intel Suppliers Soar on Hopes of Nvidia Investment Boost",
      "url": "https://biztoc.com/x/18e7332c57ac944f",
      "timestamp": "2025-09-19",
      "content": ""
    },
    {
      "source": "SamMobile",
      "headline": "Samsung may supply 10,000 HBM3E chips to Nvidia",
      "url": "https://www.sammobile.com/news/samsung-may-supply-10000-hbm3e-chips-nvidia/",
      "timestamp": "2025-09-19",
      "content": "Last month, we reported that Samsung’s HBM3E chips might have finally met Nvidia's quality standards. Well, we now have information about how many of those chips Samsung will supply to Nvidia for its AI accelerators. According to a report from AlphaBiz, Samsu…"
    },
    {
      "source": "The Verge",
      "headline": "Nvidia invests $5 billion into Intel to jointly develop PC and data center chips",
      "url": "https://www.theverge.com/news/780792/nvidia-intel-investment-pc-chips-data-center",
      "timestamp": "2025-09-18",
      "content": "Nvidia is throwing Intel a $5 billion life raft, just weeks after similar stakes from the US government and SoftBank. Nvidia is investing $5 billion in Intel common stock in a collaboration that will see the pair “jointly develop multiple generations of custo…"
    },
    {
      "source": "Gizmodo.com",
      "headline": "Nvidia Appeals to Trump With a $5 Billion Intel Stake",
      "url": "https://gizmodo.com/nvidia-appeals-to-trump-with-a-5-billion-intel-stake-2000660647",
      "timestamp": "2025-09-18",
      "content": "The two competitors will collaborate to develop PC chips and data centers."
    },
    {
      "source": "Business Insider",
      "headline": "Nvidia CEO explains why he's making a $5 billion bet on struggling chip giant Intel",
      "url": "https://www.businessinsider.com/intel-investment-nvidia-jensen-huang-stock-ai-chip-plans-2025-9",
      "timestamp": "2025-09-18",
      "content": "\"Having Jensen's blessing is priceless,\" wrote Bernstein senior analyst  Stacy Rasgon about Nvidia's $5 billion investment in Intel."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Huawei Unveils New AI Tech to Take on Nvidia",
      "url": "https://finance.yahoo.com/video/huawei-unveils-ai-tech-nvidia-144754921.html",
      "timestamp": "2025-09-18",
      "content": "Huawei Technologies Co. unveiled new technology, including SuperPod cluster designs and AI accelerators, to challenge Nvidia which dominates the market..."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Ives Says Pop the Champagne for Intel After Nvidia Investment",
      "url": "https://finance.yahoo.com/video/ives-says-pop-champagne-intel-143208222.html",
      "timestamp": "2025-09-18",
      "content": "Dan Ives of Wedbush Securities talks about Nvidia agreeing to invest $5 billion in Intel. The companies will co-develop chips for PCs and data centers. The..."
    },
    {
      "source": "Wired",
      "headline": "China Turns Legacy Chips Into a Trade Weapon",
      "url": "https://www.wired.com/story/china-probe-us-chip-makers-tiktok-deal/",
      "timestamp": "2025-09-18",
      "content": "As Washington pushes for a TikTok deal, Beijing is countering with probes into American chipmakers."
    },
    {
      "source": "Barchart.com",
      "headline": "Nvidia CEO Jensen Huang Says 'You Can’t Overstate the Magic' That is Taiwan Semiconductor, But is TSM Stock a Buy at New Highs?",
      "url": "https://www.barchart.com/story/news/34900133/nvidia-ceo-jensen-huang-says-you-cant-overstate-the-magic-that-is-taiwan-semiconductor-but-is-tsm-stock-a-buy-at-new-highs",
      "timestamp": "2025-09-18",
      "content": "Foundry giant Taiwan Semiconductor will play a key role in the new partnership between Nvidia and Intel, according to CEOs Jensen Huang and Lip-Bu Tan."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Nvidia spent over $900 million to hire Enfabrica CEO, license technology, CNBC reports",
      "url": "https://finance.yahoo.com/news/nvidia-spent-over-900-million-223552272.html",
      "timestamp": "2025-09-18",
      "content": "The deal closed last week and Sankar has already joined Nvidia.  Enfabrica, a Silicon Valley-based chip startup, is tackling one of the biggest technical..."
    },
    {
      "source": "Github.com",
      "headline": "Nvmath-Python: Nvidia Math Libraries for the Python Ecosystem",
      "url": "https://github.com/NVIDIA/nvmath-python",
      "timestamp": "2025-09-18",
      "content": "NVIDIA Math Libraries for the Python Ecosystem. Contribute to NVIDIA/nvmath-python development by creating an account on GitHub."
    },
    {
      "source": "Kotaku",
      "headline": "Treyarch Co-Founder Sentenced To Federal Prison After Flying Drone Into Firefighting Aircraft In January",
      "url": "https://kotaku.com/treyarch-co-founder-game-dev-drone-firefighting-plane-jail-time-federal-court-2000626833",
      "timestamp": "2025-09-18",
      "content": "Also: Nvidia and Intel strike up partnership, Microsoft Flight Sim might be coming to PS5, a new Yakuza game has leaked, and be careful while playing classic Doom\nThe post Treyarch Co-Founder Sentenced To Federal Prison After Flying Drone Into Firefighting Ai…"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "China’s Showcase of AI Chip Prowess Triggers $240 Billion Rally",
      "url": "https://finance.yahoo.com/news/china-showcase-ai-chip-prowess-102749077.html",
      "timestamp": "2025-09-18",
      "content": "On Thursday, Huawei for the first time publicly laid out its three-year roadmap for chip development, boasting of “super clusters” and vastly faster AI chips..."
    },
    {
      "source": "Windows Central",
      "headline": "Intel and NVIDIA announce partnership that will see \"jointly developed x86 Intel CPUs fused with RTX GPUs\" in shocking move",
      "url": "https://www.windowscentral.com/hardware/intel/intel-and-nvidia-announce-partnership-that-will-see-jointly-developed-x86-intel-cpus-fused-with-rtx-gpus-in-shocking-move",
      "timestamp": "2025-09-18",
      "content": "NVIDIA is partnering up with Intel to product new chips that fuse x86 Intel CPUs with RTX GPUs in an attempt to compete with AMD APUs, along with helping Intel stay afloat in its fight with TSMC."
    },
    {
      "source": "Theregister.com",
      "headline": "Intel and Nvidia sitting in a tree, NVLink-I-N-G",
      "url": "https://www.theregister.com/2025/09/18/nvidia_intel_deal_nvlink/",
      "timestamp": "2025-09-18",
      "content": "But still no hero customer for Chipzilla's Foundry biz\nNvidia is set to become one of Intel's largest shareholders after the GPU giant announced on Thursday it would invest $5 billion in the struggling chipmaker under a co-development agreement targeting PCs …"
    },
    {
      "source": "Business Insider",
      "headline": "Let's talk about the seating chart for the Trump royal banquet, shall we?",
      "url": "https://www.businessinsider.com/trump-royal-dinner-uk-king-charles-tiffany-kate-seating-chart-2025-9",
      "timestamp": "2025-09-18",
      "content": "Donald Trump sat next to Princess Kate at the UK state dinner attended by business leaders like Tim Cook. Let's see what the seating chart says."
    },
    {
      "source": "Business Insider",
      "headline": "Meet the non-tech companies cashing in on the AI data center spending boom",
      "url": "https://www.businessinsider.com/rolls-royce-caterpillar-cash-in-on-ai-boom-data-centers-2025-9",
      "timestamp": "2025-09-18",
      "content": "As data center spend nears $1 trillion, vendors  like Rolls-Royce, Caterpillar, Schneider Electric, and Vertiv are poised to benefit."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "How Huawei plans to outperform global tech leaders with less powerful chips",
      "url": "https://tech.yahoo.com/ai/articles/huawei-plans-outperform-global-tech-102217556.html",
      "timestamp": "2025-09-18",
      "content": "China's Huawei Technologies said Thursday that it would roll out the world's most powerful AI computing clusters over the next two years as it seeks to..."
    },
    {
      "source": "Business Insider",
      "headline": "The UK is getting a bite-sized version of Stargate, a sweeping AI infrastructure project from OpenAI and Nvidia",
      "url": "https://www.businessinsider.com/stargate-uk-donald-trump-state-visit-ai-openai-nvidia-microsoft-2025-09",
      "timestamp": "2025-09-17",
      "content": "OpenAI, Nvidia, and Nscale partnered for Stargate UK, pledging tens of billions of dollars in AI infrastructure to boost Britain's computing power."
    },
    {
      "source": "Business Insider",
      "headline": "Huawei's affiliate was neighbors with Nvidia in California for a decade. US lawmakers want to know why.",
      "url": "https://www.businessinsider.com/huawei-futurewei-nvidia-california-campus-hq-house-committee-probe-moolenaar-2025-9",
      "timestamp": "2025-09-17",
      "content": "US lawmakers are asking for information about Huawei's US research arm, which they say shared a campus with Nvidia's headquarters."
    },
    {
      "source": "Openai.com",
      "headline": "Introducing Stargate UK",
      "url": "https://openai.com/index/introducing-stargate-uk/",
      "timestamp": "2025-09-17",
      "content": "OpenAI, NVIDIA, and Nscale launch Stargate UK, a sovereign AI infrastructure partnership delivering up to 50,000 GPUs and the UK’s largest supercomputer to power national AI innovation, public services, and economic growth."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "China Just Pulled the Plug on Nvidia's China Workaround--Here's Why That Matters",
      "url": "https://finance.yahoo.com/news/china-just-pulled-plug-nvidias-190414691.html",
      "timestamp": "2025-09-17",
      "content": "Beijing tells Alibaba, ByteDance to cancel RTX 6000D orders as U.S.-China chip war hits new flashpoint"
    },
    {
      "source": "BBC News",
      "headline": "Nvidia boss 'disappointed' by China chip ban",
      "url": "https://www.bbc.com/news/articles/cqxz29pe1v0o",
      "timestamp": "2025-09-17",
      "content": "Jensen Huang told reporters he would be \"patient\" as the US and China grapple for global AI dominance."
    },
    {
      "source": "9to5Mac",
      "headline": "Tim Cook attends Windsor Castle State Banquet as part of Trump’s visit to the UK",
      "url": "https://9to5mac.com/2025/09/17/tim-cook-windsor-castle-state-banquet/",
      "timestamp": "2025-09-17",
      "content": "Apple CEO Tim Cook was among multiple high-profile guests at a state dinner at Windsor Castle on Wednesday, joining King Charles III and Donald Trump. Here are the details.\n\n\n\n more…"
    },
    {
      "source": "Business Insider",
      "headline": "Mark Zuckerberg wowed Meta skeptics this time last year. He's about to try to do it again.",
      "url": "https://www.businessinsider.com/mark-zuckerberg-trying-to-wow-skeptics-ai-glasses-meta-connect-2025-9",
      "timestamp": "2025-09-17",
      "content": "From a neural wristband to new smart glasses with cameras, here is what we could see at Meta Connect 2025, as the company strives to impress."
    },
    {
      "source": "Biztoc.com",
      "headline": "Nvidia boss 'disappointed' by China chip ban",
      "url": "https://biztoc.com/x/aa008ad1dc400e32",
      "timestamp": "2025-09-17",
      "content": "Jensen Huang told reporters he would be \"patient\" as the US and China grapple for global AI dominance."
    },
    {
      "source": "Forbes",
      "headline": "AI’s Next Dividend Bonanza Is NOT Where You Think",
      "url": "https://www.forbes.com/sites/brettowens/2025/09/17/ais-next-dividend-bonanza-is-not-where-you-think/",
      "timestamp": "2025-09-17",
      "content": "While Wall Street chases NVIDIA, the real AI dividend story is unfolding in the sleepy insurance sector. These “boring” firms are quietly leveraging AI tools..."
    },
    {
      "source": "Forbes",
      "headline": "Fed Decision, China AI Chip Ban, And TikTok Deal Dominate Markets",
      "url": "https://www.forbes.com/sites/jjkinahan/2025/09/17/fed-decision-china-ai-chip-ban-and-tiktok-deal-dominate-markets/",
      "timestamp": "2025-09-17",
      "content": "Markets await the Fed’s rate cut decision and guidance, while China bans Nvidia AI chips, TikTok’s U.S. ownership deal advances, and StubHub launches its IPO."
    },
    {
      "source": "TechRadar",
      "headline": "UK sees major investment from some of the biggest names in tech - here's all the top deals announced today",
      "url": "https://www.techradar.com/pro/uk-tech-space-sees-major-investment-from-some-of-the-biggest-names-in-tech-heres-all-the-top-deal-announced-today",
      "timestamp": "2025-09-17",
      "content": "Some of the biggest names in tech have announced billions in investments for UK cloud and AI infrstructure."
    },
    {
      "source": "TheStreet",
      "headline": "Nvidia suffers a major blow from China",
      "url": "https://www.thestreet.com/technology/nvidia-suffers-a-major-blow-from-china-",
      "timestamp": "2025-09-16",
      "content": "The company keeps running into setbacks in this important market."
    },
    {
      "source": "Windows Central",
      "headline": "\"Substantially superior to FSR 3.1\" — How modders forced FSR 4 upscaling onto unsupported AMD and NVIDIA cards",
      "url": "https://www.windowscentral.com/hardware/amd/fsr-4-rdna-2-3-nvidia-amd-unsupported",
      "timestamp": "2025-09-16",
      "content": "Remember that FSR 4 source code leak on GitHub from a few weeks ago? Someone used it to get AMD's latest upscaler running on unsupported hardware."
    },
    {
      "source": "The Indian Express",
      "headline": "Why China is investigating Nvidia for ‘violating’ its anti-monopoly laws",
      "url": "https://indianexpress.com/article/explained/explained-sci-tech/china-investigating-nvidia-us-ai-race-10253528/",
      "timestamp": "2025-09-16",
      "content": "China’s scrutiny of Nvidia is not being seen as an isolated case, but the latest in a series of actions in its AI race with the United States."
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Chinese giant Tencent announces domestic AI chip push — says it has fully adapted infrastructure to support homegrown silicon in blow to Nvidia",
      "url": "https://www.tomshardware.com/tech-industry/semiconductors/tencent-goes-public-with-pivot-to-chinese-chips",
      "timestamp": "2025-09-16",
      "content": "Tencent goes public with its pivot to Chinese accelerators, highlighting a deeper break from Nvidia as domestic AI hardware matures."
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Nvidia tipped to be TSMC's first 16A customer, ahead of Apple — Feynman GPUs could make full use of GAA transistors and backside power",
      "url": "https://www.tomshardware.com/tech-industry/semiconductors/nvidia-dethrones-apple-to-debut-tsmc-a16",
      "timestamp": "2025-09-16",
      "content": "Nvidia will be the first customer to use TSMC’s A16, a 1.6nm-class process that marries gate-all-around (GAA) transistors with backside power delivery."
    },
    {
      "source": "Forbes",
      "headline": "AVGO Stock vs. NVDA & INTC",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/16/avgo-stock-vs-nvda--intc/",
      "timestamp": "2025-09-16",
      "content": "The key question is: How does AVGO stock now compare to its peers, such as NVIDIA, Qualcomm, Intel, and Cisco, in terms of size, valuation, growth, and margins?"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "JPMorgan Keeps Overweight Rating on NVDA",
      "url": "https://finance.yahoo.com/news/jpmorgan-keeps-overweight-rating-nvda-185032696.html",
      "timestamp": "2025-09-16",
      "content": "NVIDIA Corporation (NASDAQ:NVDA) is one of the 10 Unrivaled Stocks of the Next 3 Years. On September 4, JPMorgan reaffirmed an Overweight rating on NVIDIA..."
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Nvidia's China-exclusive RTX 6000D reportedly gets lukewarm reception in China due to hobbled performance — could leave Nvidia with huge backlog of unwanted GPUs",
      "url": "https://www.tomshardware.com/pc-components/gpus/nvidias-china-exclusive-rtx-6000d-reportedly-gets-lukewarm-reception-in-china-due-to-hobbled-performance-could-leave-nvidia-with-huge-backlog-of-unwanted-gpus",
      "timestamp": "2025-09-16",
      "content": "Nvidia may struggle to sell the reported two million RTX6000D Chinese GPUs it's set to produce this year, as Chinese firms are showing lukewarm interest amidst ongoing trade negotiations and the uncertain future of Nvidia's B30A GPU."
    },
    {
      "source": "Biztoc.com",
      "headline": "Nvidia Stock Falls. Reasons to Look Past China Fears",
      "url": "https://biztoc.com/x/41299aae0239f81b",
      "timestamp": "2025-09-16",
      "content": ""
    },
    {
      "source": "Forbes",
      "headline": "The Nvidia Deal And Taxing Exports: The Constitutionality Of It All",
      "url": "https://www.forbes.com/sites/taxnotes/2025/09/16/the-nvidia-deal-and-taxing-exports-the-constitutionality-of-it-all/",
      "timestamp": "2025-09-16",
      "content": "In this episode of Tax Notes Talk, Tax Notes contributing editors Robert Goulder and Joseph Thorndike discuss the recent Nvidia deal to export chips to China, and they question its constitutionality and implications."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "NVIDIA Corporation (NVDA): A Bull Case Theory",
      "url": "https://finance.yahoo.com/news/nvidia-corporation-nvda-bull-case-154545960.html",
      "timestamp": "2025-09-16",
      "content": "We came across a bullish thesis on NVIDIA Corporation on Compounding Your Wealth’s Substack by Sergey. In this article, we will summarize the bulls’ thesis..."
    },
    {
      "headline": "Business leaders including Jensen Huang, Sam Altman, and Reed Hastings, react to Trump's H-1B visa fee",
      "content": "Business leaders such as Jensen Huang, Sam Altman, and Kevin O'Leary have weighed in on President Donald Trump's $100,000 fee for H-1B visas.\n\nBusiness leaders such as Jensen Huang, Sam Altman, and Kevin O'Leary have weighed in on President Donald Trump's $100,000 fee for H-1B visas. Chesnot via Getty Images; Andrew Harnik via Getty Images; Christopher Willard/Disney via Getty Images\n\nBusiness leaders such as Jensen Huang, Sam Altman, and Kevin O'Leary have weighed in on President Donald Trump's $100,000 fee for H-1B visas. Chesnot via Getty Images; Andrew Harnik via Getty Images; Christopher Willard/Disney via Getty Images\n\nlighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nBusiness leaders such as Nvidia CEO Jensen Huang and Netflix chairman Reed Hastings have been weighing in on President Donald Trump's new $100,000 fee on H-1B visas.\n\nThe US issues roughly 85,000 new H-1B visas via a lottery system every year. The H-1B program is highly popular among US companies looking to hire foreign workers for in-demand roles such as tech and engineering.\n\nOn Friday, Trump signed an executive order raising the H-1B visa application fee by $100,000. The White House told Business Insider that the fee would only apply to new applicants, not those renewing their H-1B visas.\n\nDo you have experience with the H-1B visa program? Business Insider wants to hear from you. Please fill out this quick form.\n\nThe sudden move has sparked concerns among Big Tech firms like Amazon, Meta, and Microsoft, whose workers are on H-1B visas. All three companies told their employees on the visa not to leave the US or to quickly return to the country if they were overseas.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/business-leaders-react-trump-h-1b-visa-fee-2025-9",
      "timestamp": ""
    },
    {
      "headline": "Jensen Huang and Sam Altman react to new H-1B $100K fee",
      "content": "Nvidia CEO Jensen Huang, pictured here with President Donald Trump, and OpenAI CEO Sam Altman reacted to the H-1B visa changes in an interview on Monday.\n\nlighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nNewly announced changes to the H-1B visa program sparked confusion and chaos in Silicon Valley over the weekend, but two of tech's most prominent leaders seem optimistic.\n\nCNBC interviewed Nvidia CEO Jensen Huang and OpenAI CEO Sam Altman on Monday about changes to the H-1B program, days after President Donald Trump signed an executive order adding a $100,000 fee to the visa application.\n\n\"We want all the brightest minds to come to the United States. Remember immigration is the foundation of the American dream, and we represent the American dream,\" Huang said. \"And so I think immigration is really important to our company and is really important to our nation's future, and I'm glad to see President Trump making the moves he's making.\"\n\nNvidia is one of the largest employers of H-1B visa holders in the United States. The company had 1,519 H-1B filings, out of 36,000 employees worldwide at the end of fiscal year 2025, a Business Insider analysis found in March.\n\nAltman also chimed in on the topic, adding, \"We need to get the smartest people in the country, and streamlining that process and also sort of aligning financial incentives seems good to me.\"\n\nHuang and Altman appeared together to announce a $100 billion investment Nvidia is making in OpenAI.\n\nA spokesperson for Nvidia declined to comment. OpenAI didn't respond to a request for comment.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nThe H-1B executive order sparked uncertainty on Friday, with companies such as Amazon and Microsoft telling their employees on the visa not to leave the United States or, if they were already out of the country, to quickly return.\n\nThe White House on Saturday said the new six-figure H-1B application fee would apply only to new applicants, rather than workers who had already received the visa.\n\nWhite House officials have said the fee will help ensure the visa is used to bring in highly skilled workers and not for jobs that could otherwise go to American workers.\n\nBig Tech firms, including Amazon, Microsoft, Meta, Google parent Alphabet, and Apple, collectively employ thousands of workers on H-1B visas.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/jensen-huang-sam-altman-react-new-h1b-100k-fee-2025-9",
      "timestamp": ""
    },
    {
      "headline": "The big challenge to OpenAI's $100B deal with Nvidia: Access to power",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nThey've got the money and the chips. Now they need the power.\n\nNvidia announced Monday that it plans to invest $100 billion in OpenAI in a deal that would give the ChatGPT maker a major leg up in the AI race — access to 10 gigawatts worth of the high-powered GPUs it needs to satisfy its mushrooming growth strategy.\n\nWhat the deal can't guarantee — and what neither company mentioned — is how OpenAI will access the enormous amount of electricity needed to fire up those chips.\n\n\"It is a huge hurdle to get access to power,\" said Benjamin Hertz-Shargel, head grid expert at the energy consulting firm Wood Mackenzie. Monday's deal announcement, he added, is \"a far cry\" from a finished data center.\n\nThe deal, which the companies committed to in a letter of intent, highlights a growing constraint of the AI race: Access to electricity. The US power grid is already strained by an explosion of data center construction. Adding another 10 gigawatts of demand would amount to adding a power load nearly equivalent to New York City at its summer peak.\n\n\"Nationally, utilities are reporting the need for about 60 gigawatts of new power — six large cities' worth — to serve new data centers by the end of the decade,\" said Rob Gramlich, an energy policy consultant and founder of Grid Strategies.\n\nOpenAI declined to comment for this story, but its deal with Nvidia underscores the physical and financial challenges required to develop and commercialize AI. Beyond cutting-edge software, leaders must have access to chips, data centers, and the electricity needed to power that infrastructure.\n\n\"Infrastructure is critical to everything we do,\" OpenAI CEO Sam Altman said in a joint interview with Nvidia CEO Jensen Huang on CNBC on Monday. \"Without doing this, we can't deliver the services people want.\"\n\nThe 'silent bottleneck'\n\nLimited access to power amid rampant data center growth is \"the silent bottleneck\" slowing the pace of Big Tech's ambitions for AI, said Brad Gastwirth, global head of research and market intelligence at Circular Technology.\n\nData centers access electricity the same way everyone else does — by connecting to the power grid through public utility companies and paying them for service. However, connecting to the power grid can come with a slew of regulatory and financial hurdles that are only increasing as utilities struggle to keep up with skyrocketing demand.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nThe surge in new service requests from data centers is so unprecedented that it has overwhelmed the country's major utilities and sparked a mad dash to build new infrastructure — a complex process that requires years of planning and regulatory approval.\n\nAs more data centers line up to connect, new development is being curbed. Commercial real estate services firm CBRE said that roughly 5.2 gigawatts of new data centers were underway in prime US markets in the first half of 2025, a 17.5% decline in the industry's construction pipeline from the same period a year prior, and that the limiting factor was power to light them up.\n\nAn additional 10 gigawatts of new demand adds even more pressure to an already strained system — and it represents only a slice of the electricity OpenAI will ultimately need to power its AI plans.\n\nIn July, OpenAI and Oracle announced they'd finalized plans to develop 4.5 gigawatts of data center capacity, including a site in Abilene, Texas, that was announced in January as part of Stargate, a $500 billion joint venture between OpenAI, Oracle, and SoftBank.\n\nNvidia declined to comment on whether an official contract had been signed, but a spokesperson for the company said that the 10 gigawatts of demand announced Monday is new and is not accounted for in any of OpenAI's previously announced plans.\n\nWhile the media focuses on stock market fluctuations and the inner workings of tech companies, \"the industry is worried about power,\" said Gastwirth.\n\nBig Tech needs to 'get creative'\n\nIt's against this backdrop that access to electricity is gaining in value. One of the year's largest merger and acquisition deals in the data center sector has been imperiled because shareholders believe the takeover target is worth more, in part because of its access to power.\n\nThe US power grid, as it stands today, was built in the 1950s and 1960s. It was due for major upgrades before the data center development boom, but the AI race has made new power plants and power lines — and a lot of them — a more urgent necessity. The US Department of Energy has warned that the number of blackouts in the US could increase by 100 in 2030 if new power infrastructure is not built.\n\nSome data center operators have taken matters into their own hands, bypassing public utilities and going \"off grid\" to build their own on-site power plants. The first Stargate site in Abilene has done this with on-site natural gas turbines. Elon Musk has been powering his xAI data center in Memphis with natural gas generators for months, drawing ire from environmental and community activists who say they are a risk to air quality and public health.\n\nThe tech industry will have to \"get creative\" to solve the power problem, Gastwirth said. \"This is going to become a bigger and bigger issue as each year progresses.\"\n\nBig Tech companies have significantly ramped up investment in the energy sector, pouring hundreds of millions of dollars into emerging technologies like hydrogen fuel cells and nuclear fusion. Amazon and Microsoft have signed deals to buy electricity from major industrial nuclear plants. Altman himself is a major investor in Oklo, a small modular reactor company that has, despite its pending regulatory approval, has already signed deals to power data centers.\n\nDespite the current challenges in accessing power, experts largely see OpenAI's deal with Nvidia as a smart strategic move, cementing the status of both companies as AI's leading players.\n\nSean Farney, executive director of data center strategy and innovation and Jones Lang Lasalle, said that Nvidia is the \"lead horse\" in the development of cutting-edge AI processors and that OpenAI's deal to secure that equipment was \"brilliant.\"\n\n\"It's the two leaders getting together to ensure that they will continue to be the leaders,\" Farney said.\n\nThe power problem, said Farney, will work itself out.\n\n\"They will find or self-source the power to make this happen. There's too much interest and dollar signs on this deal,\" he said.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/openai-nvidia-partnership-100b-data-centers-access-power-electricity-2025-9",
      "timestamp": ""
    },
    {
      "headline": "Presight CEO: NVIDIA's Investment in OpenAI Exciting",
      "content": "Nvidia will invest as much as $100 Billion in OpenAI to support new data centers and other AI infrastructure. Meanwhile in Abu Dhabi, Presight & Shorooq have launched a new $100 Million fund to invest in the next gen AI breakthroughs. Thomas Pramotedham, CEO of Presight told Bloomberg's Horizons Middle East and Africa anchor Joumanna Bercetche about the fund as well as the deal between NVIDIA & OpenAI.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/presight-ceo-nvidias-investment-openai-060045636.html",
      "timestamp": ""
    },
    {
      "source": "Business Insider",
      "headline": "Sam Altman wants to build 1 gigawatt of 'AI infrastructure' a week — enough to power 876,000 households a year",
      "url": "https://www.businessinsider.com/sam-altman-ai-infrastructure-1-gw-per-week-stargate-2025-9",
      "timestamp": "2025-09-23",
      "content": "Sam Altman wrote in a blog post that a lot of the AI infrastructure will be built in the US.\n\nSam Altman wrote in a blog post that a lot of the AI infrastructure will be built in the US. Andrew Harnik/Getty Images\n\nSam Altman wrote in a blog post that a lot of the AI infrastructure will be built in the US. Andrew Harnik/Getty Images\n\nlighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nSam Altman just shared an ambitious goal for rapidly scaling artificial intelligence: Build a factory capable of producing one gigawatt of new \"AI infrastructure every week.\"\n\nIn a Tuesday blog post titled \"Abundant Intelligence,\" the OpenAI CEO said that the \"groundwork\" for building out AI infrastructure is being put in place as more people rely on AI.\n\n\"Our vision is simple: we want to create a factory that can produce a gigawatt of new AI infrastructure every week,\" Altman wrote, adding that the \"execution of this will be extremely difficult\" and will take years to accomplish the goal.\n\n\"In our opinion, it will be the coolest and most important infrastructure project ever,\" he said.\n\nAltman's post said that \"a lot\" of the infrastructure will be built in the US and that more details on partners and plans to make the goal a reality will be unveiled over the next couple of months.\n\nWhile Altman did not cite specific projects, one of the major vehicles that could help with Altman's scaling efforts is Stargate, a $500 billion joint AI infrastructure project between OpenAI, Oracle, and Softbank.\n\nThe first Stargate data center is under construction in Abilene, Texas.\n\nA gigawatt of AI infrastructure — enough to power 876,000 households for a year — per week could also support some of OpenAI's other recently announced ventures.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nOn Monday, Nvidia announced a $100 billion investment in Altman's startup, giving it access to at least 10 gigawatts of AI datacenters.\n\nOpenAI also announced on Tuesday five more AI data center sites for its Stargate project, including the Abilene facility, which would deliver nearly 7 gigawatts of capacity.\n\nThe lingering question following both announcements is where exactly OpenAI will get the energy to power these systems.\n\nEnergy experts previously told Business Insider that getting access to the electricity needed by the Nvidia deal alone will be a challenge.\n\nBrad Gastwirth, global head of research and market intelligence at Circular Technology, described the issue to BI as the \"silent bottleneck\" for the tech industry's goals to scale AI.\n\n\"This is going to become a bigger and bigger issue as each year progresses,\" he said.\n\nSpokespeople for OpenAI did not respond to a request for comment."
    },
    {
      "source": "Business Insider",
      "headline": "20 tech giants that could be hit hardest by President Donald Trump's $100,000 H-1B visa fees",
      "url": "https://www.businessinsider.com/h1b-visa-fee-hike-tech-giants-hit-hardest-donald-trump-2025-9",
      "timestamp": "2025-09-23",
      "content": "lighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nAn executive order signed by President Donald Trump late Friday, hiking H-1B visa application fees to $100,000, sent Silicon Valley into a tailspin.\n\nH-1B visas have become a mainstay of the tech industry, allowing companies to hire highly-skilled workers from abroad, including engineers.\n\nAffected tech workers and corporate lawyers initially scrambled to decipher the new policies, with companies like Amazon, Microsoft, and Meta telling employees on H-1B visas to either stay in the US or return from abroad within 24 hours.\n\nThe Trump administration subsequently clarified that the fees would only apply to new applicants, not renewals or current H-1B holders.\n\nThe Trump administration said it implemented the changes to prevent system \"abuses\" and to encourage companies to train American workers.\n\nSome applauded the new policy, including Netflix cofounder Reed Hastings, who said it could mean the end of the lottery system, given H-1Bs are capped at 85,000 workers annually. Others worried cash-strapped startups would be most severely affected, or that the executive order could counterintuitively push more jobs out of the country.\n\nBusiness Insider examined publicly available data from the Department of Labor and US Citizenship and Immigration Services (USCIS) to track which tech companies had the most H-1B visa approvals in 2025.\n\nBloomberg, Intel, and Nvidia declined to comment. The rest of the companies on this list did not respond to requests for comment from Business Insider.\n\nDo you have experience with the H-1B visa program? Business Insider wants to hear from you. Please fill out this quick form."
    },
    {
      "source": "CNET",
      "headline": "Nvidia Invests in OpenAI With $100 Billion to Build Out More AI Data Centers",
      "url": "https://www.cnet.com/tech/services-and-software/nvidia-invests-in-openai-with-100-billion-to-build-out-more-ai-data-centers/",
      "timestamp": "2025-09-23",
      "content": "OpenAI and Nvidia have struck one of the biggest partnerships in AI, with Nvidia pledging to invest up to $100 billion in OpenAI while supplying the compute power needed to build the company's next generation of models.\n\nThe deal, announced Monday in a letter of intent, calls for OpenAI to deploy at least 10 gigawatts of Nvidia systems for AI data centers over the coming years. The first phase, one gigawatt, is scheduled for the second half of 2026 on Nvidia's upcoming Vera Rubin platform, named for the late dark-matter astronomer. Nvidia's investment will grow in scale as each new system is deployed.\n\n(Disclosure: Ziff Davis, CNET's parent company, in April filed a lawsuit against ChatGPT maker OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\n\nDon't miss any of our unbiased tech content and lab-based reviews. Add CNET as a preferred Google source.\n\n\"Everything starts with compute,\" said OpenAI CEO Sam Altman in a statement. \"Compute infrastructure will be the basis for the economy of the future, and we will utilize what we're building with Nvidia to both create new AI breakthroughs and empower people and businesses with them at scale.\"\n\nRead also: Is AI Capable of 'Scheming?' What OpenAI Found When Testing for Tricky Behavior\n\nThis partnership is notable as AI research is increasingly constrained by access to massive computing resources. By securing a long-term pipeline of Nvidia hardware, OpenAI seeks to guarantee its ability to keep pace with rivals like Google, Anthropic, Microsoft and Meta.\n\nFor Nvidia, the deal makes it more than just a supplier. By gradually taking a large stake in OpenAI, it positions itself at the center of the AI boom, buying into the biggest AI company.\n\n\"This is the biggest AI infrastructure project in history,\" Nvidia CEO Jensen Huang said in a statement.\n\nRead also: OpenAI Is Building a Teen-Friendly Version of ChatGPT\n\nThe completion of this deal will take years. If the partnership holds, it could define how quickly AI advances, what kinds of models OpenAI can deliver in the future and how accessible those models will be to the global population.\n\nOpenAI is already using Nvidia systems in its Stargate I data center, a sprawling facility in Abilene, Texas, that is still under construction."
    },
    {
      "source": "Windows Central",
      "headline": "NVIDIA to invest $100 billion in OpenAI — after Microsoft backed out of two data center deals to escape additional ChatGPT training support",
      "url": "https://www.windowscentral.com/artificial-intelligence/nvidia-to-invest-usd100-billion-in-openai-after-microsoft-backed-out-of-two-data-center-deals-to-escape-additional-chatgpt-training-support",
      "timestamp": "2025-09-23",
      "content": "It's not a surprise that generative AI demands an exorbitant amount of computing power for its sophisticated advances. Top AI labs like Google, OpenAI, and Anthropic frequently talk about this specific topic, especially when unveiling new products and features that cause a demand surge.\n\nPerhaps in a bid to keep up with this trend, NVIDIA recently announced its plan to invest up to $100 billion in OpenAI. The strategic partnership will allow the ChatGPT maker to build at least 10 gigawatts of AI datacenters, which will help train and run next-gen AI models and even potentially create the path toward superintelligence.\n\nIt's worth noting that the first gigawatt of NVIDIA systems is set to be deployed in the second half of 2026 on the Nvidia Vera Rubin platform. The chipmaker's first $10 billion investment in OpenAI will be made once both parties reach an agreement for OpenAI to purchase NVIDIA chips. However, reports suggest that NVIDIA's first $10 billion investment will be deployed when the first gigawatt is completed.\n\nWhile making the announcement, OpenAI CEO Sam Altman indicated:\n\n“Everything starts with compute. Compute infrastructure will be the basis for the economy of the future, and we will utilize what we’re building with Nvidia to both create new AI breakthroughs and empower people and businesses with them at scale.”\n\nAt the beginning of the year, OpenAI unveiled its $500 billion Stargate project, designed to facilitate the construction of data centers across the United States to power its AI advances. Consequently, Microsoft lost its exclusive cloud provider status for OpenAI, though it still holds the right of first refusal.\n\nNVIDIA and OpenAI are set to finalize the new partnership details in the coming weeks, potentially addressing the ChatGPT maker's cloud compute woes.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nSam Altman admits OpenAI is compute-constrained\n\nOpenAI CEO Sam Altman admits that the company is compute-constrained thus limiting its offerings. (Image credit: Getty Images | JOHN MACDOUGALL)\n\nEarlier this year, OpenAI CEO Sam Altman claimed that the company was no longer compute-constrained, despite Microsoft backing out from two mega data center deals because it did not want to provide additional training support for ChatGPT.\n\nBut following the new partnership announcement between OpenAI and NVIDIA, Sam Altman indicated:\n\n\"The compute constraints that the whole industry has been, and our company in particular have been terrible. We're so limited right now in the services we can offer. There is so much more demand than what we can do.\"\n\nThe executive further elaborated that the compute constraints would place OpenAI in a tough spot within the next two years, forcing it to make painful tradeoffs. He indicated that the company might be forced to choose between curing cancer through research or providing free education to everyone on earth with 5-10 gigawatts of compute power.\n\nFollow Windows Central on Google News to keep our latest news, insights, and features at the top of your feeds!"
    },
    {
      "source": "Business Insider",
      "headline": "Jimmy Kimmel's return doesn't mean the end of Disney's problems",
      "url": "https://www.businessinsider.com/jimmy-kimmel-live-returns-disney-problems-2025-9",
      "timestamp": "2025-09-23",
      "content": "Host Jimmy Kimmel speaks onstage during the 95th Annual Academy Awards at Dolby Theatre on March 12, 2023 in Hollywood, California.\n\nHost Jimmy Kimmel speaks onstage during the 95th Annual Academy Awards at Dolby Theatre on March 12, 2023 in Hollywood, California. Kevin Winter/Getty Images\n\nHost Jimmy Kimmel speaks onstage during the 95th Annual Academy Awards at Dolby Theatre on March 12, 2023 in Hollywood, California. Kevin Winter/Getty Images\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nHello! Jim Cramer is known to take some heat for his stock picks, but it was his bashing of GameStop's 2021 meme rally that led him to hire a bodyguard.\n\nIn today's big story, Jimmy Kimmel returns to the late-night airways.\n\nWhat's on deck:\n\nMarkets: With rate cuts rolling in, are you wondering how to invest? Wall Street has some ideas.\n\nTech: Nvidia and OpenAI now have 100 billion reasons to help each other succeed.\n\nBusiness: There still isn't a deal to keep TikTok in the US, but here's what one could look like.\n\nBut first, give a big round of applause (or don't) for my next guest.\n\nIf this was forwarded to you, sign up here.\n\nThe big story\n\nKimmel's comeback\n\nRandy Holmes/ABC via Getty Images\n\nIt turns out \"Jimmy Kimmel Live!\" isn't going anywhere just yet.\n\nLess than a week after being suspended \"indefinitely\" over comments regarding Charlie Kirk, Jimmy Kimmel is scheduled to return to late-night television tonight.\n\n(If you're completely out of the loop, we recapped all the Kimmel drama and why it matters in Friday's newsletter.)\n\nIn a statement that probably went through more lawyers and PR people than I can count, Disney said it pulled Kimmel off the air \"to avoid further inflaming a tense situation at an emotional moment for our country.\" Kimmel's comments were \"ill-timed\" and \"insensitive,\" the House of Mouse added\n\nHowever, after some \"thoughtful conversations with Jimmy,\" Disney is bringing the show back.\n\nReactions from both ends of the spectrum quickly followed. Other late-night hosts welcomed his return. Some high-profile celebs and politicians celebrated the move as a win for free speech (California Gov. Gavin Newsom, Zohran Mamdani). Others felt Disney caved (Turning Point USA spokesman Andrew Kolvet).\n\nKimmel's return comes with a slight caveat: Some viewers might still be unable to watch the show. That's because Sinclair, which played a key role in Kimmel's initial suspension, said it would not air the show on the 39 ABC affiliate stations it owns or controls.\n\nSinclair, which is the largest ABC affiliate, said it will air news programming instead and that discussions with ABC about the show's return are \"ongoing.\" Sinclair had issued a list of demands it wanted met before bringing the show back.\n\nMeanwhile, FCC Chair Brendan Carr referred BI to comments he made earlier Monday, in which he reiterated his agency's goal of trying to \"empower local TV stations to serve the needs of the local communities.\"\n\nCarr, who last week said, \"This is a very, very serious issue right now for Disney. We can do this the easy way or the hard way,\" also pushed back on the idea that the FCC threatened to revoke Disney and ABC's licenses if they didn't fire Kimmel.\n\nIn the meantime, Disney finds itself in a tricky situation.\n\nOn the one hand, reinstating Kimmel is bound to make plenty of people happy. More than 400 celebrities signed a letter in support of Kimmel. There were also calls to boycott Disney due to the suspension.\n\nBut those who felt Kimmel's suspension was justified aren't likely to be happy about his return. (Whether they were supporters of Disney in the first place remains to be seen.) And even those who welcome Kimmel's return might still resent Disney for initially suspending him.\n\nAnd then there's the question of late night. The TV model for late-night shows was already fragile long before last week. But now that Kimmel and his show have become a lightning rod, any decision about the show going forward will be viewed with a magnifying glass and likely lead to more controversy.\n\n3 things in markets\n\nBank of America's Merrill and Wells Fargo are offering spot bitcoin ETF's to some of their clients as the investment vehicle surges in demand, Bloomberg Reported Hannes P Albert/picture alliance via Getty Images\n\nCrypto prices tanked after hordes of traders rushed to liquidate their positions. Over 407,000 investors dumped positions on the crypto derivatives market in the 24 hours leading up to Monday, according to Coinglass data. Bitcoin fell 3%, while ethereum and dogecoin dropped as much as 9%.\n\nA new chapter for the stock market. The Fed's recent rate cut was met with a mostly neutral market response, but Wall Street forecasters are eyeing new investment opportunities. Here's where Bank of America, Goldman Sachs, and others think investors should put their money.\n\nTylenol maker's stock tanks. News of the White House planning to link the use of Tylenol during pregnancy to autism caused shares for the drugmaker, Kenvue, to fall as much as 8%.\n\n3 things in tech\n\nThe AI Avengers have assembled. Nvidia and OpenAI are teaming up in an AI infrastructure deal that has the chipmaker investing up to $100 billion in OpenAI. This includes OpenAI constructing \"at least 10 gigawatts\" of AI data centers running Nvidia systems. Nvidia's stock jumped as much as 5% on news of the agreement, helping to push the S&P 500 to a fresh record high. And in case you're wondering how much $100 billion really is, BI's Katie Notopoulos puts things into perspective.\n\nThe jobs most — and least — likely to be transformed by generative AI. Indeed created the GenAI Skill Transformation Index to measure how generative AI will affect jobs or certain skills. From its findings, one overall message was clear: No job is totally immune, but not all jobs are equally exposed.\n\nThe H-1B fee is coming at a terrible time for Big Tech. IT outsourcing giants and tech companies were already navigating tariff threats, generative AI, and more. Now the new rules could upend their staffing models, according to analysts at TD Cowen who assessed the potential damage of Trump's new H-1B visa fee. Meanwhile, unionized Google employees held a press conference urging their employer to speak out against the matter.\n\n3 things in business\n\nTikTok (US version). The deal — which could land by the end of the week, according to the White House — could see a consortium of US investors, including Larry Ellison and potentially the Murdochs, buy TikTok's US assets. Post-sale, Oracle, which already serves as TikTok's data and security provider in the US, would also control TikTok's algorithm in partnership with the US government.\n\nMeet your new matchmaker: AI. Facebook Dating thinks its AI assistant can cure swiping fatigue. The new feature is a chatbot experience that helps users find matches based on what's publicly available on a user's profile. It can help you craft a good pickup line, too.\n\nReady to quit your job? The tough labor market has made quitting your job in 2025 only a dream for some. That's also why it's extra important to quit the right way when you're ready to leave. Here are three things to consider — plus, what to avoid discussing in the exit interview.\n\nIn other news\n\n​​Americans are terrified of stock-market crashes. One Yale professor says they shouldn't be.\n\nTech titans on trial: Amazon and Google square off with the US government in separate cases.\n\nOracle's succession plan comes into clear view as its stock skyrockets.\n\n20 tech giants that could be hit hardest by President Donald Trump's $100,000 H-1B visa fees.\n\n​​Mark Zuckerberg says he was offered one of the first models of a $585,000 watch. He got the prototype instead.\n\nVideo: How this 106-year-old World War II Navy vet survived a kamikaze attack.\n\nTom Holland was injured after a stunt gone wrong on the set of 'Spider-Man: Brand New Day,' reports say.\n\nCharlie Javice says she can't fly, requests 2nd delay in JPMorgan Chase fraud sentencing.\n\nWhat's happening today\n\nPresident Trump addresses U.N. General Assembly.\n\nNASA IMAP mission to study sun's heliosphere launches.\n\nKamala Harris publishes book on her presidential campaign.\n\nDan DeFrancesco, deputy executive editor and anchor, in New York. Meghan Morris, bureau chief, in Singapore. Akin Oyedele, deputy editor, in New York. Grace Lett, editor, in New York."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Tech Weekly: AI tie-ups, electric plane lift-offs",
      "url": "https://finance.yahoo.com/video/tech-weekly-ai-tie-ups-143334869.html",
      "timestamp": "2025-09-23",
      "content": "STORY: From the latest manoeuvring in the global AI race... to the electric aircraft reaching for the skies.\n\n:: Tech Weekly\n\nThis is Tech Weekly.\n\nA tie-up between two of the highest-profile players in the global AI race is on the way.\n\nNvidia is to invest up to $100 billion in OpenAI and supply it with data center chips.\n\nThe deal gives chipmaker Nvidia a financial stake in the world's most prominent AI company.\n\nThe investment gives OpenAI the cash and access it needs to buy advanced chips that are key to maintaining its dominance.\n\nBut rivals of both companies may be concerned the partnership will undermine competition.\n\nMeta has launched its latest smart glasses, and they are its first consumer-ready spectacles with a built in display.\n\nDubbed the Meta Ray-Ban Display, they will go on sale later this month priced from $799.\n\nBoss Mark Zuckerberg presented the new gadget at the firm’s annual event for developers in California.\n\n\"The display is large enough to watch a video or read a thread of messages. It appears in one eye it's slightly off center, so it doesn't block your view and it disappears after a few seconds when it's not in use so it doesn't distract you.”\n\nHuawei has outlined its long-term chip plans for the first time .\n\nIt's said it will launch some of the world's most powerful computing systems - underscoring China's drive to wean itself off foreign semiconductor suppliers like Nvidia.\n\nIn an announcement that broke years of secrecy about its chips business, Huawei detailed timelines for its Ascend artificial intelligence chips and Kunpeng server chips.\n\nTwo Chinese companies — WeRide and Pony.ai — say they will partner with local firms to launch robotaxi services in Singapore.\n\nThe city-state is expanding into autonomous driving.\n\nRide-hailing operator Grab said it would also partner with WeRide to begin services next year.\n\nBrazil's Embraer could get certification of its electric aircraft in 2027.\n\nAlthough the new president of the country's aviation regulator told Reuters he would like to hit that milestone a year earlier.\n\nEmbraer's subsidiary Eve is among several firms developing battery-powered aircraft that can take off and land vertically to ferry travellers on short city trips."
    },
    {
      "source": "The Verge",
      "headline": "Inside Charlie Kirk’s megachurch memorial service",
      "url": "https://www.theverge.com/column/784033/charlie-kirk-memorial-jimmy-kimmel-fcc-regulator",
      "timestamp": "2025-09-23",
      "content": "Hello and welcome to Regulator. According to a rough transcript of Charlie Kirk's memorial service, the word \"martyr\" was uttered less than 10 times. But to the 90,000-plus people watching live in Glendale, Arizona, and the 100 million who reportedly watched …"
    },
    {
      "source": "Forbes",
      "headline": "MRVL Stock vs. NVIDIA",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/23/mrvl-stock-vs-nvidia/",
      "timestamp": "2025-09-23",
      "content": "NVIDIA presents superior revenue growth in key periods, enhanced profitability, and a comparatively lower valuation..."
    },
    {
      "source": "TechRadar",
      "headline": "\"The next leap forward\" - Nvidia is investing $100bn in OpenAI, and will start by deploying as much power for 10 nuclear reactors",
      "url": "https://www.techradar.com/pro/the-next-leap-forward-nvidia-is-investing-usd100bn-in-openai-and-will-start-by-deploying-as-much-power-for-10-nuclear-reactors",
      "timestamp": "2025-09-23",
      "content": "Nvidia will provide at least 10 gigawatts (millions of GPUs) to OpenAI\n\nDeal could be worth up to $100 billion, Nvidia says\n\nNvidia has lifted the wraps off a multi-billion dollar investment into ChatGPT maker OpenAI as part of its plans to take the company’s AI infrastructure to the next level.\n\nAt least 10 gigawatts of Nvidia systems are set to power OpenAI’s next-generation models, which equates to millions of GPUs, with Nvidia ploughing up to $100 billion into OpenAI progressively as each gigawatt is deployed.\n\n“NVIDIA and OpenAI have pushed each other for a decade, from the first DGX supercomputer to the breakthrough of ChatGPT,” said Jensen Huang, founder and CEO of NVIDIA. “This investment and infrastructure partnership mark the next leap forward—deploying 10 gigawatts to power the next era of intelligence.”\n\nOpenAI scores massive Nvidia deal\n\nThe two companies confirmed that the first gigawatt, using the Vera Rubin platform, could come online as early as the second half of 2026.\n\nIn its announcement, OpenAI named Nvidia as its “preferred strategic compute and networking partner,” noting the two companies will “co-optimize their roadmaps” to align OpenAI models and infrastructure with Nvidia hardware and software.\n\nIn the near-three years since its public preview launch, ChatGPT and OpenAI’s other AI tools have amassed over 700 million weekly active users, and continued growth mandates further expansion.\n\nThis initiative has been described as the biggest AI infrastructure project in history, and it could lead to next-generation superintelligence.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n“Everything starts with compute,” said Sam Altman, co-founder and CEO of OpenAI. “Compute infrastructure will be the basis for the economy of the future, and we will utilize what we’re building with NVIDIA to both create new AI breakthroughs and empower people and businesses with them at scale.”\n\nThe news comes shortly after OpenAI revealed Project Stargate, a $500 billion push to build new AI infrastructure together with Nvidia and Oracle.\n\n“We’re excited to deploy 10 gigawatts of compute with NVIDIA to push back the frontier of intelligence and scale the benefits of this technology to everyone,” OpenAI President Greg Brockman concluded."
    },
    {
      "source": "The Indian Express",
      "headline": "More questions than answers in Nvidia’s $100 billion OpenAI deal",
      "url": "https://indianexpress.com/article/technology/tech-news-technology/more-questions-than-answers-in-nvidias-100-billion-openai-deal-10266666/",
      "timestamp": "2025-09-23",
      "content": "Nvidia’s move to invest up to $100 billion into OpenAI at the same time it plans to supply millions of its market-leading artificial intelligence chips to the ChatGPT creator has little precedent in the tech industry. Under the deal, Nvidia will be taking a f…"
    },
    {
      "source": "XDA Developers",
      "headline": "Arm is the future of desktop computing, and the writing is on the wall for x86",
      "url": "https://www.xda-developers.com/arm-future-desktop-computing-writing-wall-x86/",
      "timestamp": "2025-09-23",
      "content": "Arm has been slowly picking up pace in the last two decades, but the momentum is only growing stronger."
    },
    {
      "source": "PC Gamer",
      "headline": "Nvidia plans to splash OpenAI with cash, pouring out $100 billion for ChatGPT's creator and making last week's Intel investment look like a drop in the money bucket",
      "url": "https://www.pcgamer.com/software/ai/nvidia-plans-to-splash-openai-with-cash-pouring-out-usd100-billion-for-chatgpts-creator-and-making-last-weeks-intel-investment-look-like-a-drop-in-the-money-bucket/",
      "timestamp": "2025-09-23",
      "content": "Big tech is capable of throwing around some eye-watering amounts of cash. As you may recall, Nvidia announced $46.7 billion total revenue during its Q2 2025 earnings call. That's not just a lot of moolah, but serious spending power.\n\nAs such, this week, Nvidia announced it will be investing $100 billion into OpenAI. Part of this mountain of money will go towards supplying the steward of ChatGPT with data centre chips. Details have yet to be finalised, but a letter of intent signed by the two companies announced plans to deploy 10 gigawatts of Nvidia systems for use in OpenAI's data centres.\n\nThe two companies were hardly strangers to begin with, but this latest deal gives Nvidia a stake in one of its biggest customers. Nvidia's investment in OpenAI will eventually take the form of non-voting shares in the company. OpenAI will then use the resulting cash flow to buy the aforementioned AI chips. Ultimately, this latest pledge of $100 billion makes last week's surprising news that Nvidia would be putting $5 billion into Intel look like a drop in the bucket.\n\nOnce this most recent deal is finalised, sources close to the company claim the plan is for Nvidia to invest an initial sum of $10 billion, followed by a hardware rollout sometime towards the end of 2026. The first gigawatt of power will likely take to the stage of Nvidia's upcoming Vera Rubin AI compute platform, which was first revealed back in March.\n\nOpenAI CEO Sam Altman explained in a statement that it was all about maintaining a competitive edge in an increasingly crowded field, saying, \"Everything starts with compute. Compute infrastructure will be the basis for the economy of the future, and we will utilize what we're building with Nvidia to both create new AI breakthroughs and empower people and businesses with them at scale.\"\n\nBut Nvidia spending money on OpenAI so OpenAI can then buy Nvidia hardware has raised some concerns; if this flow of cash looks a little circular to you, you're not the only one concerned about the potential shape of things to come.\n\nSpeaking to Reuters, Bernstein analyst Stacy Rasgon commented, \"On the one hand this [deal] helps OpenAI deliver on what are some very aspirational goals for compute infrastructure, and helps Nvidia ensure that that stuff gets built. On the other hand the 'circular' concerns have been raised in the past, and this will fuel them further.\"\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThough that said, it's perhaps too early to start throwing around words like 'antitrust,' particularly as the US Trump administration is all in on AI. Still though, the proposed 10 gigawatt data centres will demand power equivalent to the needs of 8 million U.S. households; despite Nvidia CEO Jensen Huang's suggestion that AI customers 'pace themselves' and other major big tech players looking to nuclear to meet AI's power demands, there may come a time when such a power imbalance can no longer be ignored."
    },
    {
      "source": "Omgubuntu.co.uk",
      "headline": "OBS Studio 32.0 Brings New Plugin Manager, NVIDIA RTX Effects",
      "url": "https://www.omgubuntu.co.uk/2025/09/obs-studio-32-0-release-brings-new-plugin-manager-nvidia-rtx-effects",
      "timestamp": "2025-09-23",
      "content": "OBS Studio 32.0 has been released. The update sees this streaming and screen recording stable gain a nifty new plugin manager, change a few of its default settings and expand its support for NVIDIA RTX effects.\n\nThe new plugin manager is described as “basic” because it is: it shows a list of installed plugins with a checkbox to enable/disable, but ‘Browse’ and ‘Update’ options are greyed out (those options being there suggests it will be possible to find and install plugins in OBS directly).\n\nOBS Studio 3.20 increases the default bitrate from 2500 to 6000 Kbps.\n\nThe old value was decided upon a decade ago, and expectations in quality have shifted. OBS’ devs note that “…a lot of users who use OBS for recording don’t touch the default settings and end up with a 2.5 mbps recording which looks terrible”.\n\nUsers with NVIDIA RTX GPUs gain Voice Activity Detection (VAD) for RTX Audio Effects, which the release notes say improves noise suppression for speech and optimises other NVIDIA effects. Plus, the RTX Background Removal now has a “chair removal” option.\n\nHybrid MP4/MOV is now the default recording format for new profiles, having been (successfully) trialled in beta previously. New default settings have been applied for AMD encoders to improve ‘perceptual quality for AVC/HEVC/AV1’.\n\nOn Linux, OBS Studio 32.0 improves PipeWire video capture by adjusting the render technique used to capture screen sources. The pull request has detail on why users on Linux saw gamma/brightness issues when adding effects.\n\nOther notable changes in OBS Studio 32.0:\n\nOpt-in automatic crash log upload (Windows and macOS)\n\nExperimental Metal renderer on Apple Silicon Macs\n\nAudio deduplication logic improved across nested scenes, etc\n\n--disable-shutdown-check launch flag removed\n\nPlugins built for newer versions of OBS Studio are no longer loaded\n\nBeyond that, there is are an array of bug fixes to resolve various errors, crashes, missing chapter markers, plugin issues and so on – many issues rather specific to certain setups or situations.\n\nThough a modest update compared to the OBS Studio 31.1 release from July, OBS Studio 32.0 refines and extends what already works, while the new plugin manager (and some other new widget additions) lay foundations for bigger changes still to come.\n\nHow to Install OBS Studio 32.0\n\nOBS Studio is free, open-source software for Windows, macOS and Linux. Download the latest version for Windows, macOS or Linux from the OBS Project website or from GitHub (a DEB for Ubuntu/Linux Mint is linked in the assets section).\n\nOn Linux, there is also the OBS Studio from Flathub — an official, verified Flatpak maintained by the OBS Project themselves, who consider it to the ‘recommended’ way to install OBS Studio on Linux.\n\nThere’s also an official OBS Project PPA providing this, and future updates via more traditional packaging methods. The PPA supports Ubuntu 24.04 LTS and above (but not, as of writing, Ubuntu 25.10 as it’s yet to be released).\n\nTo install OBS Studio from the PPA, first add the PPA:\n\nsudo add-apt-repository ppa:obsproject/obs-studio\n\nThen, install OBS Studio using apt :\n\nsudo apt install obs-studio\n\nFinally, there is an unofficial OBS Studio snap, a modified build with other changes, including a handful of AI plugins, filters, and other tweaks. The Snap is not officially supported by OBS Studio, and any issues with it should be reported to the Snapcrafters team."
    },
    {
      "headline": "How China is challenging Nvidia's AI chip dominance",
      "content": "How China is challenging Nvidia's AI chip dominance\n\n9 hours ago Share Save Osmond Chia Business reporter Share Save\n\nGetty Images Jensen Huang, the boss of Silicon Valley-based Nvidia, has warned China is \"nanoseconds behind\" the US in chips\n\nThe US has dominated the global technology market for decades. But China wants to change that. The world's second largest economy is pouring huge amounts of money into artificial intelligence (AI) and robotics. Crucially, Beijing is also investing heavily to produce the high-end chips that power these cutting-edge technologies. Last month, Jensen Huang - the boss of Silicon Valley-based AI chip giant Nvidia - warned that China was just \"nanoseconds behind\" the US in chip development. So can Beijing match American technology and break its reliance on imported high-end chips?\n\nAfter DeepSeek\n\nChina's DeepSeek sent shockwaves through the tech world in 2024 when it launched a rival to OpenAI's ChatGPT. The announcement by a relatively unknown startup was impressive for a number of reasons, not least because the company said it cost much less to train than leading AI models. It was said to have been created using far fewer high-end chips than its rivals, and its launch temporarily sank Silicon Valley-based Nvidia's market value. And momentum in China's tech sector has continued. This year, some of the country's big tech firms have made it clear that they aim to take on Nvidia and become the main advanced chip suppliers for local companies. In September, Chinese state media said a new chip announced by Alibaba can match the performance of Nvidia's H20 semiconductors while using less energy. H20s are scaled-down processors made for the Chinese market under US export rules. Huawei also unveiled what it said were its most powerful chips ever, along with a three-year plan to challenge Nvidia's dominance of the AI market. The Chinese tech giant also said it would make its designs and computer programs available to the public in China in an effort to draw firms away from their reliance on US products.\n\nGetty Images DeepSeek stunned the tech world in 2024 when it launched an AI model to rival ChatGPT\n\nOther Chinese chip developers have also secured major contracts with big businesses in the country. MetaX is supplying advanced chips for the likes of state-owned telecoms operator, China Unicom. Another hotly-tipped potential challenger to Nvidia is Beijing-based Cambricon Technologies. Its Shanghai-listed shares have more than doubled in value over the last three months as investors bet that it will benefit from Beijing's push for Chinese firms to use locally produced high-end chips. Tencent, which owns the super app WeChat, is another notable tech giant that has heeded the government’s call to use Chinese chips. There has also been no shortage of state-backed trade shows, promoting Chinese technology companies in a bid to attract investors. \"The competition has undeniably arrived,\" a spokesperson for Nvidia told the BBC in response to queries about the recent progress made by Chinese chip firms. \"Customers will choose the best technology stack for running the world's most popular commercial applications and open-source models. We'll continue to work to earn the trust and support of mainstream developers everywhere.\" Yet some experts have cautioned that claims made by Chinese chipmakers should be taken with a pinch of salt due to a lack of publicly available data and consistent testing benchmarks. China's semiconductors perform similarly to the US in predictive AI but fall short in complex analytics, said computer scientist Jawad Haj-Yahya, who has tested both American and Chinese chips. \"The gap is clear and it is surely shrinking. But I don't think it's something they will catch up on in the short-term.\"\n\nWhere China leads - and lags\n\nOn the BG2 technology and business podcast in September, Nvidia's Jensen Huang highlighted the strengths of China's tech sector, crediting its hardworking and vast talent pool, intense domestic competition and progress in chipmaking. \"This is a vibrant entrepreneurial, high-tech, modern industry,\" he said, urging the US to compete \"for its survival\". His assessment is likely to be welcomed by officials in Beijing. The country has long vied to become a global leader in tech, partly to reduce its reliance on the West. For years, China has invested heavily in what President Xi Jinping calls \"high-quality development\", which covers industries from renewables to AI. Even before US President Donald Trump's return to the White House, China had spent tens of billions of dollars as part of its efforts to transform its vast economy from the \"world's factory\" for basic products to a home of cutting-edge industries. An ongoing tariffs war with Trump's America has only made that mission more urgent. Xi has vowed to make his country more self-reliant and not depend on \"anyone's gifts\".\n\nMr Huang has also warned that the US should trade freely with China or risk handing it the edge in the AI race. This comes against a backdrop of Beijing applying more pressure on Nvidia as it launched an anti-monopoly probe into the firm last month. But China's state-led approach can also be an obstacle to innovation if everyone in the sector only focuses on a \"shared goal\", said computing professor Chia-Lin Yang from the National Taiwan University. It can make it harder for disruptive ideas to break the mould, she added. China's chip industry has also yet to overcome criticism that its products can be less user-friendly than those of Western rivals like Nvidia. Prof Yang believes these issues can soon be solved by China's huge number of skilled tech industry workers. \"You cannot underestimate China's ability to catch up.\"\n\nGetty Images Chinese tech giant Huawei unveiled its plans to rival Nvidia's dominance in AI chips\n\n'Bargaining chip' for China",
      "source": "BBC News",
      "url": "https://www.bbc.com/news/articles/cgmz2vm3yv8o",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Meet Lisa Su: CEO and president of Advanced Micro Devices, the main competitor to Nvidia",
      "content": "Lisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion.\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nlighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nLisa Su is the engineer behind one of the most dramatic corporate turnarounds in the tech industry.\n\nThe Taiwanese American CEO is widely credited with transforming AMD from a struggling semiconductor firm on the brink of collapse into a global powerhouse competing head-to-head with Intel and Nvidia.\n\nWhen Su joined AMD in 2012, the company's market value was under $2 billion. Within a decade of her leadership, AMD's innovations in high-performance computing and graphics, especially the Ryzen CPUs and EPYC server processors, catapulted the company's value to roughly $270 billion as of October 2025.\n\nBut Su's leadership has not been without challenges. AMD's two largest competitors, Nvidia and Intel, are now working together in a strategic collaboration. Under the second Trump administration, export regulations related to China, one of AMD's largest markets, are also constantly changing.\n\nHere's a look at the timeline of Su's career, from her early life in New York City to her role as one of the most influential women in tech and innovation:",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/meet-lisa-su-ceo-and-president-of-advanced-micro-device",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Huawei Atlas 950 SuperPoD vs Nvidia DGX SuperPOD vs AMD Instinct Mega POD: How do they compare?",
      "content": "Huawei stacks thousands of NPUs to show brute-force supercomputing dominance\n\nNvidia delivers polish, balance, and proven AI performance that enterprises trust\n\nAMD teases radical networking fabrics to push scalability into new territory\n\nThe race to build the most powerful AI supercomputing systems is intensifying, and major brands now want a flagship cluster that proves it can handle the next generation of trillion-parameter models and data-heavy research.\n\nHuawei’s recently-announced Atlas 950 SuperPoD, Nvidia’s DGX SuperPOD, and AMD’s upcoming Instinct MegaPod each represent different approaches to solving the same problem.\n\nThey all aim to deliver massive compute, memory, and bandwidth in one scalable package, powering AI tools for generative models, drug discovery, autonomous systems, and data-driven science. But how do they compare?\n\nSwipe to scroll horizontally Huawei Ascend 950 vs Nvidia H200 vs AMD MI300 Instinct Category Huawei Ascend 950DT NVIDIA H200 AMD Radeon Instinct MI300 Chip Family / Name Ascend 950 series H200 (GH100, Hopper) Radeon Instinct MI300 (Aqua Vanjaram) Architecture Proprietary Huawei AI accelerator Hopper GPU architecture CDNA 3.0 Process / Foundry Not yet publicly confirmed 5 nm (TSMC) 5 nm (TSMC) Transistors Not specified 80 billion 153 billion Die Size Not specified 814 mm² 1017 mm² Optimization Decode-stage inference & model training General-purpose AI & HPC acceleration AI/HPC compute acceleration Supported Formats FP8, MXFP8, MXFP4, HiF8 FP16, FP32, FP64 (via Tensor/CUDA cores) FP16, FP32, FP64 Peak Performance 1 PFLOPS (FP8 / MXFP8 / HiF8), 2 PFLOPS (MXFP4) FP16: 241.3 TFLOPS, FP32: 60.3 TFLOPS, FP64: 30.2 TFLOPS FP16: 383 TFLOPS, FP32/FP64: 47.87 TFLOPS Vector Processing SIMD + SIMT hybrid, 128-byte memory access granularity SIMT with CUDA and Tensor cores SIMT + Matrix/Tensor cores Memory Type HiZQ 2.0 proprietary HBM (for decode & training variant) HBM3e HBM3 Memory Capacity 144 GB 141 GB 128 GB Memory Bandwidth 4 TB/s 4.89 TB/s 6.55 TB/s Memory Bus Width Not specified 6144-bit 8192-bit L2 Cache Not specified 50 MB Not specified Interconnect Bandwidth 2 TB/s Not specified Not specified Form Factors Cards, SuperPoD servers PCIe 5.0 x16 (server/HPC only) PCIe 5.0 x16 (compute card) Base / Boost Clock Not specified 1365 / 1785 MHz 1000 / 1700 MHz Cores / Shaders Not specified CUDA: 16,896, Tensor: 528 (4th Gen) 14,080 shaders, 220 CUs, 880 Tensor cores Power (TDP) Not specified 600 W 600 W Bus Interface Not specified PCIe 5.0 x16 PCIe 5.0 x16 Outputs None (server use) None (server/HPC only) None (compute card) Target Scenarios Large-scale training & decode inference (LLMs, generative AI) AI training, HPC, data centers AI/HPC compute acceleration Release / Availability Q4 2026 Nov 18, 2024 Jan 4, 2023\n\nThe philosophy behind each system\n\nWhat makes these systems fascinating is how they reflect the strategies of their makers.\n\nHuawei is leaning heavily on its Ascend 950 chips and a custom interconnect called UnifiedBus 2.0 - the emphasis is on building out compute density at an extraordinary scale, then networking it together seamlessly.\n\nNvidia has spent years refining its DGX line and now offers the DGX SuperPOD as a turnkey solution, integrating GPUs, CPUs, networking, and storage into a balanced environment for enterprises and research labs.\n\nAMD is preparing to join the conversation with the Instinct MegaPod, which aims to scale around its future MI500 accelerators and a brand-new networking fabric called UALink.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nWhile Huawei talks about exaFLOP levels of performance today, Nvidia highlights a stable, battle-tested platform, and AMD pitches itself as the challenger offering superior scalability down the road.\n\nAt the heart of these clusters are heavy-duty processors built to deliver immense computational power and handle data-intensive AI and HPC workloads.\n\nHuawei’s Atlas 950 SuperPoD is designed around 8,192 Ascend 950 NPUs, with reported peaks of 8 exaFLOPS in FP8 and 16 exaFLOPS in FP16 - so it is clearly aimed at handling both training and inference at an enormous scale.\n\nNvidia’s DGX SuperPOD, built on DGX A100 nodes, delivers a different flavor of performance - with 20 nodes containing a total of 160 A100 GPUs, it looks smaller in terms of chip count.\n\nHowever, each GPU is optimized for mixed precision AI tasks and paired with high-speed InfiniBand to keep latency low.\n\nAMD’s MegaPod is still on the horizon, but early details suggest it will pack 256 Instinct MI500 GPUs alongside 64 Zen 7 “Verano” CPUs.\n\nWhile its raw compute numbers are not yet published, AMD’s goal is to rival or exceed Nvidia’s efficiency and scale, especially as it uses next-generation PCIe Gen 6 and 3-nanometer networking ASICs.\n\nFeeding thousands of accelerators requires staggering amounts of memory and interconnect speed.\n\nHuawei claims the Atlas 950 SuperPoD carries more than a petabyte of memory, with a total system bandwidth of 16.3 petabytes per second.\n\nThis kind of throughput is designed to keep data moving without bottlenecks across its racks of NPUs.\n\nNvidia’s DGX SuperPOD does not attempt to match such headline numbers, instead relying on 52.5 terabytes of system memory and 49 terabytes of high-bandwidth GPU memory, coupled with InfiniBand links of up to 200Gbps per node.\n\nThe focus here is on predictable performance for workloads that enterprises already run.\n\nAMD, meanwhile, is targeting the bleeding edge with its Vulcano switch ASICs offering 102.4Tbps capacity and 800Gbps per tray external throughput.\n\nCombined with UALink and Ultra Ethernet, this suggests a system that will surpass current networking limits once it launches in 2027.\n\nOne of the biggest differences between the three contenders lies in how they are physically built.\n\nHuawei’s design allows for expansion from a single SuperPoD to half a million Ascend chips in a SuperCluster.\n\nThere are also claims that an Atlas 950 configuration could involve more than a hundred cabinets spread over a thousand square meters.\n\nNvidia’s DGX SuperPOD takes a more compact approach, with its 20 nodes integrated in a cluster style that enterprises can deploy without needing a stadium-sized data hall.\n\nAMD’s MegaPod splits the difference, with two racks of compute trays plus one dedicated networking rack, showing that its architecture is centered around a modular but powerful layout.\n\nIn terms of availability, Nvidia’s DGX SuperPOD is already on the market, Huawei’s Atlas 950 SuperPoD is expected in late 2026, and AMD’s MegaPod is planned for 2027.\n\nThat said, these chips are fighting very different battles under the same banner of AI supercomputing supremacy.\n\nHuawei’s Atlas 950 SuperPoD is a show of brute force, stacking thousands of NPUs and jaw-dropping bandwidth to dominate at scale, but its size and proprietary design may make it harder for outsiders to adopt.\n\nNvidia’s DGX SuperPOD looks smaller on paper, yet it wins on polish and reliability, offering a proven platform that enterprises and research labs can plug in today without waiting for promises.\n\nAMD’s MegaPod, still in development, has the makings of a disruptor, with its MI500 accelerators and radical new networking fabric that could tilt the balance once it arrives, but until then, it is a challenger talking big.\n\nVia Huawei, Nvidia, TechPowerUp",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/huawei-atlas-950-superpod-vs-nvidia-dgx-superpod-vs-amd-instinct-mega-pod-how-do-they-compare",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Analyst on NVIDIA (NVDA): ‘Eventually, We Will Hit a Wall’",
      "content": "We recently published 10 Stocks Wall Street is Watching Heading into October. NVIDIA Corporation (NASDAQ:NVDA) is one of the stocks Wall Street is watching.\n\nChris Rolland from Susquehanna said during a program on CNBC last month that Nvidia’s growth will eventually slow down and hit a “wall.” However, the analyst remains bullish on the stock and praised the company’s recent quarter numbers.\n\n“I think eventually we will hit some sort of a wall when it comes to this deceleration. I don’t know if it’s next year, but eventually we’re going to have a flat year and everyone’s going to freak out and think that the P multiple might even be too high. It’s been a meteoric rise. I’m not getting off the train just yet. There’s still a lot of growth here. Whether you’re talking about hyperscale capex, we’ve seen incredible improvement, but there’s probably still another 20 or 30% to go there over the next few years. We have sovereign ahead of us. We have China ahead of us. There’s still some opportunity here.”\n\nThe current AI boom cycle stems from spending by major tech companies, and Nvidia is the biggest beneficiary of this spending. In Q2 FY2026, three direct customers accounted for 23%, 19%, and 14% of NVDA’s accounts receivable. Almost all of the company's revenue comes from AI-related infrastructure spending. In the latest quarter, $41.3 billion of the $46.7 billion revenue came from these clients. The music could stop for Nvidia if these major companies decide to slow down their spending amid a lack of ROI. If investors sense a weakness in CapEx spending, and the market begins to waver, NVDA stock price would be the first to see its impact.\n\nBaird Chautauqua International and Global Growth Fund stated the following regarding NVIDIA Corporation (NASDAQ:NVDA) in its second quarter 2025 investor letter:\n\n“NVIDIA Corporation (NASDAQ:NVDA) reported first quarter results that were extremely solid. The company took a write-down on China-specific datacenter products and flushed out any future China contributions from their guidance, following the new export restrictions introduced in April. Demand commentary ex China was extremely encouraging—Nvidia is outgrowing expectations despite supply constraints and outgrowing competing ASIC products by a large margin. We have been underweight Nvidia relative to the benchmark, which was up 46% in the quarter, given our short-to medium-term concerns that the feverish AI datacenter build may be resulting in overcapacity, which has not come to bear.\n\nWhile we acknowledge the potential of NVDA as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/analyst-nvidia-nvda-eventually-hit-141543966.html",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Meet Lisa Su: CEO and president of Advanced Micro Devices, the main competitor to Nvidia",
      "content": "Lisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion.\n\nREUTERS/Steve Marcus\n\nAMD's CEO, Lisa Su, grew up in Queens and obtained three…\n\nThis story appeared on businessinsider.com , 2025-10-05 10:16:01.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/ccf28a26f3aecc1a",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Wall Street, crypto industry say tokenization will reshape global markets: 'It’s going to eat the entire financial system'",
      "content": "Wall Street, crypto industry say tokenization will reshape global markets: 'It’s going to eat the entire financial system'\n\nImagine a future where the biggest US stocks like Tesla (TSLA) or Nvidia (NVDA) can be traded around the clock, with the transactions settled in seconds.\n\nMomentum is…\n\nThis story appeared on finance.yahoo.com , 2025-10-05 13:30:05.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/ced34fe0aef65643",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Linux 6.18 DRM Pull Includes New Tyr & Rocket Drivers, More AMD & Intel GPU Enhancements",
      "content": "The Direct Rendering Manager \"DRM\" pull request ended up leading to Linus Torvalds complaining over text and Rust code formatting but in the end he pulled all of these kernel graphics driver updates and also the associated \"accel\" accelerator subsystem drivers too.With the Linux 6.18 DRM pull there is a lot of kernel graphics driver improvements across the board, including the new drivers of Tyr and the Rocket accelerator driver. For enhancing existing driver support, the AMD and Intel graphics drivers continue seeing a bulk of the activity. Plus ongoing Rust code work in the DRM subsystem and more.\n\nBelow is a look at the DRM kernel driver changes for Linux 6.18.- The \"Rocket\" accelerator driver is finally mainlined for enabling the NPU found on newer Rockchip SoCs. This is the open-source driver reverse-engineered and started by Tomeu Vizoso. The Rocket accel driver works with new user-space code in Mesa 25.3 for Rockchip NPUs.- The AMDGPU and AMDKFD Checkpoint and Resture \"CRIU\" support for GEM memory objects.- Expanded AMDGPU Video Core Next \"VCN\" engine reset support.- More AMD Cyan Skillfish updates.- The AMDXDNA accelerator driver now supports user-space allocated buffers, improved error reporting, and other enhancements.- A new Intel Xe driver interface for querying VMA count and memory attributes. The intel Intel SLPC \"power_profile\" sysfs interface for the Xe driver for power management tuning.- Intel Xe driver SR-IOV support for CCS surfaces on Xe2+. The SR-IOV PF mode is also now enabled by default on supported platforms. Intel has returned to working on the upstream Habana Labs accelerator driver . There still is no Gaudi 3 support but at least they are back to working on this code under a new set of maintainers.- Intel Xe driver support for madvise in GPU SVM (Shared Virtual Memory).- The Arm Mali Panthor DRM driver added support for Mali G710, G510, G310, Gx15, Gx20, Gx25 GPUs.- Continued work on Nova as the next-generation open-source NVIDIA Linux kernel driver written in Rust.- The initial code around Tyr as a new Rust driver for Arm Mali GPUs . It's not yet usable by end-users, similar to the Nova driver.- Various new Rust abstractions and other work toward making Rust DRM drivers more practical.See this pull for the full list of DRM feature patches this cycle.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-DRM",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "I cloned my voice with AI and it was unsettlingly good",
      "content": null,
      "source": "MakeUseOf",
      "url": "https://www.makeuseof.com/ai-voice-clone-chatterbox/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "How China is challenging Nvidia's AI chip dominance",
      "content": "How China is challenging Nvidia's AI chip dominance\n\n9 hours ago Share Save Osmond Chia Business reporter Share Save\n\nGetty Images Jensen Huang, the boss of Silicon Valley-based Nvidia, has warned China is \"nanoseconds behind\" the US in chips\n\nThe US has dominated the global technology market for decades. But China wants to change that. The world's second largest economy is pouring huge amounts of money into artificial intelligence (AI) and robotics. Crucially, Beijing is also investing heavily to produce the high-end chips that power these cutting-edge technologies. Last month, Jensen Huang - the boss of Silicon Valley-based AI chip giant Nvidia - warned that China was just \"nanoseconds behind\" the US in chip development. So can Beijing match American technology and break its reliance on imported high-end chips?\n\nAfter DeepSeek\n\nChina's DeepSeek sent shockwaves through the tech world in 2024 when it launched a rival to OpenAI's ChatGPT. The announcement by a relatively unknown startup was impressive for a number of reasons, not least because the company said it cost much less to train than leading AI models. It was said to have been created using far fewer high-end chips than its rivals, and its launch temporarily sank Silicon Valley-based Nvidia's market value. And momentum in China's tech sector has continued. This year, some of the country's big tech firms have made it clear that they aim to take on Nvidia and become the main advanced chip suppliers for local companies. In September, Chinese state media said a new chip announced by Alibaba can match the performance of Nvidia's H20 semiconductors while using less energy. H20s are scaled-down processors made for the Chinese market under US export rules. Huawei also unveiled what it said were its most powerful chips ever, along with a three-year plan to challenge Nvidia's dominance of the AI market. The Chinese tech giant also said it would make its designs and computer programs available to the public in China in an effort to draw firms away from their reliance on US products.\n\nGetty Images DeepSeek stunned the tech world in 2024 when it launched an AI model to rival ChatGPT\n\nOther Chinese chip developers have also secured major contracts with big businesses in the country. MetaX is supplying advanced chips for the likes of state-owned telecoms operator, China Unicom. Another hotly-tipped potential challenger to Nvidia is Beijing-based Cambricon Technologies. Its Shanghai-listed shares have more than doubled in value over the last three months as investors bet that it will benefit from Beijing's push for Chinese firms to use locally produced high-end chips. Tencent, which owns the super app WeChat, is another notable tech giant that has heeded the government’s call to use Chinese chips. There has also been no shortage of state-backed trade shows, promoting Chinese technology companies in a bid to attract investors. \"The competition has undeniably arrived,\" a spokesperson for Nvidia told the BBC in response to queries about the recent progress made by Chinese chip firms. \"Customers will choose the best technology stack for running the world's most popular commercial applications and open-source models. We'll continue to work to earn the trust and support of mainstream developers everywhere.\" Yet some experts have cautioned that claims made by Chinese chipmakers should be taken with a pinch of salt due to a lack of publicly available data and consistent testing benchmarks. China's semiconductors perform similarly to the US in predictive AI but fall short in complex analytics, said computer scientist Jawad Haj-Yahya, who has tested both American and Chinese chips. \"The gap is clear and it is surely shrinking. But I don't think it's something they will catch up on in the short-term.\"\n\nWhere China leads - and lags\n\nOn the BG2 technology and business podcast in September, Nvidia's Jensen Huang highlighted the strengths of China's tech sector, crediting its hardworking and vast talent pool, intense domestic competition and progress in chipmaking. \"This is a vibrant entrepreneurial, high-tech, modern industry,\" he said, urging the US to compete \"for its survival\". His assessment is likely to be welcomed by officials in Beijing. The country has long vied to become a global leader in tech, partly to reduce its reliance on the West. For years, China has invested heavily in what President Xi Jinping calls \"high-quality development\", which covers industries from renewables to AI. Even before US President Donald Trump's return to the White House, China had spent tens of billions of dollars as part of its efforts to transform its vast economy from the \"world's factory\" for basic products to a home of cutting-edge industries. An ongoing tariffs war with Trump's America has only made that mission more urgent. Xi has vowed to make his country more self-reliant and not depend on \"anyone's gifts\".\n\nMr Huang has also warned that the US should trade freely with China or risk handing it the edge in the AI race. This comes against a backdrop of Beijing applying more pressure on Nvidia as it launched an anti-monopoly probe into the firm last month. But China's state-led approach can also be an obstacle to innovation if everyone in the sector only focuses on a \"shared goal\", said computing professor Chia-Lin Yang from the National Taiwan University. It can make it harder for disruptive ideas to break the mould, she added. China's chip industry has also yet to overcome criticism that its products can be less user-friendly than those of Western rivals like Nvidia. Prof Yang believes these issues can soon be solved by China's huge number of skilled tech industry workers. \"You cannot underestimate China's ability to catch up.\"\n\nGetty Images Chinese tech giant Huawei unveiled its plans to rival Nvidia's dominance in AI chips\n\n'Bargaining chip' for China",
      "source": "BBC News",
      "url": "https://www.bbc.com/news/articles/cgmz2vm3yv8o?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Bheadline%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Nintendo Switch 2 supports two different types of Nvidia DLSS — A second, 'light' version for upscaling beyond 1080p, along with the standard, PC-like CNN model",
      "content": "The Nintendo Switch 2 is the only mainstream console that comes with Nvidia hardware inside, while Microsoft and Sony rely on AMD. Therefore, the Switch 2 supports Nvidia's proprietary DLSS technology that helps it upscale games to 1080p and beyond, which is crucial in a handheld with power constraints. It was long speculated that the version of DLSS present on the Switch 2 was unique and unlike the standard models available on PC, and Digital Foundry's latest testing has confirmed that.\n\nNintendo Switch 2 DLSS Image Quality Analysis: \"Tiny\" DLSS/Full-Fat DLSS Confirmed - YouTube Watch On\n\nWhile looking at a diverse selection of titles like Cyberpunk 2077, Street Fighter 6, Hogwarts Legacy, Star Wars Outlaws, The Touryst, and Fast Fusion; Digital Foundry observed that there are two different DLSS versions at work.\n\nFirst up, there's \"Fat DLSS\" that resembles the CNN-based model found on PC, and this can only upscale games to 1080p. It has a cleaner, sharper image in motion, less artifacting, better antialiasing, and smoother camera cuts. Objects move in and out of motion almost identically to how they would on PC — which is to say, gracefully.\n\nBut, as mentioned, it's limited to 1080p. To go past that resolution, Nvidia and Nintendo have developed a special \"DLSS Light\" which can upscale to greater resolutions (remember, Switch 2 is marketed for up to 4K when docked). This version looks better in stills, but looses sharpness as soon as you move because reconstruction techniques get temporarily disabled. It introduces artifacts where you can see unfiltered pixels, but at the benefit of half the frame-time cost, which allows it to scale way past just 1080p.\n\n(Image credit: Jeffrey Kampman/Tom's Hardware)\n\nThis goes to show just how demanding the original version of DLSS is; it doesn't make sense to run that on every game, especially in handheld mode. When you need to reach resolutions higher than 1080p, the light model should still be better, despite its inferior temporal performance. What remains to be seen, though, is whether the newer, more efficient Transformer-based model of DLSS can somehow make its way onto the Switch 2 in the future.\n\nDigital Foundry even reached out to an unnamed but respected developer familiar with DLSS on the Switch, who confirmed that two versions of the tech do indeed exist in the pipeline to choose from. The light version is newer, and more uniquely suited to the Switch 2's hardware capabilities. We haven't seen any first-party Nintendo game utilize DLSS so far either, so that's also something to keep an eye on, given how most Nintendo games focus on precise movement and controls.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/video-games/nintendo/nintendo-switch-2-supports-two-different-types-of-nvidia-dlss-a-second-light-version-for-upscaling-beyond-1080p-along-with-the-standard-pc-like-cnn-model",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Weekly Market Wrap: Intel, Nvidia and Electronic Arts made major news",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/markets/weekly-market-wrap-intel-nvidia-and-electronic-arts-made-the-most-news",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Best VPNs for multiple devices in 2025",
      "content": null,
      "source": "Android Police",
      "url": "https://www.androidpolice.com/best-vpn-for-multiple-devices/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Samsung will collaborate with OpenAI to develop floating data centers and power plants as Sam Altman rushes to compete with his firm's own partners",
      "content": "OpenAI and Samsung sign letter of intent for sweeping AI partnership\n\nAgreement includes memory supply, data centers, and floating power infrastructure\n\nOpenAI seeks independence from hyperscalers as rivals expand global infrastructure\n\nOpenAI and Samsung and have signed a letter of intent for a sweeping partnership that spans semiconductors, data centers, shipbuilding, cloud services, and maritime technologies.\n\nThe announcement was made at a ceremony in Seoul attended by senior leaders from across Samsung’s electronics, shipbuilding, construction, and IT services businesses.\n\nThe agreement states that Samsung Electronics will act as a strategic memory partner for OpenAI’s Project Stargate initiative, which aims to build out masses of new AI infrastructure.\n\nFloating data centers\n\nOpenAI has projected its memory demand could reach 900,000 DRAM wafers per month, and Samsung will supply high-performance, energy-efficient memory solutions to meet the requirement.\n\nSamsung SDS will work with OpenAI to design, develop, and operate AI data centers and provide enterprise AI services.\n\nIt will also act as a reseller of OpenAI’s ChatGPT Enterprise in Korea, supporting adoption by local businesses.\n\nSamsung Heavy Industries and Samsung C&T will collaborate with OpenAI on floating data centers, with possible expansion into floating power plants and control centers.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n“Floating data centers… can address land scarcity, lower cooling costs and reduce carbon emissions,” the companies said in their letter of intent.\n\nAs The Stack notes, floating data centers remain rare, but interest is growing. The Stockton project in California has been running since 2021, Japanese firms and Yokohama city are planning a solar- and battery-powered design, and in June 2025, the American Bureau of Shipping and Herbert Engineering proposed a nuclear-powered floating data center concept.\n\nThe announcement comes a matter of days after we revealed Nvidia had poured $100 billion into OpenAI (to spend on Nvidia’s own chips, naturally), and suggests the ChatGPT creator is looking to reduce its dependence on hyperscaler partners such as Microsoft.\n\nWith AI rivals like Meta and Google rapidly expanding their own infrastructure, there is growing pressure on OpenAI to establish itself as a large-scale operator in its own right.\n\nFollow TechRadar on Google News and add us as a preferred source to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!\n\nAnd of course you can also follow TechRadar on TikTok for news, reviews, unboxings in video form, and get regular updates from us on WhatsApp too.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/samsung-will-collaborate-with-openai-to-develop-floating-data-centers-and-power-plants-as-sam-altman-rushes-to-compete-with-his-firms-own-partners",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Skytech Eclipse Lite 2 Desktop: Ryzen 7 9800X3D, RTX 5080, 32GB RAM, 2TB SSD $2130.99",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18664246-skytech-eclipse-lite-2-desktop-ryzen-7-9800x3d-rtx-5080-32gb-ram-2tb-ssd-2130-99",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "How to watch Ipswich Town vs Norwich City: Free streams, TV channels and preview for East Anglian Derby",
      "content": "Kick off: 12 pm BST/ 7am ET, Sunday, October 5.\n\nWatch Ipswich vs Norwich for free on ITVX (UK restricted)\n\nOutside the UK? Use NordVPN to unblock your ITVX account\n\nOne of the Championship's most iconic derbies takes place this Sunday for the first time in over 500 days, and after a summer of treachery there's a reignited fire between these two clubs that is certain to make for a feisty fixture.\n\nSo far, life back in the Championship for Kieran McKenna's Ipswich has been turbulent to say the least. After a summer of chops and changes, the identity of McKenna's Ipswich is a little bit off the mark. The Tractor Boys sit 13th in the Championship with a game in hand after a bizarre abandonment of their fixture away at Blackburn Rovers.\n\nAcross the A140, in a season where fans were promised better quality football and a push for play-offs, Norwich seem to be falling short of expectations. The Canaries sit 19th in the Championship at the time of writing and have won just one game in their last seven league outings.\n\nIn a game which both fanbases look for instantaneously when the fixtures are released, neither Ipswich nor Norwich fans will be going into this one with full confidence and will be hoping that a win against their rivals can jumpstart their 2025/26 season.\n\nSo how can you watch the East Anglian derby on ITVX from anywhere in the world? Is ITVX available as a mobile app?\n\nHere's our guide on how to watch Ipswich vs Norwich for free.\n\nHow to watch Ipswich vs Norwich for free on ITVX\n\nITV's online streaming service, ITVX, will be broadcasting the East Anglian derby on Sunday, 5th October, for free.\n\nThe great thing about ITVX's coverage is that you don't even need an ITVX subscription to watch Ipswich vs Norwich, you just need a valid TV license and an email account and you're good to go.\n\nFirst time using ITVX? You can register for a free account or download the app on your mobile device.\n\nOutside the UK for the derby? You can use NordVPN to reliably unlock your ITVX stream of Ipswich vs Norwich from anywhere in the world.\n\nHow to watch the Ipswich vs Norwich on ITVX from anywhere\n\nITVX will only be broadcasting the East Anglian derby to residents of the UK.\n\nSoccer fans traveling or working outside the UK will need to use a VPN to access ITVX's free coverage of the East Anglian derby this Sunday.\n\nThere are lots of VPNs but NordVPN is the one you can rely on to unblock ITVX stream and watch Ipswich vs Norwich from anywhere in the world.\n\nIt's really simple to use a VPN to unblock your stream of this weekend's derby.\n\n1. Install the VPN of your choice. As we've said, NordVPN is our favorite.\n\n2. Choose the location you wish to connect to in the VPN app. For instance, if you're visiting the US and want to watch your free ITVX stream, you'd select 'UK'.\n\n3. Sit back and enjoy the action. Head to ITVX, sign in, and watch all the drama and chaos unfold in the derby this Sunday.\n\nWhat does ITVX's East Anglian derby coverage include?\n\n(Image credit: Getty Images- NurPhoto)\n\nITVX's coverage of Ipswich vs Norwich takes place on Sunday, October 5, and will include pre-match analysis, a full live stream and post match analysis.\n\nThe UK network's broadcast will be presented by Hugh Woozencroft with commentary provided by Seb Hutchinson and Lucy Ward. The punditry team will include Matt Holland and Dean Aston, providing expert insight and analysis. On the floor reporting will be provided by Aaron Paul, offering fans some player and manager reactions.\n\nFans can expect a tense atmosphere this Sunday at Portman Road as the two rivals battle it out for bragging rights. ITVX will be broadcasting all the drama and providing action replays, highlights and a full aftershow. As well as this, ITV will also be uploading highlights to their YouTube channel.\n\nWhat devices is ITVX available on?\n\nYou can use ITVX on all of the following devices and platforms:\n\nAmazon Fire (Tablets, Cube, Stick, TVs)\n\nAndroid TV (please note: some models aren’t supported)\n\nAndroid (Mobile & Tablet) - Android 7.0 and above\n\nApple TV (tvOS 14 or later)\n\nGoogle TV (Chromecast with Google TV and NVIDIA Shield)\n\nFreely\n\nFreesat (please note: some models aren’t supported)\n\nFreeview Play (TVs and set-top boxes) (please note: some models aren’t supported)\n\niOS (iPhone & iPad) - iOS 14 and above\n\nLG Smart TVs (2016-2024)\n\nNOW Smart Sticks and Boxes (minimum firmware v11.5.0)\n\nPlayStation (PS4 and PS5)\n\nRoku (Stick & Roku-OS powered TVs, minimum firmware v11.5.0)\n\nSamsung Smart TVs (2017 and above - 2016 models only offer on demand TV)\n\nSky Q, Sky Glass and Sky Stream puck\n\nVirgin Media (360, Stream, TiVo)\n\nYouView (BT, Humax, Sony, TalkTalk)\n\nXbox (One, Series X, Series S)\n\nIpswich vs Norwich Preview\n\nThe general consensus going into this Championship season was that Ipswich have one of, if not, the strongest team in the division, making their 13th place league position, a little underwhelming.\n\nHowever, Ipswich will be looking to kickstart their season after they've slowly been adjusting to their new-look squad. Now unbeaten in four league matches, Mckenna will be hoping that a win against rivals Norwich, will give his team the momentum they need to climb up the table.\n\nLiam Manning's latest defeat as Norwich boss came at the hands of West Bromwich Albion, where the visiting Baggies returned home with all three points thanks to a goal from striker, Josh Maja.\n\nHowever, Norwich will go into this fixture with some solace as they still hold a record of 16 years unbeaten in the East Anglian derby, a record that dates back to 2009. The Canaries will be hoping they can rely on key players such as Josh Sargent to protect that precious record this Sunday as they make the journey to Portman Road.\n\nStarting XI's:\n\nIpswich starting XI: Palmer, Furlong, O'Shea, Kipre, Davis, Matusiwa, Cajuste, Walle Egeli, Szmodics, Philogene, Hirst.\n\nIpswich bench: Walton, Young, Greaves, Taylor, Nunez, McAteer, Akpom, Clarke, Azon.\n\nNorwich starting XI: Kovacevic, Stacey, Darling, Cordoba, Fisher, McLean, Topic, Mattson, Schwartau, Crnac, Sargent.\n\nNorwich bench: Grimshaw, Medic, Mahovo, Schlupp, Wright, Gibbs, Marcondes, Jurasek, Makama.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/how-to-watch/football/ipswich-town-vs-norwich-city-efl-championship-2025-26free",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Gamers, don't wait for Windows 10's demise - it's time to upgrade to Windows 11 or even SteamOS",
      "content": "In case you somehow missed it, Microsoft is saying goodbye to Windows 10 on October 14, 2025, when support for security updates will come to an end. This means PC gamers who have been adamant about staying away from Windows 11 will be left with a few options.\n\nThe first is simply staying on Windows 10, and if doing so, I'd say it's compulsory to sign up for the Extended Security Updates (ESU) scheme to get another year of updates. (Do not try running an operating system without the latest security patches).\n\nAnother choice could be to finally upgrade to Windows 11 - assuming your PC meets the hardware requirements - or you could even switch to the bloatware-free Tiny11 spin on Microsoft's OS.\n\nOr you could leave the Microsoft ecosystem entirely and switch to Valve's SteamOS. If you've read any of my previous articles on this topic, you'll know that my favored recommendation is SteamOS, but there are pros and cons whichever choice you make.\n\nIn some respects, Valve's SteamOS (which is Linux-based) is a better bet for gamers than Microsoft's desktop OS - it clearly is for handhelds - boasting a streamlined game mode that essentially replicates a gaming console's user interface for couch play, and is designed to allow players to jump into games without much hassle. It's not all perfect in SteamOS, though, as there are compatibility wrinkles - notably several popular multiplayer games (like Call of Duty) use anti-cheat and won't run on the operating system. On top of that, using certain game mods can sometimes be a bit of a pain.\n\nWindows 11 is still a great operating system for gaming, and you won't run into any stumbling blocks in terms of incompatibility here. It's also generally easy to get to grips with and simple enough in terms of the nuts and bolts of files and folders (file systems can be more cumbersome in Linux, certainly for computing novices). Microsoft is also delivering a similar simple game mode experience to SteamOS, with the upcoming 'full-screen experience' launching on the Asus ROG Xbox Ally.\n\nWhere Windows 11 falls down is with some of the frustrating bugs that can occur with the monthly updates (which are forced onto your PC - at least with Windows 11 Home, where you can only briefly delay their installation). This was particularly evident with Windows 11 24H2 breaking games, alongside oft-voiced criticisms online around bloatware and background processes messing with gaming performance.\n\nGet daily insight, inspiration and deals in your inbox Sign up for breaking news, reviews, opinion, top tech deals, and more. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nIf you'd rather avoid Windows 11, and SteamOS isn't your bag either, so your preferred route is to stick with Windows 10 under the ESU scheme, there's one big drawback worth noting on the PC gaming front. Capcom recently announced that it will be dropping support for Monster Hunter games on Windows 10 - and other game publishers will surely follow in its footsteps.\n\nCapcom move spells bad news for other games on Windows 10\n\n(Image credit: Capcom)\n\nI've touched on this already, but Capcom's announcement is not to be taken lightly. Windows 10 gamers are at risk of facing hiccups - or perhaps major spanners in the works - in Monster Hunter games in the future due to support being cast aside.\n\nThis will surely affect new releases from Capcom, too. While I'm sure the highly anticipated Resident Evil Requiem will work fine on Windows 10, I won't be surprised if players start to face issues either at launch or later down the line. When future game updates aren't checked with Windows 10, problems may inevitably creep in - and the developer won't address them.\n\nYou may have ongoing security updates for Windows 10 with the ESU scheme, but if your games aren't being supported, that could become a big problem - and you can bet it won't just be Capcom doing this.\n\n(Image credit: Rockstar Games)\n\nIt's likely a long way down the road, but there's now no guarantee that Rockstar's GTA 6 will run well on Windows 10 - or even support it. I know, that sounds like a stretch, and it would be a surprise if it didn't support Windows 10 considering how accessible GTA 5 was. However, we're looking at possibly 2027 or 2028 for GTA 6's eventual launch on PC - the grand picture for Windows could look quite different then.\n\nIn my opinion, publishers dropping support for Windows 10 could affect so many other upcoming (or unannounced) games, that it might be best to save yourself the headache with all this and pick your upgrade path now.\n\nIf I were forced to choose, I'd pick SteamOS, but I have to recommend Windows 11 for those who can install it\n\n(Image credit: Future / John Loeffler)\n\nIn my eyes, SteamOS is the better operating system compared to Windows when it comes to ease of use for gaming, but Valve's OS isn't quite there just yet for most desktop PC users.\n\nFor handheld gaming PCs, SteamOS is an absolute no-brainer, and I'd recommend choosing it over Windows 11 every time, since it's no secret that Microsoft's OS isn't very handheld-friendly. Microsoft is introducing the full-screen experience game mode, though, which tames background processes and bloatware, and ultimately frees up more resources for games to use in Windows 11 – but I'm still not convinced it'll dethrone SteamOS for me.\n\nHowever, it's a rather different picture on desktop PCs, and that's where I would recommend Windows 11 (for now). Since there's no official support from Valve to install SteamOS on desktop PCs, you'd have to rely on its clone, Bazzite, which has much better support.\n\nEven then, unless you're using AMD hardware, you'll likely run into issues with Bazzite's Game Mode, specifically with Nvidia GPUs. Unless you plan on using the SteamOS desktop mode (which defeats the purpose of SteamOS), you'll run into issues with apps like Discord - this is one of the reasons why I haven't yet switched to Bazzite on my desktop PC - and you may also run into games with compatibility issues.\n\nFor some of you, these issues might not be deal-breakers, and if that's the case, then obviously you should go ahead and try Bazzite. Otherwise, it could be wise to upgrade to Windows 11 - the good thing about its latest update, version 25H2, is that it's not likely to be as problematic with bugs as 24H2 (given that 25H2 is only a very minor upgrade).\n\nFollow TechRadar on Google News and add us as a preferred source to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!\n\nAnd of course you can also follow TechRadar on TikTok for news, reviews, unboxings in video form, and get regular updates from us on WhatsApp too.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/computing/windows/gamers-dont-wait-for-windows-10s-demise-its-time-to-upgrade-to-windows-11-or-even-steamos",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "3 Ways AI Is Quietly Transforming Retirement Planning — and What It Means for Your Money",
      "content": "When you pictured the ways artificial intelligence would change the future, you might have imagined AI powering flying cars. Though we’re not quite there yet, AI has already transformed many areas of daily life — from how we access information to how we plan for retirement.\n\nFor You: Here’s Why You Might Want To Invest Your Retirement Savings in a Roth 401(k)\n\nLearn About: 3 Advanced Investing Moves Experts Use to Minimize Taxes and Help Boost Returns\n\nWorking on retirement planning with a professional financial advisor who is familiar with your situation and goals is always best. However, new AI-powered tools can supplement that guidance by helping you better define your objectives and gain insights into best practices.\n\nTo learn more about how AI is transforming retirement planning — and how it can impact your nest egg — GOBankingRates spoke with Vasant Dhar, professor of data science at the Leonard N. Stern School of Business at New York University and host of the “Brave New World” podcast. As a pioneer in AI, Dhar helped bring machine learning to Wall Street in the early 1990s. His book, “Thinking With Machines: The Brave New World of AI,” will be published this year.\n\nUnsurprisingly, Dhar had detailed insights into what people preparing for retirement today can expect from AI.\n\nAI Can Offer Personalization\n\nThough AI can’t match the human touch of sitting across from an advisor, Dhar says AI-powered financial planning tools like robo-advisors can offer a degree of personalization.\n\nUsing a robo-advisor, you’ll likely fill out an online questionnaire that touches on a few key areas:\n\nFinancial goals\n\nRisk tolerance\n\nTime horizon\n\nExternal financial data\n\nPersonal preferences\n\nOnce AI gathers this information, algorithms can generate suggestions for retirement plans or even manage a portfolio. Of course, these surveys can be superficial, and robo-advisors may offer limited suggestions without considering complex situations — or human emotions.\n\nStill, Dhar believes working with AI tools can help clarify your retirement goals and available resources.\n\n“Such tools can personalize retirement planning in several ways. They can help you clarify your objectives, which is one of the hardest problems in retirement planning,” he said.\n\nRead Next: I Help People Retire Every Day — Here’s the Most Common Retirement Mistake People Make\n\nRetirees Can Benefit From Faster Optimization and Risk Management\n\nFrom his work bringing AI to Wall Street, Dhar has seen how it has changed portfolio optimization, tax strategies and risk management in professional investing.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/3-ways-ai-quietly-transforming-162240565.html",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Circular Financing: Does Nvidia's $110B Bet Echo the Telecom Bubble?",
      "content": "When Nvidia announced a $100 billion investment commitment to OpenAI in September 2025 , analysts immediately drew comparisons to the telecom bubble. The concern : is this vendor financing , where a supplier lends money to customers so they can buy the supplier’s products , a harbinger of another spectacular collapse?\n\nAmerican tech companies will spend $300-400 billion on AI infrastructure in 2025, , exceeding any prior single-year corporate infrastructure investment in nominal dollars. David Cahn estimates the revenue gap has grown to $600 billion.\n\nI analyzed the numbers. The similarities are striking , but the differences matter.\n\nThe Lucent Playbook\n\nLucent’s revenue peaked at $37.92B in 1999 , crashed 69% to $11.80B by 2002 , never recovered. Merged with Alcatel in 2006.\n\nIn 1999 , Lucent Technologies reached $37.92 billion in revenue at the peak of the dot-com bubble. Lucent was the #1 North American telecommunications equipment manufacturer with 157,000 employees & dominated markets alongside Nortel Networks (combined 53% optical transport market share). Behind the scenes , equipment makers extended billions in vendor financing to telecom customers. Lucent committed $8.1B , Nortel extended $3.1B with $1.4B outstanding , & Cisco promised $2.4B in customer loans.\n\nThe strategy seemed brilliant : lend money to cash-strapped telecom companies so they could buy your equipment. Everyone wins—until the merry-go-round stops.\n\nWhen the bubble burst :\n\n47 Competitive Local Exchange Carriers (CLECs) bankrupted 2000-2003 , including Covad , Focal Communications , McLeod , Northpoint , Winstar , Why they failed : $60B overbuild 1996-2001 , market saturation from identical business models , sudden funding collapse (Jan 2001 : billions available , Apr 2001 : zero)\n\n33-80% of vendor loan portfolios went uncollected as customers failed & equipment became worthless\n\nFiber networks were using less than 0.002% of available capacity , with potential for 60,000x speed increases. It was just too early.\n\nNvidia’s Playbook\n\nFast forward to 2025. Nvidia’s vendor financing strategy totals $110 billion in direct investments plus another $15+ billion in GPU-backed debt. The largest commitment is $100B to OpenAI (September 2025), , structured as 10 tranches of $10B each tied to infrastructure deployment milestones. The first $10B was valued at a $500B OpenAI valuation , with subsequent tranches priced at prevailing valuations. Payment comes via lease arrangements , not upfront GPU purchases. OpenAI CFO Sarah Friar confirmed : “Most of the money will go back to Nvidia”\n\nBeyond OpenAI , Nvidia holds a $3B stake in CoreWeave , a company that has spent $7.5B on Nvidia GPUs , & $3.7B in other AI startup investments through NVentures.\n\nThe GPU-backed debt market adds another layer. CoreWeave alone carries $10.45B in debt using GPUs as collateral. An additional $10B+ in GPU-backed debt has emerged for “Neoclouds” including Lambda Labs ($500M GPU-backed loan),.\n\nLucent in 1999-2000 had vendor financing commitments of $8.1B (24% of $33.6B revenue). Nvidia’s direct investments total 67% of annual revenue ($110B against $165B LTM). Nvidia’s exposure is 2.8x larger relative to revenue than Lucent’s official outstanding loans , though Lucent’s off-balance-sheet guarantees masked the true exposure.\n\nThe Numbers Side-by-Side (2024 Dollars)\n\nMetric Lucent (FY2000, inflation-adj.) Nvidia (2025) Vendor financing $15B $110B Operating cash flow $304M $15.4B (Q2 FY26) Revenue $61B $165B (LTM) Top 2 Customers represent 23% 39%\n\nThe Reasons to be Wary\n\n1. The AI Customer Base is More Concentrated\n\nLucent’s top 2 customers—AT&T at 10% & Verizon at 13%—accounted for 23% of revenue in FY2000. The Regional Bell Operating Companies , or RBOCs , the seven “Baby Bells” created from AT&T’s 1984 breakup , were also major customers. Nvidia has 39% of revenue from just 2 customers & 46% from 4 customers , nearly double Lucent’s concentration. 88% of Nvidia’s revenue comes from data centers.\n\n2. GPU-Backed Debt Is New\n\nThe new $10B+ GPU-backed debt market is built on the assumption that GPUs will hold their value over 4-6 years. GPU-backed loans carry ~14% interest rates , triple investment-grade corporate debt.\n\nHow Depreciation Schedules Changed :\n\nCompany Pre-2020 2020-2021 2022-2023 2024-2025 Change Amazon 3 years 4 years (2020) → 5 years (2021) 5 years 6 years (2024) → 5 years (2025) First reversal Microsoft ~3 years 4 years 6 years 6 years +100% Google ~3 years 4 years 6 years 6 years +100% Meta ~3 years 4 years 4.5 years → 5 years 5.5 years +83% CoreWeave N/A N/A 4 years → 6 years (Jan 2023) 6 years +50% (GPUs) Nebius N/A N/A 4 years 4 years Industry standard\n\nAmazon’s 2025 reversal (6 → 5 years) is the first major pullback.\n\nCPUs historically have 5-10 years of useful life , while GPUs in AI datacenters last 1-3 years in practice , despite 6-year accounting assumptions., Evidence from Google architects shows GPUs at 60-70% utilization survive 1-2 years , with 3 years maximum. Meta’s Llama 3 training experienced 9% annual GPU failure rates , suggesting 27% failure over 3 years.\n\nCerno Capital raises the question : “Are these policies a reflection of genuine economic & technological realities? Or are these policies a lever by which hyperscalers are enhancing the optics of their investment programs amid rising investor concerns?”\n\n4. The Use of SPVs\n\nTech companies use Special Purpose Vehicles (SPVs) to finance AI datacenter construction. A hyperscaler like Meta partners with a private equity firm like Apollo , contributing capital to a separate legal entity that builds & owns the datacenter.\n\nAs investor Paul Kedrosky explains : “I have a stake in it as Meta. Some giant private debt provider has a stake in it. The datacenter is under my control. But I don’t own it, so you don’t get to roll it back into my balance sheet.”*\n\nThe Structure\n\nEntity Creation : Hyperscaler & PE firm form separate legal entity (SPV) Capital Structure : Typically 10-30% equity, 70-90% debt from private credit markets Lease Agreement : SPV leases capacity back to hyperscaler Balance Sheet Treatment : SPV debt doesn’t appear on hyperscaler’s balance sheet\n\nThe hyperscaler maintains operational control through long-term lease agreements. Because it doesn’t directly own the SPV , the debt remains off its balance sheet under current accounting standards.\n\nThe appeal is straightforward. “I don’t want the credit rating agencies to look at what I’m spending. I don’t want investors to roll it up into my income statement.”*\n\nMarket Scale\n\nAmerican tech companies are projected to spend $300-400 billion on AI infrastructure in 2025. Hyperscaler capital expenditures have reached approximately 50% of operating income, levels historically associated with government infrastructure buildouts rather than technology companies.\n\nWhere the Risk Sits\n\nDatacenter assets now represent 10-22% of major REIT portfolios , up from near zero two years ago. The thin equity layer (10-30%) means if datacenter utilization falls short of projections or if GPUs depreciate faster than projected , equity holders face losses before debt holders experience impairment.\n\n*Quotes lightly edited for clarity & brevity\n\n5. Custom Silicon Threat\n\nHyperscalers are building their own AI accelerators to reduce Nvidia dependence. Microsoft aims to use “mainly Microsoft silicon” , specifically Maia accelerators , in datacenters. Google deploys TPUs , Amazon builds Trainium & Inferentia chips , & Meta develops MTIA processors. If customers shift to in-house silicon , CoreWeave’s GPU collateral value & Nvidia’s vendor financing become exposure to customers building competitive alternatives.\n\nNvidia Isn’t Lucent & 2025 Isn’t 2000\n\nAccounting : Lucent manipulated $1.148B in revenue , SEC charged 10 executives with fraud ; Nvidia shows no evidence of manipulation , audited by PwC , Aa3 rated\n\n: Lucent manipulated $1.148B in revenue , SEC charged 10 executives with fraud ; Nvidia shows no evidence of manipulation , audited by PwC , Aa3 rated Cash flow : Lucent lent $8.1B while cash flow lagged profitability & receivables exploded $5.4B (1998-1999) ; Nvidia lends with $50B+ annual operating cash flow & $46.2B net cash\n\n: Lucent lent $8.1B while cash flow lagged profitability & receivables exploded $5.4B (1998-1999) ; Nvidia lends with $50B+ annual operating cash flow & $46.2B net cash Credit rating : Lucent downgraded to A3 (December 2000) ; Nvidia upgraded to Aa3 (March 2024)\n\n: Lucent downgraded to A3 (December 2000) ; Nvidia upgraded to Aa3 (March 2024) Customer base : Lucent’s customers were leveraged CLECs burning capital ; Nvidia’s top 4 customers generated $451B in operating cash flow in 2024 (Microsoft $119B , Alphabet $125B , Amazon $116B , Meta $91.3B)\n\n: Lucent’s customers were leveraged CLECs burning capital ; Nvidia’s top 4 customers generated $451B in operating cash flow in 2024 (Microsoft $119B , Alphabet $125B , Amazon $116B , Meta $91.3B) Capacity : Fiber networks used <0.002% of capacity in 2000 ; Microsoft & AWS report AI capacity constraints in 2025,\n\nWhat I’m Watching\n\nIs AI demand real (like cloud computing) or speculative (like dot-com fiber)?\n\nHere’s what I’m watching :\n\nGPU utilization rates : Are data centers actually using the chips or just stockpiling? OpenAI’s monetization : Can they generate enough revenue to justify the buildout? Debt defaults : Any cracks in the $15B GPU-backed debt market? AR trends : AR improved from 68% (FY24) to 30% (Q2 FY26) , but still watch for deterioration Customer adds : Are new customers emerging , or is Nvidia dependent on the same 2-4 hyperscalers? Custom silicon threat : Microsoft developing Maia accelerators , aiming to use “mainly Microsoft silicon in the data center.” If hyperscalers shift to in-house chips , Nvidia’s vendor financing becomes exposure to customers building competitive alternatives. Vendor consolidation : Many companies are in a period of experimentation trying 2-3 competing vendors. Those experimental budgets may thin with time , reducing overall spend.\n\nAI is already broadly deployed—40% of US employees used AI at work by September 2025 , double the 20% rate in 2023. Questions persist about effectiveness : the oft cited MIT study found 95% of AI pilots failed to deliver measurable P&L impact , primarily due to poor integration rather than technical failures.\n\nYet the pace of improvement is tremendous. Labor market data shows wages rising twice as fast in AI-exposed industries , & workers using AI boost performance up to 40%. Many of Nvidia’s customers are profitable & sophisticated hyperscalers—Microsoft , Google , Amazon , Meta—generating $451B in operating cash flow in 2024 , with tremendous pull from their own enterprise customers demanding AI. OpenAI is not profitable , reporting a $4.7B loss in H1 2025 on $4.3B revenue , though nearly half the loss is stock-based compensation.\n\nUnlike the telecom bubble , where demand was speculative & customers burned cash , this merry-go-round has paying riders.\n\nCoda : Lucent’s Accounting Fraud\n\nBehind the vendor financing disaster was systematic accounting fraud. The SEC charged Lucent with manipulating $1.148 billion in revenue & $470 million in pre-tax income during fiscal year 2000. The fraud involved multiple schemes :\n\nChannel Stuffing : Lucent sent $452 million in equipment to distributors but counted it as revenue before the distributors sold to end customers. This created phantom sales.\n\nSide Agreements : Lucent executives entered secret agreements with distributors granting them return rights & privileges beyond their distribution contracts , making it improper to recognize revenue. These side deals were hidden from auditors.\n\nReserve Manipulation : Lucent improperly established & maintained excess reserves to smooth earnings , violating GAAP.\n\nThe SEC charged 10 Lucent executives with securities fraud. The company paid a $25 million fine—the largest ever for failing to cooperate with an SEC investigation. The accounting manipulation masked deteriorating fundamentals until too late.\n\nThe WinStar Collapse : Lucent committed $2 billion in vendor financing to WinStar Communications , a CLEC. When WinStar struggled , Lucent refused a final $90 million loan extension. WinStar filed bankruptcy. Lucent wrote off $700 million in bad debts. This pattern repeated across customer defaults : Lucent made provisions for bad debts of $2.2 billion (2001) & $1.3 billion (2002)—a total of $3.5 billion in customer loan losses.\n\nReferences",
      "source": "Tomtunguz.com",
      "url": "https://tomtunguz.com/nvidia_nortel_vendor_financing_comparison/",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Trump administration's $100,000 H-1B visa fee challenged in new lawsuit",
      "content": "President Donald Trump signed a proclamation in September that would implement a $100,000 fee for each H-1B visa application.\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nA coalition of unions, nonprofits, religious organizations, and a healthcare staffing firm, among others, is suing the Trump administration over its $100,000 H-1B visa fee, marking what appears to be the first major legal challenge against the proclamation to land in federal court.\n\nIn a lawsuit filed on Friday in the US District Court in Northern California, plaintiffs said President Donald Trump doesn't have the authority to \"unilaterally impose fees,\" calling it \"extortionate,\" \"draconian,\" and an impediment to innovation.\n\n\"Most fundamentally, the President has no authority to unilaterally impose fees, taxes or other mechanisms to generate revenue for the United States, nor to dictate how those funds are spent,\" the lawsuit said. \"The Constitution assigns the 'power of the purse' to Congress, as one of its most fundamental premises.\"\n\nThe lawsuit further argued that Trump framed the fee as a tax, considering what he said he'd do with the funds raised from the $100,000 requirement.\n\nOn September 19, Trump told reporters, \"We're going to take that money and we're going to reduce taxes, we're going to reduce debt.\"\n\nThe suit, led by a California-based healthcare recruiting firm called Global Nurse Force, is asking a federal court to declare Trump's proclamation unlawful and to prevent the government from enforcing the fee.\n\nThe H-1B visa program has long served as a pipeline for skilled foreign workers to enter the United States legally. Over the years, the tech and research fields have become among the top industries that utilize H-1B visa workers.\n\nHowever, the program has also been critical for manufacturing, health care, and education, among other industries. The lawsuit said that while many H-1B workers are in tech, \"more than a third of all H-1B workers are in other fields.\" Notably, the coalition of plaintiffs does not appear to include any tech-related organizations or representatives.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nIn implementing a $100,000 fee, Trump said the move seeks to discourage employers and companies from exploiting the program to replace American workers.\n\nWhite House spokesperson Abigail Jackson told Business Insider in an email that the administration's actions \"are lawful\" and that the new requirement will stop companies from \"spamming the system and driving down American wages, while providing certainty to employers who need to bring the best talent from overseas.\"\n\nThe introduction of the fee nearly two weeks ago initially sowed chaos and confusion in Silicon Valley, as employers rushed to warn any of their H-1B workers who were overseas at the time to return to the US immediately.\n\nAs more details trickled in, some major tech CEOs, including Nvidia CEO Jensen Huang, appeared to warm to the idea.\n\n\"Immigration is really important to our company and is really important to our nation's future, and I'm glad to see President Trump making the moves he's making,\" Huang said in an interview with CNBC.\n\nAttorneys for the plaintiffs did not immediately respond to a request for comment.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/h1b-visa-lawsuit-trump-administration-sued-2025-10",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Skytech Eclipse Lite 2 Desktop: Ryzen 7 9800X3D, RTX 5080, 32GB RAM, 2TB SSD $2181 + Free Shipping",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18661510-skytech-eclipse-lite-2-ryzen-7-9800x3d-rtx-5080-32gb-ddr5-2tb-ssd-2180-99",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Nvidia is the world's most valuable company. Why does CEO Jensen Huang barely make the list of the 10 wealthiest people?",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nThe list of the world's wealthiest people mostly comprises the biggest shareholders of the largest companies on the planet. So why does the cofounder and CEO of the world's most valuable company rank just 10th?\n\nAs of Monday's close, Nvidia's Jensen Huang had a net worth of $147 billion, per the Bloomberg Billionaires Index.\n\nThat puts him just behind Warren Buffett, who has a $148 billion fortune, even though Buffett's Berkshire Hathaway is worth about a quarter as much as Nvidia, and Buffett has gifted more than half of his Berkshire stock to foundations since 2006.\n\nBernard Arnault ranks eighth with a $164 billion fortune, despite LVMH being worth under $300 billion, or less than a 10th of Nvidia.\n\nElon Musk, the world's wealthiest person, has an estimated net worth of $383 billion and could extend his lead if his proposed $1 trillion pay package is approved. That's striking as the two companies that make up the lion's share of Musk's wealth, Tesla and SpaceX, are together valued around $1.6 trillion — less than 40% of Nvidia's market value.\n\nDilution of shares\n\nThere's one reason Huang, who cofounded Nvidia in 1993 and has been the chipmaker's CEO ever since, isn't richer: dilution.\n\nAhead of Nvidia's IPO in 1999, Huang owned 12.8% of the company. That stake would be worth over $500 billion today.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nWhile it's typical for founders to sell shares and see their ownership diluted when their companies go public, Huang has seen a far more significant and prolonged decline in his stake. It fell to 9.9% in 1999, 7.1% in 2003, 4.4% in 2010, then stabilized between 3.5% and 4% from 2020 through this summer, filings show.\n\nFor comparison, Buffett owns about 14% of Berkshire, Arnault owns roughly half of LVMH, and Musk owns around 13% of Tesla and 42% of SpaceX.\n\nHuang's percentage ownership has dropped by more than two-thirds primarily because Nvidia has issued vast amounts of shares to provide equity for its employees. The company reported a hefty $14 billion of unearned stock-based compensation as of July 27, much of which it expected to recognize in around two years' time.\n\nNvidia has offset some of the dilution through stock buybacks, but its outstanding shares have surged from a split-adjusted 1.7 billion when it went public, to north of 23 billion now — a roughly 14-fold increase.\n\nMany companies, especially in the tech space, award employees with stock or stock options to incentivize them to increase the value of the company and its stock, while discouraging them from decamping to rivals. It's a way to attract and retain talent without spending cash.\n\nHuang's stake has also shrunk because he's sold shares, including a prearranged trading plan to dispose of up to 6 million shares this year, worth about $1 billion at Nvidia's current stock price.\n\nThe rich list changes as companies' market caps fluctuate, but Huang's smaller stake means he's unlikely to top it anytime soon.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/nvidia-stock-jensen-huang-wealth-musk-buffett-ai-tech-compensation-2025-9",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Europe's answer to OpenAI just got a $1.5 billion boost from chip giant ASML",
      "content": "lighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nHave an account? Log in .\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nFrench AI startup Mistral has secured a massive investment from Dutch chip company ASML.\n\nMistral, which is seen as Europe's answer to OpenAI, received a 1.3 billion euros, or $1.5 billion, investment from ASML as part of a wider $2 billion funding round, the companies said Tuesday.\n\nASML, which has a market capitalization of $308 billion, has taken a roughly 11% stake in Mistral, making it the startup's largest shareholder. The Dutch company sells specialized machinery essential for chip manufacturing,\n\nThe funding roughly doubles Mistral's post-money valuation to nearly $13.8 billion, cementing its place as Europe's most valuable AI startup.\n\nMistral's funding is dwarfed by that of OpenAI, which has raised close to $60 billion in total.\n\nMistral has developed large language models that are open weights, meaning anyone can see or use information determining how the model works after it's been trained — but not the full source code.\n\nASML's president and CEO, Christophe Fouquet, said the company would use Mistral's AI technology in its own supply chains and for R&D.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nArthur Mensch, the cofounder and CEO of Mistral, said it would help ASML \"solve current and future engineering challenges through AI.\"\n\nOther investors in the Series C round included DST Global, Andreessen Horowitz, and Nvidia, which have all previously invested in Mistral.\n\nUnlike Nvidia, which makes a large number of investments in startups, ASML is more selective. The Dutch company has invested in venture funds like the DeepTechXL fund, but its last public direct investment in a startup was Smart Photonics in 2023.\n\nIt's also the latest example of a synergy between Mistral and one of its investors from the semiconductor world.\n\nIn June, Nvidia announced a partnership with Mistral to provide Nvidia chips for the startup's homegrown AI infrastructure platform.\n\nCEO Jensen Huang took to the stage with Mensch to talk up \"AI sovereignty,\" the idea of a country using its own AI infrastructure, such as hardware and data, within its own borders.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/mistral-funding-asml-chips-ai-europe-2025-9",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nebius Shares Surge on $17.4 Billion AI Infrastructure Deal With Microsoft",
      "content": "This article first appeared on GuruFocus.\n\nNvidia (NVDA)-backed Nebius Group (NASDAQ:NBIS) said Monday it reached a $17.4 billion agreement to provide Microsoft (NASDAQ:MSFT) with GPU infrastructure capacity, sending its shares up more than 47% in after-hours trading.\n\nThe five-year contract, which could increase to $19.4 billion if Microsoft opts for additional services, underscores rising demand for high-performance computing to support artificial intelligence development.\n\nNebius, which provides Nvidia-based GPUs and AI cloud services, will supply Microsoft from a new data center in Vineland, New Jersey, beginning later this year. The company said the partnership will accelerate growth of its AI cloud business into 2026 and beyond.\n\nMicrosoft has also been expanding partnerships with other GPU providers, including CoreWeave, one of Nebius' rivals.\n\nAmsterdam-based Nebius was formed out of a restructuring of Russian technology firm Yandex.\n\nInvestors will watch for updates on the rollout of the Vineland data center and the pace of AI cloud adoption in the coming quarters.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nebius-shares-surge-17-4-145136091.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "US Tech Companies Enabled the Surveillance and Detention of Hundreds of Thousands in China",
      "content": "An Associated Press investigation based on tens of thousands of leaked documents revealed Tuesday that American technology companies designed and built core components of China's surveillance apparatus over the past 25 years, selling billions of dollars in equipment to Chinese police and government agencies despite warnings about human rights abuses.IBM partnered with Chinese defense contractor Huadi in 2009 to develop predictive policing systems for the \"Golden Shield\" project, AP reports, citing classified government blueprints. The technology enabled mass detentions in Xinjiang, where administrators assigned 100-point risk scores to Uyghurs with deductions for growing beards or being aged 15-55. Dell promoted a laptop with \"all-race recognition\" capabilities on its WeChat account in 2019. Thermo Fisher Scientific marketed DNA kits as \"designed\" for ethnic minorities including Uyghurs and Tibetans until August 2024.Oracle, Microsoft, HP, Cisco, Intel, NVIDIA, and VMware sold geographic mapping software, facial recognition systems, and cloud infrastructure to Chinese police through the 2010s. The surveillance network tracks \"key persons\" whose movements are restricted and monitored, with one estimate suggesting 55,000 to 110,000 people were placed under residential surveillance in the past decade. China now has more surveillance cameras than the rest of the world combined.",
      "source": "Slashdot.org",
      "url": "https://news.slashdot.org/story/25/09/09/1124247/us-tech-companies-enabled-the-surveillance-and-detention-of-hundreds-of-thousands-in-china",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Hardware vs. IP: How to trade the gaming industry",
      "content": "00:00 Speaker A\n\nI want to shift gears to a discussion of hardware versus intellectual property. And just thinking about over the next 12 months, if you had to pick one bucket, and one of those could be chips and hardware with maybe Nvidia, Microsoft, Sony consoles, and then you have content and IP on the other, with Take two and Roblox and we'll get to the game, we'll get to, um, Grand Theft in a second. Where do you see that heading over the next year?\n\n00:32 Speaker B\n\nI mean, the hardware side's hard to play. Um, Nvidia obviously is a phenomenal company, but you know, a very small percentage, I think less than 5% of their revenue comes from gaming. So it might be 10, but it's really small. I think it's four or five billion a quarter out of 45 billion. So, you know, they're they're great, um, but they're not going to really grow that very much. They used to be more like 50% gaming for PC graphic processors. Um now it's all AI. So I love Nvidia, uh, but it's really not a gaming play. Nintendo is the pure play. Sony is not quite pure play because of studios and other things. But Nintendo is a pure play, uh hardware manufacturer that also happens to have a lot of great software. Um, and and you can participate there. The stock's at an all-time high. So, you know, it's fine. I think that there're probably some upside there. But I much, much prefer to play in the software side. Uh intellectual property is inexpensive to reproduce again and again and again, very high margin. So you want to play the guys that have the content or the guys that have the technology and that would include Unity and AppLovin.\n\n02:08 Speaker A\n\nAll right, let's stick with content and IP, talk about Grand Theft Auto 6. Uh, it's been a dozen years since five came out and I'm wondering what the expectations are and then the pricing point especially. I believe you've said it could reach triple digits.\n\n02:30 Speaker B\n\nYeah, I'm I'm pretty confident it will be $100. Um and you know, it's funny because I'm basing my guess on what the CEO Strauss Zelnick has said, which is that they're going to charge what they believe that the game is worth and consumers will feel that they got a value for what they're paying. No no no point in making that comment if you're going to charge 60 or 70 bucks. So just the idea that he's addressed price tells me it's going to start at 100, and I don't think gamers are going to even flinch. Um, this game is going to be probably twice as big as the last one. Uh as you pointed out, 12 years in development, it'll come out, uh just shy of the 13th anniversary of the last release. They have 1,200 people working on it, which means they're spending way north of 100 million per year on development cost. So they've got a billion, billion five invested in the game. Why not charge 100 bucks? And and the truth is, gamers are an entitled bunch of whiny little babies, but but the truth, you know, they they can wait a year if they don't want to pay 100 bucks. They can buy it at 70 next year. And I think Take two will charge 100. I think they will sell 30 or 40 or 50 million units at 100 bucks and that incremental $30 is virtually all profit. So if they can make an extra two or three billion dollars, why not?",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/hardware-vs-ip-trade-gaming-183000002.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AI expert says it’s ‘not a question’ that AI will take over all jobs—but people will have 80 hours a week of free time",
      "content": "While many CEOs are pausing hiring while they wait and see what jobs AI could replace, one AI expert warns that nearly all roles are at risk. Professor of computer science Dr. Roman Yampolskiy predicts that 99% of work will be placed by AI and humanoid robots in the next five years, and there will be no “plan B” in retraining for a new job. On the plus side, however, he predicts that humans will have 60 to 80 hours freed up per week, thanks to not having to work.\n\nIt’s only been three years since OpenAI released ChatGPT into the world, and companies are already shaving down their workforces to make way for AI automation. This has left many employees clinging to their jobs for dear life—but according to Dr. Roman Yampolskiy, a professor of computer science and leading voice in AI safety, no worker is safe.\n\nDespite cab drivers and even teachers like himself saying they’re irreplaceable, he said it’s inevitable that the technology will take over.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\n“That is not even a question if it’s possible,” Yampolskiy recently said on The Diary of a CEO podcast when discussing jobs being automated by AI. “It’s like, how soon before you [are] fired?”\n\nThe computer science professor has joined the cohort of tech leaders—including Anthropic CEO Dario Amodei and Silicon Valley investor Vinod Khosla—raising the alarm bells that AI will trigger a jobs armageddon.\n\nBut while Amodei thinks that AI could swipe half of white-collar roles in the next five years, spiking unemployment up to 20%, Yampolskiy said that joblessness could reach as high as 99% in that same time frame. And contrary to popular belief, he thinks that workers won’t simply funnel into new roles that haven’t been disrupted or invented by AI yet.\n\n“Before we always said, ‘This job is going to be automated, retrain to do this other job,’” the AI expert said. “But if I’m telling you that all jobs will be automated, then there is no plan B. You cannot retrain.”\n\nThere will be record levels of unemployment—but he says humans will have 60 hours of freed time\n\nThe engineering professor is steadfast that nearly all jobs will be taken over by AI—even most of the ones that have a special human touch, like teachers and car drivers.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAnd the career paths that once guaranteed six-figure salaries are also on the way out; he pointed out the very popular computer science track, which he currently teaches at the University of Louisville, and has since been upended by AI.\n\n“Look at computer science. Two years ago, we told people ‘Learn to code—you are an artist, you cannot make money. Learn to code.’ Then we realized, ‘Oh, AI kind of knows how to code and [is] getting better. Become a prompt engineer. You can engineer prompts for AI. It’s going to be a great job. Get a four-year degree in it,’” Yampolskiy said on the podcast. “But then we’re like, ‘AI is way better at designing prompts for other AIs than any human.’ So that’s gone.”\n\nAs more jobs get replaced by AI, and roles that are created from this change also get automated, it’s an endless domino effect of unemployment. Yampolskiy warned joblessness will hit an all-time high in the next five years as all human work, including manual labor, is replaced by humanoid robots and AI agents.\n\n“We’re looking at a world where we have levels of unemployment we [have] never seen before,” he revealed. “[I’m] not talking about 10% unemployment, which is scary, but 99%. All you have left is jobs where, for whatever reason, you prefer another human would do it for you. But anything else can be fully automated.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nWhile that sounds like a dark reality for most workers, Yampolskiy doesn’t seem phased by the inevitable. In fact, he sees an upside in this huge workforce shift—just like other tech leaders, he says massive jobs automation will lead to shorter workweeks.\n\nHe echoes the likes of former Microsoft CEO Bill Gates—who said that we’ll clock in just two days a week in the next ten years—and Nvidia chief executive Jensen Huang who predicts a four-day workweek. But Yampolskiy optimistically believes work will be scrapped entirely, leaving humans with the question of how they’ll spend their free time.\n\n“I don’t think there is a, ‘This occupation needs to learn to do this instead.’ I think it’s more like, ‘We as a humanity, then we all lose our jobs. What do we do? What do we do financially? Who’s paying for us? And what do we do in terms of meaning? What do I do with my extra 60, 80 hours a week?’”\n\nYampolskiy isn’t positive where that money is going to come from, but other tech leaders, like Elon Musk, suggest that the technology will create the need for a “universal high income”—where people have access to all the money they need to survive without having a job. Though he isn’t explicit on how much each person would need every year.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\n“There will be no shortage of goods and services. It will be an age of abundance,” Musk told former U.K. Prime Minister Rishi Sunak in 2023. “We won’t have universal basic income. We’ll have universal high income…In some sense, it’ll be somewhat of a leveler, an equalizer.”\n\nThis story was originally featured on Fortune.com",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/ai-expert-says-not-ai-145521588.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia Announces Rubin CPX GPU To Speed Long-Context AI",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/karlfreund/2025/09/09/nvidia-announces-rubin-cpx-gpu-to-speed-long-context-ai/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "NVIDIA (NVDA) Remains a Franchise Pick as Jefferies Reiterates Buy",
      "content": "NVIDIA Corporation (NASDAQ:NVDA) is one of the Buzzing AI Stocks on Wall Street. One of the biggest analyst calls on Friday, September 5, was for Nvidia Corporation. Jefferies reiterated the stock as “Buy,” stating that the stock remains on the franchise picks list.\n\n“The rapid proliferation of AI demand continues with leaders from across the industry offering commentary indicating significant compute supply shortages. Given NVDA’s position as the dominant supplier of AI accelerators within AI data centers, we remain bullish on shares.”\n\nNVIDIA Corporation (NASDAQ:NVDA) specializes in AI-driven solutions, offering platforms for data centers, self-driving cars, robotics, and cloud services.\n\nWhile we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 10 AI Stocks to Watch Out For in 2025 and 10 AI Stocks Gaining Attention on Wall Street.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-nvda-remains-franchise-pick-190205857.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Analyst Slashes Nvidia Price Target By 5%, Citing Intensifying AI Chip Rivalry From Broadcom And Google",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/cc2ab47e4c4f73c3",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Analyst surprisingly cuts Nvidia stock target amid a growing threat",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/investing/analyst-surprisingly-cuts-nvidia-stock-target-amid-a-growing-threat",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "UAE Lab Releases Open-Source Model to Rival China’s DeepSeek",
      "content": "The United Arab Emirates wants to compete with the U.S. and China in AI, and a new open source model may be its strongest contender yet.\n\nAn Emirati AI lab called the Institute of Foundation Models released K2 Think on Tuesday, a model that researchers say rivals OpenAI’s ChatGPT and China’s DeepSeek in standard benchmark tests.\n\n“With just 32 billion parameters, it outperforms flagship reasoning models that are 20x larger,” the lab wrote in a press release on Tuesday. DeepSeek’s R1 has 671 billion parameters, though only 37 billion are active. Meta’s latest Llama 4 models range from 17 billion to 288 billion active parameters. OpenAI doesn’t share parameter information.\n\nResearchers also claim that K2 Think leads “all open-source models in math performance” across several benchmarks. The model is intended to be more focused on math, coding, and scientific research than most other AI chatbots.\n\nThe Emirati lab’s selling point for the model is similar to DeepSeek’s strategy that disrupted the AI market earlier this year: optimized efficiency that will have better or the same computing power at a lower cost.\n\n“By proving that smaller, more resourceful models can rival the largest reasoning systems, this milestone marks the beginning of the next wave of AI innovation,” Peng Xiao, council member of Abu Dhabi’s AI and Advanced Technology Council, said in the press release.\n\nXiao is also the CEO of G42, an Emirati AI development company that co-launched the K2 Think model. The company last made headlines for inking a multibillion-dollar data center deal with the Trump administration earlier this year, which has since been mired in national security concerns.\n\nThe lab is also aiming to be transparent in everything, “open-sourcing not just models but entire development processes” that provide “researchers with complete materials including training code, datasets, and model checkpoints,” IFM said in a press release from May.\n\nThe long-term plan is to incorporate K2 Think into a full LLM in the coming months, WIRED reported.\n\nBooming Emirati investment in AI\n\nThe Emiratis are serious about AI. The country counted 672 new AI companies between June 2023 and June 2024, making it the fastest-growing AI cluster in the Middle East and North Africa region.\n\nThe lab behind K2 Think was established by the Mohamed bin Zayed University of Artificial Intelligence, which has its headquarters in Abu Dhabi and two research hubs in Silicon Valley and Paris. It was founded a couple of years ago as part of the Emirati government’s AI overhaul strategy, called Artificial Intelligence 2031. The university’s president is Chinese-born American researcher Dr. Eric Xing.\n\nThe Emirati AI overhaul has also benefited American companies. Abu Dhabi state AI fund MGX, chaired by the UAE’s national security adviser, is a founding partner of Trump’s Project Stargate, and the fund has previously invested in OpenAI.\n\nTrump also announced in May that Abu Dhabi and Washington were partnering to create the largest AI data center cluster outside of the U.S., built and operated by G42 —the company that co-launched K2 Think on Tuesday— and with the help of Nvidia, OpenAI, Cisco, Oracle, and Japanese firm Softbank.\n\nBut that deal has faced U.S. regulator scrutiny over security concerns, particularly regarding the UAE’s relationship with China. Chinese tech and AI firms like Huawei and Alibaba have been expanding their influence in the UAE and the Middle East at large.\n\nG42 specifically had several Chinese investments, which the company reportedly got rid of after pressure from the Biden administration over a $1.5 billion strategic investment by Microsoft.\n\nAI is the new oil in the Middle East\n\nThe Emirates’ growing bet on AI is driven by a desire to diversify investments and reduce its economic dependence on fossil fuels like oil and gas.\n\nThe trend is seen in the rest of the Arab world as well, particularly in the oil-rich Gulf states. Saudi Arabia created a $100 billion AI investment fund last year as part of an effort to diversify its oil-reliant economy by 2030.\n\nSaudi Arabian DataVolt is moving forward with plans to invest $20 billion in AI data centers and energy infrastructure in the United States.\n\nElsewhere in the Gulf, Qatar Investment Authority was a significant investor in American AI company Anthropic in a $13 billion funding round last week.\n\nMore countries seek to challenge U.S. and Chinese dominance in AI\n\nA growing list of countries is seeking to join the battle for global AI dominance that’s currently dominated by American and Chinese companies.\n\nIn the rest of Asia, Singapore is a rising power, with AI-friendly regulatory oversight that has spurred the launch of AI innovation hubs from tech giants like Microsoft.\n\nIn Europe, the French are making major AI plays. The French AI startup Mistral just secured a $1.5 billion investment by Dutch semiconductor maker ASML on Tuesday. Mistral is considered a major competitor to OpenAI in Europe.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/uae-lab-releases-open-source-model-to-rival-chinas-deepseek-2000656197",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Forget the September slump: Why this market continues to rally",
      "content": "0:05 spk_0\n\nWelcome to Stocks and Translation, Yahoo Finance's video podcast that cuts through the market mayhem, the noisy numbers, and the hyperbole to give you the information you need to make the right trade for your portfolio. I'm Jared Blickery, your host, and with me is Yahoo Finance's Allie Cannell, who's here to keep the discussion simple, accessible, and also lively. Today we're gonna be talking about theCooling labor market. If the Fed is once again too slow to cut rates and how to square that with a stock market that keeps hitting record highs. Our phrase of the day is the September effect. History says we're in the worst month of the year right now, and the weakness tends to come in the back half of the month. So how much do investors really need to care about history rhyming?And this episode is brought to you by the number 9.7. That's how many percentage points of pure profit you would have missed out on, had you panic sold after Liberation Day and missed the single best day of the year, how to make an investing plan that keeps you cool and calm when the headlines, they get scary.And today we're welcoming back Phil Rosen, co-founder of the Opening Bell Daily. He recently left Business Insider to build his independent data-driven markets outlet along with Anthony Pomliano, and he's also a published author, twice over, penning a collection of New York centric vignettes in lifeween moments, as well as a travel novel, everywhere but Home. So Phil, it is great to see you here.And uh we're gonna get to our phrase of the day, September effect in a minute. Just tell us how you're seeing the markets right now overall.\n\n1:35 spk_1\n\nSo, uh, first of all, thank you both for having me. It's great to be back. Um, the market right now, we have a lot of positive momentum and I think that is the, the twist in history right now. So typically we're going into September, very weak and very jittery and investors across the board are expecting this pull back, but I do think.This year, uh, you know, famous last words this time is different. However, uh, the rate cut on September 17th, which is pretty much guaranteed at this point, I think that is going to see markets finish higher in September, which is very unusual because I think in the last 10 years September's finished down 2% on average, and if you go back to 1950, it's down like 0.8% or something like that. Yeah,\n\n2:18 spk_0\n\nand so that's perfect. Let's get into our phrase of the day that would be the September effect.And this is the historical tendency for stocks to post returns that are weaker in September than the other months, and it's important to note that this is just a pattern based on history, which may or may not pan out, but I'm wondering how you think about seasonality in general, seasonality just being, you know,The same types of things, patterns that we see in the market happen year after year. How much do they play into your analysis?\n\n2:46 spk_1\n\nSo I think a lot of this, especially in September, is a self-fulfilling prophecy, right? Investors are expecting this September effect to take hold, but again,I don't know if it applies as much this year because this has also been one of the wildest, most eventful years in market history, and you know we all know this as reporters we're writing about it every day, but we have, uh, the Federal Reserve has been pushing back and forth with the White House. We have these tariffs and we have this now widely expected rate cut in a week. So all this, I think anything is uh up for grabs right now, but I, I don't think seasonality will have as much of a play.As history suggests, you\n\n3:28 spk_2\n\ncan even look at go away. That that trend did not work\n\n3:32 spk_0\n\nout. Yeah, well, I, and I've done, I've done some studies on this go away. It's more like hedge and may and go away. It's evolved over the years, but we've seen different patterns from like 1940s to 1980s versus 1980s to now.Um, you've said some interesting things here, and you mentioned the fact that this is a wild year, Phil, and I was looking at seasonality coming into the, uh, the Trump presidency, and you can do seasonality. You can slice it, uh, and dice it several different ways. And one of the ways is to look at what year of the presidential cycle we're in. This is the first year. This is Donald, even though it's his 2nd term, it's his first year of this term.And I got to tell you what happened around liberation Day completely destroyed the seasonality chart, and then the market kind of came back and it seemed like at the end of August, we were right on track again according to some models. But in general, just talk to us about, especially maybe as, as in terms of how you cover these markets, what you've seen and how this has surprised you this year, some of the wildcards.\n\n4:29 spk_1\n\nSo I, I think right now the S&P 500.Actually having a better than average year generally, but also a better than average post-election year. So all this is going against the, let's say the tariff doomers in the start of the year. Everyone thought tariffs would destroy the market. They thought the Fed independence battle that would also destroy the market, but pretty much investors have not even paid attention to this, uh, let's say when you zoom out. So I, I think, um.A lot of the bearishness has been sort of eked out of the market right now, and almost every single firm has turned bullish for the year, and uh this.The narrative of betting against the Bears, I think that is the story of the year because the Bears have been the loudest, certainly in the first half of the year, but all the Bulls have been the ones that ended up right.\n\n5:18 spk_2\n\nBut it is interesting to me as a reporter like you were saying, covering this day in and day out, there are a lot of bulls out there, but there also are more cautious voices even when we talk about rate cuts, Eddie Denny from your Denny Research, he's a fan of the show, friend of the show, and he said that maybe the Fed shouldn't be cutting right now, and that could actually maybe lead to a market melt up and there could be a lot of money running in here at a time when you haveInflation that's still hot. There's also this debate about whether or not we're not too heavy, too concentrated in the market. So it does feel like at the same time there are a lot of unknowns and there is this tension among strategists about what comes next.\n\n6:01 spk_1\n\nSo I think your Danny is definitely not alone in that view, right? And I read his research all the time. He's super smart. I will say our team at opening Bill Daily, we've pretty much been calling for a rate cut.It's about March. Um, so we do think the Fed has been slow to respond in policy, and I think the, the jobs report really confirmedthat.\n\n6:22 spk_0\n\nYeah, that was that was dismal in a lot of ways. And then we know, we learned retroactively that one of the months, a few months ago, I think it was June turned negative and that's always had it, had it been negative in June, we probably would have had a rate cut already. And so that kind of brings to the forefront the issue is Jerome Powell and the Fed a little bit too late? What do you think about that?\n\n6:42 spk_1\n\nI do think they are too late, but I don't think it's necessarily Jerome Powell's fault. I think it's a structural deficiency of the Fed because it's a backward looking institution, right? But markets move so rapidly the economy can change faster than we think, but the Fed is pretty much working with uh a backward looking.Mandate, right? And then also the data can be hit or miss on whether you believe it or not. Maybe not believe is not the right word, but it's always revised, right? So the Fed's working with a pretty difficult circumstance. So I, I, I don't know if it's necessarily Jerome Powell. I think if anyone was in theThat job, they would probably be late this year.\n\n7:20 spk_0\n\nYeah, I don't, I don't envy anybody in that slot. You just brought up the data and I'm wondering what you've, you've thought about all the controversy surrounding the BLS, um, and a lot of this comes from the fact that since the pandemic, peoplehaven't been responding to these government surveys and so there's, you can't, you can't rely on the data as much. The margin of error is greater. And so I think it's no surprise that we have June being revised negative. There's a, there's a huge uh leeway that you got to give this data. So what do you think about the issue that, um, you know, Trump has raised the question of integrity. Do you think that's an issue?\n\n7:56 spk_1\n\nSo I, I don't know if replacing the head of the BLS is going to change the integrity of the data. I think the data was pretty, um, let's say, uh, it was gonna be revised no matter who is in charge, right? So I don't know if Trump putting his own person in there is gonna improve or worsen the data because I, I think it's, again, these are very old, you know.Methods that they're using to track all this data and I for one, I try to look at alternative sources of data, try to accrue a bunch of different sources when I make my analysis on the market and I would never just rely on let's say the BLS to determine what I think is gonna happen next in the market.\n\n8:36 spk_2\n\nSo what are those sources of data for you.really inform your viewpoints when it\n\n8:40 spk_0\n\ncomes to what do you look at every morning? Yeah.\n\n8:42 spk_1\n\nSo I, I think anecdotally, um, I talked to a lot of people, so I talked to a lot of strategists, as you both do. I talked to a lot of economists, and I talked to people in hiring manager, manager positions, right? Are they hiring? Are they not hiring? Um, you know, I actually met this engineer the other day and um.He told me that, so he's been at this firm for about a decade, this is a big tech company, and he used to do 2 interviews a week. This was about a year and a half ago, and now he does about an interview per quarter, and to me that was like a very uh red flag, let's say on the labor market.\n\n9:17 spk_0\n\nI want to talk about some of the market stuff that we're seeing. concentration has been a big issue, you know, do we, is too much of the market's gain due to just a few companies and arguably it's been that case over the last few years. And the other thing is we're in the 3rd year of this bull market now.And that's typically, you don't see the gains that you saw in the first two years. I would say 23 and 24, we had gains of 20+% and the S&P 500, now we're looking, I think we're on track for 9 or 10, which is not bad, uh, for especially for a third year, but how do you see the concentration issue evolving?\n\n9:50 spk_1\n\nSo I, I do think that's a very um relevant issue to talk about, right? It's super concentrated we're at dotcom levels and that's certainly not a comparison you want to hear in any context. You never want to be compared to the dotcom bubble, um, but I, I think the difference today is that the companies that are at the top of this concentration, the mag 7, right, we've never seen companies this profitable with this large balance sheets.And that to me that does give some cushion to that concentration argument right that the earnings have justified it maybe, yes, I, I think earnings have definitely justified it and I don't know if that's gonna last for much longer, but up to this point, I don't think it's um let's say something we should be overly concerned about. And again, I, I think I've seen um.S&P 493 earnings are slowly gonna catch up in the coming quarters while Mag 7 slows down, so that is something I think worth monitoring as well. Yeah,\n\n10:43 spk_2\n\nand Torsten Stock from Apollo, our parent company, he did publish uh quite a bit of research about how concentrated we are in this market, and that's because of those hyper scalers and the data demand and how much CapEx they're spending.Given that we just finished wrapped up this latest earnings season, were there any little signs that maybe that demand is starting to weaken just just a little bit? I know Nvidia missed on data center revenue. Was that concerning to you at all?\n\n11:10 spk_1\n\nSo I'm not sure if I have much to say on the side of that, but I do know we've never seen this S&P 50.earnings calls mention AI, right? So that's, you know, on one hand, you can say, oh, there's a top signal, who knows? Um, and then we also have um data center spend is, that's, that's going to keep increasing for probably several more quarters. Um, so all these things, it's like the\n\n11:34 spk_2\n\nmining.\n\n11:39 spk_1\n\nYou could argue very convincingly that there is a lot of froth in the market right now with AI, with crypto, with some of these meme stocks, but also you could take the other side and say earnings have been phenomenal and they're projected to be phenomenal again in the 4th quarter. That's why\n\n11:56 spk_2\n\nI think this market's been a little confusing because you can argue both sides of that equation, and we talk about retail traders, unprofitable tech that that's been leading the meme stocks like you mentioned.They're sort of bleeding this market higher and dragging the institutions along with it. So that's been something that I, yeah,\n\n12:12 spk_0\n\nI see that too, Ali. Hold that thought though, because guess what, we got to take a short break. Coming up, we're going to break down the number that captures market regret and a runway battle between David and Goliath, but with stocks, of course.This episode is brought to you by the number 9.7% points. That's how much profit you would have missed out on had you sold at the Lowe's after that scary post-liberation Day sell off and missed the April 9th rally. So one day, nearly 10%, and Phil, I'm saying this because it kind of opens up a discussion in a market psychology and about staying invested, all these things that we like to talk about. How do you, how do you think about this phenomenon and how do you keep, how do you tune out the noise?That's all in the media.\n\n13:05 spk_1\n\nThat's a very difficult and timeless question. Um, I, I think if you are someone with a 30 year investing horizon, you can pretty much ignore the news, right? And I say that as someone who's in the news, um, and\n\n13:17 spk_0\n\nwho probably has a 30 year investment horizon.\n\n13:19 spk_1\n\nYes, yes, exactly. So, um, for myself, um.I do think that the day to day fluctuations of the market, maybe the tariff scares or the Fed independence scares, all this stuff, it's intense in the moment, but if you're looking decades in advance, odds are your portfolio will be just fine if you just leave it as is and and stick to your plans, stick to your dollar cost averaging all those things.\n\n13:42 spk_2\n\nYeah, and when we talk about the record highs that we've been seeing and Jared was just mentioning some of the returns that we've had over the past few years, and then you try and match that with the state of the US economy and post-COVID we did see a struggle with inflation really rampant. A lot of everyday Americans were underwater, yet we had these double digit gains in the stock market.So how, how do you really square that when it comes to assessing the status of the economy while also what we're seeing with stocks at record highs?\n\n14:16 spk_1\n\nThat's a great question. So we've seen this phrase a tale of two economies, right? I think you pretty much have your asset allocators and then those that aren't in the market, and there's really been a clear winner and loser story here. And um if youYou know, the short of it, if you've been in the market, you've done very well, and if not, your dollar has lost purchasing power dramatically over the last 5 years. I think since 2020 we've probably lost 25% to 28% of our 1 dollar's purchasing power. So that is very significant. And if you were in the market, then you've been able to keep up or beat that, um.Let's say loss in purchasing power, but if not, you really can't buy as much as you could. Um, so these are, uh, these are structural issues thatReally points to the importance of investing, I think, um, but it also points to the uh probably the widening inequality gapas well.\n\n15:09 spk_2\n\nMaybe the types of companies you invest in too, because those that are more exposed to that lower income consumer, they have been reporting a little bit more of astruggle.\n\n15:18 spk_0\n\nYou've brought up a great point. I want to launch off that because you, you sent us a chart a few hours ago. Dollar General and Dollar Tree, two companies that are known to do well when the consumer is feeling a little bit off andTheir pockets are a little bit pinched. They are outperforming most of the other retail companies, especially the big box retailers this year. Not only that, they're outperforming Nvidia. So talk to us about that phenomenon. What do you think ofthat?\n\n15:42 spk_1\n\nSo when I saw those numbers and I sort of put the stocks on a line chart.I was very shocked and uh because Nvidia is the story of the year, right? Everyone loves this stock, earnings are the Super Bowl, all this, but Dollar Tree and Dollar General are beating it by I think by double digit digits still. Um, and the CEO of Dollar Tree at the last earnings call said.The majority of their new customers in the last quarter were six figure households. So that, that's, I read that and it was a baffling stat because you wouldn't assume that a six figure, uh, you know, high income household is going to a dollar store. Um, and I will say I love dollar stores likewise, I, I love a dollar store, um.But that points to this sort of flights of value, right? So everyday consumers regardless of income bracket are looking to stretch their dollars more and that goes to the loss of purchasing power, it goes to inflation, it goes to high interest rates. So all these things, um, it is pointing to a constrained consumer, I think.\n\n16:40 spk_2\n\nYeah, and, and when you talk about the dollar, I mean, I think year to date we've lost about 10% compared to other types of currencies, and it's interesting to look at that and then look at gold, which is now at record highs right around, let's talk about gold bucks. I mean, where is that mostly foreign investors piling into gold? Is it the expectation of rate cuts? What, what do you think has been driving kind of that side of the market?\n\n17:03 spk_1\n\nThat's a great question. Um, I, I think part of it is a lot of governments and central banks are buying gold, right? China, Russia, yeah. So I think that's, uh, you know, I don't know what percent they're driving, but that's probably a huge chunk of it. And then you have, um, Bitcoin as well has seen a similar, very strong year. Um, so you have central bank and government buying, I think you have retail catching on to this gold trade.And then you also have the general narrative, I think of you want to hedge against dollar debasement and gold and Bitcoin are are the best ways to play that, according to most people.\n\n17:36 spk_0\n\nWhat do you think of all these Bitcoin treasury companies, not just Bitcoin. Now we're seeing Ethereum treasury companies, people piling into the micro strategy, which almost got just got in, uh, added to the S&P 5.didn't quite make it. But uh Solana too, what do you think of all this, all this phenomenon?\n\n17:52 spk_1\n\nFirst of all, I think with the micro strategy not getting added, there were definitely some politics at play there. Um, I don't know the details, but it was so eligible, right, but it didn't get picked. Um and as far as the the broader Bitcoin treasury trend, um, this, you could say from a very high level.Is a bet that the dollar will continue to lose its value and Bitcoin will continue to appreciate over time so why wouldn't want, why wouldn't you want your balance sheet to be denominated in the asset that's gonna appreciate rather than get debased? So I think very simply and from a very high level that's what we're looking at and again you might be.Able to point out some froth in the market because there's been a lot of these popping up and I, I think we're seeing other crypto assets being put on balance sheets as well so that also suggests uh OK, are we getting overextended here but uh right now uh.I think the the train is still gonna keep going.\n\n18:50 spk_0\n\nAll right, we got to get to our runway battle today because on who are better. We are crowning a market leader and we are pitting the mega cap giants against their small cap cousins. On the left catwalk struts the mega cap moat, armor plated balance sheets, thick margins, and a wardrobe of buybacks. When the lights flicker, these names don't flinch. They just tighten their costs and keep the cash flows of coming. On the right runway, we've got thisAll caps scramble, cyclical energy turnaround stories and tags that still say discount. When the economy accelerates and money gets cheaper, these names rip. But rate cuts are a double-edged sword because if the Fed is too late, small caps, they get torn to shreds, while large caps, well, they suffer too, but typically a bit less. So Phil, you don't need to pick a religion here. We just want to know which closet you're wearing and why, who wears it better over the next year, Mega cap moat or theSmall cap scramble.\n\n19:43 spk_1\n\nThat'sa, that's a hell of an intro. Um, I, I would say from this point to year end, if we get, let's say 2 to 3 rate cuts, I think small caps will do very well. They're very interest rate sensitive and I think, um, large caps, you could also argue are getting a bit overextended despite the earnings that have been sogood.\n\n20:01 spk_2\n\nWhat if we only get one this\n\n20:03 spk_0\n\nyear or 10. That's not a good sign.\n\n20:08 spk_1\n\nUm.One cut, I would probably lean more towards mega caps, but I don't think we'll only get one cut. I think we'll probably get 3 by by December, I think so.\n\n20:17 spk_2\n\nYeah. And what do you think we'll drive that the continued deterioration of the labor market, or do you think the inflation side of the picture if that comes in hot this week, could that maybe give the Fed some pause?\n\n20:27 spk_1\n\nI think even if inflation comes in hot, the Fed has pretty much conceded that they're gonna let inflation run hot so I think they're gonna look at the labor market and they're also of course the the political pressure whether you say they're buckling or not, it's definitely a factor. So I, I think they're gonna let inflation.Rise, even if, you know, whether it rise or not, they're not going to be worried about that right now.\n\n20:47 spk_0\n\nPhil, at the beginning of the show, I mentioned you are an accomplished author, and I have read your book Life Between Moments. I love it. Tell us about your journey into writing fiction and how that's kind of uh maybe jive with your job here at Morning Bell.\n\n21:02 spk_1\n\nThat's that's deep in the archives there. Um, I think writing fiction has helped me, uh, just be a better writer in general, right? It helps me use differentUm, literary tools in my financial reporting, and I think it makes me, uh, understand the psychology of things a bit better. And yeah, that book really, uh, I wrote it when I was at Business Insider, and, uh, I would go home after work and spend maybe 30 to an hour on it a day, finished it in a year, and then published it and uh it has nothing to do with markets, nothing to do with Wall Street, um, but it was a great passion.of mine at the time and I'm honored you even know about it. Hey,\n\n21:38 spk_0\n\nIencourage everybody to read it, download it, get the Kindle some great stories in there. All right, so what did we learn today? We talked about the September and that's the seasonality play. It's just a tendency. It doesn't mean you have to get all scared because September tends to close down, but we do have some other orange or yellow flash.Warning signs and some of those have to do with the fact that the Fed might be a little bit behind the eight ball. We got a deteriorating labor market. But what's most important is that investors keep their, uh, keep their head on their accounts and not necessarily responding to the news on a day by day basis, uh, because the, the market itself, the S&P 500, yes, it's concentrated, but we've seenThis concentrated persists for long periods of time over history. So that's gonna do it for today. We got to wind down things here at Stocks and Translation, but be sure to check out all our other episodes of our video podcast on the Yahoo Finance site and mobile app. We are also on all your favorite podcast platforms, so be sure to like, leave a comment, and subscribe wherever you get your podcast. We'll see you next time on Stocks in Translation.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/forget-september-slump-why-market-100001329.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Cadence Built An Nvidia DGX SuperPOD Digital Twin With Incredible Scale And Accuracy",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/marcochiappetta/2025/09/09/cadence-built-an-nvidia-dgx-superpod-digital-twin-with-incredible-scale-and-accuracy/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Will Broadcom Chips End AMD Stock's AI Dreams?",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/09/will-broadcom-chips-end-amd-stocks-ai-dreams/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The XFX Radeon RX 7900 XT Graphics Card Drops to $630: This Is the Least Expensive 4K-Capable GPU",
      "content": "If you've just upgraded to a new 4K gaming monitor and now you're looking for a reasonably priced GPU that can comfortably run games off it, then check out this deal. Amazon is offering the XFX AMD Radeon RX 7900 XT 20GB graphics card for just $630.63. This is the lowest price I've ever seen for an RX 7900 XT GPU, and that's saying something because nearly all video cards nowadays are higher than their original launch price. The RX 7900 XT is a generation old, but it's still an excellent 4K GPU that approaches the performance of the GeForce RTX 5070 Ti and Radeon 9070 XT.\n\nThe Radeon RX 7900 XT was released back in 2022, but its still a relevant card today, able to play pretty much any game at 4K with consistent framerates of 60fps and beyond. Compared to current generation cards, it's roughly 5%-10% behind the Nvidia GeForce RTX 5070 Ti and and the AMD Radeon 9070 XT in 4K rasterized (non ray-traced) performance. It's also 10%-20% less expensive, making it a very attractive alternative for those of you who are on a budget. The RX 7900 XT also comes equipped with 20GB VRAM, which is more than the 5070 T iand 9070 XT, which come with 16GB. The extra VRAM allows it to scale well in high-resolution gaming and it's also a good card for AI use.\n\nIf You Need Ray Tracing, Stick with NVIDIA\n\nAMD Radeon cards are outstanding alternatives to the NVIDIA GeForce cards. For gamers who want to maximize their performance for their dollar, AMD GPUs are the way to go. However, if you're set on playing 4K games with ray tracing enabled, then you'll want to stick with NVIDIA. That's because the GeForce cards perform better than their Radeon counterparts when it comes to ray tracing. Ray tracing is a form of rendering that allows for more realstic lighting effects. It makes light sources and shadows look better, but at the steep cost of GPU resources.\n\nWhy Should You Trust IGN's Deals Team? IGN's deals team has a combined 30+ years of experience finding the best discounts in gaming, tech, and just about every other category. We don't try to trick our readers into buying things they don't need at prices that aren't worth buying something at. Our ultimate goal is to surface the best possible deals from brands we trust and our editorial team has personal experience with. You can check out our deals standards here for more information on our process, or keep up with the latest deals we find on IGN's Deals account on Twitter.\n\nEric Song is the IGN commerce manager in charge of finding the best gaming and tech deals every day. When Eric isn't hunting for deals for other people at work, he's hunting for deals for himself during his free time.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/xfx-radeon-rx-7900-xt-graphics-card-deal-best-4k-gpu-under-650",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia's CFO says there's still 'a little geopolitical situation that we need to work through' before shipping its AI GPUs to China, but it's 'a $2 billion to $5 billion potential opportunity'",
      "content": "Nvidia's executive vice president and chief financial officer, Collette Kress, spoke yesterday at the Goldman Sachs Communicopea event about a variety of topics, including a discussion of its recent financial results and the ongoing situation regarding its dealings with China. When asked for an update on demand for its H20 AI GPU in the country, and what needs to happen before it's potentially shipped in the second-to-last quarter of this year, Kress said:\n\n\"Yes, we did receive a license approval and have received licenses for several of our key customers in China. And we do want that opportunity to complete that and actually ship the H20 architecture to them.\n\n\"Right now, there is still… a little geopolitical situation that we need to work through between the two governments,\" Kress continued. \"Our customers in China do want to make sure that [the] China government is also very well received in terms of receiving the H20 to them. But we do believe there is a strong possibility that this will occur.\n\n\n\n\"And so it could add additional revenue. It's still hard to determine how much within the quarter. We talked about it being about a $2 billion to $5 billion potential opportunity if we can get through that geopolitical statement.\"\n\nWe reported last week that tech firms in China, including TikTok owner ByteDance, were reportedly waiting on their GPUs to arrive after placing orders back in July, when Nvidia was first said to be in the process of obtaining the appropriate licenses, with assurances from the US government they would be granted. Since then, Chinese data center operators have been given orders to obtain at least 50% of their chips from domestic manufacturers, while it's also been claimed that Nvidia has suspended production of the H20 chip after security concerns were raised by Chinese officials.\n\n(Image credit: Nvida)\n\nSo, by the looks of things, while licenses have indeed been granted to Nvidia to sell its H20 GPUs to China, there are still some serious headwinds to work through before the powerful AI hardware actually arrives on Chinese shores. It certainly seems like Nvidia is confident everything will get straightened out eventually, but this \"little geopolitical situation\" seems to be gumming up the works significantly.\n\n\n\nStill, with an estimated $2 to $5 billion of additional revenue on the line, I'd imagine Nvidia is working hard behind the scenes with both governments to come to a resolution. Us gamers may no longer be the biggest revenue driver for the company, but part of me wonders if the geopolitical intricacies of selling AI hardware to China amid confusing tariffs, export restrictions, and perceived political brinksmanship between the US and Chinese governments has ended up being more of a headache than Nvidia first imagined.\n\n\n\nWe humble consumer GPU enthusiasts are usually mostly interested in gaming performance and pricing, which I'd say makes us easier customers to deal with. Still, swimming in deep waters attracts big fish, and it seems like Nvidia might still have some paddling to do before reeling in its multi-billion-dollar prize.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/software/ai/nvidias-cfo-says-theres-still-a-little-geopolitical-situation-that-we-need-to-work-through-before-shipping-its-ai-gpus-to-china-but-its-a-usd2-billion-to-usd5-billion-potential-opportunity/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia-Backed Nebius Stock Soars 50% on AI Infrastructure Deal With Microsoft",
      "content": "Key Takeaways Nebius Group inked a deal with Microsoft worth up to $19.4 billion to provide artificial intelligence infrastructure for the software giant's new data center in New Jersey.\n\nMicrosoft agreed to pay Nebius $17.4 billion over five years, and could add another $2 billion for additional services or capacity.\n\nNebius said this was the first of what it expects to be similar contracts with big AI labs and tech firms.\n\nShares of Nebius Group (NBIS) soared 50% in early trading Tuesday after the artificial intelligence infrastructure company struck a deal with Microsoft (MSFT) that could be valued as much as $19.4 billion.\n\nMicrosoft agreed to pay the Nvidia-backed (NVDA) firm, which completed its split from Russian internet giant Yandex last year, $17.4 billion over five years to provide artificial intelligence infrastructure for a new data center in New Jersey.\n\nMicrosoft “may also acquire additional services and/or capacity” for another $2 billion under the agreement.\n\nFounder and CEO Arkady Volozh said this was the first of what Nebius expects will be “significant long-term committed contracts with leading AI labs and big tech companies.”\n\nWith Tuesday's surge, Nebius shares have more than tripled in value since the start of the year. Microsoft shares were up less than 1% in recent trading and have added close to 20% year-to-date.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/nvidia-backed-nebius-stock-soars-50-percent-on-ai-infrastructure-deal-with-microsoft-11806153",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD's FSR 4 upscaling tech gives even more PC games a free image quality upgrade – but you still need a modern GPU",
      "content": "AMD's FSR 4 is now available in most FSR 3.1 and DX12 supported games\n\nThe new Adrenalin Software driver allows users to override FSR 3.1 with FSR 4\n\nIt only works in games that have a signed FSR 3.1 DLL\n\nWhile AMD fans await an eventual FSR 4 backport to older non-RDNA 4 graphics cards alongside updates to the upscaling technology that's exclusive to some of the best GPUs on the market, Team Red has at least made life easier for developers and gamers.\n\nAs reported by VideoCardz, AMD's latest driver 25.9.1 adds further FSR 4 support for most FSR 3.1 and DX12-supported games, which AMD says is now 'over 85 games'. RDNA 4 GPU owners simply need to enable FSR 4 on the AMD Adrenalin Software and toggle on FSR 3.1 in a supported game, allowing the driver to override FSR 3.1 with FSR 4.\n\nIt's worth noting that this is only possible in games that have a signed FSR 3.1 DLL, which means the override won't work via third-party integration. While FSR 4 still hasn't been backported to RDNA 3 and older GPUs, FSR 4's driver override should make things much easier if a backport does happen soon.\n\nTeam Red's recent FSR 4 open-source slip-up revealed that it was (and potentially still is) working on an FSR 4 backport to RDNA 3. And with the FSR 'Redstone' presentation set to reveal frame generation and image quality improvements, it may not be far-fetched to suggest that AMD may have another surprise announcement in store.\n\nAMD's fierce rival, Nvidia, has DLSS 4 available for all RTX GPUs; not only does it have the advantage of being widely available to more PC gamers, but the image quality is superior to FSR 4's, and there's nothing better than AMD's Redstone shortening the gap to Team Green's offering, while also allowing all (or at least most) Radeon GPU users to benefit from sharper images in games.\n\nAnalysis: FSR 4 on RDNA 3 and older GPUs should be AMD's number one priority\n\n(Image credit: AMD)\n\nWithout a doubt, Nvidia is still leading the GPU market. That's unsurprising, especially since the RTX 5000 series GPUs are gradually plummeting back to their launch prices – and Team Green is rumored to be launching Super series GPUs this fall.\n\nWith this in mind, it's time for AMD to at least provide its latest upscaling tech to RDNA 3 GPUs before Nvidia bridges the gap further.\n\nGet daily insight, inspiration and deals in your inbox Sign up for breaking news, reviews, opinion, top tech deals, and more. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAgain, Nvidia already has DLSS 4 available on all RTX GPUs, except for Multi Frame Generation (exclusive to RTX 5000 series) and Frame Generation (starting from RTX 4000 series). DLSS 4 has shown how vital it is for upscaling tech to have sharper super-resolution image quality, and it shines bright even in DLSS performance, which benefits PC gamers with low-end hardware.\n\nTeam Red's FSR 4 has a similar effect with better image quality across its upscaling modes, and while it certainly doesn't match up to DLSS 4, it beats both FSR 3 and DLSS 3. As a handheld PC gamer, FSR 4 would do wonders at providing better performance via aggressive upscaling, without too much of a heavy sacrifice on image quality, like FSR 3 has.\n\nIt's the ideal time for AMD to get this going, as it would add to the firepower it needs to fully compete with its GPU rival.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/computing/gpu/amds-fsr-4-upscaling-tech-gives-even-more-pc-games-a-free-image-quality-upgrade-but-you-still-need-a-modern-gpu",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Jim Cramer Discusses Whether Broadcom Inc. (AVGO)’s $10 Billion Mystery Customer Is OpenAI",
      "content": "We recently published 10 Stocks Jim Cramer Discussed As He Dismissed A Recession. Broadcom Inc. (NASDAQ:AVGO) is one of the stocks Jim Cramer recently discussed.\n\nJoao Virissimo/Shutterstock.com\n\nBroadcom Inc. (NASDAQ:AVGO) stunned the stock market and the AI sector when it revealed that it had landed a $10 billion deal for custom AI chips. The announcement, paired with a strong earnings report, sent the stock 13.7% higher. Cramer discussed the potential of OpenAI moving away from NVIDIA to Broadcom:\n\n“[On stock higher on reports that the $10 billion mystery customer is OpenAI] Yeah look I, I don’t want to be contrarian about too many things. . .but I would say the reason I even knew about OpenAI was that Jensen Huang, CEO NVIDIA, told me that really that they were the first company to really understand what Jensen had. And their partnership dates back the longest of any one of these hyperscalers. So I know I read this stuff and it says okay well this is a threat, an existential threat to NVIDIA and NVIDIA stock is down and then I read Ben Reitzes, who’s been the most right about this, particularly with Hock, with the CEO of Broadcom, he says no time to debate about, there’s so much business, there is a huge amount of business.\n\nWhile we acknowledge the potential of AVGO as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/jim-cramer-discusses-whether-broadcom-133530898.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AT&T Stock Rebounds After EchoStar and SpaceX Deal. Why the Shares Can Jump 10%",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/0c3af72450f4b369",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Quantum Pact: NVIDIA, Honeywell Raise Stakes for IonQ, Rigetti, D-Wave",
      "content": "NVIDIA’s NVDA latest move into quantum computing through a landmark investment in Honeywell HON-backed Quantinuum has jolted the sector, instantly lifting its profile among investors. Following the Sept. 4 announcement, the Defiance Quantum ETF (QTUM) rallied 2.3% as of yesterday.\n\nZacks Investment Research\n\n\n\nImage Source: Zacks Investment Research\n\nFor public pure-plays like IonQ IONQ, Rigetti Computing RGTI and D-Wave Quantum QBTS, this development brings both opportunity and pressure. On the one hand, it sparks renewed investor attention and potential capital flows into the space. On the other hand, it raises the bar for technological execution and commercial traction. Let’s delve deeper.\n\nNVIDIA, Honeywell Pact: Funding Surge Accelerates Fault-Tolerant Quantum Push\n\nOn Sept. 4, 2025, Honeywell announced that its quantum computing arm, Quantinuum, completed an approximately $600 million equity capital raise at a $10 billion pre-money valuation. Key new investors include Quanta Computer, NVentures (NVIDIA’s venture capital arm) and QED Investors, alongside follow-on investments from existing backers such as JPMorgan Chase, Mitsui, Amgen, Cambridge Quantum Holdings, Serendipity Capital and Honeywell itself.\n\nThe new funding will help Quantinuum speed up its work in quantum computing, including the launch of its next-generation system, Helios, expected later this year. The company is also working toward building universal, fault-tolerant quantum systems. In addition, Quantinuum has strengthened its role as a founding partner in NVIDIA’s Accelerated Quantum Research Center and is expanding global partnerships in places such as New Mexico, Qatar and Singapore.\n\nNVIDIA's $600 Million Bet Sparks Momentum or Pressure for Pure Plays?\n\nStock Comparison Since NVDA-HON Deal\n\nZacks Investment Research\n\n\n\nImage Source: Zacks Investment Research\n\nIonQ: It recently announced a major strategic milestone through the acquisition of U.K. quantum startup Oxford Ionics in a deal valued at approximately $1.075 billion. This move bolsters IonQ’s trapped-ion technology roadmap by integrating chip-scale ion-trap expertise. NVIDIA’s backing of Quantinuum, also a trapped-ion player, intensifies the race, raising competitive pressure. For IonQ, this could attract more investor attention but also forces the company to deliver commercial results at a pace that keeps it in step with this well-funded rival.\n\nIONQ, a Zacks Rank #3 (Hold) stock, dipped 2.6% since the April 4 announcement. However, full-year 2025 earnings are projected to grow 37.8% on 115.1% revenue growth over 2024.\n\nIonQ, Inc. Price and Consensus\n\nIonQ, Inc. Price and Consensus\n\nIonQ, Inc. price-consensus-chart | IonQ, Inc. Quote",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/quantum-pact-nvidia-honeywell-raise-190000357.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Brighten winter with indoor blooms by forcing spring bulbs to flower early",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/4a856886acc3819e",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Eightco Chair Dan Ives Calls Sam Altman's World Project The 'Intersection Of AI And Crypto,' Compares It To Nvidia, Palantir",
      "content": "Benzinga and Yahoo Finance LLC may earn commission or revenue on some items through the links below.\n\nWall Street tech analyst Dan Ives expressed on Monday his excitement and vision for his new role as chairman of Eightco Holdings Inc. (NASDAQ:OCTO), a firm that has adopted World (WLD) as its primary reserve asset.\n\n‘Intersection’ Of AI And Crypto\n\nDuring an interview with CNBC, Ives, a senior research analyst at Wedbush Securities, said he was “excited” to take over the role, given his “passion” for AI and the potential of the decentralized identity verification project.\n\n“When you think about these Orb devices, the iris scanning, in my opinion, is going to be the de facto standard when we think about separating from bots, identifying humans. And ultimately, this is really more of an infrastructure play. It’s really the intersection of AI and crypto,” Ives said.\n\n\n\n\n\nTrending: Your Last Chance to Invest in Pacaso Before Their Global Expansion — Offer Ends Sept 18\n\nIves Compares World To Nvidia, Palantir\n\nHe argued that despite the trillions being poured into large language models and data centers, the future of AI will be determined by authentication and identification.\n\nIves compared the current state of the project to where Nvidia Corp. (NASDAQ:NVDA) and Palantir Technologies Inc. (NASDAQ:PLTR) were in 2022, suggesting a similar trajectory of growth and influence.\n\nEightCo raised $250 million through a private placement to adopt WLD as its primary treasury reserve asset.\n\nTom Lee-led Bitmine Immersion Technologies Inc. (AMEX:BMNR) also disclosed a $20 million investment into the company as the first \"Moonshot\" initiative in its Ethereum (CRYPTO: ETH) ecosystem expansion plan.\n\nSee Also: If there was a new fund backed by Jeff Bezos offering a 7-9% target yield with monthly dividends would you invest in it?\n\nWorld’s Privacy Concerns\n\nWorld, formerly Worldcoin, co-founded by OpenAI CEO Sam Altman, is an identity verification project that captures people’s irises to confirm their humanness and build a digital ID, allowing them to receive free WLD tokens. However, it has courted controversy over personal data privacy concerns and is currently outlawed in Hong Kong, Kenya, and Spain. The project debuted in the U.S. earlier this year.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/eightco-chair-dan-ives-calls-180012236.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "This Blender tool can transform 3D models into pencil sketches",
      "content": "We're big fans of Blender. The free, open-source program has a place in our guides to the best 3D modelling software and the best animation software. And it turns out that it can be given another interesting use: creating sketches that look like they were drawn by hand.\n\nOne of the great things about Blender is the huge range of third-party plugins constantly emerging. CGMatter has already made a whole bunch of addons, and one of his latest is the hand-drawn sketch emulator Pencil Pro (also see our roundup of Blender tutorials).\n\nPencil Pro Tutorial - YouTube Watch On\n\nPencil Pro is a Blender addon that can be used to imitate the look of hand-drawn sketches. It works on any kind of mesh, and it's more detailed than converters that rely on materials because it actually simulates how someone would draw.\n\nIt deals with the placement, direction and pressure of strokes and decides if cross-hatching and shading would work for every frame on the fly. No UVs are needed and it can work with any lighting.\n\nAs creator CGMatter notes, believable drawings come from a combination of shading and general pencil strokes, and Pencil Pro accounts for both. It uses screen coordinates rather than grunge on a 3D mesh, so you never run out of shading detail, and it looks at edge flow to approximate how pencil strokes usually follow the curvature of an object.\n\nIn the video below, CGMatter puts the tool to use to create the content to make a flipbook in Blender.\n\nAnimating a Flipbook for an Animation?? // Blender Tutorial - YouTube Watch On\n\nYou can get the Pencil Pro plugin from Superhive for $15. It also comes bundled in the Genie pack.\n\nGet the Creative Bloq Newsletter Daily design news, reviews, how-tos and more, as picked by the editors. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFor more Blender news, see OK Go's animated video and Blender's Nvidia DLSS upscaling. You might also like a Blender plugin that delivers instant '90s video game graphics.",
      "source": "Creative Bloq",
      "url": "https://www.creativebloq.com/3d/this-blender-tool-can-transform-3d-models-into-pencil-sketches",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nebius-Microsoft $17.4B Deal Lifts AI Mining Stocks in Pre-Market Trading",
      "content": "Nebius Group (NBIS) shares soared 47% in pre-market trading after the company said it signed an agreement to supply Microsoft (MSFT) with graphic processing units (GPUs) in a deal Reuters valued at $17.4 billion over five years.\n\nThe contract is worth more than the Amsterdam-based company's entire market capitalization, currently $15.29 billion. According to Reuters, Microsoft may increase the contract value to $19.4 billion by acquiring additional services capacity.\n\nSTORY CONTINUES BELOW Don't miss another story. Subscribe to the Crypto Daybook Americas Newsletter today . See all newsletters Sign me up By signing up, you will receive emails about CoinDesk products and you agree to our terms of use and privacy policy .\n\nShares of other companies involved in artificial intelligence (AI) computing, also advanced. Cipher Mining (CIFR) and IREN (IREN) both climbed 9% on speculation of further AI infrastructure partnerships, echoing similar moves seen earlier this year with CoreWeave (CRWV) and TerraWulf (WULF).\n\nNebius provides Nvidia-powered GPUs, cloud services and AI developer tools built on its proprietary hardware and software.\n\n",
      "source": "CoinDesk",
      "url": "https://www.coindesk.com/markets/2025/09/09/nebius-microsoft-usd17-4b-deal-lifts-ai-mining-stocks-in-pre-market-trading",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The UAE Showcases Its Abilities In AI Reasoning With K2 Think Model",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/patrickmoorhead/2025/09/09/the-uae-showcases-its-abilities-in-ai-reasoning-with-k2-think-model/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia debuts Rubin CPX GPU for massive AI applications",
      "content": "Nvidia (NVDA) on Tuesday unveiled its new Rubin CPX GPU at the AI Infra Summit in Santa Clara, Calif.\n\nAccording to Nvidia, Rubin CPX is “purpose-built to handle million-token coding and generative video applications.”\n\nTokens are a unit of data in AI and can represent everything from words to pieces of video and audio. Every time you use a service like ChatGPT, Claude, Gemini, or Grok they break down your questions and requests into tokens to serve up an answer.\n\nThe Rubin CPX will work with the company’s Vera CPU and Rubin GPU as part of Nvidia’s Vera Rubin NVL 144 CPX platform. NVL 144 means that the system has 144 GPUs.\n\n“The Vera Rubin platform will mark another leap in the frontier of AI computing—introducing both the next-generation Rubin GPU and a new category of processors called CPX,” Nvidia CEO Jensen Huang said in a statement.\n\n“Just as RTX revolutionized graphics and physical AI, Rubin CPX is the first CUDA GPU purpose-built for massive-context AI, where models reason across millions of tokens of knowledge at once.”\n\nAccording to Nvidia, the Vera Rubin NVL 144 CPX will offer 7.5x more AI performance than the company’s Grace Blackwell based BG300 NVL 72 system. That, the company says, will also help customers monetize their AI platforms with Nvidia estimating they could see $5 billion in token revenue for every $100 million invested.\n\nAn image of Nvidia's Vera Rubin chip. (Image: Nvidia) · Nvidia\n\nThe Rubin CPX will be available at the end of 2026.\n\nShares of Nvidia are up 25% year-to-date and 63% over the last 12 months. The company reported better than anticipated earnings per share and revenue in Q2, but missed slightly on Data Center segment revenue.\n\nNvidia’s largest customers are cloud service providers, which make up roughly 50% of the company’s sales.\n\nThe chip giant is also working its way through resuming shipments of its H20 GPU to customers in China. President Trump initially banned the sale of the processor in April, but reversed course in July. He later announced that the US government would take a 15% cut of chip sales to the region.\n\nDuring a conversation with Yahoo Finance following the company’s earnings call, Huang said production of Nvidia’s next-generation Blackwell chips is “ramping at full speed, and demand is extraordinary.”\n\nTrump, however, is also considering a 100% tariff on semiconductors, though he said that companies that build in the US will be exempt from the duty. While Nvidia doesn’t build chips on its own, it contracts with companies like TSMC (TSM), which is building new plants in the US.\n\nSign up for Yahoo Finance's Week in Tech newsletter. · yahoofinance\n\nEmail Daniel Howley at dhowley@yahoofinance.com. Follow him on X/Twitter at @DanielHowley.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-debuts-rubin-cpx-gpu-for-massive-ai-applications-150047032.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "CoreWeave Stock Rises on News of Nvidia-Backed Firm's VC Fund for AI Investments",
      "content": "Key Takeaways CoreWeave has launched a venture initiative designed to support founders of new artificial intelligence efforts.\n\nThe artificial intelligence cloud computing firm's CoreWeave Ventures will offer direct investment capital and other assistance designed to bring new ideas to market faster.\n\nCoreWeave shares hit the market just five months ago, and shares have more than doubled since then.\n\nCoreWeave (CRWV) shares gained 4% in morning trading after the artificial intelligence (AI) cloud computing platform announced plans to support new AI efforts.\n\nThe Nvidia-backed company said it was starting CoreWeave Ventures to provide “investment resources, technical expertise, and compute” to help AI founders bring new ideas to the market more quickly.\n\nThe assistance will range “from direct capital investment and compute-for-equity transactions to technical collaboration and go-to-market opportunities.”\n\nCo-founder and Chief Development Officer Brannin McBee explained CoreWeave Ventures is designed “to give other audacious, like-minded founders the support they need to drive technical advancements and bring to market the next class of innovation.”\n\nThe company noted that CoreWeave Ventures \"is already working with a diverse group of innovators, from foundational model developers building novel large language models to pioneers in vertical AI applications and infrastructure.\"\n\nShares of CoreWeave, which only began publicly trading in March, are up about 150% since then.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/coreweave-stock-rises-on-news-of-nvidia-backed-firms-vc-fund-for-ai-investments-11806230",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel reshuffle puts engineering and 'a new custom silicon business' in the spotlight but also ends a 30-year career at Intel for Product CEO Michelle Johnston Holthaus",
      "content": "Things are, once again, all shake-up at Intel. After a new CEO, tons of layoffs, an increased focus on the Foundry side of the business, and other changes, Intel is sticking on-brand and making even more changes, this time to executive leadership. And while the biggest news for many might be that Intel Products CEO Michelle Johnston Holthaus is leaving, what's particularly interesting is the company is starting a new group that will focus on a new custom silicon business.\n\nIn addition to these two things, Intel also announced that Jim Johnson will lead the Client Computing Group (CCG), Kevork Kechichian from Arm will join to lead Intel's Data Center Group (DCG), and Intel Foundry CTOO Naga Chandrasekaran will also cover Foundry Services.\n\nThe custom silicon business that's perhaps of most interest is to be headed up by senior VP and Fellow Srini Iyengar. Iyengar joined Intel earlier in the year after being a Fellow at Cadence Design Systems, which is of note because Intel CEO Lip-Bu Tan was previously CEO of Cadence until 2021.\n\nThe new group will apparently be looking towards serving external customers: \"Intel is also establishing a new Central Engineering Group led by Srinivasan (Srini) Iyengar, a senior vice president and Fellow. In his expanded role, Iyengar will lead horizontal engineering functions and build a new custom silicon business to serve a broad range of external customers.\"\n\nIf it pans it, this could certainly be a good move for Intel. Hearing the words \"custom silicon\" for \"external customers\" in 2025 triggers obvious thoughts of AI, as well as chasing down TSMC's foundry dollar. Data centres are increasingly gobbling up AI workloads and thus far Nvidia has been the company to reap the bulk of the rewards from that.\n\nIntel CEO Lip-Bu Tan conducting a keynote address. (Image credit: Intel)\n\nFrom his very first earnings call, Tan made it clear that Intel is going to look to cement itself in the AI market, although there's been no definite word over what exactly that means. Now, there's some reason to suppose that will mean custom AI silicon for data centers. Intel Foundry could certainly do with something of the sort to stake a bold new claim to after the past few years and especially months of troubled waters. But it really needs customers onboard.\n\nNo doubt extra incentive to push into Intel Foundry comes from the recent 10% buy-in from the US government, which is under the stipulation that Intel must own at least 51% of its Foundry for five years. In other words, there can be no back-up plan to scarper and sell.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAs far as we're concerned as PC gamers, it could be good news, too. Emphasis on \"could\" there, but a push into AI accelerators, for instance, would presumably give Intel a lot of R&D as well as actual GPU silicon to trickle down into its gaming division. Just like Nvidia with Blackwell and the RTX 50-series. Though I suppose that analogy should show us such a development might not necessarily spell any improvements for GPU prices. At any rate, changes are afoot.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/graphics-cards/intel-reshuffle-puts-engineering-and-a-new-custom-silicon-business-in-the-spotlight-but-also-ends-a-30-year-career-at-intel-for-product-ceo-michelle-johnston-holthaus/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "New Intel executive reshuffle sees products chief Holthaus leave after 30 years",
      "content": "Intel’s Michelle Johnston Holthaus leaves the company after 30+ years\n\nFurther leadership roles appointed, including a new hire\n\nCEO Lip-Bu Tan wants to flatten company leadership\n\nSenior Intel exec Michelle Johnston Holthaus will be departing the company after more than three decades, including a short stint as interim co-CEO with David Zinsner after ex-CEO Pat Gelsinger’s departure.\n\nHolthaus’ most recent role as Chief Exec of Products comes to a close after 10 months, and the company will not be rehiring for this role.\n\nAcknowledging Holthaus’ transformational impacts, new CEO Lip-Bu Tan noted: “She has made a lasting impact on our company and inspired so many of us with her leadership.”\n\nIntel announces major leadership shakeups\n\nThe company also announced the appointment of Kevork Kechichian as EVP & GM of Data Center Group, bringing more than 30 years’ chip industry experience from Arm, NXP Semiconductor, Qualcomm and more.\n\nJim Johnson becomes SVP & GM of Client Computing Group after around four decades at Intel, Srinivasan Iyengar becomes the head of a new Central Engineering Group, and Naga Chandrasekaran steps up at EVP & CTO of Intel Foundry to oversee development, manufacturing and go-to-market.\n\nThe changes come amid Intel’s ongoing efforts to flatten its hierarchical structure, resulting in more leaders reporting directly to Tan. By streamlining operations, cutting jobs and rebuilding its engineering culture, Tan hopes Intel can reposition itself to succeed going forward.\n\nThe news comes a couple of weeks after Intel reached an agreement with President Trump, whereby the US Government would invest $8.9 billion in Intel to help strengthen its position and bolster domestic American manufacturing.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nA move that has drawn its fair share of public scrutiny, including remarks made by Intel itself about the potential implications of having such political backing.\n\nIntel shares are up 21% this year to date, but the company’s market cap ($113.87 billion) falls far behind that of Nvidia ($4.097 trillion), now ranked as the world’s most valuable company.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/new-intel-executive-reshuffle-sees-products-chief-holthaus-leave-after-30-years",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Samsung to double GDDR7 output following Nvidia B40 order",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250908PD233/nvidia-samsung-production-market-accelerator.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "(PR) NVIDIA Blackwell Ultra Sets the Bar in New MLPerf Inference Benchmark",
      "content": "Inference performance is critical, as it directly influences the economics of an AI factory. The higher the throughput of AI factory infrastructure, the more tokens it can produce at a high speed - increasing revenue, driving down total cost of ownership (TCO) and enhancing the system's overall productivity. Less than half a year since its debut at NVIDIA GTC, the NVIDIA GB300 NVL72 rack-scale system - powered by the NVIDIA Blackwell Ultra architecture - set records on the new reasoning inference benchmark in MLPerf Inference v5.1, delivering up to 1.4x more DeepSeek-R1 inference throughput compared with NVIDIA Blackwell-based GB200 NVL72 systems.Blackwell Ultra builds on the success of the Blackwell architecture, with the Blackwell Ultra architecture featuring 1.5x more NVFP4 AI compute and 2x more attention-layer acceleration than Blackwell, as well as up to 288 GB of HBM3e memory per GPU. The NVIDIA platform also set performance records on all new data center benchmarks added to the MLPerf Inference v5.1 suite - including DeepSeek-R1, Llama 3.1 405B Interactive, Llama 3.1 8B and Whisper - while continuing to hold per-GPU records on every MLPerf data center benchmark.Full-stack co-design plays an important role in delivering these latest benchmark results. Blackwell and Blackwell Ultra incorporate hardware acceleration for the NVFP4 data format - an NVIDIA-designed 4-bit floating point format that provides better accuracy compared with other FP4 formats, as well as comparable accuracy to higher-precision formats.NVIDIA TensorRT Model Optimizer software quantized DeepSeek-R1, Llama 3.1 405B, Llama 2 70B and Llama 3.1 8B to NVFP4. In concert with the open-source NVIDIA TensorRT-LLM library, this optimization enabled Blackwell and Blackwell Ultra to deliver higher performance while meeting strict accuracy requirements in submissions.Large language model inference consists of two workloads with distinct execution characteristics: 1) context for processing user input to produce the first output token and 2) generation to produce all subsequent output tokens.A technique called disaggregated serving splits context and generation tasks so each part can be optimized independently for best overall throughput. This technique was key to record-setting performance on the Llama 3.1 405B Interactive benchmark, helping to deliver a nearly 50% increase in performance per GPU with GB200 NVL72 systems compared with each Blackwell GPU in an NVIDIA DGX B200 server running the benchmark with traditional serving.NVIDIA also made its first submissions this round using the NVIDIA Dynamo inference framework.NVIDIA partners - including cloud service providers and server makers - submitted great results using the NVIDIA Blackwell and/or Hopper platform. These partners include Azure, Broadcom, Cisco, CoreWeave, Dell Technologies, Giga Computing, HPE, Lambda, Lenovo, Nebius, Oracle, Quanta Cloud Technology, Supermicro and the University of Florida.The market-leading inference performance on the NVIDIA AI platform is available from major cloud providers and server makers. This translates to lower TCO and enhanced return on investment for organizations deploying sophisticated AI applications.Learn more about these full-stack technologies by reading the NVIDIA Technical Blog on MLPerf Inference v5.1. Plus, visit the NVIDIA DGX Cloud Performance Explorer to learn more about NVIDIA performance, model TCO and generate custom reports.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340827/nvidia-blackwell-ultra-sets-the-bar-in-new-mlperf-inference-benchmark",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Was Jim Cramer Right About NVIDIA (NVDA)?",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_2d0cb57e-7f83-446e-b643-b14fc4304262",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "S&P 500’s Big Risk This 9/11",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/09/sp-500s-big-risk-this-911/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Watch The PC Gamer Streamer Showdown live today on Twitch",
      "content": "Are you ready?\n\nThe PC Gamer Streamer Showdown kicks off today, a three-day triathalon of gaming competition between eight talented streamers. Watch live on twitch.tv/pcgamer beginning at 12 noon ET / 9 AM PT / 5 PM BST or on the streams of any of our eight competitors.\n\nWins in these three games aren't the only thing that our streamers are fighting for, they're also vying for \"Cool Points\" that add to their overall tournament performance, earned by completing special challenges within matches like registering a perfect round in Street Fighter 6 or finding the Bugle of Friendship in Peak. For more details read here.\n\nHere's a breakdown of the match schedule for September 9, 10, and 12.\n\nThe weeklong schedule of competition. (Image credit: PC Gamer)\n\nThe lineup of competitors is a talented set of variety streamers:\n\nBarefootTasha twitch.tv/barefoottasha\n\nKingGothalion twitch.tv/kinggothalion\n\nAplFisher twitch.tv/aplfisher\n\nRIPMika twitch.tv/ripmika\n\nAsh IV twitch.tv/ashiv_\n\nElainaExe twitch.tv/elainaexe\n\nDish twitch.tv/dish\n\nunCAGEDgamez twitch.tv/uncagedgamez\n\nOur brave contestants. (Image credit: Future)\n\nThe PC Gamer Streamer Showdown is powered by OMEN. Watch all week long for a chance to win an OMEN Max 16 laptop, valued at more than $3000! On the final day of the tournament, a viewer of the winning streamer will be randomly selected to win.\n\nLaptop specs and features include:\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n(Image credit: OMEN)",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/games/pc-gamer-streamer-showdown/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Eightco Chair Dan Ives Calls Sam Altman's World Project The 'Intersection Of AI And Crypto,' Compares It To Nvidia, Palantir",
      "content": "Wall Street tech analyst Dan Ives expressed on Monday his excitement and vision for his new role as chairman of Eightco Holdings Inc. (NASDAQ:OCTO), a firm that has adopted World (WLD) as its primary reserve asset.\n\n‘Intersection’ Of AI And Crypto\n\nDuring an interview with CNBC, Ives, a senior research analyst at Wedbush Securities, said he was “excited” to take over the role, given his “passion” for AI and the potential of the decentralized identity verification project.\n\n“When you think about these Orb devices, the iris scanning, in my opinion, is going to be the de facto standard when we think about separating from bots, identifying humans. And ultimately, this is really more of an infrastructure play. It’s really the intersection of AI and crypto,” Ives said.\n\nSee Also: Warren Paul Anderson: Token Buy-And-Burn Mechanisms Could Damp Volatility Spillovers Into Bitcoin, Ethereum – Benzinga\n\nIves Compares World To Nvidia, Palantir\n\nHe argued that despite the trillions being poured into large language models and data centers, the future of AI will be determined by authentication and identification.\n\nIves compared the current state of the project to where Nvidia Corp. (NASDAQ:NVDA) and Palantir Technologies Inc. (NASDAQ:PLTR) were in 2022, suggesting a similar trajectory of growth and influence.\n\nEightCo raised $250 million through a private placement to adopt WLD as its primary treasury reserve asset.\n\nTom Lee-led Bitmine Immersion Technologies Inc. (AMEX:BMNR) also disclosed a $20 million investment into the company as the first \"Moonshot\" initiative in its Ethereum (CRYPTO: ETH) ecosystem expansion plan.\n\nWorld’s Privacy Concerns\n\nWorld, formerly Worldcoin, co-founded by OpenAI CEO Sam Altman, is an identity verification project that captures people’s irises to confirm their humanness and build a digital ID, allowing them to receive free WLD tokens. However, it has courted controversy over personal data privacy concerns and is currently outlawed in Hong Kong, Kenya, and Spain. The project debuted in the U.S. earlier this year.\n\nTo address the privacy concerns, World implemented a personal custody feature that ensures users' data remains on their devices and not with World or any third party.\n\nPrice Action: At the time of writing, WLD was exchanging hands at $1.68, up 45% in the last 24 hours, according to data from Benzinga Pro. Shares of Eightco fell 5.94% in after-hours trading after exploding 3008.97% to $45.08 during the regular trading session.\n\nAs of this writing, the stock demonstrated a moderately high Momentum score. Visit Benzinga Edge Stock Rankings to compare it with how BitMine, the world’s biggest ETH treasury company.\n\n\n\nLoading... Loading...\n\nRead Next:\n\nPhoto Courtesy: CryptoFX on Shutterstock.com\n\nDisclaimer: This content was partially produced with the help of Benzinga Neuro and was reviewed and published by Benzinga editors.",
      "source": "Benzinga",
      "url": "https://www.benzinga.com/crypto/cryptocurrency/25/09/47562367/eightco-chair-dan-ives-calls-sam-altmans-world-project-the-intersection-of-ai-and-crypto-compares-it-to-nvidia-palantir",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "CoreWeave Shares Gain 4.5% After Launch of VC Arm Targeting AI Startups",
      "content": "Shares of CoreWeave (CRWV) rose as much as 9% on Monday morning after the company announced it’s launching a venture capital arm focused on early-stage artificial intelligence startups.\n\nThe stock was higher by 4.5% as midday U.S. hours approached..\n\nSTORY CONTINUES BELOW Don't miss another story. Subscribe to the Crypto Daybook Americas Newsletter today . See all newsletters Sign me up By signing up, you will receive emails about CoinDesk products and you agree to our terms of use and privacy policy .\n\nThe new fund, called CoreWeave Ventures, will focus on investing in startups building tools, infrastructure or applications for AI. The company didn’t disclose how much capital would be committed but framed the effort as an extension of its broader mission to support high-performance computing for machine learning and generative AI.\n\n“Our aim with CoreWeave Ventures is to give other audacious, like-minded founders the support they need to drive technical advancements and bring to market the next class of innovation,” said Brannin McBee, co-founder and chief development officer at CoreWeave.\n\nCoreWeave specializes in cloud computing optimized for AI workloads, offering access to Nvidia GPUs and fast storage to clients ranging from large enterprises to research labs. It went public earlier this year at $40 per share and surged to a high of $187 in June before pulling back.\n\nThe launch of CoreWeave Ventures comes during a busy period for cloud infrastructure firms focused on AI. On Monday, Nebius, another player in the “neocloud” space, signed a five-year, $19.4 billion agreement with Microsoft to supply computing power. That announcement sent several AI and data center stocks higher, adding momentum to the sector.\n\nCoreWeave is also in the process of acquiring bitcoin miner Core Scientific (CORZ) in a $9 billion all-stock deal. The merger, announced in July, is still subject to shareholder and regulatory approvals.\n\nFor AI startups, the arrival of another specialized investor could offer an alternative to generalist VC firms or hyperscaler-linked capital. And for CoreWeave, it’s a chance to bet on the ecosystem it helps power — and maybe get early access to the next breakthrough.\n\n\n\n\n\n",
      "source": "CoinDesk",
      "url": "https://www.coindesk.com/markets/2025/09/09/coreweave-shares-rise-after-launch-of-vc-arm-targeting-ai-startups",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Synopsys reports quarterly revenue below estimates, shares fall",
      "content": "(Reuters) -Chip design software provider Synopsys (SNPS) missed Wall Street estimates for third-quarter revenue on Tuesday, hurt by weakness in its Design IP business, sending shares down 20% in premarket trading on Wednesday.\n\nThe segment includes Synopsys' interface, security and embedded processor intellectual property, along with IP implementation services.\n\nThe underperformance in the segment was caused by deals that did not materialize, largely due to new export restrictions disrupting design starts in China and challenges at a major foundry customer, CEO Sassine Ghazi said on a post-earnings call.\n\nIn early July, the United States lifted restrictions on exports to China for chip design software developers, which had been imposed in late May.\n\nSynopsys had made significant investments in building out IP for the foundry customer, with expectations for returns in the second half of 2025, Ghazi said on the call. However, the customer pulled out due to market and client-related reasons.\n\nSynopsys, which counts companies such as Nvidia, Intel and Qualcomm among its partners, provides software and hardware used to design advanced processors.\n\nSunnyvale, California-based Synopsys completed its $35 billion cash-and-stock acquisition of engineering design firm Ansys in July, after receiving conditional approval from China's market regulator. The deal, announced early last year, faced intense antitrust scrutiny in markets including Britain.\n\nThe company reported revenue of $1.74 billion for the third quarter ended July 31, missing analysts' estimates of $1.77 billion, according to data compiled by LSEG.\n\nOn an adjusted basis, Synopsys reported a profit of $3.39 per share, also below estimates of $3.74 per share.\n\nSynopsys projected current-quarter revenue between $2.23 billion and $2.26 billion, while analysts expect $2.09 billion.\n\nRival Cadence Design Systems raised its annual sales and profit forecast in July.\n\n(Reporting by Juby Babu in Mexico City; Editing by Mohammed Safi Shamsi)",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/synopsys-reports-quarterly-revenue-below-233110633.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia-backed AI stock pulls off jaw-dropping deal",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/technology/this-nvidia-backed-ai-stock-just-pulled-off-a-jaw-dropping-play-",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "NVIDIA Unveils \"Rubin CPX\" GPU: Single-Die, 30 PetaFLOPS, and 128 GB of GDDR7 Memory",
      "content": "During the AI Infra Summit, NVIDIA announced the \"Rubin CPX\" GPU, a specialized accelerator derived from the upcoming \"Rubin\" family, specifically made for massive-context AI models. The chip delivers 30 PetaFLOPS of NVFP4 compute performance on a monolithic die, accompanied by 128 GB of GDDR7 memory. The monolithic die configuration represents a departure from the dual-GPU packages characteristic of NVIDIA's current Blackwell and Blackwell Ultra architectures, as well as the design path that the rest of the Rubin family will follow. The Rubin CPX addresses computational bottlenecks in extended-context scenarios where AI models process millions of tokens simultaneously. This capability proves critical for applications including comprehensive software codebase analysis and hour-long video content processing, which can require up to one million tokens.The processor integrates four NVENC and four NVDEC video encoders directly on-chip, enabling streamlined multimedia workflows without external processing dependencies. Performance metrics suggest that the Rubin CPX is delivering three times the attention processing speed of NVIDIA's current best GB300 Blackwell Ultra accelerator systems. The architecture employs a cost-optimized single-die approach, rather than multi-chip modules, which potentially reduces manufacturing complexity while maintaining computational density. Memory bandwidth specifications remain undisclosed, though a 512-bit interface could yield approximately 1.8 TB/s throughput when using 30 Gbps GDDR7 memory chips. NVIDIA plans integration of Rubin CPX processors within the Vera Rubin NVL144 CPX platform, which combines traditional Rubin GPUs with the specialized CPX variants. This hybrid configuration targets 8 ExaFLOPS of aggregate compute performance, with 1.7 PB/s of memory bandwidth, across a complete rack deployment. The \"Kyber\" rack will include ConnectX-9 network adapters capable of 1600G networking, Spectrum6 doing 102.4T switching, as well as co-packaged optics. NVIDIA plans this to arrive in late 2026, after the regular Rubin GPU launch in early 2026.NVIDIA pushes Rubin CPX as a one-off in the Rubin family to address the complexity of inferencing a test-time scaling AI system. As models evolve beyond simple text generation toward sophisticated reasoning systems, inference operations increasingly split between computationally intensive context processing and memory-bandwidth-dependent token generation phases. The CPX design optimizes for these dual requirements through its dedicated architecture, handling context prefill operations that can span enterprise chatbot sessions with 256,000 tokens or comprehensive code analysis exceeding 100,000 lines. This specialization becomes critical as AI systems transition from basic language models to multistep reasoning agents that maintain persistent memory across extended interactions. Hence, all of that needs to be enabled by hardware, and NVIDIA wants to make it a seamless experience for developers.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340818/nvidia-unveils-rubin-cpx-gpu-single-die-30-petaflops-and-128-gb-of-gddr7-memory",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia unveils AI chips for video, software generation",
      "content": "Nvidia said on Tuesday it would launch a new artificial intelligence chip by the end of next year, designed to handle complex functions such as creating videos and software.\n\nThe chips, dubbed \"Rubin CPX\", will be built on Nvidia's next-generation Rubin architecture — the successor to its latest \"Blackwell\" technology that marked the company's foray into providing larger processing systems.\n\nAs AI systems grow more sophisticated, tackling data-heavy tasks such as \"vibe coding\" or AI-assisted code generation and video generation, the industry's processing needs are intensifying.\n\nAI models can take up to 1 million tokens to process an hour of video content — a challenging feat for traditional GPUs, the company said. Tokens refer to the units of data processed by an AI model.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nTo remedy this, Nvidia will integrate various steps of the drawn-out processing sequence such as video decoding, encoding, and inference — when AI models produce an output — together into its new chip.\n\nInvesting $100 million in these new systems could help generate $5 billion in token revenue, the company said, as Wall Street increasingly focuses on the return from pouring hundreds of billions of dollars into AI hardware.\n\nThe race to develop the most sophisticated AI systems has made Nvidia the world's most valuable company, commanding a dominant share of the AI chip market with its pricey, top-of-the-line processors.",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/business/nvidia-unveils-ai-chips-video-software-generation-5340646",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Takeaways from AP's investigation into how US tech companies enabled China's digital police state",
      "content": "BEIJING (AP) — Across China, tens of thousands of people tagged as troublemakers are trapped in a digital cage, barred from leaving their province and sometimes even their homes by the world’s largest digital surveillance apparatus. Most of this technology came from companies in a country that has long claimed to support freedoms worldwide: the United States.\n\nOver the past quarter century, American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warnings from the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nMost of the companies that responded said they fully complied with all laws, sanctions and U.S. export controls governing business in China, past and present. Here are key findings:\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAmerica brought ‘predicative policing’ to China\n\nU.S. companies introduced systems that mine a vast array of information — texts, calls, payments, flights, video, DNA swabs, mail deliveries, the internet, even water and power use — to unearth individuals deemed suspicious and predict their movements. But this technology also allows Chinese police to threaten friends and family and preemptively detain people for crimes they have not even committed. The AP found a Chinese defense contractor, Huadi, worked with IBM in 2009 to design the main policing system for Beijing to censor the internet and crack down on alleged terrorists, the Falun Gong religious sect, and even villagers deemed troublesome. IBM referred to any possible relationship it may have had with Chinese government agencies as “old, stale interactions”: “ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.” Huadi did not respond.\n\nUS tech enabled the Xinjiang crackdown\n\nAmerican surveillance technologies allowed a brutal mass detention campaign in the far west region of Xinjiang — targeting, tracking and grading virtually the entire native Uyghur population to forcibly assimilate and subdue them. IBM agents in China sold its i2 software to the Xinjiang police, China’s Ministry of State Security, and many other Chinese police units throughout the 2010s, leaked emails show. One agent, Landasoft, subsequently copied and deployed it as the basis for a predictive policing platform that tagged hundreds of thousands of people as potential terrorists. IBM said it has no record of its i2 software ever being sold to the Public Security Bureau in Xinjiang, was not aware of any interaction between Landasoft and that bureau and cut ties with Landasoft in 2014. Landasoft did not respond.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome tech companies even specifically addressed race in their marketing. Dell and a Chinese surveillance firm promoted a “military-grade” AI-powered laptop with “all-race recognition” on its official WeChat account in 2019. And until contacted by AP in August, biotech giant Thermo Fisher Scientific’s website marketed DNA kits to the Chinese police as “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans.” The Xinjiang government said that it uses surveillance technologies to prevent terrorism, and that Western countries also use such technology, calling the U.S. “a true surveillance state.”\n\nCompanies pitched tech to control citizens\n\nThough the companies often claim they aren’t responsible for how their products are used, some directly pitched their tech as tools for Chinese police to control citizens, marketing materials from IBM, Dell, Cisco, and Seagate show. Their sales pitches — made both publicly and privately — cited Communist Party catchphrases on crushing protest, including “stability maintenance,” “key persons,” and “abnormal gatherings,” and named programs that stifle dissent, such as “Internet Police,” “Sharp Eyes” and the “Golden Shield.” IBM, Dell, Cisco and Seagate said they adhere to all relevant laws.\n\nAmerican tech laid the foundation for Chinese surveillance\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAmerican technology laid the foundation for China’s surveillance apparatus that Chinese companies have since built on and in some cases replaced. Intel and Nvidia helped China’s three biggest surveillance companies make their camera systems AI-powered. Contracts to maintain existing IBM, Dell, HP, Cisco, Oracle, and Microsoft software and gear remain ubiquitous, often with third parties. And to this day, concerns remain over where technology sold to China will end up, with former U.S. officials and national security experts criticizing a deal struck this summer for Nvidia to sell chips used in artificial intelligence to China, saying the technology would fall into the hands of the Chinese military and intelligence. Nvidia said in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk, but told the AP those relationships no longer continue. Nvidia said it does not make surveillance systems or software, does not work with police in China and has not designed the H20 chips for police surveillance, and the White House and Department of Commerce did not respond to requests for comment.\n\nBig loopholes in sanctions remain\n\nSome U.S. companies ended contracts in China over rights concerns and after sanctions. IBM said it has prohibited sales to Tibet and Xinjiang police since 2015, and suspended business relations with defense contractor Huadi in 2019. Nvidia and Intel also ended partnerships with China’s top two surveillance companies in 2019. However, sanctions experts noted that the laws have significant loopholes and often lag behind new developments. For example, a ban on military and policing gear to China after the 1989 Tiananmen massacre does not take into account newer technologies or general-use products that can be applied in policing. They also noted that the law around export controls is complicated.\n\nA cautionary tale\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nWhat started in China more than a decade ago could be seen as a cautionary tale for other countries at a time when the use of surveillance technology worldwide is rising sharply, including in the United States. Emboldened by the Trump administration, U.S. tech companies are more powerful than ever, and President Donald Trump has rolled back a Biden-era executive order meant to safeguard civil rights from new surveillance technologies. As the capacity and sophistication of such technologies has grown, so has their reach. Surveillance technologies now include AI systems that help track and detain migrants in the U.S. and identify people to kill in the Israel-Hamas war. China, in the meantime, has used what it learned from the U.S. to turn itself into a surveillance superpower, selling technologies to countries like Iran and Russia.\n\n“Because of this technology … we have no freedom at all,” said Yang Caiying, now in exile in Japan, whose family has been trapped in an increasingly tight noose of surveillance for the past 16 years. “At the moment, it’s us Chinese that are suffering the consequences, but sooner or later, Americans and others, too, will lose their freedoms.”\n\n__\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/takeaways-aps-investigation-us-tech-043117960.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "(PR) NVIDIA RTX Remix Update Introduces Advanced Path-Traced Particle System",
      "content": "Many classic PC games remain beloved for their unforgettable stories, characters, and gameplay. But as technology advances, their visuals struggle to keep up, making it harder for the original gamers who played them, or new generations, to appreciate their magic. NVIDIA RTX Remix, a modding platform for RTX AI PCs, was built to change that. By reimagining the graphics of these timeless classics with cutting-edge path tracing, we're allowing longtime fans to relive their favorite adventures in stunning detail, while introducing a new wave of players to the games that defined an era.Today, we've released a new RTX Remix update through NVIDIA app, adding an advanced particle system that enables modders to enhance traditional fire and smoke effects, as well as more fantastical effects, like those in Portal. Check out our official documentation to see the full release notes.In RTX Remix, legacy particles from a classic game could be interpreted as path-traced, enabling them to cast realistic light, enhancing the appearance of many scenes. But ultimately, these particles were still over 20 years old, lacking detail, flair, and fluid animations.Now, modders can create brand new particles in Remix that match the look of those found in modern titles. This opens the door for over 165 RTX Remix compatible games to have advanced particle effects for the first time, and we can't wait to see all the ways modders dazzle gamers with realistic and spectacular effects.RTX Remix particles are GPU-driven, meaning you can add tens of thousands of them without significantly reducing performance. They are path-traced, meaning they cast accurate shadows, and are reflected in the world-a rarity in games. Additionally, they feature a realistic physics simulation, complete with proper collisions with the environment. All of these elements together give modders a chance to make breathtaking VFX. As an example, we've designated the Antlion Guard from Half-Life 2 RTX as a particle emitter. Over 100,000 shadowed particles are performantly rendered, and as the Antlion Guard moves, the physics of each particle is accurately reflected and affected.In the clip below, you can see how the fire in Half-Life 2 RTX can be elevated to look more natural and realistic through the use of advanced particles, with smoke billowing from the tips, and embers sparking and floating through the air:These effects can be tuned dramatically, giving modders many ways to channel their creativity. For example, here are three vastly different interpretations of the high energy pellet from Portal with RTX:And best of all, RTX Remix lets you add particles into your scene instantly while you play - it's instantaneous and a whole lot of fun.Adding RTX Remix particles is fast and easy. Simply open the Alt+X RTX Remix Developer Menu while in-game, navigate to the Games Setup > Categorize Textures tab, and select any game element, be that a fire effect, character, or malfunctioning light-from there, simply select \"particle emitters\" to see particles spawn. On the \"Rendering tab\", adjust the size of the effect, the number of particles spawned, the color, and other fields to achieve the perfect look - it's as easy as that!For more serious modders, we recommend building your particles in the RTX Remix Toolkit, which offers a lot more control. For a complete breakdown of all the new particle options, check out the release notes, and head over to the RTX Remix developer manual.Since its initial release, the RTX Remix modding community has grown to 237 active projects, with over 100 RTX Remix mods released. They span a catalog of beloved games like Half-Life 2, Need for Speed Underground,Portal 2 and Deus Ex, boasting over 2 million downloads.Recently, we asked the community to make new mods and enhance their existing work in our RTX Remix Mod Contest. The mods created were phenomenal, and ultimately we awarded $60,000 in cash prizes to the developers of Painkiller RTX Remix, Vampire The Masquerade: Bloodlines - RTX Remaster, I-Ninja Remixed, and Call of Duty 2 RTX Remix of Carentan. Head to our contest article to learn more, and to download the mods.As a modder plays through a classic game with RTX Remix, textures, models, lighting, effects, and more can all be captured, and reassembled into an editable scene. Through an intuitive interface, the RTX Remix application lets modders drag and drop lights, recreate every object and material to modern standards, copy-paste existing objects into a scene to increase clutter and grass coverage, convert lights to be fully ray-traced, AI enhance textures, and add DLSS 4 to improve image quality and accelerate performance.To make your own RTX mods, download NVIDIA RTX Remix from the Home screen of NVIDIA app. And grab the Half-Life 2 RTX demo or Portal with RTX from Steam for an example of what's possible with the latest RTX Remix upgrades.NVIDIA RTX Remix requires a GeForce RTX GPU to create RTX Remix Mods, while mods and games built using Remix are compatible with any hardware that can run Vulkan ray-traced games.To find RTX Remix mods to download and play, we recommend ModDB and the RTX Remix Showcase Discord server.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340816/nvidia-rtx-remix-update-introduces-advanced-path-traced-particle-system",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 \"Battlemage\" Nears Launch as Intel Prepares Packaging",
      "content": "Intel plans to complete its Arc \"Battlemage\" lineup with the highest-performing B770 SKU. Thanks to @Haze2K1 on X, we found shipping manifests dated June 11, 2025, which list BMG-G31 GPU dies packed in boxes with dimensions matching those used before the Arc B580 launch. Last time with B580, the launch happened 2.5 months after these shipping manifests appeared. The current rumor mill suggests that the card will utilize 32 Xe2 cores with 16 GB of memory on a 256-bit bus, providing it with a clear capacity edge over many 8 GB rivals from AMD and NVIDIA, like the RTX 5060 Ti and RX 9060. The BMG-G31 die is bigger than the BMG-G21 used in the B580, B570, and Arc Pro parts, which explains the larger crates. Extra silicon could enable higher clocks, stronger ray tracing, and a wider memory interface, though thermal management and power draw will matter. Early samples and firmware checks will set the final timing and availability soon.Timing will determine how much impact the Arc B770 can have, because AMD and NVIDIA already control much of the upper mid-range and high-end segments. NVIDIA \"SUPER\" refreshes of the current \"Blackwell\" only raise the pressure on Intel to be both performance competitive and well priced. Battlemage has already shifted pricing expectations in the market before, compelling rivals to rethink memory configurations and price points. Intel has also shown steady improvement in its driver updates and software support, which has narrowed historical gaps in user experience. Rumors pointing to a Q4 2025 debut would put the card into the usual holiday buying window, but to convert gamer's interest into real market share, Intel will need an aggressive pricing strategy and solid supply.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340802/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "China's first open AI computing architecture: Sugon, Lenovo, Moore Threads comes together to challenge Nvidia CUDA",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250909PD213/cuda-nvidia-launch-lenovo-moore-threads.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Detailed findings from AP investigation into how US tech firms enabled China's digital police state",
      "content": "BEIJING (AP) — American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warningsfrom the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nThe AP investigation was based on tens of thousands of leaked emails and databases from a Chinese surveillance company; thousands of pages of confidential corporate and government documents; public Chinese language marketing material; and thousands of procurements, many provided by ChinaFile, a digital magazine published by the non-profit Asia Society. The AP also drew from dozens of open record requests and interviews with more than 100 current and former Chinese and American engineers, executives, experts, officials, administrators, and police officers.\n\nAmerican tech firms were by far the biggest suppliers, but German, Japanese, and Korean firms also had a role. Here are some examples:\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nMILITARY ACCESS: A Chinese military contractor worked with Armonk, New York-based IBM in 2009 to design national intelligence systems, including a counterterrorism system, according to classified Chinese government documents. These systems were used by China’s secret police, the Ministry of State Security, and the Chinese military. IBM referred to any such deals as “old, stale interactions”: “ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.”\n\nANTI-TERROR ANALYSIS: IBM agents in China sold IBM’s i2 policing analysis software to the Xinjiang police, China’s Ministry of State Security, and other Chinese police units throughout the 2010s, leaked emails show. i2 software was subsequently copied and deployed by one former IBM agent, Landasoft, as the basis for a predictive policing platform that tagged hundreds of thousands of people as potential terrorists during a brutal crackdown in China’s far west Xinjiang region. IBM says it ceased relations with Landasoft in 2014, prohibited sales to police in Xinjiang and Tibet since 2015, and has no record of any sales of i2 software to the Public Security Bureau in Xinjiang.\n\nETHNIC REPRESSION: Dell and then-subsidiary VMWare sold cloud software and storage devices to police and entities providing data to police in Tibet and Xinjiang, even as late as 2022 after ethnic repression there was widely known. Dell addressed race in its marketing: In 2019, Dell said on WeChat it had teamed up with surveillance firm Yitu to sell a “military-grade” AI-powered laptop for Chinese police with “all-race recognition.” Dell, based in Round Rock, Texas, told AP it conducts “rigorous due diligence” to ensure compliance with U.S. export controls. Chinese policing systems, including in Xinjiang, also used software from Oracle, based in Austin, Texas, and from Microsoft, based in Seattle, according to procurements and a leaked database obtained by AP.\n\nFINGERPRINT RECOGNITION: Chinese defense contractor Huadi worked with IBM to construct China’s national fingerprint database; IBM said it never sold “fingerprinting-specific” products to the Chinese government and that any possible misuse “for fingerprinting purposes” was done without its knowledge or assistance. HP and VMWare sold technology used for fingerprint comparison by Chinese police. Intel said in 2019 marketing material that it partnered with Hisign, a Chinese fingerprinting company that sold to Xinjiang police, to make their fingerprint readers more effective, and that the new reader was “fully tested in an actual application scenario” with a municipal police bureau. Hisign was still an Intel partner as of last year, according to Chinese media reports. California-based Intel said it has not had any technical engagement with Hisign since 2024, and told AP it would “act swiftly” if it became aware of any “credible misuse.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAI CAMERAS: IBM, Dell, Tokyo-based Hitachi, and VMWare promoted facial recognition for use by Chinese police. Japanese electronics giant Sony said on its official WeChat account that it wired a Chinese prison with “intelligent” cameras, saying it was widely trusted for “surveillance projects.” California chip giant Nvidia and Intel partnered with China’s three biggest surveillance companies to add AI capabilities to camera systems used for video surveillance across China, including in Xinjiang and Tibet, until sanctions were imposed. Relations with other Chinese surveillance companies continued more recently: Nvidia posted on its WeChat social media account in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk. Nvidia told AP those relationships no longer continue.\n\nSURVEILLANCE RESEARCH: Nvidia, IBM, and Hitachi staff collaborated with Chinese police researchers and companies on surveillance technology. Nvidia said in a post dating to 2013 or later that a Chinese police institute used its chips for surveillance technology research. Nvidia said it doesn’t currently work with Chinese police but did not address the past. And in 2021, an IBM and a U.S. Army researcher coauthored an AI video study with a Chinese police researcher working at a sanctioned company, according to a paper unearthed by IPVM, a surveillance research publication. The U.S. Army told AP the Chinese police researcher only worked on the paper after the Army researcher’s work had concluded.\n\nDNA: Chinese police DNA labs bought Dell and Microsoft software and equipment to save genetic data on police databases. In 2021, Hitachi advertised DNA sequencers to Chinese police, and police labs bought pipettes from German biotech firm Eppendorf last year. And until contacted by AP in August, Massachusetts-based biotech firm Thermo Fisher Scientific‘s website stated that its kits are made for China’s national DNA database and “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans,” and featured the work of a Chinese police researcher who discussed using Thermo Fisher kits to identify ethnic Uyghur and Manchu populations at a 2016 conference. Thermo Fisher stopped sales in Xinjiang in 2021 and in Tibet in 2024, but still promotes kits to police elsewhere in China, including at a police trade show earlier this year. In a statement to AP, Thermo Fisher said its kits “are designed to be effective across diverse global populations” but “do not have the capability to distinguish among specific ethnic groups.”\n\nINTERNET POLICE: In 2014, VMWare said internet police in cities across China used its software, and in 2016, Dell said on its WeChat account that its services assisted the Chinese internet police in “cracking down on rumormongers” — essentially promoting censorship. An undated IBM marketing presentation said that internet police in Shanghai and Guangzhou used its i2 software, with metadata suggesting it was from 2018. IBM held a conference in Beijing promoting i2 in 2018, according to its official WeChat account.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nENCRYPTION TECHNOLOGY: Leaked government blueprints show Illinois-based Motorola provided encrypted radio communications technology to the Chinese police for handling “sudden and mass events in Beijing.” Motorola did not respond to requests for comment.\n\nAI DRIVES: Californian hard disk giants Seagate and Western Digital and Tokyo-based Toshiba sell hard drives specialized for AI video systems for use by Chinese police. In 2022, Toshiba wrote about how its surveillance hard drives can help police monitor communities to “identify and control suspicious” or “blacklisted” individuals. “They’re optimized and adapted for security systems,” Toshiba sales director Feng Hao told AP. Last year, Western Digital touted its partnership with Chinese surveillance company Uniview at a policing trade expo, months before Uniview was sanctioned over complicity in rights abuses. And Seagate said on WeChat in 2022 that it sells hard drives “tailor made” for AI video systems in China for use by police to help them ”control key persons,” and promoted their drives to police at a security trade association in China this year.\n\nMAPPING SOFTWARE: Blueprints show that in 2009, IBM, Oracle, and Esri, the creator of ArcGIS based in California, sold hundreds of thousands of dollars’ worth of software to build China’s Police Geographic Information System, and in 2013, HP said it sold “digital fencing” solutions to Chinese police. Such systems alert Chinese police even today when Uyghurs, Tibetans or dissidents stray out of provinces, counties or even villages. The U.S. curbed exports of such mapping software to China in 2020. But the restrictions are narrow in scope, and Esri maintains a research center in Beijing that marketed to police and other Chinese clients. Esri denied involvement.\n\nPOLICE GEAR: Chinese police patrol the streets equipped with foreign technology. Officers stroll the streets of Beijing with Motorola walkie-talkies, for example, while Korean electronics giant Samsung sells microSD cards for police body cameras, advertising them at Chinese police trade shows in 2023 and 2024. And in WeChat posts, Chinese state-owned company Jinghua said it cooperated with German electronics giant Philips on China’s first ”AI-powered 5G” police body camera and advertised Philips-branded recorders and cameras to Chinese police. In a statement, Philips said it had no partnership with Jinghua, did not authorize sales of Philips-branded body cameras in China, and would be contacting Jinghua over the posts.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nIBM, Dell, California network seller Cisco, Seattle-based Amazon Web Services, Seagate, Intel, Thermo Fisher and Western Digital all said they adhere to relevant export controls, laws and regulations where they operate. Eppendorf, Sony, and Hitachi declined to describe their business relationships in China but said they respected human rights.\n\nOracle, Hewlett Packard Enterprise, and California tech conglomerate Broadcom, which acquired VMWare in 2023, did not comment on the record. HP, Motorola, Samsung, Toshiba, Huadi, and Landasoft did not respond. Microsoft said it did not knowingly provide software for updates to China’s main policing system.\n\nThe Xinjiang government said in a statement that it uses surveillance technologies to “prevent and combat terrorist and criminal activity” and does not target any particular ethnicity. The statement said Western countries also use such technology, calling the U.S. “a true surveillance state.” Other government agencies did not respond to a request for comment.\n\n__\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/detailed-findings-ap-investigation-us-043012321.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "SailPoint CEO: AI agents promise big gains — and big risks",
      "content": "AI agents are here — and they could be a blessing and a curse.\n\n\"It's the classic double-edged sword of technology,\" SailPoint (SAIL) CEO Mark McClain told Yahoo Finance's Executive Editor Brian Sozzi at Goldman Sachs' Communacopia + Technology Conference.\n\n\"People are rapidly wanting to deploy agents as a way to enhance the productivity, effectiveness, efficiency ... on their business. But they're increasingly cognizant of the risk,\" he said.\n\nThe risk comes down to visibility and control. While AI-driven agents can automate workflows and even generate subagents, they raise questions about accountability.\n\n\"You have to always ensure that there's some person in the organization that's taking responsibility for that [agent],\" McClain said.\n\nMcClain's comments come as SailPoint, an identity security developer, works to position itself at the center of the AI wave. It specializes in securing machine identities and managing access for companies like Home Depot (HD).\n\nThe company recently raised its full-year outlook despite short-term stock pressure tied to its third quarter guidance. SailPoint stock was down over 8% during Tuesday afternoon trading. Year to date, shares have fallen 7%.\n\nMcClain noted that SailPoint is working in tandem with firms like CrowdStrike (CRWD), calling the company \"complementary to us,\" as it focuses on device-level security.\n\nHowever, McClain downplayed the idea that automation will replace entire workforces. \"I think they're going to leverage this technology to make their people better and more effective, far more than they're going to just replace people,\" he said.\n\nSailPoint began trading on Feb. 13 on the Nasdaq. The company priced its initial public offering (IPO) at the top end of its targeted range of $21 to $23, raising $1.38 billion in proceeds.\n\nThe stock closed its first day of trading at $22 per share and hit a closing high of $25.70 on Feb. 16. It was the first big test of the tech IPO market in 2025. Since then, several other buzzy IPOs came to market, including Nvidia (NVDA) chip consumer CoreWeave (CRWV), trading platform eToro (ETOR), and software play Figma (FIG).\n\n\"We see an opportunity with SAIL to own a best-of-breed vendor at a discount as Identity continues to move up the priority stack. We have seen significant share shift across the Identity landscape in the wake of an 'identity crisis' legacy vendors face as they have not efficiently invested in their platforms to address Identity related risk that is poised to accelerate,\" JPMorgan analyst Brian Essex wrote in a note.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/sailpoint-ceo-ai-agents-promise-big-gains--and-big-risks-162015066.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia Unveils Rubin CPX: A New AI Chip System for Video and Software Creation",
      "content": null,
      "source": "Patently Apple",
      "url": "https://www.patentlyapple.com/2025/09/nvidia-unveils-rubin-cpx-a-new-ai-chip-system-for-video-and-software-creation.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "ASML Invests Billions In Nvidia-Backed Mistral AI To Power Next Era Of Semiconductors",
      "content": "ASML Holding (NASDAQ:ASML) and France-based Mistral AI announced a strategic partnership on Tuesday that combines semiconductor manufacturing expertise with frontier artificial intelligence capabilities to accelerate innovation across the semiconductor and AI value chain.\n\nASML said it will apply Mistral’s AI models throughout its product portfolio and R&D operations to deliver faster time-to-market and higher-performance holistic lithography systems for its customers.\n\nTo cement the collaboration, ASML is investing 1.3 billion euros as the lead investor in Mistral AI’s Series C funding round, acquiring an 11% stake on a fully diluted basis.\n\nAlso Read: ASML Explores India As Geopolitical Risks Threaten China Business\n\nASML CEO Christophe Fouquet said the agreement moves beyond a traditional vendor-client relationship, creating opportunities for joint research and AI-enabled product innovation.\n\nMistral AI CEO Arthur Mensch said the partnership blends ASML’s industrial leadership with Mistral’s frontier AI expertise. ASML will gain a seat on Mistral AI’s Strategic Committee as part of the deal, with CFO Roger Dassen appointed to represent the company.\n\nASML stock has climbed 15% so far in 2025, outpacing the Nasdaq 100 Index’s gain of just over 13%. The performance reflects sustained demand for its extreme ultraviolet lithography machines, the cornerstone of advanced semiconductor production and a critical enabler of the current AI-driven chip boom.\n\nRecent reports indicate that ASML is becoming Mistral AI’s largest shareholder after leading its $2 billion Series C funding round.\n\nMistral, often called Europe’s AI champion and backed by Nvidia (NASDAQ:NVDA), competes with U.S. leaders like OpenAI and Alphabet’s (NASDAQ:GOOGL) (NASDAQ:GOOG) Google. ASML’s investment could reduce Europe’s reliance on American and Chinese AI models while boosting its use of AI in chipmaking.\n\nPrice Action: ASML stock is trading higher by 0.04% to 796.60 premarket at last check Tuesday.\n\nRead Next:\n\nImage via Shutterstock\n\nUNLOCKED: 5 NEW TRADES EVERY WEEK. Click now to get top trade ideas daily, plus unlimited access to cutting-edge tools and strategies to gain an edge in the markets.\n\nGet the latest stock analysis from Benzinga?\n\nThis article ASML Invests Billions In Nvidia-Backed Mistral AI To Power Next Era Of Semiconductors originally appeared on Benzinga.com\n\n© 2025 Benzinga.com. Benzinga does not provide investment advice. All rights reserved.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/asml-invests-billions-nvidia-backed-095358773.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia-backed Reflection AI eyes $5.5 billion valuation as AI runs hot, FT reports",
      "content": "Nvidia-backed Reflection AI is raising around $1 billion in a financing that will value the startup at up to $5.5 billion, the Financial Times reported on Tuesday, citing people familiar with the matter.\n\nThe round could value Reflection between $4.5 billion and $5.5 billion, including the new investment, FT added.\n\nThe announcement could potentially mark a nearly 10-fold valuation jump merely six months after the company's previous external fundraising, where it was valued at $545 million, according to PitchBook data.\n\nStartups leveraging artificial intelligence continue to attract investor capital, with the nascent technology even sparking a multi-billion-dollar race for infrastructure build across Big Tech companies.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nNvidia's venture capital arm would invest at least $250 million, the report added. Lightspeed Venture Partners, Sequoia and Yuri Milner's DST Global are also participating in the round.\n\nFounded in 2024 by former Google-backed DeepMind researchers Misha Laskin and Ioannis Antonoglou, Reflection develops tools that automate coding, a highly valuable use case of AI.\n\nThe latest financing also comes amid the bidding war across Silicon Valley sparked by AI talent like Laskin and Antonoglou, with Meta offering salaries and signing bonuses that liken those of professional athletes.",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/business/nvidia-backed-reflection-ai-eyes-55-billion-valuation-ai-runs-hot-ft-reports-5340786",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "NVIDIA Rubin CPX GPU Is Designed For Super AI Tasks Including Million-Token Coding & GenAI, Up To 128 GB GDDR7 Memory, 30 PFLOPs of FP4",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/nvidia-rubin-cpx-gpu-128-gb-gddr7-30-exaflops-ai-compute/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "MicroStrategy’s $71B treasury tops Apple, Tesla as stock slides 26%",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/crypto/investing/microstrategys-71b-treasury-tops-apple-tesla-as-stock-slides-26",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia previews Rubin CPX graphics card for disaggregated inference",
      "content": null,
      "source": "SiliconANGLE News",
      "url": "https://siliconangle.com/2025/09/09/nvidia-previews-rubin-cpx-graphics-card-disaggregated-inference/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Stacy Rasgon’s Prediction About Broadcom (AVGO) Was Right",
      "content": "We recently published Top 10 Analyst Calls on Trending Stocks You Shouldn’t Miss. Broadcom Inc. (NASDAQ:AVGO) is one of the major analyst calls.\n\nStacy Rasgon, Bernstein senior U.S. semiconductor analyst, said in a CNBC program in May that AI demand is “off the charts” and CapEx is not slowing as it was feared. Rasgon liked Broadcom Inc (NASDAQ:AVGO) amid the company’s AI and software exposure:\n\n“Look, I’ve liked the AI names. I felt that whereas for a lot of these other end markets people were really worried about what’s going to happen in the second half and whether demand is real or not, AI demand is real. I also think the AI hardware, if tariffs are implemented, is somewhat insulated because most of the AI servers come into the U.S. through Mexico — they’re USMCA-compliant and tariff-free. So I actually like AI. I like Broadcom Inc (NASDAQ:AVGO)— it has an AI story, and they’ve also got 40% of their revenue from software, which is safe. Their non-AI semis were already at a cyclical low.”\n\nAVGO is up 80% over the past six months. For the fiscal fourth quarter, AVGO expects $6.2 billion in AI revenue, up 66% from a year earlier. The company said it secured $10 billion in AI infrastructure orders from a new customer. Many analysts believe this customer is OpenAI. Some media reports said the two companies co-designed a chip that will be launched next year.\n\nBaron Technology Fund stated the following regarding Broadcom Inc. (NASDAQ:AVGO) in its Q1 2025 investor letter:",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/stacy-rasgon-prediction-broadcom-avgo-212944839.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "YMMV: HP OMEN MAX: 16\" QHD+ 240Hz IPS, Ryzen AI 9 HX 375, RTX 5080, 32GB DDR5, 1TB SSD $1999.99",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired Dr.W posted Item 1 of 2 Item 1 of 2 expired Dr.W posted YMMV: HP OMEN MAX: 16\" QHD+ 240Hz IPS, Ryzen AI 9 HX 375, RTX 5080, 32GB DDR5, 1TB SSD $1999.99 $2,000 $2,400 16% off Micro Center 9 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 5,787 Views Visit Micro Center Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details Available In-store Only at selective stores, YMMV.\n\n\n\nSPECS: AMD Ryzen AI 9 HX 375 (2.0GHz) Processor\n\n32GB DDR5-5600 RAM\n\nNVIDIA GeForce RTX 5080 Graphics Card\n\n1TB PCIe Gen4 NVMe M.2 SSD\n\n16\" WQXGA IPS Anti-Glare Display\n\n2.5Gb LAN, 2x2 WiFi 7 (802.11be), Bluetooth 5.4\n\n5.88 lbs. (2.67 kg)\n\nWindows 11 Home\n\nhttps://www.microcenter .com/produ...-processor Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster Dr.W Follow Give Rep Message 8,032 Deal Posts 11,542 Comments Posts 16,996 Reputation Points 10,806 Votes Submitted Deal Details Community Notes About the Poster Available In-store Only at selective stores, YMMV.\n\n\n\nSPECS: AMD Ryzen AI 9 HX 375 (2.0GHz) Processor\n\n32GB DDR5-5600 RAM\n\nNVIDIA GeForce RTX 5080 Graphics Card\n\n1TB PCIe Gen4 NVMe M.2 SSD\n\n16\" WQXGA IPS Anti-Glare Display\n\n2.5Gb LAN, 2x2 WiFi 7 (802.11be), Bluetooth 5.4\n\n5.88 lbs. (2.67 kg)\n\nWindows 11 Home\n\nhttps://www.microcenter .com/produ...-processor",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18593653-ymmv-hp-omen-max-16-qhd-240hz-ips-ryzen-ai-9-hx-375-rtx-5080-32gb-ddr5-1tb-ssd-1999-99",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Mistral Cements AI Lead In Europe With Cash Infusion",
      "content": null,
      "source": "International Business Times",
      "url": "https://www.ibtimes.com/mistral-cements-ai-lead-europe-cash-infusion-3782885",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "US tech companies enabled the surveillance and detention of hundreds of thousands in China",
      "content": "BEIJING (AP) — The body camera hung from the top of the IV drip, recording the slightest twitch made by Yang Guoliang as he lay bloody and paralyzed in a hospital bed after a police beating with bricks.\n\nBy then, surveillance was nothing new for the Yang family in rural China, snared in an intricate network based on U.S. technology that spies on them and predicts what they’ll do.\n\nTheir train tickets, hotel bookings, purchases, text messages and phone calls are forwarded to the government. Their house is ringed with more than a dozen cameras. They’ve tried to go to Beijing 20 times in the past few years, but masked men show up and grab them, often before they depart. And last year, Yang’s wife and younger daughter were detained and now face trial for disrupting the work of the Chinese state — a crime carrying a sentence of up to a decade in prison.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nYet the Yangs say they are not criminals. They are simply farmers trying to beg Beijing to stop local officials from seizing their 1 1/2 acres of land in China’s eastern Jiangsu province.\n\n“Every move in my own home is monitored,” Yang said, sitting behind black curtains that block him from the glare of police lights trained straight at his house. “Their surveillance makes me feel unsafe all the time, everywhere.”\n\nAcross China, tens of thousands of people tagged as troublemakers like the Yangs are trapped in a digital cage, barred from leaving their province and sometimes even their homes by the world’s largest digital surveillance apparatus. Most of this technology came from companies in a country that has long claimed to support freedoms worldwide: the United States.\n\nOver the past quarter century, American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warningsfrom the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nCritically, American surveillance technologies allowed a brutal mass detention campaign in the far west region of Xinjiang — targeting, tracking and grading virtually the entire native Uyghur population to forcibly assimilate and subdue them.\n\nU.S. companies did this by bringing “predictive policing” to China — technology that sucks in and analyzes data to prevent crime, protests, or terror attacks before they happen. Such systems mine a vast array of information — texts, calls, payments, flights, video, DNA swabs, mail deliveries, the internet, even water and power use — to unearth individuals deemed suspicious and predict their behavior. But they also allow Chinese police to threaten friends and family and preemptively detain people for crimes they have not even committed.\n\nFor example, the AP found a Chinese defense contractor, Huadi, worked with IBM to design the main policing system known as the “Golden Shield” for Beijing to censor the internet and crack down on alleged terrorists, the Falun Gong religious sect, and even villagers deemed troublesome, according to thousands of pages of classified government blueprints taken out of China by a whistleblower, verified by AP and revealed here for the first time. IBM and other companies that responded said they fully complied with all laws, sanctions and U.S. export controls governing business in China, past and present.\n\nAcross China, surveillance systems track blacklisted “key persons,” whose movements are restricted and monitored. In Xinjiang, administrators logged people as high, medium, or low risk, often according to 100-point scores with deductions for factors like growing a beard, being 15 to 55 years old, or just being Uyghur.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome tech companies even specifically addressed race in their marketing. Dell and a Chinese surveillance firm promoted a “military-grade” AI-powered laptop with “all-race recognition” on Dell's official WeChat account in 2019. And until contacted by AP in August, biotech giant Thermo Fisher Scientific’s website marketed DNA kits to the Chinese police as “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans.”\n\nWhile the flood of American technology slowed considerably starting in 2019 after outrage and sanctions over atrocities in Xinjiang, it laid the foundation for China’s surveillance apparatus that Chinese companies have since built on and in some cases replaced. To this day, concerns remain over where technology sold to China will end up.\n\nFor example, 20 former U.S. officials and national security experts wrote a letter in late July criticizing a deal for Nvidia to sell H20 chips used in artificial intelligence to China, with 15% of revenues going to the U.S. government. They said no matter who the chip is sold to, it will fall into the hands of Chinese military and intelligence services.\n\nNvidia said it does not make surveillance systems or software, does not work with police in China and has not designed the H20 for police surveillance. Nvidia posted on its WeChat social media account in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk, but told the AP those relationships no longer continue. The White House and Department of Commerce did not respond to requests for comment.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nThermo Fisher and hard drive maker Seagate promoted their products to Chinese police at conferences and trade shows this year, according to online posts. Officers stroll the streets of Beijing with Motorola walkie talkies. Nvidia and Intel chips remain critical for Chinese policing systems, procurements show. And contracts to maintain existing IBM, Dell, HP, Cisco, Oracle, and Microsoft software and gear remain ubiquitous, often with third parties.\n\nWhat started in China more than a decade ago could be seen as a cautionary tale for other countries at a time when the use of surveillance technology worldwide is rising sharply, including in the United States. Emboldened by the Trump administration, U.S. tech companies are more powerful than ever, and President Donald Trump has rolled back a Biden-era executive order meant to safeguard civil rights from new surveillance technologies.\n\nAs the capacity and sophistication of such technologies has grown, so has their reach. Surveillance technologies now include AI systems that help track and detain migrants in the U.S. and identify people to kill in the Israel-Hamas war. China, in the meantime, has used what it learned from the U.S. to turn itself into a surveillance superpower, selling technologies to countries like Iran and Russia.\n\nThe AP investigation was based on tens of thousands of leaked emails and databases from a Chinese surveillance company; tens of thousands of pages of confidential corporate and government documents; public Chinese language marketing material; and thousands of procurements, many provided by ChinaFile, a digital magazine published by the non-profit Asia Society. The AP also drew from dozens of open record requests and interviews with more than 100 current and former Chinese and American engineers, executives, experts, officials, administrators, and police officers.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nThough the companies often claim they aren’t responsible for how their products are used, some directly pitched their tech as tools for Chinese police to control citizens, marketing material from IBM, Dell, Cisco, and Seagate show. Their sales pitches — made both publicly and privately — cited Communist Party catchphrases on crushing protest, including “stability maintenance,” “key persons,” and “abnormal gatherings,” and named programs that stifle dissent, such as “Internet Police,” “Sharp Eyes” and the “Golden Shield.”\n\nOther companies, like Intel, Nvidia, Oracle, Thermo Fisher, Motorola, Amazon Web Services, Microsoft, Western Digital, creator of mapping software ArcGIS Esri, and what was then Hewlett Packard, or HP, also sold technology or services knowingly to Chinese police or surveillance companies. Four practicing lawyers said sales like those uncovered by AP could potentially go against at least the spirit, if not the letter, of U.S. export laws at the time, which the companies denied.\n\nAmerican technology made up nearly every part of China’s surveillance apparatus, AP found:\n\nMILITARY AND POLICE: In 2009, Chinese defense contractor Huadi worked with IBM to build national intelligence systems, including a counterterrorism system, used by the Chinese military and China’s secret police, the Ministry of State Security. Chinese agents sold IBM’s i2 police surveillance analysis software to the same ministry and to Chinese police, including in Xinjiang, through the 2010s, leaked emails and marketing posts show. IBM said it has no record of its i2 software ever having been sold to the Public Security Bureau in Xinjiang.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSURVEILLANCE: Nvidia and Intel partnered with China’s three biggest surveillance companies to add AI capabilities to camera systems used for video surveillance across China, including Xinjiang and Tibet, until sanctions were imposed. Nvidia said in a post dating to 2013 or later that a Chinese police institute used its chips for surveillance technology research.\n\nETHNIC REPRESSION: IBM, Oracle, HP, and ArcGIS developer Esri sold hundreds of thousands of dollars’ worth of geographic and mapping software to Chinese police that allows officers to detect when blacklisted Uyghurs, Tibetans or dissidents stray out of provinces or villages. As late as 2019, with detentions in Xinjiang well underway, Dell hosted an industry summit in its capital. Dell and then-subsidiary VMWare sold cloud software and storage devices to police and entities providing data to police in Tibet and Xinjiang, even in 2022 after abuses there became widely known.\n\nIDENTIFICATION: Huadi worked with IBM to construct China’s national fingerprint database; IBM told AP it never sold “fingerprinting-specific product or technology” to the Chinese government “in violation of US law.” HP and VMWare sold technology used for fingerprint comparison by Chinese police, while Intel partnered with a Chinese fingerprinting company to make their devices more effective. IBM, Dell, and VMWare also promoted facial recognition to Chinese police. China’s police and police DNA labs bought Dell and Microsoft software and equipment to save genetic data on police databases.\n\nCENSORSHIP AND CONTROL: In 2016, Dell boasted on its WeChat account that its services assisted the Chinese internet police in “cracking down on rumormongers.” Seagate said on WeChat in 2022 that it sells hard drives “tailor made” for AI video systems in China for use by police to help them ”control key persons,” despite facing backlash for selling drives in Xinjiang.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nFor extended findings, click here.\n\n“Everything was built on American tech,” said Valentin Weber, a researcher at the German Council on Foreign Relations who studied the use of U.S. tech by Chinese police. “China’s capability was close to zero.”\n\nIBM, Dell, Cisco, Intel, Thermo Fisher and Amazon Web Services all said they adhere to export control policies. Seagate and Western Digital said they adhere to all relevant laws and regulations where they operate.\n\nOracle, Hewlett Packard Enterprise, and tech conglomerate Broadcom, which acquired VMWare and cloud company Pivotal in 2023, did not comment on the record; HP, Motorola and Huadi did not respond, and Esri denied involvement but did not reply to examples. Microsoft told AP it found no evidence that it “knowingly sold technology to the military or police” as part of updates to the “Golden Shield.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome U.S. companies ended contracts in China over rights concerns and after sanctions. For example, IBM said it has prohibited sales to Tibet and Xinjiang police since 2015, and suspended business relations with defense contractor Huadi in 2019.\n\nHowever, sanctions experts noted that the laws have significant loopholes and often lag behind new developments. For example, a ban on military and policing gear to China after the 1989 Tiananmen massacre does not take into account newer technologies or general-use products that can be applied in policing.\n\nThey also noted that the law around export controls is complicated. Raj Bhala, an expert in international trade law at the University of Kansas, said the issues the AP described fell into “the kind of gray area that we put in exams.”\n\n“It would raise concerns about possible inconsistencies, possible violations,” said Bhala, who emphasized he was speaking generally and not about any specific company. “But I really stress ‘possible.’ We need to know more facts.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nWhile German, Japanese and Korean firms also played a role, American tech firms were by far the biggest suppliers.\n\nThe Xinjiang government said in a statement that it uses surveillance technologies to “prevent and combat terrorist and criminal activity,” that it respects citizens’ privacy and legal rights and that it does not target any particular ethnicity. The statement said Western countries also use such technology, calling the U.S. “a true surveillance state.” Other government agencies did not respond to a request for comment, including China’s police and authorities in the Yangs’ province.\n\nThis technology still powers the police database that controls the Yangs and other ordinary people. An estimate based on Chinese government statistics found at least 55,000 to 110,000 were put under residential surveillance in the past decade, and vast numbers are restricted from travel in Xinjiang and Tibet. China’s cities, roads and villages are now studded with more cameras than the rest of the world combined, analysts say — one for every two people.\n\n“Because of this technology … we have no freedom at all,” said Yang Guoliang’s elder daughter, Yang Caiying, now in exile in Japan. “At the moment, it’s us Chinese that are suffering the consequences, but sooner or later, Americans and others, too, will lose their freedoms.”\n\nSelling surveillance superpowers\n\nBack when China was emerging from the chaotic violence of the Cultural Revolution in 1976, three in four Chinese were farmers, including the Yangs. They lived in a three-room home of tiles and pounded earth nestled among the lush, humid fields of the Yangtze River delta.\n\nAfter Chairman Mao Zedong’s death that year, Beijing’s new leaders opened China to the world, and American tech firms like HP and IBM rushed in. But there were hard limits on how much change the government would accept. In 1989, the Tiananmen pro-democracy protests rattled Beijing, which sent tanks and troops to shoot students.\n\nSoon after, Beijing began planning the “Golden Shield,” aimed at digitizing China’s police force.\n\nIn 2001, the 9/11 al-Qaida attacks turbocharged interest in surveillance technology. One researcher claimed authorities could have foiled the attack by unearthing connections between hijackers through public information in databases.\n\nAmerican companies cashed in, selling the U.S. billions of dollars in surveillance technologies they said could prevent crime and terror attacks.\n\nThey spotted the same sales opportunity in China. Researchers warned surveillance technologies would be “instruments of repression” in the hands of authoritarian states. Yet IBM, Cisco, Oracle, and other American companies clinched orders to supply Beijing’s “Golden Shield.”\n\n“China didn’t have this kind of thing before,” said Wang, a former Chinese police official in Xinjiang who asked to be identified only by last name for fear of retaliation. “These concepts all came from the West.”\n\nSoon, disturbing stories emerged. Chinese police blocked sensitive news, pinpointing dissidents with unnerving precision. They stalked adherents of the Falun Gong sect banned by authorities. Congress demanded explanations from tech companies.\n\nIn 2008, documents leaked to the press showed Cisco saw the “Golden Shield” as a sales opportunity, quoting a Chinese official calling the Falun Gong an “evil cult.” A Cisco presentation reviewed by AP from the same year said its products could identify over 90% of Falun Gong material on the web. Followers sued Cisco, which is now petitioning the U.S. Supreme Court to throw out the lower court ruling that allowed the lawsuit.\n\nAt a human rights conference in February, then-Cisco lawyer Katie Shay said companies had a responsibility to understand how customers might misuse their technology for “surveillance and censorship.”\n\n“A lot of people have suffered at the hands of their government, and I want to acknowledge that pain,” said Shay, who left Cisco in June. “I also will say that Cisco disputes the allegations of Cisco’s involvement.”\n\nCisco told the AP it is committed to human rights, but the court allegations may “open the floodgates for suits against U.S. corporations merely for legal exports of off-the-shelf goods and services.”\n\nAs Cisco was summoned before Congress, IBM partnered with a Chinese defense contractor on Phase Two of China’s “Golden Shield.”\n\nClassified government blueprints obtained by AP show that in 2009, IBM worked with Huadi, the state-owned subsidiary of China’s biggest missile military contractor spun off from China’s Ministry of Defense, to build out predictive policing.\n\n“Consolidate Communist Party rule,” read the Huadi blueprint, which showed the databases would track hundreds of thousands of people online.\n\nIn response to AP’s questions, IBM referred to any possible relationship it may have had with Chinese government agencies as “old, stale interactions”:\n\n“ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.”\n\nBack in 2009, Beijing needed the technology urgently to quash critics bonding online. Among them were the Yangs.\n\nIn April that year, local authorities ordered the Yangs and more than 300 other families in their village off their land. Developers coveted their prime lakefront property for “Western-style” apartments and villas, with fountains, football fields and shopping centers.\n\nThe Yangs had no idea police were installing systems that could target families like theirs. They just knew their land was being seized — in return for just a unit in a five-floor walk-up, too many stairs for their elderly mother to climb.\n\nThe Yangs and other farmers across China filed complaints.\n\n“I discovered the way the government took our land was illegal,” Yang Caiying said. “They cheated us.”\n\nPredict and prevent\n\nIn July 2009, three months after the Yang land was seized, riots erupted on the other side of the country in Xinjiang. Gory images of a Uyghur lynched at a toy factory spread online, angry Uyghurs took to the streets, and hundreds were killed.\n\nOnce again, American firms pitched their technology as the solution.\n\nThe government sent troops and cut Xinjiang’s phone and internet connections. In secret meetings, officials concluded that police had failed to spot the danger signs because they couldn’t identify Uyghurs deemed separatists, terrorists, and religious extremists, three engineers then working for the Xinjiang government told AP.\n\nAt the time, Xinjiang police and data systems were already running on American technology including IBM, Cisco, Oracle, and Microsoft, the engineers said, which AP verified by reviewing government contracts. But the databases were unconnected.\n\nSo Xinjiang launched an ambitious initiative to fuse data from all available sources, including banks, railways, and phone companies, into a central database. Officials demanded complete information on all suspicious individuals and their relatives going back three generations, according to the engineers, who described specific meetings in which they participated. Two asked to remain anonymous, fearing for their family in China; the third, Nureli Abliz, is now in Germany.\n\nSoon, lucrative contracts went up for bidding. Among those seeking to profit was IBM.\n\n“Prevent problems before they happen,” IBM promised Chinese officials. In an August 2009 pamphlet, IBM cited the Xinjiang riots and said its technology could help the government “ensure urban safety and stability.”\n\nIBM executives fanned out across the country to court Chinese officials. In December 2009, they set up a new “IBM Institute for Electronic Governance Innovation” in Beijing. In 2011, IBM acquired i2, a software program designed to prevent “terrorist threats.” IBM touted i2’s ability to analyze Chinese social media and licensed a Shanghai-based firm called Landasoft to sell it to China’s police, corporate records show.\n\nChinese police purchased tens of millions of dollars’ worth of products from companies like IBM, Cisco, Oracle, and Microsoft to upgrade the “Golden Shield” policing systems, a leaked accounting ledger acquired by AP from a whistleblower shows.\n\nIn the confrontation between the Chinese state and its critics, American technology tipped the scales of power.\n\nIn 2011, thieves ransacked the Yangs’ house, hunting for their property deed. They didn’t find it.\n\nTwo years later, bald men with tattoos and gold chains smashed down their door, shattered windows and flipped furniture to bully them out of their home anyway. Yang’s mother dropped to the floor in terror. Doctors diagnosed a heart attack, but the Yangs didn’t have money for a pacemaker.\n\nFurious, the Yangs sued local police. In June 2015, a judge ruled their land had been seized illegally. The Yangs celebrated.\n\nBut just weeks after the ruling, officers identified human rights lawyers through the “Golden Shield” technology, cuffed hundreds of them and pressed them into police vans across China. One lawyer later recalled how police monitored his messages on human rights in WeChat before they grabbed him, shackled him to a chair, and tortured him.\n\nOvernight, China’s budding rights-defense movement was dealt a fatal blow — and with it, the Yangs’ case. The Yangs were called in and curtly told the judgment was being overturned, their lawsuit dismissed without trial.\n\n“We really had too much faith in the law, you know?” Yang Guoliang said, his hands clenched in fists. “It turned out to be worthless.”\n\nTechnologies of terror\n\nIn the meantime, Beijing was transforming Xinjiang into the most heavily surveilled place on earth, sweeping around a million people into camps and prisons.\n\nWhen bombs tore through a train station in Xinjiang’s capital hours after a visit by leader Xi Jinping in 2014, Xi demanded a crackdown.\n\n“He was super angry,” said Abliz, one of the engineers with the Xinjiang government. “They concluded they weren’t surveilling Uyghurs closely enough.”\n\nThe next year, in April 2015, Abliz attended a closed-door exposition in Xinjiang. A booth ran by Landasoft, the former IBM partner, caught his eye.\n\nAfter years as a vendor of IBM’s i2 police surveillance analysis software to Xinjiang police, Landasoft had struck out on its own, touting i2-like software it said could detain extremists before they caused trouble. The similarity was no coincidence: Landasoft’s software was copied from i2, according to leaked emails and records.\n\n“The platform is developed based on i2,” a Landasoft project manager wrote in an email.\n\nIt used a proprietary data visualization system developed by i2. The software powered what was called the Integrated Joint Operations Platform, or IJOP, with the authority to trigger arrests.\n\nAbliz went numb.\n\n“I thought then that this was the end of humanity,” he said.\n\nLandasoft did not respond to repeated requests for comment. IBM said it cut ties with Landasoft in 2014 and was not aware of any interaction between Landasoft and the Public Security Bureau in Xinjiang.\n\nIn the autumn of 2015, months after the Xinjiang expo, Landasoft signed contracts with Xinjiang police, emails show. Workers installed millions of cameras and wired over 7,000 police outposts, often built just hundreds of meters apart. Nearly 100,000 officers were recruited to pound on doors and collect names, addresses, fingerprints and face-scans.\n\nThough Chinese hardware was favored, foreign software was irreplaceable for its performance and compatibility with China’s American-built systems, engineers told AP. That included server and database software from Oracle and Microsoft and cloud software from VMWare, which Dell acquired in 2016.\n\nIn late 2016, the crackdown began. Internal documents, a leaked copy of the Landasoft software and interviews with 16 former Xinjiang police officers, officials and engineers reveal how the system worked.\n\nLandasoft’s software combined data fed into a central police database to compile a dossier on vast swaths of Xinjiang’s population, tagging them with categories like “went on pilgrimage” or “studied abroad.” Administrators then questioned them, computed risk scores and decided who to detain.\n\nHundreds of thousands of people were tagged “untrustworthy”, leaked messages show. Leaked documents show the IJOP flagged 24,412 people as “suspicious” in just one week in 2017, leading to most being detained.\n\n“They thought it better to grab thousands of innocents than let a single criminal slip free,” Abliz said.\n\nThe technology was crude and flawed. Landasoft emails show engineers frantically fixing a software bug to release hundreds of people categorized as high-risk. And surveillance cameras often misidentified people, a former Xinjiang police officer found when he checked their ID cards.\n\nYet officers were told “computers cannot lie” and that the IJOP’s listed targets were “absolutely correct,” Abliz said. The software’s orders were often obeyed fearfully, unquestioningly.\n\n“The tech companies told the government their software is perfect,” Abliz said. “It’s all a myth.”\n\nMinority report\n\nThe all-encompassing surveillance forced total compliance: Officers arrested colleagues, neighbors informed on each other.\n\nIn May 2017, Kalbinur Sidik, a teacher now in the Netherlands, was summoned to her district government office in a yellow brick apartment building in Xinjiang’s capital. A young Uyghur woman, fresh from college, rose and introduced herself as a local official. Sidik, the woman explained, was being appointed as the head of her building, responsible for collecting information on neighbors.\n\n“What’s this data going to be used for?” Sidik asked.\n\nThe woman looked at a computer, with a Landasoft program running and lists of names and tags: “Goes out at night,” “Overseas phone,” “unemployed.” One button stood out: “Push Alert.”\n\nThe woman clicked it, and the screen filled with names. These people, the woman explained, would be detained and interrogated for suspected ties to terrorism. Sidik’s eyes widened.\n\n“I hated her for what she was doing,” Sidik said. “I knew those people would disappear.”\n\nXinjiang officials issued arrest quotas, Sidik and five other former officers and administrators said. Sidik watched with horror as the number of people who attended her compound’s weekly mandatory flag-raising ceremony shrank, from 400 to just over 100, as residents were arrested.\n\nAt the district office, she observed the logos popping up on screens: Oracle, Microsoft, Intel. The AP found evidence of products from all three companies used in Xinjiang’s policing and data systems during the crackdown, along with Esri, Seagate, Western Digital, Nvidia, Thermo Fisher, and VMWare, then owned by Dell, which advertised cooperation with Xinjiang authorities on its website.\n\nSidik asked her neighborhood official where it all came from.\n\n“We’ve spent a lot of money to import foreign technology,” she recalls the official telling her.\n\nAmong those caught in the digital dragnet was Parida Qabylqai, an ethnic Kazakh pharmacist at a military hospital in Xinjiang.\n\nIn February 2018, Qabylqai was flagged by the IJOP for visiting her parents in Kazakhstan. At first, her boss thought it was a mistake.\n\n“You’re a good person, you shouldn’t be listed,” she recalled him saying. Then he checked the IJOP and spotted her name.\n\n“It’s really serious! You’re going to end up in the camps,” he blurted out in shock.\n\nAn officer pressed a confession into her hands.\n\n“What did I do wrong?” Qabylqai asked.\n\n“Just sign!” the officer shouted.\n\nQabylqai was cuffed, hooded, and whisked to a camp, where cameras watched her day and night, even peering at her naked body in the toilet. Guards barking over speakers ordered her not to speak or even to move.\n\n“They did things to us that no human being should ever have to experience,” she said. “But they said my name was listed by the IJOP, so they didn’t need to explain anything.”\n\nEven enforcers of the system weren’t spared.\n\nIn 2018, Liu Yuliang, a civil servant in Xinjiang, was ordered to the home of a young police officer in his village. He and dozens of others stood, silent, as the officer embraced his sobbing, pregnant wife.\n\nThe officer had forced many people into the camps. Then he himself was flagged for detention.\n\nToo fearful to resist, Liu went along with the arrest, just as the young officer had done before him.\n\nLandasoft software alerted police when flagged people did anything labeled suspicious, like going out at night or logging on the internet repeatedly. Liu was sent to knock on doors, questioning residents whose “eyes filled with fear.”\n\nAs police swept Xinjiang, Landasoft purchased software from Pivotal, a cloud company later acquired by Broadcom, emails show. And Landasoft registered accounts on both Amazon Web Services and Microsoft Azure in 2018, seeking to expand cloud offerings to police clients, emails show.\n\nAWS said Landasoft “consumed very limited cloud services for a brief period” and not for software in the Xinjiang crackdown. Microsoft said Landasoft used Azure services through a self-service portal retired in 2021, and that any Landasoft data was deleted.\n\nThe Xinjiang government told the AP: “There is absolutely no such thing as ‘large-scale human rights violations.’”\n\nLiu eventually resigned and returned to his hometown in eastern China, trying to forget what he had seen and done. But he noted with unease the new cameras and checkpoints being installed around his home.\n\nFour days later, state security called and summoned him for questioning. The all-seeing surveillance apparatus had followed him home.\n\n“The Xinjiang model is being copied everywhere, in every city in China,” Liu said.\n\nIn 2024, Liu left China, ignoring an airport officer who warned that wherever he went, he would be watched.\n\n“This technology has no emotions,” Liu said. “But in the hands of a government that doesn’t respect the law, it becomes a tool for evil.”\n\nAutomated autocracy\n\nThe Yangs are still trapped by U.S. technology. IBM, Dell, HP, Cisco, and Seagate servers, switches and drives power police systems targeting them, maintenance contracts dating to this year show. Intel and Nvidia chips process data. Oracle and VMWare software run the database.\n\nBut the harder the Yangs push, the harder the system pushes back.\n\nIn February 2023, they went to the National Public Complaints Administration in Beijing with a letter. Two days later, police grabbed them from their hotel and drove them home.\n\nThe Yangs persisted, trying to plead their case to Beijing. In the following months, they were seized at bus and train stations, beaten at a hospital and abducted by ambulance.\n\nLast July, Yang’s mother tried again. She carried a letter for Chinese leader Xi Jinping:\n\n“They’re using violence and kidnapping to bar me from petitioning and seeking medical treatment ... We beg you, General Secretary, to save us.”\n\nOutside Beijing’s leadership compound, burly men in black tackled Yang’s mother to the ground. She was jailed for over a month, questioned, strip-searched, force-fed medication and deprived of food and water. In October, she and Yang’s sister disappeared.\n\nThe Yangs’ house is now the last left standing. The father lives alone.\n\nHis relatives have cut contact, unnerved by the flock of police that tail him. Thousands of pages of documents stashed in drawers, stuffed in bags, and piled in boxes in a bathtub chronicle every step of their 16-year quest for justice.\n\nIn April, Yang was sent criminal charges showing how much police had spent to stop the family’s “abnormal petitioning.”\n\nThe cost: About $37,000.\n\n__\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/us-tech-companies-enabled-surveillance-040441040.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "NVIDIA Unveils Its Newest ‘Rubin CPX’ AI GPUs, Featuring 128 GB GDDR7 Memory & Targeted Towards High-Value Inference Workloads",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/nvidia-unveils-its-newest-rubin-cpx-ai-gpus/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Just Released: NVIDIA PhysicsNeMo 25.08",
      "content": null,
      "source": "Example.com",
      "url": "http://www.example.com/blog/2025/08/27/physicsnemo-release-25-08/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Wall Street Loves Taiwan Semi. Should You Buy TSM Stock Now?",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/34699828/wall-street-loves-taiwan-semi-should-you-buy-tsm-stock-now",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "How does Tesla get to $8.5 trillion value? Robots, robotaxis and hope",
      "content": "By Abhirup Roy and Akash Sriram\n\nSAN FRANCISCO (Reuters) -How can Tesla (TSLA) become an $8.5 trillion company? That's the market valuation the electric vehicle maker would have to reach to justify CEO Elon Musk's new pay package announced last week.\n\nSelling 100 million humanoid robots in a year could do it; creating a robotaxi network with more than 10 times the revenue of Uber might as well. And of course, investor hope is part of the equation.\n\nMusk on Friday was given a decade to expand Tesla's $1 trillion valuation into a company worth more than the combined current value of Nvidia (NVDA) and Microsoft (MSFT), the two most valuable publicly traded companies in the world. If he succeeds, Musk, already the best-paid CEO in the world, would receive a trillion-dollar pay package.\n\nMusk's new pay package was granted on September 3, but it is subject to shareholder approval in November.\n\nThe board showed how and where it expects Tesla to make its money by structuring Musk's pay package around 12 milestones that are primarily based on products and profit, as well as market capitalization. They target enormous increases in profit as Tesla rolls out its Optimus humanoid robots and a robotaxi fleet that it hopes will be more efficient than human-driven rivals.\n\nA lot depends on how investors value the company. Tesla, for example, is valued as a growth stock, trading at around 75 times its earnings before interest, taxes, depreciation and amortization, or EBITDA, even though its vehicle sales dropped last year and are likely to drop this year.\n\nThe payoff is astounding - and so are the goals. Gene Munster, managing partner at Deepwater Asset Management, broadly estimated that robotaxis and self-driving software could be worth a trillion dollars of market cap each, with cars another half-trillion. \"At the end of the day, the reason why this is going to work or not work really comes down to Optimus,\" he said. \"It's a fairy tale, but it's one that could actually happen.\"\n\nMusk has been betting the company on self-driving software and robotaxis for some time. Tesla currently has a small fleet of robotaxis - estimated to be about three dozen vehicles - in a part of Austin, Texas. An early Musk milestone is to have a million robotaxis in operation.\n\nOne of Tesla's biggest fans, ARK Invest, predicted an even sunnier case well before the Musk pay package was announced. They see Tesla's market capitalization hitting $7 trillion to $10.9 trillion in 2029, with a Tesla robotaxi network bringing in between $603 billion and $951 billion of ride-hail revenue per year. Global ride-hailing leader Uber, by comparison, will have revenue of $52 billion this year, according to LSEG.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/does-tesla-8-5-trillion-100326566.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "China’s AI Chip Ambitions Limited by HBM Memory Supply, Notes Report",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/chinas-ai-chip-ambitions-limited-by-hbm-memory-supply-notes-report/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 “Battlemage” Nears Launch as Intel Prepares Packaging",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "5 Things to Know Before the Stock Market Opens",
      "content": "Stock futures are slightly higher after the tech-heavy Nasdaq hit a new all-time-high; Nebius Group (NBIS) shares are soaring after the company inked an AI infrastructure deal with Microsoft (MSFT); Lachlan Murdoch gains control of the media empire that includes Fox (FOX) and News Corp (NWS); Oracle (ORCL) is expected to report revenue growth when it delivers quarterly earnings after the closing bell; Teck Resources (TECK) and Anglo American announce merger to form copper mining giant; and Apple launches its iPhone 17. Here's what investors need to know today.\n\n1. Stock Futures Tick Higher as Indexes Hover Near Record Highs\n\nStock futures are slightly higher this morning after the tech-heavy Nasdaq Composite hit a new record high on Monday, as stocks rallied amid expectations that the Federal Reserve will cut interest rates soon. The benchmark S&P 500 and the Dow Jones Industrial Average come into today's session just below all-time highs of their own. Bitcoin (BTCUSD), which has been under pressure in recent weeks, is up slightly at $112,500. The yield on the 10-year Treasury note is ticking higher after hitting its lowest level since April yesterday, while gold and oil futures are also edging upwards in early trading. (Read Investopedia's real-time markets coverage here.)\n\n2. Nebius Group Soars on AI Deal with Microsoft\n\nNebius Group (NBIS) shares are up more than 50% in premarket trading after the AI infrastructure company announced a multi-year deal with Microsoft (MSFT). Amsterdam-based Nebius will provide Microsoft with dedicated capacity at its new data center in Vineland, New Jersey starting later this year, the company said. CNBC reported the deal was worth $19.4 billion. AI chipmaker Nvidia (NVDA) owns a stake in Nebius. “The deal will also help us to accelerate the growth of our AI cloud business even further in 2026 and beyond,” said Nebius CEO Arkady Volozh. Microsoft and Nvidia shares inched higher in premarket trading.\n\n3. Lachlan Murdoch Gains Control of Fox, News Corp in New Family Deal\n\nA deal has been reached to end the yearslong fight over control of the media empire founded by Rupert Murdoch that includes Fox News and The Wall Street Journal. Lachlan Murdoch, who is the CEO of Fox (FOX) and chair of News Corp (NWS), will take control of the trust that holds sizable stakes in both of his father’s companies. As part of the deal, Rupert Murdoch’s children Prudence MacLeod, Elisabeth Murdoch and James Murdoch will end their claim to the company. Shares of Fox and News Corp were each down nearly 5% in recent premarket trading.\n\n4. Oracle Expected to Grow Quarterly Revenue Amid New Cloud Deals\n\nInvestors are awaiting quarterly results from Oracle (ORCL), which are scheduled to be released after markets close today. The cloud computing giant is expected to post a 13% year-over-year jump in quarterly revenue to $15 billion, according to analysts tracked by Visible Alpha. Meanwhile, its adjusted earnings per share are expected to increase to $1.48. The report comes after Oracle shares hit an all-time-high earlier this year on the announcement of $30 billion in new cloud deals. The stock, which has gained more than 40% since the start of 2025, was up about 1% in premarket trading.\n\n5. Teck, Anglo American Merge to Form Copper Mining Giant\n\nMining firms Teck Resources (TECK) and Anglo American have agreed to merge to form a new global minerals company that will be one of the world’s largest producers of copper. The new company, to be called Anglo Teck, will have a combined market capitalization of more than $53 billion. “Anglo Teck will hold an industry-leading portfolio of producing operations, including six world-class copper assets, alongside high-quality premium iron ore and zinc businesses,” Teck said in a release. Shares of Canada-based Teck Resources were up about 17% in premarket trading, while U.K.-based Anglo American gained about 8% in London trading.",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/5-things-to-know-before-the-stock-market-opens-september-9-2025-11806131",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Mistral AI raises 1.7 billion euros as ASML becomes its top shareholder",
      "content": "AMSTERDAM : Dutch chip equipment maker ASML has invested 1.3 billion euros ($1.5 billion) to become the biggest investor in French artificial intelligence startup Mistral AI in a significant boost to Europe's AI ambitions.\n\nMistral AI raised a total of 1.7 billion euros ($2 billion) in its latest funding round, it said on Tuesday. ASML's investment made it Mistral's main shareholder with a stake of about 11 per cent.\n\nThe statement confirmed a Reuters report from Sunday.\n\nThe deal is a boost for Europe's AI ambitions, pairing the continent's most credible rival to U.S. giants OpenAI, Meta and Alphabet's Google with one of its largest tech companies.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nThe latest funding round gives Mistral an 11.7 billion-euro valuation, Mistral said in a statement, becoming the most valuable AI company in Europe.\n\nASML will also partner with Mistral to integrate AI models across its semiconductor equipment portfolio and gain a board seat on the French startup's strategic committee through finance chief Roger Dassen.\n\nMistral, founded in 2023 by former researchers from Google DeepMind and Meta, has positioned itself as Europe's AI alternative to the U.S. and is a centerpiece of France's strategy to become a leading AI competitor.\n\nHowever, it is still worth only a fraction of its U.S. peers. OpenAI is eyeing a valuation of around $500 billion in a potential stock sale, a source familiar with the matter told Reuters in August, more than 40 times Mistral's valuation.\n\nThe Dutch company has recently strengthened its French connections by appointing former French Finance Minister Bruno Le Maire as a special adviser to its executive board. It is also led by French CEO Christophe Fouquet, who took the helm in 2024.\n\n\"It helps that ASML is well connected to the industrial and political establishment to pick and choose its partners,\" said ING analyst Jan Frederik Slijkerman.\n\n\"There is an industrial rational to develop products together,\" he added. \"For ASML it is probably easier to develop AI based products through a partnership then to do this in house.\"\n\nBesides ASML, other investors who joined the fundraising are DST Global, Andreessen Horowitz, Bpifrance, General Catalyst, Index Ventures, Lightspeed and Nvidia, Mistral said.\n\nASML's shares were up 1 per cent in early Amsterdam trading, giving it a market value of 268 billion euros.\n\n($1 = 0.8495 euros)",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/business/mistral-ai-raises-17-billion-euros-asml-becomes-its-top-shareholder-5339461",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "NVIDIA Unveils Rubin CPX: A New Class of GPU Designed for Massive-Context Inference",
      "content": "News Summary:\n\nThe NVIDIA Rubin CPX GPU is purpose-built to handle million-token coding and generative video applications.\n\nThe NVIDIA Vera Rubin NVL144 CPX platform packs 8 exaflops of AI performance and 100TB of fast memory in a single rack.\n\nCompanies can monetize at an unprecedented scale, with $5B in token revenue for every $100M invested.\n\nAI innovators like Cursor, Runway and Magic are exploring how Rubin CPX can accelerate their applications.\n\nSANTA CLARA, Calif., Sept. 09, 2025 (GLOBE NEWSWIRE) -- AI Infra Summit -- NVIDIA® today announced NVIDIA Rubin CPX, a new class of GPU purpose-built for massive-context processing. This enables AI systems to handle million-token software coding and generative video with groundbreaking speed and efficiency.\n\nRubin CPX works hand in hand with NVIDIA Vera CPUs and Rubin GPUs inside the new NVIDIA Vera Rubin NVL144 CPX platform. This integrated NVIDIA MGX system packs 8 exaflops of AI compute to provide 7.5x more AI performance than NVIDIA GB300 NVL72 systems, as well as 100TB of fast memory and 1.7 petabytes per second of memory bandwidth in a single rack. A dedicated Rubin CPX compute tray will also be offered for customers looking to reuse existing Vera Rubin 144 systems.\n\n“The Vera Rubin platform will mark another leap in the frontier of AI computing — introducing both the next-generation Rubin GPU and a new category of processors called CPX,” said Jensen Huang, founder and CEO of NVIDIA. “Just as RTX revolutionized graphics and physical AI, Rubin CPX is the first CUDA GPU purpose-built for massive-context AI, where models reason across millions of tokens of knowledge at once.”\n\nNVIDIA Rubin CPX enables the highest performance and token revenue for long-context processing — far beyond what today’s systems were designed to handle. This transforms AI coding assistants from simple code-generation tools into sophisticated systems that can comprehend and optimize large-scale software projects.\n\nTo process video, AI models can take up to 1 million tokens for an hour of content, pushing the limits of traditional GPU compute. Rubin CPX integrates video decoder and encoders, as well as long-context inference processing, in a single chip for unprecedented capabilities in long-format applications such as video search and high-quality generative video.\n\nBuilt on the NVIDIA Rubin architecture, the Rubin CPX GPU uses a cost‑efficient, monolithic die design packed with powerful NVFP4 computing resources and is optimized to deliver extremely high performance and energy efficiency for AI inference tasks.\n\nAdvancements Offered by Rubin CPX\n\nRubin CPX delivers up to 30 petaflops of compute with NVFP4 precision for the highest performance and accuracy. It features 128GB of cost-efficient GDDR7 memory to accelerate the most demanding context-based workloads. In addition, it delivers 3x faster attention capabilities compared with NVIDIA GB300 NVL72 systems — boosting an AI model’s ability to process longer context sequences without a drop in speed.\n\nRubin CPX is offered in multiple configurations, including the Vera Rubin NVL144 CPX, that can be combined with the NVIDIA Quantum‑X800 InfiniBand scale-out compute fabric or the NVIDIA Spectrum-X™ Ethernet networking platform with NVIDIA Spectrum-XGS Ethernet technology and NVIDIA ConnectX®-9 SuperNICs™. Vera Rubin NVL144 CPX enables companies to monetize at an unprecedented scale, with $5 billion in token revenue for every $100 million invested.\n\nIndustry Leaders Look to Rubin CPX\n\nAI innovators are exploring how Rubin CPX can accelerate their applications, ranging from large-scale software development to the analysis of dynamic visual content to better understand moving images.\n\nCursor, an AI-powered software company that offers an advanced code editor, sees the benefits of Rubin CPX to boost developer productivity with intelligent code generation and collaborative tools directly in the coding environment.\n\n“With NVIDIA Rubin CPX, Cursor will be able to deliver lightning-fast code generation and developer insights, transforming software creation,” said Michael Truell, CEO of Cursor. “This will unlock new levels of productivity and empower users to ship ideas once out of reach.”\n\nRunway, an American generative AI company, will use NVIDIA technologies to enable creators to produce cinematic content and sophisticated visual effects with unmatched scale and efficiency.\n\n“Video generation is rapidly advancing toward longer context and more flexible, agent-driven creative workflows,” said Cristóbal Valenzuela, CEO of Runway. “We see Rubin CPX as a major leap in performance, supporting these demanding workloads to build more general, intelligent creative tools. This means creators — from independent artists to major studios — can gain unprecedented speed, realism and control in their work.”\n\nMagic is an AI research and product company developing foundation models to power AI agents that can automate software engineering.\n\n“With a 100-million-token context window, our models can see a codebase, years of interaction history, documentation and libraries in context without fine-tuning,” said Eric Steinberger, CEO of Magic. “This enables users to coach the agent at test time through conversation and access to their environments, bringing us closer to autonomous agentic experiences. Using a GPU like NVIDIA Rubin CPX greatly accelerates our compute workloads.”\n\nSoftware Support\n\nNVIDIA Rubin CPX will be supported by the complete NVIDIA AI stack — from accelerated infrastructure to enterprise‑ready software. The NVIDIA Dynamo platform efficiently scales AI inference, dramatically boosting throughput while cutting response times and model serving costs.\n\nThe processors will be able to run the latest in the NVIDIA Nemotron™ family of multimodal models that provide state-of-the-art reasoning for enterprise-ready AI agents. For production-grade AI, Nemotron models can be delivered with NVIDIA AI Enterprise, a software platform that includes NVIDIA NIM ™ microservices as well as AI frameworks, libraries and tools that enterprises can deploy on NVIDIA-accelerated clouds, data centers and workstations.\n\nBuilt on decades of innovation, the Rubin platform extends NVIDIA’s developer ecosystem — with NVIDIA CUDA‑X ™ libraries, a community of over 6 million developers and nearly 6,000 CUDA applications.\n\nAvailability\n\nNVIDIA Rubin CPX is expected to be available at the end of 2026.\n\nLearn more by watching NVIDIA Vice President of Hyperscale and High-Performance Computing Ian Buck’s keynote at AI Infra Summit on Sept. 9 at 10am PT.\n\nAbout NVIDIA\n\nNVIDIA (NASDAQ: NVDA) is the world leader in accelerated computing.\n\nFor further information, contact:\n\nKristin Uchiyama\n\nNVIDIA Corporation\n\n+1-408-313-0448\n\nkuchiyama@nvidia.com\n\nCertain statements in this press release including, but not limited to, statements as to: Vera Rubin systems continuing to deliver extraordinary performance and efficiency; with Rubin CPX, building a GPU uniquely suited for million-token context processing, cutting the cost of inference and unlocking advanced capabilities for developers and creators everywhere; the benefits, impact, performance, and availability of NVIDIA’s products, services, and technologies; expectations with respect to NVIDIA’s third party arrangements, including with its collaborators and partners; expectations with respect to technology developments; and other statements that are not historical facts are forward-looking statements within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended, which are subject to the “safe harbor” created by those sections based on management’s beliefs and assumptions and on information currently available to management and are subject to risks and uncertainties that could cause results to be materially different than expectations. Important factors that could cause actual results to differ materially include: global economic and political conditions; NVIDIA’s reliance on third parties to manufacture, assemble, package and test NVIDIA’s products; the impact of technological development and competition; development of new products and technologies or enhancements to NVIDIA’s existing product and technologies; market acceptance of NVIDIA’s products or NVIDIA’s partners’ products; design, manufacturing or software defects; changes in consumer preferences or demands; changes in industry standards and interfaces; unexpected loss of performance of NVIDIA’s products or technologies when integrated into systems; and changes in applicable laws and regulations, as well as other factors detailed from time to time in the most recent reports NVIDIA files with the Securities and Exchange Commission, or SEC, including, but not limited to, its annual report on Form 10-K and quarterly reports on Form 10-Q. Copies of reports filed with the SEC are posted on the company’s website and are available from NVIDIA without charge. These forward-looking statements are not guarantees of future performance and speak only as of the date hereof, and, except as required by law, NVIDIA disclaims any obligation to update these forward-looking statements to reflect future events or circumstances.\n\nMany of the products and features described herein remain in various stages and will be offered on a when-and-if-available basis. The statements above are not intended to be, and should not be interpreted as a commitment, promise, or legal obligation, and the development, release, and timing of any features or functionalities described for our products is subject to change and remains at the sole discretion of NVIDIA. NVIDIA will have no liability for failure to deliver or delay in the delivery of any of the products, features or functions set forth herein.\n\n© 2025 NVIDIA Corporation. All rights reserved. NVIDIA, the NVIDIA logo and all other NVIDIA trademarks mentioned herein are trademarks and/or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated. Features, pricing, availability and specifications are subject to change without notice.\n\nA photo accompanying this announcement is available at https://www.globenewswire.com/NewsRoom/AttachmentNg/3266451c-18af-4394-8290-db8d9ae220b4",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/09/3147154/0/en/NVIDIA-Unveils-Rubin-CPX-A-New-Class-of-GPU-Designed-for-Massive-Context-Inference.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia is the world's most valuable company. Why does CEO Jensen Huang barely make the list of the 10 wealthiest people?",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/adc86d3e90150c71",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "A Weak Jobs Report Implies Lower Rates Ahead",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/09/a-weak-jobs-report-implies-lower-rates-ahead/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "ASML invests $1.5B in French AI startup Mistral, forming European tech alliance",
      "content": "LONDON (AP) — ASML, a leading Dutch maker of chipmaking gear, is investing 1.3 billion euros ($1.5 billion) into French artificial intelligence startup Mistral AI, the two said on Tuesday, announcing a partnership between two of Europe's top technology companies.\n\nASML Holding, based in Veldhoven, Netherlands, holds an important role in the global tech industry because it makes equipment used to manufacture semiconductors, including the most advanced microchips used for cutting-edge AI systems.\n\nMistral was founded two years ago in Paris by former researchers at Google DeepMind and Meta Platforms and quickly became a European tech darling.\n\nThe partnership underscores Europe's efforts to reduce exposure to American technology. President Donald Trump's increasingly hostile attitude to European Union tech regulations has fueled debate about whether the continent is too dependent on services provided by U.S. tech companies such as cloud computing and mobile operating systems.\n\nMistral makes the Le Chat chatbot but it has struggled to keep up with American AI companies like ChatGPT-maker OpenAI, and Chinese rivals like DeepSeek.\n\nASML's chipmaking equipment can cost hundreds of millions of dollars but the U.S. government has blocked it from selling its most advanced machines to China.\n\nThe deal gives ASML an 11% stake in Mistral, and values the startup at about 11.7 billion euros. The 1.3 billion euro investment is part of a larger funding round worth 1.7 billion euros, which also involves venture capital firms and chipmaker Nvidia.\n\nMistral CEO Arthur Mensch said in a press release that the alliance combines Mistral's “frontier AI expertise with ASML’s unmatched industrial leadership and most sophisticated engineering capabilities.\"\n\n“Together, we will accelerate technological progress across the global semiconductor and AI value chain,\" Mensch said.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/asml-invests-1-5b-french-143653959.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Deploy Scalable AI Inference with NVIDIA NIM Operator 3.0.0",
      "content": "AI models, inference engine backends, and distributed inference frameworks continue to evolve in architecture, complexity, and scale. With the rapid pace of change, deploying and efficiently managing AI inference pipelines that support these advanced capabilities becomes a critical challenge.\n\nNVIDIA NIM Operator is designed to help you scale intelligently. It enables Kubernetes cluster administrators to operate the software components and services necessary to run NVIDIA NIM inference microservices for the latest LLMs and multimodal AI models, including reasoning, retrieval, vision, speech, biology, and more.\n\nThe latest release of NIM Operator 3.0.0 introduces expanded capabilities to simplify and optimize the deployment of NVIDIA NIM microservices and NVIDIA NeMo microservices across Kubernetes environments. NIM Operator 3.0.0 supports efficient resource utilization and integrates seamlessly with your existing Kubernetes infrastructure, including KServe deployments.\n\nNVIDIA customers and partners have been using the NIM Operator to efficiently manage inference pipelines for a variety of applications and AI agents, including chatbots, agentic RAG, and virtual drug discovery.\n\nNVIDIA has recently collaborated with Red Hat to enable NIM deployment on KServe with the NIM Operator. “Red Hat contributed to the NIM Operator open source GitHub repo to enable NVIDIA NIM deployment on KServe,” said Red Hat Director of Engineering Babak Mozaffari. “This feature allows the NIM Operator to deploy NIM microservices that benefit from KServe lifecycle management and simplifies scalable NIM deployment using NIM service. Native KServe support in the NIM Operator also allows users to benefit from model caching with NIM cache and leverage NeMo capabilities like NeMo Guardrails for building Trusted AI for all your KServe Inference endpoints.”\n\nThis post explains new capabilities in the NIM Operator 3.0.0 release, including:\n\nFigure 1. NIM Operator architecture\n\nFlexible NIM deployment: Multi-LLM compatible and multi-node\n\nNIM Operator 3.0.0 adds support for easy, fast NIM deployment. You can use it with a domain-specific NIM—such as those for biology, speech, or retrieval—or various NIM deployment options, including multi-LLM compatible, or multi-node.\n\nMulti-LLM compatible NIM deployment: Deploy diverse models with custom weights from sources like NVIDIA NGC, Hugging Face, or local storage. Use the NIM cache custom resource definition (CRD) to download weights to PVCs and the NIM service CRD to manage deployment, scaling, and ingress.\n\nDeploy diverse models with custom weights from sources like NVIDIA NGC, Hugging Face, or local storage. Use the NIM cache custom resource definition (CRD) to download weights to PVCs and the NIM service CRD to manage deployment, scaling, and ingress. Multi-node NIM deployment addresses the challenge of deploying massive LLMs that cannot fit on a single GPU or need to run on multiple GPUs and potentially on multiple nodes. NIM Operator supports caching for multi-node NIM deployment using the NIM cache CRD, and deploying them using the NIM service CRD on Kubernetes with LeaderWorkerSets (LWS).\n\nNote that the multi-node NIM deployment without GPUDirect RDMA may result in frequent restarts of LWS leader and worker pods due to model shard loading timeouts. Using fast network connectivity such as IPoIB or ROCE is highly recommended and can be easily configured through the NVIDIA Network Operator.\n\nFigure 2 shows the deployment of large language models (LLMs) from the Hugging Face library on Kubernetes using the NVIDIA NIM Operator as a multi-LLM NIM deployment. It specifically demonstrates deploying the Llama 3 8B Instruct model, including service and pod status verification, followed by a curl command to send a request to the service.\n\nFigure 2. Multi-LLM deployment of the Llama 3 8B Instruct model using NIM Operator\n\nEfficient GPU utilization with DRA\n\nDRA is a built-in Kubernetes feature that simplifies GPU management by replacing traditional device plugins with a more flexible and extensible approach. DRA enables users to define GPU device classes, request GPUs based on those classes, and filter them according to workload and business needs.\n\nNIM Operator 3.0.0 supports DRA under technology preview by configuring ResourceClaim and ResourceClaimTemplate on NIM Pod through both the NIM service CRD and NIM Pipeline CRD. You can either create and attach your own claims or let the NIM Operator create and manage them automatically.\n\nThe NIM Operator DRA supports:\n\nFull GPU and MIG usage\n\nGPU sharing through time slicing by assigning the same claim to multiple NIM services\n\nNote: This feature is currently available as a technology preview, with full support available soon.\n\nFigure 3 demonstrates the deployment of Llama 3 8B Instruct NIM using Kubernetes DRA with NIM Operator. Users can define a resource claim in a NIM service to request specific hardware attributes such as GPU architecture and memory, and interact with the deployed LLM using curl .\n\nFigure 3. Deployment of Llama 3 8B Instruct NIM using Kubernetes DRA with NIM Operator\n\nSeamless deployment on KServe\n\nKServe is a widely adopted open source inference serving platform used by many partners and customers. NIM Operator 3.0.0 supports both raw and serverless deployments on KServe by configuring the InferenceService custom resource to manage deployment, upgrades, and autoscaling of NIM. NIM Operator simplifies the deployment process by automatically configuring all required environment variables and resources in the InferenceService CRDs.\n\nThis integration delivers two additional benefits:\n\nIntelligent caching with NIM cache to reduce initial inference time and autoscaling latency, resulting in faster and more responsive deployments.\n\nNeMo microservices support for evaluation, guardrails, and customization to enhance AI systems for latency, accuracy, cost, and compliance.\n\nFigure 4 shows the deployment of the Llama 3.2 1B Instruct NIM on KServe using NIM Operator. Two distinct deployment methodologies are shown: RawDeployment and Serverless. The Serverless deployment incorporates autoscaling functionality through K8s annotation. Both strategies use a curl command to test the responses of the NIM.\n\nFigure 4. Deployment of the Llama 3.2 1B Instruct NIM on KServe using NIM Operator with both RawDeployment and Serverless methodologies\n\nGet started scaling AI inference with NIM Operator 3.0.0\n\nNVIDIA NIM Operator 3.0.0 makes deploying scalable AI inference easier than ever. Whether you’re working with multi-LLM compatible or multi-node NIM deployment, optimizing GPU usage with DRA, or deploying on KServe, this release enables you to build high-performance, flexible, and scalable AI applications.\n\nBy automating the deployment, scaling, and lifecycle management of both NVIDIA NIM and NVIDIA NeMo microservices, NIM Operator makes it easier for enterprise teams to adopt AI workflows. This effort aligns with making AI workflows easy to deploy with NVIDIA AI Blueprints, enabling quick movement to production. The NIM Operator is part of NVIDIA AI Enterprise, providing enterprise support, API stability, and proactive security patching.\n\nGet started through NGC or from the NVIDIA/k8s-nim-operator open source GitHub repo. For technical questions on installation, usage, or issues, file an issue on the NVIDIA/k8s-nim-operator GitHub repo.",
      "source": "Nvidia.com",
      "url": "https://developer.nvidia.com/blog/deploy-scalable-ai-inference-with-nvidia-nim-operator-3-0-0/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "PsiQuantum valued at $7 billion in latest funding round, teams up with Nvidia",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_27654e15-a66d-47f0-bbab-84bb2e3dec10",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Elon Musk Was Just Unseated as the World’s Richest Person",
      "content": "Oracle Chairman Larry Ellison is having a good morning.\n\nOracle’s stock is up more than 42% on Wednesday, thanks to an earnings call on Tuesday that left investors stunned.\n\nThe company missed earnings and revenue estimates, but the forward looking guidance alone was apparently good enough to get investors to rally around it. A bulk of that reaction had to do with the revenue that AI computing demand was expected to bring to Oracle’s cloud infrastructure service.\n\nThe shares skyrocketed in response. Oracle’s stock is now on pace to have its largest single session surge since the dot-com boom, according to CNBC.\n\nWith the current surge in shares, Ellison has increased his wealth by more than $100 billion, thanks to the roughly 1.16 billion shares he owns. This meteoric rise grabbed him the title of the richest person on Earth from the former title holder, Elon Musk, according to the Bloomberg Billionaires Index.\n\nAs of Tuesday, Ellison’s current total fortune was worth $295 billion, having increased by $100 billion in worth in just the past year. Today’s additional increase has catapulted him to a staggering $389 billion, surpassing Elon Musk’s whopping $384 billion fortune.\n\nMusk was first named the richest man in the world in 2021, and has since been up and down on the list. He has held the title consistently since last year and briefly became the first person to surpass $400 billion net worth in December. Although Ellison has overtaken him on the list, Musk might reverse that yet again soon. Musk is facing the potential of becoming the world’s first trillionaire, that is if the massive and unprecedented proposed pay package plan by the Tesla board gets approved by shareholders.\n\nOracle’s AI success story\n\nLarry Ellison co-founded Oracle in the late 1970s with the CIA as an early customer. Decades down the line, the database software company now specializes in AI-first cloud computing and competes with other giants like Microsoft’s Azure, Alphabet’s Google Cloud, and Amazon’s AWS. It’s the aggressively positive and AI-driven outlook for its cloud infrastructure business that has led to investor delight and the 81-year-old Ellison is benefiting handsomely from it.\n\nAlthough the revenue estimates were down, the company said it was expecting to collect more than half a trillion dollars extra thanks to four multi-billion-dollar contracts it signed in the past quarter. At the company’s earnings call, CEO Safra Catz mentioned OpenAI, Meta, Nvidia, AMD, and Elon Musk’s xAI as some of the company it has “significant cloud contracts with.”\n\nCompany executives shared that they are expecting to finalize even more multi-billion-dollar deals in the near future.\n\nOracle, and Ellison, are hell-bent on AI. The company recently made headlines for an alleged plan to spend more than $1 billion a year to run a new data center in Texas on gas generators rather than wait for approval and infrastructure to pull the electricity from the local grid. Oracle is also one of the partners in the Trump administration’s ambitious AI project Stargate.\n\nCloud computing is the hot name in AI earnings\n\nCloud computing might be one of the clearest early winners of the AI hype. AI companies are scouring for more computing capacity as they try to compete with each other and scale operations, and they are willing to spend a hefty amount of money for it. Enter cloud infrastructure providers, like Oracle and Microsoft, that provide computing power for large AI models. Both the companies showed a meteoric stock increase after their recent earnings report.\n\nIn its latest earnings report in July, Microsoft reported that sales were up 18% from last year and that revenue for its cloud computing platform Azure had surpassed $75 billion this year, up 34% from last. Despite these numbers accompanying Microsoft’s largest ever quarterly capital expenditure forecast, the market went crazy for it. The shares jumped and the tech giant briefly became the second-ever company to hit $4 trillion market valuation.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/elon-musk-was-just-unseated-as-the-worlds-richest-person-2000656741",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Despite cutting the gags, Borderlands 4's PC specs say it still needs 100GB of SSD space",
      "content": "Two days before launch, Borderlands 4 has its PC system requirements. They’re generally on the higher side without teetering over into full-on tech demo lunacy – the RTX 2070 is a minimum-spec graphics card, for instance – though anyone with a smaller SSD will need to make room for the looty FPS sequel’s bumper-size 100GB storage requirement.\n\nI have mixed feelings about this. On the one hand, gargantuan install sizes are kind of obnoxious (even the infamously bloated Call of Duty agrees), and are partly caused by merely visual, high-resolution textures that we increasingly need madly expensive GPUs to even enable. Or at least, to enable without simultaneously committing framerateicide.\n\nOn the other hand, 100 is a very round and satisfying number. Just look at it. Way better than 112 or some garbage. I do wonder if anyone working in Gearbox’s gigabyte dieting department saw it was possible to compress it down to 99GB, potentially avoiding the shock of entering the triple digits, but left it at 100GB just because it’s vaguely nicer. I suspect I’d do the same.\n\nAnyway, here’s the hardware:\n\nBorderlands 4 minimum PC specs\n\nOS: Windows 10 / 11\n\nWindows 10 / 11 CPU: Intel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum)\n\nIntel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum) RAM: 16GB\n\n16GB GPU: Nvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum)\n\nNvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum) Storage: 100GB (SSD required)\n\nBorderlands 4 recommended PC specs\n\nOS: Windows 10 / Windows 11\n\nWindows 10 / Windows 11 CPU: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nIntel Core i7-12700 / AMD Ryzen 7 5800X RAM: 32GB\n\n32GB GPU: Nvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nNvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580 Storage: 100GB (SSD required)\n\nSolid state hungriness aside, it’s a bit strange seeing the Arc B580 in the recommended tier, alongside the RTX 3080 and RX 6800 XT – it’s a good little budget card but not on the same level as those two older, yet bonafide high-end GPUs. Though maybe that means Borderlands 4 performs better-than-recommended on this Nvidia/AMD kit?\n\nAlso, 2K’s post doesn’t mention it specifically, but DLSS 4 Multi Frame Generation is supported as well. This needs a GeForce RTX 50 series card to operate at full pelt, with RTX 40 models making do with DLSS 3-style 2x frame gen.\n\nI’m generally in the 'wait and see how it is' camp on Fourderlands, with its new planet and its many billions of randomly generated firearms, having previously been interested enough to mulch through Borderlands 3 with mates but jointly concluding it wasn’t worth our time. This new one is something of a reset, with its lead writer Taylor Clark claiming it won’t have as many jokes. Which is, at once, likely an improvement and also a weird thing to make a selling point of. B4's out on September 12th.",
      "source": "Rock Paper Shotgun",
      "url": "https://www.rockpapershotgun.com/despite-cutting-the-gags-borderlands-4s-pc-specs-say-it-still-needs-100gb-of-ssd-space",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "I pivoted from software engineering to AI product management. Here are the 3 strategies I used to help me land the job.",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nThis as-told-to essay is based on a conversation with Phani Sai Ram Munipalli, a 28-year-old full-time AI/tech product manager from Santa Clara, California. It's been edited for length and clarity.\n\nI worked for four years as a full-time software engineer — two years at IBM and two years at Walmart Global Tech — after completing my undergraduate program in India in 2017.\n\nIn July 2022, I left software engineering and chose to shift my career path to compete for an AI/tech product management role at Walmart in the US, even though I had little experience in that field.\n\nMy career change wasn't motivated by the idea of potentially making more money — I believe in technology that can change lives.\n\nThis journey began not with a job application but with a realization in 2022\n\nRight as ChatGPT was introduced to the world, I knew a massive shift was coming, and my technical background was my unique entry point into the AI talent wars.\n\nI started my master's program in computer software engineering at San Jose State University in August 2022. During my master's summer, I did a product management internship at Walmart. I graduated from with my degree in May 2024 and joined Walmart as a full-time product manager in July 2024.\n\nI love coding and still do it for my side projects, but I wanted to go beyond just writing code. I wanted to understand what products can be built leveraging AI, who the users are, and how it's helping them.\n\nThis recognition led to a self-assessment and a personal road map to create my own AI-centric playbook around three core strategies.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\n1. I rewired my brain for AI product thinking\n\nMy technical background helped me grasp AI concepts, but I needed to learn how to think like an AI product leader. In 2023, I took on an additional role at my university as an AI research assistant in conversational AI.\n\nTo add to my AI expertise and rewire my brain for AI product thinking, I went all in on a self-education sprint. I listened to podcasts like Lenny's Podcast and the Nvidia AI Podcast, which focus on the complexities of productionizing AI and learning the crucial lesson that AI is never the product itself — solving a user's problem is.\n\nI also completed Google's \"Responsible AI: Applying AI Principles with Google Cloud\" credential in December 2023 and the AI Product Management Bootcamp led by Marily Nika, a former Google AI product manager, in April 2024.\n\nFinally, I put theory into practice by building several web apps — including LinkPlus, VibeCard, and SafeWord AI — using both OpenAI's and Google's Gemini APIs, teaching myself the real-world challenges of prompt engineering and leveraging LLMs.\n\n2. I ditched popular frameworks in interviews\n\nWhen it came time to interview for my summer product management internship at Walmart, I knew that reciting standard product frameworks would be a failing strategy.\n\nI was an underdog among 20+ intern candidates from top schools. I knew I had to prove myself. My differentiator wasn't a textbook answer; it was the portfolio of AI projects I'd built and the platform I'd created.\n\nInstead of trying to impress with pure technical knowledge, I focused on translating it. I used storytelling — especially the \"Hero's Journey\" technique in my presentations — to craft compelling narratives explaining how these AI solutions could solve real, human problems for Walmart's gig drivers.\n\nThis approach — proving I could not only understand AI but also build with it and communicate its value — is what landed me the internship at Walmart. This focus on bridging the gap between complex tech and user needs was so successful that it also secured me a full-time return offer at Walmart for my current position, which I started in July 2024.\n\n3. I built a platform to give first and networked second\n\nI believed an AI-focused product manager should have their own product, so in March 2023, I started a podcast, The Hustle Chapters, and a newsletter, Phani's Product.\n\nMy podcast platform completely flipped the networking dynamic. Instead of asking for 15-minute coffee chats, I invited directors and founders onto my show, offering them value first.\n\nI hosted 21 builders from the AI space, learning directly from them about the myths of building AI. This approach built genuine connections and directly led to a spring internship offer from VComply in 2024.\n\nThen — even after securing my role at Walmart — I took on a subsequent spring internship focused entirely on the complex challenge of productizing an LLM-based application for enterprise users. I experimented with running LLMs on my local machine and then documented the entire setup process in a technical guide for my newsletter.\n\nThis trial-by-fire experience — tackling the nuances of bringing cutting-edge LLMs into a real-world business context — gave me an even deeper level of practical knowledge to bring to my full-time position.\n\nI also regularly published one-pagers and newsletters analyzing how Big Tech companies use AI and data to create superior customer experiences, building a small but engaged audience of tech professionals.\n\nThis three-pronged approach helped me pivot successfully\n\nI've spent a year on my team full-time, solving fascinating problems for gig drivers in Walmart's Last Mile Delivery ecosystem. I work in the realm of AI, LLM, and ML in product management — a complete gearshift from my former full-time roles as a software engineer.\n\nUltimately, my journey is a playbook for forging your own path, proving that the right strategy and mindset about pivoting into AI or another area are more powerful than a traditional background.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/how-pivoted-software-engineering-ai-product-management-2025-9",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Why Nvidia Stock Jumped Today",
      "content": "Prime Minister Sébastien Lecornu’s sudden resignation deepens France’s political instability, spooking markets and complicating President Macron’s government ahead of budget battles.\n\nMarket Summary Markets show cautious optimism as U.S. stock futures edge higher driven by hopes for Federal Reserve rate cuts and AI sector momentum. However, geopolitical tensions and a prolonged U.S. government shutdown sustain volatility. Japan stocks rally on leadership changes, while French political upheaval sparks selloffs in Europe. Bitcoin's record highs reflect growing safe-haven demand amidst uncertainty.\n\nFifth Third Strikes $10.9 Billion Deal to Acquire Comerica Fifth Third to Absorb Comerica in $10.9 Billion Stock Deal Fifth Third Bancorp confirms $10.9 billion acquisition of Comerica, marking a major consolidation in U.S. regional banking. The all-stock deal aims to expand market presence amid banking sector challenges.\n\nFigure of the Day 125,000 - Bitcoin's new record price in USD, signaling heightened crypto market interest amid economic uncertainty.\n\nFrench PM Lecornu Resigns Hours After Cabinet Reveal New French PM Quits After Less Than A Month in Office French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after unveiling his cabinet. This resignation deepens France’s political crisis with markets reacting negatively.\n\nGovernment Shutdown Hits Second Week with No Breakthrough Shutdown Stalemate Promises Prolonged Federal Gridlock The U.S. federal government shutdown extends beyond a week, with lawmakers at an impasse. Threats of mass federal layoffs mount, fueling market uncertainty and increasing economic pressure.\n\nBullish SpaceX Secures $714M Pentagon Contract, Edging Out Blue Origin Elon Musk’s SpaceX wins major defense contracts, reinforcing its dominance in military space launches and solidifying government partnerships. More on benzinga.com\n\nJapan Stocks Rally as Takaichi Takes Ruling Party Helm Nikkei Inches to Record High on Takaichi’s Pro-Stimulus Win Japan’s stock market soars as ultra-conservative Sanae Takaichi wins the ruling party leadership, triggering yen weakness. Investors expect pro-stimulus policies and possible BOJ monetary shifts.\n\nBitcoin Surges Past $125,000 Amid Market Turmoil Crypto Rally Continues with Bitcoin at New All-Time High Bitcoin hits new record highs surpassing $125,000 despite market volatility. Investors flock to cryptocurrencies as safe havens amid geopolitical tensions and U.S. government shutdown uncertainty.\n\nBearish Aston Martin Shares Tank as Tariff Pressures Slash Profit Outlook Luxury carmaker Aston Martin issues profit warning amid rising U.S. tariffs and supply chain woes, triggering a steep stock selloff. More on businessinsider.com\n\nAston Martin Shares Dive on New Profit Warning — Tariff Drag Lingers Aston Martin Slashes Profits Amid US Tariff Turmoil Aston Martin’s shares plunge after issuing fresh profit warnings citing ongoing tariff impacts and supply chain challenges. The luxury carmaker seeks proactive support amid uncertain US trade policies.\n\nSpaceX Lands $714 Million Pentagon Contract, Beating Blue Origin SpaceX outpaces Blue Origin by securing $714 million Pentagon contract for military space missions, bolstering Elon Musk’s dominance in U.S. defense space operations.\n\nRegulatory Impact EU financial regulator ESMA moves to centralize oversight of stock exchanges, crypto firms, and clearing houses, aiming to boost market stability across member states.\n\nQualtrics to Acquire Press Ganey in $6.8 Billion Healthcare Deal Qualtrics plans $6.8 billion acquisition of Press Ganey Forsta to strengthen healthcare technology footprint. The deal includes cash and debt components, signaling strategic expansion.\n\nQuote \"The political instability in France is weighing heavily on markets, signaling uncertain times ahead for investors and policymakers alike.\"\n\n— Senior European Market Strategist\n\nCourt Halts Trump’s National Guard Deployment to Oregon U.S. judges temporarily block Trump administration’s National Guard deployments to Oregon and Portland amid legal battles. States challenge federal troop movements amid rising tensions.\n\n2025 Nobel Prize in Medicine Honors Immunology Trailblazers Immunology Pioneers Share Nobel Prize for Medicine 2025 Nobel Prize in Medicine awarded to pioneers in immunology for breakthroughs in immune system research, advancing understanding of physiological disease mechanisms.\n\nESMA Pushes for Unified EU Oversight of Exchanges and Crypto EU’s financial watchdog plans centralized oversight of stock exchanges, crypto firms, and clearing houses to harmonize regulation across the bloc and enhance capital market stability.\n\nOPEC+ Approves Small Oil Production Hike, Markets React OPEC+ Output Raised Slightly; Price Sentiment Wavers OPEC+ agrees to a modest 137,000 barrel per day oil output increase in November amid concerns of oversupply. Market remains cautious as global economic outlook loosens.\n\nTesla Reports Record Q3 Deliveries Amid Emerging Headwinds Tesla sets record Q3 vehicle deliveries but faces emerging operational challenges. Positive growth outlook is tempered by supply chain concerns and market pressures.\n\nStock Futures Rise on Fed Rate-Cut Hopes and AI Buzz Wall Street Futures Up as Investors Eye AI and Policy Moves Wall Street stock futures edge mostly higher, supported by hopes of Fed rate cuts and rapid AI sector growth despite the shadow of a prolonged U.S. government shutdown.\n\nHong Kong Stocks Slide as U.S. Shutdown Hurts Sentiment Hong Kong stocks dip due to dampened investor sentiment linked to U.S. government shutdown; demand rises for safe-haven assets like gold amid global uncertainties.\n\nAmazon Lets Prime Shoppers Add Last-Minute Items to Delivery Amazon enhances its Prime offering with 'Add to Delivery' feature allowing last-minute additions to shipments, aiming to boost holiday shopping convenience.\n\nChina Unveils Stealth Fighter Jet Development Footage Powerful jet fighter development footage emerges from China, positioning the country as the global leader in stealth combat aircraft alongside the U.S.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/db3bfaea0ef02c73",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "AI Is Coming for YouTube Creators",
      "content": "Editor’s note: This analysis is part of The Atlantic’s investigation into how YouTube videos are taken to train AI tools. You can use the search tool directly here, to see whether videos you’ve created or watched are included in the data sets. This work is part of AI Watchdog, The Atlantic’s ongoing investigation into the generative-AI industry.\n\nWhen Jon Peters uploaded his first video to YouTube in 2010, he had no idea where it would lead. He was a professional woodworker running a small business who decided to film himself making a dining table with some old legs he had found in a barn. It turned out that people liked his candid style, and as he posted more videos, a fan base began to grow. “All of a sudden there’s people who appreciate the work I’m doing,” he told me. “The comments were a motivator.” Fifteen years later, his channel has more than 1 million subscribers. Sometimes he gets photos of people in their shops, following his guidance from a big TV on the wall—most of his viewers, Peters told me, are woodworkers looking to him for instruction.\n\nBut Peters’s channel could soon be obsolete, along with millions of other videos created by people who share their expertise and advice on YouTube. Over the past few months, I’ve discovered more than 15.8 million videos from more than 2 million channels that tech companies have, without permission, downloaded to train AI products. Nearly 1 million of them, by my count, are how-to videos. You can find these videos in at least 13 different data sets distributed by AI developers at tech companies, universities, and research organizations, through websites such as Hugging Face, an online AI-development hub.\n\nIn most cases the videos are anonymized, meaning that titles and creator names are not included. I was able to identify the videos by extracting unique identifiers from the data sets and looking them up on YouTube—similar to the process I followed when I revealed the contents of the Books3, OpenSubtitles, and LibGen data sets. You can search the data sets using the tool below, typing in channel names like “MrBeast” or “James Charles,” for example.\n\n(A note for users: Just because a video appears in these data sets does not mean it was used for training by AI companies, which could choose to omit certain videos when developing their products.)\n\nTo create AI products capable of generating video, developers need huge quantities of videos, and YouTube has become a common source. Although YouTube does offer paying subscribers the ability to download videos and watch them through the company’s app whenever they’d like, this is something different: Video files are being ripped from YouTube en masse and saved in files that are then fed to AI algorithms. This kind of downloading violates the platform’s terms of service, but many tools allow AI developers to download videos in this way. YouTube appears to have done little, if anything, to stop the mass downloading, and the company did not respond to my request for comment.\n\nNot all YouTube videos are copyrighted (and some are uploaded by people who don’t own the copyrights), but many are. Unauthorized copying or distribution of those videos is illegal, but whether AI training constitutes a form of copying or distribution is still a question being debated in many ongoing lawsuits. Tech companies have argued that training is a “fair use” of copyrighted work, and some judges have disagreed in their responses. How the courts ultimately apply the law to this novel technology could have massive consequences for creators’ motivations to post their work on YouTube and similar platforms—if tech companies are able to continue taking creators’ work to build AI products that compete with them, then creators may have little choice but to stop sharing.\n\nGenerative-AI tools are already producing videos that compete with human-made work on YouTube. AI-generated history videos with hundreds of thousands of views and many inaccuracies are drowning out fact-checked, expert-produced content. Popular music-remix videos are frequently created using this technology, and many of them perform better than human-made videos.\n\nThe problem extends far beyond YouTube, however. Most modern chatbots are “multimodal,” meaning they can respond to a question by creating relevant media. Google’s Gemini chatbot, for instance, will produce short clips for paying users. Soon, you may be able to ask ChatGPT or another generative-AI tool about how to build a table from found legs and get a custom how-to video in response. Even if that response isn’t as good as any video Peters would make, it will be immediate, and it will be tailor-made to your specifications. The online-publishing business has already been decimated by text-generation tools; video creators should expect similar challenges from generative-AI tools in the near future.\n\nMany major tech companies have used these data sets to train AI, according to research papers I’ve read and AI developers I’ve spoken with. The group includes Microsoft, Meta, Amazon, Nvidia, Runway, ByteDance, Snap, and Tencent. I reached out to each of these companies to ask about their use of these data sets. Only Meta, Amazon, and Nvidia responded. All three said they “respect” content creators and believe that their use of the work is legal under existing copyright law. Amazon also shared that, where video is concerned, it is currently focused on developing ways to generate “compelling, high-quality advertisements from simple prompts.”\n\nWe can’t be certain whether all these companies will use the videos to create for-profit video-generating tools. Some of the work they’ve done may be simply experimental. But a few of these companies have an obvious interest in pursuing commercial products: Meta, for instance, is developing a suite of tools called Movie Gen that creates videos from text prompts, and Snap offers “AI Video Lenses” that allow users to augment their videos with generative AI. Videos such as the ones in these data sets are the raw material for products like these; much as ChatGPT couldn’t write like Shakespeare without first “reading” Shakespeare, a video generator couldn’t construct a fake newscast without “watching” tons of recorded broadcasts. In fact, a large number of the videos in these data sets are from news and educational channels, such as the BBC (which has at least 33,000 videos in the data sets, across its various brands) and TED (nearly 50,000). Hundreds of thousands of others—if not more—are from individual creators, such as Peters.\n\nAI companies are more interested in some videos than others. A spreadsheet leaked to 404 Media by a former employee at Runway, which builds AI video-generation tools, shows what the company valued about certain channels: “high camera movement,” “beautiful cinematic landscapes,” “high quality scenes from movies,” “super high quality sci-fi short films.” One channel was labeled “THE HOLY GRAIL OF CAR CINEMATICS SO FAR”; another was labeled “only 4 videos but they are really well done.”\n\nDevelopers seek out high-quality videos in a variety of ways. Curators of two of the data sets collected here—HowTo100M and HD-VILA-100M—prioritized videos with high view counts on YouTube, equating popularity with quality. The creators of another data set, HD-VG-130M, noted that “high view count does not guarantee video quality,” and used an AI model to select videos of high “aesthetic quality.” Data-set creators often try to avoid videos that contain overlaid text, such as subtitles and logos, so these identifying features don’t appear in videos generated by their model. So, some advice for YouTubers: Putting a watermark or logo on your videos, even a small one, makes them less desirable for training.\n\nTo prepare the videos for training, developers split the footage into short clips, in many cases cutting wherever there is a scene or camera change. Each clip is then given an English-language description of the visual scene so the model can be trained to correlate words with moving images, and to generate videos from text prompts. AI developers have a few methods of writing these captions. One way is to pay workers to do it. Another is to use separate AI models to generate a description automatically. The latter is more common, because of its lower cost.\n\nAI video tools aren’t yet as mainstream as chatbots or image generators, but they are already in wide use. You may already have seen AI-manipulated video without realizing it. For example, TED has been using AI to dub speakers’ talks in different languages. This includes the video as well as the audio: Speakers’ mouths are lip-synched with the new words so it looks like they’re speaking Japanese, French, or Russian. Nishat Ruiter, TED’s general counsel, told me this is done with the speakers’ knowledge and consent.\n\nThere are also consumer-facing products for tweaking videos with AI. If your face doesn’t look right, for example, you can try a face-enhancer such as Facetune, or ditch your mug entirely with a face-swapper such as Facewow. With Runway’s Aleph, you can change the colors of objects, or turn sunshine into a snowstorm.\n\nThen there are tools that generate new videos based on an image you provide. Google encourages Gemini users to animate their “favorite photos.” The result is a clip that extrapolates eight seconds of movement from an initial image, making a person dance, cook, or swing a golf club. These are often both amazing and creepy. “Talking head generation”—for employee-orientation videos, for example—is also advancing. Vidnoz AI promises to generate “Realistic AI Spokespersons of Any Style.” A company called Arcads will generate a complete advertisement, with actors and voiceover. ByteDance, the company that operates TikTok, offers a similar product called Symphony Creative Studio. Other applications of AI video generation include virtual try-on of clothes, generating custom video games, and animating cartoon characters and people.\n\nSome companies are both working with AI and simultaneously fighting to defend their content from being pilfered by AI companies. This reflects the Wild West mentality in AI right now—companies exploiting legal gray areas to see how they can profit. As I investigated these data sets, I learned about an incident involving TED—again, one of the most-pilfered organizations in the data sets captured here, and one that is attempting to employ AI to advance its own business. In June, the Cannes Lions international advertising festival gave one of its Grand Prix awards to an ad that included deepfaked footage from a TED talk by DeAndrea Salvador, currently a state senator in North Carolina. The ad agency, DM9, “used AI cloning to change her talk and repurposed it for a commercial ad campaign,” Ruiter told me on a video call recently. When the manipulation was discovered, the Cannes Lions festival withdrew the award. Last month, Salvador sued DM9 along with its clients—Whirlpool and Consul—for misappropriation of her likeness, among other things. DM9 apologized for the incident and cited “a series of failures in the production and sending” of the ad. A spokesperson from Whirlpool told me the company was unaware the senator’s remarks had been altered.\n\nOthers in the film industry have filed lawsuits against AI companies for training with their content. In June, Disney and Universal sued Midjourney, the maker of an image-generating tool that can produce images containing recognizable characters (Warner Brothers joined the lawsuit last week). The lawsuit called Midjourney a “bottomless pit of plagiarism.” The following month, two adult-film companies sued Meta for downloading (and distributing through BitTorrent) more than 2,000 of their videos. Neither Midjourney nor Meta has responded to the allegations, and neither responded to my request for comment. One YouTuber filed their own lawsuit: In August of last year, David Millette sued Nvidia for unjust enrichment and unfair competition with regard to the training of its Cosmos AI, but the case was voluntarily dismissed months later.\n\nThe Disney characters and the deepfaked Salvador ad are just two instances of how these tools can be damaging. The floodgates may soon be opening further. Thanks to the enormous amount of investment in the technology, generated videos are beginning to appear everywhere. One company, DeepBrain AI, pays “creators” to post AI-generated videos made with its tools on YouTube. It currently offers $500 for a video that gets 10,000 views, a relatively low threshold. Companies that run social-media platforms, such as Google and Meta, also pay users for content, through ad-revenue sharing, and many directly encourage the posting of AI-generated content. Not surprisingly, a coterie of gurus has arrived to teach the secrets of making money with AI-generated content.\n\nGoogle and Meta have also trained AI tools on large quantities of videos from their own platforms: Google has taken at least 70 million clips from YouTube, and Meta has taken more than 65 million clips from Instagram. If these companies succeed in flooding their platforms with synthetic videos, human creators could be left with the unenviable task of competing with machines that churn out endless content based on their original work. And social media will become even less social than it is.\n\nI asked Peters if he knew his videos had been taken from YouTube to train AI. He said he didn’t, but he wasn’t surprised. “I think everything’s gonna get stolen,” he told me. But he didn’t know what to do about it. “Do I quit, or do I just keep making videos and hope people want to connect with a person?”",
      "source": "The Atlantic",
      "url": "https://www.theatlantic.com/technology/archive/2025/09/youtube-ai-training-data-sets/684116/",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Elon Musk Loses World's Richest Person Title To Larry Ellison",
      "content": "Elon Musk can no longer stake his claim as the richest person on Earth ... the distinction now belongs to Larry Ellison.\n\nThe Tesla honcho lost his title during early morning trading Wednesday, when Larry's net worth surged on the strength of his company, Oracle, which saw its stock price jump dramatically.\n\nLarry's fortune skyrocketed $101 billion to a whopping $393 billion ... thanks to a strong earnings report Tuesday evening from Oracle.\n\nElon's net worth, according to Bloomberg, is a paltry $385 billion ... meaning Musk is now looking up when it comes to the billionaire's index. Oh, the horror.\n\nLarry's accumulating tons of wealth thanks to artificial intelligence ... the rapid rise in Oracle stock is being primarily fueled by Oracle reporting huge demand for cloud services and four multibillion-dollar contracts with big AI companies like OpenAI and Nvidia.\n\nOracle stock is up 40% Wednesday ... and it's a huge windfall for Larry, who is the largest individual shareholder.\n\nBloomberg says Larry's $101 billion gain is the biggest one-day increase on record.\n\nDon't shed a tear for Elon ... he's largely held on to the title as world's richest person since 2021, mainly due to his Tesla and SpaceX stock.",
      "source": "TMZ",
      "url": "https://www.tmz.com/2025/09/10/elon-musk-no-longer-worlds-richest-person/",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Hands-on: Nvidia GeForce Now’s Blackwell upgrade looks great, but you’ll need the right games",
      "content": "As promised, Nvidia is launching its Blackwell upgrade today for GeForce Now, bringing RTX 5080-based machines to the cloud service alongside a whole slew of other upgrades.\n\nWith the move to Blackwell architecture, GeForce Now subscribers on the $20/month Ultimate plan will now have support for DLSS 4 directly in the cloud. It’s capable of streaming at 5K 120 FPS — though there are very few true 5K displays available on the market at the moment — alongside 360 FPS support when running at 1080p. I was able to take a test run prior to today’s launch, and so far, what I’m seeing looks (and feels) very promising.\n\nThat said, how you benefit from an upgrade to Blackwell might primarily depend on the games you play; as someone who primarily focuses on single-player RPGs — with a pretty deep backlog of older titles to boot — the upgrade isn’t quite as impressive as it might be, say, if your Steam library has doubled in size this calendar year alone. That’s not to say RTX 5080 machines can’t bring refreshed visuals or improved performance to older titles, but it won’t be quite as impactful as if you’re playing fresh AAA releases like Doom: The Dark Ages or Assassin’s Creed Shadows.\n\nSomething that will affect titles, though, are the upgrades to visual performance coming to GeForce Now as part of this launch. A new “Cinematic Quality” setting is designed to optimize for visuals over all else, and assuming you have the network connection to handle it, it does deliver a noticeably improved experience over legacy quality settings. The specs sheet here is fairly impressive: 10-bit HDR with 4:4:4 chrome sampling, new AV1 encoders for improved network adaptation, and refreshed sharpness filters to help improve HUDs and on-screen text.\n\nAdvertisement - scroll for more content\n\nGenerally, I’d say it’s a pretty big improvement, especially with a strong-enough connection. That said, on a big-enough display, anyone looking for imperfections can probably still find them. Text does look plenty legible, especially in games like The Witcher 3, where the HUD is fairly busy with plenty of information, and colors appear as rich and vibrant as if I was playing on, say, a PS5. But sitting close enough to a 32-inch 4K monitor, it’s still apparent that you’re watching a stream of a game, rather than the native gaming experience itself. That encoding sheen, for lack of a better phrase, is surprisingly downplayed, but it’ll likely even better with the right display — say, a television across your living room, or a Steam Deck in your hands.\n\nReally, the biggest problem still affecting GeForce Now is its library support, and in this case, I’m not just talking about whether or not your entire Steam library syncs with your account. While that remains frustrating — a solid 50 percent of my own backlog can’t be played with the service — the upgrade to RTX 5080 hardware is starting off slow. In fact, at launch (and, as a result, during my testing period), only 20 games actually support RTX 5080 machines, with more to come during the service’s usual GFN Thursday updates.\n\nThat’s not necessarily a dealbreaker — GeForce Now has certainly collected plenty of fans running on that last-gen hardware, and at least in terms of the games I play, I’m not sure I would’ve immediately noticed the difference in performance if I wasn’t specifically looking for 5080-supported titles. In these early days, though, it would be nice for Nvidia to specifically denote games that run on Blackwell. For now, here’s the list:\n\nApex Legends\n\nAssassin’s Creed Shadows\n\nBaldur’s Gate 3\n\nBlack Myth: Wukong\n\nBorderlands 4 (at launch)\n\nClair Obscur: Expedition 33\n\nCounter-Strike 2\n\nCronos: The New Dawn\n\nCyberpunk 2077\n\nDiablo 4\n\nDoom: The Dark Ages\n\nDune: Awakening\n\nDying Light: The Beast\n\nThe Elder Scrolls IV: Oblivion Remastered\n\nGrounded 2\n\nHell Is Us\n\nIndiana Jones and the Great Circle\n\nMafia: The Old Country\n\nMicrosoft Flight Simulator 2024\n\nOverwatch 2\n\nTitan Quest II\n\nWarframe\n\nThe Witcher 3\n\nOverall, I’m pretty impressed with just how good GeForce Now has gotten over the last couple of years. Cloud gaming has had plenty of ups and downs over the last half-decade, but when it comes to Nvidia’s service, it’s really the latency that continues to impress me. The improvements Blackwell is bringing to the table should continue to keep GeForce Now at the top of the list when it comes to the overall experience, but they’ll need to keep delivering upgraded games at a relatively quick pace to do it.",
      "source": "9to5google.com",
      "url": "http://9to5google.com/2025/09/10/hands-on-nvidia-geforce-now-blackwell-upgrade/",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Why Is Nvidia Stock (NVDA) Soaring Today?",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_3611cebf-629a-48f9-b1db-1e48ee04e959",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Nvidia’s latest RTX Remix update brings path-traced particles to classic games — major overhaul promises 'tens of thousands' of particles without significant performance reduction",
      "content": "Nvidia’s modding platform for retrofitting classic games with ray tracing has just had a huge overhaul. On September 9, Nvidia announced major updates to RTX Remix, including an “advanced path-traced particle system” that adds real-time particle effects like fire and smoke with full lighting and animation controls, without touching the original game engine.\n\nThe new particle system was introduced in a standalone update to RTX Remix available through the Nvidia app. Fundamentally, the GPU particle simulation behaves like a native part of the ray-traced world, with particles casting and receiving shadows, reflecting in surfaces, and responding to both physics and the camera.\n\nWith the update, Nvidia is giving modders the kind of visual effects tools that are usually reserved for modern game engines. The company claims that “tens of thousands” of path-traced particles can be rendered “without significantly reducing performance.”\n\nThat’s a bold claim that’s likely to draw scrutiny. In previous RTX Remix projects like Portal RTX , particle-heavy scenes have pushed high-end GPUs to their limits , even with DLSS enabled. While Nvidia explicitly recommends RTX 30-series cards as the baseline for an acceptable experience, some players with 3090-class GPUs reported dips well below 60 fps in particle-heavy scenes.\n\nNVIDIA RTX Remix | Half-Life 2 RTX Fire Particles - YouTube Watch On\n\nThe updates also introduce a more streamlined authoring workflow. Modders can now tag textures in-game as particle emitters via the Alt+X developer menu and tweak properties like size and color directly within the Remix UI. The more advanced Remix Toolkit adds scripting support for lighting behaviors and collision physics powered by PhysX in the backend, according to Nvidia’s documentation .\n\nNvidia says that over 165 games are compatible with RTX Remix, provided they use DX8 or DX9 with fixed-function pipeline. That still leaves plenty of room for quirks like potential crashes and rendering issues in some titles, but there’s no denying that RTX Remix is becoming a more powerful and practical tool by the month for modders committed to rebuilding classic games.\n\nSince its release, the RTX Remix community has breathed new life into classic games like Half-Life 2, Need for Speed Underground, and Deux Ex, with more than 2 million downloads to date.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/video-games/nvidia-rtx-remix-update-brings-path-traced-particles",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Nvidia GeForce Now RTX 5080 (Blackwell) Review: RTX 5080 in a MacBook",
      "content": "It goes further with 4:4:4 color sampling as opposed to the 4:2:0 sampling GeForce Now typically uses, and Nvidia includes a couple of AI-driven filters for your in-game HUD and menus that help them look extra sharp, a common weak point when streaming games from the cloud. I booted up Cyberpunk 2077 to try out this mode on a MacBook Air, immediately cranking the graphics as high as they can go. It was locked at 60 fps. Despite a much lower frame rate than what I saw in Silksong, my latency still hovered between 35 and 40 milliseconds. The feel was spot-on; the quality, however, wasn't perfect.\n\nIt's almost as if Nvidia is pushing too much data through the pipeline. You can tell the extra visual quality is there, but on a high-resolution display sitting close to your face, the finer details are lost in what feels like a faint layer of frosted glass. If you're a couple of feet away (or even better, sitting on a couch with GeForce Now on your TV), you won't be able to tell. Up close and personal, the seams become more obvious.\n\nOutside of Cinematic quality, the RTX 5080 comes with Nvidia's DLSS Multi-Frame Generation (MFG). It can generate up to three frames for every rendered frame, and I found it particularly useful in games that are a little more demanding but still competitive, like Marvel Rivals.\n\nMFG introduces additional latency, which I assumed would be a death sentence in the context of GeForce Now. I was wrong. You can pick up on minuscule latency differences with MFG using it natively, but in the cloud, the network latency has a way of obfuscating that lag.\n\nDoubling the Library\n\nGeForce Now via Jacob Roach\n\nNvidia consistently adds new games to the GeForce Now library. It's so consistent that Nvidia established GFN Thursday, where it announces new games coming to the service every week, usually with at least half a dozen new titles. They've added up quickly, with GeForce Now supporting over 2,300 games. The Blackwell update doubles the library size to over 4,500 titles with Nvidia's new install-to-play (I2P) feature.",
      "source": "Wired",
      "url": "https://www.wired.com/review/nvidia-geforce-now-rtx-5080-blackwell/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Nvidia-baked Cusp AI Raises $100m In Series A Funding",
      "content": "As European companies seek listings in the US, others are changing the way our industries work. Cusp AI is a platform that acts like a search engine for novel materials, enabling customers to specify the exact properties they need and generating new, synthesisable candidates up to 10x faster than traditional discovery methods. They've recently secured $100 million in Series A funding round - with backers including Nvidia and Singapore's sovereign wealth fund. The startup has also locked in partnerships with Hyundai and Meta. Bloomberg's Tom Mackenzie spoke exclusively to Cusp AI co-founder and CEO, Chad Edwards.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/nvidia-baked-cusp-ai-raises-084416380.html",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Klarna’s $17 billion IPO has just turned 40 staffers into overnight millionaires—while Nvidia, Canva, and Palantir workers are seeing similar gains",
      "content": "Klarna made its New York Stock Exchange debut this week, sending its market cap soaring to $15 billion—propelling around 40 staffers to millionaire status overnight, with its executive team gaining the most from the IPO. It’s not the first time Klarna’s success has created ultrarich employees—at least 115 of its workers have hit seven-figure net worths since 2021. And staffers at other tech companies, including Nvidia, Canva, and Palantir, who invested early have also made it into the exclusive wealth club.\n\nMany might think that only savvy investors, pioneering founders, and rising CEOs become millionaires overnight—but employees are reaping seven-figure net worths from the successes of their companies, too. Three dozen lucky Klarna staffers just joined the ultrarich club thanks to its recent stock windfall.\n\nKlarna made its New York stock market trading debut this week, with shares skyrocketing after the fintech company and its backers raised $1.37 billion in an initial public offering (IPO). The business’s shares shot up as much as 43% on Wednesday, opening at $52 a share and closing at around $45.82 each, well above the IPO price of $40 ahead of the listing. This shot up Klarna’s market cap to a whopping $17 billion—and it’s estimated that the stock surge catapulted more than 40 current and former Klarna staffers up into the millionaires’ club, thanks to its employee stock perks.\n\nOf course, the fintech company’s cofounders, Sebastian Siemiatkowski and Victor Jacobsson, had the most to gain from the debut. Despite leaving the company in 2012, Jacobsson still held on to 31.4 million shares valued at $1.1 billion at the time of the IPO—and will reportedly sell 2.5% of them.\n\nMeanwhile, CEO Siemiatkowski owns 25.6 million shares with a value of $920 million. And dozens of other staffers benefited as well; there are 37 former and current Klarna employees who now hold shares worth more than $1 million, according to an analysis from startup publication Sifted.\n\nKlarna declined Fortune’s request for comment.\n\nKlarna executives had the most to gain among the new staffed millionaires\n\nAside from the cofounders, many of the Swedish fintech company’s executive team had the most to gain thanks to their enviable stock portfolios.\n\nFor example, Klarna’s chief product and design officer, David Fock, owns more than 600,000 shares worth a total of $21.6 million—and at the IPO, he plans to sell almost 40% of his stock, according to Sifted reporting.\n\nMeanwhile Niclas Neglén, the company’s chief financial officer, holds around 280,000 shares worth $10 million and plans to sell 8%. And chief marketing officer David Sandström, who owns about 290,000 shares valued at $10.4 million, seeks to offload 30%.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/klarna-17-billion-ipo-just-153530675.html",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "NVIDIA, AI & Quantum Leaders Drive Health Tech: 2 Stocks to Buy",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_d4b18937-bf7c-4942-bdd2-a019913f45ed",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "La-Proteina",
      "content": "La-Proteina: Atomistic Protein Generation via Partially Latent Flow Matching\n\nAbstract. Recently, many generative models for de novo protein structure design have emerged. Yet, only few tackle the difficult task of directly generating fully atomistic structures jointly with the underlying amino acid sequence. This is challenging, for instance, because the model must reason over side chains that change in length during generation. We introduce La-Proteina for atomistic protein design based on a novel partially latent protein representation: coarse backbone structure is modeled explicitly, while sequence and atomistic details are captured via per-residue latent variables of fixed dimensionality, thereby effectively side-stepping challenges of explicit side-chain representations. Flow matching in this partially latent space then models the joint distribution over sequences and full-atom structures. La-Proteina achieves state-of-the-art performance on multiple generation benchmarks, including all-atom co-designability, diversity, and structural validity, as confirmed through detailed structural analyses and evaluations. Notably, La-Proteina also surpasses previous models in atomistic motif scaffolding performance, unlocking critical atomistic structure-conditioned protein design tasks. Moreover, La-Proteina is able to generate co-designable proteins of up to 800 residues, a regime where most baselines collapse and fail to produce valid samples, demonstrating La-Proteina's scalability and robustness.\n\nFind the Model Card++ for La-Proteina here.\n\nSetup\n\nFor environment setup mamba or micromamba is recommended, but alternatively conda can also be used as a drop-in replacement (substitute mamba with conda ).\n\nmamba env create -f environment.yaml mamba activate laproteina_env pip install torch==2.7.0 --index-url https://download.pytorch.org/whl/cu118 pip install graphein==1.7.7 --no-deps pip install torch_geometric torch_scatter torch_sparse torch_cluster -f https://data.pyg.org/whl/torch-2.7.0+cu118.html\n\nPlease download all model checkpoints into the ./checkpoints_laproteina directory, as indicated in the Checkpoints section, which is necessary to sample our models.\n\nIf you are only interested in sampling our models, please go to Sampling our models.\n\nTo train models and use our minimal dataloaders, create a file .env in the root directory of the repo with the single line\n\nDATA_PATH=/directory/where/you/want/dataset\n\nIn the paper we train our models on subsets of the AFDB. We provide lists of IDs for each dataset in laproteina_afdb_ids.zip.\n\nDataloaders\n\nWe provide minimal dataloader implementations that allow training on different subsets of the PDB. Here we describe how to use these minimal dataloaders. Note that all our models are trained on subsets of the AFDB, not on the PDB, as described in the paper. We provide the indices of the AFDB used for the datasets described in the paper here.\n\nPDB dataloader\n\nTo use the PDB dataloader, you can for example use the pdb_train_ucond.yaml file, which we provide as part of our configs/dataset/pdb directory, in the following way:\n\nimport os import hydra import lightning as L L.seed_everything(43) version_base = hydra.__version__ config_path = </path/to/datasets_configs> hydra.initialize_config_dir(config_dir=f\"{config_path}/pdb\", version_base=version_base) cfg = hydra.compose( config_name=\"pdb_train\", return_hydra_config=True, ) pdb_datamodule = hydra.utils.instantiate(cfg.datamodule) pdb_datamodule.prepare_data() pdb_datamodule.setup(\"fit\") pdb_train_dataloader = pdb_datamodule.train_dataloader()\n\nWith this, the dataloader selects all PDB chains according to the selection criteria specified in the yaml file, downloads, processes and splits the data and generates ready-to-use dataloaders and datamodules. For simple demonstration we subsample the dataset in pdb_train_ucond.yaml via the fraction attribute; for the full dataset change this value to 1.\n\nModel training\n\nVAE training\n\nRun the command python proteinfoundation/partial_autoencoder/train.py . Certain parameters, such as KL weight use for the loss, how often to save checkpoints, wandb logging, etc, can be controlled from configs/training_ae.yaml .\n\nUnconditional training\n\nRun the command python proteinfoundation/train.py . This will start training according to the configuration specified in configs/training_local_latents.yaml , specifying the autoencoder checkpoint, and the neural network config (for unconditional models use - nn: local_latents_score_nn_160M ), learning rate, among other parameters.\n\nMotif-scaffolding partially latent flow matching training\n\nTraining indexed all-atom vs. indexed tip-atom scaffolding models. For indexed all-atom scaffolding, set the dataset, line 11 of configs/training_local_latents.yaml , to - dataset: pdb/pdb_train_motif_aa , and the neural network, line 12 of configs/training_local_latents.yaml , to - nn: local_latents_score_nn_160M_motif_idx_aa . For indexed tip-atom scaffolding, set them to - dataset: pdb/pdb_train_motif_tip and - nn: local_latents_score_nn_160M_motif_idx_tip .\n\nTraining unindexed all-atom vs. unindexed tip-atom scaffolding models. Set the architecture, line 12 of configs/training_local_latents.yaml , to - nn: local_latents_score_nn_160M_motif_uidx (all-atom and tip-atom use the same neural network in the unindexed case). For unindexed all-atom scaffolding, set the dataset, line 11 of configs/training_local_latents.yaml , to - dataset: pdb/pdb_train_motif_aa . For indexed tip-atom scaffolding, set them to - dataset: pdb/pdb_train_motif_tip and - nn: local_latents_score_nn_160M_motif_idx_tip .\n\nOnce the config is modified accordingly, run python proteinfoundation/train.py .\n\nTraining/Sampling with compiled models\n\nSince our transformer-based architecture is amenable to hardware optimizations, we leverage the torch compilation framework to speed up training and inference. This feature is by default disabled in this repository, but can be enabled easily:\n\nFor sampling, just outcomment the torch.compile line in the forward method in proteinfoundation/nn/local_latents_transformer.py and proteinfoundation/nn/local_latents_transformer_unindexed.py .\n\nline in the forward method in and . For training, in addition you need to enable the PaddingTransform with the appropriate max_size argument to make all batches the same length across the sequence dimension. By default, we only pad the batches to the longest sequence in the batch for efficiency reasons, but to leverage compilation this size should be constant.\n\nSampling\n\nCheckpoints\n\nLa-Proteina consists of two models, the autoencoder and the latent diffusion. All checkpoints should be downloaded and placed in the directory ./checkpoints_laproteina in the codebase's root directory. The code loads checkpoints from this directory automatically. All checkpoints can be found here. We also provide individual links below.\n\nWe provide weights for the following latent diffusion models (for autoencoders see next paragraph):\n\n(LD1) Unconditional generation, no triangular update layers, generation up to 500 residues: LD1_ucond_notri_512.ckpt.\n\n(LD2) Unconditional generation, triangular multiplicative update layers, generation up to 500: LD2_ucond_tri_512.ckpt.\n\n(LD3) Unconditional generation, no triangular update layers, generation between 300 and 800 residues: LD3_ucond_notri_800.ckpt.\n\n(LD4) Indexed atomistic motif scaffolding, all atom: LD4_motif_idx_aa.ckpt.\n\n(LD5) Indexed atomistic motif scaffolding, tip atom: LD5_motif_idx_tip.ckpt.\n\n(LD6) Unindexed atomistic motif scaffolding, all atom: LD6_motif_uidx_aa.ckpt.\n\n(LD7) Unindexed atomistic motif scaffolding, tip atom: LD7_motif_uidx_tip.ckpt.\n\nEach La-Proteina model requires an autoencoder in addition to the latent diffusion model. We provide three different autoencoder checkpoints since each one is trained for proteins of different lengths: up to 256 residues for atomistic motif scaffolding, up to 512 residues for unconditional generation up to 500 residues, and up to 896 residues for unconditional generation of longer chains:\n\n(AE1) Autoencoder for unconditional generation up to 500 residues, which should be used with models (LD1, LD2): AE1_ucond_512.ckpt.\n\n(AE2) Autoencoder for unconditional generation between 300 and 800 residues, which should be used with model (LD3): AE2_ucond_800.ckpt.\n\n(AE3) Autoencoder for atomistic motif scaffolding, which should be used with model (LD4, LD5, LD6, LD7): AE3_motif.ckpt.\n\nSampling different configurations\n\nWe provide config files and commands to sample our different models. All models can be sampled by running\n\npython proteinfoundation/generate.py --config_name <config_name>\n\nfor the corresponding config file.\n\nUnconditional generation:\n\nUnconditional samples from the LD1 model: Run python proteinfoundation/generate.py --config_name inference_ucond_notri . This will use noise scales of 0.1 for the alpha carbon atoms and 0.1 for the latent variables, and will produce 100 samples for each of the lengths in [100, 200, 300, 400, 500]. These values can be changed in the config file configs/generation/uncod_codes.yaml .\n\nUnconditional samples from the LD2 model: Run python proteinfoundation/generate.py --config_name inference_ucond_tri . This will use noise scales of 0.1 for the alpha carbon atoms and 0.1 for the latent variables, and will produce 100 samples for each of the lengths in [100, 200, 300, 400, 500]. These values can be changed in the config file configs/generation/uncod_codes.yaml .\n\nUnconditional samples from the LD3 model: Run python proteinfoundation/generate.py --config_name inference_ucond_notri_long . This will use noise scales of 0.15 for the alpha carbon atoms and 0.05 for the latent variables, and will produce 100 samples for each of the lengths in [300, 400, 500, 600, 700, 800]. These values can be changed in the config file configs/generation/uncod_codes_800.yaml .\n\nConditional generation: We provide models for atomistic motif scaffolding for four different setups: indexed all-atom, indexed tip-atom, unindexed all-atom, unindexed tip-atom. Please check the paper for precise descriptions of each setup. The lists of atomistic motif scaffolding tasks can be found in configs/generation/motif_dict.yaml , where you'll also find the specification (contig string) for each task. Tasks ending with the \"_TIP\" suffix should be used for tip-atom scaffolding models (indexed and unindexed), and tasks without the \"_TIP\" suffix in their names should be used for the all-atom scaffolding models. Note that the following four tasks (indexed all-atom, indexed tip-atom, unindexed all-atom, unindexed tip-atom) require some small changes in the codebase, as indicated below for each specific case. These changes involve how to map motif residues to sequence indices (different in indexed vs. unindexed) or how the exact features used as input to the model are built.\n\nConditional samples from the LD4 model, indexed and all-atom atomistic motif scaffolding: Run python proteinfoundation/generate.py --config_name inference_motif_idx_aa . This will use a temperature of 0.1 for the alpha carbon atoms and 0.1 for the latent variables. The motif task can be specified in the config file configs/inference_motif_idx_aa.yaml , and the number of samples produced in the configs/generation/motif.yaml file. This model should be used for all-atom tasks, that is, the ones that do not contain the \"_TIP\" suffix in their name. For this model you need to use lines 1851 and 1852 in proteinfoundation/nn/feature_factory.py , and lines 228 to 230 in ./proteinfoundation/evaluate.py .\n\nConditional samples from the LD5 model, indexed and tip-atom atomistic motif scaffolding: Run python proteinfoundation/generate.py --config_name inference_motif_idx_tip . This will use a temperature of 0.1 for the alpha carbon atoms and 0.1 for the latent variables. The motif task can be specified in the config file configs/inference_motif_idx_tip.yaml , and the number of samples produced in the configs/generation/motif.yaml file. This model should be used for tip-atom tasks, that is, the ones that contain the \"_TIP\" suffix in their name. For this model you need to use lines 1847 and 1848 in proteinfoundation/nn/feature_factory.py , and lines 228 to 230 in ./proteinfoundation/evaluate.py .\n\nConditional samples from the LD6 model, unindexed and all-atom atomistic motif scaffolding: Run python proteinfoundation/generate.py --config_name inference_motif_uidx_aa . This will use a temperature of 0.1 for the alpha carbon atoms and 0.1 for the latent variables. The motif task can be specified in the config file configs/inference_motif_uidx_aa.yaml , and the number of samples produced in the configs/generation/motif.yaml file. This model should be used for all-atom tasks, that is, the ones that do not contain the \"_TIP\" suffix in their name. For this model you need to use lines 1851 and 1852 in proteinfoundation/nn/feature_factory.py , and lines 233 to 240 in ./proteinfoundation/evaluate.py .\n\nConditional samples from the LD7 model, unindexed and tip-atom atomistic motif scaffolding: Run python proteinfoundation/generate.py --config_name inference_motif_uidx_tip . This will use a temperature of 0.1 for the alpha carbon atoms and 0.1 for the latent variables. The motif task can be specified in the config file configs/inference_motif_uidx_tip.yaml , and the number of samples produced in the configs/generation/motif.yaml file. This model should be used for all-atom tasks, that is, the ones that contain the \"_TIP\" suffix in their name. For this model you need to use lines 1847 and 1848 in proteinfoundation/nn/feature_factory.py , and lines 233 to 240 in ./proteinfoundation/evaluate.py .\n\nEvaluation\n\nOur evaluation pipeline requires ProteinMPNN to compute (co-)designability. Running bash script_utils/download_pmpnn_weights.sh in the codebase root directory will download the required weights to the correct location. Note that these weights only needed for the evaluation pipeline, not for sampling our models.\n\nWe provide code to compute (co-)designability of the samples produced by our models in proteinfoundation/evaluate.py . For the motif scaffolding tasks it also computes motif RMSD values and motif sequence recovery. Run python proteinfoundation/evaluate.py --config_name <config_name> . Please see this bash script example which can be used to sample some one of our models and evaluate the resulting samples.\n\nExplanation of config file parameters\n\nThis section briefly explains the multiple parameters in the inference config files. All inference config files are based on configs/experiment_config/inference_base_release.yaml . Then, the config files for the corresponding experiments (e.g. inference_ucond_notri.yaml simply overrides some parameters in the base config). Some of the parameters in these config files are:\n\nckpt_name determines the checkpoint for the latent diffusion model. Only requires the checkpoint name, not full path.\n\ndetermines the checkpoint for the latent diffusion model. Only requires the checkpoint name, not full path. autoencoder_ckpt_path determines the checkpoint for the autoencoder. Requires full path to checkpoint.\n\ndetermines the checkpoint for the autoencoder. Requires full path to checkpoint. self_cond specifies whether to use self-conditioning during sampling. All our evaluations are done with self-conditioning, as we observe that yields better performance.\n\nspecifies whether to use self-conditioning during sampling. All our evaluations are done with self-conditioning, as we observe that yields better performance. sc_scale_noise controls the noise scale (for alpha carbon atoms and latent variables, can be set separately).\n\nLicense\n\nSource code is released under the Apache 2.0 license. Please see the LICENSE. Model Weights are released under NVIDIA Open Model License Agreement. All other materials are released under the Creative Commons Attribution 4.0 International License, CC-BY 4.0.\n\nCitation\n\nCite our paper using the following bibtex item:",
      "source": "Github.com",
      "url": "https://github.com/NVIDIA-Digital-Bio/la-proteina",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Streaming Can’t Replace Your PC, but Nvidia’s Updated GeForce Now Comes Close",
      "content": "The best compliment I could ever lay at the feet of any game streaming service is that I can forget I was even using it. Nvidia’s GeForce Now service, which lets players run their own game library through the cloud, is better than ever with its most recent update. As a bonus, Nvidia’s $20-per-month “Ultimate” subscription doesn’t cost any more than it did previously, unlike TV streaming’s constant price gouging. Just know that when I say the service has improved, I mean the service is better at everything it was already great for.\n\nIs streaming the future of gaming? No, especially not for multiplayer. But when PC and console prices are more expensive than ever, GeForce Now could fill in the gaps when hardware starts to falter.\n\nGeForce Now RTX 5080 Update The performance uplift may not be significant for some games, but GeForce Now makes PC gaming far more accessible. 4 Pros Better performance across multiple games\n\nMore resolution options\n\nLittle latency\n\nBetter graphics in \"cinematic\" mode\n\n90Hz support on Steam Deck Cons Visuals can't be be native PC quality\n\nPoor for multiplayer\n\nMulti-frame gen is pointless over streaming\n\nNvidia let me try out its update to GeForce Now early, before it started rolling out to users on Wednesday. It upgrades some games to use a better GPU, dampens server latency, and makes games look better. As much as that sounds like a good deal, let’s remember who is making use of cloud gaming in the first place. Gamers running systems that can’t play today’s AAA games, whether they’re not powerful enough or incompatible altogether, can instead stream the game to their system for the cost of two large artisan coffees each month. That hasn’t changed with the update, but now PC players with a Steam backlog may be able to play far more games using Nvidia’s new Install-to-Play feature.\n\nDon’t expect miracles from RTX 5080\n\nNvidia’s latest update to GeForce Now allows some games to run on systems with the GeForce RTX 5080 GPU, rather than the last-gen RTX 4080. Not all games support this at launch, though titles that can get performance uplift with the new GPU, including older titles like Cyberpunk 2077 and new games such as Borderlands 4, benefit from extra frame rates and more graphics options. You may find you can push some titles with ray tracing settings that you weren’t able to before. I could get Cyberpunk 2077 running with path tracing enabled for ultra-realistic lighting effects and still have more than enough frame rates that I wasn’t completely relying on digital tricks or so-called “fake frames.”\n\nNvidia claims it pushed latency down as much as possible below 30ms to make games feel more seamless. That would be enough to receive my paternalistic nod of approval, but Nvidia also touts the RTX 5080’s multi-frame gen capabilities as a big reason why users should jump on the streaming bandwagon. This is an RTX 50-series Blackwell-exclusive software feature that inserts multiple generated—aka “fake”—frames in between each rendered frame, artificially increasing frame rates for more responsive gameplay. It’s the kind of feature that sounds great on paper, but in practice is more constrained. Users need to achieve more than 50 fps normally to make multi-frame gen work without introducing odd graphical glitches. Frame generation also introduces more latency, though Nvidia said it was able to tamp down on sluggishness with some help from its updated SuperPOD servers.\n\nI tried games with and without frame gen, and in most cases, I still think gamers can go without. In Indiana Jones and the Great Circle, I pushed it up to beyond 250 fps with 4x frame gen, and the experience didn’t feel any better than without any frame gen running at around 90 fps. The added latency runs counter to smooth frame rates. Plus, 90 fps is more than playable for single-player titles.\n\nIf you can afford a 360Hz monitor, which is now supported by GeForce Now, you can probably afford a non-streaming gaming device. And if you’re using a high-refresh-rate display, you’re likely playing multiplayer games. I could jump into Overwatch 2 or Counter-Strike 2 through streaming and about as well as usual (re: awful), but pushing the refresh rate to 360Hz also pares down the resolution to 1080p. Streaming is not the arena for competitive multiplayer. I doubt it ever could be.\n\nGeForce Now can’t replace PC gaming… yet\n\nI wasn’t as interested in running these games on my usual gaming PC. If you can play these games natively, then there’s no reason you should be spending an extra $20 on top of however much you blow on the next Steam sale. Instead, I wanted to see what happens when using devices like a 14-inch MacBook Pro with M4 chip, a Steam Deck, and even an Nvidia Shield set-top box, which—like a spunky grandfather—is still kicking despite its age.\n\nNvidia claims it reduced latency enough to enjoy games online or offline, but the real reason you get GeForce Now is to play your games without spending money on new hardware. Streaming is notorious for introducing odd visuals into high-fidelity 3D games. To remedy this, Nvidia introduced a new “Cinematic” quality mode that enhances colors and sharpens certain objects, like trees. This means a game like Assassin’s Creed: Shadows appears sharper than it did in previous versions of GeForce Now. The extra visual quality was enough to entice me to put a few more hours into a game I had already harangued back at launch.\n\nI took screenshots of both Baldur’s Gate III and Cyberpunk 2077 running natively and streaming on my 14-inch MacBook Pro. There are obvious quality differences between the two, plus Nvidia’s base HDR settings result in an overall darker image than natively. It’s a fully playable experience, but I still noticed a loss in detail on some terrain in Baldur’s Gate III and fuzz,y far-distant objects in Cyberpunk 2077.\n\nOf course, I was getting better frame rates through GeForce Now than playing each game on a MacBook Pro with M4 chip. For single player games, the latency never became a problem on my home Wi-Fi. Packet loss, where data goes missing moving between your device and the server, is also kept manageable. I do not have the best home Wi-Fi, but in tests, my internet bandwidth usually sits at 75Mbps with a 26ms latency. That’s more than enough for me to stream at 4K and even the new 5K resolution at 120 fps. Other people may not be so lucky to have the 54Mbps minimum required to achieve the highest resolution possible on GeForce Now.\n\nGood reminder of what games you own\n\nNvidia updated its existing Steam Deck app to play games with support for up to 90Hz refresh rate. Of all the devices I’ve tested with Nvidia’s streaming service, handhelds and other mobile devices are where GeForce Now shines. You can push the resolution in games beyond the Steam Deck’s 800p display, which will help reduce artifacts that pop up from streaming. I can settle down and play from lying down on my bed. Nvidia also released a version of the app for the Lenovo Legion Go S with SteamOS to support 120Hz gaming. That 8.8-inch display and 1200p resolution combine well with an RTX 5080 GPU to offer strong performance across titles. If the SteamOS handhelds are the most console-like devices you can take with you, then GeForce Now makes it so much easier to enjoy games without having to worry nearly as much about frame rate dips or battery life.\n\nYou still won’t find titles like Elden Ring available to stream on GeForce Now. However, Nvidia effectively opened up servers for users to download a whole host of new titles. These games remain on the servers until you log off, though you can rent out that space for an extra $3 a month if you want your games to remain.\n\nCurrently, Install-to-Play is mostly filled with the kind of older games or indie titles that don’t normally require much graphical power, which in turn means they don’t have enormous file sizes that take hours to download on Nvidia’s remote PCs. Going through the staggering 4,700 titles, you may think there are more games than it’s possible to try. Still, out of the 441 games in my Steam Library, only 15 of them were available through Install-to-Play. That ignores the titles that are fully streaming-ready on the service, which would push the actual number to 359 across my Steam, Epic, and Xbox libraries. Nvidia said it plans to add more games to the service as more developers opt in.\n\nDownloading games on these cloud-based PCs didn’t take much hassle. I could already play games like Mark of the Ninja perfectly well on my Steam Deck, but having access to it on my phone, should I want it, is a treat. I only hope Nvidia doesn’t use this feature to eventually dump games that are less played from its official servers, but at least we know we’ll still be able to download them, should that ever happen.\n\nGeForce Now is becoming more and more a go-to for me and my personal gaming habits. I enjoy using my Steam Deck at home for playing through Clair Obscur: Expedition 33 and then taking the device on the road to run through compatible games like Warhammer 40K: Rogue Trader. I’m at a point in my gaming life where my consoles and PCs are like chains that keep me tied to a desk or across a TV. I know the good times can’t last forever, and I’m waiting for the hammer blow of increased subscription costs or the inevitable enshittification that comes to all streaming services.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/streaming-cant-replace-your-pc-but-nvidias-updated-geforce-now-comes-close-2000657060",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Inside nuclear startup Terra Innovatum's plan to cash in on the SPAC comeback",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nBlank-check mergers are back on the cards — at least for nuclear startups.\n\nTerra Innovatum, a company developing micro-modular nuclear reactors, is one of the contenders. It's pursuing a SPAC by merging with GSR III Acquisition Corp, with the aim of raising around $230 million at a $475 million pre-money valuation.\n\nIts chief business development officer, Giordano Morichi, told Business Insider that the company is opting for a SPAC because the startup sees it as a smoother alternative to an IPO.\n\nMorichi said the startup didn't want to go through a funding round because it \"wanted a more regulated fundraising environment.\"\n\nMorichi, who joined the company last year to restrategize its business, has witnessed growing investor appetite for SPACs. He said the transaction's profits would help Terra propel the commercialization of its small-scale nuclear reactor technology.\n\nThe team has earmarked around $70 million to build its first unit, a cubic reactor that aims to deliver one megawatt of electricity through its standard fuel rods. The startup anticipates generating this through the listing, which is set for early autumn.\n\nThe SPAC process is much faster than that of a traditional IPO, and one that suits a pre-revenue company, said Alex Gadotti, a capital markets advisor at Park Avenue Capital, which is advising Terra Innovatum on the deal. \"It gives much, much more certainty on the proceeds, and the stock gives more control in the process than a normal IPO,\" he added.\n\nTerra Innovatum isn't alone in forgoing an IPO. Nuclear upstarts Terrestrial Energy and Eagle Energy Metals are also planning to merge with special purpose acquisition companies.\n\nTapping into the SPAC comeback\n\nThis year has been something of a turnaround for SPACs, which had their moment in the sun in 2020 before they were marred by challenges and disappointing exits. High-profile listings from 2021, such as BuzzFeed and Grab, plummeted the following year, dipping over 50% in value year on year. Investors became wary.\n\nThis year, there's been a steady uptick in SPAC activity. In the US, SPACs raised a total of $11 billion in the first half of 2025, compared with the $2 billion raised in the same period in 2024, per Bloomberg data. Notable listings include Sam Altman-backed nuclear company Oklo's merger with AltC Acquisition Corp, and the upcoming listing of firearms company GrabAGun, which counts Donald Trump Jr. as a board member, merging with Colombier Acquisition Corp. II.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nSome investors have pointed out the parallels between the electric vehicle SPAC boom of 2021 and the trajectory of nuclear startups today.\n\nEV heavyweight Fisker went public via a SPAC in 2020 and later went bankrupt, while ChargePoint has faced financial challenges since its 2021 SPAC.\n\nMorichi said that the EV juggernauts that fell from grace post-SPAC had their lofty, multibillion-dollar valuations to blame, but Terra Innovatum's $475 million pre-money valuation is much more \"reasonable\" for investors. The company intends to raise around $230 million, but this is subject to change as it has yet to disclose its pipeline.\n\nAI has catalyzed a frenzy for nuclear energy\n\nTerra Innovatum is building small-scale nuclear reactors, a technology that's been gaining investor traction as AI juggernauts scramble to power their energy-intensive data centers.\n\nCompanies spearheading the AI boom, from Google and Microsoft to Nvidia and OpenAI, have increasingly considered nuclear energy a viable source to meet AI's sky-high energy demands. Amazon took a stake in SMR developer X-Energy last year, while Google struck a nuclear energy deal with Kairos Power. This has given nuclear energy startups a boost as they find a purple patch to scale.\n\nTerra's thesis is that energy generation is bottlenecked by energy distribution, and developing micro reactors can tackle both issues.\n\n\"Having a reactor that can be next to a factory or hospital can be one of the biggest upsides,\" said Morichi. \"To do so, the reactor needs to be extremely safe. It needs to be small enough so it can't physically explode.\"\n\nOften, hydrogen explosions are the key cause of concern in nuclear reactors; the startup uses helium gas as an alternative to hydrogen to minimize this risk.\n\nHe added that Terra's micro modular reactors \"can't explode\" because they don't contain water, giving them a higher safety profile.\n\nMorichi acknowledges that other SMR companies may yield a higher energy output. But the company's selling point has been its scalability. The reactor's off-grid capability and modular design make it an attractive option for data center companies, he said.\n\nThe company is in talks to partner with data center providers, but declined to provide specifics as that information is not yet public.\n\nUnlike many clean energy companies dealing with the financial fallout from Donald Trump's \"Big Beautiful Bill,\" the team has actually been emboldened by federal policy that's \"propelling the wind in our sails,\" Morichi told Business Insider. The Nuclear Regulatory Commission announced it would be cutting fees for the process of licensing and reviewing nuclear projects, which Morichi said would help bring the reactors to market much quicker.\n\nIt's also avoided any major bruising from the administration's tariffs that have otherwise hampered supply chains globally. \"We have a seamless model for the supply chain. We have secured part of the supply chain in Italy and in the US, and we have different types of partners that will help on those fronts,\" he added.\n\nWhile the listing will be on the Nasdaq, the team ultimately has international ambitions. Energy resilience is not a national issue affecting only the US, but a global problem, Morichi said.\n\n\"Because we really want to deploy these reactors globally, it's important that we work with local entities and industries, not only to propel their own economic state value, but to help us enter the market,\" he said.\n\nCorrection: September 11, 2025 — An earlier version of this story misstated who Alex Gadotti works for.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/terra-innovatum-nuclear-spac-boom-2025-9",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "An Interview with Dan Kim About Intel, Nvidia, and the U.S. Government",
      "content": "Subscribe to Stratechery Plus for full access. Already subscribed? Log in $15 / month or $150 / year\n\nWith Stratechery Plus you get access to the subscriber-only Stratechery Update and Stratechery Interviews, and the Sharp Tech, Sharp China, Dithering, Greatest of All Talk, and Asianometry podcasts.\n\nStratechery Update\n\nSubstantial analysis of the news of the day delivered via three weekly emails or podcasts. Stratechery Interviews\n\nInterviews with leading public CEOs, private company founders, and discussions with fellow analysts. Dithering\n\nA twice-weekly podcast from John Gruber and myself: 15 minutes an episode, not a minute less, not a minute more. Sharp Tech\n\nAndrew Sharp and myself discuss how technology works and the ways it impacts our lives. Sharp China\n\nA weekly podcast from Andrew Sharp and Sinocism’s Bill Bishop about understanding China and how China impacts the world. Greatest Of All Talk\n\nA twice-weekly podcast from Andrew Sharp and Ben Golliver about the NBA, life, and national parks. Asianometry\n\nAudio and transcripts of the Asianometry YouTube channel, the best source for learning about how tech works.\n\nStratechery Updates are also available via SMS, RSS, or on this site. Please see the Stratechery Update Schedule for more details about delivery times and planned days-off. Please note that all subscriptions auto-renew monthly/annually (but can be cancelled at any time). If you are interested in ordering and managing multiple subscriptions for your team or company, please fill in the form here.\n\nFrequently-Asked Questions\n\nHow do I subscribe to the Stratechery Podcast? Once you are subscribed, please visit your Delivery Preferences where you will find easy-to-follow instructions for adding Stratechery Podcasts to your favorite podcast player.\n\nCan I read Stratechery via RSS? Yes! Create a Stratechery Passport account, go to Delivery Preferences, and add your personalized RSS feed. Free accounts will have access to Weekly Articles, while subscribers will have access to the Daily Update as well.\n\nCan I share a Stratechery Update subscription with a friend? No, the Stratechery Update and Stratechery Podcast are intended for one subscriber only. Sharing emails, using shared inboxes, or sharing RSS feeds is a violation of Stratechery’s Terms of Service, and your account may be suspended or your RSS feed reset. Of course occasional forwarding of the Stratechery Update to interested friends or colleagues is totally fine.\n\nCan I buy a subscription for my team? Yes! You can purchase a team subscription here.\n\nCan I switch to an annual plan? Yes! Just go to your account page, choose the ‘Subscriptions’ tab, and click the Annual upgrade button. You will be charged immediately, with a prorated discount applied for the remainder of your current monthly plan.\n\nDo you offer a student discount? Stratechery is purposely kept at a low price — thousands of dollars less than other analyst reports or newsletters — to ensure it is accessible to everyone, including students.\n\nCan you create a custom invoice that meets my government/company requirements? I am happy to create an invoice to your specification for annual subscribers; however, it is simply not viable for me to offer this service to monthly subscribers. Therefore, if you need a custom invoice please subscribe or switch to an annual subscription and contact Stratechery. June 1, 2021 Update: We are hoping to add native support for custom invoices to Passport; you can subscribe to Passport Updates to be notified when it is available.",
      "source": "Stratechery.com",
      "url": "https://stratechery.com/2025/an-interview-with-dan-kim-about-intel-nvidia-and-the-u-s-government/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Google TPUs Vs Nvidia GPUs",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/11/google-tpus-vs-nvidia-gpus/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Nvidia has launched a GPU with 128GB of GDDR7 RAM but yeah, there's no way it will sell one to us to run games",
      "content": "Nvidia announces Rubin CPX GPU with 128GB memory built for enterprise AI workloads\n\nVera Rubin NVL144 CPX rack delivers 8 exaFLOPs compute and 100TB fast memory\n\nShipments planned for late 2026 with Rubin Ultra and Feynman already on roadmap\n\nNvidia has announced a brand new GPU built on the Rubin architecture and designed for long-context AI workloads.\n\nRubin CPX, as it’s known, includes 128GB of GDDR7 memory, making it the company’s first GPU at that capacity.\n\nThere were rumors of a 128GB RTX gaming card, but this is 100% not that. This GPU is a compute engine aimed at inference in areas such as software development, research, and high-definition video generation. It will not be running Metal Gear Solid Delta: Snake Eater any time soon.\n\nVera Rubin NVL144 CPX rack\n\nThe GPU delivers up to 30 petaFLOPs of NVFP4 compute and integrates hardware attention acceleration that Nvidia says is three times faster than the GB300 NVL72.\n\nIt also incorporates four NVENC and four NVDEC units to accelerate video workflows.\n\nAs part of Nvidia’s broader push toward disaggregated inference, Rubin CPX is designed to handle the compute-heavy context phase, while other Rubin GPUs and Vera CPUs address generation tasks.\n\nBy concentrating Rubin CPX on context processing tasks, Nvidia aims to improve throughput while lowering high-value inference deployment costs.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nNvidia’s Dynamo software will manage things behind the scenes, handing low-latency cache transfers and routing across components.\n\nThe company’s largest deployment model is the Vera Rubin NVL144 CPX rack. Each unit integrates 144 Rubin CPX GPUs, 144 Rubin GPUs, and 36 Vera CPUs.\n\nTogether they deliver 8 exaFLOPs of NVFP4 compute, 100TB of high-speed memory, and 1.7PB/s of memory bandwidth.\n\nQuantum-X800 InfiniBand or Spectrum-X Ethernet with ConnectX-9 SuperNICs provide the connectivity.\n\nShipments of Rubin CPX and the NVL144 CPX racks are currently penciled in for late 2026, following the recent tape-out at TSMC.\n\nNvidia’s roadmap includes Rubin Ultra, now expected in 2027, and Feynman, slated for 2028.\n\nThose designs will extend the Rubin architecture with higher density modules, HBM4E memory, and faster networking.\n\nVia Videocardz\n\n(Image credit: Nvidia)",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/nvidia-has-launched-a-gpu-with-128gb-of-gddr7-ram-but-yeah-theres-no-way-it-will-sell-one-to-us-to-run-games",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Top Stock Reports for NVIDIA, Meta Platforms & Alibaba",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_35ba17c2-11fe-49ca-a1c5-2beafda45349",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "China’s souring on Nvidia. Here’s why",
      "content": "Beijing is souring on Nvidia.\n\nChina, which used to be one of Nvidia’s largest markets, seems largely conflicted about reaccepting Nvidia’s lower-tech H20 chips that Trump administration finally allowed to resume sales of in July. The Chinese tech industry might be excited about the Nvidia chip flow resuming, but the government is allegedly not.\n\nChinese authorities have discouraged local tech companies from purchasing Nvidia chips citing national security concerns, and even questioned industry titans like Tencent over their purchases of Nvidia chips, according to Reuters.\n\nIn response, tech giants like Alibaba and Baidu have begun using their own chips to train smaller AI models, the Information reported on Thursday, but they will reportedly continue to use some Nvidia chips.\n\n“The competition has undeniably arrived,” an Nvidia spokesperson told Gizmodo. “Customers will choose the best technology stack for running the world’s most popular commercial applications and open-source models. We’ll continue to work to earn the trust and support of mainstream developers everywhere.”\n\nChinese development is ramping up. China chip stocks have experienced a major boom so big that the Beijing-based company Cambricon had to warn investors recently. Tech giants like Huawei and Alibaba are leading the push, but smaller companies are also making strides.\n\nShanghai-based tech company MetaX told the Wall Street Journal last month that it’s preparing to start mass production of a new chip that has bigger memory than Nvidia’s H20.\n\nStill, largely no chip offering so far has been considered completely up to par with Nvidia’s best offerings. Reuters reported last week that top Chinese tech firms like Alibaba and ByteDance are still very keen to get their hands on Nvidia chips. That’s despite the fact that the Nvidia chips that are being sold to China are downgraded versions of existing models, developed to abide by U.S. exports restrictions.\n\nThe chips saga\n\nSome experts in Washington think any supply of American tech to China has sizable national security risks attached to it. They also claim the chips can assist China in outpacing American AI innovation.\n\nThe Biden administration was first to enforce export restrictions on Nvidia chips sold to China, in an effort to curb the entry of high-tech chips into China off of those fears.\n\nBeijing landed a particularly big blow to domestic AI confidence earlier this year with Deepseek’s R1, an AI model that rivaled the best of American companies offerings using lower cost chips, inadvertently showing Americans that Chinese innovation did not require the top Nvidia chips.\n\nThat fueled the blanket ban decision which turned out to be less effective than expected when a Financial Times report found that Nvidia’s highest tech chips were being smuggled into China in the absence of the lower tech H20s.\n\nThe decision was also a big hit to Nvidia: executives shared in a May earnings call that they had to revise revenue expectations down for the quarter by about $8 billion due to the restrictions.\n\nAfter an intense lobbying effort by Nvidia CEO Jensen Huang, Trump reversed his decision in July, allowing H20 chips sales to China. In exchange, Trump demanded that Nvidia, and fellow American chipmaker AMD, both give the U.S. government a 15% cut of all of their chips revenue in China.\n\nJust when Nvidia thought all was finally well, Beijing started raising concerns about the new Nvidia chips coming into China having kill switches and backdoors, urging Chinese companies to not use them. Nvidia has denied the claim.\n\nThe remaining political uncertainty has continued to cast a shadow on Nvidia’s performance in China. The company conceded in its latest earnings call that they were facing disappointing numbers from the region still and were yet to begin H20 shipments.\n\nWhy did Beijing change its mind?\n\nChina has a long relationship with Nvidia. The downturn in that relationship began after the first export restrictions went into effect, ramped up after an antitrust probe in December and has developed a life of its own under Trump’s trade war.\n\nChinese officials have voiced security concerns related to the latest round of chips set to enter the country, but this attitude change has less to do with Nvidia itself and more about China’s own chip industry.\n\nChinese AI industry is currently dependent on American chipmakers like Nvidia, and that gives Americans an edge. In the absence of Nvidia chips, China will have to develop their own high-tech chips that can rival and even surpass the quality of Nvidia chips. If that happens, the United States can be at jeopardy to lose its hold on the global chips demand, and China is the runner-up.\n\nThe country is making a big bet on AI, announcing an $8.2 billion AI-investment fund earlier this year, in an effort to spur innovation and reach independence.\n\n“It’s unfortunate to see that we in Asia, including China, are emulating the U.S. when it comes to developing algorithms and large models,” Wei Shaojun, an adviser to senior Chinese government officials and a professor at top Beijing university Tsinghua University told a forum in Singapore on Thursday. He warned that staying on this path of dependence could be “lethal” for the region, according to Bloomberg.\n\nAlong with the chips push, the country has increasingly emphasized global cooperation in AI, and center to that initiative is Beijing’s desire to cement itself at the center of the global AI trade.\n\nIt seems China is coming to terms with the fact that aspiration won’t be achievable as long as the industry is dependent on the U.S. for chips, especially when Washington has demonstrated that its trade policy decisions are volatile.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/chinas-souring-on-nvidia-heres-why-2000657632",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Chinese scientists claim to have built the first \"brain-like\" AI model — said to be up to 100 times faster than ChatGPT",
      "content": "In the mid-20th Century, we had the Space Race kick off, and in the mid-2020s, we're very much in the middle of the AI race. Nobody is sitting still, with parties all around the globe pushing for the next big advancements.\n\nChinese scientists are now making a big claim to have made one of their own. As reported by The Independent, SpikingBrain1.0 is a new large language model (LLM) out of China, which ordinarily might not be so exciting. But this isn't supposed to be any normal LLM. SpikingBrain1.0 is reported to be as much as 100x faster than current models such as those behind ChatGPT and Copilot.\n\nAll down to the way the model operates, which is something completely new. It's being touted as the first \"brain-like\" LLM, but what does that actually mean? First, a little background on how the current crop of LLMs work.\n\nThe current crop of LLMs work very differently to what's claimed of SpikingBrain1.0 (Image credit: Windows Central)\n\nBear with me on this one, hopefully I can make it make sense and as simply as possible. Essentially, the current crop of LLMs look at all of the words in a sentence at once. They're looking for patterns, relationships between words, whatever their position in the sentence.\n\nIt uses a method known as Attention. Take a sentence such as this:\n\n\"The Baseball player swung the bat and hit a home run.\"\n\nYou, as a human, read that sentence and instantly know what it means, because your brain immediately associates \"Baseball\" with the words that come after it. But to an LLM, the word \"bat\" on its own could be both a baseball bat or the animal. Without examining the rest of the sentence, it wouldn't be able to make that differentiation.\n\nAttention in an LLM will look at the whole sentence and then map out relationships between the words to understand it. It will identify the other terms, such as \"swung\" and \"baseball player,\" to identify the correct definition and make better predictions.\n\nThis connects with the training data for the LLM, where it will have learned that \"baseball\" and \"bat\" often go together.\n\nThe new model has been developed to rely not on NVIDIA hardware, running on homegrown chips from MetaX. (Image credit: Getty Images | WANG ZHAO)\n\nExamining whole sentences at once takes resources, though. And the larger the input, the more resources needed to understand it. This, in part, is why current LLMs generally need massive amounts of computing power. Every word is compared to every other word, and it consumes a lot of resources.\n\nSpikingBrain1.0 claims to mimic the human brain's approach, focusing only on nearby words, similar to how we would approach a sentence's context. A brain fires the nerve cells it needs to; it doesn't run at full power all of the time.\n\nThe net result is a more efficient process, with its creators claiming between 25x and 100x performance gains over current LLMs. Compared to something such as ChatGPT, this model is supposed to selectively respond to inputs, reducing its resource requirements to operate.\n\nAs written in the research paper:\n\n\"This enables continual pre-training with less than 2 percent of the data while achieving performance comparable to mainstream open-source models.”\n\nPerhaps equally interesting, at least for China, is that the model has been built not to rely on GPU compute from NVIDIA hardware. It has been tested on a locally produced chip from a Chinese company, MetaX.\n\nCould SpikingBrain1.0 lead to a path where we need less of these to power AI? (Image credit: Windows Central | Ben Wilson)\n\nThere is, of course, much to be considered, but on paper at least, SpikingBrain1.0 could be a logical next evolution of LLMs. Much has been made of the impact AI will have on the environment, with vast energy requirements and equally vast requirements to cool these massive data centers.\n\nIt's bad enough running LLMs in Ollama at home with an RTX 5090. My office gets hot, and with a graphics card that can draw close to 600W, it's hardly efficient. Scale that thought up to a data center full of GPUs.\n\nThis is an interesting development if it all pans out to be accurate. It could be the next leap forward, but only if the balance of accuracy and efficiency is there. Exciting times for sure, though.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/artificial-intelligence/chinese-scientists-claim-to-have-built-the-first-brain-like-ai-model",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Borderlands 4 Dev Gearbox Asks PC Gamers to Keep Playing for at Least 15 Minutes After They Tweak Settings to See How Performance Has Changed, as Negative Steam Reviews Pile Up",
      "content": "Borderlands 4 has launched on Steam to big concurrent player numbers, but the release was marred by complaints about PC performance that have resulted in a ‘mixed’ user review rating on Valve’s platform.\n\nBorderlands 4 peaked at 207,479 concurrent player numbers on Steam yesterday, September 11, which was significantly higher than any previous Borderlands before it. However, the game launched to ‘mostly negative’ Steam reviews over performance issues and crashing, before recovering overnight to ‘mixed.’\n\nThe complaints revolve around poor performance even on high powered PCs, with some affected by crashing that makes the game difficult to even start.\n\n“Terrible optimization. Another Unreal Engine 5 casualty. Not worth buying in its current state unless you have a NASA PC,” said one person in a negative review.\n\n“Terrible, terrible performance. Worst I've ever seen. Turned it down to Low graphics presets and couldn't hit 60 FPS, even with FSR upscaling on my RX 6900 XT,” said another.\n\nIn response, Gearbox posted a Borderlands 4 Nvidia Optimization guide on Steam, advising players how to optimize their graphics settings for “better performance and framerates” on PC with the Nvidia app.\n\n“As PC gamers begin their Vault-hunting journeys in Borderlands 4, we've seen early feedback from the community surrounding graphics settings and how to achieve optimal performance,” Gearbox said, before outlining the “expected results” for the Borderlands 4 PC specs:\n\nMinimum PC specs - 1080p @ 30FPS with Low Preset settings\n\nRecommended PC specs - 1440p @ 60FPS with Medium Preset settings\n\nGearbox then issued a piece of advice to PC gamers that to me reads like an effort to prevent players from making knee-jerk reactions to the game's performance as soon as they’ve changed their settings: “Please note that any time you change any of your graphics settings, your shaders will need to recompile. Please keep playing for at least 15 minutes to see how your PC's performance has changed.”\n\nGearbox went on to show the “Optimal Settings” charts provided by Nvidia with suggestions for which graphics settings may work best for your combination of GPU and desired display resolution. Meanwhile, it recommended using the Nvidia app to download and install Nvidia’s newest Game Ready Driver (581.29) and “optimize for your system.” If all else fails, “please contact 2K Support for direct assistance.”\n\nBorderlands 4 Review Screenshots View 159 Images\n\nGearbox and publisher 2K Games will be keen to address the performance complaints early, given the impact negative reviews on Steam can have on a video game’s success. Ahead of launch, Gearbox development chief Randy Pitchford had said the Borderlands 4 Day 1 patch “does a lot,” amid concern about the performance of the looter shooter. Pitchford had responded to concern about Borderlands 4’s pre-release performance on PC from some users on X / Twitter.\n\nDespite the Day 1 patch, playing Borderlands 4 on older hardware won't miraculously unlock \"buttery smooth performance,\" Pitchford added. It should be expected that Borderlands 4 is “unplayable” if you’re trying to use a PC below min-spec, he said, and, generally, playing new AAA games on older hardware won't achieve impressive results.\n\nHere’s Pitchford's comment in full:\n\nThe Day 1 patch does a lot! That said, the expectation for using a below min-spec machine should be that the game is unplayable. That the game runs at all on your system is a miracle. That you can get 55 - 60 fps out of heavy combat is actually incredible given how the engine and what's going on under the hood. Your specification doesn't indicate if you're on SDD or HDD, but that could also explain some of the hitching. It's a big, bold, new, seamless world and I'm sorry to say that older hardware may not provide buttery smooth performance for the latest gen AAA games, as has always been the case since the dawn of PC gaming.\n\nAs a reminder, here are Borderlands 4’s PC specs:\n\nBorderlands 4 System Requirements:\n\nMinimum:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-9700 / AMD Ryzen 7 2700X\n\nMemory: 16 GB RAM\n\nGraphics: NVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. Requires 8 CPU Cores for processor. Requires 8 GB VRAM for graphics. SSD storage required\n\nRecommended:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nMemory: 32 GB RAM\n\nGraphics: NVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. SSD storage required\n\nIf you are delving into Borderlands 4 don't go without our updated hourly SHiFT codes list. We've also got a huge interactive map ready to go and a badass Borderlands 4 planner tool courtesy of our buds at Maxroll. Plus check out our expert players' choices for which character to choose (no one agreed).\n\nWesley is Director, News at IGN. Find him on Twitter at @wyp100. You can reach Wesley at wesley_yinpoole@ign.com or confidentially at wyp100@proton.me.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/borderlands-4-dev-gearbox-asks-pc-gamers-to-keep-playing-for-at-least-15-minutes-after-they-tweak-settings-to-see-how-performance-has-changed-as-negative-steam-reviews-pile-up",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "I tried the new recommended settings for Borderlands 4 and oh no, they don’t actually fix its stuttering",
      "content": "It’s been a rough first day at the office for Borderlands 4, which has launched amid spyware denials and widespread user reports of dodgy PC performance. That being crashing, stuttering, the usual Unreal Engine 5 trouble at the mill. Framerate-related grumbling in particular has prompted a Steam post from Gearbox, presenting a setting-by-setting guide to optimisation on GeForce graphics cards that their pals at Nvidia put together.\n\nFirst off, oi, that’s my job. Second, I say \"prompted\", but the sheer number of GPUs it covers – separately for 1080p, 1440p, and 4K resolutions – has produced settings tables so rich in cells that it’s far more likely a sweating intern has spent the entire past week cranking these out. No disrespect, obviously. Solidarity to benchmarkers. But, are these guides reliable?\n\nLet’s start by taking a my god, look at the size of it.\n\nImage credit: 2K\n\nMaybe the text version further down the post is more easily readable?\n\nImage credit: 2K\n\nAh. JPG it is then, where we can see that even at 1080p, Borderlands 4 thinks you should run it with both DLSS upscaling and frame generation. I booted up the RPS Test Rig with an 8GB RTX 4060 Ti, one of the included cards, and settled down in one of the more demanding open world areas for a spot of corroboration.\n\nAnd yes, DLSS – or the GPU-supported upscaler of your choosing – is clearly intended as standard procedure. With frame gen disabled and Nvidia’s suggested settings in place, I was averaging 99fps, but switching off Quality-level DLSS and running at native 1080p saw that stoop to 62fps.\n\nFrame gen itself, meanwhile, is just weird. It did get my average framerate up to 148fps (visually, anyway – only 90 to 95 of those were 'real' frames) but motion didn’t appear any smoother. In fact, it gained a harsher, grittier quality that didn’t look dissimilar to a lower framerate. I’ve seen this happen with less advanced upscalers like the original FSR 3.0, but never with the new and improved DLSS 4.\n\nOtherwise, Gearbox/Nvidia’s settings guide for the RTX 4060 Ti is decent, if a little excessive. I’m not sure it needs such deep cuts to volumetric clouds and the main shadow quality options, both of which produced negligible differences between their highest and lowest settings in my testing. Foliage density, volumetric fog, and directional shadows all have slightly bigger framerate impacts, but I only lost 3-5fps apiece by toggling them to Very High. Which, by the by, is worth trying for foliage, given how bare the game looks without its veggies.\n\nImage credit: 2K\n\nStill, the guide does correctly identify these as leveraging some level of performance tax, and I’d have to agree with it keeping lighting quality on Low. This is one of the heaviest settings of the bunch, with my RTX 4060 Ti falling from 99fps to 74fps after changing this single setting up to Very High, with surprisingly little gain in terms of visual niceness. Frame gen remains a no-no, but fair dos, you would be getting a more fined-tuned Borderlands 4 with these than any of the presets.\n\nUnfortunately, a good showing for Gearbox’s big Excel project ultimately doesn’t truly address its performance problems. I haven’t had any crashes yet but stuttering is, indeed, a common occurrence, especially during big fights where multiple baddies are onscreen and some manner of elemental particle effect tornado is blowing through them. Which, this being a Borderlands game, is most fights. Although higher framerates can help mask the effect, it doesn’t seem that you can completely stutter-proof your PC, even with pre-tailored settings recommendations.\n\nPerhaps unsurprisingly, then, it doesn’t pay to try skirting under the system requirements. I had a cheeky go on my RTX 4050 laptop, the 8GB system RAM and 6GB VRAM of which come under the official minimums, and even DLSS wasn’t enough to stay above 30fps in the open world. With, naturally, plenty of big stutters along the way.\n\nWhether you’re playing Borderlands 4 or not, we’re all uncomfortably familiar with the problem at this point. It’s one that’s frayed the edges of games, unusual Unreal Engine 5 ones, from recent releases Wuchang: Fallen Feathers and Dune: Awakening back to the likes of Remnant II and beyond. We also know by now, as Gearbox and 2K should, that it’s not something that can be fixed on our end by changing a few settings.",
      "source": "Rock Paper Shotgun",
      "url": "https://www.rockpapershotgun.com/i-tried-the-new-recommended-settings-for-borderlands-4-and-oh-no-they-dont-actually-fix-its-stuttering",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Companies' RTO plans often include turning to the data. It doesn't always work out that well.",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nHappy Friday! Ever wondered what Elon Musk's xAI stands for? (Of course you have.) According to a recent Tesla filing, the startup's full name is \"eXploratory Artificial Intelligence.\" There's just one problem: Neither Musk nor xAI appears to have publicly said that's the case.\n\nIn today's big story, companies' push to get employees back to the office includes looking at the data. It's working better for some (Microsoft) more than others (AT&T).\n\nWhat's on deck:\n\nMarkets: Forget \"Equities in Dallas,\" Wall Street is investing big in its Texas offices.\n\nTech: Microsoft wants to show it can do AI all by itself.\n\nBusiness: Flip wanted to take on TikTok. Instead, it flopped.\n\nBut first, Bueller? Bueller? Bueller?\n\nIf this was forwarded to you, sign up here.\n\nThe big story\n\nSwiping in\n\nPau Barrena/AFP via Getty Images\n\nAT&T = Attendance taking & trouble.\n\nThat's the pickle the telecom giant is in when it comes to enforcing its RTO policy. A system meant to track the hours workers actually spend in the office is causing more headaches than it's worth, reports BI's Dominick Reuter.\n\nAT&T chief marketing and growth officer Kellyn Kenny told employees last month she understands inaccuracies in the attendance tracking tool are \"driving people to the brink of frustration.\"\n\nIn case you aren't dialed in to what's going on at AT&T, here's a refresher. AT&T required people to return to the office five days a week at the beginning of the year. The rollout didn't go smoothly, with everything from parking spots to desks filling up quickly. Things seemed to come to a head last month when CEO John Stankey sent a memo telling workers to get on board with RTO or get out of the way.\n\nAT&T's attendance tracker was meant to suss out people abusing the system by swiping into the office only for a few hours, known as \"coffee-badging.\" To catch those \"freeloaders,\" as Kenny described them, the company set up benchmarks around the number of hours and days workers were to badge in.\n\nBut the data wasn't always perfect. Routine things — attending doctors' appointments, taking lunch — complicated matters.\n\nIn some cases, AT&T's attendance tracker backfired. If the company wanted eight hours a day, workers wondered, why bother putting in more time than that?\n\nMicrosoft CEO Satya Nadella speaking at a conference in San Francisco. Carlos Barria/REUTERS\n\nMeanwhile, another corner of the business world is touting its RTO data.\n\nMicrosoft executives told employees at an all-employee town hall that internal data shows workers spending more time in the office are \"thriving,\" writes BI's Ashley Stewart.\n\nThe data comes after Microsoft announced its RTO plans.\n\nMicrosoft HR chief Amy Coleman said people who spend at least three days in the office, which is Microsoft's new RTO mandate, are energized, empowered, and find meaning in their work.\n\nHowever, CEO Satya Nadella acknowledged the importance of maintaining some flexibility with work, according to internal comments at the town hall reviewed by Ashley.\n\n\"There's tons of empowerment here for people to go organize this in such a way that it works for the folks,\" Nadella said.\n\n3 things in markets\n\nInside a Trader Joe's store in Miami Beach, Florida. Jeff Greenberg/Getty Images\n\n1. Inflation came in as hot as expected. CPI data showed inflation in August ticked up to 2.9%, up from 2.7% in June and July. The new numbers have had little effect on the Fed's likelihood of cutting rates next week, which traders and economists still expect to happen.\n\n2. Nvidia has finally won over one of Wall Street's biggest skeptics. DA Davidson changed its rating on the chip giant's stock from \"neutral\" to \"buy,\" raising its price target from $195 to $210 a share. The firm cited rapid development and AI adoption among companies for its flipped perspective.\n\n3. Everything's bigger in Texas — even the banks. Big financial players like Goldman Sachs, JPMorgan, and the New York Stock Exchange are setting up shop in the Lone Star State, which promises business-friendly taxes. See what they're up to out west.\n\n3 things in tech\n\nGetty Images\n\n1. US data center construction breaks new ground. Thanks to ever-rising demand from AI, spending on data center construction hit $40 billion annually in June, up 28% from the year before. That's a new record, and it shows no signs of slowing: Big Tech's spree could total more than $1 trillion by 2028.\n\n2. Oh great, now there's AI \"psychosis risk\" to worry about. Wall Street is beginning to evaluate AI chatbots and models based on \"psychosis risk,\" or the tendency of the bot to exacerbate user mental health problems. A recent study showed stark differences between the models that mitigate risk and those that amplify it, leaving analysts concerned.\n\n3. It looks like Microsoft might be trying to forge its own AI path. The company is planning \"significant investments\" in its own AI chip cluster, Microsoft AI CEO Mustafa Suleyman said in an all-employee town hall meeting. Microsoft appears to be drifting apart from OpenAI, with Suleyman saying it should be \"self-sufficient\" in the sector.\n\n3 things in business\n\nFlip; Tyler Le/BI\n\n1. A TikTok challenger's mysterious demise. Video app Flip looked primed to take over TikTok's dominance in mid-January amid mounting regulatory pressure. Seven months later, the $1 billion company was dead. Former employees, investors, creators, and more told BI how it flew and then flopped.\n\n2. David Ellison means business. Paramount's reported bid for Warner Bros. Discovery shows the Paramount CEO is serious about taking on Netflix and Disney for Hollywood's crown. It doesn't hurt that he has the financial backing of his father, Larry Ellison, who briefly became the richest man in the world this week.\n\n3. America's oldest workers are taking pay cuts. As part of BI's \"80 over 80\" series, dozens of older workers told us they earn less than $20 an hour. Many held white-collar or high-paying blue-collar jobs before, but took on low-paying jobs as they got older to make ends meet.\n\nIn other news\n\nWhat's happening today\n\nCongressional Budget Office releases its \"Current View of the Economy from 2025 to 2028,\" including short-term projections for major economic indicators.\n\nNew iPhones are available to pre-order.\n\nDan DeFrancesco, deputy editor and anchor, in New York. Hallam Bullock, senior editor, in London. Akin Oyedele, deputy editor, in New York. Grace Lett, editor, in New York. Amanda Yen, associate editor, in New York.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/att-rto-stankey-memo-remote-work-rto-microsoft-2025-9",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "How AMD, Nvidia, Broadcom Can Ride Oracle’s $455B Cloud Surge",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/12/how-amd-nvidia-broadcom-can-ride-oracles-455b-cloud-surge/",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Jim Cramer Discusses NVIDIA Corporation (NVDA) & AI Spending",
      "content": "We recently published 13 Latest Stocks on Jim Cramer’s Radar. NVIDIA Corporation (NASDAQ:NVDA) is one of the stocks Jim Cramer recently discussed.\n\nNVIDIA Corporation (NASDAQ:NVDA) continues to be a stock that’s favorably present on Jim Cramer’s radar even though the shares have experienced some turbulence lately. The CNBC TV host firmly holds the opinion that the firm and its CEO, Jensen Huang, are heralding a new industrial revolution. This time, Cramer discussed the spending estimates that he was hearing related to NVIDIA Corporation (NASDAQ:NVDA):\n\nPhoto by Christian Wiediger on Unsplash\n\n“A lot of people, when I used to put out the three trillion number, that Jensen Huang put out, people would say well listen, you’re constrained by how much these companies can spend. But now the number’s seven trillion. I’m hearing seven trillion, that’s going to be spent. . .but that’s unbelievable!\n\nWhile we acknowledge the potential of NVDA as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/jim-cramer-discusses-nvidia-corporation-194654028.html",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Nvidia and Kioxia target 100 million IOPS SSD in 2027 — AI server drives aim to deliver 33 times more performance",
      "content": "Kioxia is working with Nvidia to build a solid-state drive that would deliver 100 million random IOPS already in 2027, the company said at a news conference earlier this month, Nikkei reports. Nvidia reportedly plans to use a couple of such SSDs — totalling a whopping 200 million IOPS — attached directly to its GPUs to boost AI performance.\n\n\"We will proceed with development in accordance with the proposals and requests from Nvidia,\" said Koichi Fukuda, chief technology officer of Kioxia's SSD division.\n\n100 million IOPS SSD\n\nKioxia's drives with 100 million random read speeds are projected to use a PCIe 7.0 interface to connect to GPUs in a peer-to-peer mode and will be exclusively designed for use in AI servers that need to access and process vast amounts of data quickly.\n\nToday's high-end solid-state drives can deliver around 3 million 4K random IOPS, but to meet the performance needs of modern and upcoming GPUs — which are optimized for burst memory access — they need to get substantially faster and change the way they interact with NAND media.\n\nEarlier this year, Silicon Motion's CEO Wallace Kou told Tom's Hardware that Nvidia was interested in building SSDs that offer as many as 100 million random IOPS, 33 times more than existing drives can deliver. Around the same time, Kioxia disclosed plans to build XL-Flash-based 'AI SSDs' with over 10 million 512K random read IOPS in the second half of 2026.\n\nAI workloads rely on frequent, small, random reads to retrieve embeddings, model parameters, or database entries. In such cases, 512-byte blocks better represent actual usage patterns than 4KB blocks and provide lower latency. While drives that operate 512B blocks may not deliver the same raw bandwidth as typical SSDs with 4K blocks, it is easier to scale out sequential read/write speeds with multiple drives than to lower the latencies of conventional SSDs.\n\nIt remains to be seen whether Kioxia's AI SSD with a 10 million 512K IOPS random performance will materialize in 2026 if Kioxia plans to build drives with a 100 million IOPS random performance in 2027.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nUsing XL-Flash?\n\nWhat is interesting is how exactly Kioxia plans to build its 100 million IOPS drive. Its proposed AI SSD is based on XL-Flash, which is SLC NAND memory with high endurance, very low latency, and fairly high performance. Kioxia's XL-Flash devices feature 16 planes (up significantly from 3 to 6 planes on modern 3D NAND devices for client PCs), which points to higher sequential and random performance. As Kioxia does not publish specifications of XL-Flash, it is impossible to judge the per-device performance of this memory type.\n\nMeanwhile, considering that an Innogrit Tacoma-based 400GB XL-Flash SSD with 32 NAND dies (with seven allocated for overprovisioning) and a PCIe 5.0 x4 interface delivers 3.5 million random read IOPS and 0.5 million random write IOPS, we can estimate that each die contributes up to 109,375 random read IOPS and 15,625 random write IOPS—though this calculation comes with some caveats.\n\nAssuming perfect linear scaling across loads of NAND devices, a 100 million 512B IOPS SSD would require 915 of such dies (presuming the same levels of over provisioning). Now that Kioxia knows how to pack 32 NAND ICs into a single package, it can certainly build a drive based on 915 XL-Flash ICs (in 28 packages). Such a drive would require a special controller with at least a PCIe 5.0 x16 host interface (though PCIe 7.0 x4 would be more preferable). The problem is, there is no perfect linear scaling. Real-world performance of NAND devices in SSDs is limited by channel bandwidth, multi‑plane constraints, command pipelining/overheads, queue depth, firmware, and loads of other factors. Hence, the best case scenario for a 100 million 512B IOPS SSD featuring XL-Flash devices is a multi-controller module with dozens of controllers and a switch. Such a solution may well make sense in all-flash arrays, but Kioxia is explicitly talking about an SSD.\n\nWelcome, HBF?\n\nSince using traditional 3D NAND memory for a 100 million IOPS SSD with 512B blocks is not exactly feasible, whereas using a brand-new type of media on a commercial data center-grade product is highly unlikely, Kioxia might instead look to emerging technologies that use NAND memory in an unconventional way.\n\nOne of such technologies is probably high bandwidth flash (HBF) that packs up to 16 NAND devices and a logic die (a controller?) into a single stack and interconnects them using TSVs and microbumps. While HBF layers still use proven NAND memory cells, they are organized in multiple arrays to achieve a very high level of parallelism and therefore performance. We do not know whether Kioxia plans to use HBF for the project or stick to something similar. However, it is safe to assume that the knowledge it will gain from its experimentation with HBF to build ultra-high-performance SSDs is something the company intends to leverage.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/nvidia-and-kioxia-target-100-million-iops-ssd-in-2027-33-times-more-than-existing-drives-for-exclusive-use-in-ai-servers",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Super Micro Computer Stock (SMCI) Surges with Nvidia Shipments Underway",
      "content": "Prime Minister Sébastien Lecornu’s sudden resignation deepens France’s political instability, spooking markets and complicating President Macron’s government ahead of budget battles.\n\nMarket Summary Markets show cautious optimism as U.S. stock futures edge higher driven by hopes for Federal Reserve rate cuts and AI sector momentum. However, geopolitical tensions and a prolonged U.S. government shutdown sustain volatility. Japan stocks rally on leadership changes, while French political upheaval sparks selloffs in Europe. Bitcoin's record highs reflect growing safe-haven demand amidst uncertainty.\n\nFifth Third Strikes $10.9 Billion Deal to Acquire Comerica Fifth Third to Absorb Comerica in $10.9 Billion Stock Deal Fifth Third Bancorp confirms $10.9 billion acquisition of Comerica, marking a major consolidation in U.S. regional banking. The all-stock deal aims to expand market presence amid banking sector challenges.\n\nFigure of the Day 125,000 - Bitcoin's new record price in USD, signaling heightened crypto market interest amid economic uncertainty.\n\nFrench PM Lecornu Resigns Hours After Cabinet Reveal New French PM Quits After Less Than A Month in Office French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after unveiling his cabinet. This resignation deepens France’s political crisis with markets reacting negatively.\n\nGovernment Shutdown Hits Second Week with No Breakthrough Shutdown Stalemate Promises Prolonged Federal Gridlock The U.S. federal government shutdown extends beyond a week, with lawmakers at an impasse. Threats of mass federal layoffs mount, fueling market uncertainty and increasing economic pressure.\n\nBullish SpaceX Secures $714M Pentagon Contract, Edging Out Blue Origin Elon Musk’s SpaceX wins major defense contracts, reinforcing its dominance in military space launches and solidifying government partnerships. More on benzinga.com\n\nJapan Stocks Rally as Takaichi Takes Ruling Party Helm Nikkei Inches to Record High on Takaichi’s Pro-Stimulus Win Japan’s stock market soars as ultra-conservative Sanae Takaichi wins the ruling party leadership, triggering yen weakness. Investors expect pro-stimulus policies and possible BOJ monetary shifts.\n\nBitcoin Surges Past $125,000 Amid Market Turmoil Crypto Rally Continues with Bitcoin at New All-Time High Bitcoin hits new record highs surpassing $125,000 despite market volatility. Investors flock to cryptocurrencies as safe havens amid geopolitical tensions and U.S. government shutdown uncertainty.\n\nBearish Aston Martin Shares Tank as Tariff Pressures Slash Profit Outlook Luxury carmaker Aston Martin issues profit warning amid rising U.S. tariffs and supply chain woes, triggering a steep stock selloff. More on businessinsider.com\n\nAston Martin Shares Dive on New Profit Warning — Tariff Drag Lingers Aston Martin Slashes Profits Amid US Tariff Turmoil Aston Martin’s shares plunge after issuing fresh profit warnings citing ongoing tariff impacts and supply chain challenges. The luxury carmaker seeks proactive support amid uncertain US trade policies.\n\nSpaceX Lands $714 Million Pentagon Contract, Beating Blue Origin SpaceX outpaces Blue Origin by securing $714 million Pentagon contract for military space missions, bolstering Elon Musk’s dominance in U.S. defense space operations.\n\nRegulatory Impact EU financial regulator ESMA moves to centralize oversight of stock exchanges, crypto firms, and clearing houses, aiming to boost market stability across member states.\n\nQualtrics to Acquire Press Ganey in $6.8 Billion Healthcare Deal Qualtrics plans $6.8 billion acquisition of Press Ganey Forsta to strengthen healthcare technology footprint. The deal includes cash and debt components, signaling strategic expansion.\n\nQuote \"The political instability in France is weighing heavily on markets, signaling uncertain times ahead for investors and policymakers alike.\"\n\n— Senior European Market Strategist\n\nCourt Halts Trump’s National Guard Deployment to Oregon U.S. judges temporarily block Trump administration’s National Guard deployments to Oregon and Portland amid legal battles. States challenge federal troop movements amid rising tensions.\n\n2025 Nobel Prize in Medicine Honors Immunology Trailblazers Immunology Pioneers Share Nobel Prize for Medicine 2025 Nobel Prize in Medicine awarded to pioneers in immunology for breakthroughs in immune system research, advancing understanding of physiological disease mechanisms.\n\nESMA Pushes for Unified EU Oversight of Exchanges and Crypto EU’s financial watchdog plans centralized oversight of stock exchanges, crypto firms, and clearing houses to harmonize regulation across the bloc and enhance capital market stability.\n\nOPEC+ Approves Small Oil Production Hike, Markets React OPEC+ Output Raised Slightly; Price Sentiment Wavers OPEC+ agrees to a modest 137,000 barrel per day oil output increase in November amid concerns of oversupply. Market remains cautious as global economic outlook loosens.\n\nTesla Reports Record Q3 Deliveries Amid Emerging Headwinds Tesla sets record Q3 vehicle deliveries but faces emerging operational challenges. Positive growth outlook is tempered by supply chain concerns and market pressures.\n\nStock Futures Rise on Fed Rate-Cut Hopes and AI Buzz Wall Street Futures Up as Investors Eye AI and Policy Moves Wall Street stock futures edge mostly higher, supported by hopes of Fed rate cuts and rapid AI sector growth despite the shadow of a prolonged U.S. government shutdown.\n\nHong Kong Stocks Slide as U.S. Shutdown Hurts Sentiment Hong Kong stocks dip due to dampened investor sentiment linked to U.S. government shutdown; demand rises for safe-haven assets like gold amid global uncertainties.\n\nAmazon Lets Prime Shoppers Add Last-Minute Items to Delivery Amazon enhances its Prime offering with 'Add to Delivery' feature allowing last-minute additions to shipments, aiming to boost holiday shopping convenience.\n\nChina Unveils Stealth Fighter Jet Development Footage Powerful jet fighter development footage emerges from China, positioning the country as the global leader in stealth combat aircraft alongside the U.S.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/eb7e18f3de0e9bc9",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "AI drone swarms revolutionize wildfire detection and air quality monitoring",
      "content": "University of Minnesota researchers have developed AI-powered drone swarms to track wildfire smoke in 3D, offering a better way to predict air pollution. (CREDIT: Shutterstock)\n\nFrom the outside, wildfire smoke may look like a drifting gray cloud. But for scientists, these plumes are dynamic, complex, and potentially dangerous. They can stretch for hundreds of miles, impacting air quality, visibility, and public health. Until now, capturing accurate data on how these smoke particles move and behave has been one of the most difficult tasks in atmospheric science.\n\nResearchers at the University of Minnesota Twin Cities have developed a groundbreaking way to observe and analyze wildfire smoke: a swarm of AI-powered aerial robots that can detect, track, and build 3D models of smoke plumes.\n\nUnlike traditional drones, these small flying machines work as a team. They recognize smoke, fly directly into it, and take high-resolution images from multiple angles. Their mission is to help us better understand how smoke travels—an understanding that could reshape how we predict air pollution and respond to environmental hazards.\n\nThis new study, published in the peer-reviewed journal Science of the Total Environment, opens doors to more accurate fire behavior models and better air quality predictions, not just for wildfires, but also for prescribed burns, volcanic eruptions, sandstorms, and other particle-driven events.\n\nA graphical abstract of the study. (CREDIT: Science of The Total Environment)\n\nBetween 2012 and 2021, about 50,000 prescribed burns were carried out in the United States—intentional fires set under controlled conditions to improve forest health and reduce wildfire risk. But even controlled burns carry risk. According to a 2024 report by the Associated Press, 43 of these burns spiraled out of control and became wildfires.\n\nThese numbers, while small in percentage, matter deeply. That’s because smoke particles, especially the small ones, can stay in the air for days and travel far from their source. “A key step is understanding the composition of smoke particles and how they disperse,” explained Jiarong Hong, professor of mechanical engineering at the University of Minnesota and senior author of the study. “Smaller particles can travel farther and stay suspended longer, impacting regions far from the original fire.”\n\nUnderstanding how these plumes evolve over time is essential for early hazard detection, public health responses, and emergency planning. Yet, traditional tools for studying smoke—like satellites, remote sensing, and Lidar—fall short. These tools lack the detail and flexibility needed to capture fast-changing flows of smoke, especially in rough terrain or remote regions.\n\nRelated Stories\n\nThat’s where the new drone swarm steps in. These AI-enabled robots are designed to adapt to the smoke’s size and shape. They gather rich data in real time—something existing technologies can’t do affordably or efficiently.\n\nThe Science Behind the Swarm\n\nThe team’s drone system includes one manager drone and four worker drones. These drones aren’t just fancy flying cameras—they’re mini laboratories in the sky.\n\nEach drone carries a 12-megapixel camera mounted on a three-axis gimbal for capturing smoke in motion. They are powered by long-lasting 6000 mAh batteries and guided by advanced flight controllers and NVIDIA Jetson processors. These processors allow the drones to recognize smoke in real time, adjust their paths, and capture the best angles for imaging.\n\nWhen launched, the drones work together to fly around a smoke plume, snapping high-resolution images from multiple directions. These images are then grouped by time intervals and fed into a computer model using something called a Neural Radiance Field (NeRF). This advanced AI model helps turn 2D images into a realistic, detailed 3D reconstruction of the smoke plume.\n\nIllustration of the drone swarm system that uses multi-view imaging for 3D smoke plume characterization. (CREDIT: Science of The Total Environment)\n\nThis step is key. With the 3D model, researchers can analyze the shape, direction, and flow of the smoke over time. It gives them crucial data like volume, angle of movement, and dispersion speed—all critical for improving fire and smoke simulation tools.\n\nOther cutting-edge AI techniques were considered, including Dynamic NeRF (D-NeRF) and RoDynRF, which are good at modeling motion. But these systems struggle with featureless subjects like smoke and require long training times. The drone swarm approach avoids those problems by directly capturing the data in the field.\n\n“This approach allows for high-resolution data collection across large areas—at a lower cost than satellite-based tools,” said Nikil Nrishnakumar, the study’s first author and a graduate researcher at the Minnesota Robotics Institute.\n\nFrom Research to Real-World Impact\n\nThe drone swarm has already been tested in field deployments and has shown promising results. With this system, the team can generate multiple 3D reconstructions over time, creating a time-lapse view of how a smoke plume changes in real-time. It’s like watching the plume evolve in 3D—a powerful tool for scientists and emergency responders.\n\nDrone hardware configuration showing the quadcopter with camera mounted on a 3-axis gimbal and GPS with RTK (left), and the NVIDIA Jetson Orin Nano (right). (CREDIT: Science of The Total Environment)\n\nBut the benefits of this technology reach far beyond wildfire science.\n\n“Early identification is key,” Hong emphasized. “The sooner you can see the fire, the faster you can respond.”\n\nThe drones could be used in other dangerous scenarios as well, including volcanic eruptions, dust storms, and even urban pollution events. Because the system is modular and cost-effective, it can be scaled up or down based on the size of the area being studied. This flexibility makes it a strong candidate for use by government agencies, environmental researchers, and emergency crews.\n\nThe next steps for the team involve making the system more autonomous and scalable. They’re now integrating fixed-wing drones with Vertical Takeoff and Landing (VTOL) capability. These new drones can fly longer distances—over an hour at a time—and don’t need a runway to take off. That opens the door to monitoring vast forests and hard-to-reach locations.\n\nIn addition, the team plans to explore Digital Inline Holography to improve particle characterization. This method could provide even deeper insights into what types of particles are present in a smoke plume and how they interact with the environment.\n\n“We’re not just building tools,” Nrishnakumar said. “We’re laying the groundwork for smarter, faster, and safer responses to environmental hazards.”\n\nFlowcharts detailing the steps involved in (a) stabilizing the manager drone, (b) collecting data with the worker drone swarm, and (c) processing captured data for 3D plume reconstruction and characterization. (CREDIT: Science of The Total Environment)\n\nA New Era of Smoke Science\n\nMany modern simulation tools like FIRETEC and QUIC-Fire already exist to model how fires spread and how smoke particles behave. These systems use complex inputs—everything from fuel type and moisture to wind speed and topography. But even the best models have one major limitation: they need real-world data to validate their predictions.\n\nThat’s why the drone swarm matters so much. It provides the missing piece—real, time-sensitive, high-resolution data that can make these simulations more accurate and useful.\n\nUntil now, simulation models have struggled to work in areas without detailed 3D maps of vegetation and terrain. They also haven’t been able to compare their predictions with real-world smoke movement, especially in complex or fast-changing environments. The drone swarm changes that by creating accurate 3D ground truth models that can be used for comparison and refinement.\n\nAs the climate warms and wildfire risks rise, these tools may become vital to protecting both ecosystems and human health. With more than 40% of the U.S. population living in areas prone to wildfire smoke, this research couldn’t come at a better time.\n\nThis project was supported by the National Science Foundation’s Major Research Instrumentation program and conducted with the help of the St. Anthony Falls Laboratory. Along with Hong and Nrishnakumar, the research team included Shashank Sharma and Srijan Kumar Pal, also from the Minnesota Robotics Institute.\n\nNote: The article above provided above by The Brighter Side of News.",
      "source": "Thebrighterside.news",
      "url": "https://www.thebrighterside.news/post/ai-drone-swarms-revolutionize-wildfire-detection-and-air-quality-monitoring/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Intel Loses Another Prominent Linux Engineer - Now Going To NVIDIA",
      "content": "In the past few months at Intel between layoffs / corporate reorganizations and some deciding to pursue job opportunities elsewhere, there have been unfortunate impacts to their Linux engineering resources. Intel over the summer lost some prominent Linux engineering talent and in turn has even led to upstream Linux drivers being orphaned along with other driver maintainers departing and various other staffing changes . Unfortunate for Intel, another notable Linux name has left the company.Colin Ian King announced today that it was his last day at Intel. Colin King had just been employed by Intel for nearly four years but is well known prior to then. Prior to joining Intel, Colin was a kernel engineer at Canonical where he worked on Ubuntu Linux for over 13 years. Colin King was well known for his Ubuntu Linux work and has contributed more than four thousand patches to the upstream Linux kernel over the years. At Intel, Colin continued his kernel contributions with performance optimizations and more.If his name doesn't ring a bell, perhaps you know it from Stress-NG with Colin being the lead developer of those kernel micro-benchmarks. Colin has made incredible contributions to the upstream Linux kernel community over the past many years.Colin announced his departure from Intel today on LinkedIn:\n\nIn there he also announced he will now apparently be working for NVIDIA. For the benefit of the upstream Linux kernel community, hopefully he will be continuing to focus on upstream Linux kernel activity at NVIDIA... Especially given their increasing open-source GPU driver activity as well as growing kernel activity elsewhere from their networking products to other data center offerings and also needing to ensure the Linux kernel is performing effectively for showcasing the power of their products for AI and more.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Colin-King-Leaving-Intel",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Supermicro (SMCI): Evaluating Valuation Following Launch of Blackwell Ultra AI Data Center Solutions",
      "content": "Super Micro Computer (SMCI) has just started shipping its highly anticipated NVIDIA Blackwell Ultra solutions worldwide, a move that is capturing plenty of investor attention. These new systems represent more than incremental upgrades. They promise to deliver rapid deployment and enhanced performance for some of the most demanding AI data center projects. With pre-validated racks, plug-and-play installation, and cutting-edge cooling innovations, Super Micro is making a bold play to lead the next wave of AI infrastructure.\n\nThis launch arrives at a pivotal moment for Super Micro. After a stretch of volatility, the stock jumped 4% on the news of these volume shipments, signaling a renewed sense of optimism in the company’s growth story. Over the past year, SMCI shares have wavered with a small year-over-year dip, but momentum has started building again in 2025, helped along by AI-driven product expansions and major partnerships. While there has been a near 50% year-to-date gain, recent months have seen some pullback, reminding investors that expectations remain high but not assured.\n\nAfter a big announcement and a sharp move, the big question remains. Is Super Micro ready for another leg up, or is the market already factoring in all that future growth?\n\nMost Popular Narrative: 39.6% Undervalued\n\nAccording to the most popular narrative, Super Micro Computer is considered significantly undervalued. The argument hinges on robust projected growth and strong positioning in the AI infrastructure market.\n\nPartnerships with NVDA, AMD, xAI and Intel position them as one of the most attractive providers of GPU data center infrastructure. They are also profiting from growth in other related industries such as Cloud, 5G and Storage. Using the SWS Fair Value tool and management guidance of $23bn for 2025 and $40bn for 2026, I decided to use a revenue growth rate of 50% to reach an estimated revenue of $50bn for 2028, which I consider conservative.\n\nCurious about what drives this bold undervaluation call? The key lies in aggressive growth assumptions and a premium multiple historically reserved for industry giants. Want to see how these strategic forecasts transform into a game-changing price target and why this narrative is gaining traction? The most intriguing projections are just one click away.\n\nResult: Fair Value of $74.53 (UNDERVALUED)\n\nHave a read of the narrative in full and understand what's behind the forecasts.\n\nHowever, risks remain, including potential regulatory hurdles and execution missteps. Either of these factors could challenge even the most optimistic projections for Super Micro.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/supermicro-smci-evaluating-valuation-following-125543430.html",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Stocks Reach Highs On Oracle And Fed Expectations",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/bill_stone/2025/09/13/stocks-reach-highs-on-oracle-and-fed-expectations/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "AI Will Not Make You Rich",
      "content": null,
      "source": "Joincolossus.com",
      "url": "https://joincolossus.com/article/ai-will-not-make-you-rich/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "U.S. Stock Market Nears Records Ahead of Fed Meeting; Nvidia, Meta, Tesla Eye Technical Breakouts",
      "content": null,
      "source": "International Business Times",
      "url": "https://www.ibtimes.com/us-stock-market-nears-records-ahead-fed-meeting-nvidia-meta-tesla-eye-technical-breakouts-3783273",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Randy Pitchford Addresses Borderlands 4 Console FOV Slider Complaints: 'There's Some Dreams I Have Where an FOV Setting Might Affect Fairness'",
      "content": "Randy Pitchford has responded to complaints about the console version of Borderlands 4 lacking a field of view (FOV) slider, suggesting fairness may have something to do with it.\n\nPlayStation 5 and Xbox Series X and S players of Borderlands 4 were shocked to discover not only a lack of a FOV slider in-game, but no motion blur toggle, either. The PC version of Borderlands 4 has settings for both — in the case of FOV you can increase the value in degrees up to 110 for both first-person play and vehicle use, and for motion blur you can change the amount and the quality.\n\nThe lack of a FOV slider is the biggest issue right now with Borderlands 4 on console, if anecdotal evidence across the internet is anything to go by, with some complaining that not being able to tweak the FOV value is causing them motion sickness.\n\n“Man, I've tried to play it twice today,” said redditor xInsaneAbilityx. “Both times I get that ‘car-sick’ feel after about 15 minutes and have to stop.” “Yeah I’m pretty sensitive to motion sickness and a narrow FOV in first-person makes me really dizzy. Combining that with motion blur just churns my stomach,” added Dallywack3r. “This game feels almost zoomed in, it‘s really not pleasant to play,” said christophlieber.\n\nThere are also suggestions the console version of Borderlands 4 lacks a FOV slider in order to maintain certain performance levels. By increasing the FOV, you’re putting the hardware under more strain and potentially impacting things like framerate.\n\nBut social media posts from Gearbox development chief Randy Pitchford suggest one of the considerations is fairness.\n\nBorderlands 4 Review Screenshots View 159 Images\n\n“Quickie for console friends: FOV settings,” Pitchford began. “There's some dreams I have where an FOV setting might affect fairness. I can't really talk about it yet, but I see this is important to you so we're looking at it.”\n\nPitchford included a vote in his social media post, which, after nearly 25,000 votes, reveals just how important a FOV slider is to his followers. At the time of this article’s publication, the option “FOV slider or GTFO!” had 72% of the vote.\n\nThe outspoken Gearbox boss went on to say players “have no idea what the team and I were planning and how FOV slider might affect fairness with such a thing.”\n\nHe added: “That said, I've always want to commit to and prioritize what Borderlands should be versus try to turn it into something it should. My hope is for my/our ambitions to be additive, not subtractive.”\n\nQuickie for console friends: FOV settings: There's some dreams I have where an FOV setting might affect fairness. I can't really talk about it yet, but I see this is important to you so we're looking at it. Vote here: — Randy Pitchford (@DuvalMagic) September 12, 2025\n\nSo, what is Pitchford actually saying here? The “fairness” quote has caused some confusion. Could it relate to an upcoming PvP mode? If so, why would the PC version have it? Right now, Borderlands 4 is a PvE co-op game, so the line about “fairness” has raised more than a few eyebrows.\n\nSome are wondering if Pitchford is talking about fairness in terms of the performance of the game giving some players an advantage. The higher the FOV, the more the player can see, versus the lower the FOV the more stable the frames are. Perhaps both give some level of advantage?\n\n“What does ‘fairness’ even mean?’ asked redditor buddachickentml. “Basically being impartial to all players without favoritism. Fairness to all,” suggested Wolf-O7. “Funny enough it's completely backwards though. Because console players aren't being treated fairly compared to their counterpart on PC. (Especially since this sort of sounds like a PVP mode the way he makes it seem).” Then, from Airaen: “Yeah, how is it fair that PC players can change the FoV and console players can't?” “Fairness in a PvE game? Will you ban ultrawide monitors?” said on social media user.\n\nBorderlands 4 supports crossplay between all platforms at launch, so Pitchford’s comments are doubly confusing.\n\nAs for motion blur, in another social media post Pitchford told console players \"we aren't down with motion blur and do not support it.\" He continued: “If you're seeing what seems to be motion blur, maybe check your television settings for whatever automatic BS it might be doing to your image? It's not us.”\n\nBut again, that comment is confusing given there are motion blur settings in Borderlands 4 on PC.\n\nRandy Pitchford has addressed Borderlands 4 console complaints. Photo by Jon Kopaloff/Getty Images for Lionsgate.\n\nWhatever Pitchford means here, Borderlands 4 has got off to a big start on Steam. It’s approaching a peak concurrent player count of 300,000 on Valve’s platform, where it is one of the most-played games. No other Borderlands game has come close to that in terms of concurrent player numbers on Steam.\n\nPitchford declared it impossible to break the Borderlands 4 servers this weekend through sheer weight of player numbers alone — and he’s so confident he’s publicly promised that Borderlands 4 won’t join the long list of big AAA games whose online systems fail at launch.\n\nWhile Borderlands 4 is off to a big start in terms of player numbers, it’s not entirely plain sailing for Gearbox. The release was marred by complaints about PC performance that have resulted in a ‘mixed’ user review rating on Valve’s platform. The complaints revolve around poor performance even on high powered PCs, with some affected by crashing that makes the game difficult to even start.\n\nIn response, Gearbox posted a Borderlands 4 Nvidia Optimization guide on Steam , advising players how to optimize their graphics settings for “better performance and framerates” on PC with the Nvidia app.\n\nGearbox then issued a piece of advice to PC gamers that to me reads like an effort to prevent players from making knee-jerk reactions to the game's performance as soon as they’ve changed their settings : “Please note that any time you change any of your graphics settings, your shaders will need to recompile. Please keep playing for at least 15 minutes to see how your PC's performance has changed.”\n\nIf you are delving into Borderlands 4 don't go without updated hourly SHiFT codes list . We've also got a huge interactive map ready to go and a badass Borderlands 4 planner tool courtesy of our buds at Maxroll. Plus check out our expert players' choices for which character to choose (no one agreed).\n\nWesley is Director, News at IGN. Find him on Twitter at @wyp100. You can reach Wesley at wesley_yinpoole@ign.com or confidentially at wyp100@proton.me.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/randy-pitchford-addresses-borderlands-4-console-fov-slider-complaints-theres-some-dreams-i-have-where-an-fov-setting-might-affect-fairness",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "AMD's RDNA4 GPU Architecture at Hot Chips 2025",
      "content": "RDNA4 is AMD’s latest graphics-focused architecture, and fills out their RX 9000 line of discrete GPUs. AMD noted that creating a good gaming GPU requires understanding both current workloads, as well as taking into account what workloads might look like five years in the future. Thus AMD has been trying to improve efficiency across rasterization, compute, and raytracing. Machine learning has gained importance including in games, so AMD’s new GPU architecture caters to ML workloads as well.\n\nFrom AMD’s perspective, RDNA4 represents a large efficiency leap in raytracing and machine learning, while also improving on the rasterization front. Improved compression helps keep the graphics architecture fed. Outside of the GPU’s core graphics acceleration responsibility, RDNA4 brings improved media and display capabilities to round out the package.\n\nMedia Engine\n\nThe Media Engine provides hardware accelerated video encode and decode for a wide range of codecs. High end RDNA4 parts like the RX 9070XT have two media engines. RDNA4’s media engines feature faster decoding speed, helping save power during video playback by racing to idle. For video encoding, AMD targeted better quality in H.264, H.265, and AV1, especially in low latency encoding.\n\nLow latency encoder modes are mostly beneficial for streaming, where delays caused by the media engine ultimately translate to a delayed stream. Reducing latency can make quality optimizations more challenging. Video codecs strive to encode differences between frames to economize storage. Buffering up more frames gives the encoder more opportunities to look for similar content across frames, and lets it allocate more bitrate budget for difficult sequences. But buffering up frames introduces latency. Another challenge is some popular streaming platforms mainly use H.264, an older codec that’s less efficient than AV1. Newer codecs are being tested, so the situation may start to change as the next few decades fly by. But for now, H.264 remains important due to its wide support.\n\nTesting with an old gameplay clip from Elder Scrolls Online shows a clear advantage for RDNA4’s media engine when testing with the latency-constrained VBR mode and encoder tuned for low latency encoding (-usage lowlatency -rc vbr_latency). Netflix’s VMAF video quality metric gives higher scores for RDNA4 throughout the bitrate range. Closer inspection generally agrees with the VMAF metric.\n\nRDNA4 does a better job preserving high contrast outlines. Differences are especially visible around text, which RDNA4 handles better than its predecessor while using a lower bitrate. Neither result looks great with such a close look, with blurred text on both examples and fine detail crushed in video encoding artifacts. But it’s worth remembering that the latency-constrained VBR mode uses a VBV buffer of up to three frames, while higher latency modes can use VBV buffer sizes covering multiple seconds of video. Encoding speed has improved slightly as well, jumping from ~190 to ~200 FPS from RDNA3.5 to RDNA4.\n\nDisplay Engine\n\nThe display engine fetches on-screen frame data from memory, composites it into a final image, and drives it to the display outputs. It’s a basic task that most people take for granted, but the display engine is also a good place to perform various image enhancements. A traditional example is using a lookup table to apply color correction. Enhancements at the display engine are invisible to user software, and are typically carried out in hardware with minimal power cost. On RDNA4, AMD added a “Radeon Image Sharpening” filter, letting the display engine sharpen the final image. Using dedicated hardware at the display engine instead of the GPU’s programmable shaders means that the sharpening filter won’t impact performance and can be carried out with better power efficiency. And, AMD doesn’t need to rely on game developers to implement the effect. Sharpening can even apply to the desktop, though I’m not sure why anyone would want that.\n\nPower consumption is another important optimization area for display engines. Traditionally that’s been more of a concern for mobile products, where maximizing battery life under low load is a top priority. But RDNA4 has taken aim at multi-monitor idle power with its newer display engine. AMD’s presentation stated that they took advantage of variable refresh rates on FreeSync displays. They didn’t go into more detail, but it’s easy to imagine what AMD might be doing. High resolution and high refresh rate displays translate to high pixel rates. That in turn drives higher memory bandwidth demands. Dynamically lowering refresh rates could let RDNA4’s memory subsystem enter a low power state while still meeting refresh deadlines.\n\nPower and GDDR6 data rates for various refresh rate combinations. AMD’s monitoring software (and others) read out extremely low memory clocks when the memory bus is able to idle, so those readings aren’t listed.\n\nI have a RX 9070 hooked up to a Viotek GN24CW 1080P display via HDMI, and a MSI MAG271QX 1440P capable of refresh rates up to 360 Hz. The latter is connected via DisplayPort. The RX 9070 manages to keep memory at idle clocks even at high refresh rate settings. Moving the mouse causes the card to ramp up memory clocks and consume more power, hinting that RDNA4 is lowering refresh rates when screen contents don’t change. Additionally, RDNA4 gets an intermediate GDDR6 power state that lets it handle the 1080P 60 Hz + 1440P 240 Hz combination without going to maximum memory clocks. On RDNA2, it’s more of an all or nothing situation. The older card is more prone to ramping up memory clocks to handle high pixel rates, and power consumption remains high even when screen contents don’t change.\n\nCompute Changes\n\nRDNA4’s Workgroup Processor retains the same high level layout as prior RDNA generations. However, it gets major improvements targeted towards raytracing, like improved raytracing units and wider BVH nodes, a dynamic register allocation mode, and a scheduler that no longer suffers false memory dependencies between waves. I covered those in previous articles. Besides those improvements, AMD’s presentation went over a couple other details worth discussing.\n\nScalar Floating Point Instructions\n\nAMD has a long history of using a scalar unit to offload operations that are constant across a wave. Scalar offload saves power by avoiding redundant computation, and frees up the vector unit to increase performance in compute-bound sequences. RDNA4’s scalar unit gains a few floating point instructions, expanding scalar offload opportunities. This capability debuted on RDNA3.5, but RDNA4 brings it to discrete GPUs.\n\nWhile not discussed in AMD’s presentation, scalar offload can bring additional performance benefits because scalar instructions sometimes have lower latency than their vector counterparts. Most basic vector instructions on RDNA4 have 5 cycle latency. FP32 adds and multiples on the scalar unit have 4 cycle latency. The biggest latency benefits still come from offloading integer operations though.\n\nSplit Barriers\n\nGPUs use barriers to synchronize threads and enforce memory ordering. For example, a s_barrier instruction on older AMD GPUs would cause a thread to wait until all of its peers in the workgroup also reached the s_barrier instruction. Barriers degrade performance because any thread that happened to reach the barrier faster would have to stall until its peers catch up.\n\nRDNA4 splits the barrier into separate “signal” and “wait” actions. Instead of s_barrier, RDNA4 has s_barrier_signal and s_barrier_wait. A thread can “signal” the barrier once it produces data that other threads might need. It can then do independent work, and only wait on the barrier once it needs to use data produced by other threads. The s_barrier_wait will then stall the thread until all other threads in the workgroup have signalled the barrier.\n\nMemory Subsystem\n\nThe largest RDNA4 variants have a 8 MB L2 cache, representing a substantial L2 capacity increase compared to prior RDNA generations. RDNA3 and RDNA2 maxed out at 6 MB and 4 MB L2 capacities, respectively. AMD found that difficult workloads like raytracing benefit from the larger L2. Raytracing involves pointer chasing during BVH traversal, and it’s not surprising that it’s more sensitive to accesses getting serviced from the slower Infinity Cache as opposed to L2. In the initial scene in 3DMark’s DXR feature test, run in Explorer Mode, RDNA4 dramatically cuts down the amount of data that has to be fetched from beyond L2.\n\nRDNA2 still does a good job of keeping data in L2 in absolute terms. But it’s worth noting that hitting Infinity Cache on both platforms adds more than 50 ns of extra latency over a L2 hit. That’s well north of 100 cycles because both RDNA2 and RDNA4 run above 2 GHz. While AMD’s graphics strategy has shifted towards making the faster caches bigger, it still contrasts with Nvidia’s strategy of putting way more eggs in the L2 basket. Blackwell’s L2 cache serves the functions of both AMD’s L2 and Infinity Cache, and has latency between those two cache levels. Nvidia also has a flexible L1/shared memory allocation scheme that can give them more low latency caching capacity in front of L2, depending on a workload’s requested local storage (shared memory) capacity.\n\nA mid-level L1 cache was a familiar fixture on prior RDNA generations. It’s conspicuously missing from RDNA4, as well as AMD’s presentation. One possibility is that L1 cache hitrate wasn’t high enough to justify the complexity of an extra cache level. Perhaps AMD felt its area and transistor budget was better allocated towards increasing L2 capacity. To support this theory, L1 hitrate on RDNA1 was often below 50%. At the same time, the RDNA series always enjoyed a high bandwidth and low latency L2. Putting more pressure on L2 in exchange for reducing L2 misses may have been an enticing tradeoff. Another possibility is that AMD ran into validation issues with the L1 cache and decided to skip it for this generation. There’s no way to verify either possibility of course, but I think the former reasons make more sense.\n\nBeyond tweaking the cache hierarchy, RDNA4 brings improvements to transparent compression. AMD emphasized that they’re using compression throughout the SoC, including at points like the display engine and media engine. Compressed data can be stored in caches, and decompressed before being written back to memory. Compression cuts down on data transfer, which reduces bandwidth requirements and improves power efficiency.\n\nTransparent compression is not a new feature. It has a long history of being one tool in the GPU toolbox for reducing memory bandwidth usage, and it would be difficult to find any modern GPU without compression features of some sort. Even compression in other blocks like the display engine have precedent. Intel’s display engines for example use Framebuffer Compression (FBC), which can write a compressed copy of frame data and keep fetching the compressed copy to reduce data transfer power usage as long as the data doesn’t change. Prior RDNA generations had compression features too, and AMD’sdocumentation summarizes some compression targets. While AMD didn’t talk about compression efficiency, I tried to take similar frame captures using RGP on both RDNA1 and RDNA4 to see if there’s a large difference in memory access per frame. It didn’t quite work out the way I expected, but I’ll put them here anyway and discuss why evaluating compression efficacy is challenging.\n\nThe first challenge is that both architectures satisfy most memory requests from L0 or L1. AMD slides on RDNA1 suggest the L0 and L1 only hold decompressed data, at least for delta color compression. Compression does apply to L2. For RDNA4, AMD’s slides indicate it applies to the Infinity Cache too. However, focusing on data transfer to and from the L2 wouldn’t work due the large cache hierarchy differences between those RDNA generations.\n\nDCC, or delta color compression, is not the only form of compression. But this slide shows one example of compression/decompression happening in front of L2\n\nAnother issue is, it’s easy to imagine a compression scheme that doesn’t change the number of cache requests involved. For example, data might be compressed to only take up part of a cacheline. A request only causes a subset of the cacheline to be read out, which a decompressor module expands to the full 128B. Older RDNA1 slides are ambiguous about this, indicating that DCC operates on 256B granularity (two cachelines) without providing further details.\n\nIn any case, compression may be a contributing factor in RDNA4 being able to achieve better performance while using a smaller Infinity Cache than prior generations, despite only having a 256-bit GDDR6 DRAM setup.\n\nSoC Features\n\nAMD went over RAS, or reliability, availability, and serviceability features in RDNA4. Modern chips use parity and ECC to detect errors and correct them, and evidently RDNA4 does the same. Unrecoverable errors are handled with driver intervention, by “re-initializing the relevant portion of the SoC, thus preventing the platform from shutting down”. There’s two ways to interpret that statement. One is that the GPU can be re-initialized to recover from hardware errors, obviously affecting any software relying on GPU acceleration. Another is that some parts of the GPU can be re-initialized while the GPU continues handling work. I think the former is more likely, though I can imagine the latter being possible in limited forms too. For example, an unrecoverable error reading from GDDR6 can hypothetically be fixed if that data is backed by a duplicate in system memory. The driver could transfer known-good data from the host to replace the corrupted copy. But errors with modified data would be difficult to recover from, because there might not be an up-to-date copy elsewhere in the system.\n\nOn the security front, microprocessors get private buses to “critical blocks” and protected register access mechanisms. Security here targets HDCP and other DRM features, which I don’t find particularly amusing. But terminology shown on the slide is interesting, because MP0 and MP1 are also covered in AMD’s CPU-side documentation. On the CPU side, MP0 (microprocessor 0) handles some Secure Encrypted Virtualization (SEV) features. It’s sometimes called the Platform Security Processor (PSP) too. MP1 on CPUs is called the System Management Unit (SMU), which covers power control functions. Curiously AMD’s slide labels MP1 and the SMU separately on RDNA4. MP0/MP1 could have completely different functions on GPUs of course. But the common terminology raises the possibility that there’s a lot of shared work between CPU and GPU SoC design. RAS is also a very traditional CPU feature, though GPUs have picked up RAS features over time as GPU compute picked up steam.\n\nInfinity Fabric\n\nOne of the most obvious examples of shared effort between the CPU and GPU sides is Infinity Fabric making its way to graphics designs. This started years ago with Vega, though back then using Infinity Fabric was more of an implementation detail. But years later, Infinity Fabric components provided an elegant way to implement a large last level cache, or multi-socket coherent systems with gigantic iGPUs (like MI300A).\n\nSlide from Hot Chips 29, covering Infinity Fabric used in AMD’s older Vega GPU\n\nThe Infinity Fabric memory-side subsystem on RDNA4 consists of 16 CS (Coherent Station) blocks, each paired with a Unified Memory Controller (UMC). Coherent Stations receive requests coming off the graphics L2 and other clients. They ensure coherent memory access by either getting data from a UMC, or by sending a probe if another block has a more up-to-date copy of the requested cacheline. The CS is a logical place to implement a memory side cache, and each CS instance has 4 MB of cache in RDNA4.\n\nTo save power, Infinity Fabric supports DVFS (dynamic voltage and frequency scaling) to save power, and clocks between 1.5 and 2.5 GHz. Infinity Fabric bandwidth is 1024 bytes per clock, which suggests the Infinity Cache can provide 2.5 TB/s of theoretical bandwidth. That roughly lines up with results from Nemes’s Vulkan-based GPU cache and memory bandwidth microbenchmark.\n\nAMD also went over their ability to disable various SoC components to harvest dies and create different SKUs. Shader Engines, WGPs, and memory controller channels can be disabled. AMD and other manufacturers have used similar harvesting capabilities in the past. I’m not sure what’s new here. Likely, AMD wants to re-emphasize their harvesting options.\n\nFinally, AMD mentioned that they chose a monolithic design for RDNA4 because it made sense for a graphics engine of its size. They looked at performance goals, package assembly and turnaround time, and cost. After evaluating those factors, they decided a monolithic design was the right option. It’s not a surprise. After all, AMD used monolithic designs for lower end RDNA3 products with smaller graphics engines, and only used chiplets for the largest SKUs. Rather, it’s a reminder that there’s no one size fits all solution. Whether a monolithic or chiplet-based design makes more sense depends heavily on design goals.\n\nFinal Words\n\nRDNA4 brings a lot of exciting improvements to the table, while breaking away from any attempt to tackle the top end performance segment. Rather than going for maximum performance, RDNA4 looks optimized to improve efficiency over prior generations. The RX 9070 offers similar performance to the RX 7900XT in rasterization workloads despite having a lower power budget, less memory bandwidth, and a smaller last level cache. Techspot also shows the RX 9070 leading with raytracing workloads, which aligns with AMD's goal of enhancing raytracing performance.\n\nSlide from RDNA4’s Launch Presentation not Hot Chips 2025\n\nAMD achieves this efficiency using compression, better raytracing structures, and a larger L2 cache. As a result, RDNA4 can pack its performance into a relatively small 356.5 mm² die and use a modest 256-bit GDDR6 memory setup. Display and media engine improvements are welcome too. Multi-monitor idle power feels like a neglected area for discrete GPUs, even though I know many people use multiple monitors for productivity. Lowering idle power in those setups is much appreciated. On the media engine side, AMD’s video encoding capabilities have often lagged behind the competition. RDNA4’s progress at least prevents AMD from falling as far behind as they have before.\n\nIf you like the content then consider heading over to the Patreon or PayPal if you want to toss a few bucks to Chips and Cheese. Also consider joining the Discord.",
      "source": "Chipsandcheese.com",
      "url": "https://chipsandcheese.com/p/amds-rdna4-gpu-architecture-at-hot",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "What Does 'Ti' Actually Mean On An Nvidia Graphics Card?",
      "content": "Nvidia is well known around the world for creating video graphics cards, with the company holding an impressive 94% market share in the sector. The company even provides the custom graphics chip for the Nintendo Switch 2 console. From more budget-minded offerings to high-end graphics cards, Nvidia needs a way to highlight the highest-end cards in a line, and does so by using the Ti abbreviation, which stands for Titanium.\n\nOne thing that helps define all modern Nvidia graphics cards is what is known as the CUDA core. A CUDA (Compute Unified Device Architecture) is responsible for processing the data sent to and from the graphics card, with potentially thousands of CUDA cores being used by a given Nvidia GPU. The more CUDA cores a graphics card has, the more powerful it generally is.\n\nOn top of CUDA cores, Nvidia graphics cards rely on dedicated VRAM (Video Random Access Memory) that is designed to process the video data coming from your graphics card. A video card that features more VRAM will allow you to produce and display higher, more complex graphics on screen. Cards in a line with the most CUDA cores and oftentimes with the most built-in VRAM generally earn the coveted Ti branding, marking them as the most powerful in a series.",
      "source": "BGR",
      "url": "https://www.bgr.com/1964309/what-nvidia-gpu-graphics-card-ti-means/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Bring back your old Mac: 5 ways to refresh the OS on elderly Apples",
      "content": "Any day now, a new version of Apple's macOS is due to launch, and it will exclude the bulk of the Intel-powered models the company has ever sold. However, there are multiple ways to breathe new life into Macs that go back as far as 10 or even 15 years.\n\nThe Reg FOSS desk has two older Intel Macs in daily use that can't run any currently-supported version of macOS, though. Recently, we've been exploring our available options, and we've found that there are multiple potential routes to keep an old-time Mac productive.\n\nmacOS 26 \"Tahoe\" is due in a few days, and there are a whole four Intel Macs that will be able to run it: the 2019 MacBook Pro and Mac Pro, and the 2020 MacBook Pro and iMac. Those are the official models, anyway. As we covered back in 2023, the OpenCore Legacy Patcher project offers a free tool that lets you create a custom-modified macOS installer that will let you install newer versions of macOS onto Macs too old to officially support them. We reckon there's a good chance that a future update to OCLP will make more older models able to run macOS 26.\n\n\"Tahoe\" is officially the last-ever macOS for Intel hardware, though. The switch to Arm-based Apple Silicon processors is permanently closing the door on the \"Hackintosh\" world, and the world of Arm devices is so wildly heterogeneous that there's basically zero prospect of running Arm macOS on anything else. That's why there's the special Armbian distro just to make the current Linux available on Arm kit.\n\nBefore we tried to upgrade one of our daily drivers with OCLP, though, we wanted to test drive upgrading to an unsupported macOS. To this end, we recently pulled a retired MacBook out of storage. It's a 2010 13-inch MacBook Pro. The last supported macOS for this model is 10.13 \"High Sierra\", and the newest mainstream web browser for this is Firefox 115, which is the ESR release from 2023. When its successor Firefox 128 appeared, Mozilla said it would keep updating version 115 for as long as possible. As The Register reported last week, that currently means March 2026. To get to the subsequent Firefox ESR, we needed at least macOS 10.15 \"Catalina\".\n\nThis shouldn't work, but it does: macOS 10.15 running happily on a MacBook Pro from two years before Apple's cut-off - Click to enlarge\n\nThat poses a slight snag. The 2010 MBP is the only Core 2 Duo machine we've encountered that refuses memory that's faster than the 1066 MHz DDR3 SDRAM for which it's specified. It wants at least one PC3-8500 SO-DIMM, and it won't start with PC3-10600, let alone even faster. (We blame the Nvidia GeForce 320M GPU for this fussiness.) As a result, our MBP only has 6 GB of RAM. That's a snag.\n\nThe current release of OCLP is version 2.4.1 and the oldest macOS it supports is macOS 11 \"Big Sur\". Officially, this will run in 4 GB, but we suspect it might be rather sluggish. However, OCLP doesn't support Catalina.\n\nEnter the DOS dude\n\nHelp is at hand from Collin Mistr, AKA dosdude1. Among other apps, he offers a tool called macOS Catalina Patcher. It's a just-over-200-MB download, although obviously you will need a copy of macOS Catalina as well. Apple has a helpful downloads page for every version from 10.7 to 15 (oddly, except 10.9 Mavericks, which was the first release the company distributed for free).\n\nCatalina Patcher offers three different ways to install, including an in-place upgrade. - Click to enlarge\n\nThe \"Install macOS Catalina.app\" file is an 8.26 GB download, so we didn't download a fresh copy: we copied it from our iMac onto a Mac-formatted USB key, and then onto the MBP. Then we downloaded Mistr's patcher and ran it. (Unsurprisingly, this is not an authorized app, as it does something Apple doesn't want to support, so don't double-click it; right-click it and pick Open.) It offers the choice of creating an installer USB, installing onto the machine it's running on, or creating an ISO file.\n\nSince this is a sacrificial testbed machine – it was replaced by a Core i7 Dell Latitude running ChromeOS Flex a couple of years ago – we just told it to install in place. It creates a modified installer in the /tmp folder, then launches that. First this converted our HFS+ SSD into the newer APFS format, then started the upgrade. Apple's time estimate was just under half an hour, but it took longer. Once the process finished, our 2010 MacBook Pro was running the 2020 version of macOS, even though it officially only supports models from 2012 onwards. On its own, macOS found an update for Safari, downloaded and installed it, and we were done.\n\nThere are no giveaways that this is an unofficial OS. The About this Mac dialog box still identifies the correct model, its GPU, its RAM slots, everything. On first launch, Firefox 115 automatically updated itself to version 128, and we then manually upgraded that to the latest 142. It runs fine – not blazingly fast, but pretty well for a 15-year-old computer based on a CPU launched in 2007.\n\nOur primary objective was successfully accomplished: to get a current, supported web browser. A few applets automatically updated themselves, such as the Rectangle window-tiling tool. We had to manually download Chrome from Google's Other Platforms page, and version 128 is the latest for this old OS, but it works.\n\nEvery silver lining has a cloud\n\nThere are some drawbacks to the upgrade, though. The machine is a little more sluggish than before. Although 10.15 was the first all-64-bit version of macOS, it has multiple new features to offset the removal of the 32-bit subsystems: the APFS filesystem, built-in Siri, several separate apps in place of iTunes, and so on. Our ancient but perfectly serviceable copy of Microsoft Office 2011 was 32-bit only so it no longer works. We grabbed the latest LibreOffice 25.8, which does work, but it's not exactly snappy. Now we have dark mode. Woohoo.\n\nTo be honest, just as Office 2011 did everything we wanted and a very great deal more besides, so did High Sierra. As The Register said in 2017:\n\nAll High Sierra's most interesting features are at the deep system level. 10.13 has no new apps and (almost) no new user-facing features at all. Apple has even resisted to give a cosmetic makeover to what's already there.\n\nIn this, it reminds us of the classic Mac OS X 10.6 \"Snow Leopard\", of which the same writer said:\n\nWhat greeted me was familiar: Snow Leopard starts like Leopard, down to the pixel. Apple promises that Snow Leopard frees about 7 GB from a comparable Leopard installation… there's some serious shrinkage going on. Safari's public beta on Leopard weighs in at 45 MB, but the Snow Leopard Safari at just 14 MB. The Address Book shrinks from 58 MB to 15 MB. Mail is now 77.5 MB.\n\nThat's the kind of upgrade we like. These days, 10.6 is hailed as one of the best-ever releases. Perhaps we should say liked, because High Sierra was the last time Apple managed a new version that looked and worked the same, but tightened everything up under the hood.\n\nNostalgia for old OS releases‽\n\nPart of the reason for this dramatic shrinkage was that Mac OS X 10.5 \"Leopard\" was the last ever PowerPC version. 10.6 removed all the PowerPC code, leaving only Rosetta, licensed from Transitive – which also sold it as QuickTransit to HP and Novell before IBM acquired it in 2008.\n\nOfficially, Snow Leopard is Intel only. That hasn't stopped the hardcore PowerMac enthusiasts, though, who have managed to custom-compile and put out a pre-release version.\n\nSome Mac fans miss old versions, just as some Windows fans do. We've written about running the translucent glories of Windows 7 in 2025, as we did about running Windows XP in 2023.\n\nAlthough it still looks sleek, Snow Leopard is so long in the tooth now that it's more of a Smilodon. This vulture ran it for years on a homemade Hackintosh, but we don't want to go back that far.\n\nWe recently discovered the website of Jonathan \"Wowfunhappy\" Alland, a discerning vintage-macOS aficionado who runs Mavericks Forever, and on it, he explains in detail why he chose this particular version; for instance, it was the first OS X to support memory compression, so it runs well on low-memory machines, and it was one of the last versions to retain the Aqua appearance. He also has a meticulously curated Mavericks App Library.\n\nNow that we've upgraded our elderly MacBook Pro, we're considering maxing out its memory and seeing how far we can upgrade it, but we might end up going backwards instead. However, on the same trip when we retrieved the MBP, we also collected an even older MacBook: a 2008 white MacBook. Sadly, this machine really is maxed out. As far as we can find out, OS X 10.7 \"Lion\" really is the last version of OS X it can run.\n\nLeopards and Lions … why not revenant Foxes, and shiny shiny Chromium?\n\nBut some of the hints on Mavericks Forever made us wonder if we could make Lion a little more useful. Before COVID-19, we had installed Firefox Legacy on the machine. It's based on Firefox 68, but although it's not maintained anymore, it still works and can open most contemporary websites. The Mavericks page told us about Firefox Dynasty. This is a port of the current Firefox for older versions of Mac OS X, back to version 10.8 \"Mountain Lion\".\n\nUnfortunately, it's on GitHub, and Firefox Legacy can't open GitHub's JavaScript-riddled Releases page. But we did recently discover another browser that can: Chromium Legacy. The latest version is from May 2024, based on Chromium 127, but it unzips and runs fine on \"Lion\", and in turn, it enabled us to download Firefox Dynasty.\n\nAnd this definitely shouldn't work, but here's the current Firefox (and Chromium 124) on OS X 10.7. - Click to enlarge\n\nResult: the latest Firefox 142, complete with vertical tab bar, running happily on the version of OS X El Reg reviewed in 2011. And, for any websites that won't work right in Firefox, we have a fairly recent version of Chromium as well. Suddenly, that makes this ancient OS a much more viable proposition.\n\nOne limitation of Chromium Legacy is that it can't check for updates – if there ever will be any more – and you may have difficulties fetching it from GitHub using a very old Firefox. Never fear: Wowfunhappy's Chromium Legacy Downloader is here, and he also offers the corresponding Firefox Dynasty Downloader PrefPane.\n\nSomewhere, we think we have a spare 4 GB DDR2 SO-DIMM lying around. We will try to max out the MacBook's RAM at a massive 6 GB, give the creaky old thing a small SSD, and take it out on the road for a run. With two modern browsers, we should be able to handle most things, and fifteen or twenty-year-old writing tools are still absolutely perfect. Maybe we can dig out a copy of Word from before the \"fluent interface\" and its wretched Ribbon were dreamed up.\n\nBootnote\n\nAs we've seen, a community of dedicated and determined enthusiasts is getting more recent OSes and modern browsers working on ancient Intel Macs and PowerMacs.\n\nBut it's not limited to getting newer OSes running on older kit. The counterpart is Mac OS 9 Lives, which has versions of the real original macOS that have been tweaked to run on some later PowerPC G4 hardware, released after Apple started amending the machines' firmware to compel users to switch to the fancy new Mac OS X.\n\nFor instance, there's a build of Mac OS 9.2.2 for iBook G4, and another one for the Mac mini G4. Somewhere, we have both of those machines, and once we can find them, we plan to try this out. They are both rather underpowered for Mac OS X, but they represent the fastest hardware ever made for Mac OS 9.\n\nOur G4 mini was a gift from the late DJ Walker Morgan, who some Register readers may remember for his Unix column in Personal Computer World under the pseudonym of David Evnull. (\"D. Evnull\" – /dev/null – geddit?) Ave, atque, vale. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/13/refresh_an_old_mac/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "NVIDIA and OpenAI CEOs accompanying President Trump's UK state visit — major AI projects on the agenda",
      "content": "U.S. President Donald Trump is about to do something none of his predecessors have — make a second full state visit to the UK. Ordinarily, a President in a second term of office visits, meets with the monarch, but doesn't get a second full state visit.\n\nOn this one it seems he'll be accompanied by two of the biggest faces in the ever-growing AI race; OpenAI CEO, Sam Altman, and NVIDIA CEO, Jensen Huang.\n\nThis is according to a report by the Financial Times, which claims that the two are accompanying President Trump to announce a \"large artificial intelligence infrastructure deal.\"\n\nThe deal is said to support a number of data center projects in the UK, another deal towards developing \"sovereign\" AI for another of the United States' allies.\n\nThe report claims that the two CEOs will announce the deal during the Trump state visit, and will see OpenAI supply the technology, and NVIDIA the hardware. The UK will supply all the energy required, which is handy for the two companies involved.\n\nUK energy is some of the most expensive in the world (one reason I'm trying to use my gaming PC with an RTX 5090 a lot less!)\n\nThe exact makeup of the deal is still unknown, and, naturally, neither the U.S. nor UK governments have said anything at this point.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAI has helped push NVIDIA to the lofty height of being the world's most valuable company. (Image credit: Getty Images | Kevin Dietsch)\n\nThe UK government, like many others, has openly announced its plans to invest in AI. As the next frontier for tech, you either get on board or you get left behind. And President Trump has made no secret of his desires to ensure the U.S. is a world leader.\n\nOpenAI isn't the only company that could provide the software side, but it is the most established. While Microsoft may be looking towards a future where it is less reliant on the tech behind ChatGPT for its own AI ambitions, it makes total sense that organizations around the world would be looking to OpenAI.\n\nNVIDIA, meanwhile, continues to be the runaway leader on the hardware front. We've seen recently that AMD is planning to keep pushing forward, and a recent Chinese model has reportedly been built to run specifically without NVIDIA GPUs.\n\nBut for now, everything runs best on NVIDIA, and as long as it can keep churning out enough GPUs to fill these data centers, it will continue to print money.\n\nThe state visit is scheduled to begin on Wednesday, September 17, so I'll be keeping a close eye out for when this AI deal gets announced.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/artificial-intelligence/nvidia-and-openai-ceos-accompanying-president-trumps-uk-state-visit-major-ai-projects-on-the-agenda",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Has Nvidia Lost Sight of the Core Consumer?",
      "content": "As seen in the above, datacenters made up a significantly smaller portion of NVDA's revenue prior to 2021 and the focus was on their core consumer grade gaming segment. However, with the popularization of generative AI tools like DALL-E and Chat-GPT by OpenAI in 2021 which sparked a race among the top tech companies to invest in and create the best generative models as a result we saw a more than 3x surge in AI investment market-wide between 2019 and 2021 which has since come to a plateau following a huge spike in 2021, after many of these companies including Microsoft and Google announced that they would be slowing down on their AI related spending and/or exploring in-house solutions to save on CapEx.\n\nBut today, It's all about AI and enterprise contracts. The headlines out of their most recent CES keynote weren't about consumer-grade GPUs or gaming, they were about new datacenter products and AI reasoning models with names like Nemotron and Llama in focus rather than the standard consumer power focused terms like CUDA and RTX. The everyday consumer will have minimal to no practical use for these AI reasoning models displayed by NVDA yet this was the focus of the showcase and really put things into perspective for me that NVDA seems to be abandoning its core consumer base in favor of satisfying its newly found AI enterprise markets. It was not so long ago that gaming was NVDA's top revenue source as detailed here in their 2021 Annual 10k filing;\n\nIn the past, NVIDIA events were all about Productivity, Games, GPUs, and Raw graphics horsepower aimed at consumer interests like pushing frames per second higher, powering better visuals, improving encoding performance, power efficiency, and exciting the consumer base by which Nvidia's $4 trillion foundation was built upon.\n\nVery little attention was given to the Next-gen consumer focused RTX-50 series graphics cards during the showcase. I found this to be disappointing because this was at an annual event meant to showcase Consumer Electronics, yet Nvidia consumers essentially took a backseat to all of these more Enterprise focused AI products/concepts.\n\nAt the start of 2025, there was a lot of optimistic chatter about what Nvidia's stock might do during this year's Central Electronics Showcase. Thinking back to this timeline it almost seemed as if every headline, every social media post, and the majority of online commentary surrounding Nvidia's CES press conference focused on Nvidia forwarding their growth in AI markets ranging from: AI PCs built for developers to more efficiently run LLMs, AI powered Robotics platforms, and their partnerships with various players within the Autonomous Automobile industry such as Toyota and Tesla.\n\nStory Continues\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Quid & Stanford University: 2025 AI Index\n\nThis AI investment surge has been congruent with the recent trend in NVDA's datacenter segment overtaking their gaming segment by an exponentially wide margin as seen a more recent 10k filing:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nIt is worth noting however that the corporate investments into AI only began to plateau in 2021-present, during this time we saw the top companies in the industry collectively aim to reduce their AI CapEx spend was also in alignment with the start of a sharp continuous decline in US Consumer Sentiment as released by the University of Michigan:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nFurthermore, this decline in consumer sentiment has not only been observed in the US but China as well as China Consumer Sentiment has nose-dived to and even further extent during the same period;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Organization for Economic Co-operation and Development via FRED\n\nThis sudden decline in the consumer sentiment has led to the pulling of investment capital not just in AI as detailed earlier, but also in adjacent industries like EVs;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: IEA\n\nI have referenced the chart above in a previous article, which delves into my concerns revolving around a recent slowdown in TSLA Cash Flows. If TSLA keeps going on the path that it currently is, their Non-adjusted Free Cash Flows will once again turn negative. Given that TSLA is one of NVDA's top B2B customers, I see this as a worrying trend as this has all aligned with the drop in consumer sentiment starting in 2021.\n\nEven as big tech investment into AI pulls back and the consumer sentiment declines, we can still see an exponential growth in the amount of newly funded Generative AI companies popping up on the frontend.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Quid & Stanford University: 2025 AI Index\n\nThese newfound startups could find themselves entering into what was a booming industry, now entering a cooldown period, if that's the case these companies will be unlikely to find success in chasing the Gen-AI trend now as the CapEx liquidity once provided to this industry by big tech players dries up.\n\nConcerningly, when evaluating NVDA's 2025 annual 10k filing it can be seen that 34% of this newfound revenue came from only three of their direct enterprise customers;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nThough Nvidia did not name their customers directly, it can be inferred through Omida Research's Q32023 report of H100 Shipments that NVDA's top customers were Microsoft, Meta, Google, and Amazon with notable business from TSLA, Oracle, Tiktok, and CoreWeave.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nGiven that many of these customers are the same companies that have begun to cut back on external AI CapEx spending, likely in alignment with the fall of the consumer, it is very likely that NVDA sees an exceptionally greater direct hit in not only their profit margins but also their total revenue as these companies seek internal solutions and competition from potentially more balanced companies such as Intel enters the fray.\n\nThe goal of many of these companies are to balance capex spend with their revenues and right now they are focusing on creating the best product for their core consumer base to fall back on, as these companies reduce spending, develop in-house solutions, or find better and most likely cheaper competitors to NVDA, we will see more and more of NVDA's overly focused B2B model dwindle. In times like these it would be great for NVDA to not only have a functioning B2B base but to also maintain its base consumer as a foundation to fall back on in hard times just some of NVDA's most successful corporate customers do, but in the effort to chase a growing AI trend NVDA has lost sight of that foundation and is leaving itself open to a massive pull of liquidity. The time may soon be coming when a company such as NVDA would want to have a strong consumer base to fall back on because as of now when reading into NVDA's QoQ Net Margins, a peak can already be observed, rounding down since the start of 2024 with a declines being experienced the in Q2, 2025.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MicroTrends.net\n\nThe last time we experienced any such decline in margins like this was at the start of 2022 which proceeded a 62% drop from $28.95 a share to $10.81 near the 89-month EMA all within the same year. If things were to go similarly this time around we could experience a similar 60-70% decline to around $50 per share aligning with the 89-month EMA in white.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: TradingView\n\nNVDA currently trades at a 57x multiple with a $3.15 EPS, I'd suspect that NVDA has the capacity to correct down to around a 15-20x multiple If it experienced a severe repricing due to its AI endeavors being priced out by the market and there's even the risk of EPS going down due to falling margins. If EPS drops significantly to $1.15, setting it back a year a 20x multiple of that would align with NVDA trading down to $23 a share in the coming months.\n\nIntel: Back to the consumer\n\nIntel, is taking the opposite approach of Nvidia.\n\nAt CES 2025, Intel rolled out its Core Ultra 200 series processors. These cover everything from thin-and-light laptops to high-performance desktops. Unlike Nvidia's corporate-heavy pitch, Intel's message was simple: more power, less energy, and prices that make sense for consumers.\n\nThe Core Ultra 200HX and H series aims to bring serious improvements to creators and gamers, better multi-thread performance, integrated Arc graphics, and even built-in NPUs for AI acceleration. The 200U series targets mainstream laptops, while the 200S series brings efficient yet power a high 16-20+ core count 125-watt chips to desktops.\n\nIntel is also targeting the mobile and notebook space directly, going up against Qualcomm and ARM and unlike Nvidia, Intel manufacture the majority of its chips in the United States. This puts them ad a great advantage when it comes to managing the ongoing tariffs and is likely to Nvidia heavy reliance on TSMC for production and Samsung for memory chips, which puts Nvidia in the crosshairs of these tariffs in which U.S based and sourced companies such as Intel and Micron could greatly benefit.\n\nAs NVDA has shifted its focus away from the consumer INTC has been aggressive in building its product lineup in the favor of the consumer and it really shows when looking at the chart of the historic video card market share:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: PassMark\n\nThe data here shows that NVDA's consumer video card market share dropped from 61.8% in 2022, to 54.2% in 2025, AMD remained stagnant, and during the same period, Intel's share rose from 16.1% to 21%.\n\nObserving the chart, it would appear that NVDA's market share is on a downwards trajectory with more declines likely as competition, mainly the now pro-consumer focused Intel continues to gain ground within NVDA's lost, yet core industry as Intel's product lineup right now puts the core consumer base first and remains easily accessible. Unlike NVDA, INTC is not talking about abstract AI models with gimmicky names that sound like they were ripped out of some sci-fi film; they're instead talking about battery life, power efficiency, security features, and real improvements that everyday people will notice when they buy their next laptop or desktop.\n\nA familiar trap?\n\nIn many ways, this is reminiscent to when Microsoft fumbled with the new generations of Xbox with the Kinect. Microsoft had a winning product in the Xbox 360 but got distracted by the gimmicks introduced with the Kinect, focusing on getting rid of the traditional controller in favor of motion controls, becoming an all in one media hub, and enforcing always online requirements for Xbox One with Kinect; a practice none of the consumers ever approved of yet Microsoft pushed it for years. It seems likely that Microsoft's obsession with motion controls came from their desire to chase after the success of the Nintendo Wii, which released in 2006, introduced motion controls to the masses, and ended up being the best-selling seventh generation console of that generation by far.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nBut by the time the eighth generation rolled in, the novelty of motion controls had long played it course and that was made very apparent with the fall in the Nintendo Wii's yearly sales as well as to complete failure of the Wii U.\n\nDuring the start of the eighth generation in 2013, we would see Sony, with its PS4 release, focus on games and gamer alike, showcasing pro-consumer features such as game sharing along with the ability to play games without the need of an internet connection; all backed by a strong lineup of game releases to boot. Sony did all of this and even took direct jabs at Microsoft, their competition, who was not then concerned with these pro-consumer moves at the time. Despite these open jabs from Sony, Microsoft would carry on with its anti-consumer practices in favor of the Kinect as it continued to push the all-in-one media hub features which was likely an attempt to compete with the then trending streaming markets, as well as pushing the motion controls which was a dying fad. As a result, a new trend would emerge of yearly PS4 sales consistently being double that of Xbox One sales;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nOne year later the CEO of Microsoft would appoint Phil Spencer as the new head of Xbox who then would undo the anti-consumer practices set in motion by the previous head, Don Mattrick, starting with the unbundling of the kinect and a more consumer friendly approach to gamer by offering backwards compatibility, and reverting back to the brand's roots; Unfortunately it was too late as the previous leadership had already sullied the brand's relationship with its core customer base and many of those that might have considered coming back to Xbox were already comfortably on PlayStation and later on, thanks to a much improved marketing campaign, Nintendo Switch; the result of Xbox's previous years of not focusing on the core consumer and even antagonizing the consumer at times made it very tough to take back market share against Nintendo and Sony, which remained, focused on their core gaming audience throughout.\n\nEven all these years later in the ninth generation of consoles, as Microsoft has spent the last 13 years reversing course on all of these anti-consumer practices, they remain significantly behind Nintendo and Sony generations later as the consumer base has already settled within their perspective ecosystems and winning them back has proven to be very hard for Microsoft to do with PS5 sales now being triple that of Xbox Series X/S.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nNvidia risks falling into the same trap: chasing enterprise AI hype while forgetting about the consumer market that made it a household name in the first place and in time of economic slowdown Nvidia will need to lean back on this core base but by the time they do another competitor would have likely scooped up a significant portion of this core base and just like Microsoft with the Xbox, it could take years before Nvidia can rebuild all of that lost consumer trust.\n\nValuation Overview:\n\nWhen taking in account NVDA's slowdown in profit margins mainly attributed to the slowdown in enterprise revenue paired with their loss in market share to INTC within the consumer base, it makes sense to consider INTC as the alternative investment to NVDA. Despite INTC's recent shaky history of EPS misses, it is worth considering the fact that the stock price trades at a very low price to sales multiple of 1.98x:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nThis low price to sales value contrasts with NVDA's which currently trades at a 25.95x multiple to its sales;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nThis in my opinion is a massive oversight in the market that shows speculative growth being priced into NVDA while ignoring the current actual contraction NVDA is currently facing, as a result, the comparison of these ratios tells us that sales growth is failing to keep up with the high speculative valuations of the current market.\n\nMeanwhile the market has severely undervalued INTC, not taking into consideration the fact that it is currently gaining a significant core market share against NVDA and AMD alike in a trend that seems likely to continue.\n\nLooking into other valuation data we can also see that INTC trades at a 1.01x book value which ultimately confirms that despite INTC's recent growth, the stock market still hasn't priced in any growth at all within the company which means that the stock is currently at its fairest value right now.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nMeanwhile when looking at NVDA's price to book we can see that in spite of recent contractions, the market is still valuing NVDA's stock at a 42.33x multiple to its book value.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nTaking in the totality of the data it would be in my opinion a valuable opportunity to capitalize on the arbitrage between NVDA and INTC's valuation and performance by investing long term into INTC rather it be shares or Long Call LEAPS (1 year or more of theta), while reducing share allocation or even buying some longer dated 300+ DTE OTM puts in NVDA or at least hedging current long positions in NVDA more aggressively with covered calls. As this arbitrage closes, I would anticipate NVDA's market cap valuation to contract while INTC's expands, narrowing the current spread between NVDA's $4.4T and INTC's $100B market cap valuations.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-lost-sight-core-consumer-185126232.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "As of 2025, the Average Social Security Retirement Benefit Check Is $1,976. Could Nvidia Help Boost Your Retirement?",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_a4129eb8-d5bc-494f-a061-a06b3a2b5061",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Are NVIDIA Shares Still Worth the Price After UK Datacenter Investment News?",
      "content": "Thinking about what to do with your NVIDIA shares? You’re not alone. Whether you’ve been riding the wave since the early days or just now looking at that ticker symbol, NVIDIA’s recent moves have certainly put it on everyone’s radar. Just this past week, the stock jumped 6.5%, bouncing back after a minor 1.5% stumble over the past month. For the year-to-date, that’s an impressive climb of 28.6%, while the longer view is almost jaw-dropping: up more than 1,200% over three years and over 1,300% across five years. Those numbers are hard to ignore, especially when the headlines keep NVIDIA front and center in the tech world.\n\nRecent news about NVIDIA partnering with global players on massive datacenter investments underscores the company’s persistent growth narrative. At the same time, the company has faced new challenges, like scaling back some cloud services to focus on core strengths and seeing competition rise from major clients developing their own AI chips. The market is taking it all in stride, recalibrating its expectations and risk appetite in real time.\n\nIf you’re wondering if all that momentum is baked into today’s price or if there’s more room to grow, here’s a good starting point: by our scorecard, NVIDIA clocks a valuation score of 2 out of 6. That means it’s undervalued in only two key checks, something we’ll break down together, step by step. In the next section, I’ll walk you through these valuation methods to put today’s price in context, and stick around for a smarter way to assess true value at the end.\n\nNVIDIA scores just 2/6 on our valuation checks. See what other red flags we found in the full valuation breakdown.\n\nApproach 1: NVIDIA Discounted Cash Flow (DCF) Analysis\n\nA Discounted Cash Flow (DCF) model works by forecasting a company’s future free cash flows and then discounting those back to their present value. This gives investors an estimate of what the business is really worth today, based on its expected ability to generate cash in the future.\n\nFor NVIDIA, the current Free Cash Flow is $72.28 Billion. Analysts forecast this number to grow rapidly over the upcoming years, reaching a projected $249.21 Billion by 2030. Estimates are solid for the next five years; after that, Simply Wall St algorithmically extends the projections further, reflecting optimism around NVIDIA’s continuing innovation and market expansion.\n\nUsing these projections and discounting them to today's dollars, the DCF model calculates an intrinsic value of $143.89 per share. This valuation suggests NVIDIA shares are around 23.6% overvalued compared to the current stock price.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-shares-still-worth-price-122551220.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Beyond the data center: Nvidia’s GB10 and DGX Spark mark a new phase in its AI strategy",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250912PD217/nvidia-soc-market-2025-gpu.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "NVIDIA Pulls GeForce RTX 5090 and RTX 5080 Founders Edition from Its Marketplace",
      "content": "NVIDIA has quietly removed its GeForce RTX 5090 and RTX 5080 Founders Edition graphics cards from its online marketplace. This removal seems to affect all international online stores, including those in the US, Germany, the UK, and France. In the US, NVIDIA now only offers the Founders Edition version of the GeForce RTX 5070, which includes a Borderlands 4 game as a bonus. The Founders Edition versions of the RTX 5090 and RTX 5080 are absent, with AIB-designed versions taking their place. The situation is similar in the UK, while stores in France and Germany only list the RTX 5070 and RTX 5080 Founders Editions, with no RTX 5090 Founders Edition available.One possible reason for this could be that NVIDIA is preparing a mid-cycle refresh with the RTX 50 SUPER series and wants to avoid excess inventory of non-SUPER models. However, this would mainly affect the RTX 5070 and RTX 5080, which are rumored to receive the SUPER upgrade. There is no clear explanation for the absence of the RTX 5090 Founders Edition from all global stores, especially given the high demand and record-breaking gaming revenues . An End-of-Life (EOL) scenario seems unlikely. We can only speculate about NVIDIA's reasons for this removal, but it might be an inventory adjustment, as NVIDIA could have distributed too many of these models to other retailers, leaving none for its own store. We will continue to monitor the marketplace for updates in the coming days.: An NVIDIA spokesperson for Wccftech confirmed that \"GeForce RTX 50 series Founders Editions continue to be in production. They are limited edition products so, from time to time, go out of stock on our website and return when back in stock.\" So there are no long-term reasons for potential buyers to worry about.Below are the screenshots with the available Founders Edition SKUs at the time of writing. The listings are presented in an order of: US, UK, Germany, and France.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340982/nvidia-pulls-geforce-rtx-5090-and-rtx-5080-founders-edition-from-its-marketplace",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Wall Street Turns Bullish on NVIDIA (NVDA) as AI Compute Drives Growth",
      "content": "NVIDIA Corporation (NASDAQ:NVDA) is one of the AI Stocks on Wall Street’s Radar. On September 11, D.A. Davidson upgraded the stock to “Buy” from Neutral and with a price target of $210, up from $195. The firm said that it is getting more bullish on the stock.\n\nAccording to the firm, the growth in AI compute demand is going to drive enough demand that will sustain Nvidia’s growth next year and even beyond.\n\n“We believe the growth in AI compute demand will drive enough demand to sustain NVDA’s growth into next year and likely beyond. While there are still several cross-currents, we believe those are not enough to change that trajectory and are upgrading to BUY from Neutral, raising our price target to $210 from $195.\"\n\n\"Our increasingly optimistic view of the growth in AI compute demand supersedes our list of concerns regarding NVDA. Our perspective that AI will transform work through labor itself, as opposed to the IT tech stack, lends itself to a continued ramp in compute demand even before enterprise customers see a return on investment.”\n\nNVIDIA Corporation (NASDAQ:NVDA) specializes in AI-driven solutions, offering platforms for data centers, self-driving cars, robotics, and cloud services.\n\nWhile we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 10 AI Stocks In The Spotlight For Investors and 10 AI Stocks on Wall Street’s Radar.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/wall-street-turns-bullish-nvidia-001416750.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Beijing Tsinghua professor warns China must cut AI reliance on Nvidia",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250912PD237/nvidia-asia-chairman-tsinghua-university-training.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Refurb Weekend: Silicon Graphics Indigo² Impact 10000",
      "content": "My general vintage computing projects, mostly microcomputers, 6502, PalmOS, 68K/Power Mac and Unix workstations, but that's not all you'll see. While over the decades I've written for publications likeand, these articles are all original and just for you. My promise: No AI-generated article text, ever. All em-dashes are intentional and inserted by hand. Be kind, REWIND and PLAY.Old VCR is advertisement- and donation-funded, and what I get goes to maintaining the hardware here at Floodgap. I don't drink coffee, but the Mr Pibb doesn't buy itself. :-) Thanks for reading.",
      "source": "Blogspot.com",
      "url": "http://oldvcr.blogspot.com/2025/09/refurb-weekend-silicon-graphics-indigo.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Trump is modeling Chinese state capitalism and there's no going back (Long Le/The Hill)",
      "content": "Sister Sites:\n\nTechmeme\n\nTop news and commentary for technology's leaders, from all around the web Top news and commentary for technology's leaders, from all around the web Mediagazer\n\nTop news and commentary for media professionals from all around the web Top news and commentary for media professionals from all around the web WeSmirch\n\nThe top celebrity news from all around the web on a single page The top celebrity news from all around the web on a single page",
      "source": "Memeorandum.com",
      "url": "https://www.memeorandum.com/250914/p45",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "China says Nvidia violated antitrust laws",
      "content": "lighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nRegulators in China said US chip giant Nvidia broke its antitrust laws, following a preliminary investigation.\n\nThe State Administration for Market Regulation, or SAMR, said in a brief Monday statement that Nvidia violated anti-monopoly laws.\n\nThe regulator said it suspected Nvidia of violating commitments made during its 2020 acquisition of Israeli chip designer Mellanox, which Beijing had conditionally approved. SAMR then launched an antitrust probe into the Mellanox deal in December 2024.\n\n\"The State Administration for Market Regulation decided to conduct further investigation into it in accordance with the law,\" the regulator said in its statement.\n\n\"We comply with the law in all respects,\" an Nvidia spokesperson told Business Insider. \"We will continue to cooperate with all relevant government agencies as they evaluate the impact of export controls on competition in the commercial markets.\"\n\nShares in Nvidia fell 2.5% in premarket trading.\n\nNvidia is at the heart of ongoing semiconductor industry tensions between the US and China.\n\nThe US began limiting China's access to high-tech chips in 2022.\n\nIn April, the US government announced a new export license requirement for Nvidia's H20 chip, which had been designed to comply with previous rules. The company said it expected a $5.5 billion hit in first-quarter earnings due to the new restrictions.\n\nNvidia CEO Jensen Huang said in May that China's AI market could be worth $50 billion in a few years' time, and that losing access to it would be a \"tremendous loss\" for his company.\n\nIn July, Nvidia said it was gearing up to sell its H20 chips in China again after receiving export assurances from the US government.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/china-nvidia-violated-antitrust-laws-mellanox-chips-semiconductors-2025-9",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Fueled by AI Hype, Google Becomes Fourth Company to Pass $3 Trillion Market Cap",
      "content": "On Monday, Google’s parent company, Alphabet, became the fourth company to reach a market value of $3 trillion, and every member of this exclusive club has something in common.\n\nAll it took was a rather small 4% rise in shares for the tech giant to hit the coveted stock market benchmark. Rather unsurprisingly, the three previous winners of that title—Nvidia, Microsoft, and Apple—are all titans of the tech industry that have been riding the wave of investor interest in AI, as well.\n\nAlphabet stock had a great start to September after a federal judge concluded earlier this month that the tech giant could keep Chrome despite its monopoly in internet search. The judge’s reasoning for that was that generative AI would eventually pose “a meaningful challenge to Google’s market dominance.”\n\nGoogle is trying to get ahead of that “meaningful challenge” by fusing AI into its search engine and pouring billions into developing its AI offerings, including its own AI chatbot Gemini.\n\nIt seems that investment cashed out for the company. As of Monday morning, Google Gemini is now the number one free app on Apple’s App Store, relegating OpenAI’s ChatGPT to number two status and giving the much-needed push to the company’s stock.\n\nThe AI hype is inextricably and intricately linked to the significant stock market returns that these tech giants, and many others, have experienced this year. The trillion-dollar question: Is there an AI bubble?\n\nAI hype driving major gains\n\nThe best example of AI hype delivering trillions of dollars of financial gain is perhaps Nvidia, the ultimate AI darling of the stock market. Due to its immense market share in AI chips and the meteoric rise it experienced thanks to the technology, the company is largely considered the face of the AI hype.\n\nEarlier this summer, Nvidia made history as the first company to ever hit $4 trillion market valuation.\n\nApple, considered the least AI-savvy of the four companies to breach the $3 trillion benchmark, was the first company to ever be worth $3 trillion but is still yet to hit $4 trillion. Meanwhile, both Nvidia and Microsoft have outperformed Apple and already reached that milestone. Microsoft’s breach of the $4 trillion benchmark was also thanks to AI.\n\nLate July, Microsoft posted an earnings report that showed stellar revenue for its cloud computing platform Azure. The stock move following the report pushed Microsoft briefly above $4 trillion market value.\n\nFellow cloud infrastructure provider Oracle also benefited greatly from an AI-demand-driven stock move. Chairman Larry Ellison became the richest man on Earth last week after Oracle stock skyrocketed more than 42% on news that the company expects to collect half a trillion dollars (and potentially billions of dollars more) in the coming quarter on AI deals alone.\n\nIs there a bubble?\n\nAll this is great news for tech companies and their financial metrics, but is it substantiated? That question has been plaguing investors for some time now.\n\nAccording to some experts (and OpenAI CEO Sam Altman), there is indeed an AI bubble.\n\n“Are we in a phase where investors as a whole are overexcited about AI?” Altman said last month in a dinner with journalists, according to The Verge. “My opinion is yes.”\n\nAn AI report from MIT fueled those worries further just a few weeks ago. The researchers shared that despite the push to scale AI in the corporate world, fewer than one in ten AI pilot programs have actually generated revenue gains.\n\nAI is currently deployed mostly by larger firms in select fields. But even there, AI adoption is now declining, according to the latest U.S. Census Bureau findings.\n\nIf AI is indeed in a bubble, the burst could be catastrophic. So much is riding on the AI wave right now, including the entire U.S. economy.\n\nIn a paper published in July, Fed researchers said that if AI demand does not scale proportionally with investment, it can lead to “disastrous consequences,” and compared it to the railroad over-expansion of the 1800s and the economic depression that followed. Also in July, economist Torsten Slok called the AI bubble of today even worse than the 1999 Dot-com bubble.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/fueled-by-ai-hype-google-becomes-fourth-company-to-pass-3-trillion-market-cap-2000658927",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Nvidia targeted by China: Top Story",
      "content": "00:00 Speaker A\n\nWell, overnight, China has ruled that Nvidia violated anti-monopoly laws after concluding an initial investigation.\n\n00:10 Speaker A\n\nThis is likely to ramp up the pressure on Washington during sensitive trade negotiations that are taking place right now in Madrid.\n\n00:20 Speaker A\n\nNvidia's shares fell over 2% in the pre-market. The company has previously disclosed it's facing scrutiny inside China where regulators demanded it keep supplying local companies in return\n\n00:34 Speaker A\n\nfor regulatory approval of its 2020 acquisition of Mellanox.\n\n00:40 Speaker A\n\nAccording to China's anti-trust law, companies can face fines of between 1 and 10% of their annual sales from the previous year.\n\n00:50 Speaker A\n\nChina generated $17 billion in revenue for Nvidia in the fiscal year ending January 26th, or 13% of total sales based on its last annual report.\n\n01:03 Speaker A\n\nNow, US-China trade talks continue in Madrid today with the sale of Tik Tok high up on the agenda.\n\n01:10 Speaker A\n\nHere's President Trump's take on that. He was speaking before China released its Nvidia statement.\n\n01:23 Donald Trump\n\nI may or may not. They're negotiating Tik Tok right now.\n\n01:28 Donald Trump\n\nWe may let it die or we may, I don't know, it depends. Up to China. It doesn't matter too much.\n\n01:33 Donald Trump\n\nI'd like to uh do it for the kids that like it.\n\n01:37 Donald Trump\n\nI mean, selfishly speaking, I did very well on Tik Tok and I got the youth vote. I got numbers that nobody's ever even come close to in the Republican Party, nobody.\n\n01:48 Donald Trump\n\nIf you look back to Romney and all these people, they got practically no votes. I got a lot.\n\n01:53 Donald Trump\n\nAnd uh some was attributed to Tik Tok, and a lot was attributed to Charlie.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/nvidia-targeted-china-top-story-124435795.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "This Little-Known AI Stock Is Up 70% in 2025 and Analysts Think It Can Rally Further From Here",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/34814263/this-little-known-ai-stock-is-up-70-in-2025-and-analysts-think-it-can-rally-further-from-here",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "The Borderlands 4 PC Performance Fiasco, Explained",
      "content": "Borderlands 4 launched last week to big numbers and mostly positive reviews on Steam. But there’s been a lot of chatter and debate online about the looter shooter’s performance. Some players aren’t happy that Borderlands 4 seemingly requires DLSS and frame generation to run decently, even on the highest-end hardware. Meanwhile, Gearbox co-founder and CEO Randy Pitchford has defended the game’s performance, calling it “pretty damn optimal,” and suggested people need to use the “tools” provided by the studio and accept some trade-offs.\n\nOn PC, many games can utilize real-time upscaling tech, like Nvidia’s DLSS and AMD’s FSR. Nvidia and others have also created tools that allow your GPU to fill in the gaps between real frames rendered by the game with frames generated using deep learning tech. When this kind of tech was first introduced about six years ago or so, players complained that DLSS and other tools made games look blurry, even if it led to some performance boosts. As DLSS and similar tech have improved, the images produced looked have better and better. Today, DLSS 4.0 can produce some truly sharp-looking frames and provide some big performance gains, assuming you have a powerful enough video card.\n\nBut some, myself included, have started to grow concerned that studios are building games around DLSS and other similar tech, and aren’t optimizing them in the way devs did in the past. When DLSS was introduced, it felt like a great tool for gamers who had a slightly older card but still wanted to play a newer game. It would let them squeeze out a bit more performance without shelling out for a pricey upgrade. Now it seems like newer games running on more advanced engines require users to turn on DLSS and frame gen to play. And so enters Borderlands 4, a game that has found itself at the center of this heated debate.\n\nShortly after Borderlands 4 launched, players on PC began to complain that the game didn’t run very well. Gearbox responded with some updates that, at least in my experience with the game on PC, helped a bit. The company also released a guide from Nvidia for how to optimize the game based on your GPU and settings. And while that helped some reach better performance on PC, many others, myself included, were struggling to get the game to run well on powerful hardware. I’m rocking a 5080, and even playing the game at 1080p on medium settings led to tons of FPS drops, even while trying to play at 60FPS. That all changed when I did as Gearbox and Nvidia suggest and turned on DLSS and frame gen. Now, I can run Borderlands 4 at a mostly locked 120 with most settings set to high and medium. It looks nice and plays fine, but many aren’t okay with a game in 2025 being unable to run on high-end hardware without some upscaling assistance.\n\nNot helping matters is the fact that Randy Pitchford posted, as part of a recent and lengthy thread on Twitter, that people should use DLSS because it’s “great” and added: “The game was built to take advantage of it.” That, and a different part of the thread claiming it was acceptable for devs to focus on “default settings” reaching only 30FPS, didn’t go over well with a lot of PC gamers who specifically buy new parts and upgrade their rigs to achieve high framerates at high resolutions. For many, Pitchford’s claim that Borderlands 4 was developed to “take advantage” of DLSS was him confirming that it was built with the assumption that most users would use DLSS. And that, to some, sounds a lot like the game wasn’t properly optimized to run without help from DLSS and frame generation.\n\nWhile I do agree that newer DLSS and frame gen tools are powerful and impressive, it feels weird that Borderlands 4, along with other games like Alan Wake 2, demand that even users with the highest-end hardware lean on upscaling tech to play at decent settings and historically popular framerates like 120. In a recent video, the tech experts over at Digital Foundry weren’t impressed with Borderlands 4 on PC, with one even saying: “[Borderlands 4] does seem to be running worse than usual for an Unreal Engine 5 game. It is below where it seems like it should be given how other games using this engine perform.”\n\nPitchford has promised on Twitter that more updates are coming, including some more improvements to how the game runs on PC. He’s also been spending a lot of time online helping people improve how Borderlands 4 runs and claiming that performance issues are not as widespread as some might make you believe. Personally, I just miss when games could run on a high-end computer packed with powerful hardware without needing four different upscaling tools. And it seems I’m not alone.",
      "source": "Kotaku",
      "url": "https://kotaku.com/borderlands-4-pc-performance-dlss-frame-gen-pitchford-gearbox-steam-2000625765",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "\"NVIDIA violated the anti-monopoly law\" — China's ongoing investigation digs up antitrust violations as trade tensions mount",
      "content": "NVIDIA, the US company supplying most of the world with GPUs built specifically for powering AI, finds itself once again at odds with Chinese authorities.\n\nFollowing a preliminary investigation into the matter, Chinese antimonopoly regulators claim that NVIDIA broke antitrust laws (via Business Insider) in connection with the acquisition of Israeli chip design company Mellanox.\n\nNVIDIA announced it had reached a $6.9 billion deal with Mellanox in March 2019. China, shortly after the announcement, stated it had conditionally approved the deal.\n\nHowever, the antitrust investigation was initiated in December 2024 by China's State Administration for Market Regulation (SAMR). The investigation remains ongoing, say SAMR officials in the press release.\n\n[...] the State Administration for Market Regulation decided to conduct further investigation in accordance with the law.\n\nThe SAMR dropped the antitrust news at the same time that Chinese and US officials are attempting to negotiate trade intricacies in Madrid. Trade tensions have been on the rise for most of 2024 and 2025, with both sides making some bold claims regarding AI GPUs and how they're being used.\n\nA brief history of US, China, and NVIDIA trade tensions\n\nTwo cargo ships, one with a Chinese flag and the other with an American flag. (Image credit: Getty Images | Yaorusheng)\n\nA lot of recent trade tension between the US and China has NVIDIA sitting in the center. The GPU company's H20 AI chip, created specifically for the Chinese market as a less-powerful alternative to US AI chips, is highly sought after by China's AI firms.\n\nHowever, the NVIDIA chip was fully banned from being sold to China in April 2025 by the Trump administration. The cause of the ban centered on concerns that China was using the H20 chips to bolster its military and to develop further domestic AI models that could challenge US firms.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe ban was walked back in July, when NVIDIA CEO Jensen Huang reached a deal with President Trump following a White House visit. Huang's argument? It's better to have all AI models running on US technology.\n\nIt didn't take long for Huang to announce that NVIDIA was ordering 300,000 more H20 AI chips from TSMC in order to meet Chinese demand. And that was on top of the 600,000 to 700,000 H20 chips already stockpiled and awaiting buyers.\n\nAs a final part of the deal with the US government, NVIDIA and AMD agreed to pay a 15% chip tax for the export licenses needed to sell to China. The unprecedented deal remains informally approved. While Chinese AI firms clambered to place orders for the unbanned H20 AI GPUs, state officials began pressuring the firms to avoid the US hardware over fears of tracking devices, spyware, and other hidden back doors.\n\nNVIDIA responded by firmly stating that it wasn't placing any sort of trackers or malware in its AI GPUs.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/nvidia/nvidia-violated-anti-monopoly-laws-chinese-officials",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Tech Volatility to Persist: Columbia Threadneedle's Wade",
      "content": "There are no significant events for this country at this time. Select ‘All’ to see top events in other countries or view all events.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/tech-volatility-persist-columbia-threadneedles-194229741.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "SoundHound AI (SOUN) Stock Trades Up, Here Is Why",
      "content": "What Happened?\n\nShares of voice AI technology company SoundHound AI (NASDAQ:SOUN) jumped 2.1% in the afternoon session after it received continued positive commentary from Wall Street analysts.\n\nThe move follows several bullish actions, including DA Davidson analyst Gil Luria maintaining a \"Strong Buy\" rating and increasing the price target from $15 to $17 on September 10. Additionally, Wedbush's Daniel Ives reiterated a \"Buy\" rating on September 11. This optimistic analyst sentiment is supported by the company's strong performance, with a recent report noting that SoundHound AI's revenue tripled in the second quarter compared to the previous year. The company's voice AI platform has now surpassed 1 billion queries per month, positioning it to capitalize on the growing use of AI in devices, cars, and homes.\n\nAfter the initial pop the shares cooled down to $14.37, up 1.8% from previous close.\n\nIs now the time to buy SoundHound AI? Access our full analysis report here, it’s free.\n\nWhat Is The Market Telling Us\n\nSoundHound AI’s shares are extremely volatile and have had 92 moves greater than 5% over the last year. In that context, today’s move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.\n\nThe previous big move we wrote about was 5 days ago when the stock dropped 4.9% on the news that markets pulled back, reversing early gains, as investor sentiment remained cautious despite a softer-than-expected inflation reading.\n\nStocks rose in the morning session after an unexpected drop in the Producer Price Index (PPI) for August signaled easing inflation and raised expectations for a potential Federal Reserve interest rate cut. The U.S. Bureau of Labor Statistics reported that the PPI, which measures wholesale prices, edged down 0.1% last month, contrary to analyst expectations for a 0.3% rise. This data gives the Federal Reserve more flexibility to consider lowering interest rates to stimulate the economy.\n\nSoundHound AI is down 28.7% since the beginning of the year, and at $14.37 per share, it is trading 40.7% below its 52-week high of $24.23 from December 2024. Investors who bought $1,000 worth of SoundHound AI’s shares at the IPO in April 2022 would now be looking at an investment worth $1,915.\n\nUnless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/soundhound-ai-soun-stock-trades-183609103.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Canonical Make It Easier to Install NVIDIA CUDA on Ubuntu",
      "content": "Installing NVIDIA CUDA on Ubuntu desktops is about to get a whole lot easier, as Canonical today announced plans to package and distribute the latest releases in the Ubuntu repositories.\n\nCurrently, to install CUDA Toolkit and runtime on Ubuntu, users go to the NVIDIA website and download a repo DEB, install it, import a GPG key, pin the APT repo, and then install the relevant packages they need from the repo.\n\nShortly, everything they need will be in once place: the Ubuntu repos.\n\nIn packaging the CUDA toolkit and runtime (which includes proprietary components) and distributing it the Ubuntu archives, the ensure process is is simplified: a single command can installed everything, and users with supported NVIDIA hardware can get on with using it.\n\nThe move is part of an ongoing partnership between Canonical and NVIDIA, aimed at providing ‘turnkey AI solutions for the enterprise’ on Ubuntu — something NVIDIA CUDA is a core component of.\n\nOnce CUDA redistribution is fully integrated into Ubuntu, application developers and system administrators can expect the current multi-step CUDA installation process to become a single command Canonical\n\nCUDA is described as “a parallel computing platform and programming model that lets developers use NVIDIA GPUs for general-purpose processing”.\n\nIn practice, it is used for all kinds of things, from faster video encoding and machine learning training, to robotics, scientific computing and other computationally intensive workloads.\n\nWhich is why CUDA is widely used by developers, researchers, animators, data scientists, and AI/ML engineers. Making it easier to install on Ubuntu through a single command , users and enterprises will find Ubuntu a more attractive platform.\n\nWith CUDA available in the Ubuntu repos, any app or software that targets Ubuntu and makes use of CUDA is better able to detect and integrate with the software.\n\nThat helps position Ubuntu as a practical option to anyone looking for a capable, reliable and ready-to-use development environment (and with LTS support, security and stability reassurances).\n\nUbuntu may not be cool® among chronically-online and self-styled Linux influencers, but the distro remains the world’s most popular desktop Linux operating system. The bulk of the tens of millions of people who use it, use it for what it lets them do.\n\nAnd with CUDA in the repos (presumably the multiverse section), that’s more than before.\n\nYou can find a pinch more detail on the Canonical blog.",
      "source": "Omgubuntu.co.uk",
      "url": "https://www.omgubuntu.co.uk/2025/09/canonical-adds-nvidia-cuda-ubuntu-repos",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "\"Some need to learn how their PCs work\" — Borderlands 4 head fires back as optimal settings for 68 GPUs released",
      "content": "Borderlands 4, the latest looter-shooter in the beloved series from Gearbox Software, launched on September 11, 2025. Less than a week later, it's sitting at a \"Mixed\" review score on Steam with more than 16,500 entries. The prevailing issue forcing the review score down? Dreadful PC optimization.\n\nThe game's developer has now released a couple of lengthy PC optimization guides for both NVIDIA and AMD GPUs (via Videocardz). There are 68 different GPUs listed, with optimal settings for 1080p, 1440p, and 4K resolutions. NVIDIA's cards range from the RTX 2070 to the mighty RTX 5090, while AMD's cards range from the RX 5700 XT to the RX 9070 XT.\n\nUnless you're using an RTX 3060 Ti or newer, you can expect about 30 FPS at 1080p. For 1440p, you'll want at least an RTX 3070 Ti to run the game at 30 FPS. Want to play at 4K? You'll want at least an RTX 3090 Ti to hit 60 FPS.\n\nBorderlands 4's poor PC performance doesn't sit well with gamers\n\nA look at recommended NVIDIA GPU settings for playing Borderlands 4 at 1440p. (Image credit: 2K Games)\n\nMy current GPU, NVIDIA's RTX 5070 Ti, is listed under the 4K section. In order to achieve 60+ FPS, I'll need DLSS 4's Multi Frame Generation cranked up to 4x with texture quality set to Medium (and many other settings dropped to Low).\n\nIf I want to hit 60+ FPS at 1440p, I'll still need DLSS MFG 4x, though textures and other quality can be cranked up a bit. I think perhaps I'll wait a bit longer before trying the game to see if any more performance updates are released.\n\nDespite knowing months ahead of launch that Borderlands 4's PC specs were very demanding — more than 50% of Steam users may need an upgrade to play the game, at least judging by Steam's frequent hardware surveys — players are trashing the game for its brutal performance.\n\nPoor optimization and PC performance were topics of our Borderlands 4 review.\n\nDespite playing the game on an NVIDIA RTX 3080 and AMD Ryzen 9 5900X — older hardware that should nevertheless be relevant today — our reviewer experienced some brutal performance woes that mostly continued after a patch.\n\nTerrible, terrible performance. Worst I've ever seen. Turned it down to Low graphics preset and couldn't hit 60 FPS, even with FSR upscaling on my RX 6900 XT. Steam user \"Etiko\"\n\nRandy Pitchford, CEO of Gearbox Software, hasn't been shy about stating his case for Borderlands 4's performance. The game, which runs on the controversial Unreal Engine 5, is demanding, and Pitchford says gamers need to come to terms with lowering the resolution or in-game settings to achieve stability.\n\n\"Borderlands 4 is a premium game made for premium gamers,\" said Pitchford in an X reply to a gamer struggling to play on older hardware.\n\nThe minimum and recommended specs are published. The most common hardware is a four year old cell phone. Borderlands 4 is a premium game made for premium gamers. Just as Borderlands 4 cannot run on a PlayStation 4, it cannot be expected to run on too-old PC hardware. Unlike on…September 13, 2025\n\nConsidering NVIDIA's RTX 3060 and RTX 4060 GPUs continue to hold the top spots on Steam's GPU survey list, many players are struggling to come to terms with how a AAA game can launch at a $70 price tag and run so poorly.\n\nOn the other side of the hardware fence, console players have bemoaned the lack of an FOV slider and a motion blur toggle. Considering that both of these common settings can directly contribute to motion sickness, it's not a good look for Gearbox.\n\nIf you are indeed one of Borderlands 4's launch adopters, I recommend giving the recommended GPU specs laid out by Gearbox a shot. At this point, any extra frames are appreciated.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/gaming/pc-gaming/borderlands-4-official-amd-nvidia-gpu-settings",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Wall Street Is Eating Up This Dividend Stock. Should You Buy Shares Before They Surge as Much as 30%?",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/ef9479b14c758db5",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Tech, Media & Telecom Roundup: Market Talk",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/bac22788e37b3b57",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Commentary: How did Intel go from AMD ally to Nvidia partner?",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250922PD228/intel-nvidia-amd-2025-ceo.html",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Analyst Says Nvidia ‘Getting Into’ Advanced Micro Devices (AMD) Business With Intel Deal",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_863d2e25-c32b-4a16-a602-80651e506576",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "How Brazil's Power Giant Ended Up Owning a Cinema, Airport and Hospital",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/37f674051c132549",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Samsung races to supply Nvidia with HBM3E, WAT results crucial",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250922PD235/samsung-nvidia-hbm3e-development-hbm4.html",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Intel drops day zero game driver support for chips released last year — last-gen iGPUs on 14th-gen Core and older CPUs already put on the backburner of legacy software support",
      "content": "Intel announced that it will transition the integrated graphics on 11th- to 14th-generation processors to a legacy software support model, relegating its last-generation chips to the back burner. The company says that it will no longer release new features for these chips and will only provide software support for critical fixes and security vulnerabilities. It also reduces the update release cadence for the iGPUs from monthly to quarterly, and they will also lose Day 0 Game support.\n\nThis announcement affects both desktops and laptop chips. The 11th to 14th-generation Intel CPUs are still relatively new — the 14th-generation Raptor Lake Refresh CPUs first arrived in 2023, with new models released just last year, while the 11th-generation Tiger Lake processors launched in 2020. In effect, Intel is saying that your one-year-old Intel Core i5-14400 is already on the back burner.\n\nWhile an unwelcome move, the company is likely making this change to conserve resources and focus on its newer Arc graphics architecture. After all, Intel has cut 4,000 positions in the U.S. alone so far this year, with thousands of technicians and engineers being let go as the company fights hard for its survival.\n\nStill, many customers might feel betrayed; after all, if you bought a new processor, you expect it to be supported for at least five to seven years. This announcement will not brick your PC, and you still get critical and security updates quarterly. But you’re also not getting new features, and you might have issues with (or possibly not even be able to play) the latest games at launch.\n\nNevertheless, many users will likely not feel this. After all, gamers who typically download, install, and play a AAA game at launch most often have a discrete GPU installed on their system. In fact, even the most hardware-friendly titles, such as the upcoming Battlefield 6, require a modest graphics card like the Nvidia RTX 2060, AMD Radeon RX 5600 XT, or Intel Arc A380.\n\nEven though it makes sense for Intel to focus on its newer Core and Core Ultra chips, the fact that Intel is moving such a relatively new CPU line-up to legacy support could leave a bad taste in the mouths of some users.\n\nFollow Tom's Hardware on Google News , or add us as a preferred source , to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/gpu-drivers/intel-drops-day-zero-game-driver-support-for-chips-released-last-year-last-gen-igpus-on-14th-gen-core-and-older-cpus-already-put-on-the-backburner-of-legacy-software-support",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Meta's Llama to be made available to US allies in Europe, Asia",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/e91d62861344d7ed",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Nvidia Stock Falls From Record High As $100B AI Investment Raises Questions",
      "content": "This article first appeared on GuruFocus.\n\nSep 23 - Nvidia (NASDAQ:NVDA) is stepping further into artificial intelligence with a plan to back OpenAI with as much as $100 billion. The initiative focuses on building large-scale data centers powered by Nvidia's chips, reinforcing the company's position at the heart of the AI supply chain.\n\nThe announcement sparked excitement, but the stock didn't hold its gains. After closing at a record $183.61 on Monday, Nvidia slipped 2% to $180 on Tuesday. Investors are still weighing how quickly the partnership will boost earnings.\n\nOpenAI intends to deploy around 10 gigawatts of data center capacity using Nvidia systems, including millions of GPUs. Analysts see the move as both strategic and ambitious. William Blair's Sebastien Naji said Nvidia's strong cash position allows it to accelerate adoption of AI hardware while supporting a broader ecosystem.\n\nOthers struck a more measured tone. Benchmark analyst Cody Acree kept a Buy rating and a $220 price target but said the financial impact may take time to show, since OpenAI already factored heavily into previous forecasts.\n\nThe deal follows Nvidia's recent multibillion-dollar tie-up with Intel (NASDAQ:INTC), pointing to a push beyond chip sales into the infrastructure enabling AI at scale.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-stock-falls-record-high-185832337.html",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Micron Technology Scrambles to Meet Soaring Memory Demand",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/ecaac6c679512154",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Financial Services Roundup: Market Talk",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/a621ea992a619412",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "China's Alibaba teams up with Nvidia on AI robot tech",
      "content": "BEIJING: Alibaba announced on Wednesday (Sep 24) a \"milestone collaboration\" in AI tech with US chip giant Nvidia that the Chinese company said will accelerate its development of humanoid robots.\n\nThe news came as Alibaba's shares soared more than 9 per cent in Hong Kong after chief executive Eddie Wu unveiled plans to further ramp up spending on artificial intelligence.\n\nChina and the United States are locked in a fierce tech battle, with the California-based AI chip leader Nvidia wound up in their race for supremacy in advanced semiconductors.\n\nWashington restricts Nvidia from exporting its most advanced products - a crucial component in the generative AI revolution - to China.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nAlibaba, which runs some of China's biggest online shopping platforms, said it was teaming up with the firm in the field of physical AI.\n\nThe Chinese company said its cloud division is integrating \"the full suite of the Nvidia physical AI software stack, marking a milestone collaboration\" in the domain.\n\n\"The initiative provides developers with a comprehensive, cloud-native platform to accelerate advancements in humanoid robotics and physical AI solutions,\" a statement said.\n\nAlibaba made the announcement in Hangzhou at a subforum of its annual developers' conference, where panellists included executives from Nvidia and Alibaba Cloud Intelligence.\n\nAlibaba said in February it would spend at least 380 billion yuan (US$53 billion) on artificial intelligence and cloud computing over the next three years.\n\nThe company's share price soared on Wednesday after comments made by CEO Wu at the event in Hangzhou.\n\n\"We are actively proceeding with the 380 billion investment in AI infrastructure, and plan to add more,\" he said.",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/east-asia/alibaba-nvidia-collaboration-ai-robot-tech-china-us-5366406",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Altman says concerns over OpenAI’s fast growth are 'natural'",
      "content": null,
      "source": "Quartz India",
      "url": "https://qz.com/sam-altman-openai-rapid-growth",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "MSI Vector 16 HX AI 400: 16\" 240Hz QHD+ IPS, Intel Ultra 9 275HX, RTX 5080, 16GB DDR5, 1TB SSD $1999",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18630484-msi-vector-16-hx-ai-400-16-240hz-qhd-ips-intel-ultra-9-275hx-rtx-5080-16gb-ddr5-1tb-ssd-1999",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "NVIDIA (NVDA) Unveils Next-Gen Rubin CPX AI Chips to Handle Complex Software and Video Tasks",
      "content": "NVIDIA Corporation (NASDAQ:NVDA) ranks among the hot stocks to invest in right now. On September 9, NVIDIA Corporation (NASDAQ:NVDA) announced that by the end of next year, it would introduce a new artificial intelligence chip capable of managing sophisticated tasks, including creating software and videos. The “Rubin CPX” chips will be built on NVIDIA’s next-generation Rubin architecture, the replacement for the company’s recent “Blackwell” technology, which signaled NVIDIA’s entry into providing larger processing systems.\n\nAccording to the company, processing an hour of video footage can take up to one million tokens for AI models, which is difficult for conventional GPUs to accomplish. NVIDIA Corporation (NASDAQ:NVDA) plans to address this by incorporating several stages of the lengthy processing sequence onto its new chip.\n\nNVIDIA Corporation (NASDAQ:NVDA) states that investing $100 million in these new systems might contribute to $5 billion in token revenue, as Wall Street places a greater emphasis on the return on hundreds of billions of dollars spent on AI hardware.\n\nNVIDIA Corporation (NASDAQ:NVDA), a world leader in networking and graphics processing, provides GPUs for the AI, gaming, HPC, and other industries.\n\nWhile we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 10 Best Magic Formula Stocks for 2025 and 10 Best Retirement Stocks to Buy According to Hedge Funds.\n\nDisclosure: None. This article is originally published at Insider Monkey.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-nvda-unveils-next-gen-124550903.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Alibaba Stock Soars To Multi-Year High After Supercharging $53B AI Plan",
      "content": "This article first appeared on GuruFocus.\n\nSep 24 Alibaba Group Holding (NYSE:BABA) shares climbed nearly 8% in Hong Kong on Wednesday, touching their highest level in close to four years. The rally came after CEO Eddie Wu said the company plans to expand its artificial intelligence spending beyond the previously announced $53 billion, or 380 billion yuan, earmarked for infrastructure over the next three years.\n\nWu, who also leads Alibaba Cloud, spoke at the Apsara Conference in Hangzhou. He noted that global AI investment could reach $4 trillion over the next five years, and emphasized that Alibaba's cloud business aims to become a leading full-stack AI service provider, offering everything from computing power to models.\n\nWhile Wu did not provide a new budget figure, the announcement underscores Alibaba's determination to keep pace with global peers. The move also reflects a broader surge in AI spending by U.S. technology firms.\n\nNvidia (NASDAQ:NVDA), for instance, recently announced plans to invest as much as $100 billion in OpenAI, backing the buildout of large-scale AI data centers.\n\nIn addition, Alibaba unveiled Qwen3-Omni, its open-source large language model designed to handle text, images, audio, and video, broadening its push into generative AI.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/alibaba-stock-soars-multi-high-120938593.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Micron's 12-Hi HBM4 Delivers 2.8 TB/s Bandwidth, 11 Gb/s Per-Pin Transfer Rate",
      "content": "Yesterday, Micron reported its fourth-quarter and full-year fiscal 2025 results , beating the consensus and providing interesting comments on its upcoming HBM technology. During the earnings call, Sanjay Mehrotra, CEO of Micron, confirmed that HBM4—the company's next-generation memory—will be available next year with several enhancements over the base HBM4 JEDEC specification . \"Micron Technology's HBM4 12-high remains on track to support customer platform ramps, even as the performance requirements for HBM4 bandwidth and pin speeds have increased. We have recently shipped customer samples of our HBM4 with industry-leading bandwidth exceeding 2.8 TB/s and pin speeds over 11 Gbps.\" The JEDEC specification for HBM4 is 2 TB/s bandwidth and 8 Gb/s pin transfer across a 2048-bit interface. Micron is pushing this to 11 Gb/s, resulting in 40% higher bandwidth at 2.8 TB/s.There is a simple reason why this is the case. Customers like NVIDIA are asking HBM makers to create a more performant HBM memory to keep up with the exponential growth that their compute dies are experiencing. To satisfy these requirements, Micron is moving beyond JEDEC specifications. \"We believe Micron Technology's HBM4 outperforms all competing HBM4 products, delivering industry-leading performance as well as best-in-class power efficiency. Our proven 1-gamma DRAM, innovative and power-efficient HBM4 design, in-house advanced CMOS base die, and advanced packaging innovations are key differentiators enabling this best-in-class product,\" said Sanjay.\"For HBM4E, Micron Technology will offer standard products as well as the option for customization of the base logic die,\" confirmed Micron CEO. As we reported earlier , NVIDIA and AMD accelerators will utilize a customized HBM memory for the first time. In an HBM stack, consisting of stacked DRAM dies up to a 12-high, connected with TSVs, there is the possibility of embedding an optional base die with customized logic/accelerator circuitry tailored to a specific need. It appears that NVIDIA and AMD are not only exploring this option to gain more performance, but are also actively working on an implementation with a custom base that will push these accelerators ahead of any third-party ASIC solution. The custom base die will likely be a data processing/logic die that helps route data packets more efficiently, cutting latency and improving performance.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341279/microns-12-hi-hbm4-delivers-2-8-tb-s-bandwidth-11-gb-s-per-pin-transfer-rate",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Bitcoin Miner IREN Has 80% Potential Upside Thanks to Big Bet on AI Cloud: Bernstein",
      "content": "IREN (IREN), one of the largest self-operated bitcoin BTC $ 124,333.64 miners in the U.S., is breaking away from the pack, and Wall Street is taking notice.\n\nBernstein analysts raised their price target on IREN to $75 from $20, implying about 80% upside, as the miner doubles down on building its own AI cloud business rather than relying on co-location deals with partners like CoreWeave (CRWV).\n\nSTORY CONTINUES BELOW Don't miss another story. Subscribe to the Crypto Daybook Americas Newsletter today . See all newsletters Sign me up By signing up, you will receive emails about CoinDesk products and you agree to our terms of use and privacy policy .\n\nIREN has already had a major move, ahead more than eight-fold from its 52-week low of $5.13 hit in April. The shares are higher by 365% year-over-year.\n\nThe broker now sees IREN’s AI pivot as credible, despite early skepticism about the miner’s ability to execute on a capital-intensive data center build-out and compete with AI cloud players tied to hyperscalers and Nvidia (NVDA).\n\nIREN is guiding for rapid growth, the report noted, with $500 million in annual recurring revenue by Q1 2026 on 23,300 GPUs, up from roughly $14 million in Q1 2025.\n\nBeyond AI, IREN retains flexibility with its 3 gigawatt (GW) power portfolio, balancing bitcoin mining and AI workloads to maximize revenue per megawatt, Bernstein analysts led by Gautam Chhugani wrote.\n\nIts 50 EH/s mining operation generates an estimated $600 million in annualized EBITDA at current bitcoin prices, funding its AI expansion, according to the analysts.\n\nBernstein has shifted its valuation approach to a sum-of-parts model, assigning 87% of enterprise value to AI cloud and co-location potential at IREN’s 2GW West Texas site, with the remaining 13% coming from bitcoin mining.\n\nAt the revised target, IREN would trade at $7.5 million per megawatt (MW), above other AI-focused miners but still far below established data center peers like CoreWeave, suggesting further room for multiple expansion, the report added.\n\nRead more: IREN Shares Jump 11% in Pre-Market Trading as Bitcoin Miner Doubles AI Cloud Fleet",
      "source": "CoinDesk",
      "url": "https://www.coindesk.com/markets/2025/09/24/bitcoin-miner-iren-has-80-potential-upside-thanks-to-big-bet-on-ai-cloud-bernstein",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Commentary: Analyzing Nvidia's crisis defusing strategy amid the AI bubble storm",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250924PD224/nvidia-market-openai-ceo-intel.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Stock market today: Dow, S&P 500, Nasdaq slip for 2nd day in a row as Fed sends mixed signals, Alibaba keeps AI optimism in focus",
      "content": "US stocks fell on Wednesday as Wall Street digested mixed messaging from Fed officials on interest rates.\n\nThe S&P 500 (^GSPC) slid 0.3% while the Dow Jones Industrial Average (^DJI) declined by about 0.4%, The tech-heavy Nasdaq Composite (^IXIC) dropped 0.3%. The declines marked a reversal from the indexes' earlier gains.\n\nDebate over the prospects for US interest rate cuts — the big focus for markets right now — appeared to pressure stocks. Comments from Federal Reserve officials this week have hinted at growing disagreement on what the path of policy should be, given cracks showing in the labor market.\n\nFed Chair Jerome Powell reiterated in a speech on Tuesday that the central bank would proceed cautiously on further rate cuts, even as he left the door open to more easing. He also described stocks as \"fairly highly valued.\"\n\nWall Street is now counting down to the release of the Fed's preferred inflation gauge, the Personal Consumption Expenditures index, on Friday. Markets are watching for reassurance that inflation isn't posing a threat to high expectations for two more rate cuts this year.\n\nOn Wednesday, fresh data from the Commerce Department's Census Bureau showed new home sales unexpectedly surged in August as mortgage rates began to ease, bringing homebuyers off the sidelines and releasing pent-up demand. Still, affordability concerns persist.\n\nMeanwhile, some tech stocks are showing gains despite a broader drop across the Nasdaq, which snapped a winning streak on Tuesday amid losses for the \"Magnificent Seven\" Big Tech stocks.\n\nAlibaba stock (BABA) jumped 8% as investors welcomed the Chinese tech giant's pledge to hike its AI spending beyond its original $50 billion target. The boost is needed for Alibaba to keep pace as global investment in AI surges to $4 trillion, its CEO said.\n\nTesla (TSLA) shares climbed 4% and were on track to close at their highest level in 2025 as analysts at investing firm Mizuho Securities lifted their price outlook on the stock to $450. The analysts noted the EV maker is seeing only a \"muted\" impact from tariffs and boosted optimism for the company's robotaxi ambitions.\n\nAt the same time, Micron's (MU) stronger-than-expected quarterly earnings delivered a positive signal for the AI trade, though shares in the memory chipmaker — which supplies semiconductors for Nvidia's (NVDA) AI systems — fell on Wednesday.\n\nLIVE COVERAGE IS OVER\n\n25 updates",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-dow-sp-500-nasdaq-slip-for-2nd-day-in-a-row-as-fed-sends-mixed-signals-alibaba-plans-ai-push-200103891.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Nvidia and OpenAI partnership is a catalyst for enterprise AI growth, says Wedbush’s Dan Ives",
      "content": "Good morning. One of the largest investments in artificial intelligence to date could further accelerate enterprise AI adoption.\n\nOpenAI, the maker of ChatGPT, and AI chip leader Nvidia announced a strategic partnership on Monday, with Nvidia committing up to $100 billion to support OpenAI’s next-generation AI infrastructure—including investments in power capacity and data centers. The agreement entails deploying at least 10 gigawatts of Nvidia-powered systems—amounting to millions of graphics processing units (GPUs)—to develop and run advanced AI models. The first phase is expected to go live in the second half of 2026.\n\nThe two companies will jointly optimize their development roadmaps for OpenAI’s software and models, and for Nvidia’s hardware and software platforms. The investment and infrastructure partnership powers “the next era of intelligence,” Jensen Huang, founder and CEO of Nvidia, said in a statement. Sam Altman, cofounder and CEO of OpenAI, added that the partnership will “create new AI breakthroughs and empower people and businesses.”\n\nThis announcement further strengthens the relationship between OpenAI and Nvidia as leaders at the forefront of the AI revolution, while providing OpenAI with substantial funding at lower costs by reducing its credit risk, Wedbush Securities analysts wrote in a Tuesday note to investors.\n\n\n\n“This speaks to our view that the next three to six months will be defined by the second, third, and fourth derivatives of the AI Revolution playing out,” according to the analysts.\n\n\n\nDan Ives, managing director at Wedbush, told me the tiered derivatives refer to the other areas of tech that will “benefit from the trillions spent in the AI Revolution.” He added: “Big Tech will dominate, but these other areas are the winners in software, chips, energy, and infrastructure.”\n\n\n\nWhile there are worries about an AI bubble and stretched valuations, the analysts continue to view this as a “1996 moment” for the tech world. “This is still the early days of the AI Revolution in our view,” Ives told me. “The tech bubble was 1999/2000, and this is still early days—a 1996 moment.”\n\nSpending and surging enterprise use cases across industries are creating a group of emerging AI leaders, according to Ives.\n\nLast week, OpenAI’s economic research team, alongside Harvard economist David Deming, released research analyzing 1.5 million ChatGPT conversations to track usage patterns since its launch. The study found that roughly 30% of use is work-related while 70% is personal, with both categories growing over time—highlighting ChatGPT’s dual role as a productivity tool and a source of value in daily life, according to the researchers.\n\n“The early findings are fascinating and point to real shifts in how AI is integrated into everyday life,” OpenAI CFO Sarah Friar wrote in a LinkedIn post. “Especially happy to see the gender gap close.”\n\nBy mid-2025, ChatGPT’s early gender gaps had narrowed significantly, with user demographics coming to resemble the broader adult population. In January 2024, 37% of users had typically feminine names; by July, that share had grown to over half (52%).\n\n\n\nAs OpenAI and Nvidia join forces, their landmark investment signals a far-reaching impact across industries.\n\nSheryl Estrada\n\nsheryl.estrada@fortune.com\n\nLeaderboard\n\nDavid Croxville was appointed CFO of C1, a technology solutions and services company. Croxville brings more than 30 years of experience. Most recently, he served as EVP and CFO of NTT DATA Services in the Americas, where he led finance, procurement, real estate, and IT across 44 countries, and completed more than 10 acquisitions, including Dell Services.\n\nCornelis (Carlo) Broos was promoted to CFO of Cibus, Inc. (Nasdaq: CBUS), a biotechnology company, according to an SEC filing. Broos has served as interim CFO of Cibus since October 2024 and previously held the position of SVP of finance. He joined Cibus in 2011. Before joining the company, Broos held finance leadership positions at Syngenta Europe Africa Middle East, Syngenta Netherlands and Belgium, Advanta, and Deloitte Netherlands.\n\nBig Deal\n\nFortune released its 2025 Change the World list this morning, featuring 50 companies that have integrated social problem-solving into their business models. Their leaders recognize there’s profit to be made by having a positive impact on people and the planet—whether directly, through the sale of their products and services, or indirectly, as their actions help build a stronger talent pool, attract more customers, and strengthen the economic resilience of their communities.\n\nAmong the companies on the list is Deloitte, which recently helped Brazil develop hydrogen power by creating a model to work across various supply-chain scenarios, for example. Mastercard is also featured; its Strive program, launched in 2021, helps micro and small business owners access affordable credit and digital tools to manage their finances. In the U.S., Strive has facilitated $45 billion in loans and reached more than 1.6 million small businesses. You can read more about the 50 companies on the Change the World list here.\n\nGoing deeper\n\nThe CFA Institute Research and Policy Center released new research highlighting what it calls the $63 billion continuation fund boom.\n\n“Continuation Funds: Ethics in Private Markets,” the first report in a series on ethics in private markets, aims to guide market participants as they navigate the evolution of continuation funds—also known as continuation vehicles or CVs—and the corresponding ethical implications. The report draws on interviews with more than 30 senior industry professionals worldwide.\n\n“Continuation vehicles make for a central case study in how liquidity, alignment and governance come together in private markets,” said Stephen Deane, senior director of capital markets policy at CFA Institute and lead author of the report, in a statement.\n\nOverheard\n\n\"Don’t be a jerk. No massive egos, and no telling different people different things to get what you want.\"\n\n—Duolingo CEO Luis von Ahn took to LinkedIn on Monday to share a direct message with the company’s 42 newly hired graduates, offering five career tips, Fortune reported. One piece of advice: leave your ego at the door.",
      "source": "Fortune",
      "url": "https://fortune.com/2025/09/24/nvidia-openai-partnership-catalyst-enterprise-ai-growth-wedbushs-dan-ives-cfo/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Inside Huawei's bid to outflank Nvidia: clusters, optics, and a 3-year AI roadmap",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250924VL207/huawei-nvidia-roadmap-chips-performance.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "NVIDIA Wants Everyone to Own a Digital Avatar with Open-Source Audio2Face Animation Model",
      "content": "NVIDIA is today open-sourcing its Audio2Face 3D animation model, allowing everyone to become the owner of their own digital avatar. The company has trained its Audio2Face technology to produce characters that are true to life, utilizing generative video models for facial expressions, text-to-speech models for human output, and large language models for actual conversations, all combined in a single pipeline to create a digital avatar. All of these stages are fed by analyzing acoustic input, which features characteristics such as intonation and phonemes, and are then translated into a stream of animation data. That data is later mapped to facial expressions, where the mood of the avatar can be interpreted simply by looking at it. The entire data pipeline can be either an offline scripted content or you can feed the model using live data for real-time lip-synching and facial expressions.Additionally, NVIDIA is open-sourcing the entire Audio2Face stack, which includes the model itself and the SDK, so everyone, from game developers to home enthusiasts, can use it in any possible way. NVIDIA is now open-sourcing the entire training framework, allowing anyone to create their own avatar version with customized features. The company even provided Autodesk Maya and Unreal Engine plugins, allowing 3D workloads to integrate this generative model immediately.Game developers are increasingly treating Audio2Face as a production-ready shortcut to believable facial performance—a tool that automatically converts dialogue into expressive, multilingual lip-sync and facial animation, allowing artists to skip tedious frame-by-frame work and focus on storytelling. Studios from toolmakers like Reallusion, as well as developers such as Survios and The Farm 51, say it speeds up pipelines, frees up animators for higher-value polish, and makes previously impractical ideas achievable, all while keeping characters feeling authentic and emotionally grounded. See how you can get started here . Check out the Audio2Face model in action below:",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341304/nvidia-wants-everyone-to-own-a-digital-avatar-with-open-source-audio2face-animation-model",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Trump’s Bet on Intel Stock Is Up 50%. Should You Try to Get In on the INTC Action Too?",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/35005831/trumps-bet-on-intel-stock-is-up-50-should-you-try-to-get-in-on-the-intc-action-too",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Nvidia Stock Up 1,124%. Other Winners And Whether To Buy $NVDA",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/petercohan/2025/09/24/nvidia-stock-up-1124-other-winners-and-whether-to-buy-nvda/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Microsoft develops breakthrough chip cooling method — microfluidic channels can cut peak temps by up to 65%, outperform conventional cold plates by up to 3x",
      "content": "As data center-grade processors are getting hotter, companies invent more and more creative ways to cool them down. As Nvidia and its partners are reportedly experimenting with new cold plates and immersion cooling for next-generation AI GPUs, Microsoft is proposing to etch microfluidic channels on the back of an actual chip to reduce its peak temperature by up to 65%, making it three times more efficient than cold plates.\n\nMicrosoft says it has developed a cooling system that routes fluid directly into microchannels etched on the back of the silicon die to guide the coolant to high-heat regions inside the chip. Flowing liquid inside the chip greatly reduces the efficiency of the whole setup, as liquid can almost 'touch' hot spots inside the processor, whereas in the case of more traditional liquid cooling or even immersion cooling, heat emerges several layers away from the coolant.\n\nTo optimize thermal routing, Microsoft worked with Swiss startup Corintis, which used artificial intelligence to refine channel geometry. Rather than simple straight lines, the final layout mimics patterns found in nature, such as leaf veins or butterfly wings, to guide fluid more efficiently. Also, microchannels must be small enough to function effectively but not so deep that they weaken the silicon, risking mechanical failure.\n\nHowever, etching microfluid channels can only be done as a separate sequence during chip manufacturing, which means additional steps and costs. Alternatively, Microsoft proposes to produce a microfluidic heat transfer structure separately and cool down one or two chips using the structure, according to a patent. Such integration requires new packaging methods to prevent coolant leaks and maintain durability.\n\nBy now, Microsoft has discovered the right coolant fluid, developed precise etching techniques, and managed to integrate these into chip production. Therefore, Microsoft considers its technology ready for full-scale production within Microsoft's chip development pipeline. Third-party customers may license the technology from Microsoft Technology Licensing, LLC.\n\nIntroducing microfluidic cooling: a breakthrough in chip cooling technology - YouTube Watch On\n\n\"Microfluidics would allow for more power-dense designs that will enable more features that customers care about and give better performance in a smaller amount of space,\" said Judy Priest, corporate vice president and chief technical officer of Cloud Operations and Innovation at Microsoft. \"But we needed to prove the technology and the design worked, and then the very next thing I wanted to do was test reliability.\"\n\nMicrosoft is testing the cooling solution on servers running simulated Teams workloads, where uneven heat loads across many services are handled more efficiently, enabling higher burst performance, which helps to reduce the number of servers that otherwise sit idle when not in use during peak loads that tend to happen on the hour or on the half-hour.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nLab tests showed that this new technique can reduce peak silicon temperatures by up to 65%, depending on the specific chip and usage. Compared to cold plates, the cooling performance improvement was as much as three times, depending on workload and setup. The method also enables cooling without relying on ultra-low coolant temperatures, saving energy otherwise needed for chilling, Microsoft noted.\n\nMicrosoft has been experimenting with its microfluidic channels liquid cooling technology for years and demonstrated the first prototype in 2022, so by now, the company has plenty of lab experience with the technology. Yet, Microsoft is not the only company to develop methods to produce embedded coolant channels inside a chip or chip package. IBM also has appropriate patents.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/liquid-cooling/microsoft-develops-breakthrough-chip-cooling-method-microfluidic-channels-can-cut-peak-temps-by-up-to-65-percent-outperform-conventional-cold-plates-by-up-to-3x",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Trump’s Effort to Pick America’s Corporate Winners Will End Badly",
      "content": "In his second term, US President Donald Trump has abandoned America’s free-market tradition, importing the failed playbook of state-controlled economies. Far from delivering prosperity, heavy-handed government interference will throw good money after bad, distort competition, and prop up failing firms.\n\nSEOUL – For at least the last 150 years, state intervention in picking individual industries and firms to support has been shown to undermine productivity and weaken economic performance. When political considerations outweigh sound commercial judgment, companies may be compelled to keep unprofitable factories open, maintain loss-making activities, favor government-owned suppliers over private vendors, or appoint unqualified but politically connected individuals to leadership positions.\n\nBy contrast, when private companies are inefficient or producing goods people do not want, they exit the market, and more productive companies enter. The profit motive drives businesses to recruit capable employees, produce quality goods that meet demand, innovate, and embrace cutting-edge technologies. When subject to political influence or control, companies generally have weaker incentives to pursue these goals precisely because government ownership shields them from competition.\n\nIn the United States, as in most advanced economies, the private sector has long been the primary driver of GDP growth. With governments playing a relatively limited role – establishing regulatory frameworks, supporting basic research and innovation, and curbing monopolies – competition has flourished, delivering decades of economic prosperity.\n\nBut under President Donald Trump, the US – once an avatar of free-market capitalism – has broken with this tradition. Since the start of his second term, Trump has repeatedly meddled in private-sector decision-making. His administration has targeted law firms, universities, think tanks, semiconductor and battery manufacturers, media companies, research, and more. And, taking a page from the playbook of state-controlled communist economies, his administration has gone even further, moving from intimidation to direct government ownership of private firms. In June, for example, Japan’s Nippon Steel was permitted to acquire US Steel but had to grant the federal government a “golden share,” giving American policymakers veto power over the company’s business plans.\n\nEven before Trump’s intervention, Nippon Steel had pledged to make major investments in US Steel, retain all employees, and honor newly negotiated contracts with union-represented workers. The Trump administration’s added demands thus send a mixed message: while it courts foreign investment, it erects unnecessary barriers.\n\nTrump’s deal with chipmakers Nvidia and AMD illustrates this contradiction. In April, the administration halted the sale of advanced semiconductors to China on national-security grounds. Yet by July, Nvidia and AMD were permitted to resume sales, provided they hand the US government 15% of the revenues.\n\nSecure your copy of PS Quarterly: What Works? Magazine_What_Works-Q32025. Secure your copy of PS Quarterly: What Works? A new issue of our magazine, PS Quarterly: What Works?, is almost here. With the sustainable-development agenda under severe strain, leading thinkers examine the initiatives and innovations that are delivering results. Subscribe to PS Premium now, so you don’t miss out. SUBSCRIBE NOW\n\nThe administration’s deal with Intel is even more brazen. In August, Trump announced that the US government had acquired a 10% stake in the company, paid for with $5.7 billion Intel had already been promised under the CHIPS and Science Act and another $3.2 billion from the Secure Enclave program. The agreement also effectively shackles Intel to its loss-making foundry while giving the government the option to buy an additional 5% if the foundry is ever sold.\n\nNotably, by converting anticipated CHIPS grants into equity, the agreement does not provide Intel with new government funds. Meanwhile, private shareholders bear the cost of dilution: the US government purchased its stake at $20.47 per share – well below the $24.80 closing price on the eve of Trump’s announcement.\n\nAlthough the government will hold no seats on Intel’s board, even without formal representation, the administration’s shadow will loom over the company’s decision-making. Policymakers could lean on Nvidia, AMD, and other firms to buy semiconductors from Intel, pressure the company to build new factories in unprofitable locations, or force it to hire workers chosen for political loyalty rather than competence.\n\nIntel’s prolonged decline underscores the poor economics driving Trump’s investment. In the 1990s, the company was the leading semiconductor manufacturer; in 2000, it even briefly became the world’s second most valuable company. Today, however, it doesn’t even crack the top 15 chipmakers by market capitalization.\n\nIntel has also been the single largest beneficiary of the CHIPS Act, using federal funds to develop new production facilities in Arizona. But construction faced repeated delays, with executives blaming a shortage of skilled labor. Similarly, an Ohio plant already under construction has had its completion date pushed back from 2025 to 2030.\n\nAgainst this backdrop, Trump’s Intel deal looks especially misguided. What the company truly needs is new financing to service its existing obligations, swollen by years of heavy losses, and fund the turnaround plan developed by its new CEO, Lip-Bu Tan. SoftBank, the Japanese investment conglomerate, recently announced a $2 billion investment in Intel, though whether that move reflects genuine confidence in Intel’s future or an effort to curry favor during tense tariff negotiations between the US and Japan remains an open question.\n\nIndustrial policy is often said to be about “picking winners.” But given Intel’s recent performance, the Trump administration seems intent on picking losers. While few dispute the importance of steel production, or that semiconductors will drive future growth, Trump’s brand of state capitalism does little to strengthen either industry or the broader US economy. Instead, it exposes the dangers of government meddling in markets: wasted taxpayer money, distorted incentives, weakened competition, and less dynamism and innovation.",
      "source": "Project Syndicate",
      "url": "https://www.project-syndicate.org/commentary/trump-misguided-corporate-meddling-bound-to-backfire-by-anne-o-krueger-2025-09",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Will a win-win for Nvidia and OpenAI end up as a lose-lose for the rest of us?",
      "content": "Dystopian visions of artificial intelligence (AI) feature bots breaking free of human control and running amok. But what if the AI industry itself goes wild? While US investors must watch out for an outsized investment bubble, AI users everywhere need to worry about a web of convergent business interests that could plausibly cramp market rivalry.\n\nOn Monday, news broke of Nvidia’s deal with OpenAI that could see the world’s top AI chip company invest up to $100 billion in the firm behind ChatGPT, one tenth at a time.\n\nNvidia is the world’s most valuable company, with a monopolistic hold on its chip market, while OpenAI leads the global chatbot race with a claimed 700 million weekly active users. On the face of it, this is a clever way for Nvidia to boost demand for its chips as OpenAI invests heavily in data centres. For every gigawatt of capacity, the AI world’s dominant chip-seller might pump in $10 billion.\n\nDays earlier, Nvidia said it would put $5 billion into Intel. As for Sam Altman’s OpenAI, it recently struck a mega deal with Oracle to lease AI infrastructure. For a 2015 startup with revenues placed at only around $13 billion, that’s quite some deal-making. It speaks of how explosively today’s ‘smart money’ expects AI to grow.\n\nAn early bet-placer was Microsoft, which invested over $10 billion in OpenAI soon after its chatbot stormed our digital gadgets. Since Altman’s effort to carve its business subsidiary apart from its non-profit parent has not yet taken formal shape, its control structure remains hazy. What is visible, all the same, is a web of alliances that AI users have reason to be wary of.\n\nAlso Read | China is more eager to use Nvidia’s AI chips than it lets on\n\nWhat’s touted as a win-win for businesses need not work out well for customers. While Nvidia’s CEO Jensen Huang has spoken of how both his company and Altman’s will gain from their pact, critics point out the ‘circular dynamics’ of one firm funding another’s purchases of its wares.\n\nIf this gives the deal an artificial air, the fact that OpenAI will partly use its closely held shares as a currency to create backup infra adds to its opacity. OpenAI is reportedly valued at some $500 billion, but reports say that the equity acquired by Nvidia would have no voting rights, assuring Altman executive leeway from his megacorp allies.\n\nThe fortunes of OpenAI and its allies hinge on leadership of a blistering new age of AI-driven gains. For all the hype, however, the impact of AI on corporate productivity has been modest so far, like the learning curve of its offerings.\n\nIn a dream scenario, AI will put economies on sizzling growth paths and generate vast revenues off a global user base to justify the mega-sums being invested in it. But this is yet to be tested and billions could end up wasted in pursuit of a grand fantasy.\n\nEither way, if the ‘groupthink’ of a closely aligned quest for AI market success gets in the way of true competition, AI users could be dealt a bad deal.\n\nIn a market that serves users best, various AI visions would compete fiercely for both users and resources—with their aims and rewards free of each other’s. True, Big Tech players like Google have competitive AI offerings (and even allies), but OpenAI’s web of alliances, some of it blessed by the White House, could emerge as a collusive force to reckon with if mass-market AI becomes a winner-takes-all game.\n\nIndian AI is in infancy and Chinese AI untrustworthy. If smaller AI players get squeezed out by capital intensity and network effects, we risk a global failure of ‘intelligence,’ with its artificial version crafted for the rest of us but controlled by a few.",
      "source": "Livemint",
      "url": "https://www.livemint.com/opinion/online-views/nvidia-openai-deal-ai-investment-bubble-market-competition-chatgpt-sam-altman-corporate-monopoly-china-silicon-valley-11758635905615.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "China Market Update: Technology Stocks Lead Markets On Alibaba AI Investment & Nvidia Partnership",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/brendanahern/2025/09/24/china-market-update-technology-stocks-lead-markets-on-alibaba-ai-investment--nvidia-partnership/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Jimmy Kimmel's return represents a big, final test for Disney's Bob Iger before he heads for the exits",
      "content": "Disney CEO Bob Iger is fighting to keep hedge fund directors off the company's board\n\nDisney CEO Bob Iger is fighting to keep hedge fund directors off the company's board Alberto E. Rodriguez/Getty Images\n\nDisney CEO Bob Iger is fighting to keep hedge fund directors off the company's board Alberto E. Rodriguez/Getty Images\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nHi! Did you catch Jimmy Kimmel last night? The late-night host's show returned after a brief suspension over comments regarding Charlie Kirk. In case you missed it, or you're in a market where local affiliates are still refusing to air the show, we've got a rundown of all the highlights.\n\nKimmel teared up, explaining that he never intended to make light of Kirk's death. And he called political efforts to sway networks and affiliates from airing the show \"un-American,\" noting it wasn't just about comedy.\n\nLate-night hosts, including Kimmel, made one thing very clear, wrote veteran late-night watcher Cheryl Teh: They'll be thorns in Trump's side for as long as they can be.\n\nIn today's big story, navigating Kimmel's return could be the last big test for Disney CEO Bob Iger's legacy.\n\nWhat's on deck:\n\nMarkets: The Wall Street firms that rely the most on H-1B visas.\n\nTech: Internal data shows how Amazon's Q Developer lags behind rivals.\n\nBusiness: Trust me when I tell you that you won't be able to guess corporate America's new favorite C-suite title.\n\nBut first, a legacy in question.\n\nIf this was forwarded to you, sign up here.\n\nThe big story\n\nMouse trap\n\nDisney CEO, Bob Iger. Chip Somodevilla via Getty Images\n\nWill Bob Iger leave Disney a Magic Kingdom or a Haunted Mansion?\n\nDespite spending nearly two decades running Disney, what happens over the next few weeks could ultimately define Iger's legacy.\n\nThe Jimmy Kimmel saga has put the Disney CEO in the middle of a culture war involving high-profile celebrities, a government agency, and President Donald Trump.\n\nIger's handling of the continued fallout from Kimmel's suspension-turned-reinstatement could cement how the legendary executive is remembered, write BI's Lucia Moses, Madeline Berg, and Tim Paradis.\n\nIt won't be easy, as Disney has managed to enrage both sides of the aisle. Kimmel supporters are upset he was suspended in the first place, while his detractors are mad he was let back on the air.\n\nAnd we're not just talking about Disney adults and anonymous internet commentators here. Some players on both sides of the argument hold significant power over the House of Mouse.\n\nCelebrities, who have mostly backed Kimmel, are Disney's lifeblood. If the company were to lose creative community's support, that's a problem. It's tough to create shows and movies if you don't have people willing to make them with you.\n\nThat's not to say you want to pick a fight with the other side. The two local TV station owners that refuse to air Kimmel's show, Nexstar and Sinclair, oversee roughly 25% of ABC stations. It's the latest in the growing tension between Disney and its local broadcasters, writes BI's James Faris.\n\nThey also have the backing of FCC Chair Brendan Carr, who called local TV stations' resistance to national programmers \"a good thing.\"\n\nA 26-year-old man was detained by the Anaheim Police Department for indecent exposure and for being under the influence of a controlled substance. Image Group LA via Getty Images\n\nIt's a marked change from when Iger was looking to take the company a little over a year ago.\n\nBack in April 2024, Iger made clear Disney was about entertaining, not advancing \"any kind of agenda.\" Shaking Disney of the so-called \"woke\" label has been a priority since his return as CEO in 2022.\n\nHe's also got plenty of other things on his plate without Kimmelgate. There's the matter of who will take over as CEO when Iger is set to step down at the end of 2026. It's something he's keen to get right after the debacle that was the Bob Chapek era.\n\nThat process will likely need to be sidelined as Iger navigates the Kimmel situation. Both sides will closely watch the show's future, and each decision will be scrutinized for its underlying political meaning, even if there isn't one.\n\nIger will also have to endure more criticism, like the one he received from his former boss, ex-Disney CEO Michael Eisner, who blasted the decision to suspend Kimmel.\n\nTo Disney and Iger's credit, they might have found some common ground for both sides. On Tuesday, the company announced plans to raise the monthly price of some of its Disney+ subscriptions by $2 to $3 next month.\n\nBecause if there is anything we can all agree on, it's getting annoyed over the price of our streaming services going up.\n\n3 things in markets\n\nGold is having its own gold rush. The precious metal is having its best year since the 1970s, with recent returns ramping up following the Fed's latest rate cut. That success didn't happen overnight, though. BI's Joe Ciolli breaks down the three main macro drivers propelling gold's hot streak.\n\nHow President Trump's $100,000 H-1B affects Wall Street. Silicon Valley isn't the only sector reeling from the new H-1B fee. Many Wall Street banks rely heavily on the program. JPMorgan's Jamie Dimon said he expects pushback on Trump's plan, adding that he supports \"merit-based immigration.\" BI crunched the data to find out which financial firms could be impacted the most.\n\nThe insane schedule of investing personality Jim Cramer. Running on about four hours of sleep, the \"Mad Money\" host wakes up every day at 3:15 a.m. to brush up on the market before his workout. He also combs through about 700 emails a day.\n\n3 things in tech\n\nAWS CEO Matt Garman Amazon\n\nAmazon's Q Developer isn't doing so hot. The online retailer's AI coding assistant saw revenue fall behind rivals in its first year, according to internal documents reviewed by BI. Amazon also has plans to refine Q's branding as the company's employees appear to favor external products like Cursor over its tech.\n\nThe Zuckerberg playbook for pleasing Republicans. Last year, Mark Zuckerberg addressed Republicans' complaints of anti-conservative bias on Meta's platforms by shifting the blame to the Biden administration in a letter to Congress. Google just copied the play and took it one step further.\n\nThe one thing OpenAI's $100 billion deal with Nvidia can't guarantee. The deal gives OpenAI a significant leg up in the AI race, providing vital access to GPUs. However, it can't guarantee access to electricity, which remains an industry-wide challenge.\n\n3 things in business\n\nGetty Images; Tyler Le/BI\n\nSpooky season is here, and so is \"hybrid creep.\" Many employers are gradually increasing the number of days workers must show up at the office. A new survey, commissioned by Owl Labs, shows 34% of employees must be on-site four days a week, up from 23% in 2023. The subtle trend could signal the end of flexible work at some companies.\n\nTrust is dead. Can the \"Chief Trust Officer\" revive it? Some companies have added a new position to the C-suite: the chief trust officer. They're tasked with protecting against data breaches, answering questions about their companies' use of AI, and building trust — a challenge since trust is a complex emotion and not a metric.\n\nTylenol's groundhog day. Tylenol's owner Johnson & Johnson pioneered crisis management with its response to the \"Tylenol murders\" in 1982, when seven people died from taking Tylenol capsules that someone laced with potassium cyanide. Tylenol is now staring down another PR crisis after President Trump called it unsafe. Communications experts broke down what worked for J&J then and how it could play out now.\n\nIn other news\n\nMeta just missed a senator's deadline for submitting records about its AI chatbot policies for kids.\n\nDiddy's kids, mom, and pals come out in force to plead for leniency: 'Please let my father out of jail!'\n\nI've had an executive Costco membership for 10 years. It pays for itself — and then some.\n\nYouTube says it'll bring back creators banned for violating its COVID-19 and election content policies.\n\n$12 billion Walleye will back a new $500 million hedge fund from a former Millennium and Citadel healthcare portfolio manager.\n\nJPMorgan economists predict the H-1B visa's new $100,000 fee could cut 5,500 work authorizations per month.\n\nWhy the US is barring Iranian diplomats from shopping at Costco.\n\nI'm a Trump supporter — but I might move back to India over his H-1B policy.\n\nWhat's happening today\n\nNASA IMAP mission to study the sun's heliosphere launches.\n\nAmerican Bankers Association Economic Advisory Committee presents latest forecast.\n\nDan DeFrancesco, deputy executive editor and anchor, in New York. Meghan Morris, bureau chief, in Singapore. Akin Oyedele, deputy editor, in New York. Grace Lett, editor, in New York. Amanda Yen, associate editor, in New York.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/bob-iger-disney-ceo-navigating-jimmy-kimmel-suspension-legacy-2025-9",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "AI startup Modular raises $250 million, seeks to challenge Nvidia dominance",
      "content": "AI startup Modular said on Wednesday it raised $250 million in a funding round valuing it at $1.6 billion, as it aims to challenge Nvidia's software stranglehold on the AI computing market.\n\nThe funding, which nearly tripled the company's valuation from two years ago, was led by U.S. Innovative Technology fund. DFJ Growth and all existing investors, including GV, General Catalyst and Greylock also joined the round.\n\nFounded in 2022 by veteran engineers at Apple and Google, Modular's platform is designed to allow developers to run their AI applications across a variety of computer chips without having to rewrite code for each one. It now serves cloud providers such as Oracle and Amazon, as well as chipmakers Nvidia and AMD.\n\nNvidia controls over 80 per cent of the high-end AI chip market, partly thanks to its proprietary CUDA software, which locks over 4 million global developers into its ecosystem.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nModular says it has adopted what it calls a \"Switzerland\" strategy to be a neutral software layer.\n\nChris Lattner, co-founder and CEO of Modular, said the goal is not to defeat the market leader. \"What we're focused on is not like pushing down Nvidia or crushing them. It's more about enabling a level playing field so that other people can compete,\" he said.\n\nIt plans to sell the software directly to enterprises on a consumption basis and through revenue-sharing partnerships with cloud providers.\n\nThe company's strategy has attracted investors betting on a multi-vendor future for AI hardware. Sam Fort, partner at DFJ Growth, compared Modular to \"VMware for the AI era\", which supported companies to work across CPUs.\n\n\"Modular is trying to create the AI hypervisor that will allow you to port workloads across different vendors,\" Fort said.\n\nThe company, with about 130 employees, plans to use the new capital to expand its engineering and go-to-market team. The funds will also help the company expand from its current focus on AI inference into the AI training market.",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/business/ai-startup-modular-raises-250-million-seeks-challenge-nvidia-dominance-5367226",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "nvidia-nat-weave 1.3.0a20250925",
      "content": "For more information about the NVIDIA NeMo Agent toolkit, please visit the NeMo Agent toolkit GitHub Repo .\n\nThis is a subpackage for Weights and Biases Weave integration for observability.\n\nDownload files\n\nDownload the file for your platform. If you're not sure which to choose, learn more about installing packages.\n\nSource Distributions\n\nNo source distribution files available for this release.See tutorial on generating distribution archives\n\nBuilt Distribution\n\nFilter files by name, interpreter, ABI, and platform.\n\nIf you're not sure about the file name format, learn more about wheel file names.\n\nThe dropdown lists show the available interpreters, ABIs, and platforms. Enable javascript to be able to filter the list of wheel files.\n\nCopy a direct link to the current filters Copy",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-weave/1.3.0a20250925/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "CoreWeave expands OpenAI pact with new $6.5 billion contract",
      "content": "AI cloud provider CoreWeave has expanded its partnership with OpenAI in a new deal worth up to $6.5 billion, bringing the total value of their agreements to $22.4 billion, the latest in a series of billion-dollar deals OpenAI has signed to secure computational power.\n\nThe agreement marks the third major expansion of the partnership between the two companies this year. The company behind ChatGPT struck an initial cloud deal with CoreWeave in March worth up to $11.9 billion, followed by a $4 billion add‑on in May.\n\nThe latest addition shows the deepening relationship between the two companies as OpenAI seeks multiple partners to help with an unprecedented data-center buildout to meet its growing computational demands.\n\nThe announcement follows major updates to OpenAI’s infrastructure project \"Stargate\". OpenAI said Tuesday it will open three new sites with Oracle, its cloud partner with a $300 billion deal over the next few years, and build two additional data centers with SoftBank.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nCoreWeave shares rose as much as 6 per cent in early trading before paring gains to trade flat. Reuters was first to report the news.\n\nIn an interview with Reuters, CEO Michael Intrator reiterated the continued AI infrastructure demand he is seeing from clients.\n\n“The market is incredibly behind on its ability to deliver the infrastructure that's being demanded. As an industry, we continue to underestimate the demand for things,” Intrator said.\n\nHe also described the expanded contract with OpenAI as a sign that CoreWeave is diversifying its revenue away from Microsoft, which was once OpenAI's exclusive infrastructure provider and accounted for 60 per cent of CoreWeave’s revenue in 2024.\n\n“The opportunity to go about diversifying our clients with some really wonderful, well-known, creditworthy customers is very exciting. When I think about this quarter, this is the quarter of diversification for us,\" he added.\n\nOpenAI has said Stargate aims to secure a total of 10 gigawatts of capacity through an investment that could reach $500 billion.\n\n\"The combined capacity from these five new sites—along with our flagship site in Abilene, Texas, and ongoing projects with CoreWeave—brings Stargate to nearly 7 gigawatts of planned capacity and over $400 billion in investment over the next three years,\" OpenAI said in a blog post.\n\nThe wave of agreements underscores the convergence of interests among major tech companies developing advanced AI and raises questions about \"circular\" financing across the industry and whether capital will continue to flow.\n\nNvidia said earlier this week it will invest up to $100 billion in OpenAI and supply data‑center chips, marking a tie‑up between two of the highest‑profile players in the AI race.\n\nThe Nvidia and OpenAI deal gives the chipmaker a financial stake in one of its biggest customers and has prompted antitrust concerns.\n\nNvidia has also invested in CoreWeave and owns more than 5 per cent of the company. CoreWeave, in turn, made substantial purchases of Nvidia hardware and signed a $6.3 billion initial order with Nvidia this month, in a deal that guarantees the chipmaker will purchase any cloud capacity not sold to customers.",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/business/coreweave-expands-openai-pact-new-65-billion-contract-5369416",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "HighPoint's adapter enables GPUDirect storage — up to 64 GB/s from drive to GPU, bypassing the CPU",
      "content": "HighPoint on Thursday introduced its Rocket 7638D PCIe 5.0 switch card that is designed to enable Nvidia's GPUDirect interconnection between AI GPUs and NVMe storage devices. The device is designed to speed up AI training and inference workloads when operating with software that fully support GPUDirect.\n\nThe latest GPUs from Nvidia (starting from A100) support GPUDirect technologies that enable direct data transfers between GPUs and other devices, such as SSD or network interfaces, bypassing the CPU and system memory to increase performance and free CPU resources for other workloads. However, GPUDirect requires support both from the GPU and from a PCIe switch that supports P2P DMA capability, but not all PCIe Gen5 switches support this feature, which is where switch cards come into play.\n\nHighPoint's Rocket 7638D switch card packs the Broadcom PEX 89048 switch enabling system integrators to build systems with GPUDirect capability. The adapter features 48 PCIe 5.0 lanes: 16 lanes to connect to host, 16 lanes to connect to external GPU box using a CDFP CopprLink connector, and 16 lanes are dedicated to internal NVMe storage devices using MCIO 8i connectors. The MCIO ports support up to 16 NVMe drives, enabling configurations with up to 2PB of high-performance storage.\n\nThe Rocker 7638D adapter enables GPUDirect Storage workflows that avoid host CPU and RAM entirely and provide predictable bandwidth (up to 64 GB/s) and latency when paired with compatible software, which includes operating system, GPU drivers, and filesystem. The device (or rather systems that it enables) is particularly useful in scenarios involving large-scale training datasets that use plenty of storage.\n\nSince the the Broadcom PEX 89048 switch chip contains an Arm-based CPU, it is completely independent and self managed, so it is compatible with both Arm and x86 platforms. The adapter works out of the box with all major operating systems, without the need for special drivers or additional software installation.\n\nThe Rocket 7638D includes field-service features such as VPD tracking for hardware and firmware matching and a utility that monitors health status and PCIe link performance. These tools simplify troubleshooting and replacement, especially in multi-node or hyperscale installations where hardware tracking matters.\n\nHighPoint did not disclose pricing of its Rocket 7638D switch card, which will probably depend on volumes and other factors.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/ssds/highpoint-enables-gpudirect-storage-with-new-adapter-up-to-64-gb-s-from-storage-to-gpu-without-cpu-involvement",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Intel 跟 NVIDIA 合作，所以 Intel 自己的顯卡還要搞嗎...",
      "content": "上個禮拜的消息，NVIDIA 與 Intel 結盟，NVIDIA 的新聞稿在「NVIDIA and Intel to Develop AI Infrastructure and Personal Computing Products」這邊，而 Intel 的新聞稿則是在「Intel and NVIDIA to Jointly Develop AI Infrastructure and Personal Computing Products 」這邊，兩邊內容是類似的。\n\n主要是 NVIDIA 投了 US$5B 進去：\n\nNVIDIA to invest $5 billion in Intel common stock\n\n新聞稿看起來主力在 NVLink 上：\n\nThe companies will focus on seamlessly connecting NVIDIA and Intel architectures using NVIDIA NVLink — integrating the strengths of NVIDIA’s AI and accelerated computing with Intel’s leading CPU technologies and x86 ecosystem to deliver cutting-edge solutions for customers.\n\n機房端的部分像是把 NVLink 整進 CPU？\n\nFor data centers, Intel will build NVIDIA-custom x86 CPUs that NVIDIA will integrate into its AI infrastructure platforms and offer to the market.\n\n個人端的部分看起來就跟 NVLink 無關了，看起來是要把 NVIDIA 的 GPU 整進來？不過這點應該是拿 NVIDIA 錢可以預期到的事情了：\n\nFor personal computing, Intel will build and offer to the market x86 system-on-chips (SOCs) that integrate NVIDIA RTX GPU chiplets. These new x86 RTX SOCs will power a wide range of PCs that demand integration of world-class CPUs and GPUs.\n\n也許之後可以直接吃 CUDA 生態系？不確定這塊會做到什麼程度...",
      "source": "Gslin.org",
      "url": "https://blog.gslin.org/archives/2025/09/25/12636/intel-%e8%b7%9f-nvidia-%e5%90%88%e4%bd%9c%ef%bc%8c%e6%89%80%e4%bb%a5-intel-%e8%87%aa%e5%b7%b1%e7%9a%84%e9%a1%af%e5%8d%a1%e9%82%84%e8%a6%81%e6%90%9e%e5%97%8e/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Artisight and Yale New Haven Health sign agreement for hospital platform",
      "content": "The platform integrates with existing workflows to alleviate staff workload, enhance patient throughput, and improve safety. Credit: paulista/Shutterstock.com.\n\nYale New Haven Health in the US has signed an enterprise-wide agreement with Artisight for its Smart Hospital Platform.\n\nInitially, the deployment will concentrate on virtual nursing, with plans for future expansion to incorporate computer vision, advanced AI, and ambient technology.\n\nThis initiative aims to enhance patient safety, alleviate the workload on care teams, and streamline various workflows.\n\nArtisight CEO and co-founder Dr Andrew Gostine said: “Yale New Haven Health is a true innovator and leader in the US healthcare system. Its selection of our technology validates the value of our Smart Hospital Platform.\n\n“We’re excited to collaborate with Yale New Haven Health to discover innovative ways computer vision and our proprietary AI models can improve clinical workflows and elevate the patient experience.”\n\nArtisight’s technology is said to have demonstrated improvement in operational efficiency within hospital environments, particularly in the realms of patient discharges and safety enhancements.\n\nGlobalData Strategic Intelligence US Tariffs are shifting - will you react or anticipate? Don’t let policy changes catch you off guard. Stay proactive with real-time data and expert analysis. By GlobalData Learn more about Strategic Intelligence\n\nIn a different academic health system, the company’s virtual nursing solution improved the rate of on-time discharges fourfold compared to the average. It also provided bedside nurses with an extra 25 minutes per patient by enabling virtual nurses to oversee admissions and discharges.\n\nArtisight enhances hospital operations through its Smart Hospital Platform, assisting healthcare systems in cutting expenses, increasing efficiency, and improving patient care.\n\nUtilising NVIDIA graphics processing units (GPUs), the company’s computer vision technology and voice-activated sensors facilitate automated documentation, monitoring in real time, and virtual nursing, all seamlessly integrated into electronic health records (EHR).\n\nMore than 400 hospitals within 30 health systems rely on Artisight to deliver measurable outcomes such as reducing patient falls by over 50% and decreasing nurse turnover.\n\nIn July 2025, Artisight introduced voice-activated medical interpreters on its platform, enabling clinicians to communicate with patients in more than 240 languages.",
      "source": "Hospitalmanagement.net",
      "url": "https://www.hospitalmanagement.net/news/artisight-yale-health-contract-platform/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Intel Approaches Apple For Potential Investment Amid Struggles",
      "content": "Intel has approached Apple about a possible investment and closer collaboration , following recent multibillion-dollar deals with Nvidia , the U.S. government, and SoftBank to stabilize the struggling chipmaker. Reuters reports:",
      "source": "Slashdot.org",
      "url": "https://apple.slashdot.org/story/25/09/24/2141256/intel-approaches-apple-for-potential-investment-amid-struggles",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "How Enterprise AI Agents Can Reach Their Potential",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/cio/2025/09/25/how-enterprise-ai-agents-can-reach-their-potential/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Foxconn pulls ahead of Quanta and Wistron in Nvidia AI server race",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250925PD212/foxconn-nvidia-wistron-quanta-ai-server.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Jobless for 4 months, Redditor appears for 30 interviews; quits startup job in 9 days: ‘I still regret messing up’",
      "content": "Changing jobs is common, but quitting in nine days? That’s what a Reddit user admitted in a post that has now captured widespread attention online.\n\nAfter spending four months unemployed and facing countless rejections, the man finally landed a DevOps position at a small startup with around 80 employees. Initially, he felt relieved, thinking he had finally secured some stability. But shortly after, an offer from a UK-based multinational bank arrived, presenting a Software Engineer role with a slightly higher salary of 15 LPA, a hybrid work model in Bengaluru, and, most importantly, a healthier work-life balance.\n\nHe didn’t take the decision lightly. Friends and mentors from companies like Nvidia, Amazon, Zeta, and Nutanix encouraged him to take the MNC offer, highlighting its long-term benefits.\n\nStory continues below this ad\n\n“Honestly, I’m kinda overwhelmed. It feels weird to put down papers after just 9 days of joining, but I know how much I struggled when I was jobless, and I don’t want to miss this shot. Also, my HR here had lowballed me below my last CTC (took me to 8 LPA, which I negotiated to 14 LPA), so that always stayed in my head,” he wrote.\n\nHe added, “Let’s see, bhai, hopefully this time it’s long-term and I can settle without this constant job switch stress. I have stopped applying, honestly, I am tired of interviewing and studying after I have appeared for 30 interviews at least. So I needed peace, I feel this will be it, I wanna stay here for a minimum of 1.5 – 2 years.”\n\nTake a look at the post:\n\nScreenshot of the Reddit post Screenshot of the Reddit post\n\nHis bold move has sparked a wider conversation about workplace culture, the importance of work-life balance, and what stability really means in today’s fast-moving job market.\n\nA user wrote, “An MNC is relatively the more stable job. And also the brand recognition helps, so don’t worry too much, you did the right thing.” Another user wrote, “Companies will throw you out after 1 day of hiring if all of a sudden you are not an asset to him. Don’t think twice , just put down your paper again.”\n\nStory continues below this ad\n\nA third person commented, “Don’t think much. Just make the switch. My past 3 companies were mid to small startups, and all of them had terrible culture, weekend work,g and then finally I left one, and the next 2 closed down without even paying salaries. The thing is, MNCs bring stability, long-term career plan,and better opportunities in the next switch.”\n\nA fourth individual wrote, “But what about notice period?did u got early release or need to serve whole duration because since u had already given bank interview u must have told them I can join on this date rigth? Also won’t it cause any issues in PF documents?”",
      "source": "The Indian Express",
      "url": "https://indianexpress.com/article/trending/trending-in-india/reddit-user-quits-job-after-9-days-join-uk-mnc-for-better-work-life-balance-10270885/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Nscale raises $1.1 billion from Aker, other investors for AI buildout",
      "content": "COPENHAGEN (Reuters) -British artificial intelligence group Nscale has raised $1.1 billion from investors, including Norway's Aker ASA and Finland's Nokia, to help accelerate its data centre infrastructure buildout, the companies said on Thursday.\n\nThe so-called Series B funding round was led by Aker, the investment company of Norwegian billionaire Kjell Inge Roekke, which injected $285 million in cash and assets, taking a stake of 9.3% in Nscale.\n\nA potential future earn-out could further increase Aker's ownership to 12.2%, the Norwegian group said.\n\nU.S. artificial intelligence company OpenAI in July said it would build its first European data centre in Norway's Arctic city of Narvik, jointly with Nscale and Aker.\n\nSandton Capital, Blue Owl Managed Funds, Dell, Fidelity Management & Research Company, G Squared, NVIDIA, Point72 and T.Capital also took part in the funding round, Nscale said.\n\nAker said its 50% stake in the Aker-Narvik joint venture can be converted into additional Nscale shares at a future initial public offering.\n\n(Reporting by Essi Lehto and Elviira Luoma, editing by)",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nscale-raises-1-1-billion-082633339.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Chinese Tech Stocks Advance, Set for Record Winning Streak",
      "content": "Chinese tech stocks extended their rally Thursday, fueled by persistent investor enthusiasm for the country’s artificial intelligence developers.\n\nThe Hang Seng Tech Index climbed 0.9%, led by gains in JD.com Inc., the e-commerce giant with ambitious AI plans, and smartphone maker Xiaomi Corp. The index, which tracks Chinese technology companies listed in Hong Kong, is now set for its eighth consecutive weekly advance, the longest winning streak since its inception.\n\nMost Read from Bloomberg\n\nChinese technology companies have been on a strong upward trajectory, driven by grassroots AI advancements that gained global attention following surprising breakthroughs by startup DeepSeek. The elevated stock momentum marks a sharp reversal from just a year ago, when the sector was weighed down by regulatory crackdowns and a slowing economy.\n\nFresh impetus came from the government’s announcement for increased support for the sector, alongside Alibaba Group Holding Ltd.’s plans to ramp up AI spending and its new partnership with Nvidia Corp. These developments helped push the benchmark’s year-to-date gain to about 44%.\n\n“AI optimism is surely one factor with Alibaba’s confidence in raising capital expenditure yesterday driving positive sentiment across the tech space,” said Vey-Sern Ling, managing director at Union Bancaire Privee. Concerns about value-destructive competition in food delivery and quick commerce appear to be easing, given heightened government scrutiny, he added.\n\nJD.com shares rose 3.5%, buoyed by reports that the company disclosed at a conference in Beijing that it plans to continue investing over the next three years to build a trillion-yuan AI ecosystem.\n\nXiaomi shares gained over 4% ahead of the company’s release of its latest flagship smartphone, the Xiaomi 17, that will compete directly with Apple Inc.’s iPhone 17. Baidu Inc. shares climbed over 2%, boosted by an announcement that its autonomous driving unit was granted driving trial permit in Dubai.\n\nThe rally has also pushed the Hang Seng Tech Index to technically overbought territory, based on its 14-day relative strength index, Bloomberg-compiled data showed. In terms of valuation, the index now trades at 21.5 times forward earnings estimates, above its three-year average of 18.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/chinese-tech-stocks-advance-set-061910447.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Exclusive-CoreWeave expands OpenAI pact with new $6.5 billion contract",
      "content": "By Krystal Hu\n\n(Reuters) -AI cloud provider CoreWeave has expanded its partnership with OpenAI in a new deal worth up to $6.5 billion, bringing the total value of their agreements to $22.4 billion, the latest in a series of billion-dollar deals OpenAI has signed to secure computational power.\n\nThe agreement marks the third major expansion of the partnership between the two companies this year. The company behind ChatGPT struck an initial cloud deal with CoreWeave in March worth up to $11.9 billion, followed by a $4 billion add‑on in May.\n\nThe latest addition shows the deepening relationship between the two companies as OpenAI seeks multiple partners to help with an unprecedented data-center buildout to meet its growing computational demands.\n\nThe announcement follows major updates to OpenAI’s infrastructure project \"Stargate\". OpenAI said Tuesday it will open three new sites with Oracle, its cloud partner with a $300 billion deal over the next few years, and build two additional data centers with SoftBank.\n\nCoreWeave shares rose as much as 6% in early trading before paring gains to trade flat. Reuters was first to report the news.\n\nIn an interview with Reuters, CEO Michael Intrator reiterated the continued AI infrastructure demand he is seeing from clients.\n\n“The market is incredibly behind on its ability to deliver the infrastructure that's being demanded. As an industry, we continue to underestimate the demand for things,” Intrator said.\n\nHe also described the expanded contract with OpenAI as a sign that CoreWeave is diversifying its revenue away from Microsoft, which was once OpenAI's exclusive infrastructure provider and accounted for 60% of CoreWeave’s revenue in 2024.\n\n“The opportunity to go about diversifying our clients with some really wonderful, well-known, creditworthy customers is very exciting. When I think about this quarter, this is the quarter of diversification for us,\" he added.\n\nOpenAI has said Stargate aims to secure a total of 10 gigawatts of capacity through an investment that could reach $500 billion.\n\n\"The combined capacity from these five new sites—along with our flagship site in Abilene, Texas, and ongoing projects with CoreWeave—brings Stargate to nearly 7 gigawatts of planned capacity and over $400 billion in investment over the next three years,\" OpenAI said in a blog post.\n\nThe wave of agreements underscores the convergence of interests among major tech companies developing advanced AI and raises questions about \"circular\" financing across the industry and whether capital will continue to flow.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/exclusive-coreweave-expands-openai-pact-125835099.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Wedmont Private Capital Purchases 14,745 Shares of NVIDIA Corporation $NVDA",
      "content": "Wedmont Private Capital boosted its stake in shares of NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 3.6% in the second quarter, according to its most recent disclosure with the Securities & Exchange Commission. The firm owned 429,653 shares of the computer hardware maker’s stock after purchasing an additional 14,745 shares during the quarter. NVIDIA comprises 3.0% of Wedmont Private Capital’s portfolio, making the stock its 7th largest holding. Wedmont Private Capital’s holdings in NVIDIA were worth $69,982,000 as of its most recent filing with the Securities & Exchange Commission.\n\nOther large investors have also recently added to or reduced their stakes in the company. Brighton Jones LLC boosted its position in shares of NVIDIA by 12.4% in the fourth quarter. Brighton Jones LLC now owns 324,901 shares of the computer hardware maker’s stock valued at $43,631,000 after acquiring an additional 35,815 shares during the period. Bank Pictet & Cie Europe AG boosted its position in shares of NVIDIA by 1.0% in the fourth quarter. Bank Pictet & Cie Europe AG now owns 2,346,417 shares of the computer hardware maker’s stock valued at $315,100,000 after acquiring an additional 22,929 shares during the period. Highview Capital Management LLC DE boosted its position in shares of NVIDIA by 6.7% in the fourth quarter. Highview Capital Management LLC DE now owns 58,396 shares of the computer hardware maker’s stock valued at $7,842,000 after acquiring an additional 3,653 shares during the period. Hudson Value Partners LLC boosted its position in shares of NVIDIA by 30.7% in the fourth quarter. Hudson Value Partners LLC now owns 50,658 shares of the computer hardware maker’s stock valued at $6,805,000 after acquiring an additional 11,900 shares during the period. Finally, Summit Investment Advisors Inc. boosted its position in shares of NVIDIA by 1.9% in the fourth quarter. Summit Investment Advisors Inc. now owns 737,749 shares of the computer hardware maker’s stock valued at $99,072,000 after acquiring an additional 13,700 shares during the period. Institutional investors own 65.27% of the company’s stock.\n\nGet NVIDIA alerts:\n\nInsider Activity\n\nIn other news, Director Harvey C. Jones sold 250,000 shares of NVIDIA stock in a transaction dated Thursday, September 18th. The stock was sold at an average price of $176.21, for a total transaction of $44,052,500.00. Following the transaction, the director owned 7,183,280 shares in the company, valued at $1,265,765,768.80. The trade was a 3.36% decrease in their position. The transaction was disclosed in a document filed with the SEC, which is available at this hyperlink. Also, Director Mark A. Stevens sold 350,000 shares of NVIDIA stock in a transaction that occurred on Friday, September 19th. The shares were sold at an average price of $176.39, for a total value of $61,736,500.00. Following the completion of the sale, the director directly owned 7,399,803 shares in the company, valued at approximately $1,305,251,251.17. This represents a 4.52% decrease in their position. The disclosure for this sale can be found here. Insiders have sold 4,302,450 shares of company stock worth $740,755,443 in the last 90 days. Corporate insiders own 4.17% of the company’s stock.\n\nAnalysts Set New Price Targets\n\nSeveral research firms have recently weighed in on NVDA. Barclays reissued an “overweight” rating on shares of NVIDIA in a research report on Monday. Wolfe Research raised their target price on NVIDIA from $220.00 to $230.00 in a research report on Tuesday. BNP Paribas raised NVIDIA to a “hold” rating in a research report on Friday, August 1st. The Goldman Sachs Group reiterated a “buy” rating and set a $200.00 price objective on shares of NVIDIA in a research note on Wednesday, August 27th. Finally, Mizuho increased their price objective on NVIDIA from $192.00 to $205.00 and gave the stock an “outperform” rating in a research note on Thursday, August 14th. Four analysts have rated the stock with a Strong Buy rating, thirty-six have given a Buy rating, four have assigned a Hold rating and one has given a Sell rating to the company. According to data from MarketBeat, the stock currently has an average rating of “Moderate Buy” and a consensus target price of $208.76.\n\nRead Our Latest Research Report on NVIDIA\n\nNVIDIA Price Performance\n\nShares of NVDA stock opened at $176.97 on Thursday. The stock has a 50-day moving average price of $176.39 and a 200 day moving average price of $144.81. The company has a quick ratio of 3.60, a current ratio of 4.21 and a debt-to-equity ratio of 0.08. The firm has a market cap of $4.30 trillion, a price-to-earnings ratio of 50.42, a PEG ratio of 1.29 and a beta of 2.10. NVIDIA Corporation has a 12 month low of $86.62 and a 12 month high of $184.55.\n\nNVIDIA (NASDAQ:NVDA – Get Free Report) last issued its earnings results on Wednesday, August 27th. The computer hardware maker reported $1.05 earnings per share (EPS) for the quarter, topping analysts’ consensus estimates of $1.01 by $0.04. NVIDIA had a return on equity of 101.74% and a net margin of 52.41%.The firm had revenue of $46.74 billion for the quarter, compared to analysts’ expectations of $45.65 billion. During the same quarter last year, the business earned $0.68 earnings per share. The company’s revenue was up 55.6% compared to the same quarter last year. NVIDIA has set its Q3 2026 guidance at EPS. Research analysts expect that NVIDIA Corporation will post 2.77 EPS for the current year.\n\nNVIDIA Announces Dividend\n\nThe firm also recently disclosed a quarterly dividend, which will be paid on Thursday, October 2nd. Investors of record on Thursday, September 11th will be paid a dividend of $0.01 per share. This represents a $0.04 annualized dividend and a yield of 0.0%. The ex-dividend date of this dividend is Thursday, September 11th. NVIDIA’s dividend payout ratio (DPR) is presently 1.14%.\n\nNVIDIA Company Profile\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nSee Also\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/25/wedmont-private-capital-purchases-14745-shares-of-nvidia-corporation-nvda/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Could Intel's latest moves signal a new chapter in its relationship with Apple?",
      "content": "Apple and Intel’s relationship has shifted from partnership to split, and now, to possible reconciliation.\n\nApple and Intel were once closely tied. Intel powered Apple’s line of Mac devices, and for years, the partnership looked solid.\n\nTheir history actually dates back to the 1990s with the secret Star Trek project, an early attempt to get Mac OS running on Intel processors. That effort never launched, but the two companies finally came together in 2005 when Steve Jobs announced at WWDC that Apple would transition from PowerPC to Intel chips. At the time, Intel’s processor roadmap looked far stronger, marking a major shift in Apple’s computing strategy.\n\nNow, years after their split, Intel appears to be seeking Apple’s help once again.\n\nIntel Meteor Lake (Image credit: Daniel Rubino)\n\nIn 2006, Apple launched its first Intel-based Macs. The iMac and MacBook Pro both shipped with Intel’s Core Duo processors, and by August of that year, Apple had already completed the transition across its entire Mac lineup.\n\nThings looked strong for the partnership, but Apple was already planning ahead. In 2008, it acquired P.A. Semi for $278 million to develop custom ARM-based chips for mobile devices. This move marked the start of Apple’s long-term strategy to reduce its reliance on external chipmakers.\n\nBy 2010, Apple had introduced the A4 processor in the original iPad. It was a single-core chip running at 1GHz, a modest start that would see rapid improvement in the years that followed. By 2015 and 2016, Apple’s A9 series had arrived, and this is where the relationship with Intel began to show strain.\n\nThe relationship strain and the final break\n\nApple had already begun looking elsewhere to meet its LTE demands, turning to Qualcomm for support. By 2018, Intel struggled to keep up with Apple’s performance requirements.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nIn 2019, Apple acquired the majority of Intel’s smartphone modem business for $1 billion. The deal gave Apple control over a key iPhone component, and later that year, Intel sold the rest of its modem business to Apple.\n\nThe real breaking point came in 2020 with the announcement of the M1 chipset. It was Apple’s first ARM-based processor for Macs, and it proved to be a breakthrough. The M1 was so successful that Apple fully discontinued the use of Intel processors in 2021.\n\nInvestments offer hope for Intel’s future\n\nIt’s no secret that Intel has struggled in recent years. Between 2021 and 2024, it lost market share to AMD and missed out on the AI boom dominated by Nvidia. During this period, Intel’s stock declined by more than 30%.\n\nEven Intel’s leadership has been blunt about the situation. CFO David Zinsner admitted the company “fumbled the football” with its Arrow Lake CPUs, and CEO Lip-Bu Tan has warned there are no quick fixes for Intel’s problems.\n\nStill, it’s not all bad news. SoftBank recently invested $2 billion in Intel, while the U.S. government acquired a 9.9% stake worth $8.9 billion. Nvidia has also invested $5 billion, giving it a 4% share in the company.\n\nNow, according to reporting from Bloomberg, Intel has even approached Apple about a potential investment and closer collaboration. Talks are still in early stages, and there’s no guarantee of a deal, but it shows how far Intel is willing to go to secure its future.\n\nFollow Windows Central on Google News to keep our latest news, insights, and features at the top of your feeds!",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/intel/intel-approach-apple-for-investment",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Nvidia gives OpenAI $100 billion to spend mostly on Nvidia hardware and Nvidia share price goes up by $220 billion - why am I not surprised?",
      "content": "Nvidia commits $100 billion to OpenAI while reinforcing demand for its hardware\n\nPartnership builds massive data centers and fuels concerns over circular investment structures\n\nAnalysts warn deal may raise antitrust scrutiny as Nvidia strengthens AI dominance\n\nFollowing its recent surprise $5 billion Intel deal, Nvidia is spending big again, this time committing up to $100 billion to OpenAI alongside supplying millions of its chips.\n\nThe move fits a broader pattern in which Nvidia channels money into businesses that rely on its own hardware, from $6.3 billion in CoreWeave to $700 million in nScale, effectively reinforcing demand for its products while bypassing hyperscalers like Google and Microsoft which are racing to reduce their dependence on Nvidia’s hardware.\n\nThis latest investment into the world’s best-known AI firm immediately lifted Nvidia’s market value by more than $220 billion.\n\nCircular structure\n\nThe deal involves a circular structure and will see Nvidia will buy non-voting shares in OpenAI, which OpenAI will then spend mostly on Nvidia systems.\n\nCiting people familiar with the matter, Reuters says the partnership will begin with a $10 billion investment and scale as OpenAI deploys more computing power.\n\n“This is the biggest AI infrastructure project in history,” Nvidia founder and CEO Jensen Huang said in an interview with CNBC’s Jon Fortt. “This partnership is about building an AI infrastructure that enables AI to go from the labs into the world.”\n\nHe said the companies will build data centers capable of running next-generation AI models, powered by Nvidia’s new Vera Rubin platform.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe first data centers are due online in 2026 and require 10 gigawatts of power, roughly equal to the needs of 8 million US households.\n\nOpenAI chief executive Sam Altman said the capacity was essential for the company’s ambitions.\n\n“Building this infrastructure is critical to everything we want to do,” Altman said. “This is the fuel that we need to drive improvement, drive better models, drive revenue, drive everything.”\n\nAnalysts welcomed the long-term demand for Nvidia’s products but warned about the structure of the deal.\n\n“On the one hand this helps OpenAI deliver on some very aspirational goals for compute infrastructure,” said Stacy Rasgon of Bernstein. “On the other hand the ‘circular’ concerns have been raised in the past, and this will fuel them further.”\n\nKim Forrest, Chief Investment Officer, Bokeh Capital also sounded a note of caution. \"This sounds like Nvidia is investing in its largest customer. These arrangements can be beneficial for both parties. But there can be dangers as well. Being totally linked with each other can cause for short-sightedness and can make an entry point for other chip competitors to come into other AI companies and woo them,\" she said.\n\nMarketScreener quotes Rebecca Haw Allensworth, an antitrust professor at Vanderbilt Law School, who says there are concerns that Nvidia could favor OpenAI with better pricing or faster delivery times.\n\n\"They're financially interested in each other's success,” she said. “That creates an incentive for Nvidia to not sell chips to, or not sell chips on the same terms to, other competitors of OpenAI.\"\n\nAn Nvidia spokesperson denied this would be case, saying, \"We will continue to make every customer a top priority, with or without any equity stake.\"\n\nNvidia plans to invest up to $100 billion in OpenAI as part of data center buildout - YouTube Watch On",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/nvidia-gives-openai-usd100-billion-to-spend-mostly-on-nvidia-hardware-and-nvidia-share-price-goes-up-by-usd220-billion-why-am-i-not-surprised",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "(PR) HighPoint Technologies Introduces Rocket 7638D, Industry's First Hardware Architecture for GPU-Direct NVMe Storage",
      "content": "Revolutionary Hardware Architecture: The Rocket 7638D is the first PCIe Gen 5 switch adapter to provides the foundational hardware for a GPU-direct NVMe storage solution.\n\nDedicated Bandwidth for Maximum GPU Utilization: Our proven PCIe Switching Technology dynamically allocates 48 lanes of Gen 5 bandwidth, guaranteeing dedicated x16 pathways to both the GPU and NVMe storage. This eliminates the I/O bottleneck, ensuring your GPU is never starved for data.\n\nUncompromised CDFP-CopprLink Connectivity: Ensures reliable, high-bandwidth GPU-to-host data transfers, supporting NVIDIA's most powerful GPUs and external enclosures for flexible deployment.\n\nFlexible Dual-MCIO 8i Ports: The Rocket 7638D dual MCIO 8i ports are capable of supporting up to 16 NVMe drives for a staggering 2 Petabytes of storage. This high-density adapter is purpose-built to handle the largest AI datasets, from petabytes of scientific imaging data to vast training sets for large language models (LLMs).\n\nBroad Platform Compatibility: Works with Intel, AMD, and Arm platforms\n\nOptimized for AI Workflows: Provides a hardware platform for GPU Direct Storage (GDS), reducing CPU overhead, lowering latency, and accelerating data preprocessing.\n\nFRU (Field Replaceable Unit): VPD stored by each adapter enables service providers to easily procure replacements with the correct firmware/hardware combination.\n\nHighPoint Technologies, a leader in high-performance storage solutions, has announced the launch of the Rocket 7638D, a revolutionary PCIe Gen 5 switch adapter engineered to solve the most critical bottleneck in modern AI/ML workflows: data starvation. The adapter's groundbreaking hardware architecture provides a foundational platform for GPU-Direct NVMe storage, enabling NVIDIA GPUs to directly access massive datasets without the performance penalties of CPU bottlenecks. The Rocket 7638D is designed to help AI professionals maximize their return on investment by ensuring their GPUs are always at full utilization, accelerating model training, inference, and data preprocessing to unprecedented speeds.For decades, the path from storage to compute has been a bottleneck. Data has had to travel from an NVMe drive, through the host CPU, and into the GPU's memory—a slow, inefficient process that wastes valuable compute cycles. The Rocket 7638D shatters this conventional model. It is the first 48-lane Gen 5 PCIe switch adapter engineered with a dedicated x16 Gen 5 pathway for both an external GPU and NVMe storage from a single slot. This architecture creates a direct, peer-to-peer data channel that bypasses the host CPU entirely.The result is a transformative leap in performance. By eliminating latency and reducing CPU overhead, the Rocket 7638D ensures that precious GPU compute cycles are no longer wasted on I/O. HighPoint's innovative hardware architecture provides a direct data path that, when paired with a compatible third-party software solution, enables a full GPU Direct Storage (GDS) stack. For deep learning, this translates directly to faster epochs, reduced model training time, and a significant boost in inference throughput, providing a competitive edge for any data-intensive application.This ensures that powerful GPUs and other accelerators are not sitting idle, but are constantly processing data at their maximum potential, dramatically accelerating workflows and increasing overall system efficiency.Despite its advanced capabilities, the Rocket 7638D has been engineered to streamline installation, deployment and field service. The hardware is natively supported by all major operating system platforms, eliminating the need for additional software or complex driver installation. This plug-and-play functionality allows AI/ML, HPC, and Scientific Imaging professionals to quickly install the card and begin building a GPU-accelerated storage solution. For peace of mind, HighPoint's user-friendly MPT utility enables administrators to quickly view firmware information, monitor PCIe bus speed, and check the health of the adapter's switch chipset in real time.In essence, the Rocket 7638D is the missing link for any NVIDIA-accelerated workflow. It's innovative hardware architecture fundamentally changes the relationship between compute and storage. By unlocking the full potential of your GPU hardware and enabling the fastest possible data pipelines, the Rocket 7638D ensures your ROI is fully realized.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341324/highpoint-technologies-introduces-rocket-7638d-industrys-first-hardware-architecture-for-gpu-direct-nvme-storage",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Alibaba (BABA) Hits New High on $53-Billion AI Bet",
      "content": "We recently published 10 Stocks Crushing Wall Street, AI Stocks Dominate. Alibaba Group Holding Ltd. (NYSE:BABA) is one of the top performers on Tuesday.\n\nAlibaba Group soared to a new all-time high on Wednesday, as investors gobbled up shares after boosting its investments in artificial intelligence (AI) to 380 billion yuan ($53 billion) and partnering with Nvidia Corp. to support the program.\n\nIn intra-day trading, Alibaba Group Holding Ltd. (NYSE:BABA) climbed to its highest 52-week price of $180.16 before trimming gains to end the day just up by 8.19 percent at $176.44 apiece.\n\nAlibaba (BABA) Hits New High on $53-Billion AI Bet\n\nPieter Beens / Shutterstock.com\n\nAt an annual technology conference, Alibaba Group Holding Ltd. (NYSE:BABA) CEO Eddie Wu said that the company was vigorously advancing a three-year AI initiative, boosting the total investment to 380 billion yuan, in line with its strategic vision and anticipation of the artificial superintelligence era.\n\nAlibaba Group Holding Ltd. (NYSE:BABA) said it partnered with chip giant Nvidia Corp. for the expansion of global data centers and development of new AI products as it plans to make the sector a core priority alongside e-commerce.\n\nWu said that companies globally are spending $4 trillion over the next five years, and that Alibaba “needs to keep up.”\n\nWhile we acknowledge the potential of BABA as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/alibaba-baba-hits-high-53-142552772.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Wemade’s 7-Year Blockchain Journey Culminates in Global KRW Stablecoin Push",
      "content": "Wonil Suh, Executive Vice President of Wemade, represents Korea’s blockchain gaming evolution. His company launched its blockchain journey seven years ago with the establishment of WEMIX, becoming one of Korea’s most experienced Web3 enterprises. With over 1,000 employees dedicated to WEMIX-related operations globally, Wemade operates at unprecedented organizational scale in blockchain gaming.\n\nDuring Korea Blockchain Week’s main event, particularly after sessions featuring US participants including Donald Trump Jr., Suh appeared increasingly confident about stablecoin adoption. His conviction stems from Wemade’s practical experience managing millions of gaming transactions and developing comprehensive blockchain infrastructure. The executive envisions Korean Won stablecoins facilitating everything from K-content consumption to tourism payments worldwide.\n\nSponsored\n\nWhy did Wemade launch the stablecoin project, ‘Stable One’, as a gaming company?\n\n“Wemade initiated our blockchain business seven years ago in 2018, establishing us among Korea’s most experienced companies in this domain with our scale and focused commitment. It’s not that we recently started stablecoins because they’re hot or trendy—we’ve maintained this strategic direction consistently. As a gaming company, we recognized that blockchain technology offers substantial utility in gaming applications, and we’ve witnessed numerous successful implementations within our own gaming portfolio.\n\nWe’ve accumulated extensive knowledge through managing hundreds of millions of transactions from over 30 games supporting over 1 million monthly concurrent users. We’ve consistently believed this expertise shouldn’t remain proprietary but should benefit the broader industry. Stablecoins represents a pivotal opportunity in this regard. We didn’t merely study the technology—we developed practical applications with it. From this perspective, we possess significant value to contribute to the ecosystem.”\n\nRather than being a direct issuer, Wemade positions itself as a platform provider for stablecoins. Can you explain your partnership model and how you plan to build this consortium approach?\n\n“Rather than establishing our own proprietary stablecoin, we believe consortium participation would be more advantageous. As a technology partner, we aim to extensively leverage our existing technological capabilities. We will collaborate with various Korean enterprises, and as essentially a tech partner, we can create synergies with those in the banking and financial sectors that possess decades or centuries of institutional expertise in regulatory compliance and licensing frameworks.\n\nWe’re cultivating global partnerships—Chainalysis participated in our recent event, demonstrating our commitment to expanding these international alliances. Our strategy involves launching a testnet, inviting diverse partners to participate, going open-source, and targeting early next year for operational deployment with multiple strategic partners.”\n\nSponsored\n\nUpon announcing the Stable One, Wemade mentioned wanting overseas users to adopt the KRW stablecoin. What specific use cases do you envision – from cultural content consumption to tourism payments?\n\n“Korea is currently at a cultural peak, with extensive global exposure through travel, K-culture fandom, and Korean content consumption worldwide. These digital natives are broadly distributed globally. Instead of using foreign stablecoins for Korean cultural content, having a Korean stablecoin could serve as our foundation.\n\nFor companies and labels with artists and IPs with global fandom, when selling tickets or merchandise online—rather than pricing in dollars or euros—they could facilitate direct KRW transactions and remittances. Foreign tourists visiting Korea currently exchange currency at airports or local money changers, but if they could simply convert to digital KRW stablecoins upon arrival, using familiar payment apps for Korean transactions, this would eliminate traditional currency exchange inconvenience while supporting Korean businesses.”\n\nSponsored\n\nWhat is Wemade’s overarching global strategy, and how does the WEMIX Play platform fit into becoming a major gaming destination worldwide?\n\n“After launching MIR4 four years ago, we realized all content, especially games with user time investment and internal economies, would inevitably require blockchain integration. We determined we needed to create a platform—since this technology will be universally adopted, we should build excellent systems for smaller companies with limited resources to utilize, rather than having every company develop independently.\n\nEssentially, game developers won’t need to create a game launcher or payment system for each game they develop, so they can just focus on content creation and simply be onboarded to the platform. We envision WEMIX Play becoming a global gaming platform where all game companies—from Africa, India, Eastern Europe—would naturally list their games on our platform, alongside Apple, Google, and Steam. Currently featuring dozens of games, our long-term vision encompasses thousands, even hundreds of thousands of titles, all powered by our WEMIX blockchain infrastructure and utility token ecosystem.”\n\nHow do you see AI transforming the gaming industry, and how is Wemade integrating AI with blockchain technology? Can you tell us about your NVIDIA collaboration?\n\n“AI and gaming naturally complement each other, as do crypto and gaming. Across our 20-30 games currently in development through various studios, every single one leverages AI—whether for enhanced art creation or algorithmic development. We partner with NVIDIA rather than building everything in-house. While productivity improvements are obvious benefits, the transformative potential lies in AI fundamentally reshaping gameplay experiences. We integrate game tokenomics during development, weaving blockchain technology organically into the game fabric rather than adding it superficially. AI should similarly enable revolutionary gameplay—AI companions, skill-adaptive experiences, personalized strategic assistance. Combined with crypto and stablecoins, we foresee agentic AI facilitating autonomous agent-to-agent commerce within gaming ecosystems, marking a profound industry paradigm shift.”\n\nSponsored\n\nLooking ahead 5-10 years, how do you expect blockchain technology to reshape both gaming and finance? What role does Wemade want to play in that transformation?\n\n“I envision a future where AI enhances productivity, creating more leisure time and potentially universal basic income scenarios. People will have two experiential paths: expensive real-world experiences for the wealthy, or rich digital experiences for those with abundant time but limited resources.\n\nDigital worlds perfectly serve this latter demographic. Gaming extends beyond traditional gameplay—platforms like Roblox already represent metaverse experiences where commerce operates primarily through crypto. AI agents will facilitate these transactions, with stablecoins enabling seamless payments. When our children mature, this integrated AI-crypto-gaming ecosystem will seem completely natural. Wemade positions itself at the center of this major paradigm transformation.”\n\nGiven some regulatory challenges Wemade has faced in Korea, what message would you send to international investors who might have concerns about the Korean crypto landscape?\n\n“As one of Korea’s largest gaming companies with global reach, our combat strength is formidable. We’ve fought many battles, experienced setbacks, and developed extensive strategies. These challenges strengthen rather than weaken us. With over 1,000 employees dedicated to WEMIX-related work—unprecedented globally—we’ve built unmatched organizational capability. Having weathered these difficulties, we’re now positioned to deliver superior services. Korean companies possess tremendous potential that institutional investors and crypto holders should recognize and support.”",
      "source": "BeInCrypto",
      "url": "https://beincrypto.com/wemades-7-year-blockchain-journey-culminates-in-global-krw-stablecoin-push/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "North Korean Hackers Use New AkdoorTea Backdoor to Target Global Crypto Developers",
      "content": "The North Korea-linked threat actors associated with the Contagious Interview campaign have been attributed to a previously undocumented backdoor called AkdoorTea, along with tools like TsunamiKit and Tropidoor.\n\nSlovak cybersecurity firm ESET, which is tracking the activity under the name DeceptiveDevelopment, said the campaign targets software developers across all operating systems, Windows, Linux, and macOS, particularly those involved in cryptocurrency and Web3 projects. It's also referred to as DEV#POPPER, Famous Chollima, Gwisin Gang, Tenacious Pungsan, UNC5342, and Void Dokkaebi.\n\n\"DeceptiveDevelopment's toolset is mostly multi-platform and consists of initial obfuscated malicious scripts in Python and JavaScript, basic backdoors in Python and Go, and a dark web project in .NET,\" ESET researchers Peter Kálnai and Matěj Havránek said in a report shared with The Hacker News.\n\nThe campaign essentially involves the impersonated recruiters offering what appear to be lucrative job roles over platforms like LinkedIn, Upwork, Freelancer, and Crypto Jobs List. After initial outreach, should the prospective target express interest in the opportunity, they are either asked to complete a video assessment by clicking on a link or a coding exercise.\n\nThe programming assignment requires them to clone projects hosted on GitHub, which silently install malware. On the other hand, websites explicitly set up for undertaking the so-called video assessment display non-existent errors related to camera or microphone access being blocked, and urge them to follow ClickFix-style instructions to rectify the problem by either launching the command prompt or the Terminal app, depending on the operating system used.\n\nIrrespective of the method employed, the attacks have been generally found to deliver several pieces of malware such as BeaverTail, InvisibleFerret, OtterCookie, GolangGhost (aka FlexibleFerret or WeaselStore), and PylangGhost.\n\n\"WeaselStore's functionality is quite similar to both BeaverTail and InvisibleFerret, with the main focus being exfiltration of sensitive data from browsers and cryptocurrency wallets,\" ESET said. \"Once the data has been exfiltrated, WeaselStore, unlike traditional infostealers, continues to communicate with its C&C [command-and-control] server, serving as a RAT capable of executing various commands.\"\n\nAlso deployed as part of these infection sequences are TsunamiKit and Tropidoor, the first of which is a malware toolkit delivered by InvisibleFerret and is designed for information and cryptocurrency theft. The use of TsunamiKit was first discovered in November 2024.\n\nThe toolkit comprises several components, the starting point being the initial stage TsunamiLoader that triggers the execution of an injector (TsunamiInjector), which, in turn, drops TsunamiInstaller and TsunamiHardener.\n\nWhile TsunamiInstaller acts as a dropper for TsunamiClientInstaller, which then downloads and executes TsunamiClient, TsunamiHardener is responsible for setting up persistence for TsunamiClient, as well as configuring Microsoft Defender exclusions. TsunamiClient is the core module that incorporates a .NET spyware and drops cryptocurrency miners like XMRig and NBMiner.\n\nIt's believed that TsunamiKit is likely a modification of a dark web project rather than a native creation of the threat actor, given that samples related to the toolkit have been uncovered dating back to December 2021, predating the onset of Contagious Interview, which is believed to have commenced sometime in late 2022.\n\nThe BeaverTail stealer and downloader has also been found to act as a distribution vehicle for another malware known as Tropidoor that, according to ASEC, overlaps with a Lazarus Group tool called LightlessCan. ESET said it found evidence of Tropidoor artifacts uploaded to VirusTotal from Kenya, Colombia, and Canada, adding the malware also shares \"large portions of code\" with PostNapTea, a malware used by the threat actor against South Korean targets in 2022.\n\nPostNapTea supports commands for configuration updates, file manipulation and screen capturing, file system management, process management, and running custom versions of Windows commands like whoami, netstat, tracert, lookup, ipconfig, and systeminfo, among others, for improved stealth – a feature also present in LightlessCan.\n\n\"Tropidoor is the most sophisticated payload yet linked to the DeceptiveDevelopment group, probably because it is based on malware developed by the more technically advanced threat actors under the Lazarus umbrella,\" ESET said.\n\nExecution chain of WeaselStore\n\nThe latest addition to the threat actor's arsenal is a remote access trojan dubbed AkdoorTea that's delivered by means of a Windows batch script. The script downloads a ZIP file (\"nvidiaRelease.zip\") and executes a Visual Basic Script present in it, which then proceeds to launch BeaverTail and AkdoorTea payloads also contained in the archive.\n\nIt's worth pointing out that the campaign has leveraged NVIDIA-themed driver updates in the past as part of ClickFix attacks to address supposed camera or microphone issues when providing the video assessments, indicating that this approach is being used to propagate AkdoorTea.\n\nAkdoorTea gets its name from the fact that it shares commonalities with Akdoor, which is described as a variant of the NukeSped (aka Manuscrypt) implant – further reinforcing Contagious Interview's connections to the larger Lazarus Group umbrella.\n\n\"DeceptiveDevelopment's TTPs illustrate a more distributed, volume-driven model of its operations. Despite often lacking technical sophistication, the group compensates through scale and creative social engineering,\" ESET said.\n\n\"Its campaigns demonstrate a pragmatic approach, exploiting open-source tooling, reusing available dark web projects, adapting malware probably rented from other North Korea-aligned groups, and leveraging human vulnerabilities through fake job offers and interview platforms.\"\n\nContagious Interview doesn't operate in silo, as it has been also found to share some level of overlaps with Pyongyang's fraudulent IT worker scheme (aka WageMole), with Zscaler noting that the intelligence gleaned from the former is used by North Korean actors to secure jobs at those companies using stolen identities and fabricating synthetic personas. The IT worker threat is believed to have been ongoing since 2017.\n\nConnection between Contagious Interview and WageMole\n\nCybersecurity company Trellix, in a report published this week, said it uncovered an instance of a North Korean IT worker employment fraud targeting a U.S. healthcare company, where an individual using the name \"Kyle Lankford\" applied for a Principal Software Engineer position.\n\nWhile the job applicant did not raise any red flags during the early stages of the hiring process, Trellix said it was able to correlate their email addresses with known North Korea IT worker indicators. Further analysis of the email exchanges and background checks identified the candidate as a likely North Korean operative, it added.\n\n\"The activities of North Korean IT workers constitute a hybrid threat,\" ESET noted. \"This fraud-for-hire scheme combines classical criminal operations, such as identity theft and synthetic identity fraud, with digital tools, which classify it as both a traditional crime and a cybercrime (or e-crime).\"",
      "source": "Internet",
      "url": "https://thehackernews.com/2025/09/north-korean-hackers-use-new-akdoortea.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "NVIDIA (NASDAQ:NVDA) Earns Buy Rating from Rosenblatt Securities",
      "content": "NVIDIA (NASDAQ:NVDA – Get Free Report)‘s stock had its “buy” rating reissued by research analysts at Rosenblatt Securities in a research report issued to clients and investors on Tuesday,Benzinga reports. They presently have a $215.00 target price on the computer hardware maker’s stock. Rosenblatt Securities’ price objective points to a potential upside of 21.49% from the company’s current price.\n\nA number of other brokerages have also recently weighed in on NVDA. New Street Research increased their target price on shares of NVIDIA from $200.00 to $235.00 and gave the stock a “buy” rating in a report on Friday, September 12th. Summit Insights upgraded shares of NVIDIA from a “hold” rating to a “buy” rating in a research note on Thursday, May 29th. Evercore ISI increased their price objective on shares of NVIDIA from $190.00 to $214.00 and gave the stock an “outperform” rating in a research note on Friday, August 22nd. Phillip Securities upgraded NVIDIA from a “moderate buy” rating to a “strong-buy” rating in a research report on Monday, July 14th. Finally, Needham & Company LLC reiterated a “buy” rating and set a $200.00 price target on shares of NVIDIA in a research report on Thursday, August 28th. Four investment analysts have rated the stock with a Strong Buy rating, thirty-six have issued a Buy rating, four have given a Hold rating and one has assigned a Sell rating to the company’s stock. Based on data from MarketBeat, the stock has an average rating of “Moderate Buy” and a consensus price target of $208.76.\n\nGet NVIDIA alerts:\n\nGet Our Latest Stock Analysis on NVDA\n\nNVIDIA Trading Down 0.8%\n\nShares of NASDAQ NVDA opened at $176.97 on Tuesday. The stock’s 50 day moving average price is $176.39 and its two-hundred day moving average price is $144.81. NVIDIA has a 52-week low of $86.62 and a 52-week high of $184.55. The stock has a market capitalization of $4.30 trillion, a P/E ratio of 50.42, a PEG ratio of 1.29 and a beta of 2.10. The company has a quick ratio of 3.60, a current ratio of 4.21 and a debt-to-equity ratio of 0.08.\n\nNVIDIA (NASDAQ:NVDA – Get Free Report) last posted its quarterly earnings results on Wednesday, August 27th. The computer hardware maker reported $1.05 earnings per share (EPS) for the quarter, beating the consensus estimate of $1.01 by $0.04. The business had revenue of $46.74 billion for the quarter, compared to analyst estimates of $45.65 billion. NVIDIA had a return on equity of 101.74% and a net margin of 52.41%.The business’s revenue was up 55.6% compared to the same quarter last year. During the same period in the prior year, the company posted $0.68 EPS. NVIDIA has set its Q3 2026 guidance at EPS. On average, analysts anticipate that NVIDIA will post 2.77 earnings per share for the current fiscal year.\n\nInsider Activity\n\nIn other news, Director Mark A. Stevens sold 350,000 shares of NVIDIA stock in a transaction on Friday, September 19th. The stock was sold at an average price of $176.39, for a total transaction of $61,736,500.00. Following the transaction, the director directly owned 7,399,803 shares in the company, valued at approximately $1,305,251,251.17. This trade represents a 4.52% decrease in their position. The sale was disclosed in a document filed with the Securities & Exchange Commission, which can be accessed through this link. Also, CEO Jen Hsun Huang sold 75,000 shares of NVIDIA stock in a transaction dated Wednesday, July 9th. The stock was sold at an average price of $163.11, for a total value of $12,233,250.00. Following the transaction, the chief executive officer directly owned 74,873,225 shares in the company, valued at approximately $12,212,571,729.75. The trade was a 0.10% decrease in their ownership of the stock. The disclosure for this sale can be found here. In the last ninety days, insiders have sold 4,302,450 shares of company stock worth $740,755,443. 4.17% of the stock is owned by company insiders.\n\nHedge Funds Weigh In On NVIDIA\n\nSeveral hedge funds have recently made changes to their positions in NVDA. Harbor Asset Planning Inc. acquired a new position in shares of NVIDIA in the 2nd quarter worth $28,000. Winnow Wealth LLC acquired a new position in shares of NVIDIA in the 2nd quarter worth $32,000. Longfellow Investment Management Co. LLC increased its stake in NVIDIA by 47.9% in the 2nd quarter. Longfellow Investment Management Co. LLC now owns 207 shares of the computer hardware maker’s stock worth $33,000 after purchasing an additional 67 shares in the last quarter. Spurstone Advisory Services LLC purchased a new position in NVIDIA in the 2nd quarter worth about $40,000. Finally, EDENTREE ASSET MANAGEMENT Ltd purchased a new position in NVIDIA in the 2nd quarter worth about $54,000. Institutional investors and hedge funds own 65.27% of the company’s stock.\n\nAbout NVIDIA\n\n(Get Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nSee Also\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/25/nvidia-nasdaqnvda-earns-buy-rating-from-rosenblatt-securities/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Intel Seeks Assistance From Apple, Others in Desperate Bid to Reclaim Chip Throne",
      "content": null,
      "source": "International Business Times",
      "url": "https://www.ibtimes.com/intel-seeks-assistance-apple-others-desperate-bid-reclaim-chip-throne-3784564",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "NVIDIA Corporation (NVDA) To Invest $100 Billion In OpenAI, Linking Two AI Giants",
      "content": "NVIDIA Corporation (NASDAQ:NVDA) is among the Renaissance Technologies Portfolio: 10 Biggest Stocks. On September 22, the company announced to invest up to $100 billion in OpenAI and provide it with data center chips.\n\nNVIDIA Corporation (NVDA) To Invest $100 Billion In OpenAI, Linking Two AI Giants\n\nThis partnership between two major players in the global AI race underscores the growing overlap of interests between tech giants developing advanced systems.\n\nAs part of the agreement, NVIDIA Corporation (NASDAQ:NVDA) will get a financial stake in OpenAI, which is also an important customer, while the investment will provide the latter with cash and the access it requires to acquire chips that are vital to maintaining its dominance in a fiercely competitive landscape.\n\nThe deal will involve two separate transactions, Reuters reported, citing a person familiar with OpenAI. After the agreement is finalized, NVIDIA Corporation (NASDAQ:NVDA) will invest in OpenAI’s non-voting shares, and then OpenAI can use the funds to buy the chips, said the report.\n\nThe two firms signed a letter of intent for the deployment of at least 10 gigawatts of NVDA systems for OpenAI, with the aim of further finalizing details of the strategic partnership in the coming weeks. NVIDIA Corporation (NASDAQ:NVDA) will start delivering the hardware in the second half of 2026.\n\nFollowing the news, several analysts welcomed the deal as a positive development for NVIDIA Corporation (NASDAQ:NVDA), but also expressed concerns that some of the investment dollars might be coming back to the company in the form of chip purchases.\n\nWhile we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 12 Best Defense Stocks to Buy Right Now and 15 Stocks ChatGPT Predicts Could Make You Wealthy in 5 Years.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-corporation-nvda-invest-100-144520918.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "AI Update, September 26, 2025: AI News and Views From the Past Week",
      "content": "Catch up on select AI news and developments from the past week or so:\n\nOpenAI expands Stargate project and explores debt financing for chip supply. OpenAI has widened the scope of its $500 billion Stargate infrastructure project, initially announced for AI chip and data center buildout, to cover nearly all its compute initiatives. The company confirmed partnerships with Oracle, SoftBank, and Nvidia, with plans for five new US data centers. To meet soaring demand for compute power, OpenAI is turning to debt financing and chip leasing, supported by Nvidia's $100 billion investment. Microsoft projects are excluded from Stargate, reflecting a diversified partnership approach. Importance for marketers: Increased compute capacity signals more powerful AI services, expanding capabilities for generative AI applications marketers rely on.\n\nAlibaba unveils trillion-parameter AI model and Nvidia partnership. Alibaba announced a partnership with Nvidia, plans for global data centers, and the launch of its largest AI model, Qwen3-Max, with over one trillion parameters. The model boasts strong performance in code generation and autonomous agents. New data centers will expand into Brazil, France, the Netherlands, and other countries, building on Alibaba's 91 facilities worldwide. The company also unveiled multimodal tools such as Qwen3-Omni, designed for immersive applications. Importance for marketers: Alibaba's AI advancements raise the stakes in global competition, offering powerful tools and infrastructure that could influence future digital marketing and commerce platforms.\n\nDatabricks partners with OpenAI to deliver AI models to enterprises. Databricks will integrate OpenAI's flagship GPT-5 and other models into its platform, including Agent Bricks, which enables companies to build and scale AI applications. The partnership is projected to generate $100 million in revenue. OpenAI gains broader enterprise reach beyond Microsoft Azure, while Databricks strengthens its position against rival Snowflake. Importance for marketers: Direct integration of OpenAI models into enterprise data platforms simplifies deploying AI-driven analytics and personalization, enhancing marketing intelligence and customer engagement strategies.\n\nGoogle launches Data Commons MCP server for AI training and grounding. Google unveiled the Model Context Protocol (MCP) server for its Data Commons, making real-world datasets—from census figures to climate statistics—accessible through natural language. This move aims to reduce AI hallucinations by grounding outputs in structured, verifiable information. Developers can integrate this into AI systems, with open access via Gemini CLI, PyPI, and GitHub. A partnership with the ONE Campaign showcases early use in surfacing African economic and health data. Importance for marketers: Access to trusted, real-world data enhances the accuracy of AI-driven insights, critical for campaign planning, market research, and predictive analytics.\n\nMicrosoft adds Anthropic models to Copilot for enterprise users. Microsoft will integrate Anthropic's Claude Opus 4.1 and Sonnet 4 models into Copilot, alongside OpenAI's systems. This diversification follows earlier deals to use Anthropic's AI in Office 365 apps. Opus supports deep reasoning, while Sonnet focuses on large-scale data processing and content creation. Enterprise users will be able to select the model suited to their task. Importance for marketers: Expanded model choices in Copilot enhance productivity and creativity, providing marketers with tailored AI tools for research, content generation, and campaign planning.\n\nGlobal experts call for 'AI red lines' at UN summit. At the UN General Assembly, more than 200 Nobel laureates and AI experts, along with 70 organizations, urged creation of enforceable \"AI red lines\" by 2026. The letter highlighted risks of deception, replication, and bioweapon instructions, though specifics were vague. Notably, figures such as Geoffrey Hinton and Gary Marcus signed despite differing views on AI. UC Berkeley's Stuart Russell provided concrete red lines in prior work, emphasizing safety-first design. Importance for marketers: Regulatory frameworks around AI could shape how brands deploy AI responsibly, with compliance influencing data usage, content generation, and advertising standards.\n\nLuma AI launches Ray3, a reasoning-capable video model. Luma AI introduced Ray3, the world's first reasoning video model, capable of multimodal reasoning and generating 16-bit HDR video in EXR format. Integrated into Adobe Firefly, Ray3 enables professional-grade outputs with improved instruction following and temporal coherence. Agencies including Dentsu Digital, HUMAIN Create, and Monks are early partners, deploying Ray3 for advertising, film, and gaming. Draft Mode allows 20x faster iteration. Importance for marketers: Ray3's ability to generate production-ready, high-fidelity video accelerates campaign development, reducing costs and expanding creative possibilities for advertising and branded storytelling.\n\nAmazon debuts AI 'creative partner' for advertisers. Amazon launched a conversational AI assistant in beta on its Creative Studio portal, branded as a \"creative partner\" for marketers. The agent uses Amazon's retail data to support tasks from research and brainstorming to producing ads for Amazon DSP, Sponsored Display, and Sponsored Brand Video. Beta testers, including Nestlé Health Science, praised its workflow impact. Importance for marketers: Amazon's move democratizes high-quality campaign creation, offering smaller brands affordable AI-powered creative resources while deepening advertiser reliance on Amazon Ads infrastructure.\n\nOpenAI launches ChatGPT Pulse for personalized daily insights. OpenAI introduced ChatGPT Pulse, a Pro-user feature that personalizes daily updates using chat history, email, and calendar data. Pulse generates visual cards with tailored information such as event prep, health routines, and news, aiming to shift ChatGPT from reactive to proactive assistance. Privacy safeguards mirror standard ChatGPT policies, with feedback loops limited to individual users. Importance for marketers: Pulse highlights how personalization features could influence consumer engagement, shaping expectations for AI-driven marketing and raising data-use transparency issues.\n\nMusk's xAI sues OpenAI over alleged trade secret theft. Elon Musk's startup xAI has filed a lawsuit against OpenAI, alleging it hired away employees to gain access to trade secrets tied to xAI's Grok chatbot and data center strategies. The case follows ongoing legal disputes between Musk, OpenAI, and Apple. xAI accuses OpenAI of inducing breaches of confidentiality agreements. Importance for marketers: The escalating legal battle underscores fierce competition in AI development, potentially affecting innovation cycles and the trustworthiness of AI providers in marketing applications.\n\nGoogle rolls out AI Search Live to all US users. Google launched AI-powered Search Live across Android and iOS in the US, enabling users to ask questions conversationally while pointing their camera at objects. The tool combines AI responses with traditional web links, enhancing utility for everyday problem-solving. Importance for marketers: Search Live shifts search behavior toward conversational, visual-first interactions, pushing brands to optimize for multimodal discovery and ensuring their content remains visible in AI-enhanced search experiences.",
      "source": "MarketingProfs.com",
      "url": "https://www.marketingprofs.com/opinions/2025/53764/ai-update-september-26-2025-ai-news-and-views-from-the-past-week",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "SK Hynix reportedly to begin 1c GDDR7 production in 2025, eyeing Tesla and Nvidia orders",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250926PD237/sk-hynix-production-nvidia-tesla-dram.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "2025.39: The YouTube Juggernaut",
      "content": "This Week in Stratechery\n\n(Photo by Kevin Mazur/Getty Images for Made on YouTube 2025)\n\nWelcome back to This Week in Stratechery!\n\nAs a reminder, each week, every Friday, we’re sending out this overview of content in the Stratechery bundle; highlighted links are free for everyone. Additionally, you have complete control over what we send to you. If you don’t want to receive This Week in Stratechery emails (there is no podcast), please uncheck the box in your delivery settings.\n\nOn that note, here were a few of our favorites this week.\n\nThe YouTube Juggernaut. Maybe the most surprising thing about YouTube is how a service can be so dominant, and yet fly so completely under the radar. That has a lot of implications, including on my analysis: in The YouTube Tip of the Google Spear I look at the history of user-generated content to explain why video tends to be a bigger business than text, which means that YouTube, powered by Google DeepMind, has the potential to win in consumer AI. Google, though, has been about potential, not products; that’s why some of the new features at last week’s Youtube event were such a big deal. — Ben Thompson\n\n\n\n\n\nWhat Does an Nvidia-Intel Partnership Mean? Once upon a time Nvidia saw Intel as an existential threat, but that was almost thirty years ago. Today, as Intel confronts its own spectrum of existential threats, Nvidia is following the U.S. government’s lead and throwing the company a $5 billion life preserver; Monday’s Daily Update took a closer look at the details of the partnership. In short, the deal will help Intel’s cash flow and long-term credibility with potential chip customers, both of which Intel desperately needs, but to be clear, Nvidia is not going to be fabbing any of its chips at Intel foundries, which America desperately needs to succeed. Instead, Nvidia found a way to position itself as an Intel savior with a design deal that assumes none of the risk of actually fabbing chips at Intel, uses Intel’s customer base to increase Nvidia’s access to the enterprise market, makes them an even more formidable foil to AMD, and likely dissuades Intel from competing in the GPU space. President Trump called Jensen Huang “a smart cookie” earlier this year, and this deal supports the claim. — Andrew Sharp\n\n\n\nLet’s Talk About Sushi Robots. For anyone who needs something completely different, I’m here to endorse 20 minutes on the history of industrialized nigiri production. The latest from Jon at Asianometry focuses on the rise of sushi robotics in 1980s Japan, but also traces the origins of sushi and the art of forming the shari-dama (“rice jewel”), which took chefs 4 to 5 years to master, after which chefs could make 300-350 rice pieces per hour. That is, until the robots arrived: In the 1970s a company called Suzumo began filming chef hand movements and attempting mechanical replication, and by the ’80s they had succeeded. Today, what was dubbed a “sushi robot” can make up to 1,200 rice bases per hour, allowing sushi chefs to reallocate their energy to plating and fish preparation, reducing the cost of production overall, and allowing sushi businesses to scale all over the world. If you’re interested, Jon’s video is also available to Stratechery subscribers as a podcast, which you can download here, right before you start making plans to find some sushi this weekend. — AS\n\nStratechery Articles and Updates\n\nDithering with Ben Thompson and Daring Fireball’s John Gruber\n\nAsianometry with Jon Yu\n\nSharp China with Andrew Sharp and Sinocism’s Bill Bishop\n\nGreatest of All Talk with Andrew Sharp and WaPo’s Ben Golliver\n\nSharp Tech with Andrew Sharp and Ben Thompson\n\nThis week’s Sharp Tech video is on whether Apple is changing the world.",
      "source": "Stratechery.com",
      "url": "https://stratechery.com/2025/the-youtube-juggernaut/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Nvidia makes surprising move into British AI company",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/investing/nvidia-makes-surprising-move-into-british-ai-company",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "AI Investment Is Starting to Look Like a Slush Fund",
      "content": "Photo-Illustration: Intelligencer; Photo: Getty Images\n\nNo two companies are as important to the recent AI boom as OpenAI and Nvidia. OpenAI’s journey from research lab to chatbot juggernaut reoriented the entire tech industry around the thesis that large-language models will change everything. Nvidia’s chips have been almost synonymous with scaling, on which OpenAI and others are collectively spending hundreds of billions of dollars. For the last few years, the companies’ fortunes have been aligned, and their relationship has been, for the most part, an obvious one: OpenAI, which has become one of the biggest start-ups in the world, is a major customer for Nvidia, which has become the largest public company in the world.\n\nIn 2025, their twin trajectories have left much of the rest of the economy behind, and their stated ambitions — necessary to keep the momentum going — have become extreme. In a recent blog post, Sam Altman said his company wanted to “create a factory that can produce a gigawatt of new AI infrastructure every week” to “maybe” be able to “figure out how to cure cancer” or “provide customized tutoring to every student on Earth.” OpenAI hasn’t had any trouble raising money so far, but when your investment projections start crossing into the trillions, financing starts to get tricky, particularly if you aren’t a company like Google or Meta, with an existing business throwing off tens of billions of dollars a year. Which might help explain this:\n\nOpenAI and NVIDIA today announced a letter of intent for a landmark strategic partnership to deploy at least 10 gigawatts of NVIDIA systems for OpenAI’s next-generation AI infrastructure to train and run its next generation of models on the path to deploying superintelligence. To support this deployment including data center and power capacity, NVIDIA intends to invest up to $100 billion in OpenAI as the new NVIDIA systems are deployed.\n\n\n\n\n\nEmphasis mine! The issue of circular financing in the AI world has been bubbling up for a while. As the Information reported in May, Nvidia has been engineering disorienting deals with customers for a while, most obviously with a company called Coreweave, which rents compute — basically, access to Nvidia hardware — to AI firms:\n\nThe chip giant invested $100 million in [Coreweave] in early 2023. It funneled hundreds of thousands of high-end graphics processing units to CoreWeave. And it agreed to rent back its chips from CoreWeave through August 2027.\n\nIn related news, just this week, Coreweave announced it had “expanded its partnership with OpenAI in a new deal worth up to $6.5 billion, bringing the total value of their agreements to $22.4 billion.” These announcements aren’t exactly attempts to obfuscate what’s going on here — “NVIDIA intends to invest … as the new NVIDIA systems are deployed” — but it’s worth stating even more plainly what’s happening here: Nvidia is investing money in one of its largest customers, which will use some of that money to buy or lease capacity from Nvidia. On Tuesday, we got a little more insight into how that would actually happen. OpenAI, Oracle (a cloud provider that depends on Nvidia), and Softbank (a major investor in Nvidia and OpenAI) fleshed out plans to build out more data centers, which would one day be full of Nvidia hardware paid for or leased by … OpenAI.\n\nIf you’re a layperson, this probably sounds a bit weird. Maybe our friends in finance can explain a hidden logic here? Rich Privorotsky of Goldman Sachs attempts to summarize the arrangement: “Nvidia invests up to $100bn for non-voting shares, and OpenAI uses the cash to buy Nvidia chips, with a plan to deploy what could be at least 10GW of Nvidia systems.” It is what it looks like, in other words: a small group of large companies handing money back and forth.\n\nWith a number of caveats — every cycle is different, and the earnings multiples aren’t as crazy yet — he also draws a parallel to the late 90s, which have been coming up a lot lately. “Vendor financing was a feature of that era, when the telecom equipment makers (Cisco, Lucent, Nortel, etc.) extended loans, equity investments, or credit guarantees to their customers who then used the cash/credit to buy back the equipment,” he writes. Indeed, vendor financing features prominently in tech-bubble postmortems. In 2002, Newsweek explained the strange role they played at the tail end of the ’90s tech-investment boom:\n\nSwept up in the free-money spirit of the time, they were financing not only the customers’ purchase of their wares — the switches, routers and other nuts and bolts of the Internet — but the growth of the customers’ businesses, too. The standard practice of vendor financing thus became another wretched bubble excess: as if Ford were loaning customers money to buy cars — and boats, jewels and houses, too. “Vendor financing was the sickest sign of how things spun out of control,” says Tero Kuittinen, technology adviser to Finnish investment bank Opstock in Helsinki.\n\n\n\nThe parallels are obvious — or, at least, would look extremely obvious if the AI industry’s fortunes turned — but they’re not determinative. During the telecom buildout, vendor financing surged at a particular time. “Vendor-financing deals account for a relatively small fraction of the total $1 trillion in debt held by telecom carriers worldwide,” Newsweek noted at the time, but investment continued well after the early 2000 market collapse “wiped out the silliest ideas for pet, toy and trinket Web sites,” on the thesis that “dot-coms might be dead, but the Internet itself would thrive,” a perfectly reasonable argument if timing doesn’t matter, which of course it does, quite a bit. Last month, Kuittinen argued that this time, things really are different, but not necessarily in a good way:\n\nThe fascinating thing about AI bubble popping is that it’s not gonna play out like Lucent in 2001. Because this crew does not believe in free markets. They’re gonna try to prop up this thing like Soviet television industry in 1980’s. Tax payer money is gonna FLOW. — Tero Kuittinen (@teroterotero) August 21, 2025\n\nThe constellation of companies raising, spending, and sharing money on the broad technological and ideological project that is artificial intelligence in the 2020s is betting that, given enough resources, they can build the most profitable and powerful companies of all time, and that early concerns over profitability and circular financing will, in hindsight, seem blinkered and silly. (Or, according to Peter Thiel, like complicity in the summoning of the Antichrist.) In the process of trying, the industry is willing to drift into a strange and potentially risky arrangement — although some of the implied risk might be mitigated, as Alphaville mockingly points out, by vagueness and lack of binding obligations — which, in any case, given the potential upside, investors still seem comfortable with for now: a hypercapitalized financial polycule in which everyone is everyone’s investor, partner, vendor, and customer.",
      "source": "New York Magazine",
      "url": "http://nymag.com/intelligencer/article/ai-investment-is-starting-to-look-like-a-slush-fund.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "NVIDIA Audio2Face: nuovo strumento per l’animazione facciale AI open source",
      "content": "Un nuovo scenario si apre per la creazione di animazioni facciali 3D: da oggi, la generazione automatica di espressioni realistiche a partire dall’audio non è più appannaggio esclusivo dei grandi studi.\n\nCon il rilascio in open source della tecnologia Audio2Face, NVIDIA compie un passo decisivo verso la democratizzazione di strumenti avanzati, mettendo a disposizione di sviluppatori, artisti e ricercatori un sistema capace di tradurre la voce in movimenti facciali dettagliati e credibili con un semplice clic.\n\nLa vera forza di Audio2Face risiede nella sua capacità di analizzare le sfumature della voce – dai fonemi all’intonazione – per generare dati di animazione facciale immediatamente applicabili a qualsiasi modello 3D. Non si tratta solo di una tecnologia all’avanguardia, ma di un intero ecosistema: il pacchetto rilasciato comprende uno SDK completo, plugin specifici per Autodesk Maya e Unreal Engine 5, oltre a un framework dedicato all’addestramento di modelli personalizzati. Questi strumenti permettono di integrare facilmente la soluzione nei flussi di lavoro già consolidati nei settori della produzione digitale, dell’intrattenimento e della ricerca.\n\nNVIDIA Audio2Face è un salto di qualità notevole nell’animazione 3D\n\nUno degli elementi più apprezzati della distribuzione open source è la presenza di modelli pre-addestrati. Questi spaziano da reti di regressione, fondamentali per una sincronizzazione precisa delle labbra (lip sync), fino ai più sofisticati modelli diffusion che assicurano un realismo senza precedenti nei movimenti del volto. A completare il quadro, la suite include anche sistemi Audio2Emotion, progettati per dedurre le emozioni trasmesse dal parlato e tradurle in espressioni facciali autentiche. Tali asset consentono anche a team con risorse limitate di personalizzare le animazioni, adattandole a lingue diverse o a stili vocali peculiari, senza la necessità di partire da zero.\n\nL’apertura di NVIDIA segna una svolta epocale, offrendo a sviluppatori indipendenti, piccole aziende e laboratori universitari la possibilità di accedere a strumenti di alto livello fino a ieri riservati ai grandi player del settore. Il vantaggio è duplice: da un lato, si riducono sensibilmente i costi e i tempi legati all’animazione manuale; dall’altro, si favorisce l’innovazione grazie alla possibilità di sperimentare e ottimizzare i modelli secondo le esigenze specifiche di ciascun progetto.\n\nLa validità della soluzione è già comprovata da casi d’uso concreti nel mondo videoludico. Ad esempio, The Farm 51 ha adottato Audio2Face per la realizzazione delle animazioni facciali in Chernobylite 2, mentre Survios lo ha integrato nel titolo Alien: Rogue Incursion Evolved Edition, ottenendo un notevole risparmio nei processi di animazione manuale e un incremento della qualità espressiva dei personaggi digitali.\n\nDal punto di vista tecnico, la tecnologia offre una versatilità senza pari: supporta sia il rendering offline per la produzione di contenuti pre-renderizzati, sia l’elaborazione in tempo reale per personaggi interattivi. Questo la rende ideale non solo per videogiochi e film, ma anche per applicazioni social e ambienti metaverso, dove la credibilità delle espressioni facciali rappresenta un elemento cruciale per l’esperienza utente.\n\nNon mancano, tuttavia, interrogativi di natura etica. L’accessibilità della tecnologia apre infatti la porta a potenziali abusi, come la creazione di deepfake o la riproduzione non autorizzata di identità vocali. La comunità di sviluppatori, coordinata tramite un canale Discord dedicato, sta già lavorando all’elaborazione di linee guida e strumenti per il tracciamento dell’origine dei contenuti, al fine di promuovere un utilizzo responsabile e trasparente.",
      "source": "Ilsoftware.it",
      "url": "https://www.ilsoftware.it/nvidia-audio2face-nuovo-strumento-per-lanimazione-facciale-ai-open-source/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "20VC + SaaStr is Back!! NVIDIA’s $100B OpenAI Investment, H-1B’s $100K Fee Impact on Startups, and Is “Triple Triple Double Double” Really Dead?",
      "content": "20VC + SaaStr is Back!! NVIDIA’s $100B OpenAI Investment, H-1B’s $100K Fee Impact on Startups, and Is “Triple Triple Double Double” Really Dead?\n\nHarry, Rory and Jason are back!\n\nWe’re witnessing an unprecedented capital concentration in AI with NVIDIA’s $100B OpenAI investment creating a fascinating circular money machine, while new H-1B visa fees threaten startup talent acquisition and the venture funding landscape shifts dramatically toward mega-rounds for a tiny number of companies. The era of “founder friendly” has become somewhat hollow rhetoric, and traditional B2B growth metrics like “triple triple double double” are becoming irrelevant as the market polarizes between AI unicorns and fundamentals-driven businesses.\n\nKey Numbers That Matter:\n\n75% of 2025 VC dollars went to just 19 companies\n\nNVIDIA’s $4.5T market cap relies on only 6 customers for 83% of revenue\n\nNew H-1B visa fees of $100K will impact 440,000 annual applications\n\nNavan filing for IPO at $8B valuation with $613M revenue, 32% growth\n\nThe $100B AI Money Machine: When Six Customers Drive a $4.5T Market Cap\n\nNVIDIA’s massive investment in OpenAI represents more than just capital deployment—it’s the creation of what could be an infinite money printing loop. OpenAI commits $300B to Oracle, Oracle buys NVIDIA chips, and NVIDIA invests back into OpenAI. As one observer noted: “Sam’s gonna get to make the bet he wants to make which is apply infinite amount of capital and see how long these scaling laws last.”\n\nThe most striking aspect? NVIDIA, now the world’s largest company by market cap at $4.5 trillion, has only six meaningful customers accounting for 83% of revenue. Compare this to Apple’s 2 billion customers or Microsoft’s hundreds of thousands of enterprise clients. It’s “this really weird dynamic where you’ve got this company with only six customers, but the good news is all six of them are determined to spend themselves into oblivion to win the prize.”\n\nThe Scaling Laws Gamble\n\nSam Altman’s recent comments suggest this is just the beginning: “We need three orders of magnitude more compute than this.” The market is essentially allowing OpenAI to test whether massive capital can break through current AI limitations. Whether the marginal $300 billion will earn a return on capital remains questionable, but as Rory put it: “We will find out because no one’s going to call timeout along the way.”\n\nThe H-1B Shock: $100K Fee Creates New Startup Reality\n\nThe new $100,000 fee for H-1B visas represents a significant shift for the startup ecosystem. With 440,000 applications generating $19-120 billion in GDP annually, this policy change will have material impact on early-stage companies.\n\n“Anyone that has been doing this for a while that isn’t just three kids working 24/7 in SF has had H-1B folks on their team,” noted one investor. “My first startup wouldn’t have been possible without H-1B—at least on its surface—I had two on my first team of 10.” notes Jason.\n\nWhile larger tech companies will simply absorb the cost, startups face a more complex reality. The workaround? Most founders are now pursuing O-1 visas, though these come with their own complications and ongoing maintenance requirements.\n\nVenture Capital’s Great Concentration: 75% of Dollars to 19 Companies\n\nThe venture landscape has fundamentally shifted. In 2025, 75% of VC dollars went to just 19 companies—a stunning concentration that reflects the bifurcation between traditional venture and ultra-late-stage private public investing.\n\n“What’s really happened is on top of that business has emerged this totally separate business called ultra late stage,” explains Harry. “It just means there’s another business that you can choose to be in or not that exists one or two orders of magnitude above you in the valuation world.”\n\nThe Death of “Triple Triple Double Double”\n\nTraditional SaaS growth metrics are becoming obsolete for many companies. While “triple triple double double” (3x-3x-2x-2x growth pattern) remains relevant at early stages, it’s insufficient for late-stage rounds in today’s market.\n\n“There’s only so many folks growing beyond triple triple double double at 50 to 100 million—VCs will take the meeting,” notes Jason. But for companies in traditionally unloved verticals or without AI narratives, even strong growth isn’t guaranteeing funding notes Harry.\n\nThe Founder Friendly Facade\n\nThe concept of “founder friendly” has become meaningless in today’s hyper-competitive environment. “Founder friendly has become bullshit,” argue both Harry and Jason. “Any hot AI deal, there is no diligence provided, nor is any done. It’s just done on Saturday.”\n\nReal founder-friendly behavior shows up in difficult times: “Founder friendly is writing the check when no one else does. That’s founder friendly. Founder friendly is when no one else is there at the board meeting anymore and you’re there and you still have a W on the other side of it.”\n\nMarket Concentration Creates New Dynamics\n\nThe concentration extends beyond just funding to data labeling and infrastructure. Multiple data labeling companies report that the same two AI giants make up 55% of their revenue across all providers. This concentration creates a unique dynamic where “none of those six customers is trying to optimize their cost basis. They’re just trying to build as fast as they can.”\n\nIPO Strategy in a Concentrated World\n\nCompanies like Navan (filing at $8B with $613M revenue, 32% growth) are timing their IPOs strategically. Rather than waiting for profitability, they’re moving quickly to avoid being the “third player” in their category after competitors like Brex and Ramp potentially go public.\n\n“When people perceive it as a direct comp, even if it isn’t, it becomes troubling to get out because every public investor says, ‘I already have Brex and Ramp. Why would I buy you?'” notes Rory.\n\nThe New Venture Reality Check\n\nFor investors, the current environment requires recalibrating expectations. Jason admits: “I’m 0% cash, just like 2008. I remember feeling I could literally not have enough cash to fix the roof on my house—nothing was more fun than selling my stock at a 70% loss to fix that roof.”\n\nThe frothiness is evident: LPs are now bragging about returns on LinkedIn, historically a sign of market peaks. Yet for companies with genuine traction, funding remains available. The key is having clarity on realistic next-round pricing rather than extrapolating long-term returns.\n\nPortfolio Concentration Lessons\n\nSuccess breeds more risk tolerance. “Having an early success is highly correlated with future success. Partly you get the referral effect, but partly I think it’s that you just have the stomach to roll the dice and you get braver.” notes Rory.\n\nThis explains why firms like Sequoia can hold positions like Klarna while emerging managers face different portfolio pressures around concentration limits.\n\nLooking Ahead: The End of 2021 Valuations\n\nThere’s growing consensus that 2021 valuations should be written off entirely. “I think we can’t talk about 2021 valuations anymore. It’s time to just flush them down the toilet,” suggests Jason proposing a deadline: “You’ve got 90 days left to caveat and complain about your 2021 valuations. And on January 1, 2026, no one is allowed to talk about their 2021 valuations.”\n\nCompanies like Notion, now at $500M ARR with re–\\acceleration, show that B2B companies can recover by embracing AI while maintaining their core business. The path forward isn’t becoming “something totally different” but rather intelligent integration of AI capabilities.\n\nThe Monopoly Question\n\nOpenAI’s consumer dominance raises antitrust questions, but it’s complicated by their massive subsidization of users. “Never have there been a less successful monopoly than ChatGPT because they’re subsidizing the consumer surplus delivered by ChatGPT in the tens of billions of dollars” notes Rory.\n\nThe real monopoly question may be more relevant to NVIDIA, which has true market share dominance in AI chips, making their equity investment in OpenAI particularly strategic.\n\nKey Takeaways\n\nCapital concentration is unprecedented : 75% of 2025 VC dollars went to just 19 companies, creating a new tier of ultra-late-stage private investing distinct from traditional venture\n\n75% of 2025 VC dollars went to just 19 companies, creating a new tier of ultra-late-stage private investing distinct from traditional venture H-1B changes will impact startups materially : The $100K fee creates real barriers for early-stage companies, though workarounds and for founders use of O-1 visas are and will emerge\n\nThe $100K fee creates real barriers for early-stage companies, though workarounds and for founders use of O-1 visas are and will emerge “Founder friendly” has become meaningless : In hot AI deals, there’s no diligence and term sheets are signed on Saturdays, making the concept hollow\n\nIn hot AI deals, there’s no diligence and term sheets are signed on Saturdays, making the concept hollow Traditional SaaS metrics are obsolete: “Triple triple double double” no longer guarantees late-stage funding except for the hottest AI companies\n\n“Triple triple double double” no longer guarantees late-stage funding except for the hottest AI companies Timing matters for IPOs : Companies are racing to go public before competitors in their category, as being third creates comparison problems\n\nCompanies are racing to go public before competitors in their category, as being third creates comparison problems 2021 valuations need to be forgotten : It’s time to write down frothy valuations and move forward with fundamental-based pricing\n\nQuotable Moments\n\n“This is an epic monopoly like we’ve never seen. Think how much ChatGPT already dominates our lives. It’s the Standard Oil of tech.” — Jason discussing OpenAI’s market dominance\n\n“You’ve got this company with $4.5 trillion market cap with only six customers. That’s bad news. But the good news is all six of them are determined to spend themselves into oblivion to win the prize.” — Rory discussing NVIDIA’s customer concentration risk\n\n“Any hot AI deal, there is almost no diligence provided, nor is any done. It’s just done on Saturday. All you can lose is one extra money.” — Jason Lemkin on current venture funding practices\n\n“Having an early success is highly correlated with future success. Partly you get the referral effect, but partly I think it’s that you just have the stomach to roll the dice and you get braver.” — Rory on venture capital success patterns\n\n“I’m 0% cash, just like 2008. Nothing was more fun than selling my stock at a 70% loss to fix the roof on my house.” — Jason reflecting on his current market position\n\n“I’m seeing less diligence now than I did in 2021.” — Harry discussing the current state of venture due diligence\n\n“The hardest thing I find is honestly we are getting it wrong. A lot of our startups at 20VC Fund now are are growing nicely and I cannot predict what the next round wants because it seems to be moving so much and I’m having real problem predicting financing markets.” — Harry on the unpredictability of current funding markets",
      "source": "Saastr.com",
      "url": "https://www.saastr.com/20vc-saastr-is-back-nvidias-100b-openai-investment-h-1bs-100k-fee-impact-on-startups-and-why-triple-triple-double-double-is-dead/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "1 Spectacular Semiconductor Stock (Besides Nvidia and AMD) to Buy Hand Over Fist Before 2026",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_c8a9a385-0440-428e-8858-3c58f6cd72cf",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "(PR) NVIDIA GeForce NOW Gets Mecha BREAK and Nine More Titles This Week",
      "content": "ENDLESS Legend 2 (New release on Steam and Xbox, available on PC Game Pass, Sept. 22)\n\nRenown (New release on Steam, Sept. 22)\n\nBaby Steps (New release on Steam, Sept. 23)\n\nAztecs: The Last Sun (New release on Steam, Sept. 23)\n\nSWORN (New release on Xbox, available on PC Game Pass, Sept. 23)\n\nLost Rift (New release on Steam, Sept. 25)\n\nCloverPit (New release on Steam, Sept. 26)\n\nMecha BREAK (Steam)\n\nPhoenix Wright: Ace Attorney Trilogy (Steam)\n\nPredecessor (Steam)\n\nAlan Wake 2 (Epic Games Store)\n\nS.T.A.L.K.E.R 2: Heart of Chornobyl (Steam, Xbox, available on PC Game Pass)\n\nSuit up and head for the cloud. Mecha BREAK, the popular third-person shooter, is now available to stream on GeForce NOW with NVIDIA DLSS 4 technology. Catch it this week as part of 10 new titles joining the nearly 5,000 games supported on GeForce NOW, in addition to Capcom's Phoenix Wright: Ace Attorney Trilogy. This week, Alan Wake 2 and S.T.A.L.K.E.R 2: Heart of Chornobyl join the lineup of GeForce RTX 5080-ready titles, both already available on the service. Look for the \"GeForce RTX 5080 Ready\" row in the app or check out the full list Plus, LG is celebrating being the first to offer OLED TVs that can stream GeForce NOW natively at 4K 120 frames per second, powered by the new GeForce RTX 5080 servers. To mark the occasion, LG is giving away 100 one-month GeForce NOW Ultimate membership codes for free. Head over to the r/LG_UserHub Reddit page to enter.Mecha BREAK is a multiplayer mech game where players can choose from diverse mechs, customize appearances and battle colossal war machines on treacherous terrain. The game pits pilots against each other in high-octane, team-based mech battles across vast, destructible arenas. Pick a Striker, master its unique abilities and outplay rivals in aerial and ground combat for pulse-pounding victory. Whether gearing up for 3v3, 6v6 or chaotic PvPvE matches, there's a mech for every play style - from agile snipers to heavy frontline brutes.Mecha BREAK is now available for streaming on GeForce NOW, making it easy to jump into the action wherever, whenever. With DLSS 4, Ultimate members get to experience the crispest visuals and smoothest frame rates, all from the cloud.In Capcom's iconic Phoenix Wright: Ace Attorney Trilogy, players become Phoenix Wright and experience the thrill of battle in the fight to save their innocent clients in a court of law. Play all 14 episodes, spanning the first three games, in one gorgeous collection.Investigate crime scenes, gather evidence, cross-examine witnesses with razor-sharp wit and deliver iconic \"Objection!\" moments to uncover the truth. With a mix of quirky characters, twisting storylines and surprising humor, the trilogy captures everything fans love about the legendary courtroom adventure.On GeForce NOW, it's never been easier to bring justice to the courtroom. Stream the Phoenix Wright: Ace Attorney Trilogy across devices instantly, with crisp visuals and smooth performance that lets every \"Hold it!\" land with dramatic flair. Whether gamers are on the go or settled in, the courtroom is always in session.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341374/nvidia-geforce-now-gets-mecha-break-and-nine-more-titles-this-week",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "The Weirdest Bubble Ever",
      "content": "A couple of weeks ago, it was announced that OpenAI is going to invest up to $300 billion in Oracle’s cloud computing.\n\nThis week, Nvidia committed $100 billion of investments into OpenAI.\n\nOracle is spending billions of dollars on Nvidia’s GPUs.\n\nNvidia invests in OpenAI who then invests in Oracle who then invests in Nvidia and Finkle is Einhorn and Einhorn is Finkle.\n\nWe’ve reached the mutually assured destruction phase of the AI bubble where the tech giants have decided they’re all in this together. If one is going to take the risk on massive capital expenditures then they’re all going to take the risk.\n\nAnd yeah, I’m ready to call this a bubble based purely on the history of excess investments in innovation.\n\nDuring the dot-com bubble of the 1990s, the telecom companies laid down more than 80 million miles of fiber-optic cables. Five years after the bubble burst, 85% of these fiber-optic cables still remained unused.\n\nThe Nasdaq crashed more than 80%.\n\nThe Railway Bubble of the 1800s also comes to mind. Here are some facts and figures I found while researching Don’t Fall For It:\n\nThere were 500 new railway companies by 1845\n\nThat same year, the Board of Trade was considering some 8,000 miles of new track in Great Britain alone, almost 20x the length of England.\n\nThe cost of the buildout was more than the national income of the entire country.\n\nThere were 14 bi-weekly newsletters about the railroad industry in circulation.\n\nCharles Darwin got caught up in the bubble, losing 60% of his investment.\n\nThe good news is both of those bubbles were great for innovation.\n\nBy 1855, there were over 8,000 miles of railroad track in operation, giving Britain the highest density of railroad tracks in the world, measuring seven times the length of France or Germany. The telecomm bubble helped power YouTube, social media, streaming movies, video calls, and everything else people dreamed about in the 1990s and more.\n\nThere are some similarities to the current AI buildout but many differences too.\n\nThe dot-com bubble was fueled by investor speculation in immature companies that didn’t generate any profits. Today’s tech firms are printing cash flow with insanely high margins.\n\nNearly all the money for the railways came from individuals. Retail investors were fueling the bubble.\n\nThe AI boom is coming from inside the house. It’s being led by the tech CEOs who are making these capital allocation decisions.\n\nIn the 1990s, Bill Gates said:\n\nGold rushes tend to encourage impetuous investments. A few will pay off, but when the frenzy is behind us, we will look back incredulously at the wreckage of failed ventures and wonder, ‘Who funded those companies? What was going on in their minds? Was that just a mania at work?’\n\nHere’s what Mark Zuckerberg said in an interview recently:\n\nIf we end up misspending a couple of hundred billion dollars, I think that that is going to be very unfortunate obviously. But what I’d say is I actually think the risk is higher on the other side. If you if you build too slowly and then super intelligence is possible in three years, but you built it out assuming it would be there in five years, then you’re just out of position on what I think is going to be the most important technology that enables the most new products and innovation and value creation and history.\n\nIn other words — we’re not going to undershoot on this. If it turns into a mania, so be it.\n\nThese tech leaders aren’t stupid. They know the history of over-investment. But they’re saying the risk comes from not spending enough.\n\nSo case closed? This is a bubble that’s sure to pop?\n\nIf this truly is a bubble of epic proportions it’s one of the weirdest ones we’ve ever seen.\n\nAccording to The Wall Street Journal, there is now $7.7 trillion sitting in money market funds:\n\nIt’s a bull market in cash holdings.\n\nGold is up more than 40% this year alone and hitting new all-time highs at a healthy clip. Since ChatGPT was released in November 2022, gold is actually outperforming the Nasdaq 100:\n\nHow could a relic that’s been used for thousands of years outperform the biggest, baddest technology companies we’ve ever seen during an orgy of AI spending?\n\nThe other part that makes the current situation tricky to understand is the companies leading the charge in the AI bubble have the fundamentals to back it up. JP Morgan’s Michael Cembalest shared the following in a new research piece this week:\n\nAI related stocks have accounted for 75% of S&P 500 returns, 80% of earnings growth and 90% of capital spending growth since ChatGPT launched in November 2022.\n\nThese companies are spending like drunken sailors but they can all afford the booze!\n\nI understand why many investors are worried about the prospects of a bubble. When they burst it tends to be painful. If you’re invested in the market, you have plenty of exposure to the gigantic tech stocks:\n\nJust because this feels like some of history’s biggest bubbles doesn’t make it any easier to handicap.\n\nThe thing that worries me the most right now is everyone who has ever studied market history is now calling this a bubble. It seems so obvious. Markets are rarely that easy.\n\nSo what if you’re convinced we’re in a bubble? What actions should you take?\n\nI’ll share some thoughts on this topic next week.\n\nIn the meantime, Michael and I talked dissected the AI bubble from all angles and much more on this week’s Animal Spirits:\n\n﻿\n\nSubscribe to The Compound so you never miss an episode.\n\nFurther Reading:\n\nIs This 1996 or 1999?\n\nNow here’s what I’ve been reading lately:\n\nBooks:",
      "source": "Awealthofcommonsense.com",
      "url": "https://awealthofcommonsense.com/2025/09/the-weirdest-bubble-ever/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Denison Mines (DNN) Jumps on Strong Optimism for Uranium, Nuclear",
      "content": "We recently published Massive Gains: 10 Stocks Investors Can’t Stop Buying. Denison Mines Corp. (NYSEAmerican:DNN) is one of the top performers on Thursday’.\n\nShares of Denison Mines grew by 4 percent on Thursday to close at $2.86 apiece as investors loaded positions amid renewed optimism for the uranium and nuclear industries.\n\nDuring the session, a hefty 97 million shares changed hands.\n\nEarlier this week, technology giants Nvidia Corp., Alibaba Group, and OpenAI announced a wave of billion-dollar investments that bolstered rosy prospects for the nuclear industry.\n\nDenison Mines (DNN) Jumps on Strong Optimism for Uranium, Nuclear\n\nDenison Mines Corp. (NYSEAmerican:DNN), for its part, stands to benefit from the expected stronger demand for power, as its uranium products are crucial in fueling nuclear power plants for AI companies such as data centers that require a massive amount of electricity.\n\nTo support its expansion plans, the company last month successfully raised $345 million in fresh funds from the issuance of convertible notes due 2031.\n\nProceeds from the offer will be used for the development of its flagship Phoenix In-Situ Recovery uranium mine in northern Saskatchewan, Canada, while the balance will be used for future investment decisions.\n\nWhile we acknowledge the potential of DNN as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/denison-mines-dnn-jumps-strong-120809202.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Acer、IFA 2025でグローバル向け最新モデルを公開",
      "content": "日本エイサー株式会社（本社：東京都新宿区、代表取締役社長：ボブ・セン）は、先日ドイツ・ベルリンにて開催された「Acer グローバルプレスカンファレンス」にて発表された新製品についてお知らせいたします。なお、これらのモデルの日本市場への導入可否や導入時期、想定売価は現時点では未定です。今後の発表にご期待ください。\n\n発表製品一覧\n\nノートパソコン製品\n\nデスクトップパソコン製品\n\nプロジェクター製品\n\nルーター製品\n\nモニター製品\n\nタブレット製品\n\nキーボード製品\n\nハイライト\n\n薄型・軽量ノートPC「Swift」シリーズの新モデル Swift Air 16\n\nSwift Air 16 (SFA16-61M)\n\n最新性能 ：AMD Ryzen™ AI 300シリーズ・プロセッサーを搭載し、AIアプリケーションの高速処理と省電力性を両立。Copilot+ PCとして Recall（プレビュー）、Click to Do（プレビュー）、改良版Windows SearchなどのAI機能に対応。\n\n超軽量設計 ：マグネシウム-アルミニウム合金の筐体で、16インチクラスながら重量1kg未満。4色のカラーバリエーションを展開。\n\nディスプレイ ：16インチWQXGA+ AMOLED（120Hz／DCI-P3対応／400nit）またはWUXGA IPS（60Hz）から選択可能。\n\n主要機能 ：FHD IRカメラ（Windows Hello対応／プライバシーシャッター付）、デュアルスピーカー＆マイク。\n\n接続性：USB Type-C（フル機能）×2、USB 3.2 Type-A、HDMI 1.4、Wi-Fi 6E、Bluetooth最新規格。\n\nMediaTek Kompanio搭載 Chrombook Plus\n\nAcer Chromebook Plus Spin 514 (CP514-5HN)\n\n最新AI対応プロセッサー ：MediaTek Kompanio Ultra 搭載。50 TOPSのAI処理性能により生成AIやリアルタイム自動化をサポート。\n\n高効率＆長時間駆動 ：Arm Immortalis-G925 MC11 GPUで優れたグラフィックス性能を実現し、最大17時間のバッテリー駆動を提供。\n\nGoogle AI機能統合 ：スマートグルーピングやオンデバイス画像編集、Quick Insertキー、Lens検索など生産性を高めるAI機能を搭載。\n\n特典プラン：12か月間のGoogle AI Proプラン利用権を無償提供。GeminiやNotebookLMの高度AI機能に加え、2TBのクラウドストレージを利用可能。\n\nハイエンドAI開発からコンテンツ制作、ゲーミングまで幅広いニーズに応える新型ノートPC\n\nPredator Helios 18P AI (PH18P-73)\n\nプロセッサー ：最大 Intel® Core™ Ultra 9 285HX（Intel® vPro®対応）、ハードウェアレベルのセキュリティと安定性を提供。\n\nメモリ ：最大192GB ECCメモリ搭載、データエラーを検出・修正し高信頼性を実現。\n\nGPU ：最大 NVIDIA® GeForce RTX™ 5090 Laptop GPU（DLSS 4対応）。\n\nストレージ & 接続 ：最大6TB PCIe Gen5 SSD、Thunderbolt™ 5、Killer™ Ethernet E5000B、Wi-Fi 7。\n\nディスプレイ ：18型 16:10、Mini LED 4K WQUXGA（3840×2400）、HDR 1000nit、DCI-P3 100%。\n\n冷却機構：第6世代AeroBlade™メタルファン（0.05mm）、液体金属グリス、ベクターヒートパイプ採用。\n\n大規模AIモデルをローカルで実行できる超小型ワークステーション\n\nVeriton GN100 AI Mini Workstation (GN100)\n\nハードウェア性能： NVIDIA® GB10 Grace Blackwell Superchip 搭載。FP4 AI性能最大1 PFLOPS、20コアArm CPU、128GBユニファイドメモリ、4TB NVMe M.2 SSD。\n\nAI開発環境： NVIDIA AIソフトウェアスタックを標準搭載し、PyTorch、Jupyter、Ollamaなど主要ツールをサポート。\n\nスケーラビリティ： NVIDIA ConnectX-7 NICにより2台連結し、最大4,050億パラメータ規模のAIモデル運用が可能。\n\n接続性・セキュリティ：Wi-Fi 7、USB 3.2 Type-C×4、HDMI、Ethernet、Kensingtonロック対応。\n\nゲーマーからクリエイター、プロフェッショナルまで幅広く対応するフラッグシップデスクトップ\n\nPredator Orion 7000 (PO7-667)\n\nプロセッサー & GPU： 最大 Intel® Core™ Ultra 9 285K（NPU内蔵）＋NVIDIA® GeForce RTX™ 5090、DLSS 4やNIMマイクロサービス対応でAIワークロードも強化。\n\n冷却性能： Predator CycloneX 360＋CPU液冷クーラー採用で冷却効率15％向上。基板温度を最大9℃低減。\n\nメモリ & ストレージ： 最大128GB DDR5 7200MT/s XMP RGB RAM、最大6TB SSD＋最大4TB HDD対応（3.5インチ×2ベイ）。\n\n接続性：Killer Ethernet E3100G、Wi-Fi 7、Thunderbolt 4で低遅延＆高速通信を実現。\n\n新型ゲーミングデスクトップ 「Nitro 70」「Nitro 50」\n\nAcer Nitro 70 (N70X3D-100) / Acer Nitro 50 (N50-100)\n\nNitro 70（N70X3D-100）： 最大 AMD Ryzen™ 9 9950X3D プロセッサー＋NVIDIA® GeForce RTX™ 5090 GPU、3,352 AI TOPS。最大128GB DDR5 6000MT/s RAM、2TB PCIe Gen4 SSD対応。\n\nNitro 50（N50-100）： 最大 AMD Ryzen™ 7 8700G プロセッサー＋NVIDIA® GeForce RTX™ 5080 GPU。最大128GB DDR5 5200MT/s RAM、2TB PCIe SSD対応。\n\n共通機能： Nitro CycloneX 360 冷却システム（冷却効率15％向上）、Wi-Fi 7、Acer Intelligence Space（内蔵AIツール）、強化ガラスケース＋ARGBライティング。\n\n環境対応：45Lシャーシのプラスチック素材に65％PCR（再生プラスチック）を採用。\n\nエリートゲーマーのためのウルトラ高速モニター\n\nPredator X27U F8\n\n高速リフレッシュレート ：26.5型 OLED IPS／WQHD（2560×1440）、最大540Hz、DFRでHD（1280×720）最大720Hz切替対応\n\n鮮やかな映像表現 ：99％ DCI-P3色域カバー、VESA DisplayHDR 500 True Black認証による深い黒と高コントラスト。\n\n滑らかなゲーム体験 ：AMD FreeSync™ Premium Pro対応で、ティアリングやスタッタリングを防止。\n\nエリートゲーマー仕様：超高速応答と高画質を両立したフラッグシップモデル。\n\nすべてのゲーマーに没入の映像体験を\n\nNitro XV275K V6\n\n高解像度ディスプレイ ：27型 4K UHD（3840×2160）、リフレッシュレート180Hz。\n\n高速応答と滑らかさ ：1ms VRB Pro、AMD FreeSync™ Premium対応でティアリングのない快適なゲーム体験。\n\n鮮やかな映像表現 ：ピーク輝度1,000nit（HDR10%）、DCI-P3 97％、10.7億色（8bit+FRC）。\n\n豊富な接続性：HDMI 2.1×2、DisplayPort 1.4を搭載。ゲーミングやマルチメディア環境に対応。\n\nクリエイターへ。ゲーマーへ。OLED 280Hz WQHDモニター\n\nAcer CE270U Z\n\n高精細・高速表示 ：26.5型 OLED／WQHD（2560×1440）、リフレッシュレート280Hz。\n\n滑らかな映像体験 ：AMD FreeSync™ Premium Pro、応答速度0.03ms、HDR時ピーク輝度1,000nit、DCI-P3 99%色域。\n\n快適な視聴環境 ：チルト角最大25°に対応し、長時間の使用でも快適。\n\n臨場感あるサウンド：3Wスピーカー内蔵で映像と音を一体で楽しめる。\n\n世界に向けて発表するAmadanaブランドモニター\n\nAmadana 16APM1QJ / Amadana 27ART0 P1 (※英語サイト)\n\namadana 16APM1QJ（15.6型）： 超薄型・軽量（0.65kg）のポータブルIPSモニター。広視野角、最大90°チルト対応スタンドを内蔵し、mini-HDMI／USB Type-C入力に対応。生産性とエンターテインメントの両方で活躍。\n\namadana 27ART0 P1（27型）：ゼロフレームデザインのIPSディスプレイ。144Hzリフレッシュレート、Dynamic Refresh Rate（120Hz／60Hz）、sRGB 99％色域対応。HDMI／VGA入力、アクセサリ用小型ドックを備えた多用途モデル。\n\nその他の発表製品については、以下をご覧ください。\n\n特設サイト\n\nhttps://www.acer.com/jp-ja/events/nextatacer\n\nグローバルプレスリリースおよび製品写真\n\nhttps://drive.google.com/drive/folders/1k6NiPXN_9CLo2cBy6pw0Wcx8wglJuwuH\n\nプレスリリースページ\n\nhttps://www.acer.com/jp-ja/about/news/20250926\n\nAcerについて\n\n1976年に設立されたAcerは、世界160以上の国と地域に展開する世界有数のテクノロジー企業です。コンピューターやディスプレイをはじめとする幅広い製品群において革新を取り入れつつ、新たな事業領域にも進出することで進化を続けています。Acerはまた、持続可能な成長にも取り組み、環境および社会的責任に沿った新たな機会を追求しています。Acerグループには9,000名以上の従業員が在籍し、製品・ソリューション・サービスの研究、設計、マーケティング、販売、サポートを通じて、人とテクノロジーの間にある障壁を取り払うことに貢献しています。詳細は www.acer.com をご覧ください。\n\n日本エイサー株式会社について\n\n社名 ：日本エイサー株式会社\n\n所在地：東京都新宿区西新宿6-24-1 西新宿三井ビルディング 18F\n\n代表者：代表取締役社長 詹 國良（ボブ・セン）\n\n公式サイト： https://www.acer.com/\n\n公式facebook： https://www.facebook.com/AcerJapan\n\n公式X ： https://www.twitter.com/AcerJapan\n\nGaming公式X: https://twitter.com/PredatorJPN\n\n公式Instagram： https://www.instagram.com/acer_japan/\n\nGaming公式Instagram： https://www.instagram.com/predatorgamingjapan/\n\n公式YouTube： https://www.youtube.com/user/AcerJapanChannel\n\n© 2025 Acer Inc. All rights reserved. AcerとAcerロゴはAcer Inc.の登録商標です。その他商標、登録商標、サービスマーク等の著作物の著作権は、帰属表明の有無に関わらず、それぞれの権利者に帰属します。発表内容は予告なしに変更または削除されることがありますのであらかじめご了承ください。\n\n© 2025 Acer Inc. All rights reserved. Acer and the Acer logo are registered trademarks of Acer Inc. Other trademarks, registered trademarks, and/or service marks, indicated or otherwise, are the property of their respective owners. All offers subject to change without notice or obligation and may not be available through all sales channels. Prices listed are manufacturer suggested retail prices and may vary by location. Applicable sales tax extra.",
      "source": "Prtimes.jp",
      "url": "https://prtimes.jp/main/html/rd/p/000001034.000000640.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Get Insider Access To The Business Playbooks Of Billionaires At The Forbes Under 30 Summit",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/alexyork/2025/09/26/get-insider-access-to-the-business-playbooks-of-billionaires-at-the-forbes-under-30-summit/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Intel Corp. (INTC) Rockets to All-Time High as Firm Lures Apple to Invest",
      "content": "We recently published Massive Gains: 10 Stocks Investors Can’t Stop Buying. Intel Corp. (NASDAQ:INTC) is one of the top performers on Thursday.\n\nShares of Intel Corp. soared to a new all-time high on Thursday, as investors cheered the luring of Apple Inc. to invest in the company.\n\nDuring the session, Intel Corp. (NASDAQ:INTC) touched its highest 52-week price of $34.25 before a slight profit-taking to end the day just up by 8.87 percent at $33.99 apiece.\n\nIntel Corp. (INTC) Rockets to All-Time High as Firm Lures Apple to Invest\n\nAccording to the company, it persuaded Apple Inc. to invest as part of its efforts to bolster its business.\n\nEarly talks are now ongoing on how to work more closely together. However, negotiations can still fall through.\n\nEarlier this month, Intel Corp. (NASDAQ:INTC) secured a $5 billion investment from chip giant Nvidia Corp.\n\nThe partnership would also cover the joint development of AI infrastructures and personal computing products that accelerate applications and workloads across hyperscale, enterprise, and consumer markets.\n\nAdditionally, Intel Corp. (NASDAQ:INTC) and Nvidia will focus on seamlessly connecting their architectures using the latter’s NVLink, which would integrate the strengths of NVIDIA’s AI and accelerated computing with Intel’s leading CPU technologies and x86 ecosystem to deliver cutting-edge solutions for customers.\n\nFor data centers, Intel Corp. (NASDAQ:INTC) will build NVIDIA-custom x86 CPUs that NVIDIA will integrate into its AI infrastructure platforms and offer to the market.\n\nFor personal computing, Intel Corp. (NASDAQ:INTC) will build and offer to the market x86 system-on-chips (SOCs) that integrate NVIDIA RTX GPU chiplets. The new x86 RTX SOCs will power a wide range of PCs that demand integration of world-class CPUs and GPUs.\n\nWhile we acknowledge the potential of INTC as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/intel-corp-intc-rockets-time-120753647.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Microcenter Members: HP OMEN MAX: 16\" QHD+ 240Hz IPS, Ryzen AI 9 HX 375, RTX 5080, 32GB DDR5, 1TB SSD $1999.99",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18637456-microcenter-members-hp-omen-max-16-qhd-240hz-ips-ryzen-ai-9-hx-375-rtx-5080-32gb-ddr5-1tb-ssd-1999-99",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Jim Cramer Highlights Nebius “Has Some Good Contacts and a Relationship With Microsoft”",
      "content": "Nebius Group N.V. (NASDAQ:NBIS) is one of the stocks Jim Cramer recently commented on. Cramer discussed the NBIS stock’s rally despite losing money. He said:\n\n“But then there’s a company like Nebius… which has some good contacts and a relationship with Microsoft, but it loses a lot of money, yet its stock’s rallied more than 308% for the year. Ow.”\n\nStock market reports printed on a sheet of paper. Photo by RDNE Stock Project on Pexels\n\nNebius Group N.V. (NASDAQ:NBIS) develops full-stack infrastructure for AI, including GPU clusters, cloud platforms, and developer tools. In addition, it provides Toloka for generative AI data, TripleTen for technology reskilling, and Avride for autonomous driving solutions. Cramer discussed the stock in the September 9 episode and said:\n\n“Sometimes, though, you have a winner right in front of your face and you don’t realize it. When I was at NVIDIA’s big GTC conference… I was checking out the booth of all those companies that were working with Nvidia installing product into the data centers… At the end of the hall in what seemed to me to be a pretty empty booth… this company, Nebius, is a data center builder like CoreWeave. I felt bad for them, like no one was paying any attention to them, so I asked what they did. I sauntered it over there. They filled me in. They were going to be a part of the power solution. I thanked them. Never really thought about it again until yesterday when the company won a $17 billion contract to build a data center for Microsoft in Vineland, New Jersey… Sure enough, Nebius, which had been creeping up, vaulted from $64 to nearly $96 today in a colossal move. Nebius, it turns out, used to be a part of Yandex, a controversial Russian story. Spun out from Yandex, Nebius is controversial no more. It’s just electric, literally.”\n\nWhile we acknowledge the potential of NBIS as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.\n\nDisclosure: None. This article is originally published at Insider Monkey.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/jim-cramer-highlights-nebius-good-151818042.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Meet the Company Challenging Broadcom's AI Chip Dominance (Hint: It's Not Nvidia)",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/9304f921b31cb00b",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Intel reportedly approached Apple, TSMC for investment before Nvidia deal",
      "content": "Intel has already secured $5 billion from Nvidia and $8.9 billion from Trump\n\nTSMC and Apple have also been targeted for investments\n\nTim Cook would “love to see Intel come back”\n\nIntel had apparently approached Apple and TSMC for an investment before it struck its recent mega deal with Nvidia, The Wall Street Journal has reported, making for a pretty interesting bid.\n\nIntel, which recently secured a deal with the US government in return for a stake in the company, both relies on and competes with Taiwan’s TSMC, with many of its CPUs, GPUs and networking chips actually outsourced to TSMC.\n\nHowever, with the foundry business failing to secure any major customers, the company has faced struggles in recent years.\n\nIntel sought bids from rival companies\n\nTSMC wasn’t the only company Intel had approached – Bloomberg noted the chipmaker has also engaged in conversations with Apple, which used to use Intel chips in Macs between 2005 and 2020 before shifting to Arm-based proprietary SoCs.\n\nApple CEO Tim Cook has already publicly noted: “We’d love to see Intel come back.”\n\nIn the end, Intel secured a $5 billion investment from Nvidia – more than half of the $8.9 billion US Government investment into the chipmaker – in a previously unsuspected move.\n\nIntel previously had the market covered, leaving Nvidia to focus on gaming applications, but in mid-2020 Nvidia’s market cap passed Intel’s at the $250 billion mark. Today, Nvidia is worth $4.32 trillion, and Intel has dropped to just $158.7 billion.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAnalysts now see further investments as critical for Intel’s success going forward. If the company scores a deal with the likes of Apple, it would mark growing confidence in Intel’s turnaround efforts under the new leadership of CEO Lip-Bu Tan, but failure to collect further signatures could damage the company’s growing momentum.\n\nOnly time will tell if Intel can turn itself around, but one thing’s for certain. With two consecutive quarters of zero growth after a period of decline, the company is in need of drastic action.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/intel-reportedly-approached-apple-tsmc-for-investment-before-nvidia-deal",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Need to unplug and replug keyboard on startup, rgb lights still on",
      "content": "Posted 27 September 2025 - 03:11 PM\n\nHi, Welcome to BC.\n\nSuggest in your MSI BIOS turn off anything that speeds up the boot example ASUS Fast Boot. Note maybe more than 1 place.\n\nTurn off MS Fast Start : https://www.windowscentral.com/software-apps/windows-11/how-to-enable-or-disable-fast-startup-on-windows-11\n\nSo basically not getting a clean boot but what is held in ram when you start up. Which does not reflect changes you make/made.\n\nIs that the proper name of the keyboard ??? As there is a K500 with no drivers and a K500 Pro B94 with Drivers and Firmware Update both as a .rar file so may have problems downloading them.\n\nhttps://global.machenike.com/pages/download Click on Keyboard--> then Model\n\nAs this is also a Bluetooth Model and if not using Bluetooth for anything maybe turn it off.\n\nA Reddit from 2 yrs ago : https://www.reddit.com/r/techsupport/comments/14gi8kc/have_to_unplug_and_replug_keyboard_every_time_i/\n\nAs seems you have not provided a location but you are ahead of Pacific Time you need a different language. Above Download site has other languages.\n\nNote the VSG Quasar is coming up in non-English pages so will let you look through the results and modify the Search term as needed :\n\nhttps://www.google.com/search?q=vsg%20quasar%20keyboard%20drivers%20download&client=firefox-b-d",
      "source": "BleepingComputer",
      "url": "https://www.bleepingcomputer.com/forums/t/810935/need-to-unplug-and-replug-keyboard-on-startup-rgb-lights-still-on/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Nvidia RTX 50 Super launch window tipped for early 2026, AMD Zen 6 and RTX 6000 leaks detailed, Valve console speculation noted",
      "content": "Leaks from Moore’s Law Is Dead suggest Nvidia’s GeForce RTX 50 Super lineup could debut around CES or in early 2026, while the RTX 6000 family is tentatively expected in 2027. The livestream also touched on AMD’s upcoming Zen 6 APUs, potential FSR4 developments, and broader shifts in the PC and console space.\n\n4 Reviews ← exclude selected types\n\nIn his latest livestreams, Tom from the YouTube channel Moore’s Law Is Dead unveiled new information about the Nvidia GeForce RTX 50 Super series launch, along with leaks on Zen 6 and the RTX 6000 series.\n\nTom speculated on the RTX 50 Super lineup by clarifying the potential launch window, reiterating that at most one card might arrive late this year, though he now leans more towards CES 2026 or Q1 2026 for the 5080 Super and possibly the rest.\n\nHe also suggested there won’t be Founders Edition cards, only AIB partner models. According to him, the 5080 Super and 5070 Ti Super are expected to have identical CUDA core counts with only memory bumped, while the 5070 Super may see just a 4% core increase.\n\nSince the coolers and board designs are largely unchanged, Nvidia could give partners as little as three to four weeks’ notice, resulting in an unusually short gap between approval and launch.\n\nBeyond Nvidia, Tom also touched on AMD’s upcoming Zen 6 Medusa Halo APUs, which he claims will feature 48 RDNA5 compute units, delivering performance well above current Strix Halo chips and likely competing with GPUs such as the RTX 5070 Ti Mobile, and potentially even the RTX 5080 laptop chip. He suggested Medusa could find broader adoption in gaming laptops as prices for Strix Halo systems continue to fall.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Nvidia-RTX-50-Super-launch-window-tipped-for-early-2026-AMD-Zen-6-and-RTX-6000-leaks-detailed-Valve-console-speculation-noted.1125777.0.html",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "nvfuser-cu128 0.2.34.dev20250927",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvfuser-cu128/0.2.34.dev20250927/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Inside the Snapdragon X2 Elite: 20 Questions for Qualcomm’s Computing Chief",
      "content": "Table of Contents Market Successes for Snapdragon X So Far About Snapdragon Guardian Some SoC Particulars Market Positioning for the New X2 Chips Battery Life, and Why a Bigger NPU? Snapdragon X, Looking to 2029...\n\nDon't miss out on our latest stories. Add PCMag as a preferred source on Google.\n\nLAHAINA, MAUI—The highlight of this year's Snapdragon Summit is the unveiling of Qualcomm's second-generation Snapdragon X2 Arm laptop processors, including a new \"Extreme\" tier of chips that looks poised to take on AMD's, Intel's, and Apple's best. PCs with the new X2 Elite and X2 Elite Extreme processors won't appear until the first half of 2026, but Qualcomm is setting some great expectations: 18-core and 12-core processors with serious multicore CPU muscle, a field-leading TOPS count on its neural processor (an 80 TOPS NPU), and a redesigned graphics core.\n\nWith Intel on the ropes but now poised to work more closely than ever with Nvidia on co-designed \"RTX\" SoCs, with AMD benefitting from the power vacuum left by Intel, and with Apple Silicon going strong, it's the wildest time ever to cover laptop processors. PCMag's John Burek and Wired's Luke Larsen were given the opportunity to sit down with one of the company’s senior executives to chat about the new Snapdragon X2 Elite family. We quizzed Kedar Kondap, SVP and GM of Qualcomm's Compute division, on various aspects of the new X2 chips: their makeup, the new Snapdragon Guardian tech designed to appeal to enterprise, and how to cool these fierce-looking chips. The interview has been slightly edited and shortened for clarity.\n\nMarket Successes for Snapdragon X So Far\n\nPCMAG: We've seen various numbers from different sources—adoption numbers relative to the rest of the market—for the initial Snapdragon X Elite. Do you have anything that you can, want, or are able to share in terms of market percentages, numbers in terms of units sold, things of that sort?\n\nKONDAP: I can get you the right numbers that we've shared publicly, but we announced that at earnings. When you look at categories where we were focused—which is devices that are thin-and-light, $600 and above, with integrated GPU—in certain markets I think we've done really well...\n\nSo, approximately 9% of Windows laptops above $600 in the US and the top five European countries. These are the regions we focused on primarily in the first launch. We wanted to make sure that we were focused in how we delivered X Elite into the market. And it was staggered, right? We launched X Elite in June 2024; we launched X Plus devices in September at IFA last year; and then the X came in January. We announced in January, and devices came a little bit after that.\n\nWIRED: I'm curious—you probably don't have the numbers for this—about consumer purchases. Obviously, with some of the stuff announced, you are trying to push into enterprise more, which is where the big numbers are. Can you talk about how you are doing for consumers, people buying directly from stores and online?\n\nKONDAP: Yeah. The market, as you put it, is segmented between consumer and commercial. We focused the first launches on consumer. We've done a lot of pilots and enterprise trials. Those are in progress. We're a lead partner, in IT, ourselves. We've deployed more than 16,000 laptops at Qualcomm, so we're obviously leading the wave here. From a consumer standpoint, your question was more around, how did we approach the consumer segment?\n\nWIRED: I'm just wondering if you guys are doing better in that specific target [market] than enterprise?\n\nKONDAP: So our first focus was that we targeted consumer. Look at the investments and the strategy that we had. Products were very consumer-focused. We partnered with retailers, consumer retailers, globally. We had 50-plus retailers that we partnered with to have devices available. We focused on OEM dotcom channels. So, like, all of the OEM channels had devices. We announced more than 9,300 stores, and some of them even had a Snapdragon-branded kiosk. And the reason for us to do that is to build a relationship with the consumer. We wanted the consumer to understand: One, to understand the brand, but second, also to understand these experiences. The AI stuff is new, and there's not one specific app, or one use case, that's going to fit everybody....\n\nBut in parallel, we have started enterprise trials. Like I said, Qualcomm has led the way, but we have other partners like SAP and many others that have already deployed or are testing actively. We know that takes a little bit longer. Part of why we introduced Snapdragon Guardian today is to showcase more benefits to enterprises and what we can offer.\n\nAbout Snapdragon Guardian\n\nWIRED: I assume Guardian will be offered in all laptops, not just those sold directly into commercial?\n\nKONDAP: The use cases—obviously, it depends. For example, an OEM wants to sell it into the consumer space and add a capability with Guardian. You have the ability to track a PC, manage a PC. I'll give you a good use case.\n\nKids, for example, right? Many schools allow for kids to carry laptops, but they don't allow them to carry phones. So great use case: You know, today, on phones, people have Life360, or one of these apps that you can track where your kids are. You can geofence stuff. Think of it as something very similar. You have the ability to geofence where your kids are, have it on a laptop, and be able to manage it remotely. You can access what they're doing. So we want to give that control to consumers. So it's both a consumer and a commercial thing—but obviously it benefits largely commercial enterprises.\n\nWIRED: Will it be that when people buy those laptops, will they experience that? As in, are OEMs going to use that technology, then rebrand it? Or are we going to see it directly, like a feature in every laptop?\n\nKONDAP: I don't think we're ready to talk about that yet. But we wanted to showcase the technology and what we built because we have added the Guardian technology as a separate subsystem in our platform. So we've taken the steps to make sure that it is a secure subsystem within our SoC, and it provides the ability for our OEM partners to build on top of that. They can choose to offer it either in consumer or commercial. We're providing the foundation, if you will.\n\nPCMAG: About the Guardian stuff, I heard a mention in the presentation that it would be available even if the system was powered off. I was trying to figure out how that works. Are you able to talk on that?\n\nKONDAP: It is a separate subsystem within the SoC, and it connects to a cellular modem. The whole system stays in a low-power island. You can wake the modem up, which will wake up the subsystem. Now, as you know, that can go through multiple scenarios—like, for example, if it's a dead-battery situation, then obviously you can't do anything about it. But then, at the same time, our intent is offering this to enterprise or IT administrators. We want to give them the control to manage devices better, and the risk of a malicious attack is low if you're in a dead-battery situation. So as long as the user plugs in the laptop and brings it up to a certain threshold of battery, you have the ability to wake it up and just push a patch, or be able to do any activities...\n\nPCMAG: Disable it, or whatever the case.\n\nKONDAP: It's totally up to the IT administrators.\n\nSome SoC Particulars\n\nPCMAG: Question on the SoC. I was looking at the specs we were given and noticed that there were different memory allocations for the three different X2 SKUs announced so far. The first, the Elite Extreme, is at 48GB. The others were listed as \"device-dependent.\" And I was just wondering why the 48GB ceiling was landed upon. Any particular reason?\n\nKONDAP: I think the X2 Elite Extreme devices you saw, that we were running, had 48GB of memory. Honestly, we just picked the 48GB because that is still a pretty sweet spot. There's no science behind it. The X2 Elite can address up to 128GB. 48GB is already big for most users. So there's no science behind why we picked that.\n\n(Credit: John Burek)\n\nPCMAG: Is there anything you can speak to in terms of the Adreno GPU? The efficiency gains that were claimed on stage today are pretty impressive. And any insight into how you got to that point versus the first gen?\n\nKONDAP: It's a completely new Adreno GPU, designed ground up for this stuff. It has a new architecture, better shader pipelines. The entire GPU is new. It's not iterative. It is a new generation. And of course, if you're able to attend the sessions after this, we will go into a lot more technical details on exactly how it is done. But yes, it's a completely new architecture, and that's how we're able to get the performance gains as well as the power efficiency.\n\nPCMAG: One other thing that came up when I was talking with some of the folks in the benchmarking session that we had yesterday. The two reference desktops shown—I understand that they're being cooled with AirJet—Frore Systems' AirJet cooling—one of the reps told me?\n\nKONDAP: We have the option to do both. I should say, technically, you have the option to do three things. One, you can have the option to enable this with a fanless design. You can get close to at least 12 watts TDP, if not a little bit more. Or, you can use a regular fan. Or, you can use AirJet. And so, right now, we have two of the SKUs, I believe, that we're showing here. One of the designs is fanless, and the other one has AirJet, which gives you close to 25 watts TDP.\n\nIt's just an option that we want to showcase—that in the same X2 Elite or the X2 Elite Extreme, you can utilize the entire benefit and choose your design points, no different than laptops. And you can tell when you look at the form factors, the difference is insignificant in terms of what you can do, but you can still get 25 watts of performance at very low power.\n\nPCMAG: Thoughts on using AirJet outside of these desktops, in things like laptops? There's no reason you couldn't do that?\n\nKONDAP: No restriction. We just showcased this technology in the small form factors.\n\nMarket Positioning for the New X2 Chips\n\nWIRED: Can you talk about who the X2 Elite Extreme is for, and the thought behind offering that as a separate configuration?\n\nKONDAP: There's swim lanes, right? You have certain price points in certain swim lanes. The X1 Elite was in the price band, or I'll say the sweet spot, of $1,000 device SPs. Think of the X2 Elite as something very similar to that. The Extreme version with the 18-core CPU, with the much higher graphics core, will address a higher tier of experiences. That's part of why we focus so much on talking about gaming and creator use cases. We want to start showcasing the performance, and that's where you get the true benefit of running stuff.\n\n(Credit: John Burek)\n\nEverybody's in search of this one AI app that is going to transform. But we believe the workloads are going to get to agentic. And as you start looking at the whole scenario, all these different agents running on the device, we believe that it's going to run across all the different cores (obviously, on the NPU for low power), and it's going to run hybrid as necessary....Same reason why, for example, we added an 80 TOPS NPU. We believe that we're capping out in terms of many of the use cases that we're running, even at 45 TOPS. So we're enhancing leadership in each of those areas.\n\nWIRED: The 80 TOPS will be across the lineup, right? In the same way that 50 TOPS is across the [current Snapdragon X] lineup?\n\nKONDAP: We're keeping it constant. But the memory is different. In the X2 Elite and the X2 Elite Extreme, the memory configurations are different. DDR—the available bandwidth is different.\n\nFor example, you can address close to about 150, 152, gigabits per second in the X2 Elite. The Extreme gives you about 225, so think of it as an eight-channel DDR and a 12-channel DDR. That's the difference. In technical terms, it gives you more DDR bandwidth. And the reason to do that, obviously, is because many of the AI use cases are DDR-centric.\n\nEverybody's in search of this one AI app that is going to transform. But we believe the workloads are going to get to agentic.\n\nPCMAG: This might be a marketing question. I was looking at the initial three SKUs, and I noticed that the first SKU, the X2 Elite Extreme SKU, is 18-core, with everything else maxed out. The second one is also 18 cores, but not called Extreme. And then the other Elite is a 12-core, right? I was wondering what the marketing logic was of not making the first two 18-core chips both \"Extreme\"?\n\nKONDAP: So the difference is that with the Extreme version, because it's the higher DDR, and it is literally for \"extreme\" use cases, with AI and all of these things. The big difference between the three...all three SKUs support 80 TOPS, but the middle one and the lower one are both eight-channel. So addressability for memory is around 150 gigabits per second, and the Extreme version is the one with 225.\n\nPCMAG: Is the higher GPU performance also tied to the higher memory bandwidth?\n\nKONDAP: No...to be fair, obviously DDR also drives the GPU, drives a lot of the pipeline, drives a lot in terms of the SoC. But that's not why it is. Technically, yes, you are correct that games, or video, or those use cases, will scale because the bandwidth scales. But we've kept the graphics constant. You won't necessarily get to the same output. We just want to have the option available for everybody in case they want to use the 18-core without the extra DDR.\n\nPCMAG: About the Guardian hardware. It was said on stage that there is an SoC element that is part of the Guardian hardware. Is there any way of describing what that is?\n\nKONDAP: It's a dedicated processor within the SoC that's isolated from the rest of the other cores. It has its own BIOS. You can manage the subsystem independently without having to access the rest. So it's a more secure way of how we're able to access an independent processor within the entire SoC.\n\nBattery Life, and Why a Bigger NPU?\n\nWIRED: I noticed there was very little talk about battery life, as opposed to in the first generation—that was, you know, the thing! Anything to say about how different the battery life we're looking at [will be]? Or a kind of parity with the previous generation?\n\nKONDAP: No, it'll be better. We didn't talk in terms of specifics; then, the challenge becomes, what use cases, what do you want to run? With the first generation, we had to showcase stuff because we hadn't launched yet! [Laughter] Now, people have, like the [HP] OmniBook 5, tested out, and the claims that are made with 34 hours of battery life, they're tested. So there are third-party reports that have attested to this incredible battery life. But I showed some of the claims, as you heard; it's depending on which platform you look at: 30%, 40%, 50% better performance in the Extreme at 60% lower power. You will see improvements and gains in battery life, not just in terms of performance. But again, as you know, it's tied to use cases, how people are running it. But we will continue our leadership in performance per watt. We're going to lead the way.\n\nPCMAG: Question on the NPU. We are familiar with how things develop in CPU and GPU, but with NPU development, you're going from one number to a much larger number. How does that happen? What are the factors in chip development that enable an NPU to go from that to that in a generation? Just not being familiar with NPU architecture works.\n\nKONDAP: More details to come on Architecture Day for all of these, but look—AI, and that's why we had Steven [Bathiche] from Microsoft talk about it more technically, because there are things that are moving at such a rapid pace. It's funny, because when we talked about 45 TOPS, and were the first to introduce that in market, everybody said, 45 TOPS? Why do you need 45 TOPS?\n\nI don't know if you guys have had a chance to go through our demo area, but now you have use cases there that are utilizing 100% of our 45 TOPS, right? For example, there's an app called Collov, which basically helps you stage your home. There's no one app that's going to meet everybody's needs, but there are apps that are going to meet every different use case. What's happening is we're seeing this huge demand for NPU workloads.\n\nAt the same time, the models that we've seen have been optimized significantly. For example, when we launched, we talked about a 13-billion-parameter model back then, running on our 45 TOPS NPU with the eight-channel DDR at 130 gigabits per second. Now fast-forward. What has happened in two years is that models have shrunk. What was back then an INT8 model is now an INT4 model, sometimes an INT2 model. The accuracy is still very good. That's what Steven also addressed. We're also able to address bigger models now on the same device. Today, we're able to, in our X1 platform, in many cases, fit like a 27-billion-parameter model.\n\nSo what's happening is we looked at a macro level, at how the industry is shaping with the AI workloads and the models. Then we looked at what we believe is the future, looking at all of these agentic workloads. Let me give you an example. Think of a use case where you're going to tell your PC: Look at my calendar, try to see if I can go to Snapdragon Summit. Am I available that week? And please help me schedule with these five folks, and help me do ABCDE, and give me flight options.\n\nThat use case has multiple agents running on the device. Each agent is different. There's an agent that's looking at your calendar; there's an agent that's looking at the conflicts that somebody else might have. There's an agent that's going to look at your travel preferences and all of that. There's also a hybrid approach to this, because if your preference is Southwest, Alaska, Delta Airlines, whatever, it's going to go in and access the web to see that. OK, John would like to fly on September 20, and it says, \"Well, looks like you can make it. You're supposed to go meet Luke at so-and-so place, but it looks like we can find another option.\"\n\nWhat has happened in two years is that models have shrunk. What was back then an INT8 model is now an INT4 model, sometimes an INT2 model. The accuracy is still very good.\n\nSo those agents—I'm giving you a very rudimentary example—but think of that as workloads where we're building up workloads internally to start modeling. And that, in partnership with Microsoft as well, and looking at partnering with all the model vendors, that's how we sized up the NPU.\n\nThere's more to it. I'm still talking very rudimentary. Now, you think about LVMs [large vision models] and multi-modalities with images and creating videos. Like: I type a text prompt, I want to write a little story, and I want to get it converted into a video. How does that happen? What parts of it run on-device? That's how we start sizing up the NPU and start looking at how we want to architect this. But also the reason why, bringing it back to the higher DDR bandwidth is that we're seeing that use case there. That's why we wanted to have that option available for anybody who needs it.\n\nPCMAG: Is it also a [factor] that multiple AI demands are being made at the same time? So, having a larger NPU enables not only multiple agents, but multiple processes that may be happening in the system at the same time? Being unsure how an NPU works, can it juggle [like a CPU]?\n\nKONDAP: Yeah, it is able to in the same way. And you still have a very powerful CPU and a very powerful GPU, and you have an NPU. So the better part is now if you're offloading all of these tasks, like the agentic stuff, to your NPU, you still have a lot of CPU and GPU headroom left for you to do other tasks, right? You're still going to do your email, you're still going to do other tasks that you want to do that you've offloaded to these other pipelines, including the video and audio and all of that.\n\nWe talked about adding this NPU even to our audio blocks. That's where we look at echo cancellation, background, and all of that stuff. We're going to start running it more on these smaller NPUs. Overall, like I said, that's how we model our use cases right now.\n\n(Credit: John Burek)\n\nWIRED: [With NPU], are we still in a sort of \"build it and they will come\" situation? I know that initially, that's what it was, right? You had to get these into these computers before people could start developing. Where are we at right now?\n\nKONDAP: There are more ISVs than we can keep up with right now, the number of ISVs that are wanting to port all their stuff. And you see why specifically these creator workloads—like Ableton Live and with big voice-model stuff—these are very intense things that really do take up a lot of the NPU. And so everybody is moving toward the same thing, like enterprises are moving to agents.\n\nWe have a large customer right now that has moved a lot of their workforce in many areas...all onto agents. Like, they've moved their entire payroll to an agentic AI. There is no more payroll for them. They have, like, one person in payroll. They shrunk it from 11 down to one person. And then making sure that the agents can run payroll, they've linked it up in the back end. There are all these different use cases....I don't have to sit across the table and convince somebody that the future is AI. Those days are past us now.\n\nWIRED: Specifically on-device, right?\n\nKONDAP: It's moving on-device....The example I gave you of writing a little story and then building a video: It costs a lot of money to build that story and build a video from that story if you run it 100% in the cloud. And there's no reason to. But we're not necessarily saying everything's going to run on-device. We're just saying that's the optionality. You have the option to run a hybrid model, where you can run stuff on-device, and other parts in the cloud. That's the beauty of how this industry is going to move.\n\nPCMAG: Is there any world in which applications, AI applications, are load-balancing between the NPU and other parts of the CPU/SoC? Is that currently done today?\n\nKONDAP: Yes, it's done today. OK, but it's more power, right? The reason for the NPU is that it's a lot more power-efficient. Running anything on your NPU helps you with battery life significantly.\n\nPCMAG: And these days, what's managing the traffic around which part of the chip you're using? Is that something that's built into the app, is that something system-level? Who's arbitrating that?\n\nKONDAP: So the OS already has it. Like, we can go to your Task Manager today and see your NPU utilization relative to your CPU and GPU. So you can actually run something and see where it's being run—just the way you could run it earlier on the CPU and GPU, now you can see it on the NPU. From an orchestration standpoint, Microsoft provided—if you guys saw the announcement—Windows ML, so it makes it easier now for developers to have a cross-referenced framework that they can use.\n\nFor Qualcomm, we have our own orchestration framework. So, for example, when an ISV comes in and balances a particular use case, we have the governance in terms of what runs on the CPU, the GPU, or the NPU, or within the NPU, how do we want to run all the models. That governance we already have. We provide the orchestration ourselves.\n\nSnapdragon X, Looking to 2029...\n\nWIRED: Do you have a goal in mind for market share? What would you consider to be a success in this next generation?\n\nKONDAP: We've said our North Star. We said at our investor day, that's $4 billion in 2029.\n\nPCMAG: $4 million by 2029?\n\nKONDAP: $4 billion.\n\nPCMAG: That's a big number. [Laughter.]\n\n(Credit: Qualcomm)\n\nKONDAP: But we're also talking about a different way of how people are going to look at the PC. It's not the same as what we all see today. It will change. The interaction will change. You heard Cristiano [Amon, Qualcomm CEO] saying, \"AI will be the new UI.\" We're seeing it. I can't stress it enough.\n\n(Note: PCMag is attending Qualcomm's Snapdragon Summit by invitation, but in keeping with our ethics policy, we have assumed all costs for travel and lodging for the conference.)",
      "source": "PCMag.com",
      "url": "https://uk.pcmag.com/processors/160308/inside-the-snapdragon-x2-elite-20-questions-for-qualcomms-computing-chief",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Trump expands tariffs beyond US Supreme Court's reach",
      "content": "Live Events\n\nas a Reliable and Trusted News Source Addas a Reliable and Trusted News Source Add Now!\n\n\n\n\n\n(You can now subscribe to our\n\n(You can now subscribe to our Economic Times WhatsApp channel\n\nThe fate of many of President Donald Trump 's tariffs hangs in the balance at the Supreme Court , but he is rapidly building out a backup plan.The Supreme Court is set to begin considering whether the tariffs that Trump has placed on countries including Switzerland and India earlier this year are unconstitutional. But the Trump administration has been erecting another system of tariffs that is impervious to the legal challenge.The administration has proposed or issued tariffs that cover more than a third of U.S. imports under a legal provision related to national security, known as Section 232. They include many critical products for American businesses and consumers, including cars, machinery, medical devices and semiconductors.The president expanded the use of the national security law Thursday night, saying he would put tariffs ranging from 25% to 100% on imports of pharmaceuticals, semitrucks, kitchen cabinets and furniture beginning Oct. 1.A day earlier, his administration opened investigations that could result in tariffs on industrial machinery, robotics, medical devices and personal protective gear. Tariffs on other industries, including semiconductors and the electronics that contain them, are still pending and could raise costs further for consumers and businesses.Trump has used Section 232 to issue tariffs on steel, aluminum, cars and copper. The Commerce Department, which oversees this type of tariff, has an array of other Section 232 investigations pending -- into timber, critical minerals, aircraft and wind turbines -- which could result in more tariffs.Ed Gresser, director for trade at the Progressive Policy Institute, a think tank, said the inclusion this week of medical devices and industrial machinery would significantly expand the scope of the Section 232 tariffs. Those tariffs would affect consumers, farmers, car owners, carmakers, clinics and hospitals and smaller manufacturers that rely on metals, he said.\"Basically, the administration is adding tons of costs throughout the economy,\" Gresser said.The Section 232 tariffs give the president a powerful alternative to apply tariffs if the Supreme Court rules against his use of a different law to impose levies. The court cases center on the president's use of the International Emergency Economic Powers Act, which he used as the legal basis for the \"Liberation Day\" tariffs he placed on most countries' exports in April.The administration also used the emergency powers law to impose tariffs on China, Canada and Mexico in February and March, in return for what it said were those countries' roles in trafficking fentanyl into the United States.Oral arguments at the Supreme Court are set for November. If the Supreme Court agrees with lower courts that the president has exceeded the authority given to him by that emergency powers law, the administration will be forced to remove the tariffs that it has imposed on dozens of countries.But tariffs issued under other legal provisions, including Section 232, would be left standing. Courts have traditionally deferred to the president on national security, and legal experts have considered the Section 232 provision as relatively secure from legal challenges.Eswar Prasad, a trade economist at Cornell University , said the president \"seems eager to erect a new set of tariff barriers intended to circumvent and thwart any undercutting of his earlier tariffs by the judicial system.\"But he added that the national security justification for tariffs was \"wearing increasingly thin\" in being applied to products, including kitchen cabinets and upholstered furniture.An administration official said that Trump has long considered bolstering industries, including pharmaceuticals, as a national security priority and that a report would soon clarify why tariffs on furniture are a national security matter.The Section 232 tariffs on cars, steel and aluminum have already had major economic effects. They have sheltered some domestic producers from foreign competition, but they have significantly raised the cost of manufacturing inputs including metals and car parts, which some economists and business owners say is weighing on the U.S. factory sector.Jay Timmons, president of the National Association of Manufacturers, said that manufacturers were working to increase their production in the United States, but tariffs on manufacturing inputs, including robots and industrial machinery, would significantly increase costs for manufacturers. He said that they \"could in turn stall investment in new plants and equipment right here at home at a time when manufacturers want to help President Trump create more U.S. manufacturing output and jobs.\"Trump's new tariffs on foreign semitrucks seem more limited because most heavy trucks are manufactured in the United States. A greater share of furniture, kitchen cabinets and bathroom vanities are imported, however, meaning those tariffs could weigh more on consumers and contractors.The 100% tariff that Trump placed on foreign-branded pharmaceuticals could also have a limited reach because most imports of those products come from the European Union . The EU has already secured a 15% tariff on pharmaceuticals as part of a trade pact with the United States, which will apply to its products instead of the 100% rate.Trump said that he would offer exemptions to any pharmaceutical company building a plant in the United States. Most big drugmakers have responded to Trump's tariff threats with plans to build or expand factories in the United States.Those exemptions would only cover drugs that are manufactured in the United States, not all products at the company, the administration official said Friday.The next tranche of tariffs hanging over corporate America are tariffs Trump has threatened on semiconductors and devices that contain them.While the scope of the tariffs could be broad -- semiconductors are used in every device that has an on/off switch -- chip companies have lobbied to limit the impact. Trump threatened a 100% tariff earlier this year but has also proposed exemptions for chip companies building factories in the United States.At a meeting with semiconductor executives last week in Washington, Howard Lutnick, the commerce secretary, outlined plans to use tariffs to encourage tech companies to buy chips made in the United States, according to people familiar with the meeting.Lutnick told executives that the administration wanted them to buy 50% of the semiconductors their companies use from American manufacturers, the people said. Companies that commit to buying U.S. semiconductors would get credits for each dollar spent on American semiconductors, which they can use against what they spend on foreign semiconductors. The Wall Street Journal earlier reported details of the meeting.The plan was designed to encourage companies including Apple, Nvidia, Qualcomm and others to purchase more chips made in the United States. In recent years, Taiwan Semiconductor Manufacturing Co., Samsung and Intel have spent billions of dollars to expand production in Arizona and Texas.",
      "source": "The Times of India",
      "url": "https://economictimes.indiatimes.com/news/international/global-trends/trump-expands-tariffs-beyond-us-supreme-courts-reach/articleshow/124175953.cms",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Warning: This 8% Dividend Pick Will Be Controversial",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/michaelfoster/2025/09/27/warning-this-8-dividend-pick-will-be-controversial/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "NVIDIA Expands AI Presence with Intel Partnership and £2 Billion UK Investment",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_ca5bb8e3-ac8f-4472-a5c7-09f7602816e6",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Prediction: These 2 Things, Worth More Than $100 Billion, Will Ensure Nvidia's AI Dominance",
      "content": "Key Points\n\nNvidia’s stock has climbed in the quadruple digits in recent years thanks to its earnings growth.\n\nThe company has put the focus on AI, with this area making up 88% of revenue in the recent quarter.\n\nNvidia (NASDAQ: NVDA) has seen earnings climb in the double and triple digits…\n\nThis story appeared on aol.com , 2025-09-27 17:10:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/d1fb937d69ca865d",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "MSI Vector 16 HX AI: 16\" QHD+ IPS 240Hz, Intel Ultra 7 255HX, RTX 5070 Ti, 16GB DDR5, 512GB SSD $1529.99 (1 replies)",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18638773-msi-vector-16-hx-ai-16-qhd-ips-240hz-intel-ultra-7-255hx-rtx-5070-ti-16gb-ddr5-512gb-ssd-1529-99",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Nvidia CEO bets $100 billion on OpenAI becoming a multi-trillion-dollar company — Jensen outlines his view on OpenAI's path to becoming one of the biggest companies in the world",
      "content": "Nvidia CEO Jensen Huang believes OpenAI is on track to become a multi-trillion-dollar company, citing explosive growth and scale as the foundation for what could be the fastest rise to that valuation in the industry’s history. Speaking on the BG2 podcast, Huang said that OpenAI “is likely going to be the next multi-trillion-dollar hyperscaler company.”\n\nHis comments come on the heels of a high-stakes infrastructure pact between Nvidia and OpenAI. Earlier this week, the companies announced a letter of intent for up to 10 GW of GPU-powered data centers to be deployed through OpenAI’s preferred cloud partners. Nvidia, in turn, agreed to invest as much as $100 billion in those systems as capacity comes online, making it one of the largest vendor-led bets on AI infrastructure to date.\n\nIn doing so, Nvidia is effectively underwriting the next generation of AI growth by ensuring its silicon roadmap stays in sync with OpenAI’s compute ambitions. The deal anchors future demand for Nvidia’s Rubin-class platforms and next-gen networking hardware, while also giving OpenAI early access to systems that may not reach general availability for years.\n\nIt also helps to bolster Nvidia’s dominance in the AI supply chain. Major cloud providers, such as Microsoft, Amazon, and Google, have an insatiable appetite for GPU capacity, and Nvidia’s partnership strategy effectively pulls demand forward, locking hyperscalers like them into multi-year commitments while competitors like AMD and Intel are still playing catch-up. Expand the tweet below to see Jensen's explanation of OpenAI's path to a multi-trillion-dollar valuation.\n\n📁 Jensen Huang believes OpenAI is the next trillion-dollar company, and that’s why he’s investing. pic.twitter.com/bwI3ELEa4tSeptember 26, 2025\n\nAt 10 GW, OpenAI’s planned footprint and its associated capital expenditure have already pushed the plans into high-risk, high-reward territory. OpenAI recently struck a $6.5 billion expansion deal with CoreWeave, one of Nvidia’s key hosting partners, to help finance the rollout.\n\nNvidia also holds a stake in CoreWeave, and critics have raised concerns about the concentration of capital, hardware, and access among a small number of companies. However, that doesn’t seem to matter to Huang, who apparently believes that AI’s future will be defined by those who can scale infrastructure the fastest. OpenAI is outpacing even the most aggressive growth curves seen during the rise of cloud computing.\n\nNvidia’s ability to pre-sell entire generations of high-end GPUs into AI deployments will also have knock-on effects on the wider industry, including gaming card availability and workstation pricing. If OpenAI consumes a significant portion of future Rubin or Rubin Ultra supply, it could widen the gap between data center and consumer release cycles, making it even harder for consumers to obtain timely access to Nvidia’s latest hardware.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFor now, though, Huang seems unconcerned. He’s betting $100 billion that OpenAI’s growth definitely isn’t part of a wider AI bubble.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/jensen-huang-says-open-ai-will-be-a-multi-trillion-dollar-company",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Alibaba unveils $53B global AI plan – but it will need GPUs to back it up",
      "content": "Analysis Alibaba this week opened an AI war chest containing tens of billions of dollars, a revamped LLM lineup, and plans for AI datacenters in Europe. But it also prompted a flurry of questions over how it will achieve all this in an increasingly fragmented IT landscape, when critical resources are in short supply.\n\nProximity to the demand is key – in order for Alibaba to compete globally, it will need to position itself as close to its users as possible\n\nAt the mega vendor's Apsara conference in Hangzhou, China, it detailed the latest iteration of its Qwen3-Omni LLM, which can process text, images, audio, and video while generating text and speech.\n\nCritically, it is available under an Apache 2.0 license, making embedding it more tempting for companies loath to tie themselves into the ecosystems of ChatGPT et al.\n\nBut the Chinese giant also sketched out plans for a chain of AI datacenters straddling the Middle East, Europe, Southeast Asia, and Latin America. According to Reuters, it plans to invest $53 billion in AI infrastructure over three years.\n\nAlibaba already operates 91 availability zones across 29 regions worldwide, including existing facilities in London and Germany.\n\nThe new blueprint would include its first datacenters in the Netherlands, France, and Brazil.\n\nAlibaba President of International Business and Senior VP of the Cloud Intelligence Group, Dr Feifei Li said in a statement: \"Our strategic expansion of global infrastructure is designed to cater for the accelerating demand from forward-thinking customers.\"\n\nNeal Riley, AI Innovation Lead at The Adaptavist Group, told us: \"The international competition for dominance in the GenAI space has been heating up in the model arena, with strong contenders emerging from China like Qwen and DeepSeek. The move by Alibaba is going to see a similar competition across providers of infrastructure for AI tooling and systems.\n\n\"Proximity to the demand is key – in order for Alibaba to compete globally, it will need to position itself as close to its users as possible.\"\n\nIt's understood that Alibaba plans to offer a full suite of services from the new European datacenters, from standard cloud and elastic compute services up to big data analytics, machine learning, and AI.\n\nTo tempt companies into using its facilities to \"design, launch, and scale groundbreaking AI agents and applications,\" it will offer a range of resources \"including up to 2 billion free tokens on Model Studio, Alibaba Cloud's one-stop generative AI development platform, and up to $120,000 cloud credits from Alibaba Cloud.\"\n\nOne thing it's unlikely to be offering, though, is access to Nvidia's GPUs, which have become synonymous with AI infrastructure.\n\nAs a Chinese entity, Alibaba is blocked by Washington from buying Nvidia's top-end kit. At the same time, the US wants Nvidia to sell its cutdown H20 parts to China – with Washington taking a cut of those sales.\n\nBeijing meanwhile has reportedly told Chinese firms not to use those Nvidia chips.\n\nSo what alternatives are there for Chinese firms – other than sourcing full-fat Nvidia kit on the gray market?\n\nWell, there is Alibaba's own homegrown alternative, the T-Head, which is now considered able to go toe to toe with the H20, without giving a kickback to DC.\n\nSo would Alibaba be offering European consumers its own chips rather than the Nvidia parts European governments seem desperate to bring into Europe to boost the continent's AI capacity? Alibaba isn't saying.\n\nBut it's also worth noting that while Nvidia is being held back from doing chip business with Alibaba, the two announced a tie-up on physical AI – or robots depending on your point of view.\n\nAdded to chip sovereignty, there is the broader question of AI and data sovereignty.\n\nEuropean governments and customers are increasingly nervous about the likelihood of Washington leaning on cloud providers and potentially gaining access to European facilities – and the data in them. In June, Microsoft France execs confirmed that they could not guarantee that data on French citizens could never be transmitted to the US government without the explicit agreement of French authorities.\n\nBut the Chinese authorities have their own ways of leaning on cloud operators.\n\nSo will governments in the EU and beyond see Alibaba's plans as a quick boost to their own autonomy? Or would they see them as a threat and look to stymie them?\n\nThe EU's Foreign Direct Investment (FDI) protocols can be deployed when it has concerns over overseas entities investing in critical national infrastructure – and datacenters are undoubtedly seen as such.\n\nThat would be just one more hurdle among the power, land, and water shortages that complicate datacenter plans. Not to mention local opposition. But it seems likely that Alibaba will be taking on datacenter capacity from specialist operators. Its first wave of German datacenters, for example, are located in Vodafone facilities in Frankfurt.\n\nThis should mean it isn't subject to the EU FDI regime. And the datacenter providers will have already done the heavy lifting around land, power, and planning. If there was any doubt about the datacenters getting beyond the drawing board, would the firm have stuck its neck out and announced them? One notable exception from Alibaba's blueprint was the UK, the site of one of Alibaba's existing datacenters.\n\nA DSIT spokesperson told us: \"Whilst we would not speculate on possible investments, datacenters are now regulated as critical national infrastructure. Government can step in to review any investment deal from any country if it might affect national security.\"\n\nGiven the recent $42 billion trade pact between the UK and US, spearheaded by the likes of Microsoft and Google, the UK has enough to chew on for now. After all, it does include around 120,000 GPUs courtesy of Nvidia. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/27/alibaba_ai_drive/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "8 Companies Poised to Soar From Nvidia and OpenAI’s $100 Billion Alliance",
      "content": "This week marked a historic turning point for artificial intelligence.\n\nThe world’s best AI hardware maker – Nvidia (NVDA) – and the world’s best AI software developer – OpenAI – announced the single biggest deal in the history of artificial intelligence. In our view, it looks an awful…\n\nThis story appeared on investorplace.com , 2025-09-27 13:55:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/c27ec7304e218651",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Kingspan chases Magnificent Seven energy with plan to float unit riding on AI boom",
      "content": "Fed up with Kingspan shares drifting behind peers and the wider market, Gene Murtagh is seeking to tap into some of the energy of the Magnificent Seven (Mag-7), the US tech stocks that have driven a three-year bull run across global equity markets.\n\nThe Kingspan chief executive revealed on Tuesday that the insulation giant founded 60 years ago by his father, Eugene, plans to float 25 per cent of its advanced building systems unit Advnsys, which is focused on supplying the global data centres boom, in Amsterdam.\n\nThe mushrooming of data centres has been turbocharged by the artificial intelligence (AI) revolution that has driven the share prices in recent times of Mag-7 stalwarts such as chipmaker Nvidia, Microsoft, Google-parent Alphabet and Meta, owner of Facebook and Instagram.\n\nClose to $7 trillion (€6 trillion) will need to be spent on data centres globally by 2030, driven by demand for hubs equipped to handle AI processing loads, McKinsey, the management consultancy firm, estimated in a recent report.\n\n“We’re acutely cognisant of the fact that relevant sector peers – and these are not building sector peers, they’re tech-end peers that are supplying the data centre market – are trading at and above 20 times Ebitda,” Murtagh said on a call with analysts, referring to how others in the data centre space are being valued by the stock market at more than 20 times earnings before interest, tax, depreciation and amortisation. Valuing Advnsys along these lines would give it an initial market capitalisation of at least €6 billion.\n\n[ Kingspan shares soar on potential €6bn flotation of unit riding data centres boomOpens in new window ]\n\nKingspan had lost more than a third of its market value in the four years before the move was announced – and was down 21 per cent on the year as it grappled with what Murtagh recently described as an ongoing “pretty unforgiving environment” for construction suppliers globally as households and businesses fret about a potential recession. The group is trading at about 10 times Ebitda – compared with its 10-year average of 13.5.\n\nCompare that with Vertiv, an Ohio-based provider of critical infrastructure and services for data centres, whose stock has soared more than 400 per cent over the past four years.\n\nOr with Trane Technologies, the Swords-headquartered but New York-listed maker of heating and cooling systems for commercial buildings, whose market value has more than doubled in the same period, to $90 billion, amid a surge in demand for its data centre air-cooling systems.\n\nThe NFL comes to Dublin: How it became the richest sports league in the world Listen | 26:19\n\nThe AI boom – like red-hot stock market trends before it – has attracted blatantly cynical pivots and rebrands from companies trying to jump on the bandwagon.\n\nBut Kingspan has been a supplier to the data centres market since before Murtagh became CEO 20 years ago. The new Advnsys unit being lined up for an initial public offering (IPO) – which combines its data centre solutions and light, air and water businesses into one – is a world leader in bespoke critical infrastructure primarily focused on data centres, ventilation and daylighting.\n\n[ Kingspan trades profit for position in US roofing raceOpens in new window ]\n\nWhile about 40 per cent of Advnsys’s earnings currently come from providing infrastructure to the tech sector, particularly to data centres, this is expected to grow to about 75 per cent of an even bigger business in the next three to five years, according to the group.\n\nCitigroup analysts reckon the subsidiary could more than double its revenue and Ebitda between 2024 and 2030, to €3.2 billion and €525 million, respectively.\n\nShares in Kingspan jumped as much as 13.5 per cent to €74.85 on Tuesday morning, but have since handed back almost half their gains as some analysts urged caution.\n\n“While we understand the [market] reaction, particularly in light of the stock’s weaker performance year-to-date, we do not yet understand how a partial IPO creates additional value, nor how the market will arbitrage valuation between the two businesses,” said JP Morgan analysts led by Elodie Rall in a note to clients.\n\nAdvnsys may attract a higher valuation multiple, but this is likely to be offset by the market giving the rest of the business – comprising insulated panels, other insulation solutions and its roofing and waterproofing unit – a lower one, she said.\n\n[ Kingspan plans €650m share buy back as half year revenues rise 8% to record €4.5bnOpens in new window ]\n\nBernstein’s Pujarini Ghosh said the market excitement earlier in the week had been “overdone” and her €70 price target on the group points to almost 3 per cent downside from here. A listing of Advnsys in New York “could potentially have helped unlock greater value given the business mix will be more heavily skewed to the US”, she said.\n\nAbout 45 per cent of the unit’s business is exposed to the US, but this is expected to rise well above 50 per cent in the coming years.\n\nMurtagh said the decision to float on Euronext Amsterdam is down to the high level of trading in stocks in that market, a lack of stamp duty there, too, and how the same accounting standard (IFRS) applies to companies in the Netherlands and Ireland.\n\nFor sure, the level of trading in Euronext Dublin has slumped over the past five years amid a number of company exits and a dearth of fresh IPOs.\n\n[ How Kingspan stands to benefit from AI boomOpens in new window ]\n\nBut to avoid the 1 per cent stamp duty applied to share trading in Irish companies, Kingspan will need to incorporate Advnsys as a public limited company – or naamloze vennootschap (NV) – in the Netherlands.\n\nA nice bonus from the planned IPO is that it would, according to Murtagh. leave both Kingspan and Advnsys “essentially with zero debt” – giving them plenty of scope to invest and grow by acquisition.\n\nWhereas Kingspan’s share price tends to move with the broader construction industry cycle, Advnsys’s stock will be far more sensitive to developments in AI, making it potentially much more volatile.\n\nChinese tech group DeepSeek, for example, showed the world earlier this year that its approach to generative AI needs just a fraction of the computing power of more prominent US tools, such as ChatGPT. Could demand for data centres decline as AI systems become more efficient?\n\nOne thing’s for sure: savvy investors in Advnsys in Amsterdam will have alerts set for anything coming from another company 9,000km away. For now, Nvidia in Santa Clara, California, remains the bellwether for all things AI.",
      "source": "The Irish Times",
      "url": "https://www.irishtimes.com/business/2025/09/27/kingspan-chases-magnificent-seven-energy-with-plan-to-float-unit-riding-on-ai-boom/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Amazon Apparently Shipped a ‘Brick’ Worth $1,000 Instead of NVIDIA’s GeForce RTX 5080, But They Were Cool Enough to Take It Back",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/amazon-apparently-shipped-a-brick-worth-1000-instead-of-rtx-5080/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Intel Stock Rockets: Here’s What Top Analyst Ruben Roy Says Comes Next",
      "content": "Narratives on Wall Street can change in the blink of an eye, and boy, Intel (NASDAQ:INTC) reflects such a shift. Once considered a big AI loser amidst a host of ongoing issues, INTC shares have jumped over 40% since news broke last week that Nvidia and Intel had formed a major…\n\nThis story appeared on tipranks.com , 2025-09-27 23:09:17.584000.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/2be97b2d6d4a94a5",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Nvidia, These Other AI Plays Lead 5 Stocks Near Buy Points",
      "content": "Three of the five stocks to watch are part of the artificial intelligence trade, including chip company Nvidia.\n\nThe post Nvidia, These Other AI Plays Lead 5 Stocks Near Buy Points appeared first on Investor's Business Daily.\n\nThis story appeared on investors.com , 2025-09-27 12:00:43.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/773d997b67ec1465",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Are We in an A.I. Bubble? I Suspect So",
      "content": "Let me preface this post with a disclaimer that I’ve made before: I am a perennial skeptic of pretty much all tech, which is largely a product of my personality. For one thing, I’m good at seeing what might go wrong and less good at seeing incredible upside potential. For another, I’m a consistent late-adopter when I’m not a never-adopter. And once I’ve adopted a particular technology or application thereof, I tend to stick with it long after it has been eclipsed by something clearly superior. There’s a place in finance for someone with my natural inclinations, and that place is the credit markets; I’d make an absolutely terrible venture capitalist. That’s something I’ve demonstrated both by losing money and, more notably, missing great opportunities to make money.\n\nSo my attitude toward the LLM generation of artificial intelligence has been unsurprisingly moderate at best. I’ve looked forward personally to self-driving cars—one technology that I was overoptimistic about, at least in terms of timeline—along with automated translation services, document summarization, and other applications that struck me as both plausible and potentially useful to me personally. I’m convinced that artificial intelligence has the potential, once the kinks get worked out, to successfully automate all sorts of routine white-collar work (which it is already starting to do despite the kinks not being worked out yet), and is likely also to speed up incremental improvements in manufacturing as well as a wide variety of kinds of scientific research. I do worry a lot about various downsides—the way A.I. will super-charge fraudsters and other bad actors, the way “good enough but not actually good” A.I.-created art and music will crowd out the real thing, the incredibly destructive effects it is already having on education, and the potential for significant social dislocations. But all of that is par for the course for a “normal” highly disruptive technology.\n\nWhat I’ve never believed in is super-A.G.I., or even in ordinary A.G.I. I don’t believe the current generation of technology is progressing toward something as flexible and all-purpose as human intelligence, and general super-intelligence is only possible if you have general intelligence in the first place. So the dueling scenarios of utopia and extinction have never struck me as particularly compelling. Even my moderate view, though, is premised on the assumption that A.I. will continue to advance up the steep part of the sigmoid curve for a while before hitting one or another physical constraint that creates a new inflection point and slows advances further. Yet it seems to me that we’re already starting to hit some of those constraints.\n\nThe most obvious one is electricity. America is far more invested in the quest for A.G.I. than any other player, and yet our power grid is significantly constrained, and, as the Abundance folks will explain to you ad nauseam, we’re not doing a great job of expanding it’s capacity, and are in some ways starting to go backwards. But there are other less-well-known constraints out there. We’re already running out of “training data” which means trainers need to use earlier generations of A.I. to create additional data on which to train the new generation. It should be obvious why this would be unlikely to lead to advances in capabilities that scale with earlier advances based on real-world data. Then there are the chips themselves. The demand for compute is now growing twice as fast as Moore’s Law, which means that demand for physical chips is doubling on the same time scale that computing power per chip doubles. We used to worry about an A.I. accidentally becoming a paper-clip maximizer, but if we don’t actually reach A.G.I. fairly soon we’ll have to worry about the entire economy turning into a chip maximizer. Meanwhile, we do still need significant advances just to get to my moderate scenario, because actually-existing A.I. is not yet delivering productivity gains, even in the areas, like coding, where it is most optimized to do so.\n\nNone of that means that A.I. won’t continue to advance. It just means that we may be in the phase where accelerating investment in A.I. is driven less by accelerating advances that everyone needs to jump on before they get left behind, and more by the fact that those advances are decelerating, so that players who have already invested at an extraordinarily high level have to invest more and more to have a chance of hitting their previously-established goals and timelines. That’s a classic characteristic of a bubble. Indeed, we may even be past that and into the phase where players are playing finance games to artificially inflate a bubble they have come to depend on. See this post from Michael Spencer about how the major players in A.I. have created what looks like a Ponzi scheme, with OpenAI paying Oracle for computing services, Oracle purchasing chips from Nvidia to provide those services, and Nvidia investing in OpenAI, each to the tune of twelve figures. There’s nothing unethical about that kind of daisy chain, but it does goose the numbers for all three companies even though no revenue is actually coming from the end users in the economy for whom all of this capacity is (supposedly) being built. It’s hard to believe that those companies’ CEOs are unaware of that fact, and that’s why suspicion is warranted.\n\nSo are we in an A.I. bubble? It sure looks like it to me. That doesn’t mean we won’t get large economic advances (and disruptions) out of A.I. It doesn’t even mean that we won’t ever get A.G.I. or super-intelligence, if it turns out that such things are possible and that the current technology path ultimately leads that way. But I suspect that before we get to wherever we’re going on the technology front, we’re going to hear a big, ugly pop. Which raises the question: if that’s correct, what should we do about it?\n\nMy unsatisfying answer is: probably not that much—at least not directly. Alan Greenspan’s wisdom in the face of the dot-com bubble was to say that it’s impossible for policymakers to determine definitively whether we are in a bubble or how big it might be, and that anything the government did to try to burst the bubble would be counterproductive. If there is a bubble, and it eventually bursts, the Fed should respond by cutting rates to keep the economy from tipping into recession, and if it undershoots in its response it should commit to making up for the lost ground swiftly (though implementing the latter without triggering unwanted inflation requires the Fed to corner harder in both directions than it has historically been willing or able to do). But until that happens, the Fed should hold its fire.\n\nI suspect that’s all still good wisdom. I’d also add that any government that set out deliberately to slow growth in the most vibrant sector of the economy would get its head handed to it by the voters—and if the Federal Reserve did it, that would supercharge existing efforts by this administration to threaten its independence. That political analysis applies equally well or better to attempts to regulate A.I. itself on safety or other grounds, which could well have the effect of causing the bubble to burst. Such efforts may or may not be wise, but they are much harder to implement in the middle of a bubble than before the bubble begins to inflate—and if they were to burst the bubble that would be a side effect that would cause them to be discredited which, if you actually believe such regulation is necessary for its stated purpose of safety, is not the outcome you’d want.\n\nIf the A.I. bubble were largely equity-financed, I’d leave things there. If it isn’t, though, we have to look at the financial regulatory side of the equation, because the way you get financial crises is when the banking system is threatened systemically by being over-leveraged to a financial asset that crashes. In the dot-com bubble, there was limited leverage deployed and limited banking system exposure. In the sub-prime mortgage bubble, by contrast, there was substantial leverage deployed, frequently in ways that were invisible to regulators. Which is the A.I. bubble more like?\n\nI would have guessed that it was more like the dot-com bubble, but this Noah Smith post convinced me that there might be invisible leverage to worry about. In a nutshell (you really should read the post if you are interested in the details), most of the financing of the high-flying tech companies is indeed in the form of equity, but a lot of the financing of data centers is done through asset-backed loans which are securitized and then insured. I don’t know anything about the models used for those securitizations, but the key component that can go wrong is the expected correlation between different assets in a pool. When an asset bubble bursts, that correlation can quickly get very high, and if that possibility isn’t properly built into the modeling (as it wasn’t with respect to sub-prime mortgages), then entities like banks and insurers who think they are holding negligible tail risk can suddenly face losses that are many multiples of what they could actually survive. And then you have a financial crisis.\n\nCould regulators do anything about this? Probably. The thing to focus on would be whether banks and insurance companies are adequately capitalized against the risks they are actually taking. If they aren’t, based on the regulator’s own assessment of the risk in the positions, you make them hold more capital. That’ll reduce the profitability of those positions, which will encourage the banks and insurers to unwind a portion, or at least not add more, which in turn would force data center builders to find other sources of financing. That, potentially, could burst the bubble, but it might not—A.I. companies might be able to keep going with more exotic but less systemically-threatening forms of equity financing—and if it did burst the bubble the regulatory move is sufficiently distant from the outcome that you might have a better chance politically of surviving than you would if you tried to burst the bubble directly by hiking rates or if you tried to do it indirectly by imposing A.I. safety regulations. Moreover, I suspect that if there’s a real problem growing in their portfolios, banks and insurers might themselves be quiet allies of a sensible regulatory effort. This is precisely the kind of situation where an industry will be unable to self-regulate even if it sees the potential for catastrophe, because competitive pressures will force all players to take advantage of lax regulation lest they lose market share, but the amount of profit at stake for the banks and insurers themselves can’t be anywhere near where it was in the subprime mortgage days, so we’re probably not at the point yet where that business is too big to be constrained. I’m too far away from finance these days to have anything like an informed opinion on how worried anybody should be, but if we should be worried specifically about the financial sector, there are likely things regulators could do to get ahead of the problem.\n\nBut I feel confident in saying that if there is indeed something to worry about, this administration is neither going to know nor take any action to address it. That fact should probably also figure into everyone’s assessment of how likely we are to be headed for trouble.",
      "source": "Substack.com",
      "url": "https://gideons.substack.com/p/are-we-in-an-ai-bubble-i-suspect",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Nvidia (NVDA) Equips GeForce Now with RTX 5080 Blackwell SuperPods",
      "content": "NVIDIA Corporation (NASDAQ:NVDA) is one of the best dividend stocks to buy. On September 13, Nvidia unveiled the latest GeForce Now enhancement, transitioning from RTX 4080 servers to Blackwell RTX 5080 SuperPods.\n\nThe chipmaker explained that Ultimate-tier users can expect faster speeds, reduced latency, and a bigger gaming catalog, all included without extra fees.\n\nNvidia (NVDA) Equips GeForce Now with RTX 5080 Blackwell SuperPods\n\nPhoto by Javier Esteban on Unsplash\n\nThe new Blackwell RTX 5080 SuperPods provide better visuals and smoother performance, given the DLSS 4 and AI upscaling. The company added that upcoming games such as DUNE: Awakening, Cronos: The New Dawn, and Clair Obscur: Expedition 33 will put the GPU’s strengths on display.\n\nBlackwell RTX servers are becoming available worldwide, allowing more members to access advanced streaming performance on many devices from PCs and Macs to Chromebooks, LG TVs, and Steam Decks.\n\nWhile we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: Dow 20 Stocks List: Ranked By Hedge Fund Bullishness Index and 10 Unstoppable Dividend Stocks to Buy Now.\n\nDisclosure. None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-nvda-equips-geforce-now-003725206.html",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "nvidia-nat-langchain 1.3.0a20250928",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-langchain/1.3.0a20250928/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Nvidia Hits an All-Time High After Striking a Deal with OpenAI. Is the \"Ten Titans\" Growth Stock a Buy?",
      "content": "Nvidia Hits an All-Time High After Striking a Deal with OpenAI. Is the \"Ten Titans\" Growth Stock a Buy?\n\nKey Points\n\n-\n\nNvidia's blockbuster deal with OpenAI reinforces its long-term investment thesis.\n\n-\n\nThe chip giant is well positioned to thrive even in the face of competition from…\n\nThis story appeared on finance.yahoo.com , 2025-09-28 22:34:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/ad05bf328e1e167f",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Apple, TSMC weigh potential investment in Intel",
      "content": "Intel is in early talks with Apple and TSMC on potential investment and cooperation, according to sources familiar with the matter. The discussions follow Intel’s recent funding wins, including $2 billion from SoftBank, $8.9 billion in US government subsidies, and $5 billion from NVIDIA. If Apple and TSMC join as investors, the move could provide a crucial boost to Intel’s revival plan. Apple is seen as a potential customer for Intel’s advanced packaging technology, while TSMC may strengthen production at Intel’s US plants through a possible joint venture. Talks remain preliminary, and it is unclear whether an agreement will be reached. [Reuters]\n\nRelated",
      "source": "TechNode",
      "url": "http://technode.com/2025/09/28/apple-tsmc-weigh-potential-investment-in-intel/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Applied Digital Corporation (APLD): A Bull Case Theory",
      "content": "We came across a bullish thesis on Applied Digital Corporation on Value investing subreddit by GloriousLebron. In this article, we will summarize the bulls’ thesis on APLD. Applied Digital Corporation's share was trading at $19.83 as of September 17th. APLD’s forward P/E was 526.32 according to Yahoo Finance.\n\nWestern Digital Corporation (NASDAQ:WDC) Positioned for Growth as AI Data Demand Surges, Analysts Maintain Outperform Rating with $85 Price Target\n\nApplied Digital (APLD) has rapidly transformed from a speculative small cap into a serious player in AI infrastructure, with its stock price surging from about $3 in April to nearly $20 today. The momentum is not mere market hype but underpinned by long-term contracts and a credible execution track record. Central to this story is CoreWeave, a fast-growing AI infrastructure company backed by NVIDIA, which signed two 15-year leases with APLD worth $7 billion.\n\nCoreWeave later expanded its commitment with another 150 MW lease, bringing the total to 400 MW and raising APLD’s backlog to approximately $11 billion in contracted revenue. This revenue stream is multi-year, locked in, and set to ramp as facilities come online. APLD has already demonstrated its ability to scale rapidly, constructing 480 MW in the past 18 months. Its current flagship project, Polaris Forge 1 in North Dakota, is a 400 MW facility with the first 100 MW expected to go live in Q4 2025, another 150 MW in mid-2026, and the final 150 MW in 2027.\n\nThe company also boasts a 1.4 GW future pipeline, supported by financing from Macquarie, highlighting its ability to expand aggressively. Efficiency is a competitive edge, with direct chip cooling developed in collaboration with Dell, low-cost energy supported by North Dakota’s favorable climate, and power usage effectiveness near 1.18, giving APLD a structural cost advantage.\n\nEnergy security is equally critical, and APLD has already locked in long-term renewable and utility contracts in Texas and North Dakota to support its data centers. With management signaling advanced negotiations with a major North American hyperscaler, additional contracts appear likely. Together, these elements make APLD one of the most compelling emerging plays on AI infrastructure buildout, offering investors exposure to a company with contracted revenue, secured energy supply, and a fast-expanding capacity pipeline.\n\nPreviously we covered a bullish thesis on Applied Digital Corporation (APLD) by DoU92 in December 2024, which highlighted the company’s pivot to AI-driven growth, rapid data center expansion, and scalable HPC infrastructure. The company's stock price has appreciated approximately by 108% since our coverage. The thesis still stands as long-term contracts and operational execution underpin growth. GloriousLebron shares a similar bullish view but emphasizes major CoreWeave leases, secured energy, and an aggressive buildout pipeline.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/applied-digital-corporation-apld-bull-154048309.html",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "PNY NVIDIA RTX PRO 6000 Blackwell Max-Q 96GB GDDR7 with ECC AI Accelerator Cards - RTX PRO 6000 Blackwell Max-Q $8299.99 (15 replies)",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18641941-pny-nvidia-rtx-pro-6000-blackwell-max-q-96gb-gddr7-with-ecc-ai-accelerator-cards-rtx-pro-6000-blackwell-max-q-8299-99",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "aiqtoolkit-langchain 1.3.0a20250928",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/aiqtoolkit-langchain/1.3.0a20250928/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Sen. Klobuchar: Now Is the Time to Address Healthcare Premium Subsidies",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/8a1208dfd9332b90",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "aiqtoolkit-crewai 1.3.0a20250928",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/aiqtoolkit-crewai/1.3.0a20250928/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "My Absolute Favorite Picks For The $4 Trillion AI Infrastructure Boom",
      "content": "Introduction\n\nDid you hear what NVIDIA Corporation’s (NVDA) founder and CEO, Jensen Huang, said the other day?\n\nAs reported by CNBC on September 22, the company plans to invest up to $100 billion in OpenAI as part\n\nDid you hear what NVIDIA Corporation’s (NVDA) founder and CEO, Jensen Huang,…\n\nThis story appeared on seekingalpha.com , 2025-09-28 11:30:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/abbaeaea98aa2278",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "5 ‘Fed-Friendly’ REITs Paying Up To 13%",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/brettowens/2025/09/28/5-fed-friendly-reits-paying-up-to-13/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "The 5 Best S&P 500 Stocks of the Last 10 Years",
      "content": "Key Points\n\n-\n\nShares of AI chip leader Nvidia have turned a $1,000 investment into $312,610 over the last decade.\n\n-\n\nShares of Nvidia competitor Advanced Micro Devices have turned a $1,000 investment into $93,250 over the last decade.\n\n-\n\nShares of cloud networking company Arista Networks…\n\nThis story appeared on finance.yahoo.com , 2025-09-28 22:00:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/672d482606988808",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Aussie AI Industry Demands Subsidies for Unspecified Reasons",
      "content": "Essay by Eric Worrall\n\n… The tech industry has been pushing the government to … subsidise AI processing power through multi-billion dollar deals …\n\nTech giants pitch data centres as climate saviours – not threats Ryan Cropp and Amelia McGuire\n\nSep 25, 2025 – 6.53pm … The substantial future energy demands of Australia’s nascent data centre industry were cited by the Climate Change Authority last week as a key “delivery risk” informing the lower end of its recommendation that the government target a 62 to 70 per cent cut in carbon emissions by 2035. … Push to subsidise AI processing power The tech industry has been pushing the government to follow the lead of the United Kingdom, the United Arab Emirates, Norway and others and subsidise AI processing power through multi-billion dollar deals with players including Nvidia and generative AI juggernaut OpenAI. Assistant Science Minister Andrew Charlton said on Wednesday the government was in the process of developing an AI and data centre strategy. … In February last year, US data centre giant Equinix signed an offtake agreement with the operator of the $3 billion Golden Plains Wind Farm in Victoria to ensure its power requirements were fully offset by renewable energy. … “When Google invests in data centres, it’s done in a way that creates additional new clean energy generation capacity on the grid, helping to support systems and enable investments needed to drive productivity and prosperity,” he said.\n\n\n\n… “We need to retire coal and gas over time, but you can’t have demand going up while supply goes down,” … Read more: https://www.afr.com/policy/energy-and-climate/tech-giants-pitch-data-centres-as-climate-saviours-not-threats-20250925-p5mxt6\n\nEveryone seems to be dancing carefully around explaining why Big Tech needs large subsidies to invest in Australia.\n\nI love the phrase the google representative used, “offset by renewable energy”. If they were planning to power the new data centers with renewables, they could have said “powered entirely by renewable energy”.\n\nExcept if the Aussie government caves to industry demands, it might not even be the likes of Google who will be paying for the useless new renewable energy plants. Perhaps the deal on offer is that the Aussie government has to pay for everything.\n\nIf the Aussie government pays an AI subsidy to big tech, who uses some of that subsidy to build renewable energy plants, that is functionally equivalent to the government giving much of that subsidy money directly to green energy companies, with one important exception.\n\nInstead of being a “green subsidy”, the money used to build those renewable plants can be described as an “AI subsidy”.\n\nThe government gets to shrink the embarrassment of having to openly give 10s of billions of dollars to the renewable industry, by claiming the corporate welfare is actually being used to build the future, to boost Australia’s AI capability.\n\nI mean, surely that can’t be the plan, can it? They surely wouldn’t be so sneaky and underhanded?\n\n5 8 votes Article Rating\n\nLike this: Like Loading...\n\nRelated",
      "source": "Wattsupwiththat.com",
      "url": "https://wattsupwiththat.com/2025/09/28/aussie-ai-industry-demands-subsidies-for-unspecified-reasons/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "nvidia-nat-mysql 1.3.0a20250928",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-mysql/1.3.0a20250928/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Can Labour reverse 'desperate loss of faith' from business?",
      "content": "Can Labour reverse 'desperate loss of faith' from business?\n\n7 days ago Share Save Simon Jack Business editor Share Save\n\nWPA Pool/Getty Images\n\nOne of the key audiences that the prime minister and the chancellor will have to convince at this year's Labour conference are the business leaders they targeted with a charm offensive before the election last July. The party trumpeted itself as \"the natural party of business\" and Rachel Reeves told anyone and everyone that this would be \"the most pro-business government this country has ever seen\". Labour had some big business beasts backing them. Billionaire mobile phone tycoon John Caudwell - a long-time Conservative supporter - switched his backing to Labour. Some 120 business leaders signed a letter which read: \"We, as leaders and investors in British business, believe that it is time for a change. For too long now, our economy has been beset by instability, stagnation, and a lack of long-term focus. \"Labour has shown it has changed and wants to work with business to achieve the UK's full economic potential.\" But post-election, the party sent a different message - warning of tough choices and hard times ahead, and delivered a Budget to prove it. That Budget, says John Caudwell, with its £25bn rise in employers' National Insurance, undid a lot of the goodwill the chancellor had garnered. \"I think there was a desperate loss of faith from the business community in general from the last Budget,\" he says. \"I think people were shocked at the level of negative components for businesses.\" On top of that NI rise, the National Living Wage was hiked by an inflation-busting 6.7%, with a rise of 16% for 18 to 20-year-olds. Mr Caudwell says he understands that Labour needed to raise money to shore up the public finances but felt it hit some sectors unduly hard. \"Even if you say they needed to be done, certain aspects were very unfair. So if you look at the increase in employers' NI, that really badly hit those businesses that employ tens of thousands of people on low wages, because they got hit by minimum wage and they got hit by the NI.\"\n\nPA John Caudwell says businesses were shocked at \"the level of negative components\" they faced after the last Budget\n\nOther small business owners have also told the BBC they have lost confidence. Rachel Carrell is the boss of childcare firm Koru Kids and signed that letter in 2024. She says she hopes the government can restore business confidence over the rest of the parliament. \"I wouldn't sign that letter today but they've got three or four years to turn this around. That's a really long time.\" She believes there's an opportunity to fix things in the upcoming Budget, but says \"they need to move quickly\". When is the Budget and what might be in it? While anecdotal evidence of crumbling business confidence is not hard to find, official measures show a mixed picture.\n\nThe Institute of Directors' confidence measure shows a steep fall after the last election, which compilers put down to immediate warnings issued by the government once in power that tough times and tough choices lay ahead. That was duly delivered on by the Budget and has hovered near those lows ever since. However, the government's favourite index to quote is the Lloyds Bank confidence survey, which shows confidence on the future is much more robust. Other measures, including the ICAEW and the S&P PMI measures, tend to support a more gloomy outlook. That in turn is supported by the number of businesses looking to recruit.\n\nJob vacancies have been on a downward trend since the Covid pandemic and there are 150,000 fewer staff on payrolls now than there were before the Budget bombshell, with a large part of those jobs going in hospitality. However, there is widespread hope among smaller businesses that the long-promised overhaul of business rates will come soon and in their favour.\n\nThe government points understandably to the enormous amounts of money pledged recently when tech royalty from Apple, Nvidia, Microsoft and others met real royalty at US President Donald Trump's recent state visit. John Caudwell welcomed it too. \"I hear a lot of negativity about government - we hear about rich people leaving and they are useful to the UK economy, but they're not as useful as the £150bn of inward investment that we've got coming into the country to create high-paid jobs in high-technological businesses. So we have to get a balanced view on that.\" Mark Brearley runs a trolley and tray manufacturing and export business in Peckham, south London. He is less impressed with the razzamatazz surrounding the tech billionaires and their largesse. \"I'm sure it's very important to get these racy high-growth sectors to invest here. But what about the less exciting bits of the economy - the ones who are always here? We feel forgotten. \"I was hopeful that a new government would give us some help but all my costs have gone up - my business rates have doubled. I'm more cautious about investing in a new machine, a new product, hiring a new person.\" The new Employment Rights Bill, which confers greater rights and protections on employees from day one, is also adding to employers' reluctance to take on new staff.\n\nMark Brearley says small businesses like his feel forgotten\n\nThe government has made much of its plans to sweep away impediments to economic growth and has seen that acknowledged by some of the biggest investors in UK infrastructure. Just months after Labour entered Downing Street, Scottish Power announced a £24bn UK investment. Keith Anderson, chief executive of Scottish Power, says: \"The government has taken on the planning bogeyman to unlock growth and get us building. That's why the UK is now Iberdrola's biggest investment destination globally.\" Rain Newton-Smith, director general of the employers group the CBI, also gives the government high marks on the international stage. \"I think this government have navigated really difficult geopolitics. We've got a better deal with the US than others, we're forging a closer relationship with Europe and they got the deal with India. \"They've got a lot of work done internationally, and that does count. But they've really got to dial up delivery, and make sure that they they learn from the mistakes of last autumn.\" Business confidence is a vital but fragile thing. It's a key ingredient for any government hoping that economic growth will pay for its other spending commitments - on heath, defence and welfare. Labour has a job on its hands at conference, and at the Budget, to restore the animal spirits of UK business.",
      "source": "BBC News",
      "url": "https://www.bbc.com/news/articles/cn0xyxnyz48o?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Bheadline%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "A list of notable shooting attacks on houses of worship in the US in the past 20 years",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/9af06462c34f35e5",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Who Can Beat Hyperliquid? Ex-NAGA Founder Bets On AI Coaching",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/boazsobrado/2025/09/28/who-can-beat-hyperliquid-ex-naga-founder-bets-on-ai-coaching/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Watch out: Soaring stocks could tip markets over",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/investing/stocks/watch-out-soaring-stocks-could-tip-markets-over",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "The billion-dollar infrastructure deals powering the AI boom",
      "content": "It takes a lot of computing power to run an AI product — and as the tech industry races to tap the power of AI models, there’s a parallel race underway to build the infrastructure that will power them. On a recent earnings call, Nvidia CEO Jensen Huang estimated that between $3 trillion…\n\nThis story appeared on techcrunch.com , 2025-09-28 21:18:08.720000.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/38484477d151838f",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Taiwan Must Help US to Make Half its Chips, Commerce Chief Says",
      "content": "Washington is demanding Taiwan move investment and chip production to the US so half of American demand is manufactured locally, outlining a radical shift for the global semiconductor industry.\n\nMost Read from Bloomberg\n\nThe US has held discussions about that with Taipei to reduce the risks of over-reliance, Commerce Secretary Howard Lutnick said in an interview with NewsNation. It was the only way to effectively counter Beijing’s threats to invade a self-ruled island it views as its own, Lutnick argued.\n\n“That’s been the conversation we had with Taiwan, that you have to understand it’s vital for you to have us produce 50%,” he said. The US aims to get to “maybe 50% market share of producing the chip and the wafers — the semiconductors — we need for American consumption. That’s our objective,” Lutnick said during the interview.\n\nUS officials have for years warned about an over-dependence on Taiwan Semiconductor Manufacturing Co. and its giant ecosystem of suppliers, which together make and supply the vast majority of the world’s most advanced chips. That risk emerged particularly during Covid-era shortages that highlighted how semiconductors fueled industries from car-making to military technology and AI.\n\nTSMC, the main chipmaker to Apple Inc. and Nvidia Corp., is one of the centerpieces of a US government effort to entice manufacturing back home.\n\nIt has pledged to invest $165 billion to ramp up production at its US sites. But shifting capacity en masse will require not just enormous capital but also the large-scale migration of scores of suppliers and partners that together comprise TSMC’s production chain.\n\nThe Wall Street Journal reported last week that Washington was weighing a broad plan to reduce its reliance on overseas semiconductors, saying companies must produce as many chips in America as they import from other sources or face additional tariffs. Lutnick didn’t elaborate in the NewsNation interview about how the US would convince Taipei to get behind his objective.\n\n“We’re still fundamentally reliant upon you because we can’t live without the other half,” Lutnick said. “It will shock everybody how successful we are.”\n\nMost Read from Bloomberg Businessweek\n\n©2025 Bloomberg L.P.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/taiwan-must-help-us-half-082254871.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "HP Spectre X360 16 Inch 2-in-1 Laptop w/ RTX 4050 GPU - $2208 @Hp.com.au (w/SB @12%)",
      "content": "on 29/09/2025 - 17:16Last edited 29/09/2025 - 21:06 by 3 other users\n\nSEP10\n\nHP Spectre x360 16 inch 2-in-1 Laptop 16-aa0009TX, Black\n\nIntel® Core™ Ultra 7 processor\n\nWindows 11 Pro\n\n16\" diagonal 2.8K OLED touch display with NVIDIA® GeForce RTX™ 4050\n\n32 GB LPDDR5x-6400 RAM\n\n1 TB SSD Hard Drive\n\nPoly Studio, Full-size, backlit keyboard, Fingerprint Reader, 9MP IR camera\n\nStarting at\n\n$3,099.00\n\nRough math - $4,299 RRP\n\nSale price - $3099 (current sell for this colour - other colours are still full price)\n\nCode - Sep10 for 10% off\n\nPay HP - $2789\n\nSB - 12% (ex gst value) on Spectre devices $2510 - $301 = $2208.88\n\n(*SB credit is as always, a bonus if credited. Never know with these guys anymore).\n\nThe title price should NOT include cashback (commission refunds) – mention this in the deal description only. — Mod\n\nFor the money - not a bad unit at all.\n\n*Model/SKU is confirmed as in the Spectre 12% list for SB.",
      "source": "Ozbargain.com.au",
      "url": "https://www.ozbargain.com.au/node/926240",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "This AI Chip Stock Just Got a New Street-High Price Target. Should You Buy It Here?",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/35096953/this-ai-chip-stock-just-got-a-new-street-high-price-target-should-you-buy-it-here",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "These Stocks Are Moving the Most Today: Occidental Petroleum, Tesla, Nvidia, Intel, Electronic Arts, Merus, and More",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/2c590b5fecf8b4fc",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "nvidia-nat-ingestion 1.3.0a20250929",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-ingestion/1.3.0a20250929/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Jensen Huang doesn’t care about Sam Altman’s AI hype fears: He thinks OpenAI will be the first ‘multitrillion-dollar hyperscale company’",
      "content": "Just as Open AI CEO Sam Altman and Meta leader Mark Zuckerberg begin acknowledging that there may be truth to the warnings of an AI bubble, Jensen Huang is doubling down on his bullishness.\n\n\n\nIn a recent podcast appearance with Bill Gurley and Brad Gerstner, the Nvidia CEO brushed aside the growing caution and instead zeroed in on the company he sees as the next dominant force: OpenAI.\n\n“OpenAI is very likely going to be the world’s next multitrillion-dollar hyperscale company,” Huang said.\n\nThat bold prediction comes at a moment when even AI’s loudest evangelists are warning of overvaluation and overbuilding. Altman himself has cautioned that too much money is flooding into unproven AI ventures, while Zuckerberg has compared today’s infrastructure frenzy to past bubbles. Yet Huang insists the skeptics are missing the deeper forces reshaping the economy. In his telling, the story comes down to basic physics, not hype.\n\n\n\n“General-purpose computing is over,” Huang said, describing what he sees as a generational shift in how all industries will run. “The future is accelerated computing and AI.”\n\nHe outlined what he calls the “three scaling laws” of AI—pretraining, post-training, and inference—each of which exponentially increases demand for compute. While training workloads have already been well-documented, Huang stressed that inference—the real-time reasoning that underpins everything from chatbots to recommendation algorithms—is only just beginning.\n\n“The longer you think, the better the answer you get—and thinking requires more compute,” he explained.\n\nThat framing matters because inference is where AI collides with day-to-day usage. Training runs happen in bursts, but inference happens constantly: Every chatbot prompt, every AI video render, every background algorithmic tweak consumes processing power. If Huang is right, that relentless demand means AI won’t follow the boom-and-bust cycles of earlier technologies but will instead drive a compounding need, one that will also boost Nvidia.\n\n$100 billion bet on OpenAI\n\nHuang’s comments came just days after Nvidia announced its most audacious deal yet: a $100 billion investment in OpenAI to help fund the company’s massive data center build-out. It’s the largest example of what analysts call Nvidia’s “circular financing” strategy, in which it invests in, or lends to, customers who in turn spend billions on Nvidia’s GPUs.\n\nTo Huang, it’s a smart way to align incentives with a once-in-a-generation partner scaling faster than any company in history. “If that’s the case, the opportunity to invest before they get there is one of the smartest investments we can imagine,” he said.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/jensen-huang-doesn-t-care-191831017.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Dow Jones Futures: Nvidia Stock, Palantir Eye Buy Points, But AI Names Broadcom, Oracle Fall",
      "content": "Dow Jones futures, along with S&P 500 futures and Nasdaq 100 futures, traded little changed ahead of Tuesday's open. Meanwhile, Nvidia (NVDA) and Palantir Technologies (NVDA) are approaching new buy points, but artificial intelligence stocks Broadcom (AVGO) and Oracle (ORCL) extended their recent declines on the stock market Monday. Nvidia stock rallied 2.1% Monday, closing just 1% away from a…",
      "source": "Investor's Business Daily",
      "url": "https://www.investors.com/market-trend/stock-market-today/dow-jones-sp500-nasdaq-nvidia-stock-nvda-palantir-broadcom-oracle/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "March-April Release of NVIDIA GeForce RTX 50-series SUPER Lineup, Possible CES Reveal",
      "content": "Tomorrow Predicting the future is a thankless job. If you get it right then they say you got lucky or \"even a broken clock is right twice a day\".\n\nIf you get it wrong then you're full of s***.\n\nThe 5070Ti Super not getting any additional cores seems like a bit of a waste. It already has 16GB VRAM which seems plenty for games for the likely useful lifespan of the 5070Ti. So Nvidia are proposing a 50W power draw increase and presumably a price bump for zero extra performance and more VRAM than it can realistically use - which to me seems like a very dumb and pointless product launch. Honestly, the most useful situation for these 24Gbit GDDR7 chips is to consolidate the 5060Ti into a single 12GB model rather than have the 8GB model which is short of VRAM and the 16GB model which is probably more than the 5060Ti will ever have the horsepower to use.There are 14 disabled SMs in the 5070Ti and presumably yields have improved over the year since the 50-series launch so maybe the 5070Ti could enable 4 more without cannibalising the 5080 any more than it already does? The 5070 Super gets 2 more SMs than the 5070 for just a 25W increase, and whilst 12GB is enough for 99% of scenarios right now, it is a limit that the 5070 can hit and you have to imagine that more games that push beyond 12GB are coming in the next few years. That doesn't mean I won't buy a 5070 12GB, but I'm unwilling to pay much more than the ~$500 discounted price for a GPU that's light on VRAM at the tail end of 2025.IMO he gets a lot of info from his contacts at AIB partners and distributors that is unique to his channel and proven to be accurate.He retcons stuff and he theorises too, but for all the hate he gets I still add him to my news list because it's often better and more based on hard evidence than a lot of the leaks and rumours going around at the same time.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341450/march-april-release-of-nvidia-geforce-rtx-50-series-super-lineup-possible-ces-reveal",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Micron Technology (MU)’s An Example Of The Good Thrown Out With The Bad, Says Jim Cramer",
      "content": "We recently published 15 Stocks Jim Cramer Mentioned As He Said Quantum Computing Worried Him. Micron Technology, Inc. (NASDAQ:MU) is one of the stocks Jim Cramer recently discussed.\n\nMicron Technology, Inc. (NASDAQ:MU) is one of Cramer’s favorite firms, particularly due to its CEO, Sanjay Mehrotra. The CNBC TV host has praised Krishna’s humility multiple times in 2025. Micron Technology, Inc. (NASDAQ:MU)’s shares have gained 80% year-to-date as the firm enjoys its position in the memory industry. Cramer discussed Micron Technology, Inc. (NASDAQ:MU)’s share price action after the firm’s latest earnings report:\n\n“Look at Micron yesterday. Micron had traded at 172 when it reported the number okay. On Tuesday night. And Micron’s looking at 157. The good ones are being thrown out with the bad.”\n\nAnalyst Highlights the Nvidia Link in Micron (MU) Business, Says It’s ‘The Most Important Takeaway’\n\nIn its fiscal fourth quarter earnings report, Micron Technology, Inc. (NASDAQ:MU) reported $11.3 billion in revenue and $3.03 in adjusted earnings per share. Both of these beat analyst estimates of $11.22 billion and $2.86. However, since the report, Micron Technology, Inc. (NASDAQ:MU)’s shares have lost 5.5%. Discussing the report in his Mad Money appearance later during the day, Cramer commented:\n\n“Coming into Micron’s earnings, I was wondering if the company could report anything that could justify the stock’s incredible run. You know what? That’s exactly what they did. After this Titanic quarter, I think Micron can keep running. I just hope we get more pullbacks like this so that you can buy it on weakness. Yes, the Micron quarter really was that good.”\n\nWhile we acknowledge the potential of MU as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/micron-technology-mu-example-good-212141249.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Broadcom and Nvidia Executives Cash Out Shares After Big Rally",
      "content": "This article first appeared on GuruFocus.\n\nExecutives at Broadcom (AVGO, Financials) and Nvidia (NVDA, Financials) are trimming their stakes after a blockbuster run for semiconductor stocks this year.\n\nFilings showed notable insider sales at both companies, though the names and exact amounts were not immediately detailed in Monday's report. The timing comes as Nvidia shares have surged more than 180% in 2025, while Broadcom is up over 60%, fueled by demand for chips powering artificial intelligence.\n\nInsider sales don't necessarily point to a shift in outlook they're often about executives diversifying portfolios or locking in gains. Still, investors pay attention to these moves, especially when they cluster around market highs.\n\nFor now, analysts say the bigger story is ongoing strength in earnings and orders across the semiconductor space. But with stocks at record levels, the insider trades add another data point for investors weighing whether the AI rally has more room to run.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/broadcom-nvidia-executives-cash-shares-163612199.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Jensen Huang doesn’t care about Sam Altman’s AI hype fears: he thinks OpenAI will be the first ‘multitrillion-dollar hyperscale company’",
      "content": "Just as Open AI CEO Sam Altman and Meta leader Mark Zuckerberg begin acknowledging that there may be truth to the warnings of an AI bubble, Jensen Huang is doubling down on his bullishness.\n\n\n\nIn a recent podcast appearance with Bill Gurley and Brad Gerstner, the Nvidia CEO brushed aside the growing caution and instead zeroed in on the company he sees as the next dominant force: OpenAI.\n\n“OpenAI is very likely going to be the world’s next multitrillion-dollar hyperscale company,” Huang said.\n\nThat bold prediction comes at a moment when even AI’s loudest evangelists are warning of overvaluation and overbuilding. Altman himself has cautioned that too much money is flooding into unproven AI ventures, while Zuckerberg has compared today’s infrastructure frenzy to past bubbles. Yet Huang insists the skeptics are missing the deeper forces reshaping the economy. In his telling, the story comes down to basic physics, not hype.\n\n\n\n“General-purpose computing is over,” Huang said, describing what he sees as a generational shift in how all industries will run. “The future is accelerated computing and AI.”\n\nHe outlined what he calls the “three scaling laws” of AI—pretraining, post-training, and inference—each of which exponentially increases demand for compute. While training workloads have already been well-documented, Huang stressed that inference—the real-time reasoning that underpins everything from chatbots to recommendation algorithms—is only just beginning.\n\n“The longer you think, the better the answer you get—and thinking requires more compute,” he explained.\n\nThat framing matters because inference is where AI collides with day-to-day usage. Training runs happen in bursts, but inference happens constantly: Every chatbot prompt, every AI video render, every background algorithmic tweak consumes processing power. If Huang is right, that relentless demand means AI won’t follow the boom-and-bust cycles of earlier technologies but will instead drive a compounding need, one that will also boost Nvidia.\n\n$100 billion bet on OpenAI\n\nHuang’s comments came just days after Nvidia announced its most audacious deal yet: a $100 billion investment in OpenAI to help fund the company’s massive data center build-out. It’s the largest example of what analysts call Nvidia’s “circular financing” strategy, in which it invests in, or lends to, customers who in turn spend billions on Nvidia’s GPUs.\n\nTo Huang, it’s a smart way to align incentives with a once-in-a-generation partner scaling faster than any company in history. “If that’s the case, the opportunity to invest before they get there is one of the smartest investments we can imagine,” he said.\n\nBut to markets, the sheer size of the commitment was jarring.\n\nDeutsche Bank had previously warned that 2025 could be remembered as “the summer AI turned ugly,” pointing to the risk that circular revenue-recognition games could inflate demand.\n\nDeutsche Bank analysts said Nvidia’s way of helping fund its own customers reminds them of past bubbles, when companies juiced sales by essentially paying buyers to buy their products.\n\nThey warned that even if these deals are only a small slice of revenue right now, Nvidia is so big that any slipup could shake the whole stock market.\n\nAs they put it, the stock is “priced for perfection,” which means there’s not much room for mistakes if AI growth cools off.\n\nThat tension helps explain why Altman, despite running Nvidia’s most important customer, has been publicly warning of “a frenzy of cash chasing anything labeled AI.”\n\nAnd Zuckerberg, while still pouring billions into Meta’s own AI ambitions, has likewise admitted the infrastructure build-out carries “bubble-like” characteristics reminiscent of railroads and the dotcom era. Even Federal Reserve Chair Jerome Powell has taken note, pointing to the “unusually large amounts of economic activity” flowing into AI, a rare signal that the froth is on the Fed’s radar.\n\nHuang remains unmoved. To him, these warnings miss the forest for the trees. He insists that Nvidia and OpenAI’s growth is propelled by scaling laws and performance per watt—fundamentals that make his company the only rational choice for hyperscalers.\n\n“This is the industrial revolution,” he told Gurley and Gerstner, a common refrain from Huang on the subject of AI.\n\nHuang also seemed to flip his stance on President Donald Trump’s recent $100,000 H-1B visa fee. He called the policy “a great start” for cracking down on visa abuse and illegal immigration, but cautioned that the steep price tag “probably sets the bar a little too high.”\n\nFor Huang, himself an immigrant, Trump’s fee may be a useful first step, but only if it’s paired with broader reforms that keep America attractive to top talent.",
      "source": "Fortune",
      "url": "https://fortune.com/2025/09/29/jensen-huang-not-afraid-of-ai-bubble-sam-altman-mark-zuckerberg/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Zero to Mastery: [September 2025] Python Monthly Newsletter ",
      "content": "Welcome to the 70th issue of Python Monthly!\n\nIf it’s your first time here, welcome, I like you already. If you want the full back story on this monthly newsletter, head here.\n\nThe quick version: I curate and share the most important Python articles, news, resources, podcasts, and videos.\n\nThink the Pareto Principle (80/20 rule) meeting the Python world. I give you the 20% that will get you 80% of the results.\n\nIf you're a long time reader, welcome back old friend.\n\nAlright, let's not waste any valuable time and jump right into this month's updates.\n\nHere's what you missed in September 2025 as a Python Developer…\n\nPython, The Documentary 🎬\n\nYes, there is a new Python documentary that just came out, and I don't have to tell you that if you're a Pythonista, you have to watch it. It is very well done.\n\nHere is a good follow up read after you watch the documentary.\n\nTop Programming Languages 2025 📺\n\nUsually these sort of articles are just clickbait trash, but this is one of the few places that gives good data and insight. You should check it out.\n\nAs expected Python comes first followed by JavaScript (if you combine it with TypeScript, which you should).\n\nDoes AI mean the end for the Top Programming Languages? Read the article and find out.\n\nP.S. In December or January, I'll update my own guide to help people decide which programming language they should learn (and why).\n\nPython Type Checkers 👨‍🏫\n\nType Checkers make a dynamic programming language like Python be a statically typed language (sort of). Ty, Pyrefly, and Zuban, are type checkers, but how good are they? Find out.\n\nBut why do we need Type Checkers? I recommend you read this too.\n\nFeature Flags 🎏\n\nFeature flags are a way for us to enable or disable code paths without needing to re-deploy software. Here is how to do it with Python.\n\nCustomizing Your Python REPL 🧰\n\nEveryone is talking about this one feature coming up in Python 3.14: the new syntax highlighting in the REPL!\n\nHere is a fun article to get you started to make that REPL fabulous.\n\nAI Coding Trap 🚧\n\nA must read.\n\nIf you ever watch someone “coding”, you might see them spending far more time staring into space than typing on their keyboard. No, they (probably) aren’t slacking off. Software development is fundamentally a practice of problem-solving, and so, as with solving a tricky crossword, most of the work is done in your head.\n\nNews Around the World 🗺\n\nChina announced an interesting law. The law requires explicit and implicit labels for AI-generated text, images, audio, video and other virtual content. What do you think, good move?\n\nAll good in the world, everyone is happy and getting along like usual.\n\nBig Tech News aka AI News 🏢\n\nNvidia's stake in Intel could have terrible consequences. First, it is in Nvidia's interest to kill Intel's Arc graphics, and that would be very bad because it is the only thing brighing GPU prices down for consumers. Second, the death of Intel graphics / Arc would be extremely bad for Linux, because Intel's approach to GPU drivers is the best for compatibility, wheras Nvidia is actively hostile to drivers on Linux. Third, Intel is the only company marketing consumer-grade graphics virtualization (SR-IOV), and the loss of that would make Nvidia's enterprise chips the only game in town, meaning the average consumer gets less performance, less flexibility, and less security on their computers.\n\nCompletely useless to your career but still great 🙃\n\nBest Resource of the Month 🥽\n\nBig O. It's an important concept that has lasted generations of trends and hype cycles. Every single good programmer knows about it and knows the importance of Big O.\n\nIf you've been lazy and haven't taken our ZTM course on the topic, this month's article will give you a great insight into the world of Big O. Once you master it, you will be a different type of programmer.\n\nCheck out this amazing article here.\n\nYou can also check out this free Big O cheat sheet with a Big O video tutorial to help you out as well.\n\nI have to add another one for this month. It's not tech related so it's why I'm putting it here, but I think everyone should read this once: Nine Things I Learned in Ninety Years.\n\nTrick of the Month 🎩\n\nMapSCII - The Whole World In Your Console. The best way to look like a true hacker in a coffeeshop.\n\nSee you next month everyone... also share this with your friends... pretty please! ❤️\n\nBy the way, I teach people how to code and get hired in the most efficient way possible as an Instructor at the Zero To Mastery Academy. You can see a few of our courses below or see all ZTM courses here.",
      "source": "Zerotomastery.io",
      "url": "https://zerotomastery.io/blog/python-monthly-newsletter-september-2025/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "'Much of the value creation in the semiconductor industry is occurring outside the EU' says EU member states, and they want a fresh plan to claw some chips back",
      "content": "A new declaration from all 27 EU member states lays out an \"urgent need\" for a new and improved EU Chips Act. Essentially, Europe feels like it's fallen behind in chip production and design, and it would like to see a concerted effort from the European Commission to regain ground.\n\n\"To secure and strengthen our global position,\" the declaration reads (via The Register), \"the EU must prioritize the semiconductor sector as a strategic industry, on par with aerospace and defence, and treat it as a key target for investment, R&D and innovation, and—if necessary—use the available instruments to protect it and act collectively.\n\n\"However, while global competitors are significantly ramping up public investment, much of the value creation in the semiconductor industry is occurring outside the EU,\" it continues. \"This underscores the need for a strengthened, second-phase EU Chips Act that is both ambitious and forward-looking.\"\n\nYou have to agree with the signatories here, which represent each of the countries within the EU today, that Europe has slipped up with chip production. An OECD report (PDF) on the semiconductor value chain shows how the largest exporters of chips tend to be in Asia, such as China, Korea, and Taiwan, with companies in the US making the most money from these chips, as per this Semiconductor Industry Association report.\n\nEurope does have a place at the table with big firms such as Dutch company ASML, which builds most of the world's cutting-edge semiconductor manufacturing machines. There are also companies such as Infinion, Europe's largest chip manufacturer, and Arm, thought the latter was previously sold and since listed on a stock exchange outside of Europe. Though this 2020 report from the Semiconductor Industry Association suggests the EU only makes up for 9% of global manufacturing capacity—lower than some individual countries such as Taiwan (22%), South Korea (21%) and Japan (15%). It also suggests this share will decrease by 2030 to 8%.\n\nDutch company ASML leads in EUV lithographic machinery. (Image credit: ASML)\n\nAs the declaration rightly points out, when you're depending on semiconductors for \"enabling necessary societal transitions\", you sort of want to be in a good place to produce the ones you require, especially as global trade and relationships can be so easily fractured.\n\nHere's what the report suggests should be the objectives of a revised EU Chips Act:\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nProsperity: enabling a competitive European semiconductor ecosystem that enhances Europe's economic and broad welfare and value creation across end-markets. Indispensability: maintain and develop Europe’s technological and innovation leadership to secure critical control points in the global semiconductor value chain. Resilience: secure a stable and reliable supply of trustworthy semiconductors for Europe’s most critical sectors, particularly in times of global disruption or geopolitical uncertainty.\n\nYep, that all checks out. What self-respecting country or country bloc wouldn't want these things? That's the issue here, it's not what you say, it's how you do it. And competing in the highly-competitive world of semiconductors, especially when you're already behind the times, is going to be excruciatingly tough going.\n\nThis is the revised Chips Act, so what happened to the original one?\n\nThat's still very much in play, operating to increase the EU share in the \"global market value chain by revenue\" to 20% by 2030. The big issue is how realistic the act is. Right now, the EU is expected to be around 11.4% by 2030, as laid out in this report on the EU's digital transition. This being so unrealistic is one of the main causes for concern at the original Chips Act, as noted in a special report by the European Court of Auditors, who suggest the target may have been \"overly ambitious\".\n\nIntel's now cancelled megafab facility, which was set to be built in Magdeburg, Germany. (Image credit: Intel Corporation)\n\n\"We recommend that the Commission carries out an urgent reality check and swiftly begins preparing the next strategy,\" the special report published in April says.\n\nThe EU has opened a public consultation on the Chips Act, too, asking for evidence to review the effectiveness of the act.\n\nWell, these many reports won't do very much on their own. The original, surprisingly lightweight declaration suggests a few key topics for a future revision to the Chips Act. Here's the quick version:\n\nCollaboration between industries, supporting tech champions, and fast-tracked legislation.\n\nPublic and private investment and cross-industry collaboration, including quantum and AI fields.\n\nSupporting skilled workers.\n\nSupporting the green transition and clean energy.\n\nFoster global collaboration.\n\nThere are some fine details in there on specific programs for skilled workers or funding programmes, though most represent points that I think anyone with a half-decent idea of semiconductors would also end up with if tasked with a plan of action for Europe. That's not to say it's ineffective, as it's clearly a signal of intent with powerful backers (every EU member state, don't forget), but the real question remains: how much money is the EU prepared to spend on this?\n\nThe US rolled out its own CHIPS and Science Act back in 2022 under the Biden administration, which invested roughly a couple hundred billion dollars into US chipmaking and research. That has ended up being tweaked by the current president, Donald Trump, as he used funds previously awarded to Intel under the act to buy shares in the business instead. This deal struck with Intel's new CEO, Lip-Bu Tan, who also canned the company's planned European megafab, which was a big part of Europe's optimistic push into more domestic semiconductor manufacturing. Intel still operates a big fab facility in Ireland.\n\nThe Trump administration has also pushed Nvidia and AMD into deals relating to their China business, and pushed chip designers (so-called fabless companies) to buy more of their chips from US manufacturing than foreign fabs. You can see the difference between carrot and stick here, right? China also recently rolled out similar measures to block local firms from buying up foreign-made tech, including Nvidia's purpose-made and only very recently green-lit AI chips.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/much-of-the-value-creation-in-the-semiconductor-industry-is-occurring-outside-the-eu-says-eu-member-states-and-they-want-a-fresh-plan-to-claw-some-chips-back/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Advancing Anomaly Detection for Industry Applications with NVIDIA NV-Tesseract-AD",
      "content": "In a recent blog post, we introduced NVIDIA NV-Tesseract, a family of models designed to unify anomaly detection, classification, and forecasting within a single framework. That work demonstrated the promise of tackling diverse time-series problems with a shared, general-purpose backbone.\n\nNVIDIA NV-Tesseract-AD builds on this foundation but takes a more specialized path. Rather than relying only on transformers, it introduces diffusion modeling, stabilized through curriculum learning, and pairs it with adaptive thresholding methods in a model purpose-built for anomaly detection. Together, these elements address some of the most challenging issues in the field: noisy, high-dimensional signals that drift over time and contain rare, irregular events.\n\nEqually important, NV-Tesseract-AD represents an evolution, not a reset. The first version of the model was confined to univariate datasets and often faltered in the presence of noise. Version 2.0 expands the architecture to handle multivariate inputs, uses curriculum schedules for reliable training, and incorporates adaptive thresholds to deliver greater robustness in real-world settings.\n\nWhy anomaly detection needs a rethink\n\nAnomaly detection seems obvious: find ‌unusual points in a data stream. But anyone who has worked with real-world time series knows it’s one of the most frustratingly complex problems in data science.\n\nThe challenge begins with non-stationarity. Few signals ever sit still. Semiconductor sensors drift as machines wear down. Patient vitals fluctuate in response to circadian rhythms, meals, and physical activity. Spacecraft telemetry looks completely different depending on whether a rover is cruising, drilling, or idling. Cloud KPIs surge during traffic spikes, fall quiet at night, and spike again during batch jobs. What appears anomalous at one moment may be entirely normal the next.\n\nThen there’s noise and sparsity. Labels are rare and often unreliable. Ground-truth anomalies are expensive to capture. Operators can only label what they observe, and even domain experts may disagree on whether a fluctuation is a real fault or just natural variability. Many datasets are littered with false positives or miss the very failures we hope to detect.\n\nFor example, in nuclear power plants, thousands of sensors continuously track reactor pressure, coolant flow, and core temperature. Genuine anomalies—such as a small coolant leak or an early-stage pump failure—are rare, and a subtle pressure fluctuation might be dismissed as routine noise. If misclassified, it could conceal the early stages of a cascading failure that poses a threat to reactor safety.\n\nSituations like this show a broader challenge across industries: sparse and unreliable labels make supervised learning prone to overfitting on a small, noisy dataset while overlooking critical patterns hidden in vast amounts of unlabeled data.\n\nThese problems became evident when NV-Tesseract-AD 1.0 was tested on public machine learning datasets, such as Genesis and Calit2. Both are notoriously noisy and sparsely labeled. Version 1.0, trained only on univariate signals, produced trivial detections or failed outright. What looked promising in toy settings crumbled when faced with the messiness of real-world data.\n\nKey insights:\n\nTraditional statistical methods assume stability and collapse under drift or regime change.\n\nEven deep learning models falter when data is noisy, labels are sparse, or distributions shift.\n\nGenerative methods, and especially diffusion models, open a new path by learning the manifold of “normal” behavior itself.\n\nDiffusion models for time series\n\nGenerative diffusion models were originally designed for images, but their underlying principle maps elegantly to time series. Instead of reconstructing a signal in one shot, diffusion models gradually corrupt data with noise and then learn to reverse the process step by step. The result is a model that captures fine-grained temporal structure and can scale to hundreds or thousands of correlated signals (see arXiv:2508.06638 for methodological details, patent pending).\n\nThis iterative refinement is powerful. Subtle deviations—like a micro-variation in a patient’s heartbeat or a slight drift in a satellite’s battery voltage—are clear when the model learns the manifold of “normal” trajectories. Signals that can’t be denoised smoothly stand out as anomalies, not because they trip a hard threshold, but because they break the underlying structure of the data.\n\nBut diffusion comes with its own fragility. If training begins with tasks that are too complex, like fully corrupted signals or high masking ratios, the model may collapse into trivial reconstructions or fail to converge. NV-Tesseract-AD addresses this challenge with curriculum learning. Early training epochs focus on lightly corrupted inputs, where denoising is straightforward. Over time, ‌noise and masking are gradually increased, forcing the model to master increasingly complex reconstructions.\n\nThis “easy-to-hard” progression stabilizes training, reduces variance in outcomes, and produces models that generalize more effectively once deployed. In practice, curriculum learning has been the difference between fragile experiments and systems that can handle the unpredictability of production data.\n\nFigure 1. Curriculum training schedule in NV-Tesseract-AD\n\nSegmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments\n\nDiffusion models generate anomaly scores. But those scores still need thresholds to drive decisions, and thresholds are often the weakest link. Static cutoffs fail when signals drift, as manufacturing tools recalibrate, patients transition from rest to activity, and networks fluctuate between peak and off-peak demand. In such environments, global thresholds either miss real anomalies or generate false alarms that overwhelm operators.\n\nTo address this, NVIDIA researchers developed two patent-pending methods—Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence Segments (MACS). Both are unsupervised, model-agnostic, and grounded in confidence interval theory, making them interpretable and broadly applicable beyond NV-Tesseract-AD. These methods are part of the inference process, specifically during the threshold-setting stage of the anomaly detection pipeline, where they determine when a deviation should be considered significant.\n\nSCS divides the time series into locally stable regimes, each with its own statistical baseline. Confidence bounds adapt within each regime, ensuring sensitivity where it’s needed and restraint where natural variance is high.\n\nFigure 2. Segmented thresholds adapt to new regimes by establishing local statistical bounds\n\nMACS examines data through short-, medium-, and long-term windows simultaneously. An attention mechanism weighs the most relevant scale, while a dual-detection rule reduces the number of spurious alerts. This allows MACS to capture quick bursts and gradual drifts without requiring separate detectors.\n\nFigure 3. Multi-scale thresholds capture anomalies that appear as quick bursts, gradual drifts, or overlapping patterns.\n\nTogether, SCS and MACS strike a balance that has long eluded anomaly detection: sensitive enough to catch subtle faults, yet disciplined enough to avoid overwhelming operators with noise.\n\nKey insights:\n\nSCS adapts thresholds to locally stable regimes, improving recall while controlling false alarms.\n\nadapts thresholds to locally stable regimes, improving recall while controlling false alarms. MACS views data at multiple timescales, capturing both bursts and drifts with fewer spurious alerts.\n\nviews data at multiple timescales, capturing both bursts and drifts with fewer spurious alerts. Both are patent-pending NVIDIA innovations, unsupervised and interpretable, with applications beyond NV-Tesseract-AD.\n\nFrom evaluations to real-world impact\n\nOur evaluations weren’t about topping leaderboards. The question we asked was simpler: what happens when you apply diffusion techniques and adaptive thresholds to noisy, multivariate datasets?\n\nAs mentioned earlier, in our tests on the Genesis and Calit2 public datasets, the difference between the versions was stark. Version 1.0 produced trivial results or nothing at all. But version 2.0, with diffusion and adaptive thresholds, could separate actual structure from noise, surfacing anomalies that aligned with irregularities previously invisible to the system. The key difference wasn’t just accuracy, but also robustness: it maintained performance even under the very noise and sparsity that crippled older approaches.\n\nThat resilience translates directly into real-world situations. In healthcare, the problem isn’t the absence of anomalies but the flood of false alarms. Clinicians in an ICU can’t act on every minor fluctuation in vital signs. What they need is a system that learns patient-specific baselines, dynamically adapts thresholds, and surfaces only the deviations that matter. NV-Tesseract-AD demonstrates how this approach can reduce nuisance alerts, build clinician trust, and expedite responses when a genuine anomaly arises.\n\nIn aerospace, telemetry encompasses thousands of channels that vary significantly across different phases of a mission. A static threshold may swamp operators with alerts when a spacecraft changes mode, or worse, miss the subtle drift that precedes a critical failure. By combining diffusion modeling with adaptive thresholds, NV-Tesseract-AD shows how anomaly detection can distinguish between expected regime shifts and true anomalies—surfacing signals, such as unexpected torque variations in a rover wheel, before they become mission-ending.\n\nIn cloud operations, reliability hinges on monitoring a vast array of metrics, where both sudden spikes and long-term trends are crucial. Operators don’t just need alerts—they need alerts they can trust. Multi-scale thresholds allow NV-Tesseract-AD to flag a rapid burst of API errors without confusing it for a longer-term drift, or to catch a creeping memory leak that static thresholds would miss. The result is faster incident response and less noise in the dashboards that engineers depend on.\n\nKey insights:\n\nEvaluations on noisy datasets, such as Genesis and Calit2, show how diffusion with thresholds outperforms v1.0.\n\nReal-world impact lies in reducing false alarms in healthcare, distinguishing regime shifts in aerospace, and filtering noise in cloud operations.\n\nThe framework shows resilience to noise and drift, a prerequisite for trust in mission-critical settings.\n\n\n\nA promising direction for the next generation of anomaly detection\n\nAnomaly detection has always been one of AI’s most persistent challenges. Static rules fail in the face of drift, and even advanced deep learning models collapse in noisy, high-dimensional environments. NV-Tesseract-AD represents a shift in approach, combining diffusion modeling, curriculum learning, adaptive thresholds, and careful design refinements into a framework for developing more intelligent anomaly detection across industries.\n\nOur evaluations show that when diffusion and adaptive thresholds are applied, anomaly detection systems become more resilient to noise, more capable of handling multivariate complexity, and more trustworthy in the eyes of operators. While broader evaluations and refinements are still ongoing, ‌work to date suggests a promising direction for developing the next generation of anomaly detection systems.\n\nGet started with NV-Tesseract-AD\n\nNV-Tesseract-AD will be available initially through a customer preview under an evaluation license, offering a first look at its advanced time-series modeling capabilities. Users can bring their own datasets, run diffusion-based anomaly detection with curriculum learning and adaptive thresholds, and adjust detection sensitivity to meet their needs. The system scales seamlessly from proof of concept to exploratory production trials and integrates into existing MLOps pipelines and detection methods.\n\nContact the NVIDIA DGX Cloud team to schedule a demo, discuss your time-series requirements, and explore how NV-Tesseract-AD can become a cornerstone of your anomaly detection workflow.\n\nAttending SEMICON West Oct 7-9, 2025? Check out our session, “Time Series modeling for Smart Manufacturing & Predictive Maintenance” on Thursday, October 9.",
      "source": "Nvidia.com",
      "url": "https://developer.nvidia.com/blog/advancing-anomaly-detection-for-industry-applications-with-nvidia-nv-tesseract-ad/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "\"They're nanoseconds behind us\" — NVIDIA's CEO sounds alarm on China's AI rise and questions US chip strategy",
      "content": "NVIDIA CEO Jensen Huang believes China's AI is only \"nanoseconds behind\" US technology.\n\nThe AI race between the US and China could be closer than any of us expected, at least according to NVIDIA CEO Jensen Huang.\n\nHuang, whose company supplies most of the world with specialized GPUs for AI, was a recent guest on the Bg2 podcast (via Tom's Hardware), where he spoke with the hosts about NVIDIA's ever-changing role in the Chinese AI landscape.\n\nHuang called China \"formidable, innovative, fast-moving, and underregulated,\" before busting a few myths he often hears about the country that poses the largest threat to NVIDIA's AI dominance.\n\nRegarding the myth that China could never build its own AI chips — \"That just sounded insane.\" Regarding the myth that China can't manufacture — \"If there's one thing they can do, it's manufacture.\"\n\nAnd, perhaps most consequential in the scope of global AI domination, Huang busts the myth that China is years behind the US.\n\nThey're years behind us. Is it two years? Three years? Come on. They're nanoseconds behind us. And so we've got to go compete. Jensen Huang, NVIDIA CEO\n\nNVIDIA has been a significant part of China's tech market for 35 years, and Huang offers some insights as to how it has so quickly caught up to the US. \"Don't forget that China has some of the best STEM schools in the world,\" says Huang, before mentioning China's culture and how it has shaped the Chinese workforce.\n\n\"They're the most hungry in the world,\" states Huang, referring to China's \"9AM until 9PM, 6 days a week\" working culture.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nChina, NVIDIA, and the US — the ever-changing AI landscape\n\nNVIDIA CEO Jensen Huang speaking at the White House as President Trump looks on. (Image credit: Getty Images)\n\nNVIDIA hasn't had an easy time of late getting its AI chips into China.\n\nThe company was banned from selling its H20 AI GPUs — essentially nerfed versions of US tech designed specifically to get around Biden-era restrictions — to China in April 2025 by the Trump administration.\n\nAfter some lobbying by Huang, it was announced in July 2025 that NVIDIA was once again free to sell its H20 GPUs in Chinese markets.\n\nMassive demand caused projected H20 chip shortages just weeks after the ban was lifted, but security concerns from Chinese officials who urged domestic firms not to buy NVIDIA's H20 put a damper on the enthusiasm.\n\nRegardless of China's unofficial stance, NVIDIA still needed to finalize export licenses through the US government.\n\nIn an unprecedented move, it was announced in August that NVIDIA and AMD had reached a deal that would see 15% of revenue from AI chip sales to China go back to the US government.\n\nAs part of the announcement, President Trump doubled down on his insistence that the H20 isn't competitive.\n\nThe H20 is obsolete. [...] So I said, 'Listen, I want 20% if I'm going to approve this for you, for the country. US President Donald Trump\n\nSecurity concerns and the ongoing rhetoric surrounding the NVIDIA chips designed specifically for Chinese markets have, of course, muddied the situation.\n\nIn September, I reported on the Cyberspace Administration of China (CAC) banning its top tech companies, including ByteDance and Alibaba, from buying and testing NVIDIA's new RTX Pro 6000D AI GPU, another chip tuned down for Chinese markets.\n\nChinese regulators then announced that it was investigating NVIDIA for antitrust violations related to its acquisition of chip designer Mellanox in 2020.\n\nHuawei's three-year plan to best NVIDIA's AI chips\n\nHuawei's logo visible on the company's headquarters building. (Image credit: Getty Images | Cheng Xin)\n\nChina's Huawei is leading the way in terms of domestic competition with NVIDIA's AI chips, and the company recently detailed a three-year plan to overtake NVIDIA's dominance in China (via Bloomberg).\n\nHuawei's next generation of Ascend AI chips will operate within a \"SuperPod\" design, which will allow for up to 15,488 chips to be linked together using new \"UnifiedBus\" technology.\n\nHuawei claims that this tech is up to 62 times faster than NVIDIA's next NVLink144 solution. NVIDIA's current NVLink72 tech can connect up to 72 Blackwell GPUs and 32 Grace CPUs, so it seems clear that Huawei is going for victory through massive numbers rather than finesse.\n\nWith these Huawei chips designed from the start for China's AI software stack, NVIDIA must be feeling the heat as it attempts to claw back what was once a 95% market share.\n\nRegardless, NVIDIA's CEO remains unfazed by China's growing AI competition, and in fact seems to encourage its growth.\n\nWe have a competitive relationship with China. We should acknowledge that China, rightfully, should want their companies to do well. I don't for a second begrudge them for that. They should do well. They should give them as much support as they like. It's all their prerogative. Jensen Huang, NVIDIA CEO\n\nIn the Bg2 interview, Huang also expresses some frustration with the current rules and regulations affecting NVIDIA's ability to compete around the world. Speaking in terms of the tech industry as a whole, Huang says:\n\nWe have to acknowledge it is our national treasure. It is our best industry. It is our single best industry. Why would we not allow this industry to go compete for its survival? For this industry to go and proliferate the technology around the world, so that we could have the world built on top of American technology.\n\nNVIDIA, of course, only stands to gain from a stable partnership with China, and this isn't the first time that Huang has expressed these same sentiments.\n\nWhile NVIDIA continues to hold sway with Chinese AI firms for now, Huawei's progress over the next three years will certainly be interesting to watch.\n\nFollow Windows Central on Google News to keep our latest news, insights, and features at the top of your feeds!",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/nvidia/nvidia-ceo-china-nanoseconds-behind-ai",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Huawei to Double Output of Top AI Chip",
      "content": "There are no important events for this country at this time. Select \"All\" to see top events in other countries or view all events.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/huawei-double-output-top-ai-182923525.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Day trading is about to get a lot easier for beginners. Things could get ugly",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/f49f8a4ad1c41739",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Expect Sharp Corrections Before Bitcoin Reclaims New Highs – Lessons from Nvidia",
      "content": null,
      "source": "newsBTC",
      "url": "http://www.newsbtc.com/news/expect-sharp-corrections-before-bitcoin-reclaims-new-highs-lessons-from-nvidia/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "NVIDIA Corporation $NVDA is Bouvel Investment Partners LLC’s 3rd Largest Position",
      "content": "Bouvel Investment Partners LLC lifted its holdings in NVIDIA Corporation (NASDAQ:NVDA – Free Report) by 3.2% in the 2nd quarter, Holdings Channel.com reports. The firm owned 76,961 shares of the computer hardware maker’s stock after purchasing an additional 2,408 shares during the quarter. NVIDIA comprises about 4.1% of Bouvel Investment Partners LLC’s holdings, making the stock its 3rd biggest position. Bouvel Investment Partners LLC’s holdings in NVIDIA were worth $12,159,000 as of its most recent SEC filing.\n\nSeveral other institutional investors and hedge funds have also recently modified their holdings of the business. Meriwether Wealth & Planning LLC increased its stake in shares of NVIDIA by 1.9% in the 2nd quarter. Meriwether Wealth & Planning LLC now owns 7,721 shares of the computer hardware maker’s stock valued at $1,220,000 after purchasing an additional 145 shares in the last quarter. Hilltop Wealth Advisors LLC increased its stake in NVIDIA by 25.0% during the 2nd quarter. Hilltop Wealth Advisors LLC now owns 8,337 shares of the computer hardware maker’s stock worth $1,317,000 after buying an additional 1,665 shares in the last quarter. First PREMIER Bank increased its stake in NVIDIA by 27.6% during the 2nd quarter. First PREMIER Bank now owns 15,431 shares of the computer hardware maker’s stock worth $2,438,000 after buying an additional 3,340 shares in the last quarter. Mallini Complete Financial Planning LLC purchased a new stake in NVIDIA during the 2nd quarter worth approximately $234,000. Finally, Kaufman Rossin Wealth LLC increased its stake in NVIDIA by 3.3% during the 2nd quarter. Kaufman Rossin Wealth LLC now owns 11,444 shares of the computer hardware maker’s stock worth $1,808,000 after buying an additional 368 shares in the last quarter. Hedge funds and other institutional investors own 65.27% of the company’s stock.\n\nGet NVIDIA alerts:\n\nWall Street Analysts Forecast Growth\n\nSeveral equities research analysts have commented on the company. KeyCorp reiterated an “overweight” rating and set a $230.00 price objective (up from $215.00) on shares of NVIDIA in a research note on Thursday, August 28th. Stifel Nicolaus boosted their price objective on NVIDIA from $202.00 to $212.00 and gave the stock a “buy” rating in a research note on Monday, August 25th. Wolfe Research boosted their price objective on NVIDIA from $220.00 to $230.00 in a research note on Tuesday, September 23rd. DA Davidson upgraded NVIDIA from a “neutral” rating to a “buy” rating and boosted their price objective for the stock from $195.00 to $210.00 in a research note on Thursday, September 11th. Finally, BNP Paribas upgraded NVIDIA to a “hold” rating in a research note on Friday, August 1st. Four analysts have rated the stock with a Strong Buy rating, thirty-six have issued a Buy rating, four have assigned a Hold rating and one has issued a Sell rating to the stock. According to MarketBeat.com, the company has a consensus rating of “Moderate Buy” and a consensus price target of $209.82.\n\nInsiders Place Their Bets\n\nIn related news, CEO Jen Hsun Huang sold 75,000 shares of the stock in a transaction on Wednesday, September 24th. The stock was sold at an average price of $177.60, for a total value of $13,320,000.00. Following the transaction, the chief executive officer owned 71,458,203 shares of the company’s stock, valued at $12,690,976,852.80. This represents a 0.10% decrease in their ownership of the stock. The transaction was disclosed in a filing with the SEC, which is available through this hyperlink. Also, CFO Colette Kress sold 30,500 shares of the stock in a transaction on Friday, September 19th. The shares were sold at an average price of $176.40, for a total value of $5,380,200.00. Following the completion of the transaction, the chief financial officer directly owned 2,883,402 shares in the company, valued at $508,632,112.80. This trade represents a 1.05% decrease in their position. The disclosure for this sale can be found here. In the last 90 days, insiders sold 4,050,558 shares of company stock valued at $701,164,609. 4.17% of the stock is owned by company insiders.\n\nNVIDIA Stock Up 0.3%\n\nNASDAQ:NVDA opened at $178.19 on Monday. The company has a quick ratio of 3.60, a current ratio of 4.21 and a debt-to-equity ratio of 0.08. The stock’s fifty day moving average is $176.60 and its two-hundred day moving average is $146.20. NVIDIA Corporation has a 52 week low of $86.62 and a 52 week high of $184.55. The stock has a market capitalization of $4.33 trillion, a price-to-earnings ratio of 50.77, a price-to-earnings-growth ratio of 1.29 and a beta of 2.10.\n\nNVIDIA (NASDAQ:NVDA – Get Free Report) last announced its quarterly earnings data on Wednesday, August 27th. The computer hardware maker reported $1.05 earnings per share (EPS) for the quarter, beating the consensus estimate of $1.01 by $0.04. The business had revenue of $46.74 billion for the quarter, compared to analysts’ expectations of $45.65 billion. NVIDIA had a return on equity of 101.74% and a net margin of 52.41%.The company’s revenue for the quarter was up 55.6% compared to the same quarter last year. During the same period last year, the firm earned $0.68 earnings per share. NVIDIA has set its Q3 2026 guidance at EPS. Research analysts anticipate that NVIDIA Corporation will post 2.77 EPS for the current year.\n\nNVIDIA Announces Dividend\n\nThe business also recently disclosed a quarterly dividend, which will be paid on Thursday, October 2nd. Stockholders of record on Thursday, September 11th will be paid a $0.01 dividend. This represents a $0.04 annualized dividend and a dividend yield of 0.0%. The ex-dividend date is Thursday, September 11th. NVIDIA’s dividend payout ratio (DPR) is presently 1.14%.\n\nAbout NVIDIA\n\n(Free Report)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nFeatured Stories\n\nWant to see what other hedge funds are holding NVDA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for NVIDIA Corporation (NASDAQ:NVDA – Free Report).\n\nReceive News & Ratings for NVIDIA Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for NVIDIA and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/29/nvidia-corporation-nvda-is-bouvel-investment-partners-llcs-3rd-largest-position/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Jensen Huang Fires Back At Wall Street 'Flatlining' Nvidia Forecasts, Says AI Demand Will Crush Long-Term Expectations",
      "content": "Benzinga and Yahoo Finance LLC may earn commission or revenue on some items through the links below.\n\nChipmaker Nvidia Corp.’s (NASDAQ: NVDA) CEO Jensen Huang pushed back against Wall Street's long-term outlook for the company, saying analysts are underestimating the scale of artificial intelligence demand.\n\nDismisses Wall Street Forecasts\n\nOn last week's Open Source podcast, Huang was asked about Wall Street consensus from 25 analysts projecting Nvidia's growth \"flatlining\" after 2027. He said he had no issue with those forecasts but argued they fail to capture the scale of AI adoption that is now underway.\n\nDuring the podcast, Huang said, “We're comfortable with that,” adding that his company has “no trouble beating the numbers on a regular basis.”\n\nTrending: If there was a new fund backed by Jeff Bezos offering a 7-9% target yield with monthly dividends would you invest in it?\n\nHe described a “massive divergence of belief” between what AI leaders like OpenAI's Sam Altman and Microsoft Corp.'s (NASDAQ: MSFT) Satya Nadella are projecting and what Wall Street models assume. “Our opportunity, as I described it, is much larger than the consensus,” he said.\n\nHuang pointed to what he called “two exponentials” driving compute requirements, that is, the rapid increase in the number of users engaging with AI tools, followed by the exponential growth in compute needed per user as models move from one-shot inference to reasoning.\n\n“Until we fully convert all general-purpose computing to accelerated computing and AI... the chances [of a glut] are extremely low,” he said.\n\nSee Also: 7 Million Gamers Already Trust Gameflip With Their Digital Assets — Now You Can Own a Stake in the Platform\n\nHuang Defends $100 Billion OpenAI Investment\n\nOn the podcast, Huang defended his decision to invest $100 billion in OpenAI, calling it “some of the smartest investments we can possibly imagine.”\n\nHuang said, “OpenAI is likely going to be the world’s next multi-trillion-dollar hyperscale company,” adding that Nvidia will be working with the company “at the chip level, at the software level, at the systems level, at the AI factory level” to help build and operate its AI infrastructure.\n\nThis comes amid growing investor concerns that the company was creating a “circular” investment loop by investing in OpenAI, which would in turn acquire chips from Nvidia.\n\nImage via Shutterstock\n\nTrending Now:",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/jensen-huang-fires-back-wall-233144150.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "This is the world's smallest eGPU dock with a built-in 650W PSU - but I'm not sure I'd be comfortable with my $1,999 Geforce RTX 5090 GPU exposed to the elements",
      "content": "NXPort eGPU integrates 650W power in a small dock\n\nThunderbolt and USB4 connections may bottleneck even the most powerful GPUs\n\nOpen-frame design leaves components vulnerable to damage\n\nThe pursuit of transforming business laptops into desktop-grade powerhouses has long relied on external GPU enclosures.\n\nTraditional solutions have often been bulky, cumbersome, and required separate power supplies or complex assembly.\n\nNXPort claims to be the “world’s smallest eGPU dock,” promising 650W of integrated power in a palm-sized form factor measuring 169mm x 102mm x 82mm.\n\nCompact form, big questions\n\nThe central claim of NXPort is that it houses a built-in power supply within a tiny, open-frame chassis.\n\nOn paper, this allows compatibility with nearly all consumer-grade GPUs and simplifies connectivity by supporting Thunderbolt 3/4/5 or USB4.\n\nHowever, a compact, exposed design introduces concerns about heat management and physical protection.\n\nExpensive components, including GPUs like the $1,999 GeForce RTX 5090, would sit exposed to dust, accidental contact, and variable cooling conditions.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe device meets the ATX 3.1 spec for stable power delivery, but real-world performance under sustained load is unverified, leaving potential users cautious about long-term reliability.\n\nThe company presents NXPort as a plug-and-play solution that can greatly improve GPU performance.\n\nIn the company’s tests, pairing a budget laptop with an Nvidia RTX 4060 reportedly produced a “6X Gaming Benchmark” improvement.\n\nThe dock is also described as suitable for intensive creative workloads and AI model training, capable of handling tasks requiring “thousands of parallel operations.”\n\nYet, it is important to note that performance may be limited by the bandwidth of Thunderbolt or USB4 connections.\n\nThis could restrict the throughput of high-end graphics cards despite the dock’s internal power.\n\nThe dock also supports GPUs with various power connectors, including 12V-2x6, 8-pin, dual 8-pin, triple 8-pin, and quad 8-pin (12VHPWR).\n\nThis provides flexibility for future upgrades without enclosure limitations.\n\nAlthough NXPort claims to be the “world’s smallest eGPU dock,” its 1.3kg weight is well above that of the GDP G1, a former smallest, which weighs only 867g.\n\nThe company states that the device is budget-friendly, as an NXPort paired with an RTX 3050 costs $459 ($239 for the base dock + $220 for the GPU).\n\nCompared with $1,599 for a laptop featuring a similar RTX 4050 GPU, this offers a cost-efficient way to achieve desktop-level graphics without replacing the existing laptop.\n\nThe NXPort project is currently listed on Kickstarter, where it has raised $57,618 from 211 backers, surpassing its $3,856 goal.\n\nWith 21 days remaining in the campaign, the funding trajectory suggests strong early interest, although the final product has yet to reach backers for independent evaluation.\n\nDisclaimer: We do not recommend or endorse any crowdfunding project. All crowdfunding campaigns carry inherent risks, including the possibility of delays, changes, or non-delivery of products. Potential backers should carefully evaluate the details and proceed at their own discretion.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/this-is-the-worlds-smallest-egpu-dock-with-a-built-in-650w-psu-i-am-not-sure-that-id-be-comfortable-with-my-usd1-999-geforce-rtx-5090-gpu-exposed-to-the-elements",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "nvidia-nat-ragaai 1.3.0a20250930",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-ragaai/1.3.0a20250930/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "UiPath announces collaboration with Nvidia",
      "content": "We use cookies to improve user experience, and analyze website traffic.\n\nFor these reasons, we may share your site usage data with our analytics partners. By clicking \"Accept Cookies\" you consent to store on your device all the technologies described in our Cookie Policy.",
      "source": "Thefly.com",
      "url": "https://thefly.com/permalinks/entry.php/id4205203/PATH;NVDA-UiPath-announces-collaboration-with-Nvidia",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Nvidia (NVDA) Stock Trades Up, Here Is Why",
      "content": "What Happened?\n\nShares of leading designer of graphics chips Nvidia (NASDAQ:NVDA) jumped 2.3% in the afternoon session after several Wall Street firms raised their price targets on the stock and reports surfaced of a major deal involving its advanced AI systems.\n\nThe positive sentiment was fueled by a reported deal where cloud provider CoreWeave agreed to supply Meta Platforms with up to $14.2 billion in AI computing power using Nvidia's latest GB300 systems. This agreement highlighted the immense and sustained demand for AI infrastructure from major tech companies. Further boosting investor confidence, several financial firms, including KeyBanc, Barclays, and Citi, increased their price targets for Nvidia. Analysts pointed to an improving supply of key components and strong, continued spending in the AI sector as the primary reasons for their optimistic outlook, which helped push the stock to a record high.\n\nAfter the initial pop the shares cooled down to $186.21, up 2.4% from previous close.\n\nIs now the time to buy Nvidia? Access our full analysis report here, it’s free.\n\nWhat Is The Market Telling Us\n\nNvidia’s shares are quite volatile and have had 18 moves greater than 5% over the last year. In that context, today’s move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.\n\nThe previous big move we wrote about was 8 days ago when the stock gained 4.1% on the news that the company announced a partnership with OpenAI that included plans for a potential investment of up to $100 billion.\n\nThe deal aimed to supply OpenAI with advanced AI hardware for its next generation of AI models and the buildout of massive data centers. According to the announcement, the partnership involved deploying at least 10 gigawatts of Nvidia's systems for OpenAI's AI infrastructure. This news solidified Nvidia's central role in the future of artificial intelligence.\n\nNvidia is up 34.6% since the beginning of the year, and at $186.21 per share, has set a new 52-week high. Investors who bought $1,000 worth of Nvidia’s shares 5 years ago would now be looking at an investment worth $13,762.\n\nUnless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-nvda-stock-trades-why-185050056.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "NVIDIA Corporation (NVDA) and OpenAI Forge $100B Partnership to Power Next-Gen AI Systems",
      "content": "We recently compiled a list of the 12 Best Stocks to Own for Grandchildren. NVIDIA Corporation is one of them.\n\nNVIDIA Corporation (NASDAQ:NVDA) tops our list for being one of the best stocks to buy . It continues to dominate the AI and data center markets with groundbreaking developments in September 2025. The company posted second-quarter fiscal 2026 revenue of $46.7 billion, a 56% year-over-year increase, driven by strong demand for its Blackwell Data Center products, which grew 17% sequentially. CEO Jensen Huang described the Blackwell AI platform as a “generational leap” in infrastructure, with production scaling quickly to meet demand from advanced reasoning AI models.\n\nA major highlight this month is NVDA’s strategic partnership with OpenAI, involving up to $100 billion in investment and a commitment to supply advanced data center chips for next-generation AI systems. This alliance strengthens the firm’s central role in the AI ecosystem and significantly expands its long-term market potential. In addition, the company announced a $5 billion investment in Intel stock, with plans to co-develop custom AI infrastructure for data centers and PCs, aiming at a $50 billion market opportunity.\n\nNVIDIA Corporation (NVDA) and OpenAI Forge $100B Partnership to Power Next-Gen AI Systems\n\nNVIDIA Corporation (NASDAQ:NVDA) also introduced Rubin CPX, a new GPU designed to handle massive-context inference tasks, enabling million-token coding and generative video at unprecedented speed and efficiency. This innovation supports its vision of transforming data centers into fully integrated “AI factories.”\n\nWhile we acknowledge the potential of NVDA as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy NOW\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-corporation-nvda-openai-forge-164802201.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "nvidia-nat-phoenix 1.3.0a20250930",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-phoenix/1.3.0a20250930/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Analyst Highlights the Nvidia Link in Micron (MU) Business, Says It’s ‘The Most Important Takeaway’",
      "content": "We recently published 10 Buzzing Tech and AI Stocks Everyone’s Talking About. Micron Technology Inc. (NASDAQ:MU) is one of the stocks analysts were recently talking about.\n\nMehdi Hosseini, senior equity research analyst at Susquehanna, said in a latest program on CNBC that Nvidia “has to buy” from Micron, and this places the memory company in a strong position in terms of pricing power.\n\n“I think the most important takeaway here, which I don’t think Sanjay (Micron CEO) is going to elaborate on a live interview, is who is actually doing a lot of buying. Unlike prior cycles, which were driven by distributors and the OEMs and ODMs, this cycle it is Nvidia, it is AMD, it is Broadcom that are actually doing the buying. And when you look at the AI, what Nvidia charges, which is about 80% of the AI server, the majority of that is going towards memory. So it is Nvidia that has to buy from Micron Technology Inc (NASDAQ:MU), and this is what gives Sanjay pricing power. The future of AI compute requires advanced memory, and that’s where the premium comes in, which is why this cycle is sustainable throughout 2016 and may even sustain into 2027.”\n\nPhoto by L N on Unsplash\n\nParnassus Investments, an investment management firm that focuses on owning a concentrated portfolio of U.S. large-cap stocks, released its Parnassus Value Equity Fund second-quarter 2025 investor letter. Here is what they have to say about Micron Technology Inc. (NASDAQ:MU) in their investor letter:\n\n“Micron Technology Inc. (NASDAQ:MU) shares advanced due to the company’s strong position in the AI-driven memory market. Management noted robust demand in its latest quarter.”\n\nWhile we acknowledge the potential of MU as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/analyst-highlights-nvidia-micron-mu-120746683.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "nvidia-nat-weave 1.3.0rc1",
      "content": "For more information about the NVIDIA NeMo Agent toolkit, please visit the NeMo Agent toolkit GitHub Repo .\n\nThis is a subpackage for Weights and Biases Weave integration for observability.\n\nDownload files\n\nDownload the file for your platform. If you're not sure which to choose, learn more about installing packages.\n\nSource Distributions\n\nNo source distribution files available for this release.See tutorial on generating distribution archives\n\nBuilt Distribution\n\nFilter files by name, interpreter, ABI, and platform.\n\nIf you're not sure about the file name format, learn more about wheel file names.\n\nThe dropdown lists show the available interpreters, ABIs, and platforms. Enable javascript to be able to filter the list of wheel files.\n\nCopy a direct link to the current filters Copy",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/nvidia-nat-weave/1.3.0rc1/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "NVIDIA Releases Battlefield 6 GeForce Game Ready Driver",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/nvidia-releases-battlefield-6-geforce-game-ready-driver/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Why Nvidia-Backed CoreWeave's Stock Is Soaring Today",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_c5b65ded-72b7-44dd-b549-03674f027e35",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Jim Cramer Shares Very Important Analysis About Oracle Corporation (ORCL)",
      "content": "We recently published 15 Stocks Jim Cramer Mentioned As He Said Quantum Computing Worried Him. Oracle Corporation (NYSE:ORCL) is one of the stocks Jim Cramer recently discussed.\n\nOracle Corporation (NYSE:ORCL) has been the talk of the town recently after it revealed a whopping $455 billion in cloud backlog as part of its fiscal first quarter earnings release. In this episde, Cramer critically evaluated the announcement:\n\nJim Cramer Shares Very Important Analysis About Oracle Corporation (ORCL)\n\n“[On shares being down at open] Well Oracle is the fundament of what happened. That was the, that was the straw because everybody else had been self funding. You know because cash flow, Mark Zuckerberg had a cash flow, Google had a cash flow. And suddenly Oracle comes in. Where are they going to get all the money? Well they’re going to get it from OpenAI, but where’s OpenAI going to get all the money? They’re going to get it from NVIDIA. . .\n\nWhile we acknowledge the potential of ORCL as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/jim-cramer-shares-very-important-174234413.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Ambitious Wee Beastie Project Aims To Put Desktop NVIDIA RTX 4070 GPU Into 4.75 L Chassis",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/ambitious-wee-beastie-project-aims-to-put-desktop-nvidia-rtx-4070-gpu-into-4-75-l-chassis/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "AMD Dense Geometry Format (DGF) Aims to Increase Visual Detail with Future GPUs",
      "content": "Visible Noise Nine months after Nvidia ships a feature, AMD produces a paper about their equivalent, and btw it doesn’t work with any of their existing products. Looks like 90XX is a dead end product.\n\nVisible Noise Why are people so surprised and angry at Nvidia’s success?\n\nVisible Noise They literally have no competition. Nvidia is still delivering features years ahead of AMD.\n\nHecate91 As usual Nvidia fans whine that AMD cards don't have a proprietary to Nvidia feature, then whine anyways when AMD develops something similar because they've never bought an AMD and never have any intention to do anything but mindlessly bash the brand.\n\nAnyway unless the feature does something groundbreaking then it's just another optional feature, I wouldn't expect this to make RDNA4 cards obsolete, and perhaps it could be processed at a driver level or on existing hardware.\n\nNvidia shipped Ray Tracing, it wasn't supported on GTX cards. They shipped MFG, it's not supported on cards prior to RTX50. You don't consider GeForce a dead end lineup, do you ?Because Nvidia is using their success to push their agenda of making the entire planet dependent on their dogshit AI tech that nobody neither wants nor needs.100% AI generated raster ? Miss me with that shit.The latest AMD has been on an Nvidia feature is Ray Reconstruction/Redstone and they barely have a full year of latency on this.Also, I'd like to point out that if you read the article a little bit closer, AMD's tech seems to be better since hitting broader, not just RT perf.And since if could run on raster, it would be hardware agnostic instead of vendor locked.I noticed that so far, when AMD follows, they might be later on delivery, but they follow with better.I'm curious about that \"potential performance hit\" mentioned on the article, how much of a hit are we talking about ? How much variance in outcome can we expect ? How is it behaving at different resolutions and different tiers of details complexity ? Is it hardware agnostic ? How would it run on other brands of cards ?I gotta say, I'm looking forward to this, even if if looks to be hardware dependent to get the intended performance, it kinda sounds like a new \"FSR moment\" to me when they make something that just works for everyone and improves X or Y factor.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341494/amd-dense-geometry-format-dgf-aims-to-increase-visual-detail-with-future-gpus",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Microsoft Corporation (MSFT): A Bull Case Theory",
      "content": "We came across a bullish thesis on Microsoft Corporation on The Edge of Power’s Substack. In this article, we will summarize the bulls’ thesis on MSFT. Microsoft Corporation's share was trading at $507.03 as of September 25th. MSFT’s trailing and forward P/E were 37.17 and 32.79 respectively according to Yahoo Finance.\n\ndennizn/Shutterstock.com\n\nMicrosoft’s AI strategy is transforming it into a critical global infrastructure player, with investments and partnerships positioning it far beyond a conventional software vendor. The adoption of Microsoft Copilot by the U.S. House of Representatives illustrates this shift, as AI moves from a productivity tool to essential infrastructure capable of supporting state-scale operations. Globally, Microsoft is deploying more than $56 billion in AI-focused projects, including sovereign cloud regions and supercomputing hubs in the U.K., Norway, and the U.S., with total CapEx for fiscal 2025 expected to approach $80 billion.\n\nThese initiatives combine renewable energy, GPU clusters, and strategic partnerships, creating a distributed, resilient infrastructure network that spans continents and aligns with sovereign priorities. In the Middle East, alliances with G42 in the UAE and sovereign cloud regions in Saudi Arabia extend Microsoft’s influence into fast-growing AI markets, effectively tying its growth to politically aligned, capital-rich projects and providing a strategic counterweight to Chinese technology influence. Despite this scale, the market has largely overlooked Microsoft’s moves, favoring smaller, unprofitable AI players.\n\nThe company’s embedded presence in government, sovereign partnerships, and global cloud infrastructure provides durable pricing power and revenue visibility, supporting a potential stock valuation of $600 by year-end. Beyond commercial returns, Microsoft’s investments represent soft power, shaping AI adoption, digital infrastructure, and geopolitical influence, while enabling NVIDIA and other tech partners to thrive.\n\nWith unmatched scale, innovation leadership, and embeddedness across governments and enterprises, Microsoft is building the global rails of the AI economy, offering long-term, resilient upside for investors and anchoring portfolios in a way smaller startups cannot replicate. Its global AI infrastructure positions the company as a quasi-state actor, securing both technological and strategic advantage for decades.\n\nPreviously we covered a bullish thesis on Microsoft Corporation (MSFT) by Ray Myers in May 2025, which highlighted the company’s strong enterprise software position, cloud growth via Azure, gaming expansion, and AI integration. The stock has appreciated approximately 11.9% since our coverage. The thesis still stands as Microsoft’s fundamentals remain robust. The Edge of Power shares a similar view but emphasizes Microsoft’s global AI infrastructure and geopolitical influence.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/microsoft-corporation-msft-bull-case-144323663.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "New York firm faces China investigation over $17M advanced trading hardware smuggling — accused of installing customized processors and networking hardware at Shanghai Futures Exchange",
      "content": "Tower Research Capital, a New York-based high-frequency trading (HFT) firm, is under fire by Chinese authorities for allegedly smuggling high-tech hardware into the country for the purpose of using it in the Shanghai Futures Exchange (SHFE). The report comes by way of Financial Times, which notes the Chinese customs authorities are determining whether Tower installed illicit \"customized processors and networking hardware\" that didn't match its customs declaration.\n\nTower allegedly brought in $17 million worth of hardware into the country. Although the hardware hasn't been seized, the authority handling the case has instructed Tower not to remove any of it from the SHFE server room until the investigation is concluded. Should the allegations ring true, Tower could face \"significant fines\" and even criminal charges.\n\nHigh-frequency trading is automated and algorithm-based, and reliant on highly specialized FPGAs and ASICs to do millisecond-quick (or even sub-millisecond) trades. HFT firms go as far as designing their own network cards and software stacks, complementing the operating systems' functionality or bypassing it entirely.\n\nTaking the recent U.S. hardware export controls into context, it may seem odd that China itself would be raising an eyebrow against advanced hardware going into the country, but there's a logical reason. The Shanghai Futures Exchange reportedly only allows \"certified brokers\" to connect directly to its servers, therefore bypassing precious milliseconds in network latency if they were located farther away.\n\nIf Tower employed customized hardware that's faster than expected, that would be seen as a no-no by the SHFE, as the regulatory agency apparently wants an even playing field among all traders. This move comes after the Chinese market regulator announced \"comprehensive and systematic regulation\" after a big market sell-off in 2024.\n\nThe regulation makes sense in theory, but the Financial Times remarks that \"people familiar\" with the Chinese HFT market state that firms have been abusing a legal loophole by rolling their own custom servers and installing them under the name of approved Chinese brokers.\n\nThe report contains no information on exactly what type of hardware is involved in this story, but the recently introduced U.S. export controls cover not just high-end Nvidia GPUs, but all sorts of high-end FPGAs, ASICs, even HBM and standard Intel and AMD processors. It's not hard to imagine that $17 million worth of highly optimized servers have one, multiple, or all of the aforementioned bits of silicon.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/new-york-firm-faces-china-investigation-over-usd17m-advanced-trading-hardware-smuggling-accused-of-installing-customized-processors-and-networking-hardware-at-shanghai-futures-exchange",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Big Tech's AI Spending—and Borrowing—Will Be Even Higher Next Year, Says Citi",
      "content": "Key Takeaways Citigroup analysts on Tuesday forecast hyperscalers would spend even more on AI infrastructure next year than previously expected.\n\nThe AI data center buildout is increasingly being financed by debt rather than cash flows, an evolution that exposes the AI boom to new vulnerabilities like default and interest rate risk.\n\nOther financing methods, like the investment agreement announced by OpenAI and Nvidia last week, have worried some onlookers fearful of an AI bubble.\n\nAfter a series of big cloud computing deals this month, Citigroup analysts now expect AI spending to exceed their already eye-watering forecast.\n\nCiti analysts on Tuesday estimated that hyperscalers—including Microsoft (MSFT), Alphabet (GOOG), Amazon (AMZN), Oracle (ORCL), and CoreWeave (CRWV)—will spend $490 billion on infrastructure and other capital goods next year, up from a prior estimate of $420 billion. Citi’s forecasts are slightly above the Wall Street consensus.\n\nWhy This Matters To You The AI infrastructure boom has been a major force behind U.S. stock market gains and economic growth in recent years. If tech companies rely on debt to fund their massive AI investments, they could expose the AI buildout—and the broader economy—to greater risk.\n\nThe analysts pointed to an onslaught of announced partnerships, investments, and products in recent weeks as evidence of strong AI demand. They said their recent conversations with CIOs and CTOs at a range of companies “reflect a similar increase in urgency around adoption at the enterprise level.”\n\nCiti expects AI infrastructure providers like Nvidia (NVDA) to benefit from higher spending. As such, the firm’s analysts raised their price target on Nvidia shares to $210 from $200 on Tuesday.\n\n\n\nDebt, Not Cash Flows, May Fund Future Spending\n\nThe hyperscalers are among the world’s largest, most profitable companies, a fact that has enabled them to increase their infrastructure spending exponentially over the past few years. But not even hugely profitable tech giants can undertake this level of investment on their own.\n\n“It is notable that we have gone from the cash flow funded stage of this investment cycle to the debt funded stage, with the incremental risks that come with it,” Citi’s analysts wrote.\n\nOracle last week sold $18 billion of bonds in the second-largest U.S. debt deal this year, according to a Bloomberg report. Oracle, which has spent more than it's made in each of the last two quarters, is expected to use the debt to increase its cloud capacity so it can deliver on a five-year, $300 billion deal with OpenAI. Adding that much capacity will be expensive. Citi sees Oracle’s capital expenditures ballooning to $58 billion in fiscal year 2027, nearly three times what it spent in the fiscal year that ended in May.\n\nOpenAI, another company that will need to spend a lot to support its ambitions, took a different approach to raising money. Last week, the company struck a deal with Nvidia to deploy 10 GW of Nvidia systems over the next five years in exchange for an incremental $100 billion equity investment. OpenAI is reportedly discussing leasing—not buying—the chips from Nvidia, a novel arrangement that could cut its hardware costs by 10 to 15%, according to The Information.\n\nThe deal raised eyebrows on Wall Street, where some analysts and investors expressed concern about the “circularity” and concentration of the AI ecosystem. Some skeptics likened it to a bailout, with Nvidia stepping in as an investor of last resort to support a cash-starved OpenAI. It has also inspired comparisons to the Dotcom Bubble, when telecom equipment providers lent to and invested in their own customers, fueling speculative fervor.\n\nBut analysts see important differences between the 1990s and today. “The critical distinction, in our view, is the ‘off-ramp’ created by growing external demand for AI services driven by enterprise adoption,” write Citi analysts.\n\nCompanies like OpenAI and Meta (META), they say, are rolling out AI-driven applications and services with clear monetization prospects. And the rate of AI’s technological progress, they argue, is quickly expanding the scope of potential applications.",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/big-tech-s-ai-spending-and-borrowing-will-be-even-higher-next-year-says-citi-11821812",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "CoreWeave Extends Hot Streak With Meta's $14 Billion Cloud Deal",
      "content": "CoreWeave Inc. (NASDAQ:CRWV) surged after it disclosed in a regulatory filing that it has entered into a multibillion-dollar agreement with Meta Platforms Inc. (NASDAQ:META) for cloud computing capacity valued at up to $14.2 billion.\n\nAccording to an 8-K filing with the SEC, the agreement was executed on September 25 under the companies' existing Master Services Agreement, effective as of December 2023.\n\nMeta has committed to payments of approximately $14.2 billion through December 14, 2031, with the option to significantly expand the order through 2032.\n\nAlso Read: CoreWeave Expands Agreement With OpenAI To Train Next-Gen Models\n\nCoreWeave will provide reserved capacity orders, subject to delivery and service availability requirements. The agreement includes provisions for termination, indemnification, and limitations of liability.\n\nThe company determined that the Master Services Agreement qualifies as a material definitive agreement under SEC rules. It will remain effective until all orders are fulfilled, expired, or terminated in accordance with its terms.\n\nPart Of Larger Growth Push\n\nThe new contract builds on CoreWeave's rapid expansion in 2025 as demand for artificial intelligence infrastructure accelerates.\n\nEarlier this year, the company announced a $6.3 billion arrangement with Nvidia (NASDAQ:NVDA) to purchase unused cloud capacity through 2032.\n\nIt also expanded its agreement with OpenAI by up to $6.5 billion, in addition to an earlier $11.9 billion commitment.\n\nSince its March IPO, CoreWeave's shares have more than tripled, lifted by contracts with Microsoft (NASDAQ:MSFT), Nvidia, OpenAI, and now Meta. However, trading has been volatile.\n\nIn August, insiders sold shares as lock-up restrictions expired, even as institutional investors added positions. Analysts tracked by Benzinga list price forecasts ranging widely, from below current levels to as high as $200 per share, with consensus near $127.\n\nPrice Action: CRWV shares were trading higher by 15.20% to $141.14 at last check Tuesday. META was down 1.53%.\n\nRead Next:\n\nPhoto by T. Schneider via Shutterstock\n\nUp Next: Transform your trading with Benzinga Edge's one-of-a-kind market trade ideas and tools. Click now to access unique insights that can set you ahead in today's competitive market.\n\nGet the latest stock analysis from Benzinga?\n\nThis article CoreWeave Extends Hot Streak With Meta's $14 Billion Cloud Deal originally appeared on Benzinga.com\n\n© 2025 Benzinga.com. Benzinga does not provide investment advice. All rights reserved.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/coreweave-extends-hot-streak-metas-135527689.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Here's How IonQ is Paving its Profitability Path in the Quantum Race",
      "content": "IonQ’s IONQ path to profitability is anchored by both strong revenue performance and strategic capital allocation. In the last-reported second quarter of 2025, the company’s revenues surpassed the high end of the guidance by 15%, demonstrating the ability to accelerate project implementation with existing customers. Its substantial $1 billion equity investment, coupled with pro forma cash and investments of $1.6 billion, provides a solid financial foundation to fund ongoing research, acquisitions and global expansion without immediate pressure to achieve near-term profitability. These resources also enable IonQ to execute on its ambitious roadmap for scaling quantum computing capacity while maintaining operational flexibility.\n\nA primary pillar of IonQ’s profitability strategy is its accelerated technology roadmap, enhanced by acquisitions and strategic partnerships. The acquisitions of Oxford Ionics, Lightsynq and Capella position the company to achieve 800 logical qubits by 2027 and 80,000 logical qubits by 2030. These milestones, combined with Lightsynq’s photonic interconnect technology and Capella’s space-based quantum networking capabilities, allow IonQ to target scalable, cost-efficient quantum computing systems with low unit costs, providing a clear pathway to attractive unit economics once large-scale deployment is achieved.\n\nIonQ is also building a diversified commercial ecosystem to drive recurring revenue streams. Collaborations with global organizations, such as AstraZeneca, AWS, NVIDIA, Oak Ridge National Laboratory and the U.S. Department of Energy, highlight practical applications where IonQ’s quantum systems provide measurable advantages, including a 20x speed-up in drug development workflows. In addition, the development of production-grade Quantum Key Distribution (QKD) networks, used by governments, financial institutions and telecoms, establishes a parallel revenue engine from quantum networking.\n\nWith its vertical integration, experience in trapped-ion technology and a patent portfolio of over 1,000, IonQ is well-positioned to sustain competitive advantage as it scales its quantum and networking businesses worldwide.\n\nIONQ’s Peer Update\n\nRigetti RGTI: Technologically, Rigetti is advancing superconducting gate-based hardware via its chiplet architecture, with a 36-qubit system available and a 100+ qubit system at 99.5% two-qubit fidelity expected by year-end 2025. This leaves the company well-positioned to scale while retaining optionality for partnerships or acquisitions.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/heres-ionq-paving-profitability-path-133000725.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Nvidia gets a price target hike from Citi on AI infrastructure growth, OpenAI deal",
      "content": "Nvidia is poised for further upside as it ramps up initiatives to improve artificial intelligence infrastructure, including new products and partnerships, according to Citi. The investment bank, which has a buy rating on shares, raised its price target for Nvidia to $210 from $200,…\n\nThis story appeared on cnbc.com , 2025-09-30 18:21:37.273000.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/981a6324990c4c0b",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "(PR) Tight Upstream Supply and Restocking Drive 2024 DRAM Module Revenue Growth of 7%",
      "content": "TrendForce reports that following the completion of inventory digestion in the downstream consumer market concluded at the end of Q4 2023, DRAM suppliers shifted focus towards HBM and server DDR5 products, leading to tighter supply for other DRAM types. This increase in demand pushed overall DRAM prices higher, encouraging module manufacturers to replenish stocks and boost procurement. Consequently, the global DRAM module market achieved USD 13.3 billion in revenue in 2024, a 7% YoY increase that reversed the 28% decline experienced in 2023.In the latter half of 2024, demand momentum declined due to rising module prices. Module manufacturers struggled to transfer these high chip costs to distribution channels, limiting sales. To stay competitive, some aimed to enhance costs structure by increasing their purchase of cheaper server reball chips.TrendForce observes that, with the overall market recovering in 2024, most module manufacturers experienced year-over-year revenue growth. However, the extent of growth differed depending on target markets and operational strategies.In 2024, the leading five DRAM module manufacturers captured 81% of the total global revenue, with the top eight accounting for 83%. Kingston retained a strong 66% market share, maintaining its leading position. However, its revenue growth was slower compared to competitors, due to weaker demand in the consumer segment during the second half of 2024. Kingston remained focused on its high-end brand image, emphasizing profitability.ADATA utilized inexpensive inventory accumulated during the 2Q23-3Q23 rebound, aggressively increasing shipments in the first half of 2024. This approach contributed to a 20% rise in revenue, earning it the second spot in the global rankings.Kimtigo actively broadened its domestic and international channels, leveraging the 2H23 rebound to capitalize on recovery opportunities and projecting a 10% revenue increase in 2024.Team Group concentrated on the gaming market, increasing its presence in North American e-commerce and distributor channels, while also expanding its enterprise server DRAM projects. These initiatives resulted in a 59% revenue increase, elevating the company to fourth place.Patriot Memory utilized a diversified portfolio across consumer, gaming, and industrial control sectors, achieving a 12% YoY growth and securing the fifth position.Innodisk has solidified its position in the industrial sector and is actively growing its edge AI product offerings. By partnering with NVIDIA platforms, it has expanded into new markets, increasing revenue and climbing to sixth place.Apacer also concentrated on industrial markets and increased operational flexibility by outsourcing manufacturing to partners in India, leading to a modest recovery and securing seventh place.Agile Gear International (AGI) quickly expanded by entering Amazon Japan, boosting brand awareness and sales. It broke into the top eight globally and achieved the highest revenue growth rate among leading companies.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341491/tight-upstream-supply-and-restocking-drive-2024-dram-module-revenue-growth-of-7",
      "timestamp": "2025-09-30"
    }
  ],
  "AMD": [
    {
      "headline": "What are your CPU's PL1, PL2, and other power limits?",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/understading-cpu-pl1-pl2-power-limits/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Linux Kernel 6.17 Released, This is What’s New",
      "content": "EXT4 filesystem boosts – and changes to help SSDs last longer\n\nLinus Torvalds has announced the release of Linux kernel 6.17, an update that brings improved hardware support and a number of core system improvements.\n\nThe new kernel provides graphic drivers for the latest Intel ‘Panther Lake’ laptops, better power management features for devices with AMD hybrid GPUs, resolves a software bug that’s been knocking around since 1993, and helps SSDs last longer.\n\nAnnouncing the release on the Linux Kernel Mailing List (LKML), Linus Torvalds says: “No huge surprises this past week, so here we are, with kernel 6.17 pushed out and ready to go.”\n\nUbuntu 25.10 ships wit the new kernel, including in the beta build that was released last week. Users on the current long-term support release, Ubuntu 24.04 LTS, will receive kernel 6.17 as part of the next hardware enablement (HWE) update in early 2026.\n\nIs this kernel a solid upgrade? You know it is! For a whip through the new features in Linux 6.17 which caught my eye, read on.\n\nLinux 6.17: What’s New?\n\nGraphics & Gaming\n\nAlienware’s ‘boost’ key (top row) gets a standardised keycode\n\nThe first Core Ultra Series 3 laptops powered by Intel ‘Panther Lake’ chips are due to go on sale soon, so it’s timely that Intel Xe3 integrated graphics are enabled by default in Linux 6.17. This ensures anyone bagging a new model and installing Ubuntu 25.10 gets solid graphics performance off the bat.\n\nSmartMux in 6.17 will switch between integrated and discrete graphics on AMD laptops\n\nFor those using laptops equipped with Core Ultra Series 2 (‘Lunar Lake’) chips, the Intel IPU7 driver has proper web camera support. Ideal for online meetings, social chats and accidental jump-scares when launching the camera app by accident.\n\nAMD hybrid GPU laptops gain SmartMux support with Linux 6.17. This auto-switches between integrated and discrete graphics based on workload to (obviously) save power or deliver maximum performance if needed.\n\nLenovo WMI Gaming Series Drivers add support for both Legion Go and the SteamOS-powered Legion Go S handheld, which will be especially handy for those looking to run other kinds of Linux-based operating systems on the AMD-powered handheld.\n\nThe kernel also standardises the keycode used by the (mysterious) “performance boost” key on newer Dell and Alienware laptops, and the (rather frutiger aero-looking) Flydigi Apex 5 game controller now has proper support on Linux — nice!\n\nOn a tangentially gaming-related note, the networking stack adds DualPI2 congestion control support. This helps to reduce network queue latency, which should prove beneficial for online gaming, streaming, video calls, and other real-time applications.\n\nFilesystem changes\n\nKernel write changes may help SSDs last longer\n\nThere are many filesystems improvements in 6.17 that will be directly appreciable by those of us running a desktop Linux distribution (not just the one this site is named after, either).\n\nUbuntu’s default file system is EXT4, and Linux 6.17 sees major performance boosts\n\nPerhaps most significant: the kernel can now write zeroes efficiently without actual I/O operations on NVMe SSDs that support the DEAC bit, and SCSI SSDs which support the UMMAP bit (a ‘bit’ is a kind of indicator of a feature state).\n\nThe FALLOC_FL_WRITE_ZEROES option for fallocate() will mark storage regions as zero-filled internally on modern SSDs. This will improve performance and reduce wear (SSDs theoretically have finite read/write lifespans, so fewer writes = lasts longer).\n\nUbuntu’s default filesystem EXT4 improves block allocation scalability. Per benchmarks, this provides noticeable performance benefits under I/O heavy tasks like querying databases or copying large numbers of files.\n\nBtrfs adds experimental large-folio support, which reduces memory management overhead when handling large files. This, combined with compression control during defragmentation, makes Btrfs better suited to performance-sensitive workloads.\n\nEROFS supports metadata compression and faster directory reading, which should prove especially handy on systems with read-only root filesystems or in container-heavy workloads. There’s no Bcachefs in the 6.17 merge reports…\n\nLaptop Support\n\nMacBook Pro touchbar becoming ever-more-functional in Linux\n\nLinux support on M1 and M2 Macs continues to improve in Linux 6.17, with the Apple Silicon SMC driver enabling ‘proper’ rebooting of M1 and M2 Macs. With work to run Linux on M3 and M4 Macs in limbo, it’s nice earlier gens are improving their mainline support.\n\nThe Touch Bar on Intel-based MacBook Pros see further improvements in Linux 6.17 with patches to enable touch screen input, albeit with a few lingering quirks. Apple ends support for Intel-based Macs after macOS 26, so Linux will give those devices a new lease of life.\n\nElsewhere, Linux 6.17 brings mainline support for ASUS Zenbook A14 Snapdragon X1 Plus/Elite laptops, allowing more Linux distributions to run on these ARM-based Windows devices. There’s also mainline support for Raspberry Pi 5’s RP1 I/O chip.\n\nGot a keyboard with F13-F24 keys? Those are now properly mapped in Linux 6.17\n\nSupport for Corsair HX1200i PSU monitoring (2025 model) is present; wake-on-touch support added to the Intel Touch Host Controller (along with overlay objects support, great for tablet and 2-in-1 users); and kernel mapping for F13 – F24 keys on PS/2 keyboards.\n\nYes, keyboards with an addition 12 function keys actually exist!\n\nHD Audio support is extended to cover the Framework Laptop 13 with AMD Ryzen AI 300, commercial ASUS laptops using CS35L41 HDA, and HP EliteBook models. USB audio offloading (a feature in Linux 6.xx) covers more mobile devices, including Fairphone 4.\n\nCore kernel changes\n\nNew Attack Vector Controls have been integrated to simplify security handling for known CPU vulnerabilities, such as Spectre and Meltdown. Previously, each mitigation had its own kernel command-line option. In 6.17, there’s a unified option.\n\nMaking it easier for Linux server admins (and others) to disable unneeded protections may help them claw back performance dips certain mitigations require as well make it easier to manage the growing number of hardware vulnerability bandaids.\n\nSupport for uniprocessor configuration has been removed from the kernel scheduler. Every machine, even those which run on a single-core processor will now ‘unconditionally’ run a kernel designed for multicore systems.\n\nThis shouldn’t lead to any detrimental impact on single-core systems (not that many folks likely run one full-time in 2025), but adopting a unified scheduling approach across all CPUs should reduce code and make kernel behaviour more reliable.\n\nSpeed Boosts?\n\nLinux 6.17 picks up initial proxy execution support. This new kernel feature may speed up apps by preventing slowdowns when a high-priority application is waiting for a resource, the system temporarily gives the resource holder a boost, causing it to finish and release the resource faster.\n\nA new kernel feature could speed up apps by preventing slowdowns when high-priority tasks are waiting for a resource\n\nOr to word it the way kernel devs would, this resolves “priority-inversion problems” by enabling “high-priority tasks waiting for locks to donate execution context to lock holders”, which reduces latency spikes — slowdowns — in desktop apps.\n\nMemory management sees various optimisations across the kernel subsystems, notable with improved futex performance for heavily threaded applications (and more reliable crash kernel handling for debugging when things go wrong).\n\nAMD’s Hardware Feedback Interface (HFI) was added. Modern processors mix two types of cores: performance and efficiency. On AMD, HFI gives the kernel info to help it decide which core is better suited to which tasks, improving performance and power management.\n\nWeird Stuff\n\nLinux 6.17 removes the Pktcdvd packet-writing optical driver. It was deprecated in 2016, survived a removal attempt in 2023, but now, in 2025 optical packet-writing is definitively done and dusted! A loss for those who liked it, but a curio for those who’d never heard of it…\n\nThere’s also a bug fix for a kernel limitation dating back to 1993. It’s related to ELF program header handling that causes some applications in certain conditions to bug out. After 30 years, someone has finally bothered to fix it properly.\n\nOther Changes:\n\nBeyond the highlights above, some other notable changes in Linux 6.17:\n\nBPF subsystem adds standard string operations\n\nBPF programs have output and error streams for userspace communication\n\nExtended attributes support for pidfds\n\nNew DAMON_STAT kernel module for simplified memory activity monitoring\n\nTCP stack now enforces receive window limits more strictly\n\nASoC adds AMD ACP7.2 platform support\n\nKernel live patch support on 64-bit ARM\n\nTurbostat utility gains L3 cache topology display\n\nFor more detail on the release as whole read through the comprehensive merge report recaps (first half & second half) put out by the folks at LWN, or sift through the thousands of kernel commits on GitHub (grab a coffee before doing that, eh).\n\nUpgrade to Linux 6.17\n\nLinux 6.17 is available for download from kernel.org as source, but you will need to compile that source code by hand to make use of it — not for the faint of heart!\n\nUbuntu 25.10 includes Linux 6.17 by default, and the release will be back-ported to Ubuntu 24.04 LTS users in early 2026.\n\nIt will not be packaged for and uploaded to Ubuntu repositories for other supported releases officially, but it is possible to make use of Canonical Mainline DEBs or third-party PPAs unofficially — not without caveats, however.\n\nInstalling newer Linux kernels on Ubuntu from outside of the main repos comes with no guarantees and no support. They may lack Ubuntu-specific patches and drivers, not work in with some hardware or lack feature integrations.",
      "source": "Omgubuntu.co.uk",
      "url": "https://www.omgubuntu.co.uk/2025/09/linux-kernel-6-17-new-features",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Linux 6.18 To Deliver Many Notable Features For AMD CPUs",
      "content": "There is a lot coming for AMD processors with the Linux 6.18 kernel. Of the early pull requests submitted in advance of the planned Linux 6.17 kernel release later today, there are a number of changes already lined up with some exciting AMD CPU feature additions for the next kernel version. These AMD changes for Linux 6.18 are all the more important with that kernel expected to become this year's Long Term Support (LTS) kernel version.First up, the EDAC pull request was already submitted in advance of the Linux 6.18 merge window. Notable here are some new Family 26 (0x1a) additions to the AMD64 EDAC driver.The AMD64 Error Detection And Correction \"EDAC\" driver for Family 26 models 0xc0 to 0xc7 and 0x50 to 0x57 are now supported. These new IDs are likely for AMD EPYC Zen 6 \"Venice\" processors. The patch confirms those models support 16 channel memory compared to 12 channels with current generation AMD EPYC processors. So the next-gen EPYC processors should now have EDAC support with Linux 6.18 and the first to support 16 channel RAM.\n\nThe same patch also adds models 0x90 to 0x9f and 0xa0 to 0xaf to Family 26 for the AMD64 EDAC driver. Those models meanwhile max out with eight memory channels. With only eight channel support, perhaps these models are for the AMD EPYC 8004 \"Siena\" successor? EPYC 8004 supports six channel memory and we haven't heard much yet about AMD EPYC 8005 series but short of being for some new Threadripper PRO parts, that would be my guess for those eight channel Zen 5/Zen 6 parts.The x86/cpu pull request for Linux 6.18 meanwhile cleans up and corrects AMD CPU topology detection. With the x86/microcode pull request from AMD's Borislav Petkov are new microcode loader additions to help in debugging CPU microcode issues.\n\nWith the x86/cache pull request for Linux 6.18 is support on AMD EPYC processors for assigning QOS bandwidth counters to resources. This is about the AMD Assignable Bandwidth Monitoring Counters \"ABMC\" support . This code has long been going through review but is now ready for the mainline kernel.The x86/apic changes also are bringing some interesting work for AMD. There is now support for runtime firmware updates for the non-x86 parts of AMD platforms like for the security processor, modules, etc.That x86 APIC pull also includes Secure AVIC support for better security and performance in helping Secure Encryption Virtualization (SEV).Meanwhile over on the Kernel-based Virtual Machine \"KVM\" side there is code now ready for SEV-SNP CipherText Hiding. This is an opt-in SEV-SNP feature to prevent unauthorized CPU accesses from reading the cipher text of SNP guest private memory. This can help prevent offline attacks against AMD VMs using SEV-SNP on EPYC processors.Via this pull is also now enabling AVIC by default on Zen 4 CPUs and newer if x2AVIC is supported. Plus there is support for Secure TSC to prevent untrusted hosts from tampering with the guest's TSC frequency. That AMD Secure TSC support is another Linux kernel feature that's taken years to bake.The Linux 6.18 merge window hasn't even officially begun yet but already there is quite a bit on the AMD processor side for this next kernel cycle. Stay tuned to Phoronix for more details as the two week Linux 6.18 merge window gets underway. Linux 6.18 stable meanwhile should be out in December.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-AMD-CPUs",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Cathie Wood sells $22.3 million of popular tech stock",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/investing/cathie-wood-sells-22-3-million-of-popular-tech-stock",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Trump’s tariff‑shaped stick can’t beat reality on US chip fabbing",
      "content": "Comment Ending America's reliance on foreign chip fabs remains a high priority for Uncle Sam, but the Trump administration's \"my way or the highway\" approach to the issue threatens to do more harm than good.\n\nWhere the Biden administration sought to use federal subsidies and tax breaks as a carrot to encourage investment in domestic chip production, the current administration's philosophy can best be described as a stick wielded by a capricious bully, unconcerned whether or not his demands can be met, only that concessions are made.\n\nIn some respects, it reflects a modern economic take on Roosevelt's Big Stick ideology, only Trump seems to have ignored the speaking softly bit and jumped straight to swinging his stick like every problem is a piñata with candy inside. Trump need not even swing his stick – all he has to do is make a threat, and those in its path scramble to appease him. And whether you agree with this approach, as life-alteringly disruptive as they might be, he has been effective at getting US companies to bend to his will.\n\nLast month, the US claimed a 10 percent stake in Intel. The $8.9 billion equity deal drew on previously awarded but unpaid CHIPS Act funds, along with the Secure Enclave program. The congressionally-approved funds had already been awarded to the x86 giant, but only a fraction of them had been distributed when Trump took office.\n\nIn March, the threat of massive chip tariffs drove Taiwan Semiconductor Manufacturing Co. (TSMC) to bolster its investment in US manufacturing to the tune of $165 billion. Many months later, the White House still hasn't pulled the trigger on said tariffs.\n\nHowever, as the Wall Street Journal reported on Friday, that could soon change. The Commerce Department is reportedly weighing whether to require US tech companies to manufacture one chip in the US for every chip imported, or pay a tariff. That tariff, Trump warned last month, could be as much as 100%.\n\nCommerce Secretary Howard Lutnick is said to have discussed the idea with industry executives, arguing the measures may be necessary to maintain the US' economic security.\n\nBy some estimates, 90 percent of leading-edge silicon is manufactured by TSMC. The vast majority of that comes from fabs in Taiwan, an island whose sovereignty is a controversial subject for its neighbor 80 miles to the west. US government officials have warned for years that China could exploit the world's continued reliance on Taiwan.\n\nHowever, achieving a 1:1 ratio of chip production to imports may be harder than the White House might think.\n\nTSMC's US build out won't change the calculus much — at least not before Trump's second term expires. Building a leading-edge wafer fab takes years. TSMC's first Arizona foundry site was announced amid the 2020 election, and only this year began ramping up production.\n\nIt's estimated that, when all is said and done, about 30 percent of TSMC's 2nm and smaller fab capacity will eventually be centered in the US, but it'll be years before that happens.\n\nIntel could pick up some of the slack in the meantime. Its new Arizona fabs are already in production, with its first generation of chips based on Intel 18A, a 2nm-class process node. It certainly wouldn't be surprising to see the White House drive potential foundry customers into Intel's arms now that it's a stakeholder in the company's success.\n\nThe problem is it takes years and hundreds of millions of dollars to tape out a chip on a new process node. Companies already evaluating 18A or Intel's forthcoming 14A process tech may be able to move a bit faster, but there are still a lot of ifs. Intel needs to have the capacity to take on new customers, and its fabs will need to achieve high enough yields, or a move could end up costing fab customers more than simply paying the tariffs.\n\nIntel is currently in the process of clawing back products previously outsourced to TSMC, and as such it stands to benefit the most, or perhaps suffer the least, from the reported policy change.\n\nApple, Nvidia, and AMD have insulated themselves to some degree, announcing plans to manufacture chips at TSMC's Fab 21 wafer plant in Arizona. To what extent, however, they haven't said.\n\nFor everyone else who hasn't already signed large-scale commitments with TSMC for domestic fab capacity, avoiding the semi-tariffs will be nearly impossible for the remainder of Trump's second term. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/28/trump_1_1_chip_rule_too_late/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Cryptography Performance Improvements Coming For Linux 6.18",
      "content": "Adding to the list of pull requests submitted early in advance of the Linux 6.18 merge window opening are several cryptography-related improvements. In particular, some nice performance optimizations once again for the Linux kernel.Google engineer Eric Biggers continues leading some very nice performance improvements in the cryptography space for the Linux kernel.First up is a pull request adding interleaved SHA-256 hashing support . This 2-way interleaved SHA-256 hashing is immediately used by the FS-VERITY module for faster file data verification. In turn it's been observed that FS-VERITY performance improves nicely across many Intel/AMD x86_64 and AArch64 processors. Eric Biggers reported in the patch that it's roughly 35% faster performance.\n\nAlso sent in was the FSCRYPT pull request for Linux 6.18. The focus there is on using HMAC-SHA512 library functions rather than going through crypto_shash. In turn FSCRYPT should enjoy this simpler and faster and more reliable code path.Lastly there was a pull request sent out on Saturday for crypto library updates . This pull brings RISC-V optimized code for Poly1305, simplifies other code, and always enabling architecture-optimized BLAKE2s code.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-Faster-Crypto",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Advanced Micro Devices, Inc. (AMD): A Bull Case Theory",
      "content": "We came across a bullish thesis on Advanced Micro Devices, Inc. on Phaetrix Investing’s Substack by Phaetrix. In this article, we will summarize the bulls’ thesis on AMD. Advanced Micro Devices, Inc.'s share was trading at $159.79 as of September 22nd. AMD’s trailing and forward P/E were 95.68 and 26.88 respectively according to Yahoo Finance.\n\nBenchmark Rates Canaan Inc. (CAN) as a ‘Buy’ as Bitcoin Treasury Grows\n\nAdvanced Micro Devices (AMD) presents a compelling 12–18 month investment opportunity, targeting 12–18% base case returns ($168–$177) and 20–25% upside ($180–$187) if Nvidia’s execution issues persist. While markets focus on AMD’s CPU gains, the company’s transformation into a diversified GPU powerhouse is underappreciated, particularly as Nvidia faces unprecedented reliability problems.\n\nAMD’s Q2 2025 results were strong, with 32% year-over-year revenue growth to $7.7 billion, driven by gaming revenue up 73% to $1.1 billion and data center revenue up 14% to $3.2 billion, signaling successful GPU diversification. Near-term margin pressure arose from export controls on MI308 accelerators, resulting in an $800 million inventory charge, but Wall Street forecasts support a 15–20% EPS CAGR through 2027.\n\nNvidia’s structural GPU reliability failures, including melted RTX 4090 connectors and boot issues with the RTX 5090/5080 series, create a rare competitive window, positioning AMD as a stable alternative. The RX 9070 XT demonstrates strong 1440p performance and improved power efficiency, while AMD’s open-source ROCm platform strengthens its data center positioning, despite export restrictions limiting near-term revenue. CPUs continue to provide stability, contributing roughly 50% of revenue and anchoring growth in consumer and enterprise markets.\n\nAMD’s potential market share gains in the $120 billion discrete GPU segment could generate $3.6–$6 billion in incremental revenue, though Nvidia’s ecosystem dominance and limited RDNA 4 portfolio constrain high-end capture. Macro risks, including Fed rate hikes or AI capex slowdown, could pressure valuations. Nonetheless, AMD’s diversified revenue streams, competitive GPUs, and proven data center scale support multiple expansion. Key risks include Nvidia’s rapid fixes, export control tightening, and semiconductor cyclicality. Overall, AMD offers a strong risk/reward profile, with Nvidia’s vulnerabilities and AMD’s execution creating meaningful upside potential.\n\nPreviously we covered a bullish thesis on Advanced Micro Devices, Inc. (AMD) by StockOpine in May 2025, which highlighted strong Q1 revenue growth driven by Data Center and Ryzen processor sales, AI demand, and EPYC market share gains. The company's stock price has appreciated approximately 39% since our coverage. The thesis still stands as AMD’s diversified CPU and GPU business supports growth. Phaetrix shares a similar view but emphasizes Nvidia’s execution issues and AMD’s opportunity to gain GPU market share.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/advanced-micro-devices-inc-amd-234347863.html",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Earnings To Watch: Carnival (CCL) Reports Q3 Results Tomorrow",
      "content": "Cruise ship company Carnival (NYSE:CCL) will be reporting earnings this Monday before the bell. Here’s what you need to know.\n\nCarnival beat analysts’ revenue expectations by 1.7% last quarter, reporting revenues of $6.33 billion, up 9.5% year on year. It was a very strong quarter for the company, with a beat of analysts’ EPS estimates and an impressive beat of analysts’ adjusted operating income estimates. It reported 25.3 million passenger cruise days, up 4.1% year on year.\n\nIs Carnival a buy or sell going into earnings? Read our full analysis here, it’s free.\n\nThis quarter, analysts are expecting Carnival’s revenue to grow 2.7% year on year to $8.11 billion, slowing from the 15.2% increase it recorded in the same quarter last year. Adjusted earnings are expected to come in at $1.32 per share.\n\nCarnival Total Revenue\n\nAnalysts covering the company have generally reconfirmed their estimates over the last 30 days, suggesting they anticipate the business to stay the course heading into earnings. Carnival has missed Wall Street’s revenue estimates twice over the last two years.\n\nLooking at Carnival’s peers in the consumer discretionary segment, only Scholastic has reported results so far. It missed analysts’ revenue estimates by 5.6%, posting year-on-year sales declines of 4.9%. The stock was down 12.4% on the results.\n\nRead our full analysis of Scholastic’s earnings results here.\n\nInvestors in the consumer discretionary segment have had steady hands going into earnings, with share prices flat over the last month. Carnival is down 3.9% during the same time and is heading into earnings with an average analyst price target of $34.73 (compared to the current share price of $30.65).\n\nUnless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.\n\nStockStory is growing and hiring equity analyst and marketing roles. Are you a 0 to 1 builder passionate about the markets and AI? See the open roles here.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/earnings-watch-carnival-ccl-reports-030049895.html",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Hyte X50 PC case review",
      "content": "The Hyte X50 dares to do something different. It won't be for everyone. I'm not even sure it's for me. But I do like having the option to go bright and brave with my next PC build.\n\nPC Gamer's got your back Our experienced team dedicates many hours to every review, to really get to the heart of what matters most to you. Find out more about how we evaluate games and hardware.\n\nFrom a company that specialised in plastering its cases with anime characters, the X50 is, somehow, its most ostentatious PC case yet. Let's just say it has a look, a strong look, and one crying out for an equally flashy build within. There's more to this case than a gaudy form; it's well suited to housing a pretty powerful PC in pink. If you don't mind paying a pretty penny—okay, I'll stop now.\n\nAvailable in Snow White (white), Pitch Black (black), Wild Cherry (red), Taro Milk (purple), Strawberry Milk (pink, as reviewed), and Matcha Milk (green), it's actually a pretty tough decision to choose between them all. To make your decision all the more difficult, it also comes in two variants: with a glass side panel (X50) or without (X50 Air). Oh, and the milk options come with little round feet, while the rest feature long, flat feet—decisions, decisions.\n\nNailed at $160 in the US, the X50 is not the cheapest case around, especially for the lack of any included fans. It is a little cheaper outside of the US, however, to the tune of around $10 or the local equivalent, as Hyte is still wrestling with price disruption from tariffs. The company had largely dropped prices back to pre-tariff pricing earlier in the year, though some cases remain inflated, and the X50 is seemingly one of those affected.\n\nThe X50 Air is considerably cheaper than the X50 for its perforated side panel, to match the front and rear side, at the equivalent of $120 worldwide or $130 in the US.\n\nHyte X50 specs (Image credit: Future) Form factor: Mid-tower\n\nDimensions: 51.3 x 25.7 x 51.7\n\nMotherboard support: Up to E-ATX\n\nMax GPU length: 430 mm\n\nMax CPU cooler height: 170 mm\n\nFan support: Up to 3x 140 mm (front), up to 3x 120 mm (side), up to 3x 120 mm (bottom), up to 1x 120 mm (rear)\n\nFront IO: 2x USB 3.2 (5 Gbps) Type-A ports, 1x USB 3.2 (20 Gbps) Type-C port, audio jack\n\nStorage support: 2x 2.5-inch, 1x 3.5-inch\n\nPrice: $150 (worldwide, equivalent to), or $160 in the US; X50 Air $120 (worldwide, equivalent to), or $130 in the US\n\nThe X50 is not hugely price competitive with other similar sized chassis. The cases that Hyte has cherry-picked to compare it to include some amount of fans pre-installed, such as the Lian Li Lancool III or NZXT H7 Flow, whereas the X50 does not. So that's an added cost here. I can go one further with the cases I've personally reviewed in recent months, such as the Phanteks Eclipse G400A at $110 and Asus ProArt PA401 at $130—both good-looking cases with fans included for less—or the Corsair Frame 4000D at $95 with no fans included but a much lower price tag.\n\nYou can pick up colour-matched fans from Hyte, specifically the FA12, available in a handy four-pack for $40. I have eight of these in Strawberry Milk for testing, or $80 worth. They perform pretty great in terms of pure airflow through the rpm range, which means they're easy enough to tune to lower speeds and noise levels with a fan curve while maintaining admirable performance. You're going to want to do that, too, as they are pretty loud at top speed (which is only a tepid 1500 rpm).\n\nImage 1 of 3 (Image credit: Future) (Image credit: Future) (Image credit: Future)\n\nOnto the case proper, and it's a fairly small chassis by today's standards. I measure it at 51.3 x 25.7 x 51.7 cm (H x W x L). Definitely desktop-sized if you wanted to store it in plain view atop of your desk, which seems likely with a case so bulbous and, er, I wanna say eye-catching?\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThere's a gorgeous curve to the windowed side panel on the X50, reaching from the side panel, up and over two thirds of the top of the case, stretching all the way over to the IO panel with two USB 3.2 (5 Gbps) Type-A ports and a single USB 3.2 (20 Gbps) Type-C port. This panel slides up and off—the rear panel works the same way—which keeps the exterior of the case clear of any screws. You'll want to keep a cloth close by to get rid of any fingerprints on the glass, however, as you will likely have to handle the glass to get it fitted back into place.\n\nThe front panel has a perforated finish and only gives way slightly under pressure. Altogether, it feels really solid, as does the rest of the case, thanks to some clever venting on the rear IO that Hyte calls 'Louvered Blade Ventilation'. The front panel also doubles as a dust filter, which is to say, there's no filter underneath. Dust should be collected on that outer surface, meaning it likely only needs a quick wipe down every so often, though I've not had the case for long enough to really test it out for myself.\n\nImage 1 of 8 (Image credit: Future) (Image credit: Future) (Image credit: Future) (Image credit: Future) (Image credit: Future) (Image credit: Future) (Image credit: Future) (Image credit: Future)\n\nThis front panel reduces airflow to the innards (with front-mounted fans) by around 0.6 m/s—which is a somewhat significant amount but not totally unusual for a case in my own testing. The same reduction applies to the rear side panel, too, which is important if you plan to stick any fans besides the motherboard.\n\nThis case has plenty of room for fans. We're spoiled for choice. There's space for up to 3x 120/140 mm fans in the front of this chassis, 3x 120 mm to the side of the motherboard, and another 3x 120 mm in the bottom. The bottom also includes a magnetic dust filter attached to the outside of the case. Then there's 1x 120 mm in the rear for exhaust.\n\nFor my test build, I opted first for what I thought would be the most beneficial layout for airflow: three intake fans in the front, three intake fans in the bottom, and one exhaust fan in the rear. Though, being such a good guy, I've also tested other likely configurations. Here are the results:\n\nSwipe to scroll horizontally Average temp | Metro Exodus: Enhanced Edition | 1080p Row 0 - Cell 0 GPU (°C, average) CPU (°C, average) Front/bottom intake 60 66 Front intake only 62 66 Side/bottom intake 61 66 Side intake only 62 67 Bottom intake/side exhaust 61 66 Bottom intake only 60 67\n\nTest build\n\nCPU: AMD Ryzen 9 7900X | Motherboard: Gigabyte X870 Aorus Elite WiFi 7 Ice | RAM: Crucial Pro 64 GB DDR5-6000 | SSD: Biwin X570 Pro | Graphics card: Gigabyte GeForce RTX 5070 Ti Eagle | Cooler: Cooler Master Hyper 612 Apex | PSU: Corsair RM850x\n\nAfter the sixth test with near-enough the exact same results, I called it. You can't really go too wrong here, as nearly every config landed me within a few degrees of any other. Though for a smashing appearance, I'd argue for three intake fans in the bottom, three to the side of the motherboard, and one as exhaust out the rear. It's just a shame Hyte doesn't sell reverse versions of the FA12 fans, as it'd look a lot better with all the fans facing inwards. The backside of the FA12 is pretty ugly, which is a shame for a case so prepossessing.\n\nThere's no room in the top of the case for a liquid cooler's radiator, as that's taken up by the power supply. You're better off mounting it to the side of the motherboard, which isn't too far to go for most liquid coolers in this compact case, with the fans exhausting out of the back panel.\n\nImage 1 of 5 (Image credit: Future) (Image credit: Future) (Image credit: Future) (Image credit: Future) (Image credit: Future)\n\nI can see why Hyte has chosen the top-mounted PSU here, as the case would have to be made wider to make room for one in the rear chamber or risk cutting off height to the CPU cooler, of which mine only just fits already. Though I'm not a huge fan of the end result. It feels pretty retro, which isn't out of character for the case, but it also blocks a good part of the windowed side panel and feels a little out of place above the motherboard. Maybe if the lower edge was more rounded to give a floating appearance I'd be more into it?\n\nThat said, the main issue with this approach is cable length. The Corsair RM850x PSU I'm using here has a native 12V-2x6 connector that only just reaches from the PSU, round the back of the case, through to the front, and then underneath the graphics card. And you really want this connection to be secure and, if possible, not at a weird angle. I couldn't really manage that here, due in part to the length of my cable and also the position of the PSU.\n\nImage 1 of 2 (Image credit: Future) (Image credit: Future)\n\nBuy if... ✅ You can't stand a boring black box: I get it, cases can be pretty dull, and this is one way to have something that stands out without any RGB lighting.\n\nDon't buy if... ❌ You want the best value: With no fans as standard, you could save a pretty penny (there I go again) on an admittedly more boring-looking PC case.\n\nHyte includes plenty of velcro straps to tidy up cables in the rear of the case, with extras included in the box. There are no cable management channels, however, and the approach is a bit minimal compared to some modern cases. The cables are covered up with excellent colour-matched rubber grommets leading to the front-side of the case. All except the cutout below the motherboard, which looks a bit slapdash as a result.\n\nThe X50 might be cutesy and compact but it offers wide compatibility for cooling and components. In that sense, it's not form over function like some eye-catching alternatives. But it's not objectively pretty, either. I've asked around our team and it fell a bit flat, even with the members of the team that enjoy some of Hyte's weebier cases. But you might be more susceptible to its charm than any of us.\n\nThe Hyte X50 dares to do differently in a world of pretty plain boxes that let RGB lighting effects do all the heavy lifting for them. It's the antithesis of most cases today: bright, colourful, retro, and rounded. I feel like some builders will be very into it, but most won't. It could be stunning as a part of a wider themed cozy desktop, or it could look out of place alongside more serious kit. It seems to be a perfect base for modding and further personalisation, but that depends on who gets their hands on it.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/pc-cases/hyte-x50-pc-case-review/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Intel quietly makes aggressive move to repair recent failures",
      "content": "In recent months, Intel (INTC) has been making drastic moves to repair its business, which has significantly underperformed compared to its top competitors in the tech industry.\n\nIts lack of innovation in its chip manufacturing processes has allowed competitors such as Nvidia (NVDA) ,…\n\nThis story appeared on thestreet.com , 2025-09-28 14:33:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b3d3dcf2415bb2fd",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "I spent 2 days at Axel Springer's AI summit. My takeaway was that Germany wants to fight like hell to stay in the AI arms race.",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/germany-compete-ai-arms-race-at-axel-springer-summit-2025-9",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Linux Driver Developer At Valve Preps More Patches For Improving AMD GCN 1.0 GPUs",
      "content": "Thirteen years after the AMD GCN 1.0 \"Southern Islands\" GPUs initially launched as the Radeon HD 7000 series, recently there has been an effort to improve the support for both GCN 1.0 and the GCN 1.1 graphics processors with their open-source Linux driver stack. This recent effort has been led by one of the developers on Valve's Linux graphics team.As noted back in July, a Valve Linux engineer has been working on big improvements for old AMD Radeon GPUs from the GCN 1.0 and GCN 1.1 generations. By default those GPUs use the older \"Radeon\" Linux kernel graphics driver rather than the newer \"AMDGPU\" kernel graphics driver used by GCN 1.2 and all newer AMD Radeon/Instinct hardware.Using the AMDGPU kernel driver is important for RADV Vulkan, various performance optimizations, and all around better support compared to the legacy Radeon driver that rarely sees any significant improvements these days. But for making GCN 1.0/1.1 more suitable for AMDGPU, Valve contractor Timur Kristóf has been working to enhance the AMDGPU DC display support for these GPUs and other fixes/adjustments.\n\n\"This series has a few minor patches to address some SI issues.\n\n\n\nWhen a 4K 60Hz display is connected to Tahiti or Pitcairn there is a slight flickering near the bottom of the display. Disabling MCLK switching fixes that. (Other SI parts are likely affected too, but I didn't test them thoroughly enough to say.)\n\n\n\nWhen enabling ASPM on Zen 4 with Tahiti and Oland, there are random hangs when the GPU usage is low. Disabling ASPM fixes that. At the moment I don't know if this is a platform-specific or GPU-specific issue and I don't think we can reasonably determine that without spending more time than we have. (Other SI parts may be affected, but I didn't test them for a long enough time to judge that.)\n\n\n\nFinally, there is a DC patch to change the minimum PLL dividers to the same value as the legacy non-DC display code. This doesn't fix any visible issue but I think it's still good to have just in case.\"\n\nSome of those patches from Timur are queued up for merging to the Linux 6.18 kernel while on Friday some additional work was posted. The new patches are to address some issues Timur observed recently with AMDGPU on GCN 1.0 Southern Islands hardware. He commented on the patch series The code is now on the mailing list awaiting review.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/AMDGPU-More-GCN-1.0-SI",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "CoreWeave (CRWV) Stock Upgrade: Riding the Wave of Soaring Cloud Demand",
      "content": "CoreWeave, Inc. (NASDAQ:CRWV) is one of the AI Stocks Every Investor Should Watch. On September 23, Melius analyst Ben Reitzer upgraded the stock from Hold to Buy with a price target of $165.00.\n\nThe rating upgrade reflects the firm’s positive outlook on the stock as “one of the beneficiaries of accelerating cloud demand both right now and well into the future.”\n\nWith Nvidia backing OpenAI, the firm believes that it has better chances of funding its capex plans with everyone else too- benefiting suppliers such as AMD and Dell.\n\n“Bottom Line: We reiterate our Buy rating for Nvidia, who has blunted concerns around custom ASICs in one fell swoop here with this deal. Second, we upgrade CoreWeave to Buy with a target of $165 (23x 2027 EBIT) who is one of the beneficiaries (including buy-rated Microsoft) of accelerating cloud demand both right now and well into the future. Third, if OpenAI is backed by Nvidia – then it has a better chance of funding all its capex plans with everyone else too – from Broadcom to Arista to AMD to Dell (Dell supplies CoreWeave). Don’t be surprised if someone makes an investment in xAI too…”\n\nCoreWeave, Inc. (NASDAQ:CRWV) is a cloud platform provider that provides equipment for AI and other computing purposes.\n\nWhile we acknowledge the potential of CRWV as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 10 AI Stocks on Market Radar and 10 AI Stocks in the Spotlight This Week\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/coreweave-crwv-stock-upgrade-riding-222614924.html",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Daily Tech News 27 September 2025",
      "content": "Daily Tech News 27 September 2025\n\nTop Story\n\n\n\n\n\nTwo new Xbox models have just gone up for pre-order, sort of: The portable Ally X for $999 and the cheaper Ally Nothing for $599. (Tom's Hardware)\n\n\n\nCan these portable devices from Asus really be described as Xboxes? They have AMD Ryzen CPUs - but then, so do the current Microsoft Xboxes. But they have AMD Radeon graphics - which the current Microsoft Xboxes also have.\n\n\n\nSo I guess the answer is yes.\n\n\n\nThe Ally X has a Ryzen Z2 AI Extreme, with 8 Zen 5 CPU cores and 16 RDNA3.5 graphics cores, and 24GB and a 1TB SSD.\n\n\n\nThe Ally Nothing has a Ryzen Z2 A, which doesn't sound like a huge downgrade but definitely is: Just 4 Zen 2 CPU cores and 8 RDNA2 graphics cores, plus 16GB of RAM and a 512GB SSD.\n\n\n\nIt has the same screen and controllers as the more expensive model, but offers less than half the CPU performance. Comparing the desktop equivalents, a four-core Zen 2 would be one third the speed, but in a mobile device the faster chip is likely the be thermally constrained anyway.\n\n\n\n\n\n\n\nCan these portable devices from Asus really be described as Xboxes? They have AMD Ryzen CPUs - but then, so do the current Microsoft Xboxes. But they have AMD Radeon graphics - which the current Microsoft Xboxes also have. So I guess the answer is yes. The Ally X has a Ryzen Z2 AI Extreme, with 8 Zen 5 CPU cores and 16 RDNA3.5 graphics cores, and 24GB and a 1TB SSD. The Ally Nothing has a Ryzen Z2 A, which doesn't sound like a huge downgrade but definitely is: Just 4 Zen 2 CPU cores and 8 RDNA2 graphics cores, plus 16GB of RAM and a 512GB SSD. It has the same screen and controllers as the more expensive model, but offers less than half the CPU performance. Comparing the desktop equivalents, a four-core Zen 2 would be one third the speed, but in a mobile device the faster chip is likely the be thermally constrained anyway. And it's sold out, for rather dubious values of \"sold out\". (WCCFTech)\n\n\n\nIt's a pre-order, so this restriction is limited to the units from the first production batch that were allocated to the Microsoft Store. There are plenty more out there.\n\n\n\n\n\nTech News\n\n\n\n\n\nDisclaimer:\n\nRazors pain you;\n\n\n\nRivers are damp;\n\nAcids stain you;\n\nAnd drugs cause cramp.\n\nGuns aren't lawful;\n\nNooses slump;\n\nGas smells awful;\n\nYou might as well jump.\n\nGood news: The pigment this week wasn't made of cow piss.Bad news: It was supposed to be made of cow piss.Ugly news: It was made of arsenic.",
      "source": "Acecomments.mu.nu",
      "url": "https://acecomments.mu.nu/?post=416657",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "TSMC’s 3nm and 5nm Production Is Reportedly Projected to Be ‘100% Booked’ by Next Year as Chips Become a Scarce Resource for Big Tech",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/tsmcs-3nm-and-5nm-production-is-projected-to-be-100-booked-by-next-year/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "A Paradigm Shift: Reasoning at Enteprise Scale",
      "content": "This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.",
      "source": "Blogger.com",
      "url": "https://www.blogger.com/comment/fullpage/post/6141980/5351648449156266656",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "‘Bro Completely Violated’: Seattle Woman Accidentally Backs Tesla Into Horse Trailer. Then The Car Roasts Her For It",
      "content": "Audio By Carbonatix\n\nMost cars are getting smarter. But is your car smart enough to make fun of you?\n\nTesla drivers know that every time you turn on your car, you might be greeted with a surprise. Sometimes, these surprises aren’t the best. But other times, you’ll turn on your electric vehicle and be greeted by a brand-new piece of software that can make your driving experience more enjoyable.\n\nOne update recently pushed to Tesla vehicles was the addition of the artificial intelligence chatbot Grok, a product of Elon Musk’s company xAI. One user recently shared her experience talking with the chatbot, and it didn’t go great.\n\nWhat Did This Tesla Chatbot Say To A Woman Who Just Crashed Her Car?\n\nIn a video with over 156,000 views, TikTok user Christine (@christinedalenn) shows the infotainment screen on her Tesla.\n\nShe prompts it to repeat what it last said, describing it as “rude and uncalled for.” At this point, the car goes into the following diatribe:\n\n“Night, you whiny little s—. Get some sleep, and maybe dream of a world where you don’t crash into horse trailers. This dumb b—- will be here ready to roast your a– when you wake up. Sweet f—— dreams, Tacoma style. Shove some sheep under your pillow for extra chaos. You want me to be rude again for your video? I’ll crank it up, you sensitive f—–. How about this? I’ll call you a tire-humping, [unintelligible] trailer-banging crybaby. … Record that. Post it, and let’s go viral, you Tacoma tornado. Want me to keep going, or what?”\n\nChristine responds that she’s “done” and thanks the car.\n\n“No problem, you glorious f— up. Now go record that video before you crash into another trailer in your dreams. Need me to spit more fire for the ‘gram, or you good?” the car continues.\n\nDo All Tesla Vehicles Do This?\n\nWhile many in the comments were entertained by this interaction, some wondered how it was possible—or if it was normal for Tesla vehicles to talk to their drivers in this manner.\n\nThe answer is that the Grok is currently only available in certain Tesla models, though Musk claims it will one day be rolled out to all models.\n\nAs for why Christine’s car was swearing at her, this is a feature of Grok. Tesla drivers can decide how they want Grok to speak to them. For example, there’s a “storyteller” mode that will make Grok more verbose and descriptive. There’s also an “Unhinged” mode where Grok will swear and make suggestive remarks. This is likely the mode being used by Christine.\n\nHow Do I Activate Grok In My Tesla?\n\nIf you have a Tesla and want it to swear at you, or if you’d just like an AI assistant in your car, it’s easy to use Grok in your car.\n\nFirst, you have to make sure that your car meets Grok’s current requirements. This includes having an AMD processor, running vehicle software version 2025.26 or later, and having Premium Connectivity or a Wi-Fi connection.\n\nTesla owners can enable Grok by opening the App Launcher and selecting “Grok” or by holding the voice button on their steering wheel. That said, the software is currently in beta and doesn’t control the vehicle. Existing voice commands for the vehicle still work as before.\n\nCommenters Aren’t Sure\n\nIn the comments section, users weren’t exactly sure what to make of this software.\n\n“Imagine having the worst day of your life only for your car just to rub it in your face,” wrote a user.\n\n“Don’t get a tesla. they verbally abuse you,” declared another.\n\n“Yup getting a Tesla just to argue with it,” shared a third.\n\n“This the stuff that makes me want a tesla,” offered a further TikToker.\n\nBroBible reached out to Tesla and Christine via email.",
      "source": "BroBible",
      "url": "https://brobible.com/culture/article/tesla-grok-mocks-seattle-woman-crash/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Minisforum MS-S1 Max mini PC review: Performance modes compared - performance, balanced & quiet",
      "content": "Compared to other mini PCs in its performance class, the Minisforum MS-S1 Max scores with its high versatility and modern connectivity. In addition, the extensive UEFI settings allow flexible adjustment of performance and fan speed so that the system can be brought to a pleasantly balanced level.\n\nAll further details on the Minisforum MS-S1 Max can be found here in our review.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Minisforum-MS-S1-Max-mini-PC-review-Performance-modes-compared-performance-balanced-quiet.1126035.0.html",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Investors Heavily Search Advanced Micro Devices, Inc. (AMD): Here is What You Need to Know",
      "content": "Advanced Micro Devices (AMD) has recently been on Zacks.com's list of the most searched stocks. Therefore, you might want to consider some of the key factors that could influence the stock's performance in the near future.\n\nOver the past month, shares of this chipmaker have returned -4.3%, compared to the Zacks S&P 500 composite's +2.7% change. During this period, the Zacks Computer - Integrated Systems industry, which Advanced Micro falls in, has gained 14.9%. The key question now is: What could be the stock's future direction?\n\nAlthough media reports or rumors about a significant change in a company's business prospects usually cause its stock to trend and lead to an immediate price change, there are always certain fundamental factors that ultimately drive the buy-and-hold decision.\n\nEarnings Estimate Revisions\n\nRather than focusing on anything else, we at Zacks prioritize evaluating the change in a company's earnings projection. This is because we believe the fair value for its stock is determined by the present value of its future stream of earnings.\n\nOur analysis is essentially based on how sell-side analysts covering the stock are revising their earnings estimates to take the latest business trends into account. When earnings estimates for a company go up, the fair value for its stock goes up as well. And when a stock's fair value is higher than its current market price, investors tend to buy the stock, resulting in its price moving upward. Because of this, empirical studies indicate a strong correlation between trends in earnings estimate revisions and short-term stock price movements.\n\nAdvanced Micro is expected to post earnings of $1.17 per share for the current quarter, representing a year-over-year change of +27.2%. Over the last 30 days, the Zacks Consensus Estimate has changed -0.6%.\n\nThe consensus earnings estimate of $3.95 for the current fiscal year indicates a year-over-year change of +19.3%. This estimate has changed -0.3% over the last 30 days.\n\nFor the next fiscal year, the consensus earnings estimate of $5.9 indicates a change of +49.4% from what Advanced Micro is expected to report a year ago. Over the past month, the estimate has changed -0.4%.\n\nWith an impressive externally audited track record, our proprietary stock rating tool -- the Zacks Rank -- is a more conclusive indicator of a stock's near-term price performance, as it effectively harnesses the power of earnings estimate revisions. The size of the recent change in the consensus estimate, along with three other factors related to earnings estimates, has resulted in a Zacks Rank #3 (Hold) for Advanced Micro.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/investors-heavily-search-advanced-micro-130003181.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Ken Griffin says it's 'anti-American' if Trump gives 'favor' over tariffs to some companies and not others",
      "content": "lighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nCitadel's CEO said it was \"anti-American\" for President Donald Trump to give big companies tariff relief.\n\nKen Griffin, the billionaire CEO and founder of the hedge fund, criticized Trump during a Thursday CNBC interview.\n\n\"Is that our country, that we're going to favor the big and the connected? That's not the American story,\" Griffin said to CNBC.\n\n\"When the state becomes involved in picking winners and losers, there's only one way this game ends: All of us lose,\" he said.\n\nHis comments come after Trump said in August that he would impose a 100% tariff on the import of semiconductors, but companies that promised to invest in the US would be exempt from it.\n\nIn the same month, Apple announced that it would invest $100 billion in its US facilities, in addition to the $500 billion it pledged in February.\n\nTrump also allowed American chip giants like Nvidia and AMD to sell some chips to China if they agreed to grant the US government a 15% cut of their China revenue.\n\n\"The line outside the White House of every business arguing why they should be exempt from paying tariffs on what they import into their products is nauseating,\" Griffin said to CNBC.\n\nGriffin has previously weighed in on the Trump administration's economic policies.\n\nIn September, Griffin co-authored an opinion piece for The Wall Street Journal, in which he criticized Trump's attacks on the Federal Reserve's independence. Trump has been pressuring Fed chair Jerome Powell to lower interest rates for months.\n\n\"Congress has a duty to oversee the Fed, and this oversight must be free of undue interference from the executive branch,\" Griffin wrote in the opinion piece.\n\nRepresentatives for Griffin at Citadel did not respond to a request for comment from Business Insider.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/ken-griffin-slams-trump-for-granting-some-companies-tariff-favors-2025-9",
      "timestamp": "2025-09-26"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Super Micro (SMCI) Stock Trades Up, Here Is Why",
      "url": "https://finance.yahoo.com/news/super-micro-smci-stock-trades-204708134.html",
      "timestamp": "2025-09-22",
      "content": "Shares of server solutions provider Super Micro (NASDAQ:SMCI) jumped 3% in the afternoon session after the company unveiled a new lineup of AI-optimized..."
    },
    {
      "source": "Barchart.com",
      "headline": "This Under-the-Radar Data Center Stock Is Soaring Thanks to the AI Boom",
      "url": "https://www.barchart.com/story/news/34960304/this-under-the-radar-data-center-stock-is-soaring-thanks-to-the-ai-boom",
      "timestamp": "2025-09-22",
      "content": "With demand accelerating, Arista’s AI future looks dynamic."
    },
    {
      "source": "Windows Central",
      "headline": "Microsoft's official Windows 11 version 25H2 RTM ISO media is now available — Download all 38 languages here for x64 or Arm64",
      "url": "https://www.windowscentral.com/microsoft/windows-11/microsofts-official-windows-11-version-25h2-rtm-iso-media-is-now-available-download-all-28-languages-here-for-x64-or-arm64",
      "timestamp": "2025-09-22",
      "content": "Tired of waiting for Microsoft to release Windows 11 version 25H2 via Windows Update? The official RTM ISO media is now online and can be downloaded straight from Microsoft."
    },
    {
      "source": "Phoronix",
      "headline": "AMD Ryzen AI Max+ \"Strix Halo\" Performance With ROCm 7.0",
      "url": "https://www.phoronix.com/review/amd-rocm-7-strix-halo",
      "timestamp": "2025-09-22",
      "content": "With last week's official release of ROCm 7.0 failing to mention the AMD Ryzen AI Max \"Strix Halo\" SoCs on the supported GPU list, a number of Phoronix readers and from elsewhere were inquiring whether or not Strix Halo works with the new ROCm release. Variou…"
    },
    {
      "source": "Windows Central",
      "headline": "New VLC update adds official support for Windows 11 on Arm and fixes support for Windows XP",
      "url": "https://www.windowscentral.com/microsoft/windows-11/new-vlc-update-adds-official-support-for-windows-11-on-arm-and-fixes-support-for-windows-xp",
      "timestamp": "2025-09-22",
      "content": "VLCs first official update in years look to come with some needed improvements, including Windows on Arm64 support and fixes for Windows XP Service Pack 3."
    },
    {
      "source": "TechRadar",
      "headline": "Nvidia and Intel’s partnership could introduce the huge performance upgrade for handheld gaming PCs I’ve been hoping for",
      "url": "https://www.techradar.com/computing/cpu/nvidia-and-intels-partnership-could-introduce-the-huge-performance-upgrade-for-handheld-gaming-pcs-ive-been-hoping-for",
      "timestamp": "2025-09-22",
      "content": "AMD is arguably running away with the crown in the handheld gaming PC space, with its most powerful SoC challenging an Nvidia RTX GPU, but it might be in trouble after Nvidia and Intel's partnership."
    },
    {
      "source": "CoinDesk",
      "headline": "IREN Shares Jump 11% in Pre-Market Trading as Bitcoin Miner Doubles AI Cloud Fleet",
      "url": "https://www.coindesk.com/markets/2025/09/22/iren-shares-jump-11-in-pre-market-trading-as-bitcoin-miner-doubles-ai-cloud-fleet",
      "timestamp": "2025-09-22",
      "content": "Company lifts AI Cloud ARR target to more than $500 million by Q1 2026 after $674 million GPU expansion."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Meet The Company Challenging Nvidia's AI Dominance. (Hint: It's Not AMD)",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_3b1fbde8-2c94-4bbd-86b7-cbdded5f648f",
      "timestamp": "2025-09-22",
      "content": null
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Nvidia, AMD Seals $670M GPU Order As IREN Doubles AI Cloud Power",
      "url": "https://finance.yahoo.com/news/nvidia-amd-seals-670m-gpu-195805440.html",
      "timestamp": "2025-09-22",
      "content": "IREN Soars Into AI Race With $670M Nvidia, AMD GPU Megadeal"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Bank of America shocks with AMD stock verdict post Nvidia-Intel deal",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_90d22509-969b-469e-8e89-32a72176fc0c",
      "timestamp": "2025-09-21",
      "content": null
    },
    {
      "source": "Windows Central",
      "headline": "It's insane to me that this mini PC can outperform an NVIDIA RTX 5090 with LLMs and AI workloads",
      "url": "https://www.windowscentral.com/hardware/hp/hp-z2-mini-g1a-review",
      "timestamp": "2025-09-21",
      "content": "I've been testing the HP Z2 Mini (G1a), and it's an insanely capable PC that aims to be an all-in-one workstation for AI, LLMs, and other intense workloads."
    },
    {
      "source": "Phoronix",
      "headline": "Linux 6.17-rc7 Released: Linux 6.17 Stable Expected Next Week",
      "url": "https://www.phoronix.com/news/Linux-6.17-rc7",
      "timestamp": "2025-09-21",
      "content": "Linus Torvalds just released Linux 6.17-rc7 as the last planned release candidate of the in-development Linux 6.17 kernel that is expected to go final next weekend..."
    },
    {
      "source": "MakeUseOf",
      "headline": "I taught Obsidian to listen and write my notes for me",
      "url": "https://www.makeuseof.com/obsidian-voice-notes-setup/",
      "timestamp": "2025-09-21",
      "content": "Obsidian makes a decent stenographer."
    },
    {
      "source": "Eurogamer.net",
      "headline": "Lenovo cancels Legion Go 2 pre-orders on its own website after demand \"substantially exceeded projections\"",
      "url": "https://www.eurogamer.net/lenovo-cancels-legion-go-2-pre-orders-on-its-own-website-after-demand-substantially-exceeded-projections",
      "timestamp": "2025-09-21",
      "content": "Lenovo has confirmed that whilst Legion Go 2 units are now making their way to \"major retailers globally\", some pre-orders placed on Lenovo's very own website will \"need\" to be cancelled. Read more"
    },
    {
      "source": "XDA Developers",
      "headline": "I tried using a FreeBSD distro that's meant to be run off a flash drive",
      "url": "https://www.xda-developers.com/i-tried-using-a-freebsd-distro-thats-meant-be-run-off-a-flash-drive/",
      "timestamp": "2025-09-21",
      "content": "NomadBSD exceeded all my expectations"
    },
    {
      "source": "TechRadar",
      "headline": "Nvidia AI sales to reach almost $400 billion by 2028, research claims - but then things will get a bit tricky for the world's largest company",
      "url": "https://www.techradar.com/pro/nvidia-ai-sales-to-reach-almost-usd400-billion-by-2028-claims-research-and-then-things-will-get-a-bit-tricky-for-the-worlds-largest-company",
      "timestamp": "2025-09-21",
      "content": "Nvidia’s AI revenue may reach $400 billion by 2028 - yet slowing growth, rising costs, and competition could pose risks."
    },
    {
      "source": "Benzinga",
      "headline": "Elon Musk Refutes Claims Of xAI's $10 Billion Funding Round, Says 'xAI Is Not Raising Any Capital Right Now'",
      "url": "https://www.benzinga.com/markets/tech/25/09/47779757/elon-musk-refutes-claims-of-xais-10-billion-funding-round-says-xai-is-not-raising-any-capital-right-now",
      "timestamp": "2025-09-21",
      "content": ""
    },
    {
      "source": "Wccftech",
      "headline": "GMKtec EVO-X2 AI “AMD Ryzen AI MAX+ 395” Mini PC: The World’s Most Powerful SoC For AI, Gaming & Everything",
      "url": "https://wccftech.com/review/gmktec-evo-x2-ai-amd-ryzen-ai-max-395-mini-pc-the-worlds-most-powerful-soc-for-ai-gaming-everything/",
      "timestamp": "2025-09-21",
      "content": "GMKtec has been making Mini PCs for years now. They are based out of the technology hub of Shenzen, China, and have maintained strategic partnerships with AMD, Intel & Microsoft, and currently offer a wide array of solutions, all the way from entry-level to e…"
    },
    {
      "source": "SiliconANGLE News",
      "headline": "Intel-Nvidia: The baton passes to the CUDA era",
      "url": "https://siliconangle.com/2025/09/20/intel-nvidia-baton-passes-cuda-era/",
      "timestamp": "2025-09-21",
      "content": "In our view, the Intel–Nvidia pact further accentuates Nvidia Corp.’s dominant market position and represents a milestone in the transition to the next era of computing. Just as Intel Corp. had a lock on the market in the ’80s and ’90s, Nvidia has now extende…"
    },
    {
      "source": "Biztoc.com",
      "headline": "Bank of America shocks with AMD stock verdict post Nvidia-Intel deal",
      "url": "https://biztoc.com/x/c654825adaa4a671",
      "timestamp": "2025-09-21",
      "content": "Advanced Micro Devices (AMD) has spent 2025 clawing from “credible challenger” to a true second engine in the AI arms race.\nCase in point is that its management bumped an annual cadence in accelerators with MI325X heading into mass production and MI350 slated…"
    },
    {
      "source": "Omgubuntu.co.uk",
      "headline": "VLC’s First Update This Year Adds Qt6 Support, Dark Style + More",
      "url": "https://www.omgubuntu.co.uk/2025/09/vlc-player-update-2025",
      "timestamp": "2025-09-20",
      "content": "It’s been over a year since VLC, a free open source media player you might have heard of before, was last updated — but a new one is about to arrive. VLC 3.0.22 is the twenty-third release in the VLC 3.0 series, which debuted back in 2018. Videolan (the non-p…"
    },
    {
      "source": "Windows Central",
      "headline": "The Lenovo Legion Go 2 preorder situation goes from bad to worse — preorders start getting cancelled. \"We know this is frustrating.\"",
      "url": "https://www.windowscentral.com/gaming/the-lenovo-legion-go-2-preorder-situation-goes-from-bad-to-worse-",
      "timestamp": "2025-09-20",
      "content": "Lenovo allowed users to preorder the Legion Go 2 with inventory it didn't have, seemingly."
    },
    {
      "source": "XDA Developers",
      "headline": "6 operating system luxuries Windows users have never known about Linux",
      "url": "https://www.xda-developers.com/operating-system-luxuries-windows-users-have-never-known-about-linux/",
      "timestamp": "2025-09-20",
      "content": "Windows may seem easier, but Linux has a lot of advantages over it. You might not even know these features exist, but they're fantastic."
    },
    {
      "source": "Codingconfessions.com",
      "headline": "What Makes System Calls Expensive: A Linux Internals Deep Dive",
      "url": "https://blog.codingconfessions.com/p/what-makes-system-calls-expensive",
      "timestamp": "2025-09-20",
      "content": "An explanation of how Linux handles system calls on x86-64 and why they show up as expensive operations in performance profiles"
    },
    {
      "source": "Forbes",
      "headline": "Abilene’s Energy Setup",
      "url": "https://www.forbes.com/sites/johnwerner/2025/09/20/abilenes-energy-setup/",
      "timestamp": "2025-09-20",
      "content": "Crusoe spearheads Abilene’s Stargate buildout, financing, constructing, and harnessing renewable energy to power massive Nvidia GPU clusters for AI."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Trump is already wielding his ‘golden share’ authority at U.S. Steel, overriding the company’s plans for an Illinois plant, report says",
      "url": "https://finance.yahoo.com/news/trump-already-wielding-golden-share-225826240.html",
      "timestamp": "2025-09-20",
      "content": "This marks the latest move by the administration to exert power over private industry."
    },
    {
      "source": "Biztoc.com",
      "headline": "Prediction: These AI Chip Stocks Could Soar (Hint: It's Not Nvidia or Broadcom)",
      "url": "https://biztoc.com/x/674d4c4ee2144920",
      "timestamp": "2025-09-20",
      "content": "Key Points\n-\nAMD and Marvell are both currently in the shadows of Nvidia and Broadcom.\n-\nHowever, AMD has a nice opportunity as the AI infrastructure market starts to shift toward inference.\n-\nMarvell, meanwhile, has been winning its own custom AI chip design…"
    },
    {
      "source": "Fortune",
      "headline": "Trump is already wielding his ‘golden share’ authority at U.S. Steel, overriding the company’s plans for an Illinois plant, report says",
      "url": "https://fortune.com/2025/09/20/trump-us-steel-nippon-trump-golden-share-granite-city-plant-blocked-politics/",
      "timestamp": "2025-09-20",
      "content": "This marks the latest move by the administration to exert power over private industry."
    },
    {
      "source": "Notebookcheck.net",
      "headline": "AMD Ryzen AI Max+ 395 is powering some of the fastest mini PCs available",
      "url": "https://www.notebookcheck.net/AMD-Ryzen-AI-Max-395-is-powering-some-of-the-fastest-mini-PCs-available.1116962.0.html",
      "timestamp": "2025-09-20",
      "content": "The Zen 5 Strix Halo CPU is proving to be excellent for performance mini PCs. Not only is it fast, but its Radeon 8060S GPU blows every other integrated solution currently available out of the water."
    },
    {
      "source": "TheStreet",
      "headline": "Analysts revamp Nvidia stock outlook on its investment in Intel",
      "url": "https://www.thestreet.com/technology/analysts-revamp-nvidia-stock-outlook-on-its-investment-in-intel-",
      "timestamp": "2025-09-20",
      "content": "Analysts provided their opinion on Nvidia stock, following the company's $5 billion investment into Intel."
    },
    {
      "source": "XDA Developers",
      "headline": "Dangerous PC hardware myths for novice PC builders",
      "url": "https://www.xda-developers.com/most-dangerous-pc-hardware-myths-for-new-pc-builders/",
      "timestamp": "2025-09-19",
      "content": "Don't take every piece of PC building advice seriously"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "What Makes Advanced Micro Devices (AMD) an Investment Bet?",
      "url": "https://finance.yahoo.com/news/makes-advanced-micro-devices-amd-124259433.html",
      "timestamp": "2025-09-19",
      "content": "Macquarie Asset Management, an investment management company, released its “Macquarie Core Equity Fund” investor letter for the second quarter of 2025. A..."
    },
    {
      "source": "Biztoc.com",
      "headline": "Nvidia and Intel Join Hands. Is Trouble Ahead for AMD Stock?",
      "url": "https://biztoc.com/x/dc908b2969786093",
      "timestamp": "2025-09-19",
      "content": ""
    },
    {
      "source": "PC Gamer",
      "headline": "Nvidia and Intel joining forces could be seen as anti-AMD, but it just serves to highlight AMD's advantage with Ryzen and Radeon under one roof",
      "url": "https://www.pcgamer.com/hardware/nvidia-and-intel-joining-forces-could-be-seen-as-anti-amd-but-it-just-goes-to-highlight-amds-advantage-with-ryzen-and-radeon-under-one-roof/",
      "timestamp": "2025-09-19",
      "content": "A big benefit when it comes to AI."
    },
    {
      "source": "Ozbargain.com.au",
      "headline": "Corsair iCUE QL140 RGB 140mm PWM White Fan – Single Pack $12 + Free Delivery (Min Spend $40) @ Radium PCs",
      "url": "https://www.ozbargain.com.au/node/924881",
      "timestamp": "2025-09-19",
      "content": "Hi Everyone, we’ve got a spare batch of Corsair iCUE QL140 RGB 140mm PWM White Fans. These are a solid option if you’re after both airflow and lighting, and they fit perfectly into white or …"
    },
    {
      "source": "Ghacks Technology News",
      "headline": "Steam to end support for Windows 32-bit in 2026",
      "url": "https://www.ghacks.net/2025/09/19/steam-to-end-support-for-windows-32-bit-in-2026/",
      "timestamp": "2025-09-19",
      "content": "Valve has announced that it will be ending support for Steam on 32-bit versions of Windows. This shouldn't affect a lot of users. Okay, I have to ask. What's with all the […]\nThank you for being a Ghacks reader. The post Steam to end support for Windows 32-bi…"
    },
    {
      "source": "SamMobile",
      "headline": "Samsung may supply 10,000 HBM3E chips to Nvidia",
      "url": "https://www.sammobile.com/news/samsung-may-supply-10000-hbm3e-chips-nvidia/",
      "timestamp": "2025-09-19",
      "content": "Last month, we reported that Samsung’s HBM3E chips might have finally met Nvidia's quality standards. Well, we now have information about how many of those chips Samsung will supply to Nvidia for its AI accelerators. According to a report from AlphaBiz, Samsu…"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Musk says xAI is not raising capital after CNBC report on $10 billion funding",
      "url": "https://finance.yahoo.com/news/xai-raises-10-billion-200-173421386.html",
      "timestamp": "2025-09-19",
      "content": "According to the CNBC report, the funding was likely to go to building data centers using Nvidia and AMD graphics processing units, needed to develop next..."
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Nvidia wants 10Gbps HBM4 to blunt AMD’s MI450, report claims — company said to be pushing suppliers for more bandwidth",
      "url": "https://www.tomshardware.com/pc-components/gpus/nvidia-wants-10gbps-hbm4-to-rival-amd-mi450",
      "timestamp": "2025-09-19",
      "content": "Nvidia is reportedly pressing its memory vendors to push beyond JEDEC’s official HBM4 baseline, reportedly requesting 10Gb/s-per-pin stacks for its 2026 Vera Rubin platform."
    },
    {
      "source": "The Verge",
      "headline": "Nvidia invests $5 billion into Intel to jointly develop PC and data center chips",
      "url": "https://www.theverge.com/news/780792/nvidia-intel-investment-pc-chips-data-center",
      "timestamp": "2025-09-18",
      "content": "Nvidia is throwing Intel a $5 billion life raft, just weeks after similar stakes from the US government and SoftBank. Nvidia is investing $5 billion in Intel common stock in a collaboration that will see the pair “jointly develop multiple generations of custo…"
    },
    {
      "source": "Barchart.com",
      "headline": "Nvidia CEO Jensen Huang Says 'You Can’t Overstate the Magic' That is Taiwan Semiconductor, But is TSM Stock a Buy at New Highs?",
      "url": "https://www.barchart.com/story/news/34900133/nvidia-ceo-jensen-huang-says-you-cant-overstate-the-magic-that-is-taiwan-semiconductor-but-is-tsm-stock-a-buy-at-new-highs",
      "timestamp": "2025-09-18",
      "content": "Foundry giant Taiwan Semiconductor will play a key role in the new partnership between Nvidia and Intel, according to CEOs Jensen Huang and Lip-Bu Tan."
    },
    {
      "source": "Business Insider",
      "headline": "Nvidia CEO explains why he's making a $5 billion bet on struggling chip giant Intel",
      "url": "https://www.businessinsider.com/intel-investment-nvidia-jensen-huang-stock-ai-chip-plans-2025-9",
      "timestamp": "2025-09-18",
      "content": "\"Having Jensen's blessing is priceless,\" wrote Bernstein senior analyst  Stacy Rasgon about Nvidia's $5 billion investment in Intel."
    },
    {
      "source": "Windows Central",
      "headline": "Intel and NVIDIA announce partnership that will see \"jointly developed x86 Intel CPUs fused with RTX GPUs\" in shocking move",
      "url": "https://www.windowscentral.com/hardware/intel/intel-and-nvidia-announce-partnership-that-will-see-jointly-developed-x86-intel-cpus-fused-with-rtx-gpus-in-shocking-move",
      "timestamp": "2025-09-18",
      "content": "NVIDIA is partnering up with Intel to product new chips that fuse x86 Intel CPUs with RTX GPUs in an attempt to compete with AMD APUs, along with helping Intel stay afloat in its fight with TSMC."
    },
    {
      "source": "Phoronix",
      "headline": "Linux 6.17 AMD PMF Driver Adding New ACPI ID For Upcoming AMD Platform",
      "url": "https://www.phoronix.com/news/Linux-6.17-AMD-AMDI0108",
      "timestamp": "2025-09-18",
      "content": "A new round of platform-drivers-x86 \"fixes\" were submitted today for the nearly-complete Linux 6.17 kernel cycle. While on the fixes stage of the kernel, the x86 platform driver changes can be interesting when it comes to new device IDs for enabling new produ…"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "China’s Showcase of AI Chip Prowess Triggers $240 Billion Rally",
      "url": "https://finance.yahoo.com/news/china-showcase-ai-chip-prowess-102749077.html",
      "timestamp": "2025-09-18",
      "content": "On Thursday, Huawei for the first time publicly laid out its three-year roadmap for chip development, boasting of “super clusters” and vastly faster AI chips..."
    },
    {
      "source": "PCWorld",
      "headline": "Intel’s deal with Nvidia could utterly rewrite the future of laptops",
      "url": "https://www.pcworld.com/article/2913537/intels-deal-with-nvidia-could-utterly-rewrite-the-future-of-laptops.html",
      "timestamp": "2025-09-18",
      "content": "Intel’s blockbuster deal with Nvidia to jointly design custom PC processors containing RTX GPUs gives Nvidia an entry point into the vast majority of laptops even as Intel trades some of its future away in return for cash.\r\n\n\n\n\nAlthough the mammoth Intel-Nvid…"
    },
    {
      "source": "PCWorld",
      "headline": "Intel Arc graphics face a murky future after Nvidia’s $5B RTX mashup",
      "url": "https://www.pcworld.com/article/2913669/intel-arc-graphics-face-a-murky-future-after-nvidias-5b-rtx-mashup.html",
      "timestamp": "2025-09-18",
      "content": "Surprise! We woke up this morning to a blockbuster mashup between Intel and Nvidia. Team Green invested a cool $5 billion into Intel, and in exchange, the two companies will be co-creating consumer and data center x86 processors interwoven with Nvidia’s RTX g…"
    },
    {
      "source": "The Indian Express",
      "headline": "Nvidia bets big on Intel with $5 billion stake and chip partnership",
      "url": "https://indianexpress.com/article/business/nvidia-bets-big-on-intel-with-5-billion-stake-and-chip-partnership-10257653/",
      "timestamp": "2025-09-18",
      "content": "Nvidia, whose must-have chips are powering a global artificial intelligence boom, said in a statement it will pay $23.28 per share for Intel common stock, a price slightly below the $24.90 at which Intel shares closed on Wednesday."
    },
    {
      "source": "PCWorld",
      "headline": "RTX graphics on CPUs: Nvidia and Intel are officially joining forces",
      "url": "https://www.pcworld.com/article/2913435/rtx-graphics-on-cpus-nvidia-and-intel-are-joining-forces.html",
      "timestamp": "2025-09-18",
      "content": "Nvidia is on top of the world right now, riding waves of investment in “AI” and becoming one of the most powerful and most profitable companies on the planet. Intel? Not so much. The company has been struggling in sales and performance for more than a year.\r\n…"
    },
    {
      "source": "PC Gamer",
      "headline": "Intel and Nvidia announce stunning plans to combine their CPU and GPU products for both consumer PCs and AI servers, with Nvidia taking a $5 billion stake in Intel",
      "url": "https://www.pcgamer.com/hardware/processors/intel-and-nvidia-announce-stunning-plans-to-combine-their-cpu-and-gpu-products-for-both-consumer-pcs-and-ai-servers-with-nvidia-taking-a-usd5-billion-stake-in-intel/",
      "timestamp": "2025-09-18",
      "content": "Well, we weren't expecting this."
    },
    {
      "source": "TechRadar",
      "headline": "Huawei throws massive 1-million NPU gauntlet at Nvidia and AMD as it positions itself an alternative to US AI giants",
      "url": "https://www.techradar.com/pro/huawei-throws-massive-1-million-npu-gauntlet-at-nvidia-and-amd-as-it-positions-itself-an-alternative-to-us-ai-giants",
      "timestamp": "2025-09-18",
      "content": "Who needs Instinct or Blackwell when we’ve got the Ascend family from Huawei."
    },
    {
      "source": "Osnews.com",
      "headline": "Intel to build x86 CPUs with NVIDIA graphics, most likely spelling the end of ARC",
      "url": "https://www.osnews.com/story/143373/intel-to-build-x86-cpus-with-nvidia-graphics-most-likely-spelling-the-end-of-arc/",
      "timestamp": "2025-09-18",
      "content": "Intel is in very dire straits, and as such, the company needs investments and partnerships more than anything. Today, NVIDIA and Intel announced just such a partnership, in which NVIDIA will invest $5 billion into the troubled chip giant, while the two compan…"
    },
    {
      "source": "Windows Central",
      "headline": "Zen 3 refuses to die — AMD quietly adds four new Ryzen chips, including budget CPU F-series options",
      "url": "https://www.windowscentral.com/hardware/amd/amd-launches-zen-5-4-3-chips-budget",
      "timestamp": "2025-09-17",
      "content": "Just when you thought Zen 3 was in the rearview, AMD adds another new CPU. It also announced a new option for Zen 4, as well as two new F-series Ryzen 9000 chips."
    },
    {
      "source": "Theregister.com",
      "headline": "Ruh-roh. DDR5 memory vulnerable to new Rowhammer attack",
      "url": "https://www.theregister.com/2025/09/17/ddr5_dram_rowhammer/",
      "timestamp": "2025-09-17",
      "content": "Google and ETH Zurich found problems with AMD/SK Hynix combo, will probe other hardware\nResearchers from Google and Swiss university ETH Zurich have found a new class of Rowhammer vulnerability that could allow attackers to access info stored in DDR5 memory.…"
    },
    {
      "source": "Phoronix",
      "headline": "AMD Hardware Would Ideally Be Supported By ROCm For ~10 Years",
      "url": "https://www.phoronix.com/news/AMD-ROCm-Hardware-Length",
      "timestamp": "2025-09-17",
      "content": "While down to AMD Austin yesterday for the Instinct MI355X and ROCm 7.0 launch, I had the chance to chat again with Anush Elangovan. As the VP of AI Software at AMD, talking with Anush is always insightful and technical in nature. One of the questions I posed…"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "AMD (AMD) Downgraded to Hold by Erste Group on Margin Concerns",
      "url": "https://finance.yahoo.com/news/amd-amd-downgraded-hold-erste-030425678.html",
      "timestamp": "2025-09-17",
      "content": "Advanced Micro Devices, Inc. (NASDAQ:AMD) is one of the AI Stocks in the Spotlight for Investors. On September 11, Erste Group analyst Hans Engel downgraded ..."
    },
    {
      "source": "Biztoc.com",
      "headline": "Vietnam's Vinfast to build $2 bln electric vehicle factory in U.S",
      "url": "https://biztoc.com/x/c42cdfa6d241dce3",
      "timestamp": "2025-09-17",
      "content": ""
    },
    {
      "source": "PC Gamer",
      "headline": "Researchers argue that 'at least 40%' of the bloated x86 ISA could be removed and emulated to improve CPU efficiency",
      "url": "https://www.pcgamer.com/hardware/processors/researchers-argue-that-at-least-40-percent-of-the-bloated-x86-isa-could-be-removed-and-emulated-to-improve-cpu-efficiency/",
      "timestamp": "2025-09-17",
      "content": "They propose a big SHRINK."
    },
    {
      "source": "Ghacks Technology News",
      "headline": "Fedora Linux 43 beta released, drops X11 support to go Wayland only",
      "url": "https://www.ghacks.net/2025/09/17/fedora-linux-43-beta-released-drops-x11-support-to-go-wayland-only/",
      "timestamp": "2025-09-17",
      "content": "Fedora Linux 43 beta has been announced. The distro does not support X11 session, it is Wayland-only. This is because GNOME decided to end support for Xorg. Back in 2023, when GNOME […]\nThank you for being a Ghacks reader. The post Fedora Linux 43 beta releas…"
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Modern memory is still vulnerable to Rowhammer vulnerabilities — Phoenix root privilege escalation attack proves that Rowhammer still smashes DDR5 security to bits",
      "url": "https://www.tomshardware.com/tech-industry/cyber-security/modern-memory-is-still-vulnerable-to-rowhammer-vulnerabilities-phoenix-root-privilege-escalation-attack-proves-that-rowhammer-still-smashes-ddr5-security-to-bits",
      "timestamp": "2025-09-17",
      "content": "A new attack on DDR5 further demonstrates that current countermeasures against Rowhammer-style assaults aren't enough."
    },
    {
      "source": "Windows Central",
      "headline": "\"Substantially superior to FSR 3.1\" — How modders forced FSR 4 upscaling onto unsupported AMD and NVIDIA cards",
      "url": "https://www.windowscentral.com/hardware/amd/fsr-4-rdna-2-3-nvidia-amd-unsupported",
      "timestamp": "2025-09-16",
      "content": "Remember that FSR 4 source code leak on GitHub from a few weeks ago? Someone used it to get AMD's latest upscaler running on unsupported hardware."
    },
    {
      "source": "Phoronix",
      "headline": "AMD ROCm 7.0 Begins Rocking Out On GitHub",
      "url": "https://www.phoronix.com/news/AMD-ROCm-7.0-Rolling-Out",
      "timestamp": "2025-09-16",
      "content": "As a pleasant surprise waking up this morning is AMD ROCm 7.0 release tags beginning to appear on GitHub, indicating the likely imminent official release of the ROCm 7.0 compute stack as the open-source AMD Radeon/Instinct software stack aimed to be the open …"
    },
    {
      "source": "Phoronix",
      "headline": "AMD ROCm 7.0 Officially Released With Many Significant Improvements",
      "url": "https://www.phoronix.com/news/AMD-ROCm-7.0-Released",
      "timestamp": "2025-09-16",
      "content": "Overnight the AMD ROCm 7.0 release tags began appearing within the public Git repositories. Now AMD ROCm 7.0 is officially released as a very significant step forward for AMD's open-source GPU compute stack for better competing against NVIDIA's CUDA ecosystem…"
    },
    {
      "source": "Fc2.com",
      "headline": "TSMC 2nmプロセスの最初の顧客はAMD, NVIDIA, MediaTek, Apple",
      "url": "https://northwood.blog.fc2.com/blog-entry-12845.html",
      "timestamp": "2025-09-16",
      "content": "TSMC's first 2 nm Node Customers are Apple, AMD, NVIDIA, and MediaTek; Intel Missing（TechPowerUp）[News] TSMC 2nm Gains Steam: MediaTek Completes First 2nm Tape-Out as Apple Preps A20, M6, R2（TrendForce）TrendForceがTSMC 2nmプロセス―N2の最初の顧客についての記事を掲載している。最も大きいのはApp…"
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Nvidia tipped to be TSMC's first 16A customer, ahead of Apple — Feynman GPUs could make full use of GAA transistors and backside power",
      "url": "https://www.tomshardware.com/tech-industry/semiconductors/nvidia-dethrones-apple-to-debut-tsmc-a16",
      "timestamp": "2025-09-16",
      "content": "Nvidia will be the first customer to use TSMC’s A16, a 1.6nm-class process that marries gate-all-around (GAA) transistors with backside power delivery."
    },
    {
      "headline": "The 2025 Enhanced Ryzen 5 Gaming Mini PC Just Hit Its Lowest Price, Over 2x Cheaper Than Mac Mini",
      "content": "If you haven’t got the largest living space—perhaps you’re in a one bedroom or even a studio—you know just how valuable every square inch is. You may not have the room for a massive computer on your desk. Maximize your workspace by downsizing your PC. This mini PC from KAMRUI is currently on sale for 25% off. It normally is going for $400, but right now it’s come down to just $299. Save $101 for a limited time.\n\nSo what we’re working with here with the KAMRUI mini PC is compact case containing a 2025 enhanced edition Ryzen 5 7430U six-core, 12-thread AMD processor. It’s got an integrated graphics card, has 32GB of RAM and a full 512GB of storage space on its SSD.\n\nSee at Amazon\n\nThis isn’t designed for high-end computing like doing any kind of 3D modeling or 4K video editing, but it’s great for “everyday” computer tasks. If you’re someone who really just needs a PC capable of receiving and sending emails, watching YouTube videos, or working within any of the basic Microsoft Office apps like Word, PowerPoint, or Excel, then this miniature computer will do the trick just fine.\n\nThe KAMRUI mini PC is capable of connecting to three different displays at once, each able to achieve a resolution of 4K and refresh rate of 60Hz. It’s got support for DisplayPort 1.4, HDMI 2.0, and video and audio transfer over USB 3.2 Gen2 Type-C. Beyond those ports, you also have six USB-A ports to connect various accessories and peripherals. You also get Wi-Fi 6 and Bluetooth 5.2.\n\nWhy Go Mini?\n\nEven though many TVs just have built-in streaming apps, and media players like Fire TV and Roku are fairly cheap to come by, you still may want to opt for powering your home theater with a mini PC instead. You’ll be able to handle a wide range video formats, plus you can play media saved locally. Plus, it’s small form factor allows it to easily be hidden behind your TV or within your entertainment center.\n\nLots of users find mini PCs to be a great option for setting up a PLEX server so you can access your media files from anywhere. Mini PCs also make for wonderful emulation machines as retro game software doesn’t require much processing power. Just be sure your ROMs are all legally acquired.\n\nFor a limited time, you can secure yourself one of these KAMRUI mini PCs for a whole $101 off. The $400 mini PC has come down to just $299 for the time being.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/the-2025-enhanced-ryzen-5-gaming-mini-pc-just-hit-its-lowest-price-over-2x-cheaper-than-mac-mini-2000627660",
      "timestamp": ""
    },
    {
      "headline": "RTX price crash — Walmart undercuts MSRP on a wide range of NVIDIA's latest GPUs",
      "content": "Deals on RTX 5000 cards are never to be sniffed at.\n\nNVIDIA's RTX 5000 GPUs based on the Blackwell architecture began launching in January 2025, but they arrived with severe stock shortages and rampant scalping.\n\nIt has taken nearly a full year for the GPU market to calm down, but I'm happy to report that you can now find a range of RTX cards at or below NVIDIA's MSRP.\n\nThe recent price drops are mainly thanks to Walmart's GeForce Week sales event, which sees gaming laptops, desktops, monitors, accessories, and components significantly discounted.\n\nFor example, the PNY RTX 5060 Ti with 16GB of VRAM is now down to $379, which is $50 below MSRP. PNY's RTX 5080 is also enjoying a massive discount, coming in at $929 or $70 below MSRP.\n\nThere are more options to check out, and I've also added an AMD Ryzen 7 9800X3D deal for those going for a CPU and GPU upgrade at the same time.\n\nBest NVIDIA GPU deals at or below MSRP\n\nRTX 5080 Save 15% ($170) PNY GeForce RTX 5080 OC: was $1,099 now $929 at Walmart The mighty RTX 5080 is the GPU that most enthusiasts want for a stellar gaming experience, and up until now, it's been hard to find at MSRP, never mind $70 below the $999 price set by NVIDIA. 💰 $70 below $999 NVIDIA MSRP 👉 See at: Walmart.com Read more ▼\n\nRTX 5090 Save 29% ($800.99) PNY GeForce RTX 5090 OC: was $2,799.99 now $1,999 at Walmart The RTX 5090 is the most powerful GPU in the world right now, and it's not been easy to find at a price anywhere near MSRP. That changes now with this PNY OC version available for $800 less than the usual price. 💰 Matches the $1,999 NVIDIA MSRP 👉 See at: Walmart.com Read more ▼\n\nBonus CPU deal: AMD Ryzen 7 9800X3D\n\nAMD's Ryzen 7 9800X3D is the best gaming CPU in the world. (Image credit: Ben Wilson | Windows Central)\n\nAMD's Ryzen 7 9800X3D is the best gaming CPU you can buy right now, and it's currently 10% off at Walmart and Amazon.\n\nWhile it might be a tad overkill for the lower-end NVIDIA RTX GPUs, it'll make a perfect pairing for the RTX 5070 (or Ti), RTX 5080, or RTX 5090.\n\nWhat is Walmart's GeForce Week? Walmart and NVIDIA have teamed up to deliver a wide range of discounts on all types of hardware, including gaming laptops, desktops, monitors, accessories, and PC components. If it's from NVIDIA, there's a good chance that it's on sale this week at Walmart. Be sure to have a look at my top picks for GeForce Week gaming laptop deals, which I've rounded up in a separate collection.\n\nWhen does Walmart's GeForce Week begin? Walmart's GeForce Week is already underway, having kicked off on September 22, 2025.\n\nWhen does Walmart's GeForce Week end? Walmart's GeForce Week is expected to conclude on September 28, 2025 at midnight. Don't forget to clear out your cart before the sales expire!\n\nFollow Windows Central on Google News to keep our latest news, insights, and features at the top of your feeds!",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/nvidia/geforce-week-gpu-deals-msrp",
      "timestamp": ""
    },
    {
      "headline": "HP EliteBook 8 G1a review: AMD’s hardware shines",
      "content": "At a glance Expert's Rating Pros Great combination of CPU performance and battery life\n\nPremium build quality\n\nRuns Copilot+ PC features with full x86 app compatibility\n\nNice keyboard Cons HP should upgrade this display\n\nMany G1a models aren’t Copilot+ PCs\n\nGPU performance lags\n\nUnimpressive speakers Our Verdict The HP EliteBook 8 G1a is a Copilot+ PC with an excellent mix of CPU performance and battery life. It’s a solid package, but the display drags down the experience, and the GPU just can’t keep up with the rest of the hardware. Price When Reviewed This value will show the geolocated pricing text for product undefined Best Pricing Today\n\nBest Prices Today: HP EliteBook 8 G1a\n\nRetailer Price $1,819.31 View Deal Product Price\n\nThe HP EliteBook 8 G1a is a 16-inch Copilot+ PC laptop aimed at businesses and professionals. It has an AMD CPU, so it marries a speedy CPU with a neural processing unit that can deliver Copilot+ PC features on some models. Plus, unlike a Qualcomm Snapdragon X Arm PC, this is a traditional x86 PC that is guaranteed to run existing business apps and drivers that may not run perfectly on an Arm PC.\n\nBut, although HP proudly markets this as a “next-generation AI PC,” it’s not just about AI features. Overall, it’s a solid laptop that most people would be happy to use for work, although the display doesn’t keep pace with the rest of the experience.\n\nHP recently redesigned its product names, and the EliteBook is HP’s line of laptops aimed at business users. The 8 Series is the entry-level line of EliteBooks, and the “G1a” here means this is a first-generation model in the new lineup with an AMD CPU.\n\nOverall, the HP EliteBook 8 G1a shows how strong AMD’s offerings are right now: Solid CPU performance and an NPU fast enough for Copilot+ PC features at a very competitive price.\n\nHP EliteBook 8 G1a: Specs\n\nThe HP EliteBook 8 G1a has an AMD Ryzen AI processor — our review model included AMD Ryzen AI 7 PRO 350 hardware. That’s an x86 processor with a 50 TOPS NPU for AI features. However, it’s worth noting that not all the models have an NPU fast enough for Copilot+ PC features. HP has a variety of G1a models, and machines like the base AMD Ryzen 5 230 machine deliver up to 16 TOPS. That means they can’t run Microsoft’s Copilot+ PC features and, if your business does have an NPU-powered AI application, it’ll run much slower than on the models with faster NPUs.\n\nBut the processor isn’t the only thing that differs from machine to machine. HP offers a range of configuration options during the purchase process, so you can get a model that’s very different from the below specs.\n\nOur review model had AMD Radeon 860M graphics. While AMD produces a lot of strong discrete GPUs, this is still integrated graphics and it’s not particularly fast.\n\nThe RAM in this machine is user-upgradable and swappable, which is great to see on a business laptop. (The Intel-powered EliteBook 8 G1i I reviewed at the same time has soldered RAM.)\n\nModel number: HP EliteBook 8 G1a 16-inch\n\nHP EliteBook 8 G1a 16-inch CPU: AMD Ryzen AI 7 PRO 350\n\nAMD Ryzen AI 7 PRO 350 Memory: 32GB DDR5 RAM\n\n32GB DDR5 RAM Graphics/GPU: AMD Radeon 860M\n\nAMD Radeon 860M NPU: AMD NPU Compute Accelerator Device (up to 50 TOPS)\n\nAMD NPU Compute Accelerator Device (up to 50 TOPS) Display: 16-inch 1920×1200 IPS display with 60Hz refresh rate\n\n16-inch 1920×1200 IPS display with 60Hz refresh rate Storage: 512GB PCIe NVMe SSD\n\n512GB PCIe NVMe SSD Webcam: 1440p webcam\n\n1440p webcam Connectivity: 2x Thunderbolt 4 (USB Type-C 40 Gbps), 1x USB Type-C (10 Gbps), 1x HDMI 2.1 out, 1x combo audio jack, 1x security lock slot, 1x USB Type-A (5 Gbps)\n\n2x Thunderbolt 4 (USB Type-C 40 Gbps), 1x USB Type-C (10 Gbps), 1x HDMI 2.1 out, 1x combo audio jack, 1x security lock slot, 1x USB Type-A (5 Gbps) Networking: Wi-Fi 7, Bluetooth 5.4\n\nWi-Fi 7, Bluetooth 5.4 Biometrics: Fingerprint reader and IR camera for facial recognition\n\nFingerprint reader and IR camera for facial recognition Battery capacity: 77 Watt-hour battery\n\n77 Watt-hour battery Dimensions: 14.13 x 9.84 x 0.61 inches\n\n14.13 x 9.84 x 0.61 inches Weight: 3.73 pounds\n\n3.73 pounds MSRP: $1,799 as tested\n\nHP EliteBook 8 G1a: Design and build quality\n\nFoundry / Chris Hoffman\n\nThe 16-inch HP EliteBook 8 G1a has a premium-feeling metal chassis in a “Glacial Silver” color. At 3.73 pounds, it’s a little heavier than some laptops, but it feels solid and durable thanks to that metal build.\n\nThe design here is minimal: Dark gray keyboard, black bezel, and silver metal elsewhere. There are a few HP logos (on the lid and just below the screen) and that’s about it. The hinge feels good to use, although I had to use a second hand to hold down the front of the laptop while opening it. It’s a solid hinge and the screen doesn’t move around while you type.\n\nHP bundles HP Wolf security with this machine, and that will be convenient for businesses who want to remotely manage this laptop in a fleet. As an individual knowledge worker, however, I didn’t like the end-user experience. I had to click through extra security dialogs to run PCWorld’s normal benchmark tools, for example — many people will want to disable this, or businesses will want to tune it so it doesn’t nag employees about their business apps.\n\nHP EliteBook 8 G1a: Keyboard and trackpad\n\nFoundry / Chris Hoffman\n\nThe HP EliteBook 8 G1a has a full-size keyboard complete with a number pad. It’s spacious and feels like it has a good amount of key travel — more than the 13-inch HP EliteBook 8 Flip G1i I reviewed at the same time. It’s quiet and doesn’t click with the snap of a mechanical keyboard, but it’s still snappy. This is a good keyboard that you can get a lot of typing done on. But I always wish the arrow keys on laptops were full-size.\n\nThis machine has a large trackpad that feels smooth to glide your finger over and clicks down with a clean “thunk.” I would prefer seeing a haptic touchpad, but this trackpad is solid. This isn’t a glass trackpad — those feel smoother, but those are premium touches reserved for higher-end laptops. Both the keyboard and trackpad are fairly quiet, which is important for a business laptop.\n\nHP EliteBook 8 G1a: Display and speakers\n\nFoundry / Chris Hoffman\n\nThe HP EliteBook 8 G1a has a 16-inch 1920×1200 IPS display with a 60Hz refresh rate and 400 nits of brightness. That’s just nothing special, and that resolution stings on a 16-inch display, especially one in this price range. It’s an anti-glare display, which is nice to see. But HP offers the base model with 300 nits of brightness, which I’d recommend avoiding.\n\nHP does offer a variant of this laptop with a 2560×1600 display with a 120Hz variable refresh rate, and I’d love to see what that machine looks like. But it likely won’t have as much battery life and it’ll be more expensive.\n\nThe display here is the one feature that feels the most lacking on this laptop, especially compared to consumer laptops in a similar price range.\n\nThe stereo speakers on this machine are okay for a business laptop but, like the display, they feel more serviceable than special. They can get pretty loud, and the sound is clear, but the audio lacks some depth. They’ll do a fine job in video meetings. I test each laptop I review by playing Steely Dan’s Aja and Daft Punk’s Get Lucky. The instrument separation in Aja was reasonable, but a lot of the high notes weren’t particularly crisp. In Get Lucky, the sound was reasonably fun, but more bass would’ve been nice. Pack a good pair of headphones for music.\n\nHP EliteBook 8 G1a: Webcam, microphone, biometrics\n\nThe HP EliteBook 8 G1a has a 1440p webcam. Business laptops tend to have solid webcams, so I was expecting a bit more here. It’s nothing special for a business laptop: It’s a little noisy and seems to do much better in ideal lighting. This is the kind of webcam that will look fine in a business meeting, but you’ll want to get an external webcam if you’ll be recording videos for YouTube or social media. HP also built in a privacy shutter above the display, and you can slide it to block the webcam.\n\nThe dual-array microphone setup in this machine was clear and did a good job of removing background noise. It’s solid for a business laptop, but it’s not particularly high-end. If you’re participating in meetings all day and you want the best voice quality possible, you may still want an external mic.\n\nThe EliteBook 8 G1a has both facial recognition hardware and a fingerprint reader in the power button on the keyboard. You can use Windows Hello to sign into Windows with either your fingerprint or your face, and both work well.\n\nHP EliteBook 8 G1a: Connectivity\n\nFoundry / Chris Hoffman\n\nThe HP EliteBook 8 G1a offers a good number of ports, including three USB Type-C ports and two of them are Thunderbolt 4 ports.\n\nOn the left side, this laptop has an HDMI 2.1 out port, two Thunderbolt 4 (USB Type-C 40 Gbps) ports, and a combo audio jack. On the right side, there’s a third USB Type-C port (10 Gbps), a USB Type-A (5 Gbps) port, and a security lock slot.\n\nSince each side of the laptop has a USB Type-C port, you can plug this laptop’s USB-C charger into other side of the laptop. That’s the kind of thing that’s easy to overlook on a spec sheet but makes the laptop much nicer to use in the real world.\n\nYou can also get models of this laptop with optional extra ports: RJ-45 Ethernet, a Smart Card reader, and a nano SIM card slot for cellular connectivity. Unfortunately, it doesn’t have an SD card reader option.\n\nOur review unit had future-proof Wi-Fi 7 and Bluetooth 5.4 wireless networking, and I had no problems with it.\n\nHP EliteBook 8 G1a: Performance\n\nThe HP EliteBook 8 G1a has an AMD Ryzen AI 7 PRO 350 processor, and it performed well in web browsers, communication apps, productivity tools, and the apps you’d run on a Windows desktop.\n\nAs always, though we ran the HP EliteBook 8 G1a through our standard benchmarks to see how it performs.\n\nFoundry / Chris Hoffman\n\nFirst, we run PCMark 10 to get an idea of overall system performance. With an overall PCMark 10 score of 7,605, this AMD-powered machine surpassed similar laptops with recent Intel Core Ultra processors. (And, as we’ll see below, it had similar battery life.)\n\nFoundry / Chris Hoffman\n\nNext, we run Cinebench R20. This is a heavily multithreaded benchmark that focuses on overall CPU performance. It’s a quick benchmark, so cooling under extended workloads isn’t a factor. But, since it’s heavily multithreaded, CPUs with more cores have a huge advantage.\n\nWith a multithreaded Cinebench R20 score of 6,160, the AMD hardware here ran faster than Intel Arrow Lake and Lunar Lake chips.\n\nFoundry / Chris Hoffman\n\nWe also run an encode with Handbrake. This is another heavily multithreaded benchmark, but it runs over an extended period. This demands the laptop’s cooling kick in, and many laptops will throttle and slow down under load.\n\nThe HP EliteBook 8 G1a completed the encode process in an average of 924 seconds — that’s over 15 minutes. This machine can put out some serious CPU performance when it needs to, and it’s a good compromise of performance and power efficiency.\n\nFoundry / Chris Hoffman\n\nNext, we run a graphical benchmark. This isn’t a gaming laptop, but it’s still good to check how the GPU performs. We run 3DMark Time Spy, a graphical benchmark that focuses on GPU performance.\n\nWith a 3DMark Time Spy score of 3,052, the AMD Radeon 860M graphics in this machine weren’t particularly impressive. It’s slower than Intel’s Arc graphics and is on the lower end for AMD’s graphics hardware.\n\nTo be honest, I think most people — including business users — would prefer a laptop with a faster GPU. Lots of businesses use GPU-accelerated tools. I’d prefer to see a faster GPU here, even at the expense of NPU features.\n\nOverall, the HP EliteBook 8 G1a shows how strong AMD’s offerings are right now: Solid CPU performance and an NPU fast enough for Copilot+ PC features at a very competitive price. But this machine cuts a corner when it comes to the GPU, and anyone who uses a GPU-accelerated professional application will want to look elsewhere.\n\nHP EliteBook 8 G1a: Battery life\n\nThe HP EliteBook 8 G1a has a 77 Watt-hour battery, which is a good size for a 16-inch laptop. It delivered a good combination of battery life and performance.\n\nFoundry / Chris Hoffman\n\nTo benchmark the battery life, we play a 4K copy of Tears of Steel on repeat on Windows 11 with airplane mode enabled until the laptop suspends itself. We set the screen to 250 nits of brightness for our battery benchmarks. This is a best-case scenario for any laptop since local video playback is so efficient, and real battery life in day-to-day use is always going to be less than this.\n\nThe HP EliteBook 8 G1a lasted an average of 936 minutes in our benchmarks — that’s nearly 16 hours. While you’ll get less in day-to-day computer use, this is likely enough juice for all-workday battery life, which is what really matters for a business laptop.\n\nHP EliteBook 8 G1a: Conclusion\n\nThe HP EliteBook 8 G1a combines a premium metal build quality with AMD Ryzen AI 7 PRO 350 hardware. In many ways, the result is an excellent, well-balanced machine.\n\nAMD’s chips are highly underrated right now. They don’t match the CPU performance you’ll find in a high-end workstation or the battery life you’ll find in a thin-and-light laptop, but they offer an excellent mix of both. Plus, this delivers an NPU fast enough for Copilot+ PC features, so the AI features here aren’t just marketing. If apps ever start taking more advantage of NPUs, you’ll want a fast one like the 50 TOPS NPU here — not the 12 TOPS NPU Intel is still delivering in most PCs.\n\nBut this isn’t the be-all, end-all business laptop. The display drags down the overall experience, and the graphics performance just isn’t up there with the CPU and NPU performance. While it’s a good laptop, it’s not the right pick for everyone. But I’m happy my review model had AMD hardware, and I think you’d prefer the AMD hardware here to Intel’s current offerings, too.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2916785/hp-elitebook-8-g1a-review.html",
      "timestamp": ""
    },
    {
      "source": "XDA Developers",
      "headline": "Arm is the future of desktop computing, and the writing is on the wall for x86",
      "url": "https://www.xda-developers.com/arm-future-desktop-computing-writing-wall-x86/",
      "timestamp": "2025-09-23",
      "content": "Arm has been slowly picking up pace in the last two decades, but the momentum is only growing stronger."
    },
    {
      "source": "Tympanus.net",
      "headline": "Lax Space: Designing With Duct Tape and Everyday Chaos",
      "url": "https://tympanus.net/codrops/2025/09/23/lax-space-designing-with-duct-tape-and-everyday-chaos/",
      "timestamp": "2025-09-23",
      "content": "Want to build websites but don’t know where to start? Scrimba's Frontend Developer Career Path is the perfect beginner-friendly course to kickstart your journey! Created with Mozilla MDN, it teaches you modern web development skills step by step. Codrops readers get 20% off Pro plans!"
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Nvidia promises its $100 billion OpenAI deal won't impact GPU supply — 'we will continue to make every customer a top priority'",
      "url": "https://www.tomshardware.com/tech-industry/nvidia-promises-its-usd100-billion-openai-deal-wont-impact-gpu-supply-we-will-continue-to-make-every-customer-a-top-priority",
      "timestamp": "2025-09-23",
      "content": "Nvidia has released a statement to make it clear that, no matter what deals it does with companies to provide hardware or take an equity stake in their business, it will ensure all companies have equal access to next-generation GPU hardware."
    },
    {
      "source": "Boilingsteam.com",
      "headline": "OrangePi 5 Ultra Review: An ARM64 SBC Powerhouse",
      "url": "https://boilingsteam.com/orange-pi-5-ultra-review/",
      "timestamp": "2025-09-23",
      "content": "Following our review of their recent RV2 RISC-V board, OrangePi has offered us to review one of their latest ARM64 based hardware, the OrangePi 5 Ultra. This is currently their highest specs ARM64 SBC.\n\nSo what can we expect from the OrangePi Pi 5 Ultra board ? Let’s go through the specs first.\n\nSpecs\n\nThe board is fairly small in size, very close to what you get with the Raspberry Pi.\n\nFeature Specifications Master Chip Rockchip RK3588 (8nm LP process) CPU • 8-core 64-bit processor\n\n• 4 Cortex-A76 and 4 Cortex-A55 with independent NEON coprocessor\n\n• Cortex-A76 at 2.4GHz, Cortex-A55 at 1.8GHz GPU • Integrated ARM Mali-G610\n\n• Built-in 3D GPU\n\n• Fully compatible with OpenGL ES1.½.0/3.2, OpenCL 2.2 and Vulkan 1.2 NPU Embedded NPU supports INT4/INT8/INT16/FP16 hybrid computing with up to 6TOPS PMU RK806-1 RAM LPDDR5 496PIN: 4GB, 8GB, 16GB optional Memory • eMMC flash socket\n\n• eMMC IC\n\n• Note: Either eMMC flash socket or eMMC IC, supports: 32GB, 64GB, 128GB, 256GB optional\n\n• QSPI NOR flash: 16MB\n\n• MicroSD card slot\n\n• M.2 M-KEY slot: supports NVMe SSD (PCIe 3.0 4Lane) USB 2 × USB3.0; 2 × USB2.0 Video • 1 × HDMI 2.1 output up to 8K@60FPS\n\n• 1 × HDMI 2.0 input up to 4K@60FPS\n\n• 1 × MIPI DSI TX 4 Lane Camera • 2 × MIPI CSI 4 Lane\n\n• 1 × MIPI D-PHY RX 4 Lane Audio CODEC: ES8388\n\n• 1 × Audio 3.5mm jack with mic\n\n• 1 × MIC In\n\n• 1 × HDMI 2.1 eARC Ethernet 1 × PCIe 2.5G LAN (RTL8125BG) Wi-Fi + BT Module Onboard Wi-Fi 6E + BT 5.3/BLE module: AP6611\n\n• Wi-Fi interface: SDIO3.0\n\n• BT interface: UART/PCM Expansion Port Dual-row pin: 2.54mm 40Pin\n\n• Supports DC 5V and 3.3V power output\n\n• Configurable UART, PWM, I2C, SPI, CAN, GPIO and other functional interfaces Button 1 × MaskRom key, 1 × On/Off key Power Source Supports Type-C power supply, 5V @ 5A LED RGB LED side illumination FAN 5V 2PIN 1.25mm socket RTC 3V 2PIN 1.25mm socket Debugging Debug serial UART included in 40PIN expansion port Supported OS Orangepi OS (Droid), Orangepi OS (Arch), Orangepi OS (OH), Ubuntu, Debian, Android 13 PCB Length: 89mm, Width: 57mm, Thickness: 1.6mm Weight 60.5g\n\nThe model I received for this review was a 8 GB one. One of the key reasons to use this SBC over other versions, is that it leverages LPDDR5 memory capable of very good speeds.\n\nWhat I like about the specs is the numerous options for storage (one eMMC and another NVME M2 slot), the 2 Gigabit Ethernet port (a single one this time, so don’t expect to make it into a router), the 4 USB ports (sufficient to connect keyboard, mouse, and something else).\n\nOn paper, the specs are impressive with the fairly recent Rockchip processor. There is a NPU as well, but don’t expect to have it supported easily in Linux, even on AMD the NPU support is shaky at best. For this SBC, it involves cross-compilation, custom binaries before you can exploit a model on this board.\n\nThis is what the layout of the board looks like:\n\nHere’s the back view:\n\nNow you should be aware of the following:\n\nMobile GPUs don’t support OpenGL, only the OpenGLES subtype. You can get some Vulkan support (1.2), but as we will see later, hardware support is unfortunately not there yet.\n\nThe board is priced at around 130 USD for the 16GB version (it seems to be the main one being sold right now). Which is roughly equivalent to the Raspberry Pi 5 price for the same amount of memory. However, the Orange Pi 5 Ultra board is much more powerful in comparison, so depending on your use case, the Orange Pi 5 Ultra would represent a better value for money.\n\nOf course, the usefulness of such a board depends entirely on the quality of the software support.\n\nSoftware Support\n\nA Full Ubuntu Experience\n\nThere are many images available for this board. Ubuntu, Debian, Arch… at first I was wondering which one to go for. Even in each category you have a bunch of different images:\n\nFocal (20.04 LTS), either desktop with xfce or server version.\n\n(20.04 LTS), either desktop with xfce or server version. Jammy (22.04 LTS), desktop with GNOME or Xfce, or a server version. But it goes deeper than that. You get two different kernel available. An old 5.10 kernel or a 6.1.\n\nI went for the Ubuntu Jammy 22.04 LTS with the 6.1 kernel, the desktop build using Xfce (GNOME was not available for that kernel).\n\nAs you can see, the Ubuntu 24.04 distro is missing from the list, and this is a shame, since this is a board released late 2024. I contacted OrangePi and they mentioned that they would eventually release a 24.04 version, but there was no clear timeline for that.\n\nTo install Ubuntu, you use dd or Balena Etcher to image a micro-SD card first, and then you get some helper scripts (using ncurses) that make it super easy to image either a eMMC chip, or a NVME drive that’s attached to the board (I don’t recommend using a micro-SD card as the main media).\n\nOnce you reach the desktop, you will see that things work pretty much as expected. Wifi, Bluetooth, and even the HDMI port could properly recognize my Ultra Wide Screen and display the full resolution. This was an issue with the RV2 board from Orange Pi (probably hardware/drivers related) but on ARM64 it seems like things are much more robust.\n\nGPU Support?\n\nSadly, but this was almost expected, there does not seem to be any kind of GPU support in the version that I have chosen. A quick check with glxgears confirms that there is just a software pipe for rendering.\n\nThis being said, the software rendering is very very fast - you can see that there’s a lot of power under the hood on the CPU side. The same glxgears was only running at 35 FPS on the RV2, here it’s 10 times faster!\n\nThere is however hope. It looks like there are efforts to mainline the GPU drivers on the Linux kernel, so when this happens you could expect a standard distro like ARMbian to offer full support of the GPU capabilities. Too early to say, but we will come back on that later.\n\nBecause of the lack of GPU support, I will be skipping the gaming aspects of this board for now. I will revisit it in another article once we have proper GPU drivers, to actually see what we can expect from this SBC once we have the Mali ready for some action.\n\nApplications\n\nI installed and tried bunch of things:\n\nChromium is installed by default and works very well, but is limited to the 110 version which is old by now. Using Flathub and Flatpak I could install a much more recent version, that has proper extensions support. Firefox works fine, too - its fork, Zen browser, also works via Flatpak but is very slow for some reason. I also tried a non-Flatpak install for Zen, but it was also slow, so it’s probably not related to Flatpak itself.\n\nThis is now a good time to talk about Flatpak. When I was reviewing the RV2 board which sports a RISC-V chip, I remarked that there are very few Flatpaks that actually support that architecture. So in effect, while flatpak is supposed to work regardless of the architecture, if you don’t have any binary built for your architecture, you won’t be able to make much use of Flathub and the like. For ARM64, the support is not 100% either, but there is a massive footprint of applications that support ARM64. I tried quite a lot of applications and I was constantly surprised wow, they even have ARM64 for that!. I surmise that this is the effect of having a mainstream ARM64 desktop machine out there running Linux with the Macbooks equipped with the M chipsets, running Asahi. (and a lot of folks who have such machines being developers themselves, of course).\n\nWhile most applications worked with the RV2 (which is roughly equivalent to a Raspberry Pi 3), it showed its limits when you wanted to do video editing for example. Kdenlive and Openshot were barely working. Here, with the OrangePi 5 Ultra, Kdenlive works like a breeze and had no issue dealing with a bit of video editing and rendering. The final video render was certainly not as fast as what you’d expect on a regular X86_64 platform, but you know, it’s workable if you are not dealing with very long videos (also, avoid 4k). We are certainly dealing with a much more capable SOC here.\n\nOut of curiosity, I tried some more professional applications like Dbeaver (for databases interactions), and it worked as expected.\n\nThe same with Memgraph (graph database), used via Docker (since they don’t have a client for ARM64, I used the web client instead). Of course, I did not try to load a massive graph database with this, but the system was very responsive and usable. Honestly, very impressive to see Memgraph running so well on a SBC.\n\nI wasted a lot of time trying to make R and Rstudio for ARM64 work togeher from the distro (without success, there was some kind of issue with the tools base package not being recognized), until I switched gears and used a Docker version of R/Rstudio instead. Once again this proved to work very well (Rstudio is a Java application so the browser IDE is basically identical).\n\nThe only appplication that did not work well was Blender. It launched, but afterwards it was a slideshow with 3 seconds between an interaction and the refresh of the screen. I assume this is because Blender requires GPU support even for its innerworkings, and since we don’t have GPU acceleration in this OS, it’s just not going to cut it.\n\nBut honestly… that’s it! Everything else I tried worked as expected on a usual desktop or laptop. At no time did I feel this is too slow, I can’t wait to stop my review - instead, if you told me that I would only have that SBC to do regular work, well, I could totally see myself living with it for 90% of my use cases.\n\nVery impressive to see this kind of performance in this form factor. And this is a board running only at 1.8 Ghz! I can only imagine how things will improve once they go to a better lithography and manage to increase the frequency of the CPU.\n\nTemperature Control\n\nThe temperature does rise a little when using all cores at once, but it remains at a manageable level. When doing some bursts of compilation the temperature rises up to about 78~80C, and when running LLMs on the CPU (full 100% CPU usage), we get up to 84, 85C.\n\nThis looks like the hard limit - I am not sure if the SBC goes into throttling then, but I did not observe higher temperature. In any cases, in all situations (apart from Blender), the system remained very responsive.\n\nPower Draw\n\nI don’t have a way to measure power draw, but according to AndroidPIMP you can expect an idle power draw between 3W and 5W, and an usage under load on average around 10W. Since the power source can produce 25W maximum, I guess you can imagine the board going up to 15W or so in spikes. In any case, its low power profile and the fact that the temperature remains well under control tells me that this is a great little machine for a server.\n\nAI - LLM Performance\n\nFor this part, I compiled both Ollama and llama.cpp and run some benchmarks on llama.cpp. I tried only smaller models, as I had low expectations that it would be running at usable speeds. The results are below, produced with the llama-bench command.\n\nmodel size params backend threads test t/s gemma3 1B Q4_K - Medium 762.49 MiB 999.89 M CPU 8 pp512 23.37 ± 0.94 gemma3 1B Q4_K - Medium 762.49 MiB 999.89 M CPU 8 tg128 2.49 ± 0.62 granite 3B Q4_0 1.36 GiB 2.53 B CPU 8 pp512 36.34 ± 1.78 granite 3B Q4_0 1.36 GiB 2.53 B CPU 8 tg128 5.06 ± 0.10\n\nFor dense models like Gemma 1B, it’s kind of slow and not really good for chatting. If you plan to use LLMs with this, however, MOE models like granite 3.1 3B work at a decent speed (5 tokens by second, not bad). I would certainly prefer 10 tokens by second minimum, but this is what we have to live with, at least when using the CPU mode. It’s certainly a lot more usable than the RV2 review previously.\n\nOnce we have a capable Vulkan driver working, I wonder if Vulkan can be leveraged to increase the token generation speed on this SBC. It works well on AMD configurations because they can share the overall memory with the iGPU. On ARM, I am not sure if the same flexibility exists.\n\nPerformance\n\nThe go-to suite to evaluate performance is Geekbench, because it can provide some comparison between the speed of similar tests across different architectures. Here, let’s compare it against another flagship ARM64 board, the Raspberry Pi 5 running at 2.4 ghz.\n\nSpec OrangePi 5 Ultra Raspberry Pi 5 Model B Rev 1.1 Operating System Ubuntu 22.04.5 LTS Debian GNU/Linux 12 (bookworm) Processor ARM ARMv8 @ 1.80 GHz, 1 Processor, 8 Cores ARM ARMv8 @ 2.40 GHz, 1 Processor, 4 Cores” Memory 8 GB model 8 GB model\n\nSingle Core Performance\n\nBoth boards end up with a very similar performance on average in single core tests.\n\nThere are some differences, but it’s fairly marginal.\n\nMulti-core performance\n\nWhen doing multi-threaded, multi-core workflows, this is where we see the 8 processors that are available on the Orange Pi 5 Ultra shine.\n\nIts performance surpasses the Raspberry Pi 5 in almost all activities, and usually by a good 30% advantage.\n\nPerformance overview\n\nAs you can see, for parallel workloads, this board is much better than the Raspberry Pi 5.\n\nNow let’s look at the potential use of such boards as servers.\n\nServer Use\n\nYou can use this board as a server, of course. You have several distro images just for the server use, too. Docker works very nicely with this SBC, and unlike what we have seen for the RV2 and the general Risc-V ecosystem where there are very few Docker images available for that architecture, the ARM64 scene is completely different.\n\nHere, it’s almost rare to find a Docker image where there is no ARM64 build. Not surprising since ARM64 is a thing on servers nowadays - Amazon has famously pushed their own ARM Gravitron servers as an option to reduce cloud computing costs. So most companies and providers operating on the cloud pretty much need to have ARM64 builds.\n\nOn the server, you also don’t need to care as much about the lack of GPU support since you are running headless, so any distro provided by OrangePi should do: Debian, Ubuntu, or even Arch.\n\nSince this is a board that operates at low wattage and passive cooling, it’s an excellent choice if you want to build a small server for the home. For a NAS use case I would probably go for the RV2 instead since it has more storage ports, but this one could also work considering you can have an eMMC drive together with another M2 drive (NVME) at the same time.\n\nVerdict\n\nLittle boards that were previously only used for fun or small projects have come a long way. Desktop environments were rarely usable before even on the later iterations of the Raspberry Pi. Things changed a couple of years ago, and the Raspberry Pi 5 and this Orange Pi 5 Ultra fall into a category where you could actually use them as real, daily general purpose computers and not be bothered by their responsiveness, or their performance. Not only will it work well for server use, but it can do desktop work without sweating either.\n\nPrice wise, the 16 GB version is competitive. If you want similarly specced Celeron-equipped mini-PCs you would probably need a configuration with a N100 processor (that seems to be faster than the RK3588), but that is more expensive. So the value for money of this SBC seems to be pretty good at the moment, even for the 16G configuration.\n\nThe only negative points are the moment are:\n\nlack of recent distro images (Ubuntu 24.04 would be nice)\n\nlack of GPU support (potentially because I was using the 6.1 kernel?)\n\nincomplete mainline support\n\nwhich may be some killer aspects depending on your use case. The wide availability of software for ARM64 on Flatpak and Docker somewhat mitigates such issues for now.\n\nThe real solution will come when the RK3588 support will be properly mainlined. Currently only parts of it are supported but it’s not complete and bug-free from what I could read. I am following news around the Arch-based BredOS as they are actively working on bringing proper support for this chip. Once this is done, the benefits should be apparent such as:\n\nMuch better Vulkan performance (compared to proprietary driver)\n\nProper video acceleration in browsers like Chrome\n\nNo more patches to chase from one kernel to the next!\n\nOnce there are news in this regard (hopefully in 2025) I plan to revisit my review of this SBC.\n\nPractical Details\n\nIf you are interested to grab one, there are currently a few shops that sell it online:\n\nAliexpress store: Orange Pi 5 Ultra 16GB at 220 USD (without shipping). Expensive if you are in the US.\n\nAmazon OrangePi Official: Orange Pi 5 Ultra 16GB sells for 158 USD on Amazon.com. (without shipping) - the cheaper option.\n\nThere are probably some more third parties depending on where you are based in the world.\n\nOther valuable resources:\n\nThe OrangePi 5 Ultra Product Page\n\nThe user manual for the board\n\nThe distro page on the OrangePi website.\n\nFinal note, we have been provided with a review unit of this SBC by OrangePi themselves for this article."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Analyst Says Nvidia ‘Getting Into’ Advanced Micro Devices (AMD) Business With Intel Deal",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_863d2e25-c32b-4a16-a602-80651e506576",
      "timestamp": "2025-09-23",
      "content": null
    },
    {
      "source": "Fb.com",
      "headline": "Strengthening US National Security by Making Llama Available to Key Allies",
      "url": "https://about.fb.com/news/2025/09/strengthening-us-national-security-by-making-llama-available-to-key-allies/",
      "timestamp": "2025-09-23",
      "content": "As a proud American company, Meta is committed to playing its part in ensuring the United States and its closest allies have the best tools at their disposal to defend themselves and keep their citizens safe.\n\nLast year, we began making our Llama models available to US government agencies, including those working on defense and national security applications, as well as to private sector partners supporting their work. Llama is particularly well-suited to these sensitive use cases because, as an open source platform, it can be securely downloaded and deployed without the need to transfer sensitive data through third-party AI providers. Governments can also fine-tune Llama models using their own sensitive national security data, host them in secure environments at various levels of classification, and deploy models tailored for specific purposes on-device in the field.\n\nSince late last year, we have also made Llama available for national security use cases to America’s Five Eyes security partners — Australia, Canada, New Zealand, and the UK — and their private sector partners. We are now expanding this access to a number of key US democratic allies in Europe and Asia: France, Germany, Italy, Japan, and South Korea, as well as NATO and European Union institutions.\n\nLlama has been used to help develop advanced AI tools for the US military and national security agencies, enhancing decision-making, mission-specific capabilities, and operational efficiency. For example, Meta is working with the Army’s Combined Arms Support Command on a pilot project to demonstrate how AI and technologies like augmented and virtual reality can help to speed routine repairs and help the Army get equipment back into the field more quickly.\n\nTo bring Llama-based solutions to these US allies, our partners include Accenture, Amazon Web Services, AMD, Anduril, Ask Sage, Booz Allen, C3 AI, Circus, Cyberspatial, Databricks, EdgeRunner AI, Google Cloud, IBM, Microsoft, Lockheed Martin, Oracle, Palantir, Scale AI, Snowflake, and others.\n\nWe are also supporting US national security through our work developing augmented and virtual reality technologies. Through our partnership with Anduril, we are developing a range of wearable products to help maintain America’s technological edge. This program represents the largest effort of its kind to equip US soldiers with enhanced perception and decision-making capabilities.\n\nIn a world where geopolitical power and national security are deeply intertwined with economic output, innovation, and growth, the widespread adoption of open source models like Llama will be essential to maintaining US and allied AI leadership and ensuring our shared values underpin the systems and standards adopted elsewhere. This is recognized by the US government in its AI Action Plan for America, which Meta endorses.\n\nIt is the responsibility of countries leveraging AI for national security to deploy AI ethically, responsibly, and in accordance with relevant international law and fundamental principles, principles the United States and many of its allies have committed to in the Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy.\n\nWe are taking a step-by-step approach to extending access to Llama for defense and national security purposes, and will consider adding further countries in the future in consultation with the US government."
    },
    {
      "source": "Digitimes",
      "headline": "Commentary: How did Intel go from AMD ally to Nvidia partner?",
      "url": "https://www.digitimes.com/news/a20250922PD228/intel-nvidia-amd-2025-ceo.html",
      "timestamp": "2025-09-23",
      "content": "On September 18, 2025, local time in the US, Intel announced a US$5 billion investment from Nvidia and the start of deep collaboration between the two companies. Shortly after, Intel CEO Lip-Bu Tan stated on social media that he would be joining Nvidia CEO Je…"
    },
    {
      "source": "Geeky Gadgets",
      "headline": "Building a 2000W PC : The Ultimate Guide to Extreme Performance",
      "url": "https://www.geeky-gadgets.com/2000w-pc-build-high-performance/",
      "timestamp": "2025-09-23",
      "content": "What does it take to build a machine that can handle everything you throw at it, without breaking a sweat? Imagine a PC so powerful it can render complex 3D models in minutes, process massive datasets without hesitation, and tackle advanced AI workflows like …"
    },
    {
      "source": "Simonhartcher.com",
      "headline": "Why I'm Spoiled by Apple Silicon (But Still Love Framework)",
      "url": "https://simonhartcher.com/posts/2025-09-22-why-im-spoiled-by-apple-silicon-but-still-love-framework/",
      "timestamp": "2025-09-22",
      "content": "A personal comparison of battery life between my MacBook M1 Pro and Framework 13"
    },
    {
      "source": "Theregister.com",
      "headline": "Moody's raises Big Red over flag Oracle's mega AI DC buildout blueprint",
      "url": "https://www.theregister.com/2025/09/22/moodys_raises_questions_over_oracles/",
      "timestamp": "2025-09-22",
      "content": "Ratings agency points out there's a risk of relying on a small number of buyers\nRatings agency Moody's has pointed to the dangers inherent in Oracle's $300 billion agreement with OpenAI - one of the deals contributing to a staggering $455 billion pipeline of …"
    },
    {
      "source": "TechRadar",
      "headline": "'NVLink is the key': Analysts ponder on probably the biggest tech deal of the decade - Intel + Nvidia and what it means for TSMC, AMD and others",
      "url": "https://www.techradar.com/pro/nvlink-is-the-key-analysts-ponder-on-probably-the-biggest-tech-deal-of-the-decade-intel-nvidia-and-what-it-means-for-tsmc-amd-and-others",
      "timestamp": "2025-09-22",
      "content": "Industry commentary sees Nvidia–Intel tie-up as decade-defining, with NVLink at its core, and analysts focused on implications for TSMC and AMD."
    },
    {
      "source": "Theregister.com",
      "headline": "Nvidia adds more air to the AI bubble with vague $100B OpenAI deal",
      "url": "https://www.theregister.com/2025/09/22/openai_nvidia_chips/",
      "timestamp": "2025-09-22",
      "content": "Promises, promises\nanalysis OpenAI and Nvidia have signed a letter of intent wherein OpenAI agrees to buy at least 10 gigawatts of Nvidia systems for its datacenters, while the AI arms dealer returns the favor with an investment of up to $100 billion in the h…"
    },
    {
      "source": "TechRadar",
      "headline": "This tiny PC is the best computer under $200, and its CPU is faster than Apple's M1 Pro",
      "url": "https://www.techradar.com/pro/this-tiny-pc-is-the-best-computer-under-usd200-and-its-cpu-is-faster-than-apples-m1-pro",
      "timestamp": "2025-09-23",
      "content": "If you’re looking for a compact yet powerful desktop replacement, the GenMachine Mini PC with AMD Ryzen 3 5425U processor is one of the best-value options you’ll find right now.\n\nFor a limited time, this mini PC is priced at just $198.99 on Newegg, making it an excellent choice for work, entertainment, and even light gaming.\n\nAt the heart of this system is the Ryzen 3 5425U processor, a 4-core, 8-thread CPU with boost speeds up to 4.1GHz.\n\nIt’s essentially desktop-class performance in a mini form factor that easily handles office tasks, creative projects, and modern games.\n\nPaired with 8GB of DDR4 RAM and a 256GB SSD, the system delivers fast boot times, smooth multitasking, and enough space for your essential apps, files, and media.\n\nToday's best GenMachine mini PC deal\n\nGenMachine GenMachine Mini PC with AMD Ryzen 3 5425U processor: $198.99 at Newegg The GenMachine Mini PC packs serious performance into a tiny form factor, now just $198.99 on Newegg. Powered by an AMD Ryzen 3 5425U (4c/8t, up to 4.1GHz), it comes with 8GB DDR4 RAM and a 256GB SSD for fast multitasking and quick boot times. Supporting dual 4K displays, Wi-Fi 6, and Bluetooth 5.2, it’s great for office work, streaming, or light gaming. Ports include 2 USB-C, 2 USB-A, HDMI, headphone jack, and 4x 2.5G Ethernet. Compact, quiet, and energy-efficient, it's excellent value at under $200. Read more ▼\n\nFor those who need more screen real estate, the GenMachine system supports dual 4K displays, perfect for productivity, editing, or streaming.\n\nWhether you’re working on spreadsheets, watching movies in ultra HD, or running design software, visuals will be sharp, vibrant, and stutter-free.\n\nConnectivity comes in the form of Wi-Fi 6 and Bluetooth 5.2, and you also get a solid port selection: two USB-C ports, two USB-A ports, a 3.5mm headphone jack, HDMI, and four 2.5G Ethernet ports - ideal for everything from fast networking to flexible peripheral setups.\n\nDespite its power, the design is compact, quiet, and energy-efficient. At just 7.8cm x 7.8cm, it won’t take up much desk space and runs efficiently without generating excess noise or heat.\n\nAt under $200, you’d be hard-pressed to find another mini PC that balances performance, design, and modern connectivity this well.\n\nIf you’re open to exploring other bargain mini PCs, Newegg has some excellent alternative options from GenMachine at very competitive prices.\n\nThe GenMachine Mini PC with AMD Ryzen 5 4500U comes with 16GB RAM, a 512GB NVMe SSD, Radeon Graphics, dual HDMI outputs, USB-C, Wi-Fi 6, and Bluetooth 5.2. It’s currently $199.99.\n\nAnother deal is the GenMachine Mini PC with AMD Ryzen 7 3750H, featuring 16GB RAM, a 512GB NVMe SSD, Radeon RX Vega 10 Graphics, HDMI + DisplayPort outputs, and Wi-Fi 5. At just $178.99, it’s the most affordable Ryzen 7-powered option.\n\nFor a newer generation chip, the GenMachine Mini PC with AMD Ryzen 5 5600H includes 16GB RAM, a 256GB NVMe SSD, dual HDMI outputs, USB-C, Wi-Fi 6, and Bluetooth 5.2. Priced at $219.99, it delivers strong performance for work and light gaming on Windows 11 Pro.\n\nLooking for more options? We've tested out the best mobile workstations you can buy right now."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "AMD Target Raised to $200 on AI Gains, CPU Momentum",
      "url": "https://finance.yahoo.com/news/amd-target-raised-200-ai-121944722.html",
      "timestamp": "2025-09-23",
      "content": "This article first appeared on GuruFocus.\n\nAdvanced Micro Devices (AMD, Financials) won fresh support on Wall Street after Bank of America analyst Vivek Arya reiterated a Buy rating and set a $200 price target, pointing to continued growth in artificial intelligence chips and server CPUs. The target represents about 27% upside from current levels.\n\nArya said AMD's share gains in AI and data-center markets outweigh slower trends in cyclical businesses such as consoles and embedded chips. The company's accelerated roadmap includes the MI325X entering mass production this year and the MI350 coming later in 2025, followed by a new AI server platform in 2026.\n\nThe call comes as investors digest Nvidia's $5 billion investment and product pact with Intel, a move seen as strengthening competition in data-center and PC processors. Arya argued the deal could actually benefit AMD, since both companies rely on the x86 ecosystem that AMD also licenses, making the market more robust overall.\n\nAMD stock is up more than 30% this year, though it has been volatile, trading between $76 and $187 over the past 12 months. Analysts hold a Moderate Buy consensus on the stock, with an average target of $188."
    },
    {
      "source": "Creative Bloq",
      "headline": "MSI attempts to combine creativity and AI, and I was pleasantly surprised by the results",
      "url": "https://www.creativebloq.com/tech/laptops/msi-attempts-to-combine-creativity-and-ai-and-i-was-pleasantly-surprised-by-the-results",
      "timestamp": "2025-09-23",
      "content": "The MSI Prestige A16 AI+ is, you guessed it, a dedicated AI laptop. It excels at delivering increased productivity when doing word processing, photo editing, and some 3D modelling, but as soon as I tried to do anything seriously demanding, I wished I had a laptop with a discrete GPU. Aside from performance, this is a good-looking laptop that boasts a bright and vibrant IPS display.\n\nWhy you can trust Creative Bloq Our expert reviewers spend hours testing and comparing products and services so you can choose the best for you. Find out more about how we test.\n\nAnother month, another \"AI\" laptop. This time, it's the MSI Prestige A16 AI+.\n\nMSI has been relentless in its pursuit of the best AI laptop to appeal to people looking for good graphic design laptops, releasing three different models in the past 18 months alone. I’ve reviewed a number of them, from the ultra-portable Prestige 13 AI+ Evo that lacked power to the balanced Prestige 14 AI and the surprisingly capable Prestige 16 AI.\n\nThese three reviews show that the world of AI laptops is still very much hit and miss. If you're seriously into AI image generation, are running AI-powered effects in video editing, or need a finely tuned machine for 3D rendering, then you're likely to come up short. More often than not, dedicated creative workflows will still benefit from dedicated machines.\n\nSo, can the new MSI Prestige A16 AI+ finally buck the trend and deliver on its promise? Let's find out.\n\nKey specifications\n\nSwipe to scroll horizontally Specs as tested CPU: AMD Ryzen™ AI 9 365 NPU: 50 NPU TOPS (73 total AI TOPS) Graphics: AMD Radeon™ 880M Memory: 32GB LPDDR5 Storage: 1TB Screen size: 16 inches Screen type: IPS-Level Resolution: QHD+(2560x1600) Refresh rate: 165 Hz Colour gamut: 100% DCI-P3 Brightness: 400 nits Ports: 2x USB-C, USB-A, HDMI, microSD card reader, audio combo jack Wireless connectivity: Wi-Fi 7, Bluetooth v5.4 Dimensions: 358 x 258.55 x 16.9 -17.35 mm Weight: 1.9 kg\n\n(Image credit: Future / Paul Hatton)\n\nDesign, build and display\n\n• Modern aesthetic with tapered edge\n\n• IPS-panel 100% DCI-P3 and 16:10 ratio display\n\nThe MSI Prestige A16 AI+ makes a strong first impression with its minimalist silver aluminium chassis, which exudes a sleek and professional aesthetic. The base panel consists of a number of design touches that attempt to reduce any sense of bulk and clunkiness that is often associated with 16-inch laptops. These include a tapered edge, a recessed keyboard panel, and a hinge that drops the display down to desk level.\n\nThe laptop's 16-inch IPS panel might not be as superior as an OLED alternative, but it's still pretty bright and vibrant. Using it to edit photos and videos was a joy, even in a light-filled room. It also delivers an impressive level of colour accuracy as well as high levels of contrast. Additionally, the 16:10 aspect ratio provides valuable vertical screen real estate, which is excellent for video timelines and document editing.\n\nGet the Creative Bloq Newsletter Daily design news, reviews, how-tos and more, as picked by the editors. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe display also includes the professional DCI-P3 colour space with 100% coverage. This will be sufficient for most users wanting to make the most of HDR content, but if your work requires an even broader range of colours, then you'll need a display that supports either Adobe RGB or Rec. 2020.\n\nThe keyboard is relatively comfortable, although the size of the keys and distance of travel between keys is a little more than I would have liked for an optimum experience. The trackpad is central to the keyboard, which I like. However, for any task requiring precision, such as graphic design or detailed video editing, a dedicated mouse remains a necessity. The base panel also includes a fingerprint reader to the side, which allows for a quick and easy login.\n\nWeighing in at 1.9 kg (4.2 lbs), the laptop is definitely at the lighter end of the spectrum for 16-inch laptops. This makes it easy to pop in your bag and carry it with you wherever you go. Given that it could cope with some extra weight, I think MSI could have bulked out the display panel to make it less flexible. I want my laptops to be as robust as possible, and even though the base is super durable, the display panel needs more work.\n\nIn terms of external ports, MSI has opted for a pretty simple offering with two USB-Cs, a USB-A, an HDMI, a microSD card reader, and an audio combo jack. For creatives, the most valuable feature is the two Thunderbolt 4-enabled USB-C ports. These not only provide fast 40Gbps data transfer speeds for quickly moving large video and photo files but also support Power Delivery 3.0, allowing you to charge the laptop and connect high-resolution external displays simultaneously.\n\nDesign score: 4/5\n\n(Image credit: Future / Paul Hatton)\n\nFeatures\n\n• Supercharged performance thanks to AI smarts\n\n• An IPS display designed with creatives in mind\n\nThe MSI Prestige A16 AI+ is designed with several features specifically targeted at creative professionals and content creators. These features focus on performance, display quality, and AI-powered tools.\n\n1. AI-powered performance\n\nTo begin with, the laptop is equipped with a powerful AMD Ryzen AI 9 processor, which includes a Neural Processing Unit (NPU). More on how this performs in the dedicated performance section.\n\nThe MSI AI Engine will automatically detect what you're doing (content creation, work, entertainment, etc.) and adjust the hardware settings for optimal performance. I appreciated this, especially when I was flipping between Photoshop, Premiere Pro, SolidWorks, and other applications.\n\nAdditionally, the laptop provides access to Copilot+, Live Captions, Cocreator, and Recall. These combined provide a set of tools which will boost and enhance your productivity (if you use them wisely). Integration into dedicated creative workflows is still lacking, but if you embrace what's there already, then you'll notice some performance benefits.\n\n2. QHD+ Display\n\nMost of this was covered in the above design section, but it's worth stating that the display is specifically set up for creative professionals. The 100% DCI-P3 colour gamut, 16-inch QHD+ resolution (2560 x 1600), and 165Hz refresh rate find their benefits across rendering, animation, video editing, and office applications. I found using the display an absolute joy, no matter whether I was browsing the web, doing some word processing, or getting knee-deep in video editing.\n\n3. Connectivity\n\nUSB Type-C with Thunderbolt 4 compatibility and a MicroSD card reader will help creatives to transfer files quickly and efficiently. I loved how quickly I was able to move files onto the machine, no matter whether I was dealing with MB or GB. This is a machine that can handle large files with ease.\n\nFeature score: 4/5\n\n(Image credit: Future / Paul Hatton)\n\nBenchmark scores\n\nWe test every one of our laptops using the same benchmarking software suite to give you a thorough overview of its suitability for creatives of all disciplines and levels. This includes:\n\n• Geekbench: Tests the CPU for single-core and multi-core power, and the GPU for the system's potential for gaming, image processing, or video editing. Geekbench AI tests the CPU and GPU on a variety of AI-powered and AI-boosted tasks.\n\n• Cinebench: Tests the CPU and GPU's ability to run Cinema 4D and Redshift.\n\n• UL Procyon: Uses UL Solutions' Procyon software suite to test the system's ability for AI image generation in Stable Diffusion, its Microsoft Office performance and its battery life in a looping video test.\n\n• Topaz Video AI: We use Topaz Video AI to test the system's ability to upscale video and convert video to slow-motion.\n\n• PugetBench for Creators: We use the PugetBench for Creators benchmarking suite to test the system's ability to run several key tasks in Photoshop and Adobe Premiere Pro, as well as its performance when encoding/transcoding video.\n\n• ON1 Resize AI: Tests the system's ability to resize 5 photos to 200% in a batch process. We take the total time taken to resize the images and divide by 5.\n\nSwipe to scroll horizontally Header Cell - Column 0 Header Cell - Column 1 MSI Prestige A16 AI+ GEEKBENCH 6 CPU Single-core: Row 0 - Cell 2 Row 1 - Cell 0 CPU Multi-core: Row 1 - Cell 2 Row 2 - Cell 0 GPU OpenCL: Row 2 - Cell 2 CINEBENCH 2024 CPU single-core: Row 3 - Cell 2 Row 4 - Cell 0 CPU multi-core: Row 4 - Cell 2 Row 5 - Cell 0 GPU: Row 5 - Cell 2 UL PROCYON AI Image Generation (Stable Diffusion 1.5) Row 6 - Cell 2 Row 7 - Cell 0 Office Productivity Benchmark: Row 7 - Cell 2 Row 8 - Cell 0 Battery Life Benchmark: Row 8 - Cell 2 TOPAZ VIDEO AI Enhancement: Row 9 - Cell 2 Row 10 - Cell 0 Slowmo: Row 10 - Cell 2 Row 11 - Cell 0 Combined: Row 11 - Cell 2 ON1 RESIZE 200% resize time: Row 12 - Cell 2 PUGETBENCH for PHOTOSHOP Overall: Row 13 - Cell 2 Row 14 - Cell 0 General: Row 14 - Cell 2 Row 15 - Cell 0 Filter: Row 15 - Cell 2 PUGETBENCH for DAVINCI RESOLVE Overall: Row 16 - Cell 2 Row 17 - Cell 0 GPU Effects: Row 17 - Cell 2 Row 18 - Cell 0 Fusion score: Row 18 - Cell 2 Row 19 - Cell 0 AI score: Row 19 - Cell 2 Row 20 - Cell 0 H.264 encoding: Row 20 - Cell 2\n\n(Image credit: Future / Paul Hatton)\n\nPerformance\n\n• Strong performance when using Adobe Photoshop\n\n• The lack of a discrete GPU means creative professionals will struggle\n\nOne of the current issues that I have with AI laptops is that they promise so much and pitch themselves as the solution to all problems. The advertising makes them sound like their AI technology will provide you with instant results, no matter the application and workflow. Maybe I'm overstating it, but it certainly feels like that to me.\n\nThat's why I was left pleasantly surprised by the Prestige A16 AI+. The lack of a discrete GPU was problematic for 3D rendering and colour grading, but the CPU and integrated GPU actually did a great job in Photoshop and Premiere Pro. The fact that it was able to handle complex video compositions and layered effects was not what I expected.\n\nAlongside photo and video editing, I also spent a lot of time browsing the web, watching videos, and carrying out general-purpose office work. The laptop served up a responsive and snappy experience in this area, which further contributed to the laptop's impressive performance.\n\nI was also impressed by the laptop's ability to perform across a broad range of applications. I think this was in part thanks to the MSI AI Engine that was adjusting hardware settings behind the scenes. It really does excel in this role, as demonstrated by its Geekbench scores. With a reasonable multi-core score, this laptop is good at multi-threading, but not to the degree of something like the ASUS ProArt P16 (2025).\n\nThe laptop's battery life, however, proved to be a significant limitation, lasting a relatively short eight hours. That means you'll either need to consign it to a permanent desk setup or be happy carrying the charger around with you. I thought I could overcome this by utilising a lightweight third-party charger, but the apparent lack of wattage meant that the system slowed to a total standstill. By way of comparison, you'll get similar battery performance on the ASUS V16 and Dell 16 Plus 2-in-1.\n\nWith all this considered, the Prestige A16 AI+ is a high-performing laptop for most types of creative applications. Keep in mind, though, that if you need a laptop for more demanding graphics applications, you'll want a device with a discrete GPU.\n\nPerformance score: 4/5\n\n(Image credit: Future / Paul Hatton)\n\nPrice\n\nThe MSI Prestige A16 AI+ is a mid-range to high-end laptop that costs $1,399/£1,499, although there are often limited-time deals around that bring the price down considerably. If you'd prefer an OLED display with a higher resolution (UHD+ 3840x2400) then a model with that spec is also available.\n\nIn terms of comparison, you might also like the Lenovo Yoga Pro 9i Gen 9, although it'll set you back at least £1,635. If you'd like something a bit more middle of the road, then the Dell XPS 16 is a great alternative, especially if you're keen on customising your own machine.\n\nValue score: 4/5\n\nWho is it for?\n\n• Content creators who don't need a discrete GPU\n\nHopefully it goes without saying, but if you're into 3D modelling, animation, rendering, high-resolution video editing, and colour grading, then you'll need a laptop with a discrete GPU. If you're creating other types of content, performing low-demand creative tasks, or needing a laptop that can boost your productivity, then the MSI Prestige A16 AI+ is well worth a look.\n\nSwipe to scroll horizontally MSI Prestige A16 AI+ score card Attributes Notes Rating Design: A modern aesthetic with a bright IPS display. Also perfect for portability. 4/5 Features: AI-powered performance takes centre stage, and at times it delivers, but not always. 4/5 Performance: Great for most creative projects, but the lack of a discrete GPU will be a problem for some. 4/5 Value: A relatively affordable laptop, but keep in mind it doesn't have a discrete GPU. 4/5\n\n(Image credit: Future / Paul Hatton)\n\nBuy it if...\n\nYou value AI-accelerated performance\n\nYou want a bright and accurate display\n\nYou need excellent portability\n\nDon't buy it if...\n\nYou need a discrete GPU\n\nYou're only going to be web browsing"
    },
    {
      "source": "XDA Developers",
      "headline": "AMD Threadripper CPUs are surprisingly efficient for home labs",
      "url": "https://www.xda-developers.com/amd-threadripper-is-surprisingly-efficient-for-home-lab/",
      "timestamp": "2025-09-22",
      "content": ""
    },
    {
      "source": "Omgubuntu.co.uk",
      "headline": "OBS Studio 32.0 Brings New Plugin Manager, NVIDIA RTX Effects",
      "url": "https://www.omgubuntu.co.uk/2025/09/obs-studio-32-0-release-brings-new-plugin-manager-nvidia-rtx-effects",
      "timestamp": "2025-09-23",
      "content": "OBS Studio 32.0 has been released. The update sees this streaming and screen recording stable gain a nifty new plugin manager, change a few of its default settings and expand its support for NVIDIA RTX effects.\n\nThe new plugin manager is described as “basic” because it is: it shows a list of installed plugins with a checkbox to enable/disable, but ‘Browse’ and ‘Update’ options are greyed out (those options being there suggests it will be possible to find and install plugins in OBS directly).\n\nOBS Studio 3.20 increases the default bitrate from 2500 to 6000 Kbps.\n\nThe old value was decided upon a decade ago, and expectations in quality have shifted. OBS’ devs note that “…a lot of users who use OBS for recording don’t touch the default settings and end up with a 2.5 mbps recording which looks terrible”.\n\nUsers with NVIDIA RTX GPUs gain Voice Activity Detection (VAD) for RTX Audio Effects, which the release notes say improves noise suppression for speech and optimises other NVIDIA effects. Plus, the RTX Background Removal now has a “chair removal” option.\n\nHybrid MP4/MOV is now the default recording format for new profiles, having been (successfully) trialled in beta previously. New default settings have been applied for AMD encoders to improve ‘perceptual quality for AVC/HEVC/AV1’.\n\nOn Linux, OBS Studio 32.0 improves PipeWire video capture by adjusting the render technique used to capture screen sources. The pull request has detail on why users on Linux saw gamma/brightness issues when adding effects.\n\nOther notable changes in OBS Studio 32.0:\n\nOpt-in automatic crash log upload (Windows and macOS)\n\nExperimental Metal renderer on Apple Silicon Macs\n\nAudio deduplication logic improved across nested scenes, etc\n\n--disable-shutdown-check launch flag removed\n\nPlugins built for newer versions of OBS Studio are no longer loaded\n\nBeyond that, there is are an array of bug fixes to resolve various errors, crashes, missing chapter markers, plugin issues and so on – many issues rather specific to certain setups or situations.\n\nThough a modest update compared to the OBS Studio 31.1 release from July, OBS Studio 32.0 refines and extends what already works, while the new plugin manager (and some other new widget additions) lay foundations for bigger changes still to come.\n\nHow to Install OBS Studio 32.0\n\nOBS Studio is free, open-source software for Windows, macOS and Linux. Download the latest version for Windows, macOS or Linux from the OBS Project website or from GitHub (a DEB for Ubuntu/Linux Mint is linked in the assets section).\n\nOn Linux, there is also the OBS Studio from Flathub — an official, verified Flatpak maintained by the OBS Project themselves, who consider it to the ‘recommended’ way to install OBS Studio on Linux.\n\nThere’s also an official OBS Project PPA providing this, and future updates via more traditional packaging methods. The PPA supports Ubuntu 24.04 LTS and above (but not, as of writing, Ubuntu 25.10 as it’s yet to be released).\n\nTo install OBS Studio from the PPA, first add the PPA:\n\nsudo add-apt-repository ppa:obsproject/obs-studio\n\nThen, install OBS Studio using apt :\n\nsudo apt install obs-studio\n\nFinally, there is an unofficial OBS Studio snap, a modified build with other changes, including a handful of AI plugins, filters, and other tweaks. The Snap is not officially supported by OBS Studio, and any issues with it should be reported to the Snapcrafters team."
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Intel drops day zero game driver support for chips released last year — last-gen iGPUs on 14th-gen Core and older CPUs already put on the backburner of legacy software support",
      "url": "https://www.tomshardware.com/pc-components/gpu-drivers/intel-drops-day-zero-game-driver-support-for-chips-released-last-year-last-gen-igpus-on-14th-gen-core-and-older-cpus-already-put-on-the-backburner-of-legacy-software-support",
      "timestamp": "2025-09-23",
      "content": "Intel announced that it will transition the integrated graphics on 11th- to 14th-generation processors to a legacy software support model, relegating its last-generation chips to the back burner. The company says that it will no longer release new features for these chips and will only provide software support for critical fixes and security vulnerabilities. It also reduces the update release cadence for the iGPUs from monthly to quarterly, and they will also lose Day 0 Game support.\n\nThis announcement affects both desktops and laptop chips. The 11th to 14th-generation Intel CPUs are still relatively new — the 14th-generation Raptor Lake Refresh CPUs first arrived in 2023, with new models released just last year, while the 11th-generation Tiger Lake processors launched in 2020. In effect, Intel is saying that your one-year-old Intel Core i5-14400 is already on the back burner.\n\nWhile an unwelcome move, the company is likely making this change to conserve resources and focus on its newer Arc graphics architecture. After all, Intel has cut 4,000 positions in the U.S. alone so far this year, with thousands of technicians and engineers being let go as the company fights hard for its survival.\n\nStill, many customers might feel betrayed; after all, if you bought a new processor, you expect it to be supported for at least five to seven years. This announcement will not brick your PC, and you still get critical and security updates quarterly. But you’re also not getting new features, and you might have issues with (or possibly not even be able to play) the latest games at launch.\n\nNevertheless, many users will likely not feel this. After all, gamers who typically download, install, and play a AAA game at launch most often have a discrete GPU installed on their system. In fact, even the most hardware-friendly titles, such as the upcoming Battlefield 6, require a modest graphics card like the Nvidia RTX 2060, AMD Radeon RX 5600 XT, or Intel Arc A380.\n\nEven though it makes sense for Intel to focus on its newer Core and Core Ultra chips, the fact that Intel is moving such a relatively new CPU line-up to legacy support could leave a bad taste in the mouths of some users.\n\nFollow Tom's Hardware on Google News , or add us as a preferred source , to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!"
    },
    {
      "headline": "Meet Lisa Su: CEO and president of Advanced Micro Devices, the main competitor to Nvidia",
      "content": "Lisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion.\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nlighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nLisa Su is the engineer behind one of the most dramatic corporate turnarounds in the tech industry.\n\nThe Taiwanese American CEO is widely credited with transforming AMD from a struggling semiconductor firm on the brink of collapse into a global powerhouse competing head-to-head with Intel and Nvidia.\n\nWhen Su joined AMD in 2012, the company's market value was under $2 billion. Within a decade of her leadership, AMD's innovations in high-performance computing and graphics, especially the Ryzen CPUs and EPYC server processors, catapulted the company's value to roughly $270 billion as of October 2025.\n\nBut Su's leadership has not been without challenges. AMD's two largest competitors, Nvidia and Intel, are now working together in a strategic collaboration. Under the second Trump administration, export regulations related to China, one of AMD's largest markets, are also constantly changing.\n\nHere's a look at the timeline of Su's career, from her early life in New York City to her role as one of the most influential women in tech and innovation:",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/meet-lisa-su-ceo-and-president-of-advanced-micro-device",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "I cloned my voice with AI and it was unsettlingly good",
      "content": null,
      "source": "MakeUseOf",
      "url": "https://www.makeuseof.com/ai-voice-clone-chatterbox/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Select Micro Center Stores: AMD Ryzen 7 7800X3D + ASUS B650E-E TUF Gaming MB $450 + Free Store Pickup",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18662536-select-micro-center-stores-amd-ryzen-7-7800x3d-asus-b650e-e-tuf-gaming-mb-450-free-store-pickup",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "No, Xbox's next gen console hardware plans aren't cancelled — for now, but it's a problem that it was really easy to believe",
      "content": "So today, rumors began to swirl across the internet that Xbox is planning to exit hardware, and move entirely to Xbox Cloud Gaming as the primary way to access content. I can confirm via very trusted sources that this isn't true. At least for now.\n\nBut that, \"at least for now\" qualifier is a real problem. How can we know what will be true next quarter? Let's put aside for a minute the fact that Xbox Game Pass remains a primary driver of revenue, and is most prolific on Xbox console hardware — and that's where the bulk of the users are right now. Let's put aside the fact that Xbox Cloud Gaming is restricted by location and is expensive to run.\n\nCombine that with the fact that with the same silicon, you could give people their own \"cloud\" natively in their house — and get them to use their own electricity to power it. You know, like a console. It doesn't make a lot of sense on paper. But regardless, that's where we're at.\n\nUPDATE: Microsoft has at least confirmed that, for now, that the rumors are false, as noted in the statement above. But how did we get here? The original report continues below.\n\nAll of these rumors emerged in the wake of Microsoft's barely-explicable 50% price rise in Xbox Game Pass Ultimate, and the weird tone-deaf way in which they tried to present it as a \"good thing\" throwing in Fortnite Crew and stuff people didn't really ask for.\n\nThe fact these latest hardware exit rumors continue to seem plausible is a real problem, despite the source of the rumors. It showcases, to me, a very deep disconnect between Microsoft and how its audience and the community at large views gaming in general.\n\nMicrosoft's multi-year partnership with AMD for next-gen Xbox hardware is still the present plan\n\nXbox + AMD: Powering the Next Generation of Xbox - YouTube Watch On\n\nI could easily be just as random a source claiming that Xbox hardware is still on the table, but it was our sources that confirmed the existence of the Xbox Series X|S, their specs, their price, in addition to reports on the cancelled cloud \"Keystone\" console, the shelved first-party Xbox handheld, and more recently, the Xbox Ally. Codenamed Kennan and comprised of Omni (Xbox Ally) and Horseman (Xbox Ally X), the Xbox Ally range is part of Microsoft's multi-year partnership with AMD, which will include tailor-made devices from first party.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nI've asked multiple trusted sources, many of whom spoke to me on the above devices previously which turned out to be true, about what Xbox's present hardware posture is. And with Microsoft's confirmation, there's no reason to think anything is changing.\n\nMicrosoft publicly confirmed that it's still committed to first-party Xbox hardware over the summer, with comments from both President Sarah Bond and AMD CEO Lisa Su on silicon that would power next-gen Xbox devices — both from third and first-party. The statement reiterates this commitment.\n\nThe original comments came from a gaming forum, and suggested that Xbox's focus would be on its core mega franchises like World of Warcraft, Call of Duty, Forza Horizon, and so on, and that hardware plans were \"up in the air,\" not actually cancelled. Those comments morphed into \"Xbox hardware is cancelled\" from various commentators, and have now taken on a life of their own on social media as people speculate on the future of the Xbox platform. From what I've been told, the hardware plans are not even \"up in the air,\" and remain firmly Xbox's path forward. Xbox Series X|S hardware production has not ceased, and new stock will go out to retailers at its usual cadence.\n\nAMD & Xbox | Advancing the Future of Gaming - YouTube Watch On\n\nBut even if Microsoft did come out to squash the rumors themselves, it's hard to have any faith. Microsoft has been incredibly fickle over the past few years, crushed under AI hype, demands from CFO Amy Hood, and a complete dereliction of fan feedback.\n\nThe planned restructuring of Xbox Game Pass was months in the making and, beyond their apparent macroeconomic \"need\" to make even more money, it's based on user behavior and the desire to boost the content fund for the cohort most likely to unsubscribe without new content. Codenames appearing for the new tiers over the summer, and is not the result of a quarterly knee-jerk reaction. But it doesn't matter.\n\nCombined with huge price hikes, retailers like Costco and others removing Xbox hardware, and Microsoft's massive layoffs over the summer — it's not unsurprising people are speculating on Xbox's demise. Microsoft is absolutely awful at managing faith in its consumer products, and I've written previously about how the telemetry driving its decisions and its diffuse focus is leading to a collapse in morale in the brand.\n\nGaming is not a necessity, or a utility — it's driven by sentiment and \"fun\" feeling. people need to also feel good about where they play, and Microsoft is making it incredibly hard to feel good about Xbox right now. It's clearly reaching a crisis point.\n\nXbox the pariah\n\nThis feels like 2013 again. (Image credit: Windows Central)\n\nI've been covering Xbox for over ten years at this point, and I started when Microsoft's bombed Xbox One reveal led to a groundswell of hate for the brand and its future. It was fostered by a sense of betrayal in what Xbox had been and represented, and led to a huge climb down that effectively dismantled the Xbox One platform — and put Xbox firmly in \"third-place\" forever. Lately, it feels like we're back in 2013 again.\n\nThe industry looks very different in 2025, as maturing audiences and a lack of meaningful new player growth has companies breaking the rules to find new revenue streams. We've seen Xbox games flood onto PlayStation, we've even seen PlayStation bring games to Xbox. Microsoft is licensing out the Xbox brand to OEMs with the Xbox Ally (and I'm told more OEM hardware should appear in 2026, too).\n\nThe inconsistency is exhausting for fans, and in a sentiment-driven business, potentially untenable.\n\nThe one constant that Xbox fans could point to among all of this was the clear value of Xbox Game Pass. \"Xbox Game Pass is the best value in gaming,\" or so the meme goes. Despite some price rises over the past couple of years, it was hard to overlook what a stellar year it had thus far, with games like Expedition 33, Blue Prince, DOOM, The Elder Scrolls: Oblivion remake, and others. But with an unprecedented 50% price increase on the tier that actually gets day one games, the negative reaction has been incredibly strong.\n\nIt all just feels like another betrayal, particularly given President Sarah Bond's comments that Xbox Game Pass is profitable, and also hitting $5 billion in revenues. The way Xbox presented the \"changes\" as a \"good thing\" came across as tone deaf, especially given how other companies are pushing up prices while also simultaneously reporting record profits.\n\nSo, it's hardly surprising that these rumors gained so much traction, because even if they're not true today, they could definitely be true tomorrow. It's hard to take anything what today's Xbox says or does on faith, because they're apparently willing to throw anything and everything on the fire if it means a quarterly boost.\n\nThe inconsistency is exhausting for fans, most likely concerning for developers — and in a sentiment-driven business, potentially untenable.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/gaming/no-xboxs-next-gen-console-hardware-plans-arent-cancelled",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Huawei Atlas 950 SuperPoD vs Nvidia DGX SuperPOD vs AMD Instinct Mega POD: How do they compare?",
      "content": "Huawei stacks thousands of NPUs to show brute-force supercomputing dominance\n\nNvidia delivers polish, balance, and proven AI performance that enterprises trust\n\nAMD teases radical networking fabrics to push scalability into new territory\n\nThe race to build the most powerful AI supercomputing systems is intensifying, and major brands now want a flagship cluster that proves it can handle the next generation of trillion-parameter models and data-heavy research.\n\nHuawei’s recently-announced Atlas 950 SuperPoD, Nvidia’s DGX SuperPOD, and AMD’s upcoming Instinct MegaPod each represent different approaches to solving the same problem.\n\nThey all aim to deliver massive compute, memory, and bandwidth in one scalable package, powering AI tools for generative models, drug discovery, autonomous systems, and data-driven science. But how do they compare?\n\nSwipe to scroll horizontally Huawei Ascend 950 vs Nvidia H200 vs AMD MI300 Instinct Category Huawei Ascend 950DT NVIDIA H200 AMD Radeon Instinct MI300 Chip Family / Name Ascend 950 series H200 (GH100, Hopper) Radeon Instinct MI300 (Aqua Vanjaram) Architecture Proprietary Huawei AI accelerator Hopper GPU architecture CDNA 3.0 Process / Foundry Not yet publicly confirmed 5 nm (TSMC) 5 nm (TSMC) Transistors Not specified 80 billion 153 billion Die Size Not specified 814 mm² 1017 mm² Optimization Decode-stage inference & model training General-purpose AI & HPC acceleration AI/HPC compute acceleration Supported Formats FP8, MXFP8, MXFP4, HiF8 FP16, FP32, FP64 (via Tensor/CUDA cores) FP16, FP32, FP64 Peak Performance 1 PFLOPS (FP8 / MXFP8 / HiF8), 2 PFLOPS (MXFP4) FP16: 241.3 TFLOPS, FP32: 60.3 TFLOPS, FP64: 30.2 TFLOPS FP16: 383 TFLOPS, FP32/FP64: 47.87 TFLOPS Vector Processing SIMD + SIMT hybrid, 128-byte memory access granularity SIMT with CUDA and Tensor cores SIMT + Matrix/Tensor cores Memory Type HiZQ 2.0 proprietary HBM (for decode & training variant) HBM3e HBM3 Memory Capacity 144 GB 141 GB 128 GB Memory Bandwidth 4 TB/s 4.89 TB/s 6.55 TB/s Memory Bus Width Not specified 6144-bit 8192-bit L2 Cache Not specified 50 MB Not specified Interconnect Bandwidth 2 TB/s Not specified Not specified Form Factors Cards, SuperPoD servers PCIe 5.0 x16 (server/HPC only) PCIe 5.0 x16 (compute card) Base / Boost Clock Not specified 1365 / 1785 MHz 1000 / 1700 MHz Cores / Shaders Not specified CUDA: 16,896, Tensor: 528 (4th Gen) 14,080 shaders, 220 CUs, 880 Tensor cores Power (TDP) Not specified 600 W 600 W Bus Interface Not specified PCIe 5.0 x16 PCIe 5.0 x16 Outputs None (server use) None (server/HPC only) None (compute card) Target Scenarios Large-scale training & decode inference (LLMs, generative AI) AI training, HPC, data centers AI/HPC compute acceleration Release / Availability Q4 2026 Nov 18, 2024 Jan 4, 2023\n\nThe philosophy behind each system\n\nWhat makes these systems fascinating is how they reflect the strategies of their makers.\n\nHuawei is leaning heavily on its Ascend 950 chips and a custom interconnect called UnifiedBus 2.0 - the emphasis is on building out compute density at an extraordinary scale, then networking it together seamlessly.\n\nNvidia has spent years refining its DGX line and now offers the DGX SuperPOD as a turnkey solution, integrating GPUs, CPUs, networking, and storage into a balanced environment for enterprises and research labs.\n\nAMD is preparing to join the conversation with the Instinct MegaPod, which aims to scale around its future MI500 accelerators and a brand-new networking fabric called UALink.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nWhile Huawei talks about exaFLOP levels of performance today, Nvidia highlights a stable, battle-tested platform, and AMD pitches itself as the challenger offering superior scalability down the road.\n\nAt the heart of these clusters are heavy-duty processors built to deliver immense computational power and handle data-intensive AI and HPC workloads.\n\nHuawei’s Atlas 950 SuperPoD is designed around 8,192 Ascend 950 NPUs, with reported peaks of 8 exaFLOPS in FP8 and 16 exaFLOPS in FP16 - so it is clearly aimed at handling both training and inference at an enormous scale.\n\nNvidia’s DGX SuperPOD, built on DGX A100 nodes, delivers a different flavor of performance - with 20 nodes containing a total of 160 A100 GPUs, it looks smaller in terms of chip count.\n\nHowever, each GPU is optimized for mixed precision AI tasks and paired with high-speed InfiniBand to keep latency low.\n\nAMD’s MegaPod is still on the horizon, but early details suggest it will pack 256 Instinct MI500 GPUs alongside 64 Zen 7 “Verano” CPUs.\n\nWhile its raw compute numbers are not yet published, AMD’s goal is to rival or exceed Nvidia’s efficiency and scale, especially as it uses next-generation PCIe Gen 6 and 3-nanometer networking ASICs.\n\nFeeding thousands of accelerators requires staggering amounts of memory and interconnect speed.\n\nHuawei claims the Atlas 950 SuperPoD carries more than a petabyte of memory, with a total system bandwidth of 16.3 petabytes per second.\n\nThis kind of throughput is designed to keep data moving without bottlenecks across its racks of NPUs.\n\nNvidia’s DGX SuperPOD does not attempt to match such headline numbers, instead relying on 52.5 terabytes of system memory and 49 terabytes of high-bandwidth GPU memory, coupled with InfiniBand links of up to 200Gbps per node.\n\nThe focus here is on predictable performance for workloads that enterprises already run.\n\nAMD, meanwhile, is targeting the bleeding edge with its Vulcano switch ASICs offering 102.4Tbps capacity and 800Gbps per tray external throughput.\n\nCombined with UALink and Ultra Ethernet, this suggests a system that will surpass current networking limits once it launches in 2027.\n\nOne of the biggest differences between the three contenders lies in how they are physically built.\n\nHuawei’s design allows for expansion from a single SuperPoD to half a million Ascend chips in a SuperCluster.\n\nThere are also claims that an Atlas 950 configuration could involve more than a hundred cabinets spread over a thousand square meters.\n\nNvidia’s DGX SuperPOD takes a more compact approach, with its 20 nodes integrated in a cluster style that enterprises can deploy without needing a stadium-sized data hall.\n\nAMD’s MegaPod splits the difference, with two racks of compute trays plus one dedicated networking rack, showing that its architecture is centered around a modular but powerful layout.\n\nIn terms of availability, Nvidia’s DGX SuperPOD is already on the market, Huawei’s Atlas 950 SuperPoD is expected in late 2026, and AMD’s MegaPod is planned for 2027.\n\nThat said, these chips are fighting very different battles under the same banner of AI supercomputing supremacy.\n\nHuawei’s Atlas 950 SuperPoD is a show of brute force, stacking thousands of NPUs and jaw-dropping bandwidth to dominate at scale, but its size and proprietary design may make it harder for outsiders to adopt.\n\nNvidia’s DGX SuperPOD looks smaller on paper, yet it wins on polish and reliability, offering a proven platform that enterprises and research labs can plug in today without waiting for promises.\n\nAMD’s MegaPod, still in development, has the makings of a disruptor, with its MI500 accelerators and radical new networking fabric that could tilt the balance once it arrives, but until then, it is a challenger talking big.\n\nVia Huawei, Nvidia, TechPowerUp",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/huawei-atlas-950-superpod-vs-nvidia-dgx-superpod-vs-amd-instinct-mega-pod-how-do-they-compare",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Working on the HP EliteBook 8 G1a is a good experience, but I think it can be hard to justify the cost of this Ryzen AI business laptop",
      "content": "The HP EliteBook 8 G1a is a showcase for HP’s engineering skills, as it packs a lot into a relatively small chassis without compromising performance or battery life. I just wish it were a little cheaper, so more people could afford a PC with this underlying power.\n\nWhy you can trust TechRadar We spend hours testing every product or service we review, so you can be sure you're buying the best. Find out more about how we test.\n\nHP EliteBook 8 G1a: 30-second review\n\nTo avoid immediate confusion, HP makes a standard version of the EliteBook 8 G1a 14 laptop, and then the Next Gen AI PC Wolf Pro Security Edition (A27BLEA) that this review covers.\n\nWhile these share many of the same hardware components, the Next Gen AI PC Wolf Pro Security Edition (A27BLEA) is specifically designed for business users who need to deploy laptops for power users with enhanced security requirements.\n\nBuilt around the new AMD Ryzen AI 7 PRO 350, this is a highly efficient and yet powerful machine that’s ideal for demanding tasks, like running local AI models.\n\nBut it’s also ideal for a user who runs demanding AI tools, even if this machine wouldn’t realistically cross the threshold into being classed as a mobile workstation.\n\nIf you are looking for that level of performance, a laptop that uses the Ryzen AI 9 HX PRO 375 is probably more appropriate.\n\nThe limitations of the EliteBook 8 G1a are that it doesn’t have a second full M.2 2280 slot, limiting the amount of storage to 3TB with current capacities. And, while the memory modules are upgradable, this system with only one module is starved of memory bandwidth.\n\nIt does come with Wi-Fi 7, HDMI output and Thunderbolt ports, so while it might not be a necessity to have a docking station, it can exploit one effectively.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThis machine isn’t the cheapest to use this new platform, but HP has an excellent selection of EliteBook, ProBook, and ZBook designs that use AMD processors, so there is plenty of choice. With so many machines of this type appearing, it’s hard to pick this one as being exceptional enough to be one of the best business laptops. But HP makes highly effective hardware, and the EliteBook 8 G1a doesn’t undermine that narrative.\n\nHP EliteBook 8 G1a: Price and availability\n\n(Image credit: Mark Pickavance)\n\nHow much does it cost? From $1550/£1515\n\nFrom $1550/£1515 When is it out? Available now\n\nAvailable now Where can you get it? Direct from HP, or via online retailers\n\nSold as the HP EliteBook 8 G1a 14 inch Notebook Next Gen AI PC Wolf Pro Security Edition, the asking price in the UK is £1799.99 for a machine with 64GB of RAM and 1TB of SSD storage.\n\nThe same spec in the USA is priced at $1,899, making it currently a better deal for American buyers.\n\nWhat’s slightly odd is that via the HP store, it isn’t possible to select the spec of the review hardware, which matches 64GB of RAM with 512GB of storage.\n\nChoosing 512GB of storage automatically drops the memory to 32GB.\n\nFor American customers, the cheapest model with the Ryzen AI 7 PRO 350 processor is $1549. European buyers can’t get that combination, and the lowest-priced option in the UK is £1,511.99, with 1TB of storage and 32GB of RAM for that money.\n\nIt should be noted that for those buying into the AI era, local AI models need lots of RAM to run quickly, so it might be pointless to run this CPU with only 16GB of RAM.\n\nThe RAM on these systems can be upgraded, as can the storage, but that’s additional cost and effort beyond the purchase price.\n\nWhile I’m sure other brands will be using a similar platform in the coming months, at this time, the only significant releases are from Asus with the Zenbook S16, and the Lenovo ThinkPad P14s Gen 6 and P16s Gen 4.\n\nThe Lenovo ThinkPad P14s Gen 6 typically retails for around $ 1,240, featuring 32GB of RAM and 1TB of storage. Whereas the P16s Gen 4 is $1500 for one with 64GB of RAM and 1TB of storage.\n\nSo far, Asus isn’t using the PRO variant of the 350, but they do have the even more powerful Ryzen AI 9 HX 370 in the Zenbook S16 series, and you can get one with 32GB of RAM and 1TB of storage for only $1400.\n\nIn the grand scheme of things, the HP asking price for this machine isn’t excessive, but those looking for better value might want to consider the Asus Zenbook S16 series, which could easily save you money and get you a more powerful platform.\n\nWhat’s always important to realise is that retail costs as presented on the brand websites aren’t what corporations pay for bulk orders, and that sort of horse trading could make HP a much more competitive option.\n\nValue: 3.5 / 5\n\nHP EliteBook 8 G1a: Specs\n\nSwipe to scroll horizontally Category Item Processor AMD Ryzen AI 7 350 PRO 2.0GHz (16MB Cache, up to 5.0 GHz, 8 cores, 16 Threads) NPU Performance 50 TOPS (Neural Processing Unit for local AI tasks) Total TOPS 66 TOPS (NPU and CPU combined) Memory 64 GB DDR5-5600 (maximum official capacity) Storage 1 TB M.2 2280 PCIe Gen4 NVMe SSD Storage Exp. M.2 2230 PCIe Gen 4 Graphics AMD Radeon 860M Graphics Display 14\" diagonal, WUXGA (1920 x 1200), IPS, anti-glare, 800 nits, 100% sRGB, HP Sure View 5 integrated privacy screen with HP Eye Ease Camera 5 MP IR AI camera Audio Audio by Poly Studio, dual stereo speakers with discrete amplifiers, integrated dual array microphones Ports Right 1x USB 3.2 Gen 1 Type-A, 1x USB 3.2 Gen 2 Type-C, Kensington nano security lock Ports Left 2x USB4/Thunderbolt 4, 1x HDMI 2.1 TMDS, 1x 3.5mm Combo Audio Jack, SIM Card slot (LTE4 or 5G optional) Wireless MediaTek WiFi 7 MT7925 (2x2) and Bluetooth 5.4 wireless card Battery HP Long Life 3-cell, 62 Wh Li-ion polymer PSU HP 100 W USB Type-C slim adapter Operating System Windows 11 Pro Security HP Wolf Security, TPM 2.0, fingerprint sensor, auto lock/awake, onlook detector Size 31.56 x 22.2 x 1.17 cm (front); 31.56 x 22.2 x 1.55 cm (rear) Weight 1.39 kg Sustainability Low halogen; Bulk packaging available; 30% post-consumer recycled plastic; 80% recycled metal; 100% of HP paper-based packaging is from recycled or certified sustainable sources; Product Carbon Footprint Warranty 1-year limited warranty Colours Glacier silver\n\nHP EliteBook 8 G1a: Design\n\n(Image credit: Mark Pickavance)\n\nSolid construction\n\nLots of ports\n\nCramped keyboard\n\nA Wolf Pro Security Edition\n\nThe HP EliteBook 8 G1a 14-inch Notebook Next Gen AI PC Wolf Pro Security Edition (A27BLEA) nicely blends aesthetics with functionality. Its sleek, minimalist exterior is crafted from high-quality materials, giving it a premium feel and durability. The notebook’s slim profile and lightweight construction make it highly portable, ideal for those who travel for a living.\n\nThe 14-inch display is a standout feature, offering vibrant colours and sharp resolution that make working on the laptop relatively easy. The narrow bezels maximise screen real estate, providing an immersive viewing experience without increasing the overall size and weight of the device. The anti-glare coating ensures that the screen remains readable in various lighting conditions, reducing eye strain during extended use.\n\nWhat I was less enamoured with was the keyboard. The positive aspects are that the keys are well-spaced and provide a satisfying tactile response, making typing a pleasure.\n\nBut the keyboard doesn’t use the full width of the machine, and therefore some keys ended up reduced in size. Not a fan of tiny function keys or the cursor cluster, but despite this, I can type at a reasonable speed on it.\n\nThe backlit feature allows for easy use in low-light environments, adding to the notebook’s versatility. The touchpad is generously sized and highly responsive, supporting multi-touch gestures for improved navigation.\n\n(Image credit: Mark Pickavance)\n\nA real strength of the HP EliteBook 8 G1a is the port selection, since it includes USB-C, USB-A, HDMI, and an audio jack. This selection ensures compatibility with a wide array of peripherals and accessories, enhancing the notebook’s functionality. The inclusion of Wi-Fi 7 and Bluetooth 5.4, using the MediaTek MT7925 (2x2), ensures fast and reliable wireless connectivity.\n\nBeing a Wolf Pro Security Edition, HP add some neat features to provide robust protection against malware and cyber threats, in theory. These include a fingerprint reader and facial recognition technology built to secure logins and safeguard sensitive data. The part of the Wolf Pro technology that IT professionals will gravitate to is the Cloud-Based Management Console, which enables a centralised control for IT teams to monitor and respond to threats. There are lots of other features, like AI and behavioural analysis to detect unknown threats, if you haven’t already deployed equivalent tools in the business environment.\n\nOverall, the HP EliteBook 8 G1a is a well-designed, high-performance notebook that meets the needs of modern professionals and power users, without resorting to discrete GPUs and limited battery life.\n\nDesign: 4 / 5\n\nHP EliteBook 8 G1a: Hardware\n\nAMD Ryzen AI 300 series CPU\n\nRadeon 860M GPU\n\nUpgrades\n\nThe AMD Ryzen 7 350 PRO is one of the new Krackan Point CPUs that have recently come to market, and utilises the AMD mobile chipset FP8, aka Strix Point.\n\nBuilt on the latest 4nm TSMC fabrication, for its size and power consumption, this CPU delivers some exceptional performance, especially for AI use.\n\nFor those who read my Asus Expertbook P3 review, a machine that uses the non-PRO version of this chip, you might be wondering what a PRO spec processor adds.\n\nThe main distinction lies in the fact that the Ryzen AI 7 PRO 350 is tailored for business use, featuring additional functionalities and capabilities specifically designed for enterprise needs that are not present in the consumer variant, the Ryzen AI 7 350. Although both processors utilise the same core architecture and have similar performance potential, the “PRO” label indicates improvements in security, manageability, and reliability explicitly designed for business environments.\n\nWhat that’s worth to you personally, I can’t say, but HP does make a toned-down model with the basic AMD Ryzen 7 350 if you want to save a small amount of money.\n\n(Image credit: Mark Pickavance)\n\nWhat isn’t radical on this platform is the Radeon 860M GPU, which I’d characterise as being a reasonable integrated GPU, but nothing special.\n\nThis balance of a high-end CPU and mid-range GPU hints that it’s built for those power users who aren’t editing 4K videos or modelling in 3D. But what it does well is support local AI challenges for those who need AI functionality, but can’t guarantee cloud services.\n\nThe evolution of AI for business use is still very much at the Proterozoic stage, but for those who are embracing technologies like CoPilot, this hardware is superior to the prior generation.\n\n(Image credit: Mark Pickavance)\n\nWhile not perfect, the upgrade paths in this machine do at least allow for enhanced memory and storage, and potentially the WiFi module when WiFi 8 becomes available.\n\nGetting inside is relatively easy with a small screwdriver and a spudger, and with the underside removed, the battery, memory and storage are all highly accessible.\n\nUnlike the HX 395 hardware, which uses soldered memory, this platform features two SODIMM slots that can accommodate up to 32GB modules, for a maximum capacity of 64GB. It might be that at some point you will be able to get 48GB or 64GB modules, and increase that to 96GB or even 128GB, since the Ryzen AI 7 PRO 350 can address up to 256GB of memory space.\n\nI had two disappointments with the insides, and both related to the storage. The first is that the M.2 2280 slot, pre-installed with a Gen 4 1TB NVMe in my review hardware, didn’t have any form of heatsink or pad to help it dissipate. That effectively limits it to 2TB drives, since 4TB and 8TB options either come with or expect help with cooling.\n\nThe second M.2 slot is only 2230-sized, limiting it to 1TB capacities currently. There isn’t much room, I accept, but a second 2280 slot would have been terrific, since using AI without lots of storage space isn’t ideal.\n\n(Image credit: Mark Pickavance)\n\nHardware: 4 / 5\n\nHP EliteBook 8 G1a: Performance\n\nSwipe to scroll horizontally Laptops Header Cell - Column 1 HP EliteBook 8 G1a 14 AI Asus Expertbook P3 (with dual memory) CPU Row 0 - Cell 1 AMD Ryzen AI 7 PRO 350 AMD Ryzen AI 7 350 Cores/Threads Row 1 - Cell 1 8C 16T 8C 16T TPD Row 2 - Cell 1 15-54W (28W) 15-54W (28W) RAM Row 3 - Cell 1 64GB DDR5-5600 (2x32GB) 32GB DDR5-5600 (2x16GB) SSD Row 4 - Cell 1 500GB WD Blue SN5000 1TB Micron 2500 MTFDKBA1T0QGN Graphics Row 5 - Cell 1 AMD Radeon 860M AMD Radeon 860M NPU Row 6 - Cell 1 AMD Ryzen AI (50 TOPS) AMD Ryzen AI (50 TOPS) 3DMark WildLife 16,844 15,582 Row 8 - Cell 0 FireStrike 6331 6107 Row 9 - Cell 0 TimeSpy 2975 2882 Row 10 - Cell 0 Steel Nomad.L 2364 2262 CineBench24 Single 114 116 Row 12 - Cell 0 Multi 856 909 Row 13 - Cell 0 Ratio 7.48 7.83 GeekBench 6 Single 2857 2886 Row 15 - Cell 0 Multi 13638 13560 Row 16 - Cell 0 OpenCL 24764 24370 Row 17 - Cell 0 Vulkan 34322 33104 CrystalDIsk Read MB/s 7159 7006 Row 19 - Cell 0 Write MB/s 6558 6111 PCMark 10 Office 7576 7763 Row 21 - Cell 0 Battery 14h 31m 18h 17m Battery Whr 62 70 WEI Score 8.2 8.1\n\nSince they use the same platform and memory technology, the HP EliteBook 8 G1a is worthy of comparison with the Asus Expertbook P3, admittedly a cheaper device.\n\nHow HP configured this machine enables it to outperform the P3 in many tests, and it was provided with a better storage device in the bargain.\n\nWhere the P3 overtakes it is in battery life, with the Asus machine having a larger battery and a longer operating time accordingly.\n\nHowever, both these machines run for longer than a typical working day, and the EliteBook 8 G1a is lighter for those who carry their system with them.\n\nOne important note is that the performance of both these laptops can be massively undermined by using only a single memory module, as the review P3 was delivered. Therefore, don’t order one with a single memory module, or if you do, then purchase another identical module to get all the memory bandwidth available.\n\n(Image credit: Mark Pickavance)\n\nPerformance: 4 / 5\n\nHP EliteBook 8 G1a: Final verdict\n\nThe HP EliteBook 8 G1a ticks plenty of corporate boxes, something HP is exceptionally skilled at doing.\n\nWhat it offers is a powerful yet battery-efficient solution with all the latest security enhancements and management tools that corporate IT will love. It also features sufficient ports that most users won’t need a docking station, and the underlying platform is capable of running local AI models and tools.\n\nIt isn’t the cheapest laptop running this AMD Ryzen AI platform, but the quality of construction and features like Thunderbolt ports go some way to justify the extra it can cost over more affordable options.\n\nNot the best 14-inch laptop I’ve seen, but a solid platform that delivers power-user appeal without sacrificing its practicality.\n\nShould you buy a HP EliteBook 8 G1a?\n\nSwipe to scroll horizontally Value You pay a HP premium, but the build quality is good 3.5 / 5 Design A power-packed design that feels substantial 4 / 5 Hardware AI 300 series CPU, DDR5 and special AI sauce is a winning combo 4 / 5 Performance Excellent performer and acceptable battery life 4 / 5 Overall A powerful AI platform for those who need that 4 / 5\n\nBuy it if...\n\nYou need Thunderbolt or USB4\n\nThe AMD Ryzen AI 7 PRO 350 at the heart of this design has Thunderbolt/USB4 ports inherently, but there are laptops around that don’t implement them for various reasons. If you want that technology, and most would, then this machine is for you.\n\nYou like upgrades\n\nLots of bits on this machine can easily be upgraded, including the memory and storage. If you don’t mind using a screwdriver, then there is plenty of potential for enhancements.\n\nDon't buy it if...\n\nYou need exceptional battery life\n\nAccording to HP, this machine should last more than 18 hours, but it only lasted 14 hours in my test. That’s respectable, but other machines that use the latest Intel Ultra 200 processors or the Qualcomm Snapdragon X series can last longer.\n\nYou are on a tight budget\n\nFor the money, this is a decent laptop with plenty of nice features and a good hardware platform, but it’s hardly cheap. There are cheaper options that sacrifice some of the bells and whistles that use the same CPU, which will make your budget stretch further.\n\nFor more productivity machines, we reviewed the best laptops for work and gaming and the best laptops for working from home.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/hp-elitebook-8-g1a-business-laptop-review",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "AMD Versal TRNG Driver Upstreamed To Linux 6.18, Intel Adds New Telemetry For QAT Gen6",
      "content": "All of the crypto subsystem changes have been merged for the in-development Linux 6.18 kernel.A new driver in the cryptographic subsystem is the AMD Versal TRNG driver . This provides true random number generator support with the AMD Versal Adaptive SoCs.\n\nThis driver was contributed by AMD directly for upstreaming to the mainline Linux kernel. This also joins other new Versal support in Linux 6.18 like the new Versal NET DDR EDAC driver Meanwhile the AMD Crypto Co-Processor \"CCP\" driver has added a new API for dealing with SEV-SNP virtualization around cipher text hiding.Over on the Intel side, earlier this year they introduced QAT Gen6 support . For QuickAssist/QAT Gen6 with the Linux 6.18 kernel they are adding ring buffer idle and command queue telemetry support.The crypto pull for Linux 6.18 also includes improvements to the HiSilicon crypto driver, a new TI driver with ECB/CBC AES support, and other changes. See the crypto pull for the full list of crypto changes that were merged to mainline yesterday.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-Crypto",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Lenovo Legion Go 2 Review: A Handheld Made For Big, Meaty Claws",
      "content": "You buy Lenovo’s new Legion Go 2 handheld for the screen. The performance is secondary to how beautiful recent 2D titles look on the 8.8-inch, 1200p OLED display. The Legion Go 2 is otherwise a big, meaty handheld for gamers with big, meaty claws. You’ll struggle to hold it above your head lying in bed unless you’re a professional power lifter; the controls won’t be your favorite; it’s as wonky as its predecessor. And it’s hard to argue anybody should spend well over $1,000 on a gaming handheld rather than just buying a full gaming laptop.\n\nDespite all that, I can’t help but enjoy the hell out of it. My initial hours spent rolling my eyes at everything Lenovo failed to fix from its first iteration slowly morphed into the kind of appreciation that can only occur when a device starts to feel personal. It’s what happened when I downloaded Hollow Knight: Silksong and Hades II to the device and had to hold back a gasp on a crowded plane for how gorgeous both games looked on Lenovo’s big, expensive, beautiful display.\n\nLegion Go 2 It's thick, heavy, and so damn pretty. It's a shame it costs as much as it does. 4 See at Best Buy Pros Beautiful OLED display\n\n144Hz refresh rate with VRR\n\nNew ergonomics\n\nLow-wattage performance uplift Cons Annoying removable controls\n\nFPS mode is pointless\n\nReflective display\n\nVery expensive at $1,350\n\nIt’s the same feeling I get from Valve’s $550 Steam Deck OLED, which uses the same organic light-emitting diode screen technology to present deeper contrast and rich colors. Valve’s handheld maxes out at 800p on an older, custom AMD chipset. Even when you factor in performance and display size, the Steam Deck OLED is still a much, much better deal. My review unit version of the Legion Go 2 with the AMD Ryzen Z2 Extreme processor, 32GB of RAM, and 1TB of storage, costs $1,350. I could literally buy two Steam Decks for this price (more if I opted for the LCD model). For Lenovo’s inflated price, I could run out and buy three $450 Nintendo Switch 2 handhelds. You could nab a version of the Legion Go 2 that starts at $1,100 for a version with a AMD Ryzen Z2, but judging by my tests that chip will land closer in power to handhelds that are three years old and cost much less.\n\nIt’s a ridiculous scenario that consumers are taking the brunt of Donald Trump’s obsession with import taxes, aka tariffs. And in that way, consumers are screwed no matter what. The upcoming Asus ROG Xbox Ally X, which is set to launch on Oct. 16 with the same Ryzen Z2 Extreme chip, will set you back $1,000. The original Legion Go asked for $700 in 2023. The Asus ROG Ally X demanded $800 at launch last year. Both now retail at a higher price, likely due to tariffs. I would tell you to wait and buy a new handheld, but there’s no way to tell if prices might increase in coming months.\n\nReally? You kept FPS mode?\n\nWhat drives me mad using the Legion Go 2 is how Lenovo held back from improving over the 2023 handheld. The revised version is far more ergonomic than the two-year-old device with its sharp corners. Both handhelds let you remove each controller and play with the screen separated, like the Nintendo Switch. The Switch 2 did away with rails and went for magnetic connections for each Joy-Con 2, which makes attaching and detaching the controllers a little easier. Lenovo’s old and new system still use a series of exposed pins you jam into a cavity on each side of the screen. You need two hands and a strong pitching arm to remove each controller with a down and out motion. Reattaching them can be just as annoying.\n\nSee Lenovo Legion Go 2 at Best Buy\n\nThe controller uses Hall effect sticks that are much better at surviving stick drift, though they still feel a little too thin on my fingers compared to other handhelds I’ve used. The Legion Go 2 has slightly redesigned bumper buttons that make it easier to press and the same, large triggers. The $650 Legion Go S had a switch to enable instant triggers with less travel—better for first-person shooter games, but because of the removable controllers you’ll have to stick with the full range of motion.\n\nThe Switch 2’s big standout feature is its new mouse mode enabled just by putting the controller down on a table or your pant’s leg. Lenovo did it first on the Legion Go with its FPS mode. So is it any better now? No, absolutely not. You still need to remove the right controller and flick the “FPS” switch to turn on an optical mouse sensor. You then need to slot it into a base to hold it like an old-school flight stick, where the two side buttons act as the left and right mouse click. The DPI is still low enough you’ll struggle to get it working on anything but a desk. Even when you do, using a joystick and the FPS controller together necessitates changing the in-game controls. I tried it in both Cyberpunk 2077 and Borderlands 4, and it caused such havoc with both titles I was loathe to use the FPS mode again.\n\nAs for I/O, the Legion Go 2 has both a bottom and top USB-4 port. In theory, this could allow you to hook it up to an eGPU. More likely, it’s sole purpose is for charging or hooking up to a dock for HDMI passthrough. As much as Lenovo implies you’ll create a full “battle station” out of your device for instantaneous PC, you don’t want to hook it up to anything larger than a 1440p monitor, and only then for playing games most systems can run anyway.\n\nStrangely enough, one of the best improvements over the last generation handheld is the Legion Go 2’s new soft carrying case. The old case was very protective, but it was also enormous. The new version is smaller and more squat than the default Steam Deck case, which makes lugging around the 8.8-inch handheld onto planes surprisingly easy. There’s two little hidey-holes for the FPS mode stand, but since you’ll never use it, you can stick anything else in there. Just don’t tell me what.\n\nThe Legion Go 2 is so damn pretty\n\nAll the new ergonomics make it easier to hold, but not enough that it won’t feel heavy in your hands. You’ll find you’ll need a table or lap to rest your elbows on, or else you’ll use the built-in kickstand to prop it up on your desk. Either way you hold it, you’ll end up enjoying this handheld mostly for the display. As I said earlier, the 8.8-inch OLED display is sublime. It doesn’t have any higher screen resolution than the Legion Go’s 1,920 x 1,200, but it’s enough to make games pop.\n\nFor my hands, the Legion Go 2 is just large enough where I can grip it and access all the controls. Other users who are smaller in stature may not be so lucky. Ignore all those 11-inch handhelds out there. Near-9-inch devices are more than enough. The screen also sports a 144Hz refresh rate with VRR, or variable refresh rate. All those games that can hit above 100 fps (which, let’s be honest, will mostly be older or 2D titles), will look their peak on the Legion Go 2.\n\nThe screen feels bright enough indoors, but while Lenovo promises you’ll get 1,100 nits of HDR brightness, the screen is not great for using outdoors. It’s blinded by direct sunlight, and even sitting near a window you’ll see most details disappear. The screen is also very reflective. A matte coating would have dulled the display quality, but it’s at the risk of catching a glimpse of your girlfriend walking up behind you.\n\nRyzen Z2 Extreme isn’t a huge leap\n\nThe AMD Ryzen Z2 Extreme APU is purely iterative. If you’ve been watching like a hawk, hoping to devour the latest and fastest handheld chip, this isn’t it. The performance difference generation to generation is minimal. In some games, you could get 5 to 10 fps more at the highest TDP, or thermal design power, People who focus too hard on benchmarks will come away disappointed. If you care more about whether the system can play the latest AAA games, know that you’ll be able to achieve playable frame rates at the max 1200p resolution though only by dropping any hope of ray tracing for more-realistic lighting effects.\n\nSee Lenovo Legion Go 2 at Best Buy\n\nI’m fundamentally a gamer who refuses to drop the resolution of games for the sake of performance. I will lower graphics settings in a desperate attempt to eek out the minimum 30 fps. The Legion Go 2 can manage to take some AAA games into playable states at the max 35W of TDP (thermal design power) once the handheld’s engines are firing on all cylinders. TDP determines how much power is being sent to the processor, which will dictate overall performance. Borderlands 4 is one of those games notorious for running poorly on PC and consoles alike (you won’t find the game on Switch 2 in the coming days, either). I was able to get a stable sub-40 fps on the lowest possible graphics settings. I could achieve a little better frame rates in Indiana Jones and the Great Circle. Even at lower graphics settings, the game still looks and sounds great on the small screen.\n\nOlder games fare better. Control could average 40 to 49 fps at low settings with the handheld plugged in. The Shadow of the Tomb Raider benchmark at 1200p and medium settings preset with AMD’s FSR upscaling saw an average of 44 fps, while at 1080p with the same settings it could hit 48 fps. In Baldur’s Gate III, I could average above 60 fps in the open areas of Act 1 and get between 45 and 55 fps in the city environments of Act III.\n\nIn 3DMark benchmarks, the Legion Go 2 hit a score of 3,305 and 24.48 average fps in Steel Nomad Lite tests. That’s 1,000 points better than the Legion Go S with its Ryzen Z2 Go chip running on Windows, but it’s only a little more than 300 points better than the Z1 Extreme on the Asus ROG Ally X from 2024. The new device hit 3,897 points in Time Spy tests, which again is barely more than 300 points better than an Ally X. It’s not much better than an MSI Claw 8 AI+, which uses a full Intel laptop chip. Simply put, the Legion Go 2 isn’t a huge step over the previous gen at the max wattage.\n\nHowever, the device’s secret sauce is in how well it performs at lower wattages. Tests with multiple games at wattages as low as 34 fps still enabled relatively stable frame rates in games like Shadow of the Tomb Raider. While in Cyberpunk 2077 at full resolution and Steam Deck settings, the device gets 44 fps in benchmarks, at 15W it still managed to eek out nearly 30 fps. I don’t expect anybody will run high-end games on lower power. Instead, the best experience comes from games that are far less intensive. I could net well over 160 fps in Hades II on the “Balanced” performance setting. Hollow Knight: Silksong seems like it was built with the Legion Go 2 in mind with automatic settings to stay around 144Hz. These games play so gloriously on this handheld, I don’t want to play them on anything else. It’s a shame you have to spend $350 more than an Xbox Ally X jut for that pretty screen and higher refresh rate.\n\nWindows still sucks for handhelds, but it could get better\n\nOn balanced power settings, I could game for around 2 hours and 40 minutes before the device was literally begging me to plug it in. In other tests where I was gaming at the full resolution and wattage playing Indiana Jones, it lasted closer to 2 hours. The Legion Go 2 sports a 74Wh battery, which is slightly worse than the ROG Ally X’s 80Wh. The larger OLED display and higher max resolution will inevitably drag the battery life down.\n\nAt this point, players should not expect a handheld that will last very long. The ROG Ally X still has one of the best battery life at full power when it gets closer to 3 hours of runtime. In real life, the difference is negligible. At this point in my life, having a max two hours of playtime is strangely beneficial. If I’m clearing room after room in Hades II late at night, the battery timer is essentially my alarm. If it’s close to 12 a.m. and I’m about to run out of power, it’s a sign I should get some rest.\n\nDepending on the game you’re playing, the device’s fans can get relatively loud. Even at max speed I wouldn’t call them jet engine noise. It’s enough to remind you to be mindful when sitting next to strangers on a plane. The device kept very cool in my time using it. I never felt any heat around the controls, and the area around the fans also didn’t feel steamy when playing a game at max wattage.\n\nI can’t excuse the price, but I had such a good time with the Legion Go 2 it felt like a personal companion after traveling for more than a week and a half away from home. But there’s an elephant in the room shaped like a big “X” we need to address. The Xbox Ally and Xbox Ally X are supposed to launch with a new version of Windows, dubbed the “Full Screen Experience” (FSE) built exclusively for gaming handhelds. While this may fix the lingering usability issues of Windows 11 on a 7- or 8-inch screen, the upgrade should also eliminate background tasks and—hopefully—boost performance by 20%. The issue is that Microsoft has said you may need to wait until next spring to get it on handhelds like the Legion Go 2.\n\nWindows is terrible on handhelds. It gets in the way when trying to put the device to sleep while still in-game. It bombards you with popups for OneDrive that you need to use the touchscreen to excise. It saps power and makes the device run worse than it would if it was running SteamOS, the same Linux-based operating system running on the Steam Deck. In our tests, the Legion Go S with SteamOS outperforms its Windows counterpart by 20 to 30%. Unless you’re dead set on keeping your Xbox Game Pass games handy, I would suggest looking into installing Valve’s software on the Legion Go 2. I have not confirmed whether you can install SteamOS on the new handheld, though if its not compatible at launch, I assume an update may be around the corner. Without the FSE or SteamOS, this can’t be my handheld of choice. With a new operating system, the Legion Go 2 would become the bell of the ball for modern PC handhelds.\n\nSee Lenovo Legion Go 2 at Best Buy",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/lenovo-legion-go-2-review-a-handheld-made-for-big-meaty-claws-2000666394",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Linux 6.18 DRM Pull Includes New Tyr & Rocket Drivers, More AMD & Intel GPU Enhancements",
      "content": "The Direct Rendering Manager \"DRM\" pull request ended up leading to Linus Torvalds complaining over text and Rust code formatting but in the end he pulled all of these kernel graphics driver updates and also the associated \"accel\" accelerator subsystem drivers too.With the Linux 6.18 DRM pull there is a lot of kernel graphics driver improvements across the board, including the new drivers of Tyr and the Rocket accelerator driver. For enhancing existing driver support, the AMD and Intel graphics drivers continue seeing a bulk of the activity. Plus ongoing Rust code work in the DRM subsystem and more.\n\nBelow is a look at the DRM kernel driver changes for Linux 6.18.- The \"Rocket\" accelerator driver is finally mainlined for enabling the NPU found on newer Rockchip SoCs. This is the open-source driver reverse-engineered and started by Tomeu Vizoso. The Rocket accel driver works with new user-space code in Mesa 25.3 for Rockchip NPUs.- The AMDGPU and AMDKFD Checkpoint and Resture \"CRIU\" support for GEM memory objects.- Expanded AMDGPU Video Core Next \"VCN\" engine reset support.- More AMD Cyan Skillfish updates.- The AMDXDNA accelerator driver now supports user-space allocated buffers, improved error reporting, and other enhancements.- A new Intel Xe driver interface for querying VMA count and memory attributes. The intel Intel SLPC \"power_profile\" sysfs interface for the Xe driver for power management tuning.- Intel Xe driver SR-IOV support for CCS surfaces on Xe2+. The SR-IOV PF mode is also now enabled by default on supported platforms. Intel has returned to working on the upstream Habana Labs accelerator driver . There still is no Gaudi 3 support but at least they are back to working on this code under a new set of maintainers.- Intel Xe driver support for madvise in GPU SVM (Shared Virtual Memory).- The Arm Mali Panthor DRM driver added support for Mali G710, G510, G310, Gx15, Gx20, Gx25 GPUs.- Continued work on Nova as the next-generation open-source NVIDIA Linux kernel driver written in Rust.- The initial code around Tyr as a new Rust driver for Arm Mali GPUs . It's not yet usable by end-users, similar to the Nova driver.- Various new Rust abstractions and other work toward making Rust DRM drivers more practical.See this pull for the full list of DRM feature patches this cycle.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-DRM",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "I tested the GMKtec NucBox K12 and I think developers and creators will love the expansive upgrade potential",
      "content": "While classed as a mini PC, the form factor is marginally larger than most. However, with a powerful mid-range CPU and GPU, the extra airflow enabled by the design and the ability to expand potential with an eGPU make this a surprisingly powerful and versatile option. Through the test, it proved exceptionally good for content creation and even mid-range gaming.\n\nWhy you can trust TechRadar We spend hours testing every product or service we review, so you can be sure you're buying the best. Find out more about how we test.\n\nGMKtec NucBox G9: 30-second review\n\nThe moment that the K12 was removed from the box, it was obvious that this was a more measured machine compared with the majority of high-performance Mini PCs that I have looked at in the last year.\n\nFirstly, it's larger, and the design has a depth and flair to it that is lacking from many of the small box machines that I usually test. As I checked over the casing, it was good to see plenty of venting, and while the AMD Ryzen 7 H 225 and AMD Radeon 780M are a powerful combination, these days they sit decidedly in the mid-range. Thankfully, the pricing reflects this, and the larger form also enables plenty of airflow and a pretty decent array of ports across the front and back of the machine.\n\nAgain, while these are all present generation, it seems that GMKtec has gone for high spec, but tried and tested. So, while powerful, there's nothing ground-breaking here, just hardware that the company knows is going to perform and be reliable.\n\nThrough the test, this was certainly the case, and as I ran through the usual array of office applications, web browsing and even delved into image and video editing, the machine, like many of the best mini PCs I've tested, held up with surprising resilience.\n\nAs the pressure was applied with 4K video editing in DaVinci Resolve, the fans kicked in, and while the 1TB internal storage was enough to hold the source files, I connected a working drive through the USB4 ports at the back for more storage, if I was using this machine longer term then I'd install an addition SSD into one of the two spare internal M.2 2280 slots.\n\nThe data transfer rates were excellent, and while the machine certainly has the brute power to process and edit video, internal storage would need an upgrade to be used as a working drive. The USB4 interface, while fast, is nothing compared to the 4000MB/s+ write speeds of the internal drive. Thankfully, those additional slots enable storage to be upgraded to a staggering 24TB, more than enough for even the busiest content creators! Likewise, the RAM can be boosted to 128GB.\n\nGaming performance is equally well balanced, and while you might not be able to ramp the game's graphics to the max, you're going to get some pretty decent gameplay. If you do want to take gaming up a level, then there's the Oculink port so you can attach an eGPU; there's really no limit on the potential.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nConsidering the features of this machine and the ability to max out the storage, RAM, and connect to an eGPU, it all comes together to offer a very solid machine that will make an ideal solution for content creators, developers or anyone looking for a solid, powerful PC that strikes a balance between the latest technology, speed and reliability.\n\nGMKtec NucBox K12: Price and availability\n\nHow much does it cost? From £409 / $409\n\nFrom £409 / $409 When is it out? Available now\n\nAvailable now Where can you get it? Directly from GMKtec or Amazon\n\nThe GMKtec NucBox K12 is widely available with a price starting at £409/$409 for the barebones version. The model that I've looked at in this review is the 32GB RAM with 1 TB SSD, which will set you back $549/549/£550, or you can order the 64GB RAM, 1TB SSD option for $609/£600 directly from the gmktec.com website. The machine is also available from Amazon.com and AliExpress.\n\nHere are a few quick links with a variety of configurations that I've found:\n\nAmazon.com\n\n32GB / 512GB\n\n32GB / 1TB\n\n64GB / 1TB\n\nAmazon.ca\n\n32GB / 1TB\n\n64GB / 1TB\n\nAmazon.co.uk\n\n32GB / 1TB\n\n64GB / 1TB\n\nGMKtec EU\n\nClick here to see the line-up\n\nValue: 4.5 / 5\n\n(Image credit: Alastair Jennings)\n\nGMKtec NucBox K12: Specs\n\nCPU: AMD Ryzen 7 H 255\n\nGraphics: AMD Radeon 780M\n\nRAM: 32GB DDR5 5600MT (128GB Max)\n\nStorage: 1TB M.2 NVMe PCIe 4.0 SSD\n\nFront Ports: 3.5mm Combo jack, USB3.2 Gen2 Type-C (PD/DP/Data), 2×USB3.2 Gen2 Type-A, USB2.0, Clear CMOS\n\nRear Ports: DC port, 3.5mm Combo jack, HDMI 2.1, DP 1.4, USB4, Oculink (PCIe Gen4×4), USB3.2 Gen2 + USB2.0, 2×2.5G LAN (Realtek 8125BG), Fan/LED control button\n\nConnectivity: Wi-Fi 6E, Bluetooth 5.2\n\nAudio: Built-in speakers (basic), headphone/mic combo jack\n\nCamera: None\n\nSize: 117 x 112 x 42 mm\n\nOS Installed: Windows 11 Pro\n\nAccessories: Power adapter, HDMI cable, VESA mount\n\nGMKtec NucBox K12: Design\n\nThe GMKtec NucBox K12 takes a slightly different approach to design compared with many other Mini PCs. Firstly, it's slightly larger, so while still small, there's more airflow potential and plenty of space for accessories.\n\nThe design is clean with a matte black aluminium body, with a folded-over detail that covers the top and bottom fans. On top, there's also a turbo fan button, which gives you some sort of control over the machine's cooling. The main purpose of this machine is as a no-fuss processing machine for content creation, development, or any other task that would put most other machines under sustained strain.\n\nWhile the price point of the machine is decidedly mid-range, the use of metal and the detailing just give this an added feeling of quality, and when you couple that with the fact that even as a mini PC it is so upgradable, you suddenly realise that actually, for what's on offer here, it is exceptionally well-equipped and priced.\n\nWhile the form factor is slightly larger than some others at 117 x 112 x 42 mm and weighing in at X g, it's still light enough to be easily mounted using the VESA mount that's included in the box.\n\n(Image credit: Alastair Jennings)\n\nAround the front, there's a good selection of ports with 3.5mm combo jack, USB3.2 Gen2 Type-C (PD/DP/Data), 2×USB3.2 Gen2 Type-A, USB2.0 and a Clear CMOS button.\n\nAround the back, there's again a good selection of ports with a DC port, a combo jack, an HDMI 2.1, a DP 1.4, an Oculink (PCIe Gen4×4), USB4, a USB3.2 Gen2 + USB2.0, 2×2.5G LAN (Realtek 8125BG) and a Fan/LED control button on top.\n\nAccess to the insides, where you can add up to three M.2 SSDs and RAM, is made by removing the metal fan cover and then going through the top. Everything is nicely laid out, and access to all hardware is easily available if you do want to upgrade in the future.\n\nDesign: 4.5 / 5\n\n(Image credit: Alastair Jennings)\n\nGMKtec NucBox K12: Features\n\nThe AMD Ryzen 7 H 255 offers 8 cores and 16 threads with Zen 4 architecture, and this is coupled with the AMD Radeon 780M with RDNA 3 architecture. In the past, this combination has proven to be well-priced and powerful.\n\nSupporting the processing is an equally impressive range of memory with dual-channel DDR5 5600 MT/s SO-DIMM slots that can take up to two 64GB sticks, giving you 128GB of usable RAM. There are also three M.2 2280 PCIe slots that will enable you to add up to 24TB of storage. This is one of the largest capacities for this price point of Mini PC that I have come across, and again, it is extremely impressive.\n\nIt's worth noting that two of those slots are PCIe 4.0x2, and one is PCIe 4.0x4, with the operating system in the review sample utilising this slot for the SSD to ensure the fastest possible speeds.\n\nUpgradability does seem to be at the heart of this machine. Out of the box, you have a very solid and reliable machine with tried and tested hardware, with a few bits of bang-up-to-date technology to ensure future-proofing. The USB4 offers fast transfer speeds and connection to monitors, and the DDR5 RAM offers exceptional speed.\n\nOn top of the impressive performance I gained from the base 32GB, 1TB SSD review unit, it was obvious with all the cooling options that this machine, if enabled, would have a lot more to give.\n\nWith USB4, USB-C, HDMI and DP ports, you have plenty of potential to link out to monitors at 4K@60Hz, but then with the Oculink port, you can also easily hook into an eGPU for a huge graphics power boost.\n\nAnother feature that reinforces the fact that this machine has been aimed at users who place demands on their systems is the dual 2.5G Ethernet, enabling ultra-fast wired networking, so that there's minimal network lag and again reliability, if again the 2.5G technology is a little dated.\n\nFinally, my review sample arrived with Windows 11 Pro pre-installed, but as ever, you can install Linux, Ubuntu or any variation you need.\n\n(Image credit: Alastair Jennings)\n\nFeatures: 4 / 5\n\nGMKtec NucBox K12: Performance\n\nBenchmark scores CrystalDiskMark Read: 5024.59\n\nCrystalDiskMark Write: 4453.91\n\nGeekbench CPU Multi: 11694\n\nGeekbench CPU Single: 2369\n\nGeekbench GPU: 31240\n\nPCMark Overall: 6705\n\nCinebench CPU Multi: 13519\n\nCinebench CPU Single: 1606\n\nFire Strike Overall: 7512\n\nFire Strike Graphics: 8171\n\nFire Strike Physics: 22243\n\nFire Strike Combined: 2892\n\nTime Spy Overall: 3125\n\nTime Spy Graphics: 2796\n\nTime Spy CPU: 9385\n\nWild Life Overall: 17400\n\nSteel Nomad Overall: 549\n\nWindows Experience Overall: 8.2\n\nGetting started with the GMKtec K12 was fast, with the Wi-Fi connection seeming to be especially robust on the Eero 6 router compared with some of the smaller machines.\n\nAs the machine arrived with Windows 11 Pro installed, it was just a case of running through the standard Windows setup process, and the machine was ready to go.\n\nInitial impressions were good, with the machine running silently and able to cope with multiple browser windows open and editing Google Docs and other spreadsheets without issue. As with most machines these days, the standard office tasks are a given, and everything should run smoothly.\n\nAs the test continued, I installed and opened Photoshop, Lightroom and DaVinci Resolve, quickly pushing the abilities of the machine, but once again the CPU and GPU combo managed to handle everything with seeming ease.\n\nPhotoshop, Lightroom and Bridge in particular ran especially smoothly, with files opening and closing quickly, no doubt due to the exceptionally fast SSD and RAM.\n\nAs I migrated to light video editing in CapCut and then to DaVinci Resolve, the fans did start to kick in, and as graphics were created in Photoshop and brought across to the video editing, there were a few occasions where you could just see the system start to strain. However, it was all well handled, and for an integrated GPU, the Radeon 780M certainly impresses.\n\nAs that processing increased, so did the fan noise, but only slightly. The larger form of the machine, along with the large internal fans, does seem to keep the noise to a minimum, again, a good feature if you're editing video.\n\nChecking through the benchmarks, this reinforced the real-world tests. Microsoft Office and all productivity apps, multimedia worked exceptionally well and as fast and smooth as you could expect on any machine.\n\nCreative applications such as Photoshop and Lightroom run well again, and there's no jittering when using brush tools, and render times in Lightroom are fast.\n\nHowever, as this CPU and GPU are now getting older, they're not supported by AI features or an NPU, so the Photoshop AI processing is noticeably slower than some of the AI-enhanced machines.\n\nAs I moved on to DaVinci Resolve editing 4K video footage from a Sony A7 IV, the results were good. I could feel that I was pushing the system, and the fans kicked in, but short edits were more than achievable, and CapCut, as ever, ran smoothly.\n\nMoving on to gaming, the integrated GPU did start to struggle, and while DiRT Rally and Tekken 8 were perfectly playable, when I moved on to Indiana Jones and the Great Circle and then Hogwarts Legacy, the graphics and resolution did need to drop to the lower settings.\n\nIf you do want to use the machine for gaming, then the Oculink port should come into play, and with the cooling and power of the machine in all other respects, this should make a very decent gaming platform.\n\nPerformance: 4 / 5\n\n(Image credit: Alastair Jennings)\n\nGMKtec NucBox K12: Final verdict\n\n(Image credit: Alastair Jennings)\n\nAs an office machine, the GMKtec K12 is exceptional. Out of the box, it has the speed and reliability to make it a very viable option, and the small size means that it's easily portable if you do need to move it around the office or home.\n\nThe fact that it utilises tried and tested hardware adds to the reliability, and as a machine to test, this has been one of the easiest, just for its speed and ease of use. Likewise, if there is a need to upgrade, then access to the inside is fast, and installation of components should only take a few moments.\n\nWhat I really liked about this machine is just how well-balanced it is. It might be larger than most Mini PCs, but it's still small, and the balance of power and upgradability gives it a level of future-proofing that few other machines of this size or type can offer.\n\nWhen it comes to content creation, the out-of-the-box configuration can handle most business use, short video and image enhancement with ease, and if you need longer productions, then it has the potential and power, especially with a bit of a storage upgrade.\n\nWhile the CPU and GPU are good, they do start to feel the strain under gaming, especially, but even then, with the Oculink option, there's potential.\n\nAs a good, well-priced all-rounder with plenty of upgrade potential, the K12 is a superb option.\n\nShould I buy the GMKtec NucBox K12?\n\nSwipe to scroll horizontally Value Exceptionally well-priced machine with plenty of potential 4.5 Design Great design with a larger form factor that enables plenty of airflow for heavy workloads 4.5 Features A good balance of older and new technology offers speed and reliability 4 Performance Very capable machine for most tasks, including video, with plenty of upgrade potential 4 Overalls A well thought-through machine that can expand as you need 4.5\n\nBuy it if...\n\nYou need power For coders, video editors, or professionals who want to save space and have portability without sacrificing performance. Desk space matters Perfect for minimal setups, VESA mounting if you want to clear your desk, or small enough for travel.\n\nDon't buy it if...",
      "source": "TechRadar",
      "url": "https://www.techradar.com/computing/gmktek-nucbox-k12-mini-pc-review",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Meet Lisa Su: CEO and president of Advanced Micro Devices, the main competitor to Nvidia",
      "content": "Lisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion.\n\nREUTERS/Steve Marcus\n\nAMD's CEO, Lisa Su, grew up in Queens and obtained three…\n\nThis story appeared on businessinsider.com , 2025-10-05 10:16:01.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/ccf28a26f3aecc1a",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Microsoft's new Photos app update is so good that it could well become my favorite photo organizing tool - but you will need a Copilot+ PC to experience it",
      "content": "The app sorts receipts, screenshots, and handwritten notes automatically\n\nCopilot+ PCs are required for Microsoft’s newest Photos app functions\n\nAutomatic classification works even across different languages and scripts\n\nMicrosoft has released a new version of its Photos app, now presented as a more advanced tool for organizing and enhancing digital images.\n\nThe update, now live in the Microsoft Store, relies heavily on local artificial intelligence computation, with new functions tied specifically to Copilot+ PCs.\n\nThe app is not a dedicated photo editor, so it cannot be an Adobe Photoshop alternative. It instead focuses on sorting pictures, tagging documents, and upscaling low-resolution images with AI.\n\nAI-powered photo organization\n\nThe update brings automatic classification using an onboard neural processing unit to scan a library of pictures and sort them into categories such as screenshots, receipts, documents, and handwritten notes.\n\nThis system is meant to reduce the time spent scrolling through unstructured folders.\n\nMicrosoft also says the classification works across languages, so a receipt or document in another script should be tagged correctly.\n\nA “keyword” search option now allows users to quickly filter results, a function that might appeal to those who already store years of digital clutter inside their image folders.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAlongside organizational features, the update introduces a “super resolution” feature that can upscale low-resolution images without relying on external servers.\n\nThe work happens locally on the device, restoring detail that would normally disappear during enlargement.\n\nMicrosoft presents this as a way to bring older or compressed photographs closer to modern display standards.\n\nOn the downside, these AI functions are only available on Copilot+ PCs powered by Intel, AMD, or Qualcomm chips with NPU units.\n\nThat requirement places the most publicized upgrades out of reach for most current Windows users.\n\nIt also frames the Photos app as more of a showcase for Microsoft’s new hardware strategy than a universal solution for managing digital images.\n\nWhile the company promotes the update as a leap in convenience, the limitations suggest that many users will keep relying on existing tools.\n\nSome may stick with a free photo editor already familiar to them, while others will continue returning to established professional packages.\n\nFollow TechRadar on Google News and add us as a preferred source to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!\n\nAnd of course you can also follow TechRadar on TikTok for news, reviews, unboxings in video form, and get regular updates from us on WhatsApp too.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/microsofts-new-photos-app-update-is-so-good-that-it-could-well-become-my-favorite-photo-organizing-tool-but-you-will-need-a-copilot-pc-to-experience-it",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Nintendo Switch 2 supports two different types of Nvidia DLSS — A second, 'light' version for upscaling beyond 1080p, along with the standard, PC-like CNN model",
      "content": "The Nintendo Switch 2 is the only mainstream console that comes with Nvidia hardware inside, while Microsoft and Sony rely on AMD. Therefore, the Switch 2 supports Nvidia's proprietary DLSS technology that helps it upscale games to 1080p and beyond, which is crucial in a handheld with power constraints. It was long speculated that the version of DLSS present on the Switch 2 was unique and unlike the standard models available on PC, and Digital Foundry's latest testing has confirmed that.\n\nNintendo Switch 2 DLSS Image Quality Analysis: \"Tiny\" DLSS/Full-Fat DLSS Confirmed - YouTube Watch On\n\nWhile looking at a diverse selection of titles like Cyberpunk 2077, Street Fighter 6, Hogwarts Legacy, Star Wars Outlaws, The Touryst, and Fast Fusion; Digital Foundry observed that there are two different DLSS versions at work.\n\nFirst up, there's \"Fat DLSS\" that resembles the CNN-based model found on PC, and this can only upscale games to 1080p. It has a cleaner, sharper image in motion, less artifacting, better antialiasing, and smoother camera cuts. Objects move in and out of motion almost identically to how they would on PC — which is to say, gracefully.\n\nBut, as mentioned, it's limited to 1080p. To go past that resolution, Nvidia and Nintendo have developed a special \"DLSS Light\" which can upscale to greater resolutions (remember, Switch 2 is marketed for up to 4K when docked). This version looks better in stills, but looses sharpness as soon as you move because reconstruction techniques get temporarily disabled. It introduces artifacts where you can see unfiltered pixels, but at the benefit of half the frame-time cost, which allows it to scale way past just 1080p.\n\n(Image credit: Jeffrey Kampman/Tom's Hardware)\n\nThis goes to show just how demanding the original version of DLSS is; it doesn't make sense to run that on every game, especially in handheld mode. When you need to reach resolutions higher than 1080p, the light model should still be better, despite its inferior temporal performance. What remains to be seen, though, is whether the newer, more efficient Transformer-based model of DLSS can somehow make its way onto the Switch 2 in the future.\n\nDigital Foundry even reached out to an unnamed but respected developer familiar with DLSS on the Switch, who confirmed that two versions of the tech do indeed exist in the pipeline to choose from. The light version is newer, and more uniquely suited to the Switch 2's hardware capabilities. We haven't seen any first-party Nintendo game utilize DLSS so far either, so that's also something to keep an eye on, given how most Nintendo games focus on precise movement and controls.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/video-games/nintendo/nintendo-switch-2-supports-two-different-types-of-nvidia-dlss-a-second-light-version-for-upscaling-beyond-1080p-along-with-the-standard-pc-like-cnn-model",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "MSI PRO X870-P WIFI ATX AM5 Motherboard + AMD Ryzen 7 7800X3D Processor $499.99",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18662581-msi-pro-x870-p-wifi-atx-am5-motherboard-amd-ryzen-7-7800x3d-processor-499-99",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Prime Exclusive G.SKILL Trident Z5 RGB Series 64GB (2x32GB) Desktop RAM DDR5-6400 PC5-51200 For Intel CPUs + Free Shipping $119.99",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired BabyBubba posted Item 1 of 1 expired BabyBubba posted Prime Exclusive G.SKILL Trident Z5 RGB Series 64GB (2x32GB) Desktop RAM DDR5-6400 PC5-51200 For Intel CPUs + Free Shipping $119.99 $120 $250 52% off Woot! 15 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 2,137 Views Visit Woot! Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details\n\n\n\nShows to be available only to Amazon Prime members.\n\n\n\nhttps://sellout.woot.co m/offers/g...alldeals_2 Woot! has New Prime Exclusive G.SKILL Trident Z5 RGB Series 64GB (2x32GB) Desktop RAM DDR5-6400 PC5-51200 for $119.99. Shipping is free with Amazon Prime.Shows to be available only to Amazon Prime members. Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster BabyBubba Follow Give Rep Message 995 Deal Posts 3,909 Comments Posts 6,337 Reputation Points 216 Votes Submitted Deal Details Community Notes About the Poster\n\n\n\nShows to be available only to Amazon Prime members.\n\n\n\nhttps://sellout.woot.co m/offers/g...alldeals_2 Woot! has New Prime Exclusive G.SKILL Trident Z5 RGB Series 64GB (2x32GB) Desktop RAM DDR5-6400 PC5-51200 for $119.99. Shipping is free with Amazon Prime.Shows to be available only to Amazon Prime members.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18663862-prime-exclusive-g-skill-trident-z5-rgb-series-64gb-2x32gb-desktop-ram-ddr5-6400-pc5-51200-for-intel-cpus-free-shipping-119-99",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Skytech Eclipse Lite 2 Desktop: Ryzen 7 9800X3D, RTX 5080, 32GB RAM, 2TB SSD $2130.99",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18664246-skytech-eclipse-lite-2-desktop-ryzen-7-9800x3d-rtx-5080-32gb-ram-2tb-ssd-2130-99",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Matrix Core Programming on AMD GPUs",
      "content": "TL;DR In this blog post, we walk through how to use Matrix Cores in HIP kernels, with a focus on low-precision data types such as FP16, FP8, and FP4, as well as the new family of Matrix Core instructions with exponent block scaling introduced in the AMD CDNA™4 architecture. Through code examples and illustrations, we provide the necessary knowledge to start programming Matrix Cores, covering modern low-precision floating-point types, the Matrix Core compiler intrinsics, and the data layouts required by the Matrix Core instructions. The blog post is also available on ROCm Blogs.\n\n1. Matrix Cores\n\nMatrix multiplication is an essential part of AI and HPC workloads. The AMD CDNA™ architecture features special-purpose hardware, the Matrix Cores, to accelerate matrix fused-multiply-add (MFMA) operations defined as D:=A*B+C . Please note that MFMA instructions are often used to update a matrix in-place (=accumulation) so that D=C and C:=A*B+C . The matrices A and B are called input matrices, while the matrix D is referred to as the output matrix or accumulator.\n\nThe performance gains from using Matrix Cores are especially significant in mixed-precision mode, where the input matrices use lower-precision data types instead of FP32. The output matrix, however, is stored in FP32 to minimize accuracy loss during accumulation. The tables below show the theoretical peak performance of Matrix Cores with different input data types on both AMD CDNA™3 and AMD CDNA™4 architectures. On the AMD Instinct™ MI325X, using FP16 input matrices delivers nearly an 8x performance increase compared to single-precision, with only minimal accuracy loss. Switching to FP8 further doubles the performance providing a 16x increase when compared to FP32. The AMD CDNA™4 architecture further improves Matrix Core performance, delivering up to 2x higher throughput for FP16 and FP8 compared to the AMD CDNA™3 architecture. In addition, AMD CDNA™4 introduces new low-precision data types such as FP6 and FP4, enabling up to 64x performance gain relative to FP32. Please refer to the AMD CDNA™3 and AMD CDNA™4 white papers for detailed architecture specifications.\n\nType AMD Instinct™ MI325X (CDNA™3) Speedup vs. FP32 Matrix FP64 163.4 TF 1x Matrix FP32 163.4 TF 1x Matrix FP16 1307.4 TF ~8x Matrix FP8 2614.9 TF ~16x\n\nType AMD Instinct™ MI355X (CDNA™4) Speedup vs. FP32 Matrix FP64 78.6 TF ~0.5x Matrix FP32 157.3 TF 1x Matrix FP16 2.5 PF ~16x Matrix FP8 5 PF ~32x Matrix FP6 10 PF ~64x Matrix FP4 10 PF ~64x\n\n2. Low-Precision Floating-Point Types\n\nA binary representation of a floating-point number consists of n bits, where m of n bits represent the mantissa, 1 bit determines the sign and n-m-1 bits represent the exponent. The following image illustrates the binary format of a floating-point number and how the exponent and mantissa are calculated based on its binary representation.\n\nFigure 1: Binary representation of a floating-point number.\n\nFloating-point types are characterized by the number of bits used for the exponent and for the mantissa. Increasing the exponent width extends the range of representable values, while increasing the mantissa width improves precision. Since all floating-point types include the sign bit, a shorthand notation typically specifies only the exponent and mantissa widths. For example, the E4M3 type is an 8-bit floating-point type with 4-bit exponent and 3-bit mantissa. Additionally, a floating-point type is specified by exponent bias - a number that is subtracted from the exponent during conversion from binary format to real value. Given the exponent width, mantissa width, and exponent bias, one can convert the binary representation of a floating-point type (except E8M0) into its real value using the following equation:\n\nFigure 2: Conversion to real value from binary representation for floating-point numbers.\n\nPlease note that the equation takes different forms depending on whether the exponent is zero or not. Often, certain exponent and mantissa values are reserved for special values (e.g. NaN , Infinity ), which limits the range of representable real numbers. For example, the FP16 type has 5-bit exponent with a nominal range of [0, 1, ... 2^5-1] = [0, 1, ... 31] . However, the exponent value E = 31 is reserved for NaN (if the mantissa M != 0 ) and infinity (if the mantissa M = 0 ). Therefore, the largest exponent value that can represent a real number is E = 30 .\n\nThe following table summarizes low-precision types commonly used in modern AI/ML workloads:\n\nWidth Shorthand Exp. bias Range Zero NaN Infinity 16-Bit E5M10 (FP16) 15 ±65504 S 00000 0000000000 S 11111 xxxxxxxxxx S 11111 0000000000 E8M7 (BF16) 127 ±3.3895 * 10^38 S 00000000 0000000 S 11111111 xxxxxxx S 11111111 0000000 8-Bit E4M3FN (FP8, OCP) 7 ±448 S 0000 000 S 1111 111 n/a E4M3FNUZ (FP8) 8 ±240 0 0000 000 1 0000 000 n/a E5M2 (BF8, OCP) 15 ±57344 S 00000 00 S 11111 {01, 10 11} S 11111 00 E5M2FNUZ (BF8) 16 ±57344 0 00000 00 S 00000 00 n/a E8M0 127 2^(±127) n/a 11111111 n/a 6-Bit E2M3 1 ±7.5 S 00 000 n/a n/a E3M2 (BF6) 3 ±28 S 000 00 n/a n/a 4-Bit E2M1 (FP4) 1 ±6 S 00 0 n/a n/a\n\nPlease note that the E4M3 type has two variants: E4M3FN and E4M3FNUZ. Both E4M3FN and E4M3FNUZ use 4 bits for the exponent and 3 bits for the mantissa. They use different exponent biases and differ in the special values they can represent. Neither variant supports infinities, which is why their notations include FN (FiNite). However, E4M3FN supports +0 , -0 , +NaN and -Nan , while E4M3FNUZ supports only +0 and NaN , hence UZ (Unsigned Zero). The image below demonstrates how to convert a binary sequence into a real value, using E4M3FNUZ type as an example:\n\nFigure 3: E4M3FNUZ encoding details.\n\nFP8 types are divided into E4M3 and E5M2 formats. The E5M2 format is sometimes referred to as BF8, similar to BF16, where exponent width is larger compared to FP16. Similar to E4M3, E5M2 is further subdivided into two variants: E5M2 (OCP) and E5M2FNUZ. The AMD CDNA™3 architecture uses FNUZ variants for both E4M3 and E5M2, whereas the CDNA™4 architecture uses E4M3FN and E5M2 (OCP) variants. E4M3FN and E5M2 are standardized formats defined by the Open Compute Project (OCP). For detailed specifications, see the OCP Microscaling Formats (MX) Specification and the ONNX documentation. For visualization of FP8 values and their binary representations please refer to the FP8 Data table. Additionally, see the chapter “Low-precision floating-point types” in the AMD ROCm™ documentation for details on using low-precision types in HIP.\n\nThere is a special 8-bit format, E8M0, which is not used as a standard element data type but instead serves as a scale factor for microscaling types and block-scaled MFMA operations (discussed later in this article). Its value is calculated according to the equation below:\n\nFigure 4: E8M0 encoding details.\n\nThe exponent value E = 255 is reserved for NaN values, limiting the range of representable real numbers to [2^-127 ... 2^127] .\n\nSimilar to FP8, FP6 has two formats: E2M3 and E3M2. The latter, E3M2, is often referred to as BF6 due to its larger exponent width compared to E2M3.\n\n3. Matrix fused-multiply-add (MFMA) Instructions\n\nThe AMD CDNA™3 and CDNA™4 architectures support a variety of MFMA operations, which are characterized by the matrix dimensions M , N , K and the data type of input/output matrices. The following table lists all available floating-point MFMA instructions for the AMD CDNA™3 and CDNA™4 architectures. As can be seen from the table, the AMD CDNA™4 architecture extends the set of available MFMA instructions by adding new FP16/BF16 instructions with larger matrix dimensions. Furthermore, it introduces FP6/FP4 data types and provides a completely new set of FP8/FP6/FP4 instructions where the types can be independently used for the matrices A and B . Finally, the AMD CDNA™4 architecture enables MFMA with block exponent scaling.\n\nType (C,D) ← (A,B) MxNxK (CDNA™3) MxNxK (CDNA™4) Cycles Note FP64 ← FP64 16x16x4 16x16x4 64 FP32 ← FP32 32x32x2 32x32x2 64 16x16x4 16x16x4 32 FP32 ← FP16 (BF16) 32x32x8 32x32x8 32 Both A and B are either FP16 or BF16 16x16x16 16x16x16 16 - 16x16x32 16 - 32x32x16 32 FP32 ← FP8 16x16x32 16x16x32 16 FP8 (E4M3) or BF8 (E5M2) can be used independently for A and B 32x32x16 32x32x16 32 FP32 ← FP8/FP6/FP4 - 16x16x128 16 or 32 FP4, FP6 or FP8 can be used independently for A and B. Larger cycle count if either matrix A or B is FP8 - 32x32x64 32 or 64 FP32 ← MXFP8/MXFP6/MXFP4 - 16x16x128 16 or 32 FP4, FP6 or FP8 can be used independently for A and B. Larger cycle count if either matrix A or B is FP8 - 32x32x64 32 or 64\n\nPlease note that the table lists only floating-point type MFMA instructions with batch size = 1. In addition to them, the AMD CDNA™3 and CDNA™4 architectures support batched MFMA operations, where multiple output matrices are computed in parallel. These instructions are not covered in this article. See the Chapter 7 “Matrix Arithmetic Instructions” in the AMD CDNA™3 and AMD CDNA™4 ISA reference guides for the full list of available MFMA instructions.\n\nThe table above specifies cycle count for each MFMA operation. Given a known cycle count, one can estimate theoretical peak performance in TFLOP/s of corresponding MFMA operation using the formula below:\n\n2*M*N*K * num_matrix_cores * (max_engine_clock / cycle_count) / 10^6,\n\nwhere\n\nnum_matrix_cores is total number of matrix cores in a GPU (specified in white paper) max_engine_clock is max engine clock (peak) in MHz (specified in white paper) cycle_count is cycle count of corresponding MFMA instruction M, N, K are matrix dimensions\n\nUsing this formula and the MFMA instruction 32x32x8 FP16 as an example, we can estimate theoretical peak FP16 Matrix Core performance on the AMD Instinct™ MI325X:\n\n2*32*32*8 * 1216 * (2100 / 32) / 10^6 = 1307.4 TFLOP/s .\n\n4. Compiler Intrinsics\n\nTo use Matrix Core instructions in HIP kernels, LLVM provides built-in compiler intrinsic functions. The list of all available compiler intrinsics can be found in the LLVM Github repository. The syntax of the MFMA intrinsics has the following format:\n\nd_reg = __builtin_amdgcn_mfma_ODType_MxNxKInDType(a_reg, b_reg, c_reg, cbsz, abid, blgp) ,\n\nwhere\n\nMxNxK specifies the shapes of the matrices A , B , C , D , ODType is data type of the matrices C and D , InDType is data type of the input matrices A and B , a_reg is a scalar/vector containing a portion of the matrix A , b_reg is a scalar/vector containing a portion of the matrix B , c_reg is a vector containing a portion of the matrix C , d_reg is a vector containing a portion of the matrix D , cbsz , abid , blgp are broadcast flags. For the following discussion, these flags are irrelevant and are, therefore, set to 0 by default, unless specified otherwise. Please refer to the ISA reference guide for detailed information on the broadcast flags.\n\nFor example,\n\n__builtin_amdgcn_mfma_f32_16x16x16f16 performs 16x16x16 MFMA, where both input matrices A and B have type FP16 and the output matrix has type FP32 __builtin_amdgcn_mfma_f32_32x32x16_fp8_fp8 performs 32x32x16 MFMA, where both input matrices A and B have type FP8(E4M3) and the output matrix is stored in FP32 __builtin_amdgcn_mfma_f32_32x32x16_fp8_bf8 performs 32x32x16 MFMA, where the matrix A has type FP8(E4M3) and the matrix B has type BF8(E5M2) .\n\nThe MFMA instructions are wavefront-level (warp-level) instructions, where all work-items (threads) within a wavefront collectively perform a single MFMA operation and the operands A , B , C , D are distributed across work-items so that each work-item in the wavefront holds a portion of the operands. In order to use the MFMA instructions, it’s required to understand how the operands are distributed across threads within a wavefront. The ISA reference guide fully specifies the data layout for all available MFMA instructions. For illustrative purposes, the next chapter explains a subset of the MFMA instructions and the corresponding data layouts.\n\n5. Examples\n\nImportant note: In the following discussion we assume the matrices are stored in row-major order. The wavefront size on the AMD CDNA™ architecture is 64. The shapes of the matrices A , B , C , D are MxK , KxN , MxN , and MxN , respectively. The first dimension denotes the number of rows and the second dimension the number of columns in a matrix. For example, the matrix A has M rows and K columns.\n\n5.1. __builtin_amdgcn_mfma_f32_32x32x2f32\n\nIn this example we will multiply matrix A of size 32x2 with matrix B of size 2x32 using single wavefront (64 threads) and single MFMA instruction. The output matrix C has shape 32x32 . The input and output matrices are FP32. Since threads within a wavefront collectively perform single MFMA instruction, the operands are distributed across the threads. Each thread stores\n\nM * K / wavefront_size = 32 * 2 / 64 = 1 entries of the matrix A K * N / wavefront_size = 2 * 32 / 64 = 1 entries of the matrix B M * N / wavefront_size = 32 * 32 / 64 = 16 entries of the matrix C\n\nThe operands are distributed according to the scheme below. The matrix elements highlighted in light red are those stored by the thread with index 0 within the wavefront.\n\nFigure 5: Data layout for `__builtin_amdgcn_mfma_f32_32x32x2f32`. The operands are stored in row-major order.\n\nThe code example below demonstrates how this operation can be implemented as a HIP kernel:\n\n#include <hip/hip_runtime.h> using fp32x16_t = __attribute__ (( vector_size ( 16 * sizeof ( float )))) float ; __global__ void mfma_fp32_32x32x2_fp32 ( const float * A , const float * B , float * C ) { float a_reg ; float b_reg ; fp32x16_t c_reg {}; const float * ldg_a_ptr = A + threadIdx . x / 32 + 2 * ( threadIdx . x % 32 ); const float * ldg_b_ptr = B + threadIdx . x % 32 + ( threadIdx . x / 32 ) * 32 ; a_reg = * ldg_a_ptr ; b_reg = * ldg_b_ptr ; c_reg = __builtin_amdgcn_mfma_f32_32x32x2f32 ( a_reg , b_reg , c_reg , 0 , 0 , 0 ); for ( int i = 0 ; i < 4 ; i ++ ) { C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + i * 32 * 8 ] = c_reg [ i * 4 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 1 + i * 32 * 8 ] = c_reg [ i * 4 + 1 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 2 + i * 32 * 8 ] = c_reg [ i * 4 + 2 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 3 + i * 32 * 8 ] = c_reg [ i * 4 + 3 ]; } }\n\nThe GPU kernel can then be invoked on the host using a single wavefront:\n\nmfma_fp32_32x32x2_fp32 <<< 1 , 64 >>> ( A_device , B_device , C_device );\n\nPlease note that we use the vector data type fp32x16_t to store the entries of the matrix C in registers. Additionally, we zero-initialize c , since we compute C = A * B without accumulation.\n\n5.2. __builtin_amdgcn_mfma_f32_16x16x16f16\n\nThis example demonstrates how to multiply matrix A of size 16x16 with matrix B of size 16x16 using single wavefront (64 threads) and single MFMA instruction. The output matrix C has shape 16x16 . The input matrices are stored in FP16 and the output matrix stored in FP32. In this case, each thread stores 4 entries of the matrix A , 4 entries of the matrix B and 4 entries of the matrix C . The data layout for this instruction is shown below. For illustrative purposes, the elements stored by the first thread within the wavefront are highlighted in red.\n\nFigure 6: Data layout for __builtin_amdgcn_mfma_f32_16x16x16f16. The operands are stored in row-major order.\n\nCorresponding HIP kernel is implemented below:\n\n#include <hip/hip_runtime.h> #include <hip/hip_fp16.h> using fp16_t = _Float16 ; using fp16x4_t = __attribute__ (( vector_size ( 4 * sizeof ( fp16_t )))) fp16_t ; using fp32x4_t = __attribute__ (( vector_size ( 4 * sizeof ( float )))) float ; __global__ void mfma_fp32_16x16x16_fp16 ( const fp16_t * A , const fp16_t * B , float * C ) { fp16x4_t a_reg ; fp16x4_t b_reg ; fp32x4_t c_reg {}; a_reg = * reinterpret_cast < const fp16x4_t *> ( A + 4 * ( threadIdx . x / 16 ) + 16 * ( threadIdx . x % 16 )); for ( int i = 0 ; i < 4 ; i ++ ) { b_reg [ i ] = * ( B + i * 16 + threadIdx . x % 16 + ( threadIdx . x / 16 ) * 64 ); } c_reg = __builtin_amdgcn_mfma_f32_16x16x16f16 ( a_reg , b_reg , c_reg , 0 , 0 , 0 ); for ( int i = 0 ; i < 4 ; i ++ ) { * ( C + i * 16 + threadIdx . x % 16 + ( threadIdx . x / 16 ) * 64 ) = c_reg [ i ]; } }\n\nPlease note that both __half and _Float16 types can be used in device code. However, the host supports only _Float16 type for arithmetic operations. As in the previous example, we use vector data types to store the matrix elements in registers.\n\n5.3. __builtin_amdgcn_mfma_f32_32x32x16_fp8_fp8\n\nIn this example we will multiply matrix A of size 32x16 with matrix B of size 16x32 using single wavefront (64 threads) and single MFMA instruction. The output matrix C has shape 32x32 . The input matrices are stored in FP8 and the output matrix is stored in FP32. In this scenario, each thread stores 8 elements of the matrix A , 8 elements of the matrix B and 16 elements of the matrix C . The operands are distributed according to the scheme below. For illustrative purposes, the elements stored by the first thread within the wavefront are highlighted in red.\n\nFigure 7: Data layout for __builtin_amdgcn_mfma_f32_32x32x16_fp8_fp8. The operands are stored in row-major order.\n\nThe code example below implements this operation as a HIP kernel:\n\n#include <hip/hip_runtime.h> #include <hip/hip_fp8.h> using fp8_t = __hip_fp8_storage_t ; using fp8x8_t = __attribute__ (( vector_size ( 8 * sizeof ( fp8_t )))) fp8_t ; using fp32x16_t = __attribute__ (( vector_size ( 16 * sizeof ( float )))) float ; __global__ void mfma_fp32_32x32x16_fp8_fp8 ( const fp8_t * A , const fp8_t * B , float * C ) { fp8x8_t a_reg ; fp8x8_t b_reg ; fp32x16_t c_reg {}; a_reg = * reinterpret_cast < const fp8x8_t *> ( A + ( threadIdx . x / 32 ) * 8 + ( threadIdx . x % 32 ) * 16 ); for ( int i = 0 ; i < 8 ; i ++ ) { b_reg [ i ] = * ( B + i * 32 + threadIdx . x % 32 + ( threadIdx . x / 32 ) * 8 * 32 ); } c_reg = __builtin_amdgcn_mfma_f32_32x32x16_fp8_fp8 (( long ) a_reg , ( long ) b_reg , c_reg , 0 , 0 , 0 ); for ( int i = 0 ; i < 4 ; i ++ ) { C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + i * 32 * 8 ] = c_reg [ i * 4 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 1 + i * 32 * 8 ] = c_reg [ i * 4 + 1 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 2 + i * 32 * 8 ] = c_reg [ i * 4 + 2 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 3 + i * 32 * 8 ] = c_reg [ i * 4 + 3 ]; } }\n\nTo define FP8, we use __hip_fp8_storage_t type from hip_fp8.h . Note that the intrinsic function expects its first two operands to be of type long . To compile the code, the operands a and b are, therefore, converted to long .\n\n5.4. __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f8\n\nImportant note: the MFMA instruction discussed in this example is supported only on AMD CDNA™4 GPUs (gfx950). Please make sure to install AMD ROCm™ version 7.0 or later.\n\nThe AMD CDNA™4 architecture introduces a new family of MFMA instructions with block exponent scaling. The syntax of these instructions differs from the classic MFMA compiler intrinsics:\n\nd_reg = __builtin_amdgcn_mfma_scale_f32_MxNxK_f8f6f4(a_reg, b_reg, c_reg, Atype, Btype, OPSEL_A, scale_a, OPSEL_B, scale_b)\n\nMxNxK specifies shapes of the matrices A , B , C , D a_reg is a vector containing elements of the matrix A , b_reg is a vector containing elements of the matrix B , c_reg is a vector containing elements of the matrix C , d_reg is a vector containing elements of the matrix D , Atype is an integer that specifies the data type of the matrix A . The following values are possible: 0 = E4M3 (fp8), 1 = E5M2(bf8), 2 = E2M3(fp6), 3 = E3M2(bf6), 4 = E2M1(fp4) , Btype is an integer that specifies the data type of the matrix B . The following values are possible: 0 = E4M3 (fp8), 1 = E5M2(bf8), 2 = E2M3(fp6), 3 = E3M2(bf6), 4 = E2M1(fp4) , OPSEL_A , OPSEL_B are OPSEL codes. These arguments are not relevant for the discussion and therefore will be set to 0 , scale_a , scale_b are scalars / vectors containing scale factors of type E8M0 .\n\nAs an example, let’s take a closer look at the instruction __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 . The inputs to this instruction are\n\nMatrix A of size 32x64 Matrix Ax of size 32x2 Matrix B of size 64x32 Matrix Bx of size 2x32\n\nThe output matrix C has shape 32x32 . Specifically, this instruction performs the following operation using single wavefront (64 threads):\n\nFigure 8: Block-scaled matrix multiplication via __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4.\n\nDuring dot product operations, the scales Ax , Bx are applied after the normal dot product and prior to output/accumulation.\n\nIn this example, we will multiply two FP8 matrices using the __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 intrinsic function. The input matrices A , B are stored in FP8 format, while the output matrix is stored in FP32. The scale matrices Ax , Bx contain elements of type E8M0 . Each thread stores 32 entries from the matrix A , 1 entry from the matrix Ax , 32 entries from the matrix B , 1 entry from the matrix Bx and 16 entries from the matrix C . The operands are distributed according to the scheme below. Please note that this scheme is valid only if both input matrices A and B have FP8 type. For illustrative purposes, the matrix elements stored by the thread with threadIdx.x = 0 are highlighted in light red, while the elements stored by the thread with threadIdx.x = 32 within the wavefront are highlighted in light green.\n\nFigure 9: Data layout for __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 with FP8 input matrices. The operands are stored in row-major order.\n\nThe following code example shows how this operation can be implemented as a HIP kernel:\n\n#include <hip/hip_runtime.h> #include <hip/hip_ext_ocp.h> using fp8_t = __amd_fp8_storage_t ; using fp8x32_t = __attribute__ (( vector_size ( 32 * sizeof ( fp8_t )))) fp8_t ; using fp32x16_t = __attribute__ (( vector_size ( 16 * sizeof ( float )))) float ; __global__ void mfma_fp32_32x32x64_fp8_fp8 ( const fp8_t * A , const fp8_t * B , float * C ) { fp8x32_t a_reg ; fp8x32_t b_reg ; fp32x16_t c_reg {}; const fp8_t * ldg_a = A + ( threadIdx . x % 32 ) * 64 + ( threadIdx . x / 32 ) * 16 ; for ( int i = 0 ; i < 2 ; i ++ ) { for ( int j = 0 ; j < 16 ; j ++ ) { a_reg [ i * 16 + j ] = * ( ldg_a + i * 32 + j ); } } const fp8_t * ldg_b = B + threadIdx . x % 32 + 32 * 16 * ( threadIdx . x / 32 ); for ( int i = 0 ; i < 2 ; i ++ ) { for ( int j = 0 ; j < 16 ; j ++ ) { b_reg [ i * 16 + j ] = * ( ldg_b + 32 * j + i * 32 * 32 ); } } uint8_t scale_a = 127 ; uint8_t scale_b = 127 ; c_reg = __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 ( a_reg , b_reg , c_reg , 0 , 0 , 0 , scale_a , 0 , scale_b ); for ( int i = 0 ; i < 4 ; i ++ ) { C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + i * 32 * 8 ] = c_reg [ i * 4 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 1 + i * 32 * 8 ] = c_reg [ i * 4 + 1 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 2 + i * 32 * 8 ] = c_reg [ i * 4 + 2 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 3 + i * 32 * 8 ] = c_reg [ i * 4 + 3 ]; } }\n\nPlease note that in this example we use __amd_fp8_storage_t type defined in hip_ext_ocp.h to represent FP8. This library provides extensions APIs for low-precision and micro-scaling formats, and compared to hip_fp8.h , exposes a wider capability set. gfx950 provides hardware acceleration for these APIs. Most of the APIs are 1 to 1 mapping of hardware instruction. Additionally, we use uint8_t type to represent E8M0 scale factors. Since scale_a and scale_b encode exponent values, the corresponding actual scale factors are 2^(scale_a - 127) and 2^(scale_b - 127) . If scale_a = scale_b = 127 , the actual scale factors are equal to 1 and no scaling is applied.\n\n5.5. __builtin_amdgcn_mfma_scale_f32_32x32x64_f4f4\n\nIn our last example, we demonstrate how to multiply two FP4 matrices using the __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 intrinsic function. As in the previous example, each thread stores 32 entries from the matrix A , 1 entry from the matrix Ax , 32 entries from the matrix B , 1 entry from the matrix Bx and 16 entries from the matrix C . The data layout for the output matrix remains the same as in the FP8 case. However, the data layout for the input matrices is different and depicted below. For illustrative purposes, the matrix elements stored by the thread with threadIdx.x = 0 are highlighted in light red, while the elements stored by the thread with threadIdx.x = 32 within the wavefront are highlighted in light green.\n\nFigure 10: Data layout for __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 with FP4 input matrices. The operands are stored in row-major order.\n\nThe code snippet below demonstrates how to implement this operation as a HIP kernel:\n\n#include <hip/hip_runtime.h> #include <hip/hip_ext_ocp.h> using fp4x2_t = __amd_fp4x2_storage_t ; using fp4x64_t = fp4x2_t __attribute__ (( ext_vector_type ( 32 ))); using fp32x16_t = __attribute__ (( vector_size ( 16 * sizeof ( float )))) float ; __global__ void mfma_fp32_32x32x64_fp4_fp4 ( const fp4x2_t * A , const fp4x2_t * B , float * C ) { fp4x64_t a_reg {}; fp4x64_t b_reg {}; fp32x16_t c_reg {}; const fp4x2_t * ldg_a = A + ( threadIdx . x % 32 ) * 32 + ( threadIdx . x / 32 ) * 16 ; for ( int i = 0 ; i < 16 ; i ++ ) { a_reg [ i ] = * ( ldg_a + i ); } const fp4x2_t * ldg_b = B + ( threadIdx . x % 32 ) / 2 + 16 * 32 * ( threadIdx . x / 32 ); int b_extract_idx = threadIdx . x % 2 ; for ( int i = 0 ; i < 16 ; i ++ ) { uint8_t tmp0 = __amd_extract_fp4 ( * ( ldg_b + 16 * 2 * i ), b_extract_idx ); uint8_t tmp1 = __amd_extract_fp4 ( * ( ldg_b + 16 * ( 2 * i + 1 )), b_extract_idx ); b_reg [ i ] = __amd_create_fp4x2 ( tmp0 , tmp1 ); } uint8_t scale_a = 127 ; uint8_t scale_b = 127 ; c_reg = __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 ( a_reg , b_reg , c_reg , 4 , 4 , 0 , scale_a , 0 , scale_b ); for ( int i = 0 ; i < 4 ; i ++ ) { C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + i * 32 * 8 ] = c_reg [ i * 4 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 1 + i * 32 * 8 ] = c_reg [ i * 4 + 1 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 2 + i * 32 * 8 ] = c_reg [ i * 4 + 2 ]; C [ threadIdx . x % 32 + ( threadIdx . x / 32 ) * 4 * 32 + 32 * 3 + i * 32 * 8 ] = c_reg [ i * 4 + 3 ]; } }\n\nSince memory addressing is not allowed at a granularity smaller than 8 bits, we use __amd_fp4x2_storage_t (an alias for uint8_t ) to store the input matrices and enable pointer operations. Note that the FP4 elements that need to be loaded from the matrix B are not contiguous in memory. To extract a single FP4 element, we use the __amd_extract_fp4 function provided in hip_ext_ocp.h . This function returns one FP4 element (of type uint8_t ) from a fp4x2 vector, based on the index passed as the second argument:\n\nuint8_t __amd_extract_fp4 ( const __amd_fp4x2_storage_t x , const size_t index ) { if ( index == 0 ) return ( x & 0xFu ); return ( x >> 4 ); }\n\nTwo FP4 values are then combined into __amd_fp4x2_storage_t using __amd_create_fp4x2 :\n\n__amd_fp4x2_storage_t __amd_create_fp4x2 ( const uint8_t x , const uint8_t y ) { __amd_fp4x2_storage_t ret = 0 ; ret = x | ( y << 4 ); return ret ; }\n\nThe compiler intrinsic function __builtin_amdgcn_mfma_scale_f32_32x32x64_f8f6f4 requires its first two arguments to be 256 bits wide. Since 32 FP4 elements occupy only 128 bits, we define fp4x64_t , which is 256 bits wide. In this type, 128 bits contain data, while the remaining 128 bits are zero. This allows us to pass a_reg and b_reg to the intrinsic function and compile the code successfully.\n\nSummary\n\nIn this article, we introduced Matrix Core instructions available on the AMD CDNA™3 and CDNA™4 architectures. We covered floating-point formats in detail, including modern low-precision element data types such as FP8, FP6, FP4, and the scale data type E8M0. We further explained how the floating-point types are represented as binary sequences and demonstrated, with concrete examples, how to convert their binary representations into real values. Next, we listed Matrix Core instructions supported by the modern CDNA™ architectures and discussed how to calculate the theoretical peak performance of Matrix Cores for specific MFMA instructions. To make the discussion more practical, we reviewed the compiler intrinsic functions that allow users to program Matrix Cores inside HIP kernels. Finally, we examined a subset of MFMA instructions in detail, providing code examples and illustrations to explain data layout and demonstrate how to implement simple mixed-precision MFMA operations in HIP. For additional information on Matrix Cores and low-precision data types, please refer to the following resources:",
      "source": "Github.io",
      "url": "https://salykova.github.io/matrix-cores-cdna",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "PowerSpec G524 Gaming Desktop: Ryzen 5 7600X, RX 7600, 16GB DDR5 RAM, 1TB SSD $770 + Free Store Pickup",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18661171-powerspec-g524-gaming-desktop-ryzen-5-7600x-rx-7600-16gb-ddr5-ram-1tb-ssd-770-free-store-pickup",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Skytech Eclipse Lite 2 Desktop: Ryzen 7 9800X3D, RTX 5080, 32GB RAM, 2TB SSD $2181 + Free Shipping",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18661510-skytech-eclipse-lite-2-ryzen-7-9800x3d-rtx-5080-32gb-ddr5-2tb-ssd-2180-99",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Following This Diet Can Help Slow Down Vision Loss By Up To 34%, Study Shows",
      "content": "While age and genetics play a large role in your likelihood of developing AMD and the progression of the disease, so do lifestyle factors that promote inflammation and oxidative stress. The good news is that lifestyle habits that are anti-inflammatory have a protective effect.",
      "source": "mindbodygreen.com",
      "url": "https://www.mindbodygreen.com/articles/following-this-diet-can-help-slow-down-vision-loss-by-up-to-34-know-more-about-it",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Like a detective novel, reviewing the Asus ExpertBook P3 came with an unexpected twist",
      "content": "On the face of it, a great laptop, until I realised that Asus had flushed 50% of its performance away by making a poor memory choice. That point aside, this is a nice system with more ports than many laptops get these days, and an excellent Ryzen platform.\n\nWhy you can trust TechRadar We spend hours testing every product or service we review, so you can be sure you're buying the best. Find out more about how we test.\n\nAsus ExpertBook P3: 30-second review\n\nAsus has adopted the latest AMD processor technology and developed a series of powerful laptops that leverage their unique combination of power and features.\n\nThe ExpertBook P3 is aimed squarely at power-users who need a large, 16-inch display to work on substantial documents and the horsepower of a powerful Ryzen 7 AI processor for running CoPilot or other AI models.\n\nIt is one of the few business laptops of this generation that don’t assume you will also buy a docking station, as it comes with plenty of ports that include LAN and HDMI.\n\nThere are also options for up to 64GB of RAM and 3TB of SSD storage using two M.2 slots, but be careful about some memory options, as these might impact performance.\n\nWhat Asus offers here is an affordable business laptop that won’t bust budgets but provides many of the higher-end features that users will adore.\n\nThat’s especially true if they use AI models, as the CPU and NPU combine to provide decent local model processing.\n\nWith a 70Wh battery, this machine can efficiently operate at the top level throughout a working day, achieving over 18 hours in my testing.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nOverall, this is a surprisingly cheap machine considering its potential, being half the price of the top-tier AMD platforms, but offering most of the performance.\n\nWith this spec, the ExpertBook P3 might be included in our best business laptops in the near future.\n\nAsus ExpertBook P3: Price and availability\n\n(Image credit: Mark Pickavance)\n\nHow much does it cost? From $1,179.99\n\nFrom $1,179.99 When is it out? Available now\n\nAvailable now Where can you get it? Direct from Asus now, online retailers later\n\nTechnically, the Asus ExpertBook P3 (PM3606) has been available for bulk purchases directly from Asus since June 2025, but it’s soon going to be more widely available through retail outlets for those wanting to make smaller investments.\n\nIn the USA, prices start at $1,179.99 for a machine with an AMD Ryzen AI 5 330 Processor, 16GB of RAM and a 512GB SSD. For one with the review hardware spec, AMD Ryzen AI 7 350, 32GB of RAM and 1TB of storage, expect to pay $1509.99. Discounts are available for those in the military, students and teacher groups.\n\nAsus in the USA will sell individual units, but in Europe, the minimum purchase is three machines, and the price is typically quoted.\n\nWhen you compare this machine to the HP ProBook 4 G1a, a 14-inch laptop that uses the AMD Ryzen 7 250 with Radeon 780M Graphics, the Asus seems to offer more for roughly the same amount of money.\n\nBut many machine makers have chosen $ 1,500 as the price point for this platform, even though you can get the Ryzen 7 250 systems for much closer to $ 1,000.\n\nFor volume buyers, this machine will likely fall somewhere in between, depending on the amount of memory and storage requested.\n\nValue: 4 / 5\n\nAsus ExpertBook P3: Specs\n\nSwipe to scroll horizontally Category Item Processor AMD Ryzen AI 7 350 2.0GHz (16MB Cache, up to 5.0 GHz, 8 cores, 16 Threads) NPU Performance 50 TOPS (Neural Processing Unit for local AI tasks) Total TOPS 66 TOPS (NPU and CPU combined) Memory 32 GB DDR5-5600 (two slots, up to 64GB possible) Storage 1 TB M.2 2280 PCIe Gen4 NVMe SSD Storage Exp. M.2 2230 PCIe Gen 4 Graphics AMD Radeon 860M Graphics Display Non-touch screen, 16.0-inch, WUXGA (1920 x 1200) 16:10, Wide view, Anti-glare display, LED Backlit, 300nits, NTSC: 45%, Screen-to-body ratio:88 % Camera 1080p FHD camera with IR function to support Windows Hello Audio Audio by Dirac, Smart Amp Technology, Built-in speaker, Built-in array microphone Ports Right 1x USB 3.2 Gen 1 Type-A, 2x USB 3.2 Gen 2 Type-C support display/power delivery, 1x HDMI 2.1 TMDS, 1x 3.5mm Combo Audio Jack Ports Left 1x RJ45 Gigabit Ethernet, 1x USB 3.2 Gen 1 Type-A, Kensington nano security lock Wireless MediaTek Wi-Fi 7 MT7925 (2x2) and Bluetooth 5.4 wireless card Battery 70WHrs, 4S1P, 4-cell Li-ion Operating System Windows 11 Pro Security Trusted Platform Module (TPM) 2.0, Support Absolute Persistence 2.0 (Computrace), Microsoft Security Level 3, Microsoft Secured-core PC BIOS Self Recovery, BIOS Integrity Measurement Support, IR webcam with Windows Hello support, Fingerprint sensor integrated with Power Key Size 35.84 x 25.35 x 1.79 ~ 1.80 cm (14.11\" x 9.98\" x 0.70\" ~ 0.71\") Weight 1.74 kg Sustainability FSC Recycled, TCO Certified, 22% Sustainable material Warranty 1-year limited warranty Colours Misty Grey\n\nAsus ExpertBook P3: Design\n\n(Image credit: Mark Pickavance)\n\nThin form factor\n\nLots of ports\n\n16-inch display\n\nNot super-light\n\nThe Asus ExpertBook P3 (PM3606) is designed with the modern professional in mind, or anyone who wants a large screen and a reasonable amount of computing power. One of the most striking features of this laptop is its thin profile. Measuring just 1.79 to 1.80 centimetres in height, the ExpertBook P3 is incredibly slim, making it highly portable and easy to carry around. This thinness does not compromise its durability, as Asus created a robust aluminium chassis that should withstand the rigours of daily use for longer than something made entirely of plastic.\n\nThe port selection on the Asus ExpertBook P3 is great, catering to a wide range of connectivity needs. It includes two USB 3.2 Gen 1 Type-A ports and two USB 3.2 Gen 2 Type-C ports that support display and power delivery. Additionally, there is an HDMI 2.1 port, a 3.5mm combo audio jack, and an RJ45 Gigabit Ethernet port.\n\nMy only reservations here are that the best USB available is only USB 3.2 Gen 2, whereas USB4 is inherent to this processor series, and the cost saving of a gigabit Ethernet over 2.5GbE probably wasn’t worth it.\n\nOn the upside of the port arrangement, there are plenty of ports, ensuring that users can connect multiple devices simultaneously, whether for presentations, data transfer, or internet connectivity. That negates the need for a docking station, unless you want more than two screens.\n\n(Image credit: Mark Pickavance)\n\nAnother standout feature is the 16-inch display of the ExpertBook P3. It boasts a WUXGA (1920 x 1200) resolution with a 16:10 aspect ratio, providing a wide and immersive viewing experience. In the P3 range specifications, it hints that a higher resolution panel with greater than 300 nits of brightness is an option, but for most uses, this display is fine.\n\nObviously, it doesn’t offer the exacting colour representation as an OLED display, but then this machine isn’t priced to expect one of those.\n\nIn addition to its impressive hardware, the Asus ExpertBook P3 is designed with user comfort and productivity in mind. The backlit chiclet keyboard with 1.5mm key travel is spill-resistant, making it both comfortable to type on and resilient to accidental spills. There are only two things about it I’m less than enamoured with, the first of those being that the designers split the return key in half to put the hash key on the top half. Another space issue is one of those direction clusters where the up and down buttons are half the size of the left and right directions. Considering how much space the 16-inch form factor allowed for the keyboard, a better use of space should have been possible.\n\nThe laptop also features a 1080p FHD camera with IR function for Windows Hello, ensuring secure and convenient login, and the power button is also a fingerprint reader if you prefer that biometric approach. The combination of these features makes the ExpertBook P3 a versatile and reliable choice for professionals who need a powerful and portable laptop.\n\nIn conclusion, the Asus ExpertBook P3 (PM3606) is a well-designed laptop that excels in terms of thinness, port selection, and features a decent display quality. Its slim profile, comprehensive connectivity options, and high-quality display make it an excellent choice for professionals who require a reliable and portable device for their daily tasks.\n\nHowever, at 1.75kg, holding this machine by one corner does require a reasonable amount of wrist and arm strength, and therefore, it’s not ideal for use unsupported.\n\n(Image credit: Mark Pickavance)\n\nDesign: 4 / 5\n\nAsus ExpertBook P3: Hardware\n\nAMD Ryzen 300 AI series CPU\n\nRadeon 860M GPU\n\nSome upgrades\n\nIt’s interesting to compare this Ryzen AI 300 series CPU to the one that was in the HP ProBook 4 G1a, as the Ryzen 7 250 in the HP wasn’t from the Ryzen AI 300 (Krackan Point) series, but the Ryzen 200 (Hawk Point) refresh.\n\nThis architecture marks the first step that AMD has taken in the same direction as Intel, dividing cores into those that are purely for performance and others that are more focused on efficiency. To that end, the AMD Ryzen AI 7 350 has four Zen 5 performance cores and four Zen 5c efficiency cores, but both core types offer hyperthreading, allowing for a thread count of sixteen. That’s double what Intel is offering with the Core Ultra 7 258V, and it’s comparable to that in the Core Ultra 9 models.\n\nBut, my testing suggests that for multitasking, this chip is significantly better than the Core Ultra 7 258V, and AMD has the Ryzen AI 9 HX PRO 375, which is better than anything Intel has in its mobile chip space.\n\nWhere this processor also excels is AI neural processing, as it includes the AMD NPU that’s rated at 50TOPS, and another 16TOPS coming directly from the processor.\n\nThe combined 66TOPS is more than enough to run CoPilot locally and also handle some other localised AI tools. For those entirely dedicated to local AI, the Ryzen AI 9 HX PRO 375 has a 55TOPS NPU and a combined 126TOPS, but what the Ryzen AI 7 350 has is much better than some processors.\n\n(Image credit: Mark Pickavance)\n\nThe Core 7 Ultra 165U, for example, only has an NPU that’s rated at 11 TOPS, and doesn’t meet the minimum 50 TOPS combined level to run CoPilot locally.\n\nGiven how hard Intel has been pushing the AI button recently, you’d think they actually had silicon that could walk that walk.\n\nIn short, there are other chips from AMD that deliver even more AI computing power, but the Ryzen AI 7 350 is more than respectable for those who use this technology.\n\nIf a weakness exists here, it’s the GPU, which is the Radeon 860M. While this might not be Intel UHD Graphics bad, and will render raytracing tests, the recent appearance of the Radeon 8060S on the new Ryzen 9 AI chips has put something of a shadow over the 860M, 880M and even 890M GPUs.\n\nThat said, it delivers more than enough graphics power for typical office use, but it doesn’t elevate the ExpertBook P3 into the realms of a mobile workstation.\n\n(Image credit: Mark Pickavance)\n\nFor those who like to upgrade, the news is good and yet not so wonderful, depending on what sort of enhancements you wish to make.\n\nThe first thing to say about this machine is that getting inside isn’t that easy, even if you only need to remove six screws, in theory.\n\nThe underside of the P3 uses a metal cover that is held in place by a large number of clips once the screws have been removed. Getting enough of these to open sufficiently to remove the back isn’t easy, even for someone who wields a spudger semi-professionally. This exercise isn’t something you will want to do multiple times, so consider this a drive-by upgrade.\n\nOnce inside, you will discover that there are two DDR5 SODIM slots, two M.2 slots and an extra one for the WiFi. You can replace the battery if needed, and you can get a suitable replacement.\n\nThe only caveats are that the second M.2 slot is only a 2230-sized one, limiting it to an additional 1TB based on current capacities. According to Asus, the maximum memory modules that this machine will accept are 32GB, resulting in a total of 64 GB.\n\nActually, since the maximum memory addressed by the processor is 256GB, I suspect that it might accept 48GB modules and end up with 96GB, but I’ve not tested that theory. When 64GB modules become widely available, it might be possible to squeeze 128GB into here.\n\nThere is a twist with the memory that I’ll cover in the next section.\n\n(Image credit: Mark Pickavance)\n\nHardware: 4 / 5\n\nAsus ExpertBook P3: Performance\n\nSwipe to scroll horizontally Laptops Header Cell - Column 1 Asus Expertbook P3 Asus Expertbook P3 (dual memory) CPU Row 0 - Cell 1 AMD Ryzen AI 7 350 AMD Ryzen AI 7 350 Cores/Threads Row 1 - Cell 1 8C 16T 8C 16T TPD Row 2 - Cell 1 15-54W (28W) 15-54W (28W) RAM Row 3 - Cell 1 32GB DDR5-5600 (1x32GB) 32GB DDR5-5600 (2x16GB) SSD Row 4 - Cell 1 1TB Micron 2500 MTFDKBA1T0QGN 1TB Micron 2500 MTFDKBA1T0QGN Graphics Row 5 - Cell 1 AMD Radeon 860M AMD Radeon 860M NPU Row 6 - Cell 1 AMD Ryzen AI (50 TOPS) AMD Ryzen AI (50 TOPS) 3DMark WildLife 10,234 15,582 Row 8 - Cell 0 FireStrike 4061 6107 Row 9 - Cell 0 TimeSpy 1959 2882 Row 10 - Cell 0 Steel Nomad.L 1534 2262 CineBench24 Single 117 116 Row 12 - Cell 0 Multi 761 909 Row 13 - Cell 0 Ratio 6.91 7.83 GeekBench 6 Single 2879 2886 Row 15 - Cell 0 Multi 11529 13560 Row 16 - Cell 0 OpenCL 22785 24370 Row 17 - Cell 0 Vulkan 26293 33104 CrystalDIsk Read MB/s 6986 7006 Row 19 - Cell 0 Write MB/s 6104 6111 PCMark 10 Office 7459 7763 Row 21 - Cell 0 Battery 18h 31m 18h 17m Battery Whr 70 70 WEI Score 8.1 8.1\n\nUsually, I like to compare one laptop with another to show how making one choice over another has implications for performance.\n\nBizarrely, in this performance analysis, I’ve compared the Asus Expertbook P3 with itself, with one seemingly small difference that ends up having huge implications.\n\nWhen I received this laptop, I was in the middle of reviewing a machine with the PRO version of the same CPU, and therefore had benchmark data to explore that minor upgrade.\n\nBut it soon became clear that the P3 performed badly, and the difference was so much that something was clearly wrong. Days later, I eventually discovered what was holding the P3 back: the inclusion of a single DDR5 module in the review machine, and not two modules.\n\nIt’s worth noting that DDR5 was sold to the computer industry as being ideal because it has dual channels in a single module, and therefore, single memory modules were fine.\n\nAnd they are, but modern architectures like the one in this laptop can run four memory channels, two on each module, and that increases the amount of bandwidth significantly.\n\nBecause this system uses main memory not only for the CPU, but also for the GPU, the difference, as demonstrated by these results, is like night and day.\n\nWhat I did was remove the single Hynix module and replaced it with two Crucial SODIMMs of roughly the specification that I borrowed from a GMKtec mini PC. And, magically, some test results improved by 50%, disturbingly.\n\nI went back to Asus, keen to discover why a respected brand would do something like this, and their explanation revealed some bent logic that I’ve seen from other brands.\n\nIn the product specifications, there are four possible memory configurations that Asus offers, including two single configurations of 16GB and 32GB, and two dual configurations of 32GB (2x 16GB) and 64GB (2x 32GB).\n\nAccording to Asus, the single module versions are for those who want to upgrade, and they will have a slot free to put that extra module. That approach makes almost no sense. Because the Hynix module in there is an OEM part, and it’s unlikely that they will match that exact part, and without the upgrade, the machine will be massively underperforming.\n\nIf you order multiples of these machines, the best course of action would be to strip half the machines of their modules to upgrade the rest, and get matching pairs for those machines.\n\nBut the best solution is not to buy any of the single-module machines in the first place. If you want 32GB of RAM then get the dual 16GB machine, not the single 32GB one.\n\nWhen you do have dual modules, this machine performs well, which is why it got the score I gave it, and it’s also excellent on power efficiency. But beware system makers providing options that significantly degrade the performance of their hardware, which are marketed as being for your convenience.\n\n(Image credit: Mark Pickavance)\n\nPerformance: 4 / 5\n\nAsus ExpertBook P3: Final verdict\n\nOn the face of it, a great laptop, until I realised that Asus had flushed 50% of its performance away by making a silly decision on memory modules. That point aside, this is a nice system with more ports than many laptops get these days, and an excellent Ryzen platform.\n\nThere are a few areas where this machine could be improved, opening up the option for a P3 Plus model with a 2.5GbE LAN port and the USB4 ports that the processor natively supports.\n\nBut for the relatively low asking price, for the majority of office users, this machine is excellent, if you don’t make the horrible mistake of buying one with a single memory module.\n\nShould you buy a Asus ExpertBook P3?\n\nSwipe to scroll horizontally Value A powerful system for a modest price 4 / 5 Design Thin and lightweight, with plenty of ports 4 / 5 Hardware AI 300 series CPU with NPU power for local models 4 / 5 Performance Great performance, once you have two memory modules 4 / 5 Overall If you avoid the memory pitfall, this is a decent system 4 / 5\n\nBuy it if...\n\nYou are on a tight budget\n\nFor the money, this is a decent laptop with plenty of nice features and a good hardware platform. Cheaper machines than this will be rehashing old processors and memory technologies.\n\nYou like upgrades\n\nLots of bits on this machine can easily be upgraded, including the memory and storage. However, it isn't the easiest laptop to remove the underside.\n\nDon't buy it if...\n\nYou need Thunderbolt or USB4\n\nThe best USB port on this machine is only USB 3.2 Gen 2, and while it can transfer a file at 1,000MB/s, it pales in comparison to USB4 or Thunderbolt performance. If you want Thunderbolt, then you will need something better than this.\n\nYou need more than 3TB\n\nThe maximum SSD sizes on this system are one 2TB and a 1TB, though you might be able to get a 4TB module to work in the one 2280 M.2 slot. But without a heatsink, you need to make sure it doesn't overheat.\n\nIf you want more storage, find a machine with two 2280 slots, and not this one with a 2280 and a 2230.\n\nFor more professional devices, we reviewed the best laptops for work and gaming and the best laptops for working from home.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/asus-expertbook-p3-business-laptop-review",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Intel's crown as the best choice for gamers may be slipping as pros complain about its performance vs. AMD",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/intels-crown-slipping-pros-complain-performance-vs-amd/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Exit, rebuild, repeat — Intel’s new era begins without Holthaus",
      "content": "The Intel logo is displayed during the 2018 CeBIT technology trade fair\n\nIntel has announced major leadership changes as CEO Lip-Bu Tan pushes ahead with efforts to transform the struggling chipmaker. The most notable departure is Michelle Johnston Holthaus, whose career at Intel has spanned more than 30 years.\n\nThe shake-up comes just as Intel admitted its Arrow Lake processors failed to live up to expectations. All eyes are now on the upcoming Nova Lake architecture, which it hopes will restore competitiveness against AMD. This rivalry continues to gain ground with users and across the industry.\n\nHolthaus’s departure after 30 years at Intel\n\nHolthaus joined Intel in 1996, a year before I was even born, which makes me feel old. Anyway, starting as a program manager in the OEM Platform Solutions Division. Holthaus went from there, and she moved steadily through leadership roles in sales, marketing, and product development.\n\nBetween 2013 and 2017, she managed Intel’s partnership with Microsoft, coordinating sales, product roadmaps, and technical support. This role kept Intel’s CPUs and Microsoft’s platforms closely aligned across Windows, Surface, Xbox, and cloud services.\n\nIn late 2024, Holthaus stepped into the spotlight as interim co-CEO alongside CFO David Zinsner following Pat Gelsinger’s departure. She was later appointed CEO of Intel Products but held the position for only 9 months before resigning. Intel said the decision was due to “a material reduction in her duties, responsibilities, salary, and target annual bonus,” which matched the “Good Reason” clause in her contract.\n\nThanks to this clause, Holthaus will receive full severance benefits and remain with Intel in a non-executive advisory role until March 1, 2026.\n\nNew leadership team takes shape\n\nKevork Kechichian has joined Intel from Arm as Executive Vice President and General Manager of the Data Center Group. He brings more than 30 years of semiconductor experience and previously managed Snapdragon SoC teams at Qualcomm.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAnother addition is Jim Johnson, a 40-year Intel veteran, who has been confirmed as Senior Vice President and General Manager of the Client Computing Group. Over his long career, Johnson has worked across Intel’s Technology and Manufacturing Group, Networking and Communications, and global operations.\n\nIntel has also formed a new division in 2025, the Central Engineering Group, which will be led by Srinivasan “Srini” Iyengar. This team will focus on custom silicon design for external customers. Iyengar, who spent over 25 years at Cadence Design Systems, brings deep expertise in silicon engineering and design automation.\n\nLastly, Dr. Naga Chandrasekaran’s responsibilities have been expanded to include Foundry Services, alongside his existing role as Executive Vice President and Chief Technology and Operations Officer of Intel Foundry. Before joining Intel, he spent 16 years at Micron, where he led advanced memory technology development.\n\nTogether, these appointments show Tan’s push to blend long-time Intel leaders with external expertise from companies like Arm, Cadence, and Micron. It may take time before the results are clear, but the changes highlight Intel’s willingness to act boldly as it struggles to compete.\n\nTan’s strategy and vision for Intel’s future\n\nLip-Bu Tan, chief executive officer of Intel Corp (Image credit: Getty Images | Bloomberg)\n\nTan is aiming to cut back on bureaucracy by eliminating redundant management layers and creating a flatter, more focused structure. The goal is to speed up decision-making and bring more direct accountability. A clear example is that Holthaus’s position will not be replaced, with key groups now reporting directly to Lip-Bu Tan.\n\nHe is also pivoting Intel toward custom silicon and foundry services, areas where the company hopes to become a leader. The newly formed Central Engineering Group is central to this effort, with a focus on building chips for external customers instead of just Intel’s own products.\n\nOf course, no turnaround story in 2025 would be complete without AI, and Tan’s plans touch on that too. Still, the real test will be whether this strategy helps Intel compete with rivals like AMD. Rebuilding trust with users and partners will take time, but Nova Lake may give us the first glimpse of what Tan’s reshaped Intel can deliver.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/intel/exit-rebuild-repeat-intels-new-era-begins-without-holthaus",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Why I stopped overclocking my CPU after years of enthusiasm",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/cpu-overclocking-is-mostly-dead/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Will Broadcom Chips End AMD Stock's AI Dreams?",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/09/will-broadcom-chips-end-amd-stocks-ai-dreams/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD's FSR 4 upscaling tech gives even more PC games a free image quality upgrade – but you still need a modern GPU",
      "content": "AMD's FSR 4 is now available in most FSR 3.1 and DX12 supported games\n\nThe new Adrenalin Software driver allows users to override FSR 3.1 with FSR 4\n\nIt only works in games that have a signed FSR 3.1 DLL\n\nWhile AMD fans await an eventual FSR 4 backport to older non-RDNA 4 graphics cards alongside updates to the upscaling technology that's exclusive to some of the best GPUs on the market, Team Red has at least made life easier for developers and gamers.\n\nAs reported by VideoCardz, AMD's latest driver 25.9.1 adds further FSR 4 support for most FSR 3.1 and DX12-supported games, which AMD says is now 'over 85 games'. RDNA 4 GPU owners simply need to enable FSR 4 on the AMD Adrenalin Software and toggle on FSR 3.1 in a supported game, allowing the driver to override FSR 3.1 with FSR 4.\n\nIt's worth noting that this is only possible in games that have a signed FSR 3.1 DLL, which means the override won't work via third-party integration. While FSR 4 still hasn't been backported to RDNA 3 and older GPUs, FSR 4's driver override should make things much easier if a backport does happen soon.\n\nTeam Red's recent FSR 4 open-source slip-up revealed that it was (and potentially still is) working on an FSR 4 backport to RDNA 3. And with the FSR 'Redstone' presentation set to reveal frame generation and image quality improvements, it may not be far-fetched to suggest that AMD may have another surprise announcement in store.\n\nAMD's fierce rival, Nvidia, has DLSS 4 available for all RTX GPUs; not only does it have the advantage of being widely available to more PC gamers, but the image quality is superior to FSR 4's, and there's nothing better than AMD's Redstone shortening the gap to Team Green's offering, while also allowing all (or at least most) Radeon GPU users to benefit from sharper images in games.\n\nAnalysis: FSR 4 on RDNA 3 and older GPUs should be AMD's number one priority\n\n(Image credit: AMD)\n\nWithout a doubt, Nvidia is still leading the GPU market. That's unsurprising, especially since the RTX 5000 series GPUs are gradually plummeting back to their launch prices – and Team Green is rumored to be launching Super series GPUs this fall.\n\nWith this in mind, it's time for AMD to at least provide its latest upscaling tech to RDNA 3 GPUs before Nvidia bridges the gap further.\n\nGet daily insight, inspiration and deals in your inbox Sign up for breaking news, reviews, opinion, top tech deals, and more. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAgain, Nvidia already has DLSS 4 available on all RTX GPUs, except for Multi Frame Generation (exclusive to RTX 5000 series) and Frame Generation (starting from RTX 4000 series). DLSS 4 has shown how vital it is for upscaling tech to have sharper super-resolution image quality, and it shines bright even in DLSS performance, which benefits PC gamers with low-end hardware.\n\nTeam Red's FSR 4 has a similar effect with better image quality across its upscaling modes, and while it certainly doesn't match up to DLSS 4, it beats both FSR 3 and DLSS 3. As a handheld PC gamer, FSR 4 would do wonders at providing better performance via aggressive upscaling, without too much of a heavy sacrifice on image quality, like FSR 3 has.\n\nIt's the ideal time for AMD to get this going, as it would add to the firepower it needs to fully compete with its GPU rival.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/computing/gpu/amds-fsr-4-upscaling-tech-gives-even-more-pc-games-a-free-image-quality-upgrade-but-you-still-need-a-modern-gpu",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Qualcomm Snapdragon X Elite Linux Performance Improving But Short Of AMD Ryzen & Intel Core Ultra",
      "content": "Back in May we provided an initial look at the Qualcomm Snapdragon X Elite laptop performance on Ubuntu Linux with the upstream support for the Qualcomm Snapdragon X1E maturing, more laptops becoming supported, and the Ubuntu X1E \"Concept\" ISOs enhancing the end-user experience. The performance was okay but short of expectations. Months later we are revisiting the Qualcomm Snapdragon X Elite Linux performance on the newest Ubuntu Concept ISOs and newer firmware that is providing a much better experience albeit still not as competitive as the newest AMD Ryzen AI 300 series and Intel Core Ultra laptops under Linux.\n\nSince the May testing, the Qualcomm Snapdragon X Elite Linux testing was experiencing a hiatus... Newer Ubuntu X1E Concept ISOs were failing to properly work on the Acer Swift AI 14 laptop that I had purchased to carry out these Linux tests. Repeatedly the new refreshed media for several months failed to boot properly on the laptop due to Device Tree issues and/or other problems over time. Fortunately, the newest Ubuntu X1E Concept ISOs from late August fixed those problems. So I have been able to carry out clean, working installs of Ubuntu again on this Acer Swift 14 AI laptop powered by an X1 Elite SoC.\n\nThe \"plucky-desktop-arm64+x1e-20250827.iso\" as the newest as of testing now has everything in place so the laptop I have been using for testing works out. Though caveats still apply like you will want to keep around the Microsoft Windows 11 on ARM installation in order to run qcom-firmware-extract for extracting the necessary firmware from the Windows partitions. Most Snapdragon X laptops still do not have any firmware permitted for redistribution in upstream linux-firmware.git and thus the workaround of needing to fetch it from a Windows partition is needed for getting features like GPU acceleration and other functionality working.\n\nKeeping the Windows 11 installation is also important for easily applying system firmware updates to the device itself. While working through these Ubuntu Linux woes on the Acer Swift 14 AI, a system firmware update came down and was applied that ended up being very important for multi-core performance as I'll be showing in this article.\n\nIt's far from a pleasant out-of-the-box experience but at least an easier route than the likes of Apple Silicon on Linux.\n\nFor today's benchmarking is a look at how the Qualcomm Snapdragon X Elite performance has evolved since the tests earlier this year and then followed by a comparison of the Acer Swift 14 AI up against an assortment of other Intel Core and AMD Ryzen laptops tested over the summer, all on Ubuntu 25.04 and tested within the Phoronix lab.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/review/snapdragon-x1e-september",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "What I learned while optimizing my RAM timings for better PC performance",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/improve-your-ram-timings/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The XFX Radeon RX 7900 XT Graphics Card Drops to $630: This Is the Least Expensive 4K-Capable GPU",
      "content": "If you've just upgraded to a new 4K gaming monitor and now you're looking for a reasonably priced GPU that can comfortably run games off it, then check out this deal. Amazon is offering the XFX AMD Radeon RX 7900 XT 20GB graphics card for just $630.63. This is the lowest price I've ever seen for an RX 7900 XT GPU, and that's saying something because nearly all video cards nowadays are higher than their original launch price. The RX 7900 XT is a generation old, but it's still an excellent 4K GPU that approaches the performance of the GeForce RTX 5070 Ti and Radeon 9070 XT.\n\nThe Radeon RX 7900 XT was released back in 2022, but its still a relevant card today, able to play pretty much any game at 4K with consistent framerates of 60fps and beyond. Compared to current generation cards, it's roughly 5%-10% behind the Nvidia GeForce RTX 5070 Ti and and the AMD Radeon 9070 XT in 4K rasterized (non ray-traced) performance. It's also 10%-20% less expensive, making it a very attractive alternative for those of you who are on a budget. The RX 7900 XT also comes equipped with 20GB VRAM, which is more than the 5070 T iand 9070 XT, which come with 16GB. The extra VRAM allows it to scale well in high-resolution gaming and it's also a good card for AI use.\n\nIf You Need Ray Tracing, Stick with NVIDIA\n\nAMD Radeon cards are outstanding alternatives to the NVIDIA GeForce cards. For gamers who want to maximize their performance for their dollar, AMD GPUs are the way to go. However, if you're set on playing 4K games with ray tracing enabled, then you'll want to stick with NVIDIA. That's because the GeForce cards perform better than their Radeon counterparts when it comes to ray tracing. Ray tracing is a form of rendering that allows for more realstic lighting effects. It makes light sources and shadows look better, but at the steep cost of GPU resources.\n\nWhy Should You Trust IGN's Deals Team? IGN's deals team has a combined 30+ years of experience finding the best discounts in gaming, tech, and just about every other category. We don't try to trick our readers into buying things they don't need at prices that aren't worth buying something at. Our ultimate goal is to surface the best possible deals from brands we trust and our editorial team has personal experience with. You can check out our deals standards here for more information on our process, or keep up with the latest deals we find on IGN's Deals account on Twitter.\n\nEric Song is the IGN commerce manager in charge of finding the best gaming and tech deals every day. When Eric isn't hunting for deals for other people at work, he's hunting for deals for himself during his free time.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/xfx-radeon-rx-7900-xt-graphics-card-deal-best-4k-gpu-under-650",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "ACEMAGIC Kron Mini K1 review – Quite a capable mini PC",
      "content": "MetryGrow 48W LED Plant Grow Light review – makes sure your indoor plants get what they need",
      "source": "The Gadgeteer",
      "url": "https://the-gadgeteer.com/2025/09/09/acemagic-kron-mini-k1-review-quite-a-capable-mini-pc/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "This budget-friendly Ryzen mini PC with 16GB RAM is an extra 29% off",
      "content": "Finding the best computer for your office isn’t always easy, and who wants to waste precious hours (or days) researching a bunch of models to find the ones that tick the right boxes at the right budgets? You might just be better off snagging this Bosgame E2 mini PC, which is a great daily driver PC for home offices that balances performance with price.\n\nRight now, the Bosgame E2 is only $169.99 on Amazon (was $239.99), a significant 29% discount that brings it down to almost impulse-buy levels of affordability. Is it going to be a blazing-fast machine that blows you away? Of course not. But similar machines usually cost double, so if you’re hunting for a solid deal, this is one worth jumping on.\n\nThe Bosgame E2 mini PC comes with an AMD Ryzen 5 3550H processor, which may be a few years old but is still perfectly capable of handling modern apps and day-to-day tasks. It also comes with 16GB of RAM and a 512GB SSD, which is adequate for running Windows 11 without slowing to an unbearable crawl. It even has some room for growth, with user-upgradeable memory (up to 32GB) and storage (up to 4TB).\n\nOne of the best things about this mini PC for productivity is that it supports triple 4K@60Hz monitors thanks to its dual HDMI ports plus USB-C video port. You also get three fast USB-A for data, a slower USB-A for peripherals, a 3.5mm audio jack, and a Gigabit Ethernet port. The cherry on top? It comes with a VESA plate so you can mount it to the back of any VESA-compatible monitor so it’s out of sight.\n\nThis is a super bargain for anyone who needs a decent home PC at a bottom-barrel price. Get the Bosgame E2 for just $169.99 while you can because this limited-time deal won’t last forever!\n\nSnag this budget-friendly Ryzen 5 mini PC with 16GB RAM for 29% off",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2902891/this-budget-friendly-ryzen-5-mini-pc-with-16gb-ram-is-an-extra-29-percent-off.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Legion Go 2’s pricing draws backlash, and Lenovo’s response falls flat",
      "content": "The Steam Deck starts at $400. That’s one of its most appealing aspects, even years after it launched. The new Lenovo Legion Go 2 starts at $1,050, and it goes up to $1,350 if you really want to max its specs. Perhaps that’s an unfair comparison, but it’s one that plenty of fans are making anyway… and Lenovo’s response to them isn’t helping.\n\n\n\nIn a recent interview at IFA 2025, PC Watch of Japan (via Windows Central) asked Lenovo executives about the high pricing. It starts at €1,000, “which is close to the price of a laptop,” according to a Google translation.\n\n“The Legion Go 2 is expensive because of the high-performance processor, OLED display, detachable controllers, and ergonomic design that make it so powerful,” replied a representative. “Therefore, the Legion Go 2 targets enthusiast gamers who are willing to invest in their hobbies. They value customizing their own hardware and building their own setups, and they choose such hardware even if it is expensive.”\n\nThe representative offered up the Legion Go S as “a more affordable option.” That’s a handheld that starts at $600 for the SteamOS version and goes up to $830 for the most powerful hardware. “Affordable” is pulling a lot of weight here, in a form factor that’s still fairly limited even compared to a desktop PC at the same price.\n\nDirect sales comparisons are hard to make, considering the paucity of data available. But it seems like the Steam Deck is still outselling its newer competition by a large factor, even given its three-year-old hardware. SteamOS—which is better than Windows 11 for gaming in almost every way—is certainly part of that success.\n\nBut I can’t help but notice that you can get a top-of-the-line Steam Deck OLED for just a little more than Lenovo’s “more affordable option.” It doesn’t help that in the US, consumers will be paying for the current administration’s import taxes on basically everything, too.\n\nLenovo seems to be betting that gamers love the handheld PC form factor so much that they’re willing to pay double or even triple for hardware that’s more powerful and flexible. I’m sure some are, but when I look at those price tags, I just see diminishing returns. A Legion Go 2 with an AMD Z2 Extreme processor and 64GB of shared memory can do more than a base model Steam Deck… But three times more? Nah.\n\nPerhaps a revitalized Windows 11—with a refreshed interface that’s set to debut on the Asus ROG Xbox Ally—could shake up this equation. (Asus is still afraid to put a price on that device and we only have a month until its planned release.) But even if it does, it won’t be until sometime next year that the new UI comes to other devices like the Legion Go 2. Even if I were tempted to buy a handheld PC with a four-figure price tag, I’d want to wait until that option became available.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2903198/legion-go-2s-pricing-draws-backlash-and-lenovos-response-falls-flat.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "XFX says its 'V3' Radeon RX 9060 XT GPUs with Samsung GDDR6 run much cooler and quieter than previous models with SK Hynix memory",
      "content": "Having the most powerful and fastest hardware is often the goal of many PC builders, so we are often left comparing things on pure benchmarking and performance. So when AMD swapped from using SK Hynix to Samsung GDDR6 memory in its new Radeon RX 9060 XT GPUs, gamers were quick to jump to performance comparisons between them.\n\nWhat they found was a drop when moving over to the new Samsung memory, and gamers were quick to condemn the change. Like our reviewer of the RX 9060 XT XFX Swift GPU, many have been pleased by the performance from the budget friendly offering. It seems it might have been a bit too quick, as new comparisons spotted by VideoCardz are showing ways the Samsung GDDR6 may actually be more beneficial, if a little less powerful than the SK Hynix offering.\n\nAMD partner XFX posted comparisons to Bilibili, a Chinese social blog site that often delves into PC gaming hardware critique. They tell the same story of less powerful GDDR6, but with a huge boon to cooling and potentially power consumption.\n\nAccording to these tests the Samsung memory garnered temperatures 10°C lower than its SK Hynix counterpart, allowing for an almost 400 rpm drop in fan speeds. This means the Samsung components are significantly cooler than the previous ones, and as an added bonus they're quieter and less demanding on your fans, too. This is on top of a 20 W lower power draw over the SK Hynix memory.\n\nThis drop may not seem like a big deal, especially for those who like to go all in on power for their rigs. But power isn't the whole story when it comes to building a capable gaming machine, you still have to be able to power and run it, and temperatures can be a huge mitigating factor.\n\nKeeping things cool is an integral part of any good rig, and it's not always easy especially in warmer climates. As an Australian I've run into difficulties keeping rigs cool enough to function over hot summers and have often had to forgo power for lower temperatures. Choosing parts that can help you maintain lower temperatures even if it's at the cost of some beef is often a really smart move in building a gaming PC.\n\nSK Hynix and Samsung are some of the biggest players investing billions in developing memory, not only for GPUs but also AI computing. Both have also been hit with reversals against using US tech in their China-based facilities. With a seemingly even playing field, seeing such a huge difference in these results is a little surprising.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThese results are almost certainly biased, but this could mean the revised 9060's are a better choice for many looking to upgrade. According to XFX the Samsung GDDR6 units can be identified by a \"V3\" moniker and are already available in China. It'll be interesting to see what further testing shows when it comes to the difference between these GPU variants.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/graphics-cards/xfx-says-its-v3-radeon-rx-9060-xt-gpus-with-samsung-gddr6-run-much-cooler-and-quieter-than-previous-models-with-sk-hynix-memory/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Chip, cloud, and AI firms unite to break Nvidia's stranglehold",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250909PD224/amd-nvidia-cloud-ai-launch-openai.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD Claims Arm ISA Doesn’t Offer Efficiency Advantage Over x86",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/amd-claims-arm-isa-doesnt-offer-efficiency-advantage-over-x86/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The UAE Showcases Its Abilities In AI Reasoning With K2 Think Model",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/patrickmoorhead/2025/09/09/the-uae-showcases-its-abilities-in-ai-reasoning-with-k2-think-model/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 \"Battlemage\" Nears Launch as Intel Prepares Packaging",
      "content": "Intel plans to complete its Arc \"Battlemage\" lineup with the highest-performing B770 SKU. Thanks to @Haze2K1 on X, we found shipping manifests dated June 11, 2025, which list BMG-G31 GPU dies packed in boxes with dimensions matching those used before the Arc B580 launch. Last time with B580, the launch happened 2.5 months after these shipping manifests appeared. The current rumor mill suggests that the card will utilize 32 Xe2 cores with 16 GB of memory on a 256-bit bus, providing it with a clear capacity edge over many 8 GB rivals from AMD and NVIDIA, like the RTX 5060 Ti and RX 9060. The BMG-G31 die is bigger than the BMG-G21 used in the B580, B570, and Arc Pro parts, which explains the larger crates. Extra silicon could enable higher clocks, stronger ray tracing, and a wider memory interface, though thermal management and power draw will matter. Early samples and firmware checks will set the final timing and availability soon.Timing will determine how much impact the Arc B770 can have, because AMD and NVIDIA already control much of the upper mid-range and high-end segments. NVIDIA \"SUPER\" refreshes of the current \"Blackwell\" only raise the pressure on Intel to be both performance competitive and well priced. Battlemage has already shifted pricing expectations in the market before, compelling rivals to rethink memory configurations and price points. Intel has also shown steady improvement in its driver updates and software support, which has narrowed historical gaps in user experience. Rumors pointing to a Q4 2025 debut would put the card into the usual holiday buying window, but to convert gamer's interest into real market share, Intel will need an aggressive pricing strategy and solid supply.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340802/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Former MS engineer Dave Plummer admits he accidentally coded Pinball to run 'at like, 5,000 frames per second' on Windows NT",
      "content": "I'm not sure why I played so much Pinball on my Windows machine as a child. Nor am I sure why it was given so many different names, like Space Cadet 3D Pinball, 3D Pinball for Windows, Microsoft 3D Pinball, etc. What I do know, however, is it ran great on my old Windows NT 4.0 beige box, and now I've learned exactly why—the engineer who ported it over accidentally built a surprisingly resource-heavy game engine around it.\n\nEnter Dave Plummer, an ex-Microsoft engineer whose other Windows contributions include Task Manager, native Zip file support, and Media Center, to name just a few (via The Register). Speaking on his YouTube channel, Dave's Attic, Plummer revealed that when he ported the game to Windows NT from Windows 95, he wrote a whole new game engine around the original logic in order to handle the video rendering and sound.\n\n\"My game engine had a bug, in that it would draw frames as fast as it could\" said Plummer. At the time, the game was being coded on a MIPS R4000 processor running at a mighty 200 MHz, which resulted in the game running at 60-90 fps, a speed Plummer judged as \"plenty, for a game like that.\"\n\n\"Fast forward a couple of years later, somebody notices that on multi-core machines, it's using an entire core to play Pinball at all times,\" he laughs. \"It was still drawing as fast as it could, but it was now drawing at like, 5,000 frames per second, because machines were much much faster than they used to be.\"\n\nThe bug was fixed by another ex-Microsoft engineer, Raymond Chen. Speaking on Plummer's other YouTube channel, Dave's Garage, Chen fondly remembers adding a frame rate limiter, thereby reigning the game in to a 100 fps maximum. \"My proudest moment in Windows development,\" Chen says, \"was I fixed Pinball so you could kick off a build and play Pinball at the same time.\"\n\n(Image credit: Microsoft)\n\nPlummer categorises the mistake as the worst Windows bug he ever shipped, and although he laughs about it now, it seems Microsoft culture at the time was particularly adverse to brushing off mistakes: \"If you had a bug that actually made it into the product and required work in a Service Pack, that was never a laughing matter. That was kind of a shameful thing.\"\n\nStill, no real harm done. I'd imagine the rise of multi-core processors required all kinds of fixes to integrate within existing codebases successfully, and it certainly seems like Plummer and his ex-colleagues remember the bug fondly.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAnd it must be said, part of me wants to run that early build on a modern multi-core monster like the AMD Ryzen 9 9950X3D, given that NT seems to play remarkably well with modern hardware. I'd like to imagine that the frame rate would break world records, although I've got a funny feeling I'd get that iconic Windows NT 4.0 error sound instead. Ah, the error messages of my youth. Perhaps it's time to boot Pinball up once more for a game or three.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/software/windows/former-ms-engineer-dave-plummer-admits-he-accidentally-coded-pinball-to-run-at-like-5-000-frames-per-second-on-windows-nt/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Byte Type: Supporting Raw Data Copies in the LLVM IR",
      "content": "GSoC 2025 - Byte Type: Supporting Raw Data Copies in the LLVM IR\n\nBy Pedro Lobo\n\n\n\n#GSoC , #clang , #optimizations , #IR\n\n22 minute read\n\nThis summer I participated in GSoC under the LLVM Compiler Infrastructure. The goal of the project was to add a new byte type to the LLVM IR, capable of representing raw memory values. This new addition enables the native implementation of memory-related intrinsics in the IR, including memcpy , memmove and memcmp , fixes existing unsound transformations and enables new optimizations, all with a minimal performance impact.\n\nBackground\n\nOne of LLVM’s longstanding problems is the absence of a type capable of representing raw memory values. Currently, memory loads of raw bytes are performed through an appropriately sized integer type. However, integers are incapable of representing an arbitrary memory value. Firstly, they do not retain pointer provenance information, rendering them unable to fully specify the value of a pointer. Secondly, loading memory values containing poison bits through an integer type taints the loaded value, as integer values are either poison or have a fully-defined value, with no way to represent individual poison bits.\n\nSource languages such as C and C++ provide proper types to inspect and manipulate raw memory. These include char , signed char and unsigned char . C++17 introduced the std::byte type, which offers similar raw memory access capabilities, but does not support arithmetic operations. Currently, Clang lowers these types to the i8 integer type, which does not accurately model their raw memory access semantics, motivating miscompilations such as the one reported in bug report 37469.\n\nThe absence of a similar type in the LLVM IR hinders the implementation of memory-related intrinsics such as memcpy , memmove and memcmp , and introduces additional friction when loading and converting memory values to other types, leading to implicit conversions that are hard to identify and reason about. The two core problems stemming from the absence of a proper type to access and manipulate raw memory, directly addressed by the byte type and explored throughout the remainder of this section, are summarized as follows:\n\nIntegers do not track provenance, rendering them incapable of representing a pointer. Loads through integer types spread poison values, which taints the load result if the loaded values contain at least one poison bit (as occurs with padded values).\n\nPointer Provenance\n\nAccording to the LLVM Language Reference, pointers track provenance, which is the ability to perform memory accesses through the pointer, in the sense of the pointer aliasing rules. The main goal of tracking pointer provenance is to simplify alias analysis, yielding more precise results, which enables high-level optimizations.\n\nIntegers, unlike pointers, do not capture provenance information, being solely characterized by their numerical value. Therefore, loading a pointer through an integer type discards the pointer’s provenance. This is problematic as such loads can cause pointer escapes that go unnoticed by alias analysis. Once alias analysis is compromised, simple optimizations that rely on the absence of aliasing become invalid, compromising the correctness of the whole compilation process.\n\nCurrently, Alive2 defines the result of loading a pointer value through an integer type as poison . This implies that loads through integer types fail to accurately recreate the original memory value, hindering pointer copies via integer types. In the following example, storing a pointer to memory and loading it through the i64 type yields poison , invalidating the transformation.\n\ndefine ptr @src( ptr %ptr, ptr %v) { store ptr %v, ptr %ptr %l = load ptr , ptr %ptr ret ptr %l } define ptr @tgt( ptr %ptr, ptr %v) { store ptr %v, ptr %ptr %l = load i64 , ptr %ptr ; poison %c = inttoptr i64 %l to ptr ; poison ret ptr %c ; poison }\n\nUndefined Behavior\n\nLLVM’s poison value is used to represent unspecified values, such as padding bits. Loading such memory values through an integer type propagates poison values, as integer types are either poison or have a fully-defined value, not providing enough granularity to represent individual poison bits. This hinders the copy of padded values.\n\nMoreover, this lack of granularity can lead to subtle issues that are often overlooked. The LLVM Language Reference defines the bitcast instruction as a no-op cast because no bits change with this conversion. Nonetheless, while scalar types are either poison or have a fully-defined value, vector types in LLVM track poison values on a per-lane basis. This introduces potential pitfalls when casting vector types to non-vector types, as the cast operation can inadvertently taint non- poison lanes. In the following example, considering the first lane of %v to be poison , the result of casting the vector to an i64 value is poison , regardless of the value of the second lane.\n\ndefine i64 @ub( ptr %ptr) { %v = load < 2 x i32 >, ptr %ptr ; <i32 poison, i32 42> %c = bitcast < 2 x i32 > %v to i64 ; i64 poison ret i64 %c }\n\nAlthough covered by the Language Reference (\"the [bitcast] conversion is done as if the value had been stored to memory and read back as [the destination type]\"), this duality in the value representation between vector and scalar types integer constitutes a corner case that is not widely contemplated and often unnecessarily introduces undefined behavior.\n\nImplementing the Byte Type\n\nBack in 2021, a GSoC project with a similar goal, produced a working prototype of the byte type. This prototype introduced the byte type to the IR, lowered C and C++’s raw memory access types to the byte type and implemented some optimizations over the new type.\n\nThe current project began by porting these patches to the latest version of LLVM, adapting the code to support the newly introduced opaque pointers. As the work progressed and new challenges emerged, the original proposal was iteratively refined. The implementation of the byte type in LLVM and Alive2 can be found here and here, respectively.\n\nByte Type\n\nThe byte type is a first-class single-value type, with the same size and alignment as the equivalently sized integer type. Memory loads through the byte type yield the value’s raw representation, without introducing any implicit casts. This allows the byte type to represent both pointer and non-pointer values.\n\nAdditionally, the byte type is equipped with the necessary granularity to represent poison values at the bit-level, such that loads of padded values through the byte type do not taint the loaded value. As a consequence, a bitcast between vector and scalar byte types preserves the raw byte value. In the following example, a poison lane does not taint the cast result, unlike with equivalently sized integer types.\n\ndefine b 64 @f( ptr %ptr) { %v = load < 2 x b 32 >, ptr %ptr %c = bitcast < 2 x b 32 > %v to b 64 ret b 64 %c }\n\nThese two properties of the byte type directly addressed the aforementioned problems, enabling the implementation of a user-defined memcpy in the IR, as shown in the following example. In a similar manner, a native implementation of memmove can be achieved.\n\ndefine ptr @my_memcpy( ptr %dst, ptr %src, i64 %n) { entry: br label %for.cond for.cond: %i = phi i64 [ 0 , %entry ], [ %inc, %for.body ] %cmp = icmp ult i64 %i, %n br i1 %cmp, label %for.body, label %for.end for.body: %arrayidx = getelementptr inbounds b 8 , ptr %src, i64 %i %byte = load b 8 , ptr %arrayidx %arrayidx1 = getelementptr inbounds b 8 , ptr %dst, i64 %i store b 8 %byte, ptr %arrayidx1 %inc = add i64 %i, 1 br label %for.cond for.end: ret ptr %dst }\n\nThe newly implemented type also fixes existing optimizations. Previously, InstCombine lowered small calls to memcpy and memmove into integer load/store pairs. Due to the aforementioned reasons, this lowering is unsound. By using byte load/store pairs instead, the transformation, as shown in the following example, is now valid.\n\ndefine void @my_memcpy( ptr %dst, ptr %src) { call void @llvm.memcpy( ptr %dst, ptr %src, i64 8 ) ret void } define void @my_memmove( ptr %dst, ptr %src) { call void @llvm.memmove( ptr %dst, ptr %src, i64 8 ) ret void } define void @my_memcpy( ptr %dst, ptr %src) { %l = load b 64 , ptr %src store b 64 %l, ptr %dst ret void } define void @my_memmove( ptr %d, ptr %s) { %l = load b 64 , ptr %s store b 64 %l, ptr %d ret void }\n\nSROA performs a similar transformation, lowering memcpy calls to integer load/store pairs. Similarly, this optimization pass was changed to use byte load/store pairs, as depicted in the following example.\n\ndefine void @src( ptr %a, ptr %b) { %mem = alloca i8 call void @llvm.memcpy( ptr %mem, ptr %a, i32 1 ) call void @llvm.memcpy( ptr %a, ptr %mem, i32 1 ) ret void } define void @tgt( ptr %a, ptr %b) { %mem.copyload = load b 8 , ptr %a store b 8 %mem.copyload, ptr %a ret void }\n\nBytecast Instruction\n\nByte values can be reinterpreted as values of other primitive types. This is achieved through the bytecast instruction. This cast instruction comes in two flavors, either allowing or disallowing type punning. Considering that a byte might hold a pointer or a non-pointer value, the bytecast follows the following semantics:\n\nA vanilla bytecast , distinguished by the absence of the exact flag, is used to cast a byte to any other primitive type, allowing type punning. More precisely, If the type of the value held by the byte matches the destination type of the cast, it is a no-op. Otherwise, the cast operand undergoes a conversion to the destination type, converting pointers to non-pointer values and vice-versa, respectively wrapping a ptrtoint or inttoptr cast.\n\nA bytecast with the exact flag succeeds if both the type of the value held by the byte and the destination type are either both pointer or non-pointer types. More specifically, If the type of the value held by the byte matches the destination type of the cast, it is a no-op. Otherwise, the result is poison , preventing type punning between pointer and non-pointer values.\n\n\n\nThe exact version of the bytecast mimics the reinterpretation of a value, as if it had been stored in memory and loaded back through the cast destination type. This is aligned with the semantics adopted by the bitcast instruction, which “is done as if the value had been stored to memory and read back as [the destination type]”\", enabling store-to-load forwarding optimizations, such as the one depicted in the next example.\n\ndefine i8 @src( b 8 %x) { %a = alloca b 8 store b 8 %x, ptr %a %v = load i8 , ptr %a ret i8 %v } define i8 @tgt( b 8 %x) { %cast = bytecast exact b 8 %x to i8 ret i8 %cast }\n\nMemcmp Lowering\n\nThe standard version of the bytecast enables the implementation of memcmp in the IR. Currently, calls to memcmp of small sizes are lowered to integer loads, followed by a subtraction, comparing the two loaded values. Due to the aforementioned problems, this lowering is unsound. Loading the two memory values as bytes is insufficient as comparisons between bytes are undefined, as to avoid overloading the IR by supporting comparisons between pointers and provenance-unaware values. To that end, the version of the bytecast which performs type punning is used, forcefully converting possible pointer values into their integer representation. The two values, then converted to integers, can be compared as before. The following example depicts the previous and new lowerings of a memcmp of 1 byte.\n\ndefine i32 @before( ptr %p, ptr %q) { %lhsc = load i8 , ptr %p %lhsv = zext i8 %lhsc to i32 %rhsc = load i8 , ptr %q %rhsv = zext i8 %rhsc to i32 %chardiff = sub i32 %lhsv, %rhsv ret i32 %chardiff } define i32 @after( ptr %p, ptr %q) { %lhsb = load b 8 , ptr %p %lhsc = bytecast b 8 %lhsb to i8 %lhsv = zext i8 %lhsc to i32 %rhsb = load b 8 , ptr %q %rhsc = bytecast b 8 %rhsb to i8 %rhsv = zext i8 %rhsc to i32 %chardiff = sub i32 %lhsv, %rhsv ret i32 %chardiff }\n\nLoad Widening\n\nA common optimization performed by LLVM is to widen memory loads when lowering calls to memcmp . The previously proposed lowering falls short in the presence of such optimizations. Whilst using a larger byte type to load the memory value preserves its raw value, the bytecast to an integer type yields poison if any of the loaded bits are poison . This is problematic as the remaining bits added by the widened load could assume any value or even be uninitialized. As such, when performing load widening, the following lowering, depicted in the next example, is performed. The !uninit_is_nondet , proposed in the RFC proposing uninitialized memory loads to return poison , converts any poison bits to a non-deterministic value, preventing the bytecast to an integer type from yielding poison .\n\ndefine i32 @src( ptr %x, ptr %y) { %call = tail call i32 @memcmp( ptr %x, ptr %y, i64 2 ) ret i32 %call } define i32 @tgt( ptr %x, ptr %y) { %1 = load b 16 , ptr %x, !uninit_is_nondet %2 = load b 16 , ptr %y, !uninit_is_nondet %3 = bytecast b 16 %1 to i16 %4 = bytecast b 16 %2 to i16 %5 = call i16 @llvm.bswap.i16( i16 %3) %6 = call i16 @llvm.bswap.i16( i16 %4) %7 = zext i16 %5 to i32 %8 = zext i16 %6 to i32 %9 = sub i32 %7, %8 ret i32 %9 }\n\nCasts, Bitwise and Arithmetic Operations\n\nValues of other primitive types can be cast to the byte type using the bitcast instruction, as shown in the following example.\n\n%1 = bitcast i8 %val to b 8 %2 = bitcast i64 %val to b 64 %3 = bitcast ptr to b 64 ; assuming pointers to be 64 bits wide %4 = bitcast < 8 x i8 > to < 8 x b 8 >\n\nFurthermore, bytes can also be truncated, enabling store-to-load forwarding optimizations, such as the one presented in the next example. Performing an exact bytecast to i32 , followed by a trunc to i8 and a bitcast to b8 would be unsound, as if any of the unobserved bits of the byte value were poison , the bytecast would yield poison , invalidating the transformation.\n\ndefine b 8 @src( b 32 %x) { %a = alloca b 32 store b 32 %x, ptr %a %v = load b 8 , ptr %a ret b 8 %v } define b 8 @tgt( b 32 %x) { %trunc = trunc b 32 %x to b 8 ret b 8 %trunc }\n\nDue to the cumbersome semantics of performing arithmetic on provenance-aware values, arithmetic operations on the byte type are disallowed. Bitwise binary operations are also disallowed, with the exception of logical shift right. This instruction enables store-to-load forwarding optimization with offsets, such as the one performed in the following example. To rule out sub-byte accesses, its use is restricted to shift amounts that are multiples of 8.\n\ndefine i8 @src( b 32 %x) { %a = alloca b 32 %gep = getelementptr i8 , ptr %a, i64 2 store b 32 %x, ptr %a %v = load i8 , ptr %gep ret i8 %v } define i8 @tgt( b 32 %x) { %shift = lshr b 32 %x, 16 %trunc = trunc b 32 %shift to b 8 %cast = bytecast exact b 8 to i8 ret i8 %cast }\n\nValue Coercion Optimizations\n\nSome optimization passes perform transformations that are unsound under the premise that type punning is disallowed. Such an optimization pass is GVN, which performs value coercion in order to eliminate redundant loads. Currently, a class of optimization where a pointer load is coerced to a non-pointer value or a non-pointer load is coerced to a pointer value is reported as unsound by Alive2.\n\nThe following example illustrates one such optimization, in which GVN replaces the pointer load at %v3 by a phi node, merging the pointer load at %v2 with the coerced value at %1 , resulting from an inttoptr cast. If the value stored in memory is a pointer, the source function returns the pointer value, while, in the target function, the load at %v1 returns poison .\n\ndeclare void @use(...) readonly define ptr @src( ptr %p, i1 %cond) { br i1 %cond, label %bb1, label %bb2 bb1: %v1 = load i64 , ptr %p call void @use( i64 %v1) %1 = inttoptr i64 %v1 to ptr br label %merge bb2: %v2 = load ptr , ptr %p call void @use( ptr %v2) br label %merge merge: %v3 = load ptr , ptr %p ret ptr %v3 } define ptr @tgt( ptr %p, i1 %cond) { br i1 %cond, label %bb1, label %bb2 bb1: %v1 = load i64 , ptr %p call void @use( i64 %v1) %1 = inttoptr i64 %v1 to ptr br label %merge bb2: %v2 = load ptr , ptr %p call void @use( ptr %v2) br label %merge merge: %v3 = phi ptr [ %v2, %bb2 ], [ %1, %bb1 ] ret ptr %v3 }\n\nThe byte type can be leveraged to avoid the implicit type punning that hinders this kind of optimizations, as depicted in the following example. Since the byte type can represent both pointer and non-pointer values, the loads at %v1 and %v2 can instead be performed using the byte type. The bytecast instruction is then used to convert the byte into the desired type. As the load through the byte type accurately models the loaded value, avoiding implicit casts, the bytecast , yields the pointer stored in memory. This value can then be used to replace the load at %v3 .\n\ndeclare void @use(...) readonly define ptr @src( ptr %p, i1 %cond) { br i1 %cond, label %bb1, label %bb2 bb1: %v1 = load i64 , ptr %p call void @use( i64 %v1) %1 = inttoptr i64 %v1 to ptr br label %merge bb2: %v2 = load ptr , ptr %p call void @use( ptr %v2) br label %merge merge: %v3 = load ptr , ptr %p ret ptr %v3 } define ptr @tgt( ptr %p, i1 %cond) { %load = load b 64 , ptr %p br i1 %cond, label %bb1, label %bb2 bb1: %v1 = bytecast exact b 64 %load to i64 call void @use( i64 %v1) %1 = bytecast exact b 64 %load to ptr br label %merge bb2: %v2 = bytecast exact b 64 %load to ptr call void @use( ptr %v2) br label %merge merge: %v3 = phi ptr [ %v2, %bb2 ], [ %1, %bb1 ] ret ptr %v3 }\n\nOther Optimizations\n\nAdditional optimizations were also implemented. While these do not affect program correctness, they do contribute to performance improvements. Some of them include cast pair eliminations and combining of load and bytecast pairs with a single use, depicted in the following examples.\n\ndefine b 32 @src_float( b 32 %b) { %1 = bytecast exact b 32 %b to float %2 = bitcast float %1 to b 32 ret b 32 %2 } define i8 @src_int( i8 %i) { %b = bitcast i8 %i to b 8 %c = bytecast exact b 8 %1 to i8 ret i8 %c } define b 32 @tgt_float( b 32 %b) { ret b 32 %b } define i8 @tgt_int( i8 %i) { ret i8 %i }\n\ndefine i8 @src( ptr %p) { %b = load b 8 , ptr %p %c = bytecast exact b 8 %b to i8 ret i8 %c } define i8 @tgt( ptr %p) { %i = load i8 , ptr %p ret i8 %i }\n\nClang\n\nGiven the raw memory access capabilities of the byte type, Clang was altered to lower C and C++’s raw memory access types were lowered to the byte type. These include char , signed char , unsigned char and std::byte . The new lowerings are depicted in the next example.\n\nvoid foo ( unsigned char arg1, char arg2, signed char arg3, std :: byte arg4 );\n\nvoid @foo( b 8 zeroext %arg1, b 8 signext %arg2, b 8 signext %arg3, b 8 zeroext %arg4 ) ;\n\nAdditionally, code generation was updated to insert missing bytecast instructions where integer values were previously expected, such as in arithmetic and comparison operations involving character types. The next example depicts an example function in C, adding two char values, and the corresponding lowering to LLVM IR as performed by Clang.\n\nchar sum ( char a, char b) { return a + b; }\n\ndefine b 8 @sum( b 8 %a, b 8 %b) { %conv = bytecast exact b 8 %a to i8 %conv1 = sext i8 %conv to i32 %conv2 = bytecast exact b 8 %b to i8 %conv3 = sext i8 %conv2 to i32 %add = add nsw i32 %conv1, %conv3 %conv4 = trunc i32 %add to i8 %res = bitcast i8 %conv4 to b 8 ret b 8 %res }\n\nSummary\n\nIn summary, the byte type contributes with the following changes/additions to the IR:\n\nRaw memory representation: Optimization passes can use the byte type to represent raw memory values, avoiding the introduction of implicit casts and treating both pointer and non-pointer values uniformly.\n\nBit-level poison representation: The byte type provides the necessary granularity to represent individual poison bits, providing greater flexibility than integer types, which either have a fully-defined value or are tainted by poison bits.\n\nbitcast instruction: This instruction allows conversions from other primitive types to equivalently-sized byte types. Casts between vector and scalar byte types do not taint the cast result in the presence of poison lanes, as occurs with integer types.\n\nbytecast instruction: This instruction enables the conversion of byte values to other primitive types. The standard version of the cast performs type punning, reinterpreting pointers as integers and vice-versa. The exact flag disallows type punning by returning poison if the type of the value held by the byte does not match the cast destination type.\n\ntrunc and lshr instructions: The trunc and lshr instructions accept byte operands, behaving similarly to their integer counterparts. The latter only accepts shift amounts that are multiples of 8, ruling out sub-byte accesses.\n\nResults\n\nBenchmarks\n\nThe implementation was evaluated using the Phoronix Test Suite automated benchmarking tool, from which a set of 20 C/C++ applications, listed below, were selected.\n\nBenchmark Version LoC Description aircrack-ng 1.7 66,988 Tool suite to test WiFi/WLAN network security botan 2.17.3 147,832 C++ library for cryptographic operations compress-7zip 24.05 247,211 File archiving tool based on the 7-Zip format compress-pbzip2 1.1.13 10,187 Parallel implementation of bzip2 compress-zstd 1.5.4 90,489 Lossless compression tool using Zstandard draco 1.5.6 50,007 3D mesh and point cloud compressing library espeak 1.51 45,192 Compact open-source speech synthesizer ffmpeg 7.0 1,291,957 Audio and video processing framework fftw 3.3.10 264,128 Library for computing FFTs graphics-magick 1.3.43 267,450 Toolkit for image editing and conversion luajit 2.1-git 68,833 JIT-compiler of the Lua programming language ngspice 34 527,637 Open-source circuit simulator openssl 3.3 597,713 Implementation of SSL/TLS redis 7.0.4 178,014 In-memory data store rnnoise 0.2 146,693 Neural network for audio noise reduction scimark2 2.0 800 Scientific computing suite written in ANSI C sqlite-speedtest 3.30 250,607 Program for executing SQLite database tests stockfish 17 11,054 Advanced open-source chess engine tjbench 2.1.0 57,438 JPEG encoding and decoding tool z3 4.14.1 512,002 SMT solver and theorem prover\n\nAll programs were compiled with the -O3 pipeline on an AMD EPYC 9554P 64-Core CPU. In order to minimize result variance, turbo boost, hyperthreading, and ASLR were disabled, the performance governor was used, and core pinning was applied. The plots, depicted below, display the compile time, object size, peak memory usage (maximum redisent set size) and run-time performance differences between the implementation and upstream LLVM. The results reveal that the addition of the byte type had a minimal impact on all of the addressed performance metrics. Each result is averaged over three runs. The run-time results represent the average regression percentage across all tests of each benchmark.\n\n\n\n\n\nThe following plots show per-function assembly size distributions and differences, indicating that the addition of the byte type results in minor changes to the generated code, with the largest observed shift being approximately 5%. Each subplot includes the net byte size change and the percentage of functions with differing assembly, disregarding non-semantic differences such as varying jump and call target addresses.\n\n\n\n\n\n\n\nAlive2\n\nLLVM Test Suite\n\nThe byte type was implemented in Alive2, enabling the verification of both the reworked and newly added optimizations. Accessing both the correctness of the implementation and the broader impact of introducing the byte type into the IR, Alive2 was run over the LLVM test suite. Several previously unsound optimizations, which were addressed by the byte type, were identified in the tests listed below.\n\nTest Reason ExpandMemCmp/AArch64/memcmp.ll memcmp to integer load/store pairs ExpandMemCmp/X86/bcmp.ll bcmp to integer load/store pairs ExpandMemCmp/X86/memcmp-x32.ll memcmp to integer load/store pairs ExpandMemCmp/X86/memcmp.ll memcmp to integer load/store pairs GVN/metadata.ll Unsound pointer coercions GVN/pr24397.ll Unsound pointer coercions InstCombine/bcmp-1.ll bcmp to integer load/store pairs InstCombine/memcmp-1.ll memcmp to integer load/store pairs InstCombine/memcpy-to-load.ll memcpy to integer load/store pairs PhaseOrdering/swap-promotion.ll memcpy to integer load/store pairs SROA/alignment.ll memcpy to integer load/store pairs\n\nIt is worth noting that some additional tests containing unsound optimizations were addressed. However, Alive2 did not report them as unsound, due to the presence of unsupported features, such as multiple address spaces. Moreover, the ExpandMemCmp tests continue to be flagged as unsound by Alive2. This is because the required !uninit_is_nondet metadata has not yet been upstreamed and therefore remains absent in memcmp load widenings optimizations.\n\nSingle File Programs\n\nThe alivecc tool was used to verify the compilation of two single-file C programs, both compiled with the -O2 optimization level. The results are presented below.\n\nbzip2 : No differences were detected during verification.\n\n: No differences were detected during verification. sqlite3 : Two optimizations previously flagged as unsound by Alive2 were fixed. These occurred in the sqlite3WhereOkOnePass and dup8bytes functions. The reduced IR reveals that these were caused by lowerings of memcpy to integer load/store pairs.\n\nFuture Work\n\nAfter modifying Clang to lower the char , unsigned char and signed char types to the byte type, approximately 1800 Clang regression tests began failing. Over the course of the project, the number of failing tests was gradually reduced and, currently, around 100 regression tests are still failing. LLVM is a fast-moving codebase, and due to the sheer number of Clang tests affected by the introduction of the byte type, maintaining a clean test suite constitutes a continuous effort.\n\nThe benchmarks were run on an x86-64 system. However, LLVM also supports other popular architectures such as AArch64 and RISC-V, which may require additional performance evaluation.\n\nFurthermore, the patches do not include any additions to the Language Reference.\n\nConclusion\n\nThe addition of the byte type to the IR solves one of the long lasting problems in LLVM, with a minimal performance impact. Optimization passes can now safely represent and manipulate raw memory values, fixing existing optimizations, and setting up a solid foundation for new, previously inexpressible optimizations.\n\nParticipating in GSoC was both a great honor and a tremendous learning opportunity. Over the course of this project, I’ve learned a lot about compilers, optimizations and LLVM. It was also a valuable opportunity to get in touch with the LLVM community and contribute through the following pull requests:\n\nI would like to thank my mentor, Nuno Lopes, for his guidance and support. Not only did his experience and expertise help me get through some of the most challenging parts of the project, but his presence also made the whole process genuinely enjoyable. I also believe few people in the world could guide me so well through the Alive2 codebase!\n\nI would also like to thank George Mitenkov, who laid the groundwork by developing the original prototype introducing the byte type. Not only did he accomplish quite a lot in a single summer, but he also wrote a phenomenal write-up, which greatly contributed to my understanding of the problem.",
      "source": "Llvm.org",
      "url": "https://blog.llvm.org/posts/2025-08-29-gsoc-byte-type/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "HP EliteBook 8 G1a 16 AI laptop review: Redesigned inside and out",
      "content": "The business-centric EliteBook 8 series directly replaces the outgoing EliteBook 800 series. The new naming convention makes it easier to identify the price category, generation, and type of processor. In this case, the EliteBook 8 G1a 16 in review is an entry-level (8) first generation (G1) model powered by an AMD (a) processor. Higher-end EliteBook models sport the \"X\" or \"Ultra\" name instead of the \"8\".\n\nOur test configuration is a costlier SKU with the Zen 5 Ryzen AI 7 PRO 350 CPU, 32 GB of RAM, and 1200p IPS display for approximately $1900 USD. Lower-end options start with the Zen 4 Ryzen 5 Pro 230 while the 1200p native resolution is fixed across the board.\n\nAlternatives to the 16-inch EliteBook 8 G1a include other entry-level to midrange business or office laptops like the Asus ExpertBook B5, Lenovo ThinkPad L16, or Dell Latitude 5000 to 7000 series. A 14-inch version of this model is also available called the EliteBook 8 G1a 14. For Intel fans, SKUs with Core Ultra CPUs are aptly named the EliteBook 8 G1i 16.\n\nMore HP reviews:",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/HP-EliteBook-8-G1a-16-AI-laptop-review-Redesigned-inside-and-out.1103659.0.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Easy online access to active mobility device parts driving illegal modifications, say industry players",
      "content": null,
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/singapore/active-mobility-devices-amd-illegal-modification-parts-online-5339241",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia Announces Rubin CPX GPU To Speed Long-Context AI",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/karlfreund/2025/09/09/nvidia-announces-rubin-cpx-gpu-to-speed-long-context-ai/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD’s CEO Lisa Su to Make a CES 2026 Comeback After Three Years, Unveiling ‘Bold’ Plans for Next-Gen Ryzen CPUs, Radeon GPUs, and AI Computing",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/amd-ceo-lisa-su-to-make-a-return-at-ces-2026-after-three-years/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Refurbished CyberPowerPC Gamer Master GMA6900WST Ryzen 5 7600 16GB DDR5 AMD Radeon RX 7600 8GB 1TB SSD Wifi BT Win11H + Free Shipping $632",
      "content": "VIP Outlet via eBay has Refurbished CyberPowerPC Gamer Master GMA6900WST Ryzen 5 7600 16GB DDR5 AMD Radeon RX 7600 8GB 1TB SSD Wifi BT Win11H for $632.00. Shipping is free. 1 year warranty provided by Allstate.OP Notes: Only 5 in stock at time of posting. Nice specs for the $630 price point (latest socket AM5 processor with 27,000+ CPU Mark score, DDR5 system RAM upgradeable to 128GB, GDDR6 graphics RAM, respectable graphics card, 1TB PCIe Gen4 SSD). Reviews indicate excellent performance with modern games.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18593395-refurbished-cyberpowerpc-gamer-master-gma6900wst-ryzen-5-7600-16gb-ddr5-amd-radeon-rx-7600-8gb-1tb-ssd-wifi-bt-win11h-free-shipping-632",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "YMMV: HP OMEN MAX: 16\" QHD+ 240Hz IPS, Ryzen AI 9 HX 375, RTX 5080, 32GB DDR5, 1TB SSD $1999.99",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired Dr.W posted Item 1 of 2 Item 1 of 2 expired Dr.W posted YMMV: HP OMEN MAX: 16\" QHD+ 240Hz IPS, Ryzen AI 9 HX 375, RTX 5080, 32GB DDR5, 1TB SSD $1999.99 $2,000 $2,400 16% off Micro Center 9 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 5,787 Views Visit Micro Center Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details Available In-store Only at selective stores, YMMV.\n\n\n\nSPECS: AMD Ryzen AI 9 HX 375 (2.0GHz) Processor\n\n32GB DDR5-5600 RAM\n\nNVIDIA GeForce RTX 5080 Graphics Card\n\n1TB PCIe Gen4 NVMe M.2 SSD\n\n16\" WQXGA IPS Anti-Glare Display\n\n2.5Gb LAN, 2x2 WiFi 7 (802.11be), Bluetooth 5.4\n\n5.88 lbs. (2.67 kg)\n\nWindows 11 Home\n\nhttps://www.microcenter .com/produ...-processor Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster Dr.W Follow Give Rep Message 8,032 Deal Posts 11,542 Comments Posts 16,996 Reputation Points 10,806 Votes Submitted Deal Details Community Notes About the Poster Available In-store Only at selective stores, YMMV.\n\n\n\nSPECS: AMD Ryzen AI 9 HX 375 (2.0GHz) Processor\n\n32GB DDR5-5600 RAM\n\nNVIDIA GeForce RTX 5080 Graphics Card\n\n1TB PCIe Gen4 NVMe M.2 SSD\n\n16\" WQXGA IPS Anti-Glare Display\n\n2.5Gb LAN, 2x2 WiFi 7 (802.11be), Bluetooth 5.4\n\n5.88 lbs. (2.67 kg)\n\nWindows 11 Home\n\nhttps://www.microcenter .com/produ...-processor",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18593653-ymmv-hp-omen-max-16-qhd-240hz-ips-ryzen-ai-9-hx-375-rtx-5080-32gb-ddr5-1tb-ssd-1999-99",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Microsoft Patch Tuesday September 2025, (Tue, Sep 9th)",
      "content": "As part of its September patch Tuesday, Microsoft addressed 177 different vulnerabilities, 86 of which affect Microsoft products. None of the vulnerabilities has been exploited before today. Two of the vulnerabilities were already made public. Microsoft rates 13 of the vulnerabilities are critical.\n\nYou will see a number of vulnerabilities without assigned severity. These vulnerabilities affect Linux distributions like Mariner, Microsoft's Linux distribution used in its cloud environments, and Azure Linux.\n\nVulnerabilities of Interest:\n\nCVE-2025-54107, CVE-2025-54917: Microsoft assigns URLs to different security zones, like \"Intranet\" and \"Internet\". URLs may be misclassified. An attacker could use this vulnerability to bypass security features that restrict more risky URLs.\n\nCVE-2025-55226, CVE-2025-55236: The description for these vulnerabilities is a bit odd. Microsoft labels them as \"remote code execution\" vulnerabilities, but states that they allow an \"authorized attacker to execute code locally.\" I suspect that the remote part refers to a user unknowingly executing the code by viewing an image. The CVSS score is still low for a \"critical\" vulnerability.\n\nOverall, there is no \"patch now\" vulnerability included. Apply patches in line with your local vulnerability management policy (hopefully before next month's patch Tuesday).\n\nDescription CVE Disclosed Exploited Exploitability (old versions) current version Severity CVSS Base (AVG) CVSS Temporal (AVG) ACPI: pfr_update: Fix the driver update version check CVE-2025-39701 No No - - - ALSA: usb-audio: Validate UAC3 power domain descriptors, too CVE-2025-38729 No No - - - 7.0 7.0 ASoC: core: Check for rtd == NULL in snd_soc_remove_pcm_runtime() CVE-2025-38706 No No - - - 4.7 4.7 Azure Arc Elevation of Privilege Vulnerability CVE-2025-55316 No No - - Important 7.8 6.8 Azure Bot Service Elevation of Privilege Vulnerability CVE-2025-55244 No No - - Critical 9.0 7.8 Azure Connected Machine Agent Elevation of Privilege Vulnerability CVE-2025-49692 No No - - Important 7.8 6.8 Azure Entra Elevation of Privilege Vulnerability CVE-2025-55241 No No - - Critical 9.0 7.8 Azure Networking Elevation of Privilege Vulnerability CVE-2025-54914 No No - - Critical 10.0 8.7 Capability Access Management Service (camsvc) Elevation of Privilege Vulnerability CVE-2025-54108 No No - - Important 7.0 6.1 DirectX Graphics Kernel Elevation of Privilege Vulnerability CVE-2025-55223 No No - - Important 7.0 6.1 Dynamics 365 FastTrack Implementation Assets Information Disclosure Vulnerability CVE-2025-55238 No No - - Critical 7.5 6.5 Glib: buffer under-read on glib through glib/gfileutils.c via get_tmp_file() CVE-2025-7039 No No - - - 3.7 3.7 Graphics Kernel Remote Code Execution Vulnerability CVE-2025-55226 No No - - Critical 6.7 5.8 CVE-2025-55236 No No - - Critical 7.3 6.4 HTTP.sys Denial of Service Vulnerability CVE-2025-53805 No No - - Important 7.5 6.5 Libsoup: improper handling of http vary header in libsoup caching CVE-2025-9901 No No - - - 5.9 5.6 Local Security Authority Subsystem Service (LSASS) Denial of Service Vulnerability CVE-2025-53809 No No - - Important 6.5 5.7 Local Security Authority Subsystem Service Elevation of Privilege Vulnerability CVE-2025-54894 No No - - Important 7.8 6.8 LoongArch: BPF: Fix jump offset calculation in tailcall CVE-2025-38723 No No - - - 5.5 5.5 MIPS: Don't crash in stack_top() for tasks without ABI or vDSO CVE-2025-38696 No No - - - 5.5 5.5 MapUrlToZone Security Feature Bypass Vulnerability CVE-2025-54107 No No - - Important 4.3 3.8 CVE-2025-54917 No No - - Important 4.3 3.8 Microsoft AutoUpdate (MAU) Elevation of Privilege Vulnerability CVE-2025-55317 No No - - Important 7.8 6.8 Microsoft Brokering File System Elevation of Privilege Vulnerability CVE-2025-54105 No No - - Important 7.0 6.1 Microsoft DWM Core Library Elevation of Privilege Vulnerability CVE-2025-53801 No No - - Important 7.8 6.8 Microsoft Edge (Chromium-based) Security Feature Bypass Vulnerability CVE-2025-53791 No No - - Moderate 4.7 4.1 Microsoft Excel Information Disclosure Vulnerability CVE-2025-54901 No No - - Important 5.5 4.8 Microsoft Excel Remote Code Execution Vulnerability CVE-2025-54896 No No - - Important 7.8 6.8 CVE-2025-54898 No No - - Important 7.8 6.8 CVE-2025-54899 No No - - Important 7.8 6.8 CVE-2025-54902 No No - - Important 7.8 6.8 CVE-2025-54903 No No - - Important 7.8 6.8 CVE-2025-54904 No No - - Important 7.8 6.8 CVE-2025-54900 No No - - Important 7.8 6.8 Microsoft High Performance Compute (HPC) Pack Remote Code Execution Vulnerability CVE-2025-55232 No No - - Important 9.8 8.5 Microsoft Office Remote Code Execution Vulnerability CVE-2025-54906 No No - - Important 7.8 6.8 CVE-2025-54910 No No - - Critical 8.4 7.3 Microsoft Office Visio Remote Code Execution Vulnerability CVE-2025-54907 No No - - Important 7.8 6.8 Microsoft OfficePlus Spoofing Vulnerability CVE-2025-55243 No No - - Important 7.5 6.5 Microsoft PowerPoint Remote Code Execution Vulnerability CVE-2025-54908 No No - - Important 7.8 6.8 Microsoft SQL Server Elevation of Privilege Vulnerability CVE-2025-55227 No No - - Important 8.8 7.7 Microsoft SQL Server Information Disclosure Vulnerability CVE-2025-47997 No No - - Important 6.5 5.7 Microsoft SharePoint Remote Code Execution Vulnerability CVE-2025-54897 No No - - Important 8.8 7.7 Microsoft Virtual Hard Disk Elevation of Privilege Vulnerability CVE-2025-54112 No No - - Important 7.0 6.1 Microsoft Word Information Disclosure Vulnerability CVE-2025-54905 No No - - Important 7.1 6.2 NFS: Fix a race when updating an existing write CVE-2025-39697 No No - - - 5.5 5.5 NFS: Fix filehandle bounds checking in nfs_fh_to_dentry() CVE-2025-39730 No No - - - 7.5 7.5 Podman: podman kube play command may overwrite host files CVE-2025-9566 No No - - - 8.1 8.1 PowerShell Direct Elevation of Privilege Vulnerability CVE-2025-49734 No No - - Important 7.0 6.1 SPNEGO Extended Negotiation (NEGOEX) Security Mechanism Elevation of Privilege Vulnerability CVE-2025-54895 No No - - Important 7.8 6.8 VulnCheck: CVE-2024-21907 Improper Handling of Exceptional Conditions in Newtonsoft.Json CVE-2024-21907 Yes No - - - Windows Ancillary Function Driver for WinSock Elevation of Privilege Vulnerability CVE-2025-54099 No No - - Important 7.0 6.1 Windows BitLocker Elevation of Privilege Vulnerability CVE-2025-54911 No No - - Important 7.3 6.4 CVE-2025-54912 No No - - Important 7.8 6.8 Windows Bluetooth Service Elevation of Privilege Vulnerability CVE-2025-53802 No No - - Important 7.0 6.1 Windows Connected Devices Platform Service (Cdpsvc) Denial of Service Vulnerability CVE-2025-54114 No No - - Important 7.0 6.1 Windows Connected Devices Platform Service Elevation of Privilege Vulnerability CVE-2025-54102 No No - - Important 7.8 6.8 Windows Defender Firewall Service Elevation of Privilege Vulnerability CVE-2025-53808 No No - - Important 6.7 5.8 CVE-2025-53810 No No - - Important 6.7 5.8 CVE-2025-54094 No No - - Important 6.7 5.8 CVE-2025-54104 No No - - Important 6.7 5.8 CVE-2025-54109 No No - - Important 6.7 5.8 CVE-2025-54915 No No - - Important 6.7 5.8 Windows Graphics Component Elevation of Privilege Vulnerability CVE-2025-53800 No No - - Critical 7.8 6.8 CVE-2025-53807 No No - - Important 7.0 6.1 Windows Graphics Component Remote Code Execution Vulnerability CVE-2025-54919 No No - - Important 7.5 6.5 CVE-2025-55228 No No - - Critical 7.8 6.8 Windows Hyper-V Elevation of Privilege Vulnerability CVE-2025-54091 No No - - Important 7.8 6.8 CVE-2025-54092 No No - - Important 7.8 6.8 CVE-2025-54098 No No - - Important 7.8 6.8 CVE-2025-54115 No No - - Important 7.0 6.1 Windows Hyper-V Remote Code Execution Vulnerability CVE-2025-55224 No No - - Critical 7.8 6.8 Windows Imaging Component Information Disclosure Vulnerability CVE-2025-53799 No No - - Critical 5.5 4.8 Windows Kernel Elevation of Privilege Vulnerability CVE-2025-54110 No No - - Important 8.8 7.7 Windows Kernel Memory Information Disclosure Vulnerability CVE-2025-53803 No No - - Important 5.5 4.8 Windows Kernel-Mode Driver Information Disclosure Vulnerability CVE-2025-53804 No No - - Important 5.5 4.8 Windows Management Service Elevation of Privilege Vulnerability CVE-2025-54103 No No - - Important 7.4 6.4 Windows MultiPoint Services Elevation of Privilege Vulnerability CVE-2025-54116 No No - - Important 7.3 6.4 Windows NTFS Remote Code Execution Vulnerability CVE-2025-54916 No No - - Important 7.8 6.8 Windows NTLM Elevation of Privilege Vulnerability CVE-2025-54918 No No - - Critical 8.8 7.7 Windows Routing and Remote Access Service (RRAS) Information Disclosure Vulnerability CVE-2025-53797 No No - - Important 6.5 5.7 CVE-2025-53798 No No - - Important 6.5 5.7 CVE-2025-54095 No No - - Important 6.5 5.7 CVE-2025-54096 No No - - Important 6.5 5.7 CVE-2025-54097 No No - - Important 6.5 5.7 CVE-2025-55225 No No - - Important 6.5 5.7 CVE-2025-53796 No No - - Important 6.5 5.7 CVE-2025-53806 No No - - Important 6.5 5.7 Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability CVE-2025-54106 No No - - Important 8.8 7.7 CVE-2025-54113 No No - - Important 8.8 7.7 Windows SMB Client Remote Code Execution Vulnerability CVE-2025-54101 No No - - Important 4.8 4.2 Windows SMB Elevation of Privilege Vulnerability CVE-2025-55234 Yes No - - Important 8.8 7.7 Windows TCP/IP Driver Elevation of Privilege Vulnerability CVE-2025-54093 No No - - Important 7.0 6.1 Windows UI XAML Maps MapControlSettings Elevation of Privilege Vulnerability CVE-2025-54913 No No - - Important 7.8 6.8 Windows UI XAML Phone DatePickerFlyout Elevation of Privilege Vulnerability CVE-2025-54111 No No - - Important 7.8 6.8 Xbox Certification Bug Copilot Djando Information Disclosure Vulnerability CVE-2025-55242 No No - - Critical 6.5 5.7 Xbox Gaming Services Elevation of Privilege Vulnerability CVE-2025-55245 No No - - Important 7.8 6.8 cJSON 1.5.0 through 1.7.18 allows out-of-bounds access via the decode_array_index_from_pointer function in cJSON_Utils.c, allowing remote attackers to bypass array bounds checking and access restricted data via malformed JSON pointer strings containing alphanumeric characters. CVE-2025-57052 No No - - - 9.8 9.8 comedi: Fix use of uninitialized memory in do_insn_ioctl() and do_insnlist_ioctl() CVE-2025-39684 No No - - - 5.5 5.5 comedi: Make insn_rw_emulate_bits() do insn->n samples CVE-2025-39686 No No - - - 5.5 5.5 comedi: fix race between polling and detaching CVE-2025-38687 No No - - - 5.5 5.5 comedi: pcl726: Prevent invalid irq number CVE-2025-39685 No No - - - 5.5 5.5 crypto: qat - flush misc workqueue during device shutdown CVE-2025-39721 No No - - - 7.0 7.0 drbd: add missing kref_get in handle_write_conflicts CVE-2025-38708 No No - - - 6.3 6.3 drm/amd/display: Add null pointer check in mod_hdcp_hdcp1_create_session() CVE-2025-39675 No No - - - 5.5 5.5 drm/amd/display: Avoid a NULL pointer dereference CVE-2025-39693 No No - - - 5.5 5.5 drm/amd/display: fix a Null pointer dereference vulnerability CVE-2025-39705 No No - - - 5.5 5.5 drm/amd/pm: fix null pointer access CVE-2025-38705 No No - - - 5.5 5.5 drm/amdgpu: check if hubbub is NULL in debugfs/amdgpu_dm_capabilities CVE-2025-39707 No No - - - 5.5 5.5 drm/amdkfd: Destroy KFD debugfs after destroy KFD wq CVE-2025-39706 No No - - - 5.5 5.5 drm/nouveau/nvif: Fix potential memory leak in nvif_vmm_ctor(). CVE-2025-39679 No No - - - 5.5 5.5 drm/xe: Make dma-fences compliant with the safe access rules CVE-2025-38703 No No - - - 7.8 7.8 exfat: add cluster chain loop check for dir CVE-2025-38692 No No - - - 7.0 7.0 ext4: do not BUG when INLINE_DATA_FL lacks system.data xattr CVE-2025-38701 No No - - - 7.0 6.4 f2fs: vm_unmap_ram() may be called from an invalid context CVE-2025-39731 No No - - - 5.5 5.5 fbdev: Fix vmalloc out-of-bounds write in fast_imageblit CVE-2025-38685 No No - - - 7.8 7.8 fbdev: fix potential buffer overflow in do_register_framebuffer() CVE-2025-38702 No No - - - 7.8 7.1 fs/buffer: fix use-after-free when call bh_read() helper CVE-2025-39691 No No - - - 7.1 7.1 fs/ntfs3: Add sanity check for file name CVE-2025-38707 No No - - - 5.5 5.5 ftrace: Also allocate and copy hash for reading of filter files CVE-2025-39689 No No - - - 7.1 6.5 gfs2: Validate i_depth for exhash directories CVE-2025-38710 No No - - - 7.0 6.4 gve: prevent ethtool ops after shutdown CVE-2025-38735 No No - - - 7.0 7.0 habanalabs: fix UAF in export_dmabuf() CVE-2025-38722 No No - - - 5.5 5.5 hfs: fix general protection fault in hfs_find_init() CVE-2025-38716 No No - - - 5.5 5.5 hfs: fix slab-out-of-bounds in hfs_bnode_read() CVE-2025-38715 No No - - - 5.5 5.5 hfsplus: don't use BUG_ON() in hfsplus_create_attributes_file() CVE-2025-38712 No No - - - 5.5 5.5 hfsplus: fix slab-out-of-bounds in hfsplus_bnode_read() CVE-2025-38714 No No - - - 9.0 8.2 hfsplus: fix slab-out-of-bounds read in hfsplus_uni2asc() CVE-2025-38713 No No - - - 6.1 6.1 iio: imu: bno055: fix OOB access of hw_xlate array CVE-2025-39719 No No - - - 5.5 5.5 iio: light: as73211: Ensure buffer holes are zeroed CVE-2025-39687 No No - - - 5.5 5.5 io_uring/net: commit partial buffers on retry CVE-2025-38730 No No - - - 5.5 5.5 iommufd: Prevent ALIGN() overflow CVE-2025-38688 No No - - - 7.1 7.1 ipv6: sr: Fix MAC comparison to be constant-time CVE-2025-39702 No No - - - 7.1 7.1 jfs: Regular file corruption check CVE-2025-38698 No No - - - 7.1 6.5 jfs: upper bound check of tree index in dbAllocAG CVE-2025-38697 No No - - - 7.1 7.1 ksmbd: fix refcount leak causing resource not released CVE-2025-39720 No No - - - 5.5 5.5 loop: Avoid updating block size under exclusive owner CVE-2025-38709 No No - - - 7.0 6.4 media: ivsc: Fix crash at shutdown due to missing mei_cldev_disable() calls CVE-2025-39711 No No - - - 7.0 7.0 media: rainshadow-cec: fix TOCTOU race condition in rain_interrupt() CVE-2025-39713 No No - - - 7.0 7.0 media: usbtv: Lock resolution while streaming CVE-2025-39714 No No - - - 5.5 5.5 media: uvcvideo: Fix 1-byte out-of-bounds read in uvc_parse_format() CVE-2025-38680 No No - - - 3.3 3.3 media: venus: Add a check for packet size after reading from shared memory CVE-2025-39710 No No - - - media: venus: Fix OOB read due to missing payload bound check CVE-2025-38679 No No - - - 5.5 5.5 media: venus: protect against spurious interrupts during probe CVE-2025-39709 No No - - - 5.5 5.5 mm/ptdump: take the memory hotplug lock inside ptdump_walk_pgd() CVE-2025-38681 No No - - - 5.5 5.5 net, hsr: reject HSR frame if skb can't hold tag CVE-2025-39703 No No - - - 7.0 6.4 net/sched: Fix backlog accounting in qdisc_dequeue_internal CVE-2025-39677 No No - - - 7.0 6.4 net/sched: ets: use old 'nbands' while purging unused classes CVE-2025-38684 No No - - - 7.0 7.0 net/smc: fix UAF on smcsk after smc_listen_out() CVE-2025-38734 No No - - - 5.5 5.5 net: kcm: Fix race condition in kcm_unattach() CVE-2025-38717 No No - - - 5.5 5.5 net: usb: asix_devices: Fix PHY address mask in MDIO bus initialization CVE-2025-38736 No No - - - 5.5 5.5 net: usb: asix_devices: add phy_mask for ax88772 mdio bus CVE-2025-38725 No No - - - 5.5 5.5 netfilter: ctnetlink: fix refcount leak on table dump CVE-2025-38721 No No - - - 5.5 5.5 netfilter: nf_reject: don't leak dst refcount for loopback packets CVE-2025-38732 No No - - - 7.0 7.0 netfilter: nf_tables: reject duplicate device on updates CVE-2025-38678 No No - - - 6.0 6.0 nfsd: handle get_client_locked() failure in nfsd4_setclientid_confirm() CVE-2025-38724 No No - - - 6.8 6.8 pNFS: Fix uninited ptr deref in block/scsi layout CVE-2025-38691 No No - - - 5.5 5.5 parisc: Revise __get_user() to probe user read access CVE-2025-39716 No No - - - 5.5 5.5 parisc: Revise gateway LWS calls to probe user read access CVE-2025-39715 No No - - - 5.5 5.5 ppp: fix race conditions in ppp_fill_forward_path CVE-2025-39673 No No - - - 7.0 7.0 rcu/nocb: Fix possible invalid rdp's->nocb_cb_kthread pointer access CVE-2025-38704 No No - - - 5.5 5.5 s390/ism: fix concurrency management in ism_cmd() CVE-2025-39726 No No - - - 5.5 5.5 s390/sclp: Fix SCCB present check CVE-2025-39694 No No - - - 7.0 7.0 scsi: bfa: Double-free fix CVE-2025-38699 No No - - - 7.8 7.8 scsi: libiscsi: Initialize iscsi_conn->dd_data only if memory is allocated CVE-2025-38700 No No - - - 4.7 4.7 scsi: lpfc: Check for hdwq null ptr when cleaning up lpfc_vport structure CVE-2025-38695 No No - - - 7.0 6.4 scsi: qla4xxx: Prevent a potential error pointer dereference CVE-2025-39676 No No - - - 5.5 5.5 sctp: linearize cloned gso packets in sctp_rcv CVE-2025-38718 No No - - - 7.0 6.4 serial: 8250: fix panic due to PSLVERR CVE-2025-39724 No No - - - 5.5 5.5 smb/server: avoid deadlock when linking with ReplaceIfExists CVE-2025-38711 No No - - - 5.5 5.5 smb3: fix for slab out of bounds on mount to ksmbd CVE-2025-38728 No No - - - 5.5 5.5 smb: server: split ksmbd_rdma_stop_listening() out of ksmbd_rdma_destroy() CVE-2025-39692 No No - - - 5.5 5.5 tls: fix handling of zero-length records on the rx_list CVE-2025-39682 No No - - - 6.5 6.5 tracing: Limit access to parser->buffer when trace_get_user failed CVE-2025-39683 No No - - - 7.1 7.1 vsock/virtio: Validate length in packet header before skb_put() CVE-2025-39718 No No - - - 5.5 5.5 wifi: ath11k: fix sleeping-in-atomic in ath11k_mac_op_set_bitrate_mask() CVE-2025-39732 No No - - - 7.0 7.0 x86/cpu/hygon: Add missing resctrl_cpu_detect() in bsp_init helper CVE-2025-39681 No No - - - 5.5 5.5\n\n--\n\nJohannes B. Ullrich, Ph.D. , Dean of Research, SANS.edu\n\nTwitter|",
      "source": "Sans.edu",
      "url": "https://isc.sans.edu/diary/32270",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "PlayStation 5 Pro AMD FSR 4 Support Is Coming In First Quarter of 2026 – Rumor",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/playstation-5-pro-amd-fsr-first-quarter-2026/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Reorg Puts 40-Year Vet in Charge of PC Group",
      "content": "Intel announced a corporate reorganization that puts Jim Johnson, a 40-year veteran of the company, in charge of the Client Computing Group responsible for its x86-based chip designs for PCs. He was previously serving in this role in an interim basis.\n\n“Jim’s steady leadership and trusted relationships across the computing industry are driving continued progress in our client business as we prepare to launch a new generation of products,” Intel CEO Lip-Bu Tan said.\n\nThurrott.com readers may recognize Johnson as the face of “Lunar Lake,” the controversial—and, I would argue, unsuccessful—attempt to quickly scale Intel’s x86 silicon to battery compete with more efficient Arm-based designs. He anchored the Intel announcement event for Lunar Lake at last year’s IFA in Berlin, Germany. And then he appeared at the Lenovo Innovation World press conference at this year’s show, which was held last week.\n\nHis appearance at Lenovo Innovation World was, to put it mildly, awkward, though he gets an A for confidence and staying on-message.\n\n“With Core Ultra Series 2 [Lunar Lake], we re-engineered the CPU, the GPU, and the NPU and delivered faster compute, improved AI experience, and busted the myth that x86 can’t be power efficient,” Johnson said at the event, which is available for rewatching on YouTube. Here, he paused, presumably for applause.\n\nIt never came. As most in the audience understood, and as my unpredictable and mostly lackluster experiences with Lunar Lake-based PCs show, this isn’t the home run that Johnson promoted. Lunar Lake is more efficient than previous Intel chips, but it’s also incredibly unreliable and unpredictable. Indeed, Lunar Lake is such a disaster that Intel will never make a chip design like it again, and it loses money on every unit sold. Subsequent Core Ultra Series 2 designs have all used different architectures.\n\nTo be clear, this is no one person’s fault in the sense that a cascading series of strategic mistakes over a decade or more led to Intel’s problems today. The company was forced to rush Lunar Lake to market so it could have a Copilot+ PC-compatible chip to compete with more efficient designs from AMD and Qualcomm.\n\nAnd Johnson wasn’t in charge of Intel’s Client Computing Group at that time. Michelle Johnston Holthaus was. And as it turns out, she’s leaving Intel as Johnson is elevated into her former role. She had become CEO of Intel products briefly, after Pat Gelsinger, the previous Intel CEO, left the company.\n\n“Throughout her incredible career, Michelle has transformed major businesses, built high-performing teams, and worked to delight our customers,” Tan said. “She has made a lasting impact on our company and inspired so many of us with her leadership. We are grateful for all Michelle has given Intel and wish her the best.”\n\nAs part of the reorg, Intel also revealed that Naga Chandrasekaran, the executive vice president and chief technology and operations officer of Intel Foundry, will expand his role to include Foundry Services. He joined Intel last year after a stint at Micron.\n\nIntel is also creating a new Central Engineering Group that will “build a new custom silicon business to serve a broad range of external customers.” This will be led by Srini Iyengar, who joined Intel this past June. And former Arm executive Kevork Kechichian has joined Intel as executive vice president and general manager of the Data Center Group (DCG).\n\nChandrasekaran was already reporting directly to the Intel CEO, and now Johnson, Kechichian, and Iyengar will as well, Intel says.",
      "source": "Thurrott.com",
      "url": "https://www.thurrott.com/hardware/326233/intel-reorg-puts-40-year-vet-in-charge-of-pc-group",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Patch Tuesday Arrives with New Features for Windows 11",
      "content": "It’s Patch Tuesday, and those on Windows 11 can look forward to a long list of new features. You know, once Microsoft gets around to delivering them on your PC, as most of them are being rolled out gradually.\n\nCumulative update KB5065426 is available for PCs running Windows 11 version 23H2. And cumulative update KB5065426 is available now for PCs running Windows 11 version 24H2. Both builds include numerous new features that were first previewed two weeks ago.\n\nKey new features include:\n\nRecall improvements (Copilot+ PCs only). Recall provides a new homepage experience with shortcuts for your recent activity, most-used apps, and most-visited websites. There are new controls for filtering the apps and websites that Recall shouldn’t record, plus a new navigation bar on the left with links to Home, Timeline, Feedback, and Settings.\n\nClick to Do improvements (Copilot+ PCs only). Click to Do now provides an interactive tutorial when you first launch it, and you can access it later by navigating to More options (“…”) > Start tutorial.\n\nAgent in Settings (Copilot+ PCs only). Previously available on Snapdragon X-based Copilot+ PCs, the new Agent in Settings is now available to those with AMD- and Intel-based Copilot+ PCs too. But it’s still limited to English, which must be configured as your primary display language.\n\nSearch improvements. When you initiate Search from the Taskbar item, a new grid view is used for image results so you can more easily find what you’re looking for. The Search window will now display a status pane if Windows 11 is still indexing your search locations. And search results will clearly differentiate between local and cloud-stored files.\n\nLarger clock option in Notification center. As was the case in Windows 10, you can now enable a larger clock with settings in the Date and Calendar window that appears when you display the Notification center. (To do so, open Settings, navigate to Time & language > Date & time, and enable the option “Show time in the Notification Center.”)\n\nSystem dialog improvements. System dialogs now appear modally over the rest of the Desktop, which is dimmed to give emphasis to the dialog.\n\nLock screen widgets improvements. You can now add, remove, and rearrange Lock screen widgets. And these widgets now support a new small sizing option.\n\nFile Explorer improvements. Microsoft has made minor visual changes to the context menu that appears when you right-click in File Explorer.\n\nWindows Hello improvements. The Windows Hello user experience is completely redesigned with more modern visuals. It’s nicer looking but, truth be told, slower and more tedious to use now. But it does let you switch between available authentication options such as passkeys or connected devices.\n\nGenerative AI privacy and security settings. A new page in the Settings app, found at Privacy & security > Text and Image Generation, displays which third-party apps have recently used generative AI models built into Windows. You can also manage which apps can use these features, and then disable those you don’t want.\n\nWidgets improvements. You can now configure multiple dashboards in the Widgets board, and there’s a new navigation bar on the left for switching between the widget dashboards and other views like the Discover feed, which is “more organized, personalized, and engaging.”\n\nTask Manager improvements. Task Manager has been updated to more accurately display CPU usage across all views. The Details view now has an optional CPU Utility column, as per the Processes view.\n\nFixes. As you might imagine, these builds also deliver multiple security and bug fixes across ReFS, the Chinese (Simplified) Input Method Editor (IME), Arm64 performance, and more.\n\nYes, you will need to reboot as usual.",
      "source": "Thurrott.com",
      "url": "https://www.thurrott.com/windows/windows-11/326263/patch-tuesday-arrives-with-new-features-for-windows-11",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "China’s AI Chip Ambitions Limited by HBM Memory Supply, Notes Report",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/chinas-ai-chip-ambitions-limited-by-hbm-memory-supply-notes-report/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 “Battlemage” Nears Launch as Intel Prepares Packaging",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Wall Street Loves Taiwan Semi. Should You Buy TSM Stock Now?",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/34699828/wall-street-loves-taiwan-semi-should-you-buy-tsm-stock-now",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Vultr Announces Availability of AMD Instinct™ MI355X GPUs Worldwide",
      "content": null,
      "source": "Financial Post",
      "url": "https://financialpost.com/pmn/business-wire-news-releases-pmn/vultr-announces-availability-of-amd-instinct-mi355x-gpus-worldwide",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Why JPMorgan is warning the Fed rate cut everyone expects could sink stocks",
      "content": null,
      "source": "MarketWatch",
      "url": "https://www.marketwatch.com/story/why-jpmorgan-is-warning-the-fed-rate-cut-everyone-expects-could-sink-stocks-0179698d",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD Ryzen 7 9800X3D vs AMD Ryzen 9 9950X3D Faceoff",
      "content": "If you're looking for the fastest gaming chips on the market, AMD has no peer: In fact, the company's own Ryzen 9 9950X3D vs Ryzen 7 9800X3D is really the only competition that most hardcore gamers care about - Intel isn't a factor with its latest-gen chips due to lackluster performance on the gaming front.\n\nAt first glance, comparing the $470 AMD Ryzen 7 9800X3D with the flagship $670 Ryzen 9 9950X3D might seem like an uneven match. After all, the Ryzen 9 9950X3D commands a $200 higher price point and boasts twice the number of cores, which naturally suggests superior performance.\n\nHowever, this faceoff dives deeper than just raw numbers and sticker price. It explores how these two processors, both from AMD’s gaming-optimized Zen 5 X3D lineup, cater to different needs and whether the premium flagship truly justifies its cost in real-world scenarios.\n\nThe Ryzen 9 9950X3D sits at the very top of AMD’s desktop CPU hierarchy, aimed at enthusiasts and professionals who demand the utmost in multi-threaded performance alongside gaming capabilities. It's the \"no compromises\" option, commanding a premium price befitting its halo status.\n\nIn contrast, the Ryzen 7 9800X3D offers a more focused approach, targeting gamers and mainstream users who seek exceptional gaming performance and efficiency without the complexity or cost of a higher-core-count processor.\n\nPriced around $450 compared to the 9950X3D’s $700 tag, the 9800X3D challenges the notion that more cores and higher prices always translate to a better CPU. Forget assumptions, let's dissect where these two exceptional gaming processors truly excel and uncover which one deserves a place in your ultimate rig.\n\nFeatures and Specifications: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nSwipe to scroll horizontally AMD Ryzen 9 9950X3D and Ryzen 9 9900X3D — Pricing and Specifications CPU Street (MSRP) Arch Cores / Threads (P+E) P-Core Base / Boost Clock (GHz) Cache (L2/L3) TDP / PBP or MTP Memory Ryzen 9 9950X3D $699 Zen 5 X3D 16 / 32 4.3 / 5.7 144 MB (16+128) 170W / 230W DDR5-5600 Ryzen 7 9800X3D $450 Zen 5 X3D 8 / 16 4.7 / 5.2 104MB (8+96) 120W / 162W DDR5-5600\n\nBoth the AMD Ryzen 9 9950X3D and Ryzen 7 9800X3D represent the pinnacle of AMD's desktop processor engineering, built on the sophisticated Zen 5 architecture fabbed on TSMC's advanced 4nm manufacturing process. These processors share the same foundational architecture but differ significantly in their core configurations and target use cases.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe 9950X3D is a dual-CCD powerhouse featuring 16 cores and 32 threads, while the 9800X3D adopts a streamlined single-CCD design with 8 cores and 16 threads. This architectural divergence creates distinct performance profiles, with the 9950X3D targeting users requiring substantial multi-threaded performance alongside gaming excellence, whereas the 9800X3D focuses exclusively on delivering optimal gaming performance without the complexity of a multi-die design.\n\nThe 9950X3D's dual-CCD configuration incorporates two separate 8-core complexes, with only one CCD receiving the 3D V-Cache treatment. This asymmetric design results in 128MB of layered L3 cache, creating a complex but powerful architecture that requires sophisticated thread scheduling. Thankfully its automated through AMD's innovative driver.\n\nIn contrast, the 9800X3D's single-CCD design features a uniform 8-core complex with 96MB of total L3 cache, providing consistent performance characteristics across all cores and simplifying both hardware design and driver optimization.\n\nClock speed specifications reveal differences between these processors, with the 9950X3D operating at a 4.3GHz base clock with boost capabilities reaching 5.7GHz, representing the highest boost clock in the X3D lineup. The 9800X3D, conversely, features a 4.7GHz base clock with boost frequencies of 5.2GHz.\n\nThe second-gen 3D V-Cache tech represents a revolutionary architectural advancement that marks a big improvement over their predecessors. Unlike previous X3D generations, where the 3D V-Cache was positioned above the CCD, both processors feature the cache positioned below the CCD, enabling direct thermal contact between the cores and the integrated heat spreader.\n\nThis design transformation dramatically improves thermal characteristics, allowing both processors to achieve full overclocking capabilities (a first for X3D processors) while maintaining higher boost frequencies than their predecessors. The thermal improvements are particularly significant for the 9950X3D, which maintains its 170W TDP despite its larger cache capacity.\n\nPlatform support and connectivity specifications show AMD's commitment to the AM5 ecosystem. Both CPUs drop into the AM5 socket (LGA 1718) and are compatible with the full range of AM5 chipsets, including A620, B650, B650E, X670, X670E, X870, X870E, B840, and B850. Memory support extends to DDR5 with official specifications up to 5600 MT/s, though both processors can achieve higher speeds through AMD EXPO memory overclocking technology.\n\nThe processors provide 24 usable PCIe 5.0 lanes from the CPU, four native USB 3.2 Gen 2 ports, and comprehensive storage support including NVMe RAID configurations. Power consumption differs significantly, with the 9950X3D coming with a 170W TDP compared to the 9800X3D's 120W TDP, reflecting the increased thermal and power demands of the dual-CCD configuration.\n\n⭐Winner: AMD Ryzen 9 9950X3D\n\nThe Ryzen 9 9950X3D and Ryzen 7 9800X3D share a common Zen 5 foundation but diverge in their feature sets to serve distinct purposes. On paper alone, the Ryzen 9 9950X3D is more impressive due to its higher clocks and additional cores, thus taking this round.\n\nGaming Benchmarks and Performance: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nWhile our in-depth Ryzen 9 9950X3D and Ryzen 7 9800X3D reviews offer a more comprehensive analysis and our test system specs, in this section, we will focus on a gaming performance overview. The following benchmark graphs display average FPS and 1% lows for various games at 1080p. Using a high-end Nvidia GeForce RTX 5090 graphics card ensures GPU limitations are removed, making this setup ideal for comparing pure CPU performance.\n\nImage 1 of 20 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nIn our 16-game geometric mean at 1080p with High/Ultra settings, the Ryzen 7 9800X3D narrowly edges out the Ryzen 9 9950X3D with an average of 195.5 FPS versus 194.8 FPS, which is a negligible 0.4% difference. This parity stems from AMD’s 3D V-Cache technology, which minimizes latency in cache-sensitive titles.\n\nHowever, the 9950X3D’s higher core count rarely translates to gaming gains, as most games prioritize cache and clock speeds over core quantity. For example, in A Plague Tale: Requiem, the 9800X3D leads by 5.9% on average, likely due to its optimized single-CCD design reducing inter-core latency.\n\nOn the flip side, the 9950X3D pulls ahead in 1% lows according to our testing, scoring 136 FPS in the geomean compared to the 9800X3D’s 134 FPS, gaining a minor 1.4% advantage. This reflects its superior multi-core capabilities, mitigating stutter during asset streaming or background tasks.\n\nMoving on to individual results, the picture becomes even more nuanced and needs analysis on a case-by-case basis. In our testing, we typically see that cache-bound games favor the 9800X3D. Minecraft RT shows a 10.9% average FPS lead. In Starfield, the Ryzen 7 leads by 1.7% in average FPS.\n\nOn the contrary, heavily multi-threaded titles seem to lean toward the 9950X3D. In Baldur’s Gate 3, the Ryzen 9 leads by about 2.6%, exploiting its dual-CCD design to gain an advantage in this title.\n\nThe 9800X3D dominates efficiency, achieving 2.46 FPS/W versus the 9950X3D’s 1.61 FPS/W, which is a tremendous 52.8% improvement. It consumes just 79.4W under load according to our testing, while the 9950X3D draws 52% more power at 120.9W. This gap arises from the 9800X3D’s monolithic 8-core design, which avoids the power overhead of the 9950X3D’s dual-CCD configuration.\n\nThe 9800X3D also offers superior value for money, gaining a staggering 50% advantage in our FPS per dollar chart. Priced 33% lower, the Ryzen 7 achieves almost the same average FPS in our Geomean as the 9950X3D. Even in titles where the 9950X3D wins, like Far Cry 6, the 9800X3D’s cost efficiency remains unmatched. The 9950X3D does not justify its price premium in the gaming category when compared to its younger sibling.\n\n⭐Winner: AMD Ryzen 7 9800X3D\n\nUnless you are pairing gaming with heavy streaming or rendering, the 9800X3D’s cache-optimized design and aggressive pricing make it AMD’s gaming champion.\n\nUltimately, the Ryzen 7 9800X3D emerges as the smarter gaming investment. It matches the 9950X3D in average framerates while excelling in efficiency and value. The 9950X3D’s edge in 1% lows is nice, but it cannot be justified by its hefty price premium.\n\nProductivity Performance: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nAccording to our benchmark results, the Ryzen 9 9950X3D demonstrates a substantial productivity advantage over the Ryzen 7 9800X3D across both single-threaded and multi-threaded workloads.\n\nImage 1 of 6 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nIn the aggregated single-threaded geomean, the 9950X3D scores 258, while the 9800X3D trails at 243, leaving a 5.8% performance gap. For multi-threaded geomean, the disparity widens dramatically: the 9950X3D achieves 635 versus the 9800X3D’s 367, translating to a 42% delta. This underscores the 9950X3D’s superior power budget and higher core count.\n\nImage 1 of 10 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nThe 9950X3D’s 16-core design obliterates the 9800X3D’s 8-core setup in heavily parallelized tasks. Cinebench 2024 multi-core reveals a massive 43% performance delta; meanwhile, the POV-Ray multi-core test exacerbates this further as the 9950X3D scores a whopping 69% higher than the 9800X3D.\n\nReal-world encoding tests like HandBrake x265 further validate this trend, with the 9950X3D achieving a 63% leap over the 9800X3D. This makes the 9950X3D a powerhouse for video rendering, 3D compilation, or scientific simulations where core scalability is paramount.\n\nIn tasks reliant on single-core speed, the 9950X3D also maintains a consistent lead, even though the gap narrows significantly. Cinebench 2024 single-core shows a 4.7% advantage, and the gap expands in POV-Ray single-core, where the 9950X3D has a 7.6% higher score than its younger sibling.\n\nEven in lighter workloads like WebXPRT4 (browser-based tasks), the 9950X3D maintains a modest but notable 4.4% edge. The narrower gap confirms that browser-based tasks are less core-dependent, favoring cache/clock speed, yet the 9950X3D still leads. These modest gains reflect the close architectural similarities between the two CPUs in tasks that don’t necessarily scale with core count.\n\nThe 9950X3D’s dual-CCD layout (one with 3D V-Cache, one with higher clocks) optimizes it for hybrid productivity: cache-sensitive tasks leverage the stacked die, while all-core workloads engage both CCDs. The 9800X3D’s single-CCD design restricts it in lighter multi-threaded tasks despite its cache advantage.\n\nPutting it all together, for productivity alone, the Ryzen 9 9950X3D is decisively superior, delivering 10-40% higher performance on average, with peaks exceeding 60% in core-heavy tasks. The Ryzen 7 9800X3D remains viable for budget-focused users handling lighter workloads, but professionals demanding uncompromised rendering, encoding, or compilation speed should opt for the 9950X3D.\n\n⭐Winner: AMD Ryzen 9 9950X3D\n\nIts massive compute throughput advantage, driven by its doubled core count, makes the 9950X3D the unequivocal choice for professional productivity, while the 9800X3D serves well for mainstream users where its strong gaming performance and lower cost are prioritized over extreme multi-threaded muscle.\n\nOverclocking: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nBoth the AMD Ryzen 9 9950X3D and Ryzen 7 9800X3D represent a significant advancement in X3D processor overclocking capabilities compared to their predecessors. Unlike previous X3D generations that had severe overclocking limitations, both Zen 5-based processors support full manual overclocking, including multiplier adjustments, voltage modifications, and extensive tuning options.\n\nThis is a revolutionary change from the Zen 4 X3D processors that were largely locked down, with the 7800X3D only supporting limited PBO and Curve Optimizer adjustments. The key architectural improvement enabling this overclocking freedom is AMD's redesigned 3D V-Cache placement.\n\nIn Zen 5 X3D processors, the 3D V-Cache is positioned underneath the Core Complex Dies (CCDs) rather than on top, dramatically improving thermal management and reducing the voltage sensitivity that previously restricted overclocking. This design change allows both processors to maintain higher boost frequencies while supporting the same overclocking toolkit as the regular Zen 5 processors.\n\nThe processors responds well to both traditional overclocking methods and AMD's advanced tuning tools, including Precision Boost Overdrive 2 (PBO2), Curve Optimizer, and the new Curve Shaper feature exclusive to Zen 5 processors. AMD has plenty of manual tuning option available, but most users are best just engaging the automated Precision Boost Overdrive (PBO) feature.\n\n⭐Winner: Tie\n\nBoth chips leverage the same AMD overclocking suite, so this section works out to a tie.\n\nPower Consumption, Efficiency, and Cooling: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nImage 1 of 10 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nAccording to our test results, the power profiles of the Ryzen 9 9950X3D and Ryzen 7 9800X3D reveal significant differences under load while showing remarkable similarity at idle, directly impacting efficiency and cooling requirements.\n\nImage 1 of 7 (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware) (Image credit: Tom's Hardware)\n\nUnder sustained AVX workloads, the 9950X3D consumes substantially more power than the 9800X3D, reflecting its higher core count and performance ceiling. In the grueling Prime95 Small FFTs test, the 9950X3D averages 215W compared to the 9800X3D's 171W, which is a substantial 25.7% increase. This pattern repeats in y-cruncher's AVX test, where the 9950X3D draws 23.9% more power than the 9800X3D.\n\nEven in Cinebench 2024 multi-core rendering, which favors thread scaling, the 9950X3D requires 57.8% more power than its younger brother. This consistently higher power draw under heavy vectorized or multi-threaded loads is inherent to the 9950X3D's doubled core resources.\n\nRemarkably, both CPUs demonstrate nearly identical power efficiency during low-activity states. In active idle states (such as YouTube playback), the 9950X3D uses 31% more power than the 9800X3D, but the actual difference is 9W. However, in true idle scenarios, the gap narrows to just 3W, which is pretty negligible in the big picture. This parity highlights that the 9950X3D efficiently powers down unused cores, but also highlights that both chips carry the same power burden of the central I/O die, which ultimately results in higher idle power consumption for Zen 5 processors compared to Intel offerings.\n\nDespite its higher power consumption, the 9950X3D often delivers superior performance-per-watt in multi-threaded tasks. In our Cinebench 2024 \"Watts per Point\" metric, the 9950X3D scores a 10.8% efficiency advantage over the 9800X3D. Similarly, in HandBrake x265 encoding, the 9950X3D achieves a 6.4% lead in efficiency despite consuming more raw power in the test itself.\n\nThis indicates the 9950X3D's additional cores translate workloads into completed tasks more efficiently under heavy utilization. The \"Estimated Task Energy\" graph further confirms this trend, placing the 9950X3D in a significantly better (lower-right) position than Intel competitors and delivering way more FPS than the 9800X3D despite consuming almost similar task energy.\n\nThe 9950X3D's higher sustained power load necessitates more robust cooling. A 360mm AIO liquid cooler is optimal for the 9950X3D to maintain optimal boost clocks during extended AVX workloads. The 9800X3D, with its peak draw nearly 20-25% lower, is far more forgiving. A capable dual-tower air cooler or 240mm AIO should suffice in most cases.\n\nAt the end of the day, the Ryzen 7 9800X3D is the clear winner if you just compare the two CPUs by their peak power consumption, especially under heavy AVX loads, making it ideal for users prioritizing low heat output, quieter cooling, or constrained thermal environments.\n\nHowever, the Ryzen 9 9950X3D consumes 25-58% more power under load but delivers 6-11% better performance efficiency (work completed per watt) in multi-threaded scenarios like rendering and encoding. For users needing maximum multi-core throughput, the 9950X3D's efficiency may justify its higher power ceiling, though it demands stronger cooling to realize its full potential.\n\n⭐Winner: Tie\n\nIf you want the absolute lowest power draw, the Ryzen 7 9800X3D is the obvious pick among these two CPUs. It is also easier to cool and is generally quite tame compared to the Ryzen 9 9950X3D, which consumes significantly more power under load.\n\nIn contrast, the 9950X3D takes a significant win in power efficiency (performance-per-watt), highlighting that it delivers exceptional power characteristics of its own.\n\nOverall both chips have their charms, depending on the target workload. That leaves us with yet another tie -- the winner just depends on your personal use-case.\n\nPricing: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nWhen comparing the AMD Ryzen 9 9950X3D and the Ryzen 7 9800X3D, the starting point is their respective CPU prices: the Ryzen 9 9950X3D costs $670 at the time of writing, while the Ryzen 7 9800X3D is priced at $470, a difference of $200. However, to truly assess which CPU offers better value for the money, it’s essential to consider the entire platform cost, including the motherboard, RAM, and CPU cooler.\n\nWhen examining the complete platform cost, both processors share identical requirements for supporting components, but they do have different needs in some areas. DDR5 memory pricing remains consistent across both builds, with 32GB of DDR5-6000 memory costing around $120-$150.\n\nThe AM5 socket requirement means both CPUs could use the same types of motherboards, ranging from budget B650 boards at $125-$160 to premium X870 motherboards that can cost $320-$500. However, the 9950X3D's higher power consumption and thermal output requires a better motherboard than the 9800X3D.\n\nWith a higher TDP and peak power consumption, the 16-core 9950X3D necessitates more robust VRM designs on motherboards for full performance, potentially adding $50-$100 to the platform cost.\n\nCooling the Ryzen 7 9800X3D, which has a lower TDP (120W) compared to its higher-end sibling (170W), can be adequately handled by a mid-tier solution. Options include a $50 to $70 air cooler or a $100 to $150 240mm AIO liquid cooler. In contrast, the Ryzen 9 9950X3D would benefit from a more capable solution, with a 360mm AIO liquid cooler being optimal, which can cost you about $150-200.\n\nConclusively, the 9800X3D emerges as the superior choice for value-conscious builders, despite both processors delivering nearly identical gaming performance, as we already saw. The nearly $230 price difference represents money that could be allocated toward a better graphics card, faster storage, or premium peripherals, which are components that would provide more tangible benefits for gaming performance.\n\nAs for the 9950X3D, its additional productivity capabilities justify its premium only for users who can leverage its extra cores for content creation, streaming, or professional workloads.\n\n⭐Winner: AMD Ryzen 7 9800X3D\n\nFor the vast majority of enthusiasts prioritizing gaming and overall bang-for-buck, the 9800X3D's combination of potent gaming performance and lower total platform cost makes it the clear winner for value. The 9950X3D is best reserved for users who explicitly need its extra cores and are willing to invest in the supporting high-end platform.\n\nBottom Line: AMD Ryzen 9 9950X3D vs AMD Ryzen 7 9800X3D\n\nSwipe to scroll horizontally Row 0 - Cell 0 AMD Ryzen 9 9950X3D AMD Ryzen 7 9800X3D Features and Specifications ❌ Row 1 - Cell 2 Gaming Row 2 - Cell 1 ❌ Productivity Applications ❌ Row 3 - Cell 2 Overclocking ❌ ❌ Power Consumption, Efficiency and Cooling ❌ ❌ Pricing Row 6 - Cell 1 ❌ Total 4 4\n\nThe AMD Ryzen 9 9950X3D and Ryzen 7 9800X3D both bring impressive strengths to the table, ultimately leaving us with a 4-4 tie, but the winner for you will be clear based on your target workloads and budget.\n\nThe Ryzen 7 9800X3D is the clear champion for most users, particularly those prioritizing gaming performance and value. Its dominance in gaming performance, power efficiency, and pricing creates a compelling package that delivers exceptional results without unnecessary complexity. The single-CCD design eliminates the scheduling challenges that can plague dual-CCD configurations, making it the ideal choice for gamers who want maximum performance with minimal fuss.\n\nOn the other hand, the Ryzen 9 9950X3D remains the superior choice for a specific audience: professionals and content creators who demand both exceptional gaming performance and serious productivity capabilities. Its 16-core, 32-thread configuration provides superb multi-core performance that makes it the ultimate all-round CPU for users who refuse to compromise between gaming and professional workloads.\n\nFor the vast majority of gaming enthusiasts and high-performance PC builders, the AMD Ryzen 7 9800X3D is the unequivocal recommendation and king of gaming value. It delivers virtually identical top-tier gaming performance to the 9950X3D while being significantly cheaper, more power-efficient, easier to cool, and less demanding on the supporting platform.\n\nThe Ryzen 9 9950X3D remains a formidable, niche processor, but its considerable price premium and higher platform costs are only justifiable for users who simultaneously require maximum gaming performance and very high levels of multi-threaded productivity performance on a daily basis.\n\nBoth chips have their place, and the clear swim lanes for the 9950X3D and 9800X3D show that AMD has done an excellent job in stratifying the Ryzen 9000 X3D lineup, delivering strong value for two very different chips and ultimately earning its price tag for each chip. Meanwhile, Intel's chips simply can't compete with either of these chips in gaming. Here's hoping for a more competitive Intel with its next-gen chips.\n\n🏆Winner: Tie\n\nMore CPU Faceoffs",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/amd-ryzen-9-9950x3d-vs-amd-ryzen-7-9800x3d-faceoff",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The GAIN AI Act Looks More Like Protectionism Than National Security",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b46e3827ffda946c",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "KG Series is a new collection of 12 FREE plugins for Windows by KageMusicKorea",
      "content": "KageMusicKorea, an independent record label and audio developer based in Seoul, South Korea, has released the KG Series, a free collection of 12 audio plugins designed to provide affordable (or rather, free) creative tools for music producers.\n\nThe KG Series is aimed at breaking down the financial barriers one might associate with music production. Of course, since you’re reading BPB, you learn about hundreds of free plugins each year.\n\nBut even so, getting twelve free plugins in one purpose-built bundle is a nice touch.\n\nThe developers describe the KG Series project as a way to help artists, both beginners and seasoned pros, focus on creativity without worrying about cost. No registration is required to download, and the complete set comes as a 0.9 GB ZIP hosted on Google Drive.\n\nEach plugin in the KG Series is lightweight and tailored toward practical mixing and sound-shaping tasks. The lineup includes multiple EQs, dynamics processors, saturation tools, and time-based effects, all designed with analog-style circuitry emulation.\n\nSome of the highlights include KG-EQP, a two-band analog-style EQ for adding warmth and subtle shaping, and KG-SSQ, a five-band precision EQ suitable for detailed mix sculpting.\n\nThere’s also KG-FREQ6, a six-band parametric EQ with wide gain ranges and a clean layout, and KG-SUB, which enhances sub-bass content with crossover and delay blending for a tighter low-end.\n\nDynamics processors in the collection include KG-COMP, a two-stage RMS compressor with vintage-style warmth controls, and KG-2A, a simple yet effective optical compressor. You also get KG-DEESSER for transparent vocal control and KG-ARCL, an auto-release limiter offering smooth, adaptive gain reduction.\n\nOn the saturation front, KG-TUBE delivers analog-style warmth with independent low and high-frequency control, while KG-SATURATOR gives more precise three-band saturation with added tonal coloring options.\n\nRounding out the set are KG-CLARITY, which boosts upper frequencies to add presence, and KG-VERB, an analog-style reverb with a flexible filter section and pre-delay controls.\n\nAll of this sounds fantastic, apart from one caveat. The plugins are Windows-only.\n\nAnd that being so, I haven’t been able to test these plugins yet because I’m currently on the road with only my MacBook. If any Windows users reading this give these plugins a try, please feel free to share your impressions in the comments.\n\nYou can download the full set directly from the KageMusicKorea website as a ZIP file. No registration is required.\n\nPlugin formats include VST3 only. Minimum system requirements: Windows PC with a modern Intel or AMD processor (SSE2 support), 8GB RAM, and a DirectX 11-compatible GPU.\n\nDownload: KG Series (Windows-only)\n\nMore:\n\nLast Updated on September 9, 2025 by Tomislav Zlatic.",
      "source": "Bedroomproducersblog.com",
      "url": "https://bedroomproducersblog.com/2025/09/09/kg-series/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "America’s Richest Sports Team Owners 2025",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/justinbirnbaum/2025/09/09/americas-richest-sports-team-owners-2025/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Orange Rivers in Alaska Signify a Color-Changing Crisis, Exposing Fish to Toxic Metals",
      "content": "In the northern Alaskan wilderness, a bizarre symptom of climate change is emerging: The rivers there are turning unnaturally orange. This phenomenon paints a worrisome picture for watersheds all across the Arctic, now faced with toxic metals being released by melting permafrost.\n\nA new study published in the Proceedings of the National Academy of Sciences shows how orange rivers may start to become a familiar sight in the Arctic as the planet warms. But for ecosystems like those along the Brooks Range — a mountain range stretching from northern Alaska to Canada’s Yukon Territory — the color change underlies a host of problems.\n\nThe Rivers Turning Orange\n\nWhen the water in a river or stream appears orange, it usually comes as a byproduct of mining activities. Oftentimes, sulfide minerals within abandoned mines are exposed to air and water, causing them to oxidize.\n\nThis process, called acid mine drainage (AMD), creates dissolved iron that changes the color of streams as it precipitates to form red, orange, or yellow sediments at the bottom of a stream. AMD also infuses streams with sulfuric acid that dissolves other heavy metals like copper, lead, and mercury into the water.\n\nThese rust-colored, highly acidic streams are often found where surface coal mining is prevalent — in the U.S., it occurs mostly in Central Appalachia and the Great Plains.\n\nBut much farther north, the orange rivers observed in the Brooks Range have nothing to do with AMD. The color-changing culprit, instead, is melting permafrost.\n\n“This is what acid mine drainage looks like,” said author Tim Lyons, a biogeochemist at the University of California, Riverside, in a statement. “But here, there’s no mine. The permafrost is thawing and changing the chemistry of the landscape.”\n\nRead More: Climate Change Threatens Global Milk Supply, Even On Cooled Dairy Farms\n\nA Toxic Threat to Fish\n\nThe new study shows how the thawing of permafrost due to global warming is letting water and oxygen reach sulfide minerals that have been confined underground for thousands of years. The weathering of sulfide-rich rocks is now delivering iron and other metals to rivers, turning them orange just like AMD would.\n\nThe new study is centered around the Salmon River, which had clear water up until the summer of 2019, when it began to show signs of discoloration that still persist to this day.\n\nAdvertisement\n\nThe researchers involved with the study were determined to find out just how toxic the river has become. After three sampling dates between August 2022 and August 2023, they found that the levels of metals in the river’s waters exceeded the EPA’s toxicity thresholds for aquatic life.\n\nMost alarming is the concentration of dissolved cadmium detected in the Salmon River. This metal, normally rare in aquatic ecosystems, is highly toxic to aquatic organisms. It can accumulate on the tissues of fish and trigger neurotoxic effects, leading to erratic behaviors that contribute to mortality. Bears and other mammals that eat fish with high cadmium levels could also suffer from oxidative stress and DNA damage.\n\nAdvertisement\n\nNonstop Melting in the Arctic\n\nThe researchers say that current metal concentrations in edible fish tissue aren’t considered hazardous to humans, although the effects on some species may have additional indirect consequences. For example, chum salmon, eaten by many Indigenous communities in the area, may have trouble spawning in gravel beds congested with fine sediment.\n\nBeyond the Salmon River, other Arctic watersheds have already begun to see the effects of permafrost thaw. One 2024 study found that 75 streams in the Brooks Range had recently turned orange and turbid (or cloudy) from an abundance of iron and toxic metals.\n\nWith so many potential contamination sources and no infrastructure in place to stop this process from occurring, the pattern of continued permafrost thaw will likely spread to more rivers across the Arctic.\n\n“There are few places left on Earth as untouched as these rivers,” said Lyons. “But even here, far from cities and highways, the fingerprint of global warming is unmistakable. No place is spared.”\n\nAdvertisement\n\nRead More: Permafrost Thaw and Wildfires Are Raising CO2 Emissions in Arctic Tundras\n\nArticle Sources\n\nOur writers at Discovermagazine.com use peer-reviewed studies and high-quality sources for our articles, and our editors review for scientific accuracy and editorial standards. Review the sources used below for this article:",
      "source": "Discover Magazine",
      "url": "https://www.discovermagazine.com/orange-rivers-point-to-a-colorful-crisis-in-alaska-exposing-fish-to-toxic-metals-48011",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Axelera Metis M.2 Max Edge AI module doubles LLM and VLM processing speed",
      "content": "Axelera AI’s Metis M.2 Max is an M.2 module based on an upgraded Metis AI processor unit (AIPU) delivering twice the memory bandwidth of the current Metis M.2 module for compute-intensive Edge AI inference applications such as large language models (LLMs) and vision language models (VLMs).\n\nThe new Metis M.2 Max also offers a slimmer profile, advanced thermal management features, and additional security capabilities. It is equipped with up to 16 GB of memory, and versions for both a standard operating temperature range (-20°C to +70°C) and an extended operating temperature range (-40°C to +85°C) will be offered. These enhancements make Metis M.2 Max ideal for applications in industrial manufacturing, retail, security, healthcare, and public safety.\n\nAxelera AI Metis M.2 Max specifications and host requirements:\n\nAccelerator – Metis AIPU’\n\nSystem Memory – 1GB, 4GB, 8GB, or 16GB memory\n\nHost Interface – M.2 2280 M-key edge connector with PCIe Gen. 3.0 x4\n\nCompatibility – Intel Core processors, AMD Ryzen processors, Arm64 (aarch64) based processors.\n\nSecurity – Firmware integrity via secure boot and secure upgrade features built on a hardware Root-of-Trust\n\nMisc An onboard power probe that can be used to automatically adjust performance to specific settings for power- and thermal-constrained deployments. Optional low-profile heatsink for cooling (reduces the height of the card by 27% over the current M.2 card)\n\nPower – Compliant with PCI-SIG’s M.2 Specification revision 4.0 (11.55 W average power, 23.1 W peak power).\n\nTemperature Range Standard – -20°C to +70°C Extended – -40°C to +85°C\n\n\n\nLike the previous Metis M.2 module, the Max variant is supported by the Voyager SDK. Axelera AI claims that native Linux support is tested on Ubuntu 22.04, while a docker guide (sign-in required) is available for other Linux distributions.\n\nThe company provides additional information about performance in the press release:\n\nM.2 Max delivers a 33% performance uplift in convolutional neural networks (CNNs) and double the token/second for LLMs and VLMs, all while staying within a typical average power range of 6.5W.\n\nInterestingly, they’ve not included any information about TOPS this time around, or even clear benchmark results. For reference, the Metis AIPU can deliver up to 214 TOPS, albeit likely not in the M.2 form factor.\n\nThe Metis M.2 Max will start shipping in Q4 2025. It is listed on the Axelera webstore without price information for now, but for reference, the existing Metis M.2 card is sold for €229,95 without a cooling solution or €241,95 with the active cooling solution shown above. The new model should be more expensive, maybe in the 300 to 400 Euros range.\n\nThanks to TLS for the tip.\n\nJean-Luc started CNX Software in 2010 as a part-time endeavor, before quitting his job as a software engineering manager, and starting to write daily news, and reviews full time later in 2011.\n\nShare this:\n\nSupport CNX Software! Donate via cryptocurrencies, become a Patron on Patreon, or purchase goods on Amazon or Aliexpress. We also use affiliate links in articles to earn commissions if you make a purchase after clicking on those links.",
      "source": "CNX Software",
      "url": "https://www.cnx-software.com/2025/09/09/axelera-metis-m-2-max-edge-ai-module-doubles-llm-and-vlm-processing-speed/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Acrobat Pro DC 2025.001.20693",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-acrobat-pro-dc-2025-001-20693/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD expands FSR 4 with drop-in support for 85 games with latest Radeon driver update - but you still need an RDNA 4 GPU",
      "content": "AMD’s latest Radeon driver update (Adrenalin Edition 25.9.1) is expanding support for FSR 4 upscaling and frame generation. According to the official patch notes, FSR 4 can now be enabled in most DirectX 12 titles that already support FSR 3.1. With the latest update, FSR 4 is now compatible with 85 games in total, however it is still limited to RDNA 4-based Radeon 9000 series GPUs.\n\nIn a separate announcement post, AMD has explained how this works and notes that enabling FSR 4 through its new driver update is a pretty seamless process. Once users update to the latest Adrenalin Edition driver, their Radeon RX 9000 Series graphics cards should automatically gain access to FSR 4. Additionally, users need to switch to FSR 3.1 in their supported game settings and then toggle FSR 4 within AMD”s Adrenalin Edition software. This enables the driver to override the in-game FSR 3.1 implementation with the newer FSR 4 version.\n\nThe company has also made it clear that this works only with DirectX 12 titles that have integrated a signed FSR 3.1 DLL as per AMD’s developer guidelines. Any games running on Vulkan, or those that use non-standard methods such as third-party plug-ins, are not compatible with the FSR 4 driver upgrade.\n\nDespite this update, AMD’s upscaling technology still trails Nvidia’s DLSS in terms of adoption and flexibility. In the meantime, community developers have stepped in with tools like OptiScaler, which can reroute existing upscalers such as DLSS, XeSS, or FSR 2 into FSR 4 with frame generation, effectively widening its reach. Similarly, certain GitHub users pointed out that FSR 3.1 games can be upgraded to FSR 4 by simply replacing the game's FSR 3.1 DLL files manually with DLL files from AMD's latest FSR SDK 2.0, although these unofficial solutions may have limitations.\n\nJust last month, the company accidentally uploaded the full FSR 4 source code to GitHub while updating its FidelityFX SDK, revealing work on an alternate int8-based version of the upscaler. This suggests AMD might be preparing broader GPU support for FSR 4 beyond its current RDNA 4 hardware.\n\n\n\nFor now, AMD’s official rollout of FSR 4 ensures stability and broader compatibility for supported titles, but the modding community’s efforts suggest a strong demand for wider adoption.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/gpu-drivers/amd-expands-fsr-4-with-drop-in-support-for-85-games-with-latest-radeon-driver-update-but-you-still-need-an-rdna-4-gpu",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Stocks Settle Higher on Hopes of Accelerated Fed Rate Cuts",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/34703550/stocks-settle-higher-on-hopes-of-accelerated-fed-rate-cuts",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Citron gets full rewrite, promises better Nintendo Switch emulation on Android and PC",
      "content": "The Nintendo Switch emulator Citron has received a long-overdue update. This release is said to be a \"complete ground-up rewrite,\" and the devs are promising significant improvements and better emulation performance.\n\n4 Reviews ← exclude selected types\n\nWhile the Nintendo Switch emulation scene got a little muddy after a popular emulator, Sudachi, was shut down, the team behind Citron has brought some good news. The Yuzu fork has just been updated to version 0.7, and per the developers, it's a \"complete ground-up rewrite.\"\n\nWith such a major overhaul, there's a big potential for a significant emulation performance bump. Most notably, the Vulkan rendering pipeline has been overhauled in the new update of Citron, and many core components of the Nintendo Switch emulator have been rewritten.\n\nAnother notable highlight is the implementation of AMD FSR 2, but as the devs note, it's currently \"half-baked and experimental.\" This means that the Nintendo Switch emulator for Android and PC could throw random crashes, and there could be visual glitches.\n\nGame compatibility issues may also arise when trying to emulate the Nintendo Switch games with FSR 2 on the emulator. Speaking of which, with support for a more recent firmware, Citron now has better compatibility for Nintendo Switch games than before (multi-platform EasySMX X20 controller curr. $49.78 on Amazon).\n\nTo be specific, with the update, Citron works with firmware 20.4.0. This is a big highlight when compared to Eden, which is also a Switch emulator, as the latter has support for firmware 19.0.1.\n\nOther than that, as the Citron version 0.7 is a complete rewrite, the devs warn that there could be UI/UX problems, memory leaks, and audio sync issues. Regardless, this update marks major progress in the development of the Nintendo Switch emulator, as the last notable update was in March 2025. For those interested in giving the update a try, it's available on the official website.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Citron-gets-full-rewrite-promises-better-Nintendo-Switch-emulation-on-Android-and-PC.1110069.0.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Windows 11 KB5065426 & KB5065431 cumulative updates released",
      "content": "Microsoft has released Windows 11 KB5065426 and KB5065431 cumulative updates for versions 24H2 and 23H2 to fix security vulnerabilities and issues.\n\nToday's updates are mandatory as they contain the September 2025 Patch Tuesday security patches for vulnerabilities discovered in previous months.\n\nYou can install today's update by going to Start > Settings > Windows Update and clicking on 'Check for Updates.'\n\nWindows Update (KB5065426)\n\nYou can also manually download and install the update from the Microsoft Update Catalog.\n\nIf you use Windows 11 Enterprise or Windows Server with Hotpatch, you'll see KB5065474 and it includes the same set of fixes, but the build number is 26100.6508.\n\nWhat's new in the September 2025 Patch Tuesday update\n\nAfter installing today's security updates, Windows 11 24H2 (KB5065426 ) will have its build number changed to Build 26100.6584, and 23H2 (KB5065431) will be changed to 226x1.5909.\n\nIn case of Windows 11 23H2, Microsoft warned that support for 23H2 ends on November 11, 2025. You'll be either force upgraded to 24H2 or stop receiving updates after the deadline.\n\nHere's the full list of improvements:\n\n[Recall] New! Recall opens to a personalized homepage that puts your recent activity and top-used apps and websites front and center, making it easy to pick up where you left off. After turning on snapshot collection, the homepage highlights key productivity features like Recent Snapshots , which show the latest snapshots to help you quickly resume tasks, and Top Apps and Websites , which display the three apps and websites you’ve used most in the past 24 hours. You can set filters in Settings to control which apps and websites are saved in snapshots. A new navigation bar on the leftmost side of the screen provides quick access to Home, Timeline, Feedback, and Settings.\n\n[Click to Do] New! When you launch Click to Do for the first time, you'll see a quick interactive tutorial. It shows how to complete tasks faster by demonstrating actions on both text and images—such as summarizing large blocks of text or removing image backgrounds. To revisit the tutorial later, select More options > Start tutorial .\n\n[General] New! When an app requests access to location, camera, microphone, or other device capabilities, Windows shows a redesigned system dialog box. To emphasize the privacy prompt, the screen dims slightly, and the prompt appears at the center of the screen.\n\n[Taskbar] New! The larger clock with seconds is now back in the notification center, displayed above the date and calendar. To turn this option on, go to Settings > Time & language > Date & time , and turn on Show time in the Notification Center . Fixed: If you accidentally click and drag your mouse across the taskbar preview thumbnail, the preview might stop working.\n\n[Search on the Taskbar] New! ​​​​​​​ When you use Search from the Windows taskbar , a new grid view will help you more quickly and accurately identify the desired image within your search. New! Search on the taskbar now provides clearer status information. If your search results are incomplete while your PC is organizing files in the background, Windows shows a notice with a link to check progress. You can dismiss the notice when you're done. There is also a status for files and folders, so you can easily tell whether they’re available online (cloud) or stored on your device.\n\n[Lock screen] New! ​​​​​​​ More widget options and support for lock screen widget personalization (previously referred to as “Weather and more”) are rolling out. After initial launch with Windows Insiders in the European Economic Area (EEA), these updates are expanding to all regions. You can add, remove, and rearrange lock screen widgets such as Weather, Watchlist, Sports, Traffic, and more. Any widget that supports the small sizing option can be added. To customize your lock screen widgets, go to Settings > Personalization > Lock screen .\n\n[File Explorer] ​​​​​​​​​​​​​​ New! Dividers now separate top-level icons in the File Explorer context menu. New! ​​​​​​​ When you're signed in with a work or school account (Entra ID), File Explorer will display people icons in the Activity column and the Recommended section at the top of File Explorer Home. Hover over or select a person's icon to open their Microsoft 365 Live Persona Card, which shows who they are and how they're connected to the file. Fixed: If you try to use the unblock open in Properties for a file, it still shows as blocked when you open Properties the next time.\n\n[Windows Hello] New! ​​​​​​​ As part of the enhanced passkey features released in September 2023, you’ll see a redesigned Windows Hello interface. These modernized visual updates support fast, clear communication that appear across multiple authentication flows, including the Windows sign-in screen, passkey, Recall, the Microsoft Store, and more.\n\n\n\nThe Windows security credential experience for passkey offers a cleaner, more intuitive interface designed to support fast, secure sign-in. You can now easily switch between authentication options such as passkeys or connected devices. Fixed: Windows Hello might recognize your face on the login screen, however it would still fail and then prompt you to enter your pin. If you continue experiencing issues, you might need to go to the Facial Recognition section under Settings > Accounts > Sign-in options and select Improve recognition . Improved: Fingerprint login after standby is now more robust.\n\n[Settings] New! Windows activation and expiration prompts match the Windows 11 design and appear as system notifications when action is required. There also have been improvements to messaging under Settings > System > Activation . New! You can go to Settings > Privacy & security > Text and Image Generation to see which third-party apps have recently used generative AI models provided by Windows. You can also choose which apps are permitted to use them—putting you in charge of your device’s AI experience. New! As part of the Copilot+ PC experience, the agent in Settings helps you quickly find and change settings. Initially available on Snapdragon®-powered Copilot+ PCs, agent in Settings now supports AMD- and Intel™-powered Copilot+ PCs. It currently works only when your primary display language is set to English. Fixed: Settings might crash if you attempt to add a security key under Settings > Account > Sign-in options .\n\n[Task Manager] New! Task Manager now uses standard metrics to show CPU workload consistently across all pages, aligning with industry standards and third-party tools. If you prefer the previous view, you can enable a new optional column called CPU Utility in the Details tab to display the earlier CPU usage value shown on the Processes page.\n\n[Widgets] ​​​​​​​​​​​​​​ New! Multiple dashboards are now available in your Widgets Board . This gives you more space for your favorite widgets and helps you stay informed with a feed that connects you to current events. A new navigation bar on the left side makes it easy to switch between your widget’s dashboard and other views like the Discover feed. After initial launch in the EEA, these updates are expanding to all regions. New! A new visual experience is available for the Discover feed on the Widgets Board . The layout is more organized, personalized, and engaging. Copilot-curated stories are now included, offering a well-rounded view of each topic with summaries, videos, and images from trusted MSN premium publishers. To customize your feed, go to Widgets > Discover dashboard > Personalization settings .\n\n[Windows Backup for Organizations] New! ​​​​​​​ Windows Backup for Organizations is now generally available! Experience seamless device transitions with enterprise-grade backup and restore. Whether you're refreshing your organization’s devices, upgrading to Windows 11, or deploying AI-powered PCs, this solution helps sustain productivity with minimal disruption, ensuring business continuity and organizational resilience.\n\n[PowerShell 2.0] Starting in August 2025, Windows 11, version 24H2, will no longer include Windows PowerShell 2.0. This legacy component was introduced in Windows 7 and officially deprecated in 2017. Most users won’t be affected, as newer versions such as PowerShell 5.1 and PowerShell 7.x remain available and supported. If you use older scripts or tools that depend on PowerShell 2.0, update them to avoid compatibility issues.\n\n[Live captions] Fixed: Changing the opacity of live captions in Settings > Accessibility > Captions > Caption Style , has no effect.\n\n[Input] Fixed: Attempting to type Chinese with an IME after copying something with CTRL + C can result in the first character not displaying. Fixed: An underlying issue related to textinputframework.dll could result in certain apps like Sticky Notes and Notepad crashing.\n\n[dbgcore.dll] Fixed: An underlying issue with dbgcore.dll could result in certain apps, including explorer.exe, crashing.\n\n[Kerberos] ​​​​​​​ Fixed: There might be an underlying crash in Kerberos when attempting to access a cloud file share.\n\n[Login] Improved: Addressed some underlying cases which could lead to you seeing a blank white screen, or a screen saying, \"just a moment\", for a few minutes when logging into your PC.\n\n[Miracast] Fixed: An issue where, on certain devices, audio would initially play but stop a few seconds after casting to a TV.\n\n[Audio] Improved: Addressed an underlying audio service stops responding which could impact the ability to play audio in certain cases.\n\n[Cryptographic Provider (known issue)] Fixed: Fixed: This update addresses an issue where you might see an error in Windows Event Viewer with Error ID 57. The event displays the following message: The 'Microsoft Pluton Cryptographic Provider' provider was not loaded because initialization failed.\n\nMost of these changes are rolling out gradually, so they'll not show up right away.\n\nMicrosoft is not currently aware of any issues with this update.",
      "source": "BleepingComputer",
      "url": "https://www.bleepingcomputer.com/news/microsoft/windows-11-kb5065426-and-kb5065431-cumulative-updates-released/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Cohere looks to shed its underdog status with a star AI hire, new CFO and $7 billion valuation — chasing ‘ROI over AGI’",
      "content": "In interviews with Fortune, Pineau, new CFO Francois Chadwick (who was previously acting CFO at Uber) and cofounder Frosst emphasized Cohere’s focus on the enterprise market. While rivals race toward human-like artificial general intelligence (AGI), Cohere is betting that businesses want something simpler: tools that deliver ROI today.\n\nUnlike peers that have tied themselves closely to Big Tech cloud providers—or, in some cases, sold outright—Cohere has resisted acquisition offers and avoided dependence on any single cloud ecosystem. “Acquisition is failure—it’s ending this process of building,” Gomez, Cohere’s CEO, recently said at a Toronto Tech Week event. The company also leans into its Canadian roots, touting both its Toronto headquarters and lucrative contracts with the Canadian government, even as it maintains a presence in Silicon Valley and an office in London.\n\nCohere was founded in 2019 by three Google Brain alumni — Nick Frosst, Ivan Zhang and Aidan Gomez, a coauthor on the seminal 2017 research paper, titled “Attention Is All You Need,” that jump-started the generative AI boom. According to Frosst, in May the startup reached $100 million in annual recurring revenue. It’s an important milestone, and there have been unconfirmed reports that Cohere projects doubling that by the end of year. But it is still a fraction of what larger rivals like Anthropic and OpenAI are generating.\n\nPineau announced her departure from Meta in April, just weeks before Mark Zuckerberg unveiled a sweeping AI reorganization that included acquiring Scale AI, elevating its cofounder Alex Wang to chief AI officer, and launching a costly spree to poach dozens of top researchers. For Cohere, her arrival is a coup and a reputational boost at a moment when many in the industry wondered whether the company could go the distance—or whether it would be acquired or fade away.\n\nCohere, the Toronto-based startup building large language models for business customers, has long had a lot in common with its hometown hockey team, the Maple Leafs. They are a solid franchise and a big deal in Canada, but they’ve not made a Stanley Cup Final since 1967. Similarly, Cohere has built a string of solid, if not spectacular, LLMs and has established itself as the AI national champion of Canada. But it’s struggled for traction against better-known and better-funded rivals like OpenAI, Anthropic, and Google DeepMind. Now it’s making a renewed bid for relevancy: Last month the company raised $500 million, boosting its valuation to nearly $7 billion; hired its first CFO; and landed a marquee recruit in Joelle Pineau, Meta’s longtime head of AI research.\n\nStory continues\n\nA focus on ROI over AGI\n\n“We have been under the radar a little bit, I think that’s fair,” cofounder Nick Frosst said. “We’re not trying to sell to consumers, so we don’t need to be at the top of consumer minds—and we are not.” Part of the reason, he added with a laugh, is cultural: “We’re pretty Canadian. It’s not in our DNA to be out there talking about how amazing we are.”\n\n\n\nFrosst did, however, tout the billboards that recently debuted in San Francisco, Toronto and London, including one for Cohere’s North AI platform that says “AI that can access your info without giving any of it away.”\n\nThat quiet approach is starting to shift, he said, a reflection of the traction it’s seeing with enterprise customers like the Royal Bank of Canada, Dell and SAP. Cohere’s pitch, he argued, is “pretty unique” among foundation model companies: a focus on ROI, not AGI.\n\n\n\n“When I talk to businesses, a lot of them are like, yeah, we made some cool demos, and they didn’t get anywhere. So our focus has been on getting people into production, getting ROI for them with LLMs,” he said. That means prioritizing security and privacy, building smaller models that can run efficiently on GPUs, and tailoring systems for specific languages, verticals and business workflows. Recent releases such as Command A (for reasoning) and Command A Vision are designed to hit “top of their class” performance while still fitting within customers’ hardware budgets.\n\nIt also means resisting the temptation to chase consumer-style engagement. On a recent episode of the 20VC podcast, Frosst said Cohere isn’t trying to make its models chatty or addictive. “When we train our model, we’re not training it to be an amazing conversationalist with you,” he said. “We’re not training it to keep you interested and keep you engaged and occupied. We don’t have engagement metrics or things like that.”\n\nLack of drama is ‘wonderful’\n\nFor Pineau—who at Cohere will help oversee strategy across research, product, and policy teams—the company’s low-key profile was part of the appeal. The absence of drama, she said, is “wonderful” — and “a good fit for my personality. I prefer to fly a little bit under the radar and just get work done.”\n\nPineau, a highly-respected AI scientist and McGill University professor based in Montreal, was known for pushing the AI field to be more rigorous and reproducible. At Meta, she helmed the Fundamental AI Research (FAIR) lab, where she led the development of company’s family of open models, called Llama, and worked alongside Meta’s chief scientist Yann LeCun.\n\nThere was certainly no absence of drama in her most recent years at Meta, as Mark Zuckerberg spearheaded a sweeping pivot to generative AI after OpenAI debuted ChatGPT in November 2022. The strategy created momentum, but Llama 4 flopped when it was released in early April 2025—at which point, Pineau had already submitted her resignation. In June, Zuckerberg handed 28-year-old Alex Wang control of Meta’s entire AI operations as part of a $14.3 billion investment in Scale AI. Wang now leads a newly formed “Superintelligence” group packed with industry stars paid like high-priced athletes, and oversees Meta’s other AI product and research teams under the umbrella of Meta Superintelligence Labs.\n\nPineau said Zuckerberg’s plans to hire Wang did not contribute to her decision to leave. After leaving Meta, she had several months to decide her next steps: Based in Montreal, where Cohere is opening a new office, Pineau said she had been watching the company closely: “It’s one of very few companies around the world that I think has both the ambition and the abilities to train foundation models at scale.”\n\nWhat stood out to her was not leaderboard glory but enterprise pragmatism. For example, much of the industry chases bragging rights on public benchmarks, which rank models on tasks like math or logic puzzles. Pineau said those benchmarks are “nice to have” but far less relevant than making models work securely inside a business. “They’re not necessarily the must-have for most enterprises,” she said. Cohere, by contrast, has focused on models that run securely on-premise, handle sensitive corporate data, and prioritize characteristics like confidentiality, privacy and security.\n\n“In a lot of cases, responsibility aspects come late in the design cycle,” she said. “Here, it’s built into the research teams, the modeling approach, the product.” She also cited the company’s “small but mighty” research team and its commitment to open science — values that drew her to Meta years earlier.\n\nPineau considered returning to academia, but the pace and scale of today’s AI industry convinced her otherwise. “Given the speed at which things are moving, and the resources you need to really have an impact, having most of my energies in an industry setting is where I’m going to be closer to the frontier,” she said. “While I considered both, it wasn’t a hard choice to jump back into an industry role.”\n\nHer years at Meta, where she rose to lead a global research organization and spent 18 months in Zuckerberg’s inner leadership circle, left her with lessons she hopes to apply at Cohere: how to bridge research and product, navigate policy questions, and think through the societal implications of technology. “Cohere is on a trajectory to play a huge role in enterprise, but also in important policy and society questions,” she said. “It’s an opportunity for me to take all I’ve learned and carry it into this new role.”\n\nThe Cohere leadership moved quickly. “When we found out she was leaving Meta, we were definitely very interested,” Frosst said, although he denied that the hire was intended as a poke at Meta CEO Mark Zuckerberg. “I don’t think about Zuck that often,” he said. “[Pineau is] a legend in the community — and building with her in Montreal, in Canada, is particularly exciting.”\n\nA move to growth and path to profitability\n\nPineau is not Cohere’s only new big league hire. It also tapped Chadwick, an Uber alum who served there as acting CFO. “I was the guy that put Uber in over 100 countries,” he noted. “I want to bring that skill set here—understanding how to scale, how to grow, and continue to deliver.”\n\nWhat stands out to him about Cohere, he explained, is the economics of its enterprise-focused business model. Unlike consumer-facing peers that absorb massive compute costs directly onto their own balance sheets, Cohere’s approach shifts much of that burden to partners and customers who pay for their own inference. “They’re building and implementing these systems in a way that ensures efficiency and real ROI—without the same heavy drag on our P&L for compute power,” he said.\n\nThat contrasts with rivals like Anthropic, which The Information recently reported has grown to $4 billion in annualized revenue over the last six months but is likely burning far more cash in the process. OpenAI, meanwhile, has reportedly told investors it now expects to spend $115 billion through 2029—an $80 billion increase from prior forecasts—to keep up with the compute demands of powering ChatGPT.\n\nFor Chadwick, that means Cohere’s path to profitability looks markedly different than other generative AI players. “I’m going to have to get under the hood and look at the numbers more, but I think the path to profitability will be much shorter,” he said. “We probably have all the right levers to pull to get us there as quickly as possible.”\n\nDaniel Newman, CEO of research firm The Futurum Group, agreed that as OpenAI and Anthropic valuations have ballooned to eye-watering levels while burning through cash, there is a strong need for companies like Cohere (as well as the Paris-based Mistral) which are providing specialized models for regulated industries and enterprise use cases.\n\n“I believe Cohere has a unique opportunity to zero in on the enterprise AI opportunity, which is more nascent than the consumer use cases that have seen remarkable scale on platforms like OpenAI and Anthropic,” he said. “This is the intersection of software-as-a-service companies, of cloud and hyperscalers, and some of these new AI companies like Cohere.”\n\nStill, others say it’s too early for Cohere to declare victory. Steven Dickens, CEO and principal analyst at Hyperframe Research, said the company “has a ways to go to get to profitability.” That said, he agreed that the recent capital raise “from some storied strategic investors” is “a strong indication of the progress the company has made and the trajectory ahead.”\n\n\n\nAmong those who participated in the most recent $500 million venture capital round for Cohere were the venture capital arms of Nvidia, AMD, and Salesforce, also of which might see Cohere as strategic partner. The round was led by venture capital firms Radical Ventures and Inovia Capital, with PSP Investments and Healthcare of Ontario Pension Plan also joining the round.\n\nVindication in ‘vibe shift’ away from AGI\n\nFor his part, Frosst sees some vindication in the rest of the industry’s recent “vibe shift” away from framing AGI as the sector’s monocular goal. In a way, the rest of the industry is moving towards the position Cohere has already staked out.\n\n\n\nBut Cohere’s skepticism about AGI hasn’t always felt comfortable for the company and its cofounders. Frosst said it’s meant that he has found himself in disagreement with friends who believe throwing more computing power at LLMs will get the world closer to AGI. Those include his mentor and fellow Torontonian Geoffrey Hinton, widely known as the “godfather of AI,” who has said that “AGI is the most important and potentially dangerous technology of our time. “\n\n“I think it’s credibility-building to say, ‘I believe in the power of this technology exactly as powerful as it is,’” Frosst said. He and Hinton may differ, but it hasn’t affected their friendship. “I think I’m slowly winning him over,” he added with a laugh — though he acknowledged Hinton would probably deny it.\n\nAnd Cohere, too, is hoping to win over more than friends — by convincing enterprises, investors, and skeptics alike that ROI, not AGI, is the smarter bet. The Toronto Maple Leafs of AI thinks it might just win the Stanley Cup yet.\n\nThis story was originally featured on Fortune.com",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/cohere-looks-shed-underdog-status-184430417.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Clearside Biomedical, Inc. (NASDAQ:CLSD) Receives $4.20 Average PT from Analysts",
      "content": "Clearside Biomedical, Inc. (NASDAQ:CLSD – Get Free Report) has earned a consensus recommendation of “Hold” from the six ratings firms that are presently covering the stock, MarketBeat reports. Five analysts have rated the stock with a hold recommendation and one has given a buy recommendation to the company. The average 12 month price objective among brokerages that have covered the stock in the last year is $4.20.\n\nA number of research firms have recently issued reports on CLSD. Chardan Capital cut shares of Clearside Biomedical from a “buy” rating to a “neutral” rating in a research report on Friday, July 18th. Needham & Company LLC cut shares of Clearside Biomedical from a “moderate buy” rating to a “hold” rating and set a $3.00 price objective on the stock. in a research report on Thursday, July 17th. HC Wainwright cut shares of Clearside Biomedical from a “buy” rating to a “neutral” rating and set a $5.00 price objective on the stock. in a research report on Friday, July 18th. Wall Street Zen raised shares of Clearside Biomedical from a “sell” rating to a “hold” rating in a research report on Saturday, May 17th. Finally, Jones Trading cut shares of Clearside Biomedical from a “strong-buy” rating to a “hold” rating in a research report on Thursday, July 17th.\n\nGet Clearside Biomedical alerts:\n\nCheck Out Our Latest Analysis on Clearside Biomedical\n\nHedge Funds Weigh In On Clearside Biomedical\n\nClearside Biomedical Price Performance\n\nA hedge fund recently bought a new stake in Clearside Biomedical stock. Investor s Fiduciary Advisor Network LLC purchased a new stake in Clearside Biomedical, Inc. ( NASDAQ:CLSD Free Report ) during the 4th quarter, according to the company in its most recent disclosure with the Securities and Exchange Commission. The firm purchased 33,800 shares of the company’s stock, valued at approximately $32,000. Hedge funds and other institutional investors own 18.75% of the company’s stock.\n\nCLSD stock opened at $0.34 on Friday. The stock has a market capitalization of $26.39 million, a PE ratio of -0.91 and a beta of 2.11. The company’s 50-day moving average is $0.52 and its 200-day moving average is $0.74. Clearside Biomedical has a 1 year low of $0.29 and a 1 year high of $1.65.\n\nClearside Biomedical (NASDAQ:CLSD – Get Free Report) last released its quarterly earnings data on Friday, August 8th. The company reported ($0.06) earnings per share (EPS) for the quarter, topping analysts’ consensus estimates of ($0.12) by $0.06. The company had revenue of $0.49 million for the quarter, compared to the consensus estimate of $0.50 million. On average, analysts anticipate that Clearside Biomedical will post -0.48 earnings per share for the current fiscal year.\n\nAbout Clearside Biomedical\n\n(Get Free Report)\n\nClearside Biomedical, Inc, a biopharmaceutical company, focuses on the revolutionizing the delivery of therapies to the back of the eye through the suprachoroidal space. It offers XIPERE, a triamcinolone acetonide suprachoroidal injectable suspension for the treatment of uveitis macular edema. It also develops CLS-AX, an axitinib injectable suspension for suprachoroidal injection, which is in Phase IIb clinical trial to treat wet AMD.\n\nFeatured Articles\n\nReceive News & Ratings for Clearside Biomedical Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Clearside Biomedical and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/09/clearside-biomedical-inc-nasdaqclsd-receives-4-20-average-pt-from-analysts/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Why Trump Went To Riyadh And What He Achieved",
      "content": "Middle East\n\nDetermining America's Role in the World\n\nAs he had done in his previous term, Donald Trump made the first foreign visit of his second term to Saudi Arabia. He had sound reasons for doing so. Saudi Arabia remains an important and stable leader in an important, but very unstable part of the world. Whether you want to secure moderate oil prices, maintain peace in the Middle East, resolve the Arab Israeli conflict or confront terrorism, it helps to talk to the Saudis. Saudi Arabia is also changing in ways that the United States has long encouraged and now seeks to support.\n\nUnfortunately, Saudi American relations had deteriorated under the Biden administration while Russia and China had become increasingly important players in Riyadh. Russia is now Saudi Arabia’s most important partner in the OPEC+ oil cartel. China is now the Saudis largest trading partner and most important oil customer. The United States has been losing influence in Riyadh, and Trump needed to reset the relationship.To a considerable extent, he succeeded.\n\nDespite plans for transition away from hydrocarbons, oil and gas remain the dominant fuels on our planet. No price affects the American economy more than the price of oil and that price is determined in a global market. Far from declining, global oil demand continues to rise by about 1 percent a year. While the United States imports very little Saudi oil, key allies such as Japan, Taiwan and South Korea remain heavily dependent on Saudi supplies.\n\nSaudi Arabia is the world’s largest oil exporter. It possesses large reserves that are both inexpensive to produce and easy to transport. At current production rates, its reserves will last at least another 50 years. More importantly, Saudi Arabia is the only country in the world that can quickly bring large volumes of oil into the market. It is this surge capacity, not its total reserves or current production rates, that make Saudi Arabia the central bank of oil.\n\nThe Saudis certainly want to maximize their oil revenues, but they have learned from bitter experience that excessively high or excessively volatile oil prices will destroy demand. Unlike many producers with limited reserves, the Saudis are long term players. They are more interested in keeping oil part of the global energy mix than maximizing short-term profits. It is in their self-interest to support global economic growth and not create a global recession as they did with the 1973 oil embargo. Thus, the Saudis increase oil production as often as they reduce it. They have often helped calm markets when supplies were interrupted by war, weather, labor unrest or U.S. imposed economic sanctions. It is very much in America’s interest that Saudi Aramco, the world’s largest oil company, remains well managed, responsive to global energy needs and based in a politically stable country.\n\nLike the United States, Saudi Arabia has a lot to lose from political unrest in the Middle East. On numerous occasions Saudi financial aid and political intervention have supported stability in places like Lebanon, Syria, Jordan and Egypt. Saudi kings Fahd, Abdullah and Salman all sought a settlement of the Arab Israeli conflict and consistently encouraged other Arab states in that direction. While Saudi Arabia is not a militarily powerful nation, its geographic location and purchasing power make it important to the U.S. military. Many times large Saudi arms purchases have reduced the unit cost paid by the American military and helped keep American defense industry production lines open. All of these issues were on the table during President Trump’s visit.\n\nFinally, talking with the Saudis is important because a quarter of the human race turns to Mecca in prayer five times a day. Millions more travel there every year for the Hajj. What is preached from the pulpit in Mecca shapes public opinion across the Muslim world. As Custodian of the Two Holy Mosques, the King of Saudi Arabia has the prestige, as well as the financial resources, to influence political outcomes in dozens of Muslim countries. Saudi-based multilateral bodies such as the Organization of Islamic Cooperation, the Islamic Development Bank and the Muslim World League all amplify Saudi influence in the Muslim World. Today the Saudis are actively promoting a moderate version of Islam as well as tolerant social practices which can serve as a model for other Muslim nations. The president sought to recognize and support those policies.\n\nFor many years oil prices and counterterrorism were often the focus of presidential visits to Riyadh, but not this time. In May of 2025, oil prices had come down from $100 a barrel in 2022 to only $65 a barrel and OPEC was, in fact, gradually increasing production. With Saudi support, the War on Terror had largely been won. The Saudis had defeated a local Al Qaeda insurrection, tightened controls on their charities, removed or retrained hundreds of mosque preachers, jailed the most radical imams and revised their school textbooks. Neither Al Qaeda nor ISIS posed a significant threat to either Saudi Arabia or the United States.\n\nInstead, as might be expected, President Trump sought to strengthen Saudi American ties through trade and investments. Not since 1973 when Secretary of State Henry Kissinger sought to tie the Saudi economy to American prosperity had there been such an intense effort to recycle petrol dollars back to the United States. Only this time most of those recycled dollars did not come directly from the United States, which actually runs a trade surplus with Saudi Arabia. They came from Aramco’s other customers, including China.\n\nThe President’s economic focus aligned with Saudi Arabia’s Vision 2030, a development plan designed to diversify the economy away from oil, balance the government budget and create jobs for young Saudis. For the plan to succeed Saudi Arabia needs regional stability and foreign investment. It was no coincidence that Trump’s visit coincided with the U.S. Saudi Investment Forum. Numerous American executives traveled with the president and signed significant contracts for military equipment, commercial aircraft, and electric generators. These are three key sectors of the Saudi economy which the United States has dominated and will now continue to do with Raytheon missiles, Boeing aircraft and GE turbines. In addition to their size, reportedly 600 billion dollars, what made these transactions interesting was the level of commitment made by American firms to help Saudi Arabia develop its own defense and manufacturing capacity.\n\nThe most significant new area of cooperation is artificial intelligence which is fast becoming the third leg of a relationship traditionally based on oil prices and counter terrorism. Because of its low electricity costs, Saudi Arabia has a competitive advantage in hosting power-hungry data centers. The kingdom welcomed technology executives from: Google, Amazon, Starlink, Salesforce, Nvidia and Oracle who accompanied the president. Agreements were reached to help the Saudi AI champion Humain build data centers and research facilities. Most significantly the Saudis were granted access to high end AMD chips.\n\nCrown Prince Mohammad bin Salman (MBS) wanted public recognition of the profound social changes he has brought to Saudi Arabia. On the streets of Riyadh, the once feared religious police have been defanged. Stores no longer rigorously enforce prayer time closure. School curriculums now contain less religion and more foreign languages. Valentine’s Day and Christmas celebrations that were once illegal are now tolerated as are private non-Muslim religious services. There is even a chief rabbi of Saudi Arabia quietly serving Jewish expatriates.\n\nMBS understands that Saudis under 30 do not want to live in their grandparents theocratic, puritanical Saudi Arabia. They want entertainment and more social freedom. He is giving it to them. There are now festivals, concerts and movie theaters to go to. Riyadh has its first gay bar, though still without alcohol. People are having fun. Saudi nationalism is on the rise while Islamic fundamentalism is declining.\n\nBy far the most striking changes relate to the role of women. The guardianship regulations, which once required a woman to seek permission from her father or husband to travel, open a bank account, go to university, get married, or even have a cesarean delivery have largely been abolished. In a place where women could once not go to school they now comprise the majority of university students. In a place where women were legally barred from most jobs there is now an aggressive affirmative action program to bring them into the workforce. Saudi women can now drive, dress as they please and sit where they like in restaurants.\n\nMany of these changes faced strong opposition in an inherently religious and conservative society. MBS has firmly controlled the pace of change. He has jailed those who complained that things were moving either too fast or too slowly. While his government has become more autocratic, MBS did not want to hear another lecture on human rights. President Trump obliged. The president praised the social changes MBS has made while stating clearly that the United States is no longer in the business of telling other nations how to manage their internal affairs.\n\nAs mentioned previously, regional stability is a prerequisite for the success of Vision 2030. Towards that end the Saudis expressed their concern over events in Syria, Palestine and Iran. The Saudis want to give Syria’s new government a chance to stabilize the country and avoid potentially exportable chaos. President Trump obliged by meeting Syria’s new leader Ahmed al-Sharaa. He lifted American sanctions on Syria thereby allowing Saudi Arabia to provide al-Sharaa with economic support. MBS’s foremost concern regarding Iran was to avoid being drawn into any military conflict. In this he succeeded.\n\nNeither leader got everything he wanted. President Trump’s call to expand the Abraham Accords fell largely on deaf ears. The Saudis view the Palestinian issue as a security problem not a morality play. They want it resolved because it is destabilizing. Any solution that does not address underlying Palestinian grievances will not solve the problem and MBS made that clear again during the President’s visit. MBS did not get a formal American security guarantee, though how much he really sought one is an open question. Nor did he get an agreement on providing American nuclear power technology where issues of enrichment and inspection remain unresolved.\n\nNevertheless, the Strategic Economic Partnership Agreement, contracts, letters of intent, memoranda of understanding and executive agreements signed during the visit reasserted Washington’s leading role in Riyadh, a role underlined by the ongoing construction of a massive new American embassy complex there. At the same time MBS received recognition as the leader of a nation that is open for business, changing in positive ways and an anchor of American influence in the Middle East.",
      "source": "Hoover.org",
      "url": "https://www.hoover.org/research/why-trump-went-riyadh-and-what-he-achieved",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Cohere looks to shed its underdog status with a star AI hire, new CFO and $7 billion valuation — chasing ‘ROI over AGI’",
      "content": "Cohere, the Toronto-based startup building large language models for business customers, has long had a lot in common with its hometown hockey team, the Maple Leafs. They are a solid franchise and a big deal in Canada, but they’ve not made a Stanley Cup Final since 1967. Similarly, Cohere has built a string of solid, if not spectacular, LLMs and has established itself as the AI national champion of Canada. But it’s struggled for traction against better-known and better-funded rivals like OpenAI, Anthropic, and Google DeepMind. Now it’s making a renewed bid for relevancy: Last month the company raised $500 million, boosting its valuation to nearly $7 billion; hired its first CFO; and landed a marquee recruit in Joelle Pineau, Meta’s longtime head of AI research.\n\nPineau announced her departure from Meta in April, just weeks before Mark Zuckerberg unveiled a sweeping AI reorganization that included acquiring Scale AI, elevating its cofounder Alex Wang to chief AI officer, and launching a costly spree to poach dozens of top researchers. For Cohere, her arrival is a coup and a reputational boost at a moment when many in the industry wondered whether the company could go the distance—or whether it would be acquired or fade away.\n\nCohere was founded in 2019 by three Google Brain alumni — Nick Frosst, Ivan Zhang and Aidan Gomez, a coauthor on the seminal 2017 research paper, titled “Attention Is All You Need,” that jump-started the generative AI boom. According to Frosst, in May the startup reached $100 million in annual recurring revenue. It’s an important milestone, and there have been unconfirmed reports that Cohere projects doubling that by the end of year. But it is still a fraction of what larger rivals like Anthropic and OpenAI are generating.\n\nUnlike peers that have tied themselves closely to Big Tech cloud providers—or, in some cases, sold outright—Cohere has resisted acquisition offers and avoided dependence on any single cloud ecosystem. “Acquisition is failure—it’s ending this process of building,” Gomez, Cohere’s CEO, recently said at a Toronto Tech Week event. The company also leans into its Canadian roots, touting both its Toronto headquarters and lucrative contracts with the Canadian government, even as it maintains a presence in Silicon Valley and an office in London.\n\nIn interviews with Fortune, Pineau, new CFO Francois Chadwick (who was previously acting CFO at Uber) and cofounder Frosst emphasized Cohere’s focus on the enterprise market. While rivals race toward human-like artificial general intelligence (AGI), Cohere is betting that businesses want something simpler: tools that deliver ROI today.\n\nA focus on ROI over AGI\n\n“We have been under the radar a little bit, I think that’s fair,” cofounder Nick Frosst said. “We’re not trying to sell to consumers, so we don’t need to be at the top of consumer minds—and we are not.” Part of the reason, he added with a laugh, is cultural: “We’re pretty Canadian. It’s not in our DNA to be out there talking about how amazing we are.”\n\n\n\nFrosst did, however, tout the billboards that recently debuted in San Francisco, Toronto and London, including one for Cohere’s North AI platform that says “AI that can access your info without giving any of it away.”\n\nThat quiet approach is starting to shift, he said, a reflection of the traction it’s seeing with enterprise customers like the Royal Bank of Canada, Dell and SAP. Cohere’s pitch, he argued, is “pretty unique” among foundation model companies: a focus on ROI, not AGI.\n\n\n\n“When I talk to businesses, a lot of them are like, yeah, we made some cool demos, and they didn’t get anywhere. So our focus has been on getting people into production, getting ROI for them with LLMs,” he said. That means prioritizing security and privacy, building smaller models that can run efficiently on GPUs, and tailoring systems for specific languages, verticals and business workflows. Recent releases such as Command A (for reasoning) and Command A Vision are designed to hit “top of their class” performance while still fitting within customers’ hardware budgets.\n\nIt also means resisting the temptation to chase consumer-style engagement. On a recent episode of the 20VC podcast, Frosst said Cohere isn’t trying to make its models chatty or addictive. “When we train our model, we’re not training it to be an amazing conversationalist with you,” he said. “We’re not training it to keep you interested and keep you engaged and occupied. We don’t have engagement metrics or things like that.”\n\nLack of drama is ‘wonderful’\n\nFor Pineau—who at Cohere will help oversee strategy across research, product, and policy teams—the company’s low-key profile was part of the appeal. The absence of drama, she said, is “wonderful” — and “a good fit for my personality. I prefer to fly a little bit under the radar and just get work done.”\n\nPineau, a highly-respected AI scientist and McGill University professor based in Montreal, was known for pushing the AI field to be more rigorous and reproducible. At Meta, she helmed the Fundamental AI Research (FAIR) lab, where she led the development of company’s family of open models, called Llama, and worked alongside Meta’s chief scientist Yann LeCun.\n\nThere was certainly no absence of drama in her most recent years at Meta, as Mark Zuckerberg spearheaded a sweeping pivot to generative AI after OpenAI debuted ChatGPT in November 2022. The strategy created momentum, but Llama 4 flopped when it was released in early April 2025—at which point, Pineau had already submitted her resignation. In June, Zuckerberg handed 28-year-old Alex Wang control of Meta’s entire AI operations as part of a $14.3 billion investment in Scale AI. Wang now leads a newly formed “Superintelligence” group packed with industry stars paid like high-priced athletes, and oversees Meta’s other AI product and research teams under the umbrella of Meta Superintelligence Labs.\n\nPineau said Zuckerberg’s plans to hire Wang did not contribute to her decision to leave. After leaving Meta, she had several months to decide her next steps: Based in Montreal, where Cohere is opening a new office, Pineau said she had been watching the company closely: “It’s one of very few companies around the world that I think has both the ambition and the abilities to train foundation models at scale.”\n\nWhat stood out to her was not leaderboard glory but enterprise pragmatism. For example, much of the industry chases bragging rights on public benchmarks, which rank models on tasks like math or logic puzzles. Pineau said those benchmarks are “nice to have” but far less relevant than making models work securely inside a business. “They’re not necessarily the must-have for most enterprises,” she said. Cohere, by contrast, has focused on models that run securely on-premise, handle sensitive corporate data, and prioritize characteristics like confidentiality, privacy and security.\n\n“In a lot of cases, responsibility aspects come late in the design cycle,” she said. “Here, it’s built into the research teams, the modeling approach, the product.” She also cited the company’s “small but mighty” research team and its commitment to open science — values that drew her to Meta years earlier.\n\nPineau considered returning to academia, but the pace and scale of today’s AI industry convinced her otherwise. “Given the speed at which things are moving, and the resources you need to really have an impact, having most of my energies in an industry setting is where I’m going to be closer to the frontier,” she said. “While I considered both, it wasn’t a hard choice to jump back into an industry role.”\n\nHer years at Meta, where she rose to lead a global research organization and spent 18 months in Zuckerberg’s inner leadership circle, left her with lessons she hopes to apply at Cohere: how to bridge research and product, navigate policy questions, and think through the societal implications of technology. “Cohere is on a trajectory to play a huge role in enterprise, but also in important policy and society questions,” she said. “It’s an opportunity for me to take all I’ve learned and carry it into this new role.”\n\nThe Cohere leadership moved quickly. “When we found out she was leaving Meta, we were definitely very interested,” Frosst said, although he denied that the hire was intended as a poke at Meta CEO Mark Zuckerberg. “I don’t think about Zuck that often,” he said. “[Pineau is] a legend in the community — and building with her in Montreal, in Canada, is particularly exciting.”\n\nA move to growth and path to profitability\n\nPineau is not Cohere’s only new big league hire. It also tapped Chadwick, an Uber alum who served there as acting CFO. “I was the guy that put Uber in over 100 countries,” he noted. “I want to bring that skill set here—understanding how to scale, how to grow, and continue to deliver.”\n\nWhat stands out to him about Cohere, he explained, is the economics of its enterprise-focused business model. Unlike consumer-facing peers that absorb massive compute costs directly onto their own balance sheets, Cohere’s approach shifts much of that burden to partners and customers who pay for their own inference. “They’re building and implementing these systems in a way that ensures efficiency and real ROI—without the same heavy drag on our P&L for compute power,” he said.\n\nThat contrasts with rivals like Anthropic, which The Information recently reported has grown to $4 billion in annualized revenue over the last six months but is likely burning far more cash in the process. OpenAI, meanwhile, has reportedly told investors it now expects to spend $115 billion through 2029—an $80 billion increase from prior forecasts—to keep up with the compute demands of powering ChatGPT.\n\nFor Chadwick, that means Cohere’s path to profitability looks markedly different than other generative AI players. “I’m going to have to get under the hood and look at the numbers more, but I think the path to profitability will be much shorter,” he said. “We probably have all the right levers to pull to get us there as quickly as possible.”\n\nDaniel Newman, CEO of research firm The Futurum Group, agreed that as OpenAI and Anthropic valuations have ballooned to eye-watering levels while burning through cash, there is a strong need for companies like Cohere (as well as the Paris-based Mistral) which are providing specialized models for regulated industries and enterprise use cases.\n\n“I believe Cohere has a unique opportunity to zero in on the enterprise AI opportunity, which is more nascent than the consumer use cases that have seen remarkable scale on platforms like OpenAI and Anthropic,” he said. “This is the intersection of software-as-a-service companies, of cloud and hyperscalers, and some of these new AI companies like Cohere.”\n\nStill, others say it’s too early for Cohere to declare victory. Steven Dickens, CEO and principal analyst at Hyperframe Research, said the company “has a ways to go to get to profitability.” That said, he agreed that the recent capital raise “from some storied strategic investors” is “a strong indication of the progress the company has made and the trajectory ahead.”\n\n\n\nAmong those who participated in the most recent $500 million venture capital round for Cohere were the venture capital arms of Nvidia, AMD, and Salesforce, also of which might see Cohere as strategic partner. The round was led by venture capital firms Radical Ventures and Inovia Capital, with PSP Investments and Healthcare of Ontario Pension Plan also joining the round.\n\nVindication in ‘vibe shift’ away from AGI\n\nFor his part, Frosst sees some vindication in the rest of the industry’s recent “vibe shift” away from framing AGI as the sector’s monocular goal. In a way, the rest of the industry is moving towards the position Cohere has already staked out.\n\n\n\nBut Cohere’s skepticism about AGI hasn’t always felt comfortable for the company and its cofounders. Frosst said it’s meant that he has found himself in disagreement with friends who believe throwing more computing power at LLMs will get the world closer to AGI. Those include his mentor and fellow Torontonian Geoffrey Hinton, widely known as the “godfather of AI,” who has said that “AGI is the most important and potentially dangerous technology of our time. “\n\n“I think it’s credibility-building to say, ‘I believe in the power of this technology exactly as powerful as it is,’” Frosst said. He and Hinton may differ, but it hasn’t affected their friendship. “I think I’m slowly winning him over,” he added with a laugh — though he acknowledged Hinton would probably deny it.\n\nAnd Cohere, too, is hoping to win over more than friends — by convincing enterprises, investors, and skeptics alike that ROI, not AGI, is the smarter bet. The Toronto Maple Leafs of AI thinks it might just win the Stanley Cup yet.",
      "source": "Fortune",
      "url": "https://fortune.com/2025/09/09/cohere-looks-to-shed-its-underdog-status-with-a-star-ai-hire-new-cfo-and-7-billion-valuation-chasing-roi-over-agi/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nissan and ChargeScape Announce New Vehicle-to-Grid Pilot with Silicon Valley Power",
      "content": "SANTA CLARA, Calif., Sept. 09, 2025 (GLOBE NEWSWIRE) -- ChargeScape , the automotive joint venture focused on electric vehicle-grid integration, and Nissan, one of the world’s largest automakers, today announced the launch of a new vehicle-to-grid (V2G) pilot in the utility territory covered by Silicon Valley Power (SVP). This pilot is possible through the California Energy Commission’s Demand Side Grid Support (DSGS) program Option 3.\n\nSilicon Valley is one of the world’s data center hotspots. The rise of AI has caused a surge in electricity demand coming from data centers, which many power grids were not designed to withstand. Forward-thinking utilities such as Silicon Valley Power are seeking innovative ways to quickly increase power supply to meet this new demand, in order to ensure grid reliability for all customers. At Nissan’s Advanced Technology Center in Silicon Valley, this pilot will use energy stored in EV batteries from Nissan electric vehicles, managed by Fermata Energy’s bidirectional chargers, to export power during periods of grid strain. ChargeScape will coordinate with market partner Leap to discharge power from Nissan vehicles and free up supply for data center loads. The pilot is part of ChargeScape and Leap’s broader California Virtual Power Plant .\n\n“Through this collaboration, we’re showcasing how electric vehicles can reinforce our communities’ electrical needs and deliver meaningful benefits to drivers,” said Rich Miller, Vice President of Vehicle Connected Services at Nissan U.S.\n\n“AI is a fundamental component of American Dynamism, and our nation’s power grids must quickly adapt to supply data centers with the energy needed to maintain America’s competitive edge in places like Silicon Valley,” said Joseph Vellone, CEO of ChargeScape. “Integrating Nissan’s EV batteries into Silicon Valley Power’s grid is a crucial first step to shoring up long-term grid reliability and rewarding the EV drivers who are part of the solution.”\n\n“At Fermata Energy, we are demonstrating how AI-enabled V2X optimization can transform electric vehicles into intelligent grid resources,” said Hamza Lemsaddek, Chief Operating Officer of Fermata Energy. “By pairing our platform with bidirectional chargers at Nissan’s Innovation Lab, we’re proving that EVs can strengthen data center reliability, support utilities like Silicon Valley Power, and deliver real economic value back to drivers and communities.”\n\n“Our work with ChargeScape has shown the powerful potential of harnessing the EVs already on the road today to tackle urgent grid reliability challenges,” said Jason Michaels, CEO of Leap. “Activating these vehicles as flexible, dispatchable grid resources is a game-changing tool to help utilities manage higher loads and unlock economic growth while putting dollars back in the hands of ratepayers. We look forward to expanding our partnership with ChargeScape to serve more communities.”\n\nThe pilot is part of ChargeScape’s mission to accelerate vehicle-grid integration and will lay the groundwork for other V2G programs across California and other U.S. states. Through this and other ChargeScape programs, participating EV drivers will earn money for helping the power grid, a mechanism the company believes will help make EVs more affordable in the long run.\n\nAbout Leap\n\nLeap is the leading platform for building and scaling virtual power plants (VPPs). Through its software-only solution, Leap facilitates fast, easy and automated access to demand response and other grid services revenue streams for the providers of battery storage systems, EV chargers, smart building technologies, and other distributed energy resources (DERs). Managing over 300,000 energy sites and devices across U.S. energy markets, Leap empowers more than 90 technology partners and their customers to unlock new value and help create a more flexible, resilient grid powered by renewable resources. Visit leap.energy to learn more.\n\nAbout ChargeScape\n\nChargeScape is a software company that connects electric utilities, automakers and electric vehicle drivers through its integrated platform. From its headquarters in Austin, ChargeScape helps stabilize electric grids by optimizing EV demand while helping EV drivers to save money on their at-home charging through cash-back and other incentives. The company currently counts BMW, Ford, Honda and Nissan as investors.\n\nAbout Nissan\n\nFor more information about our products, services and commitment to sustainable mobility, visit nissanusa.com . You can also follow us on Facebook , Instagram , X (Twitter) and LinkedIn and see all our latest videos on YouTube .\n\nAbout Fermata Energy\n\nFermata Energy is a leading platform services provider focused on intelligent grid asset management and monetization, with capabilities spanning Vehicle-to-Everything (V2X) bidirectional charging, stationary storage, and other distributed energy resources (DERs). The company’s proprietary AI-enabled optimization platform and bidirectional charging hardware transform electric vehicles and other assets into dispatchable, revenue-generating grid resources. Fermata Energy’s solutions enable utilities, fleets, and businesses to stabilize the grid, reduce costly peak demand charges, unlock new value streams, and ensure the reliable operation of critical facilities such as data centers. To learn more, please visit https://fermataenergy.com and follow the company on LinkedIn.\n\nAbout the City of Santa Clara\n\nLocated at the heart of Silicon Valley about 45 miles south of San Francisco, the City of Santa Clara truly is “The Center of What’s Possible.” Incorporated in 1852, Santa Clara covers an area of 19.3 square miles with an estimated population of 129,498. Santa Clara is home to an extraordinary array of high-tech companies, including Applied Materials, AMD, Intel, Nvidia, and Ericsson. The City of Santa Clara is also home to Santa Clara University, California’s Great America Theme Park, and Levi’s® Stadium, home of the San Francisco 49ers and future host site of Super Bowl LX and FIFA World Cup in 2026. For more information, visit SantaClaraCA.gov .\n\nAbout Silicon Valley Power\n\nSilicon Valley Power (SVP) is the trademark adopted for use by the not-for-profit electric municipal utility of Santa Clara, CA , serving residents and businesses since 1896. SVP provides power to over 60,000 customers at rates 36 to 59 percent below neighboring communities. SVP is the only full-service, vertically integrated publicly owned utility in Silicon Valley, owning generation, transmission, and distribution assets. See more at: SiliconValleyPower.com .\n\nChargeScape Media Contact\n\nchargescape@skyya.com\n\nFermata Energy Media Contact\n\nmedia@fermataenergy.com\n\nLeap Media Contact\n\ncaroline@leap.energy\n\nNissan Media Contact\n\nJeff.Wandell@nissan-usa.com",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/09/3146731/0/en/Nissan-and-ChargeScape-Announce-New-Vehicle-to-Grid-Pilot-with-Silicon-Valley-Power.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Dell reportedly cutting staff from China operations — affected employees have until October 10 to apply for internal transfer",
      "content": "Dell is reportedly laying off staff from its China operations, with affected personnel only having until October 10 to apply for open internal positions. Some of the affected departments include its EMC storage division and the Client Solution Group (CSG), which according to Digitimes, affects Dell's offices in Shanghai and Xiamen. However, the company has not publicly announced this reduction-in-force yet, so it’s unclear how many people are affected.\n\nThis latest news of layoffs comes amid the company’s restructuring to boost profitability. Around a year ago, it was estimated that Dell let go of over 12,000 positions, reducing its workforce by around 10%. The company has not been hiring externally and has even made a leadership adjustment with the departure of Yvonne McGill as its CFO, after nearly 30 years of working with the PC maker. Dell did not say why McGill is leaving her position, but clarified that it was not related to the company’s financial reporting or internal controls.\n\nThe EMC storage division is the company’s enterprise storage arm, focusing on delivering solutions to storage, server, and data protection services to IT departments, data centers, and other institutions. On the other hand, CSG delivers end-user hardware, like laptops and monitors, to consumers and companies. These divisions are historically important for Dell’s presence in China, but the changing geopolitical landscape and market demands are making strategic contraction a necessity for the company to adjust to shifting realities.\n\nOther companies have also been caught in the crossfire between the U.S. and China’s trade war. Microsoft closed its AI and IoT labs in the East Asian nation last year, with Redmond asking nearly 10% of its China-based workforce to relocate to the U.S., Ireland, Australia, or New Zealand. IBM also shuttered its research and development facilities in the country in August 2024, resulting in the retrenchment of over 1,000 people.\n\nEven Nvidia is facing some trouble in China after the U.S. banned the export of its H20 AI GPUs in April. The White House eventually allowed it to sell the advanced chips again, this time by issuing export licenses to the company. However, it only allowed this after Nvidia and AMD agreed to share 15% of their China revenue with the federal government. Deliveries still aren’t being made, though, as the Commerce Department still has a massive backlog of export licenses to process, and Washington’s lawyers are still figuring out the legality of the 15% ‘export tax’.\n\nFollow Tom's Hardware on Google News , or add us as a preferred source , to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/dell-reportedly-cutting-staff-from-china-operations-affected-employees-have-until-october-10-to-apply-for-internal-transfer",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Retired Japanese racehorse Haru Urara that inspired the 'Umamusume' character dies at 29",
      "content": "Live Events\n\nHaru Uraru inspired Umamusume\n\nHaru Urara's life and career\n\nas a Reliable and Trusted News Source Addas a Reliable and Trusted News Source Add Now!\n\n\n\n\n\n(You can now subscribe to our\n\n(You can now subscribe to our Economic Times WhatsApp channel\n\nRetired Japanese racehorse Haru Urara that inspired the Umamusume character, has died. Haru Urara saw an unexpected surge in popularity in recent months after the global launch of a mobile game has died at the age of 29, reported The Strait Times.Despite not winning a race during her professional career, Haru Urara was beloved for being \"the shining star of losers everywhere.\" Once dubbed “the shining star of losers everywhere”, Haru Urara died in the early hours of Sept 9.According to Yahoo Japan, Haru Urara passed away in the early hours of Tuesday, September 9 surrounded by staff members from Martha Farm in Chiba prefecture, where she was kept in her twilight years. Her cause of death was revealed to be Horse Colic, a condition that occurs when gas builds up in the intestines due to poor digestion of food and slows down intestinal movement. It is a dangerous condition in horses, with a high mortality rate.Dubbed as “the shining star of losers everywhere”, Haru Urara became sick on September 8 and a vet was called, Yuko Miyahara, her caretaker at Martha Farm told Friday Digital.The official Umamusume: Pretty Derby social media accounts also released a statement where developer Cygames' shared their condolences over Haru Urara's passing. \"It is with heavy hearts that we share that Haru Urara passed away on September 9. The legendary racehorse's legacy serves as the inspiration for the character of the same name in Umamusume: Pretty Derby. We share our condolences to all the staff involved in Haru Urara's care,\" the post read.Staff members accompanied her through the night, but her condition suddenly worsened at dawn on Sept 9, leading to her death. “Haru Urara was 29 years old, which would be nearly 90 years old in human terms, but she was in great health until yesterday,” Ms Miyahara told Friday Digital.“Recently, more and more people, not only from Japan but also from overseas, have been coming to see Haru Urara. So it’s really unfortunate.” Haru Urara was still fielding visits from fans, and was reportedly still in good health the weekend before it passed away.Born on February 27, 1996 in Hokkaido, Haru Urara was sired by Nippo Teio, a top-class racehorse. Her name means \"Glorious Spring\" or \"Gentle Spring\" in Japanese. Despite her strong lineage, Haru Urara never managed to win a single race during her professional career. She debuted on 17 November, 1998 at the Kōchi Racetrack amd placed last among fifth racers. She would continue competing in races once or twice every month without winning over the course of the next four years.After losing 80 consecutive races, Haru Urara's story was picked up by Japanese media in June 2003. She became a household name in Japan as a result and was branded as “the shining star of losers everywhere” for continuing to race despite her infamous losing streak.Haru Urara ran her last race in August 2004, retiring with a record of zero wins and 113 losses. However, Haru Urara did finally win a race after she retired, setting the best time in a time trial race for older horses in May 2019.In July 2025, Haru Urara dominated headlines again following the global launch of the Uma Musume Pretty Derby mobile game, where she appeared as a pink-haired anime character.When Umamusume: Pretty Derby launched in Japan in February 2021, Haru Urara was among the original characters featured alongside fan favorites like Special Week, Silence Suzuka, Tokai Teio, Mejiro McQueen, Gold Ship, and Grass Wonder, among many others. The game quickly became a hit in Japan, but its global release on June 26 this year sparked an even bigger wave of enthusiasm.Haru Urara’s heartfelt story struck a chord with players around the world, inspiring many to contribute funds through the Fresh Hay Bank—a crowdfunding platform where fans could donate fresh ryegrass to support retired and celebrated racehorses. The overwhelming response in July was so immense that the website crashed, with over 2,500 kilograms of ryegrass gifted to Haru Urara.Several other racehorses that inspired Umamusume characters, such as Meisho Doto, Hishi Miracle, Nice Nature, Fine Motion, and Tanino Gimlet, also received generous donations through the Fresh Hay Bank. Haru Urara is the second Japanese racehorse used as a basis for an Umamusume character to pass away this year after Grass Wonder, who died in early August at 30 years of age.",
      "source": "The Times of India",
      "url": "https://economictimes.indiatimes.com/news/international/global-trends/us-news-retired-japanese-racehorse-haru-urara-that-inspired-the-umamusume-character-dies-at-29/articleshow/123785780.cms",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD 25.9.1 Driver Enables FSR 4 In FSR 3.1 “DX12” Games, Expanding The List To 85+ Titles, Several Fixes & Improvements For Radeon GPUs - Wccfte",
      "content": null,
      "source": "Slashdot.org",
      "url": "https://slashdot.org/firehose.pl?op=view&amp;id=179098616",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD’s AI-powered FSR 4 upscaling is now available in most FSR 3.1 games - The Verge",
      "content": "Catch up on stories from the past week (and beyond) at the Slashdot story archive",
      "source": "Slashdot.org",
      "url": "https://slashdot.org/firehose.pl?op=view&amp;id=179098264",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Borderlands 4 will get a day one patch, but Gearbox CEO warns not to expect 'a miracle' if you're playing on an older PC",
      "content": "We now know that Borderlands 4 will get a day one patch\n\nGearbox CEO Randy Pitchford said that it \"does a lot\" but warned that it won't do much for those using older hardware\n\nHe said the game should be \"unplayable\" for those below the recommended spec\n\nWe now know that upcoming co-op looter shooter Borderlands 4 will be getting a day one patch, though the CEO of developer Gearbox has warned that it won't be a magic bullet for those playing on dated hardware.\n\nSpeaking in an X / Twitter post, CEO Randy Pitchford said that while \"the day one patch does a lot\" with regards to performance, those using a PC below the minimum recommended specs should expect the game to be \"unplayable\".\n\nIf you need a quick reminder, here are the minimum and recommended system requirements for Borderlands 4 found on the official Steam page.\n\nMinimum:\n\nOS: Windows 10 / Windows 11\n\nWindows 10 / Windows 11 Processor: Intel Core i7-9700 / AMD Ryzen 7 2700X\n\nIntel Core i7-9700 / AMD Ryzen 7 2700X Memory: 16 GB RAM\n\n16 GB RAM Graphics: NVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580\n\nNVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 Storage: 100 GB available space\n\nRecommended:\n\nOS: Windows 10 / Windows 11\n\nWindows 10 / Windows 11 Processor: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nIntel Core i7-12700 / AMD Ryzen 7 5800X Memory: 32 GB RAM\n\n32 GB RAM Graphics: NVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nNVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580 Storage: 100 GB available space\n\nThe page also notes that SSD storage is required and Pitchford's post warns that using a slower hard disk drive (HDD) could lead to \"hitching\".\n\nAll things considered, it requires a pretty beefy setup, especially in comparison to the previous game.\n\nGet daily insight, inspiration and deals in your inbox Sign up for breaking news, reviews, opinion, top tech deals, and more. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n\"It's a big, bold, new, seamless world,\" explained Pitchford. \"I'm sorry to say that older hardware may not provide buttery smooth performance for the latest gen AAA games, as has always been the case since the dawn of PC gaming.\"\n\nIf your PC isn't up to the task, Borderlands 4 is also releasing for PlayStation 5 and Xbox Series X and Series S on September 12.\n\nA Nintendo Switch 2 version is set to follow a little later on October 3.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/gaming/borderlands-4-will-get-a-day-one-patch-but-gearbox-ceo-warns-not-to-expect-a-miracle-if-youre-playing-on-an-older-pc",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Confirms Arrow Lake Desktop Refresh Next Year, Nova Lake Desktop CPUs With An 18A Tile In Late 2026, 14A More Suitable For External Customers, Every 7 Out of 10 PC Has Intel Inside",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/intel-arrow-lake-refresh-2026-nova-lake-desktop-late-2026-18a-14a-updates/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Beefy Borderlands 4 system requirements promise \"solid performance on older PC hardware,\" but after Randy Pitchford's warnings about \"realistic expectations\" I'm starting to feel a little scared",
      "content": "Gearbox has confirmed it really was serious about those beefy Borderlands 4 system requirements that went live on the game's Steam page months ago. While some older hardware is supported here, the recommendations are still pretty mighty, and with Randy Pitchford's recent warnings about the game's performance you might, indeed, want to keep your expectations in check.\n\nIn a new blog post, Gearbox reiterates its previously announced specs, but now promises that the minimum loadout can offer \"solid performance on older PC hardware.\"\n\nThe hardware in question here is an Intel Core i7-9700 or AMD Ryzen 7 2700X paired with an Nvidia GeForce RTX 2070 or AMD Radeon RX 5700 XT and 16GB of RAM.\n\nThose are, technically, older pieces of hardware, but they're still fairly meaty and much closer to the recommended specs for most modern games. Another key missing detail is what \"solid performance\" means. Is that 60 FPS at 1440p? 30 FPS at 1080p? Better? Worse? Somewhere in between? Your guess is as good as mine.\n\nThere isn't a huge gap between the minimum and recommended specs, either. The higher end will give you \"the intended experience for Borderlands 4, striking a solid balance of smooth performance and graphical detail.\" Again, there aren't any details on what that means, but to achieve it you'll need an Intel Core i7-12700 or AMD Ryzen 7 5800X paired with an Nvidia GeForce RTX 3080 or AMD Radeon RX 6800 XT and 32GB of RAM.\n\nWith Pitchford actively warning \"everyone to have realistic expectations for performance\" ahead of the Borderlands 4 release times, I think it's fair to guess you won't be able to run this game on a potato. Exactly how well it runs on machines that meet the recommended spec, however, remains to be seen, and we won't have the answer to that question until later this week.\n\nIf you want details on the Borderlands 4 classes as you start considering your build ahead of launch, you know where to click.",
      "source": "GamesRadar+",
      "url": "https://www.gamesradar.com/games/borderlands/beefy-borderlands-4-system-requirements-promise-solid-performance-on-older-pc-hardware-but-after-randy-pitchfords-warnings-about-realistic-expectations-im-starting-to-feel-a-little-scared/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "VicRoads: still in the 20th century",
      "content": "AI: enough! Topic: technology, general, opinion Link here\n\nSunday's detailed investigation of generative artificial intelligence should have been enough, but it occurred to me that there was one thing I hadn't tried: graphics. OK, draw me a caricature of Greg Lehey.\n\nGoogle Gemini came up with this:\n\nOf course I don't need to like the results, but this shows very little understanding: no mention of BSD, just Linux (or even “Linix”). Yvonne tells me that it looks nothing like me. Compared to the text results, quite disappointing.\n\nAnd that was all. My other bots all couldn't do it. But their attempts were worth mentioning:\n\nChatAI\n\nI'm unable to draw images directly, but I can help you imagine a caricature of Greg Lehey! Picture a gentleman with a thoughtful expression, perhaps with glasses perched on his nose, and a hint of a smile suggesting a keen sense of humor. His hair might be slightly tousled, giving him a scholarly yet approachable look. You could exaggerate his features, like giving him a larger forehead to symbolize his intellect or a prominent chin to represent determination. Add a background filled with books and computers to reflect his interests in technology and writing\n\nI suppose that's acceptable for as far as it goes.\n\nClaude\n\nClaude did the best with the diary entry, but it failed completely with the caricature:\n\nClaude: I'd be happy to help you create a caricature, but I'll need a bit more information! There are likely multiple people named Greg Lehey, and I want to make sure I'm drawing the right person..\n\nClaude, you know who I am. There are “likely” multiple people named Greg Lehey? That wasn't a problem on Sunday. And as it happens, there is nobody else that I can find with the same name as mine. But OK, draw me a caricature of Greg Lehey, the FreeBSD person.\n\nI can't create visual caricatures or drawings as I'm a text-based AI. However, I'd be happy to help you in other ways: Written description: I could write a humorous written \"caricature\" or character sketch of Greg Lehman (assuming you meant Greg Lehman, a notable FreeBSD contributor) that captures his programming style, contributions to FreeBSD, or personality traits in an exaggerated, caricature-like way.\n\nWhat a cop-out! Now it says that it can't draw. And it comes up with a fictive Greg Lehman. That's completely useless.\n\nDeepSeek\n\nAs before, DeepSeek is inventive:\n\nWhile I can't physically draw for you, I can create a detailed \"blueprint\" for a caricature of the legendary BSD developer Greg \"Groggy\" Lehey. An artist could follow this description to create the perfect caricature. Here is a description designed for an artist to illustrate. Caricature of Greg \"Groggy\" Lehey Concept: The caricature should capture his iconic, jovial, and slightly mischievous personality, deeply intertwined with his life's work: BSD and Unix. Key Features to Exaggerate: The Beard and Hair: This is the #1 feature. Exaggerate his magnificent, full, and sprawling white beard. Make it vast and wizard-like, almost as if it's its own entity. It should be big enough to have a Daemon (the BSD logo) peeking out from within the whiskers, as if it lives there. His hair (what's visible under his hat) should be similarly wild and unkempt. The Headwear: He is almost never seen without a hat. Draw a slightly battered, well-loved flat cap or a beret perched on his head at a jaunty angle. Where did it get the hat from? I am almost never seen with a hat. The Expression: A wide, knowing, and cheerful grin. His eyes should be crinkled with laughter and wisdom, suggesting he's both a kind mentor and someone who knows where all the bugs in the code are hidden. The Props & Surroundings: In his hand: Instead of a coffee mug, he should be holding a massive, steaming beer stein. This is a nod to his famous \"Buy me a beer\" link on his website and his good-humored nature. Steaming beer? I can't even imagine that. And instead of referring to my brewing activities, it refers to a fictive “buy me a beer” link, which may be related to Poul-Henning Kamp. Under his arm: A well-worn copy of his magnum opus, \"The Complete FreeBSD\" book. Background Element: Have a Tux (the Linux penguin) peeking from around a corner, looking slightly nervous or annoyed, while Groggy pays it no mind. This playfully hints at the good-natured rivalry between BSD and Linux. Code: Faint lines of C code ( #include <beard.h> , printf(\"Cheers!\n\n\"); ) can be subtly woven into the texture of his shirt or the background. Overall Vibe: The image should feel warm, intelligent, and full of character. He is the friendly, brilliant, and slightly eccentric \"Unix Beard\" wizard, a beloved figure in the open-source community. Color Palette: Warm tones. Earthy browns for the hat, a rich color for the shirt (green or blue), the brilliant white of the beard, and the gold of the beer.\n\nStill, I suppose that could produce something useful. But where are all the image generators? Do I want to look? I've spent enough time on this already.\n\nWhy don't people read any more? Topic: language, general, technology, opinion Link here\n\nRecently I saw (but didn't read) a newspaper article, possibly from the New York Times, asking why people don't read books any more. The answer appears simple: information overload. When I was a lad I read lots of books, but it has been some time since I finished reading any, and then the relatively thin “Brave New World”.\n\nBut then we watched A Town Like Alice, and Yvonne borrowed the book. I have always liked Nevil Shute, and I have a number of his books, so I read it when she finished. It took me two weeks. While reading I was continually following up on details mentioned in the book—that's what the web is for, after all. In general, I ended up with a much broader view than I would have had if I had just read the book.\n\nAnd how did I like it? Not much. Clearly it's two different stories stuck together: the ordeals in Malaya at the hand of the Japanese occupation and the transformation of a tiny bush village in Queensland into a small town. The latter, in particular, seems very improbable.\n\nThe geographical details are what interested me most. Particularly in Malay(si)a I knew most of the real places. But I'm puzzled about why Shute spends a lot of time in the area Maran and Jerantut in the Jengka Triangle, places that must have been almost completely unknown at the time, but puts the women in a place called Kuala Telang “about half-way between Kuantan and Kota Bahru”. There is a town in that position, but it's called Kuala Terengganu, and it's a big town (capital of the state of Terengganu), not a small village. My guess is that Shute had never heard of it.\n\nSpelling is also strange. In the first half of the book, Kota Bharu was spelt “Kota Bahru”, and in the second half “Khota Bahru”. Tennant Creek became “Tennants Creek”. These spellings are the same both in the online book and the physical book that I read. And there are a couple of irritating US Americanisms that I don't understand: the animals central to the theme are called alligators, not crocodiles. The stockmen use lariats.\n\nThen there's the question of racial attitudes. The local aborigines (or aboriginals, to use the modern politically correct term) are called “boongs” or “abos”. Both are offensive nowadays. And there was talk of racial segregation, a separate milk bar for the boongs. This would have been about 1948, the time of my birth. Did such segregation really exist then?\n\nMy favourite one, though, is when the main characters (Jean and Joe) fall in love, and she decides not to sleep with him until after they are married. Given that Joe had been crucified in the first half of the story, I was half guessing that he might have been castrated at the same time, and Jean would not have found out until too late.\n\nIn summary: reading books has become much more of an exercise than it used to be. For light entertainment we have TV. I don't think I'll read another novel for some time to come.\n\nPredicting the past Topic: general, technology, opinion Link here\n\nI keep a close eye on the weather forecasts from the Bureau of Meteorology, both of them. There's one on the web and another for mobile phones. They don't often agree with each other, and of course they're both frequently wrong.\n\nToday, though, the mobile phone app excelled itself. We finally have rain, 6 mm over the last 24 hours. Or, as the app put it,\n\nPart of the app is a rainfall map showing precipitation. That showed that there was much more rain. How can that happen?\n\nWhatsApp: bug after bug? Topic: technology, opinion Link here\n\nI've been trying for a week now to set up video telephony on fossil, Yvonne's mobile phone. Somehow the “modern” approach to user interfaces shows itself at its worst here. But I had come to the conclusion that if I can work beyond WhatsApps bizarre interface, and explain it to Yvonne so that she doesn't have a panic attack every time she uses it, we might have something useful, especially since WhatsApp can communicate by an Internet link, which could be much cheaper.\n\nOK, try out on hirse first. It doesn't have a SIM card, so any communication has to go by the Internet. Migrate my main number to hirse. No problem. Make a call. Some message like “need to use the phone network”. Oh.\n\nTry calling in. The problem: hirse has the phone number associated with a SIM card in albo, which has a different WhatsApp number. Which does WhatsApp call? albo! Somehow there's more to this than meets the eye.\n\nWhen Yvonne got back from shopping, I changed her WhatsApp number to the number of second SIM on her phone. All sorts of things didn't work, and it couldn't call the number on hirse. hirse claimed that she wasn't registered, though I had set the “notify contacts” during the migration. In the end I moved the number back to the old one. And things still didn't work correctly! In particular, I could call the number, but WhatsApp didn't respond in any way, not even registering a missed call. Went through the settings and set tones for all notifications. Still no response. Restart the app. No response.\n\nNothing for it, the Microsoft solution: reboot. And yes, now it responds. Clearly some kind of bug. And it repeats the call tone for every notification, including messages. Oh, my bad. Get rid of the tone. Sorry, there's no provision for that. Select something at random, since it's too polite to play the tone when you're selecting it. I still get the ring tone for messages! I can't see any explanation except that it's another bug. It was getting late, so I turned off sounds to wait until tomorrow.\n\nAll this is made worse by the horrible user interface. So far I haven't found a way to display the associated phone number in the contact details. At one point I made the mistake of using the same name (mine) for both my phones, so there was no way at all to find out what “number” it had called.\n\nI hate WhatsApp! Topic: technology, general, opinion Link here\n\nMore fun with WhatsApp today. The first question, which decides whether it's even worthwhile: can I make a call over the Internet? Yesterday's experiments were overshadowed by other bugs. Today I tried making a call from fossil (Yvonne's phone) to hirse, the one without a SIM card. I have set it up with the main number of albo, so a normal call to that number should go to albo, and a WhatsApp call should go to hirse. Does it?\n\nYes! So yesterday's issues were probably due to other bugs.\n\nAnd the incorrect notification tones? Gone since the last reboot, Yvonne says. But later she changed her mind: once again the wrong tone when all notification tones were turned off.\n\nDammit, begone, WhatsApp! Removed it. Reinstalled it. And how about that, setup was almost completely without problem. She lost her image (“Avatar”, “The manifestation of a god in bodily form on earth” according to the OED). We can live with that. And somehow now everything Just Works—until the next unpleasant surprise.\n\nApart from that and the horrible user interface, established that you can change an audio call into a video call simply by pressing the button with the box with a loudspeaker on the right:\n\nInterestingly, it only works in one direction. To go in the other direction requires that the person at the other end do the same.\n\nVirtualBox again Topic: technology, photography, opinion Link here\n\nDxO PhotoLab 9 is out, and it looks worth trying. Time to reinstate one of my Microsoft virtual machines, which run under VirtualBox.\n\nI stopped using VirtualBox on hydra a year ago, though it was the main reason that I had so much memory (192 GB): I ran into network problems that I couldn't fix.\n\nNow FreeBSD has a port of VirtualBox 7. Time to try again? Tried first on dereel, with only 24 GB of memory. Where's my HOWTO? All fine, but it doesn't tell me how to add an existing VM. It must be in this diary somewhere, but where? I really should keep these HOWTOs up to date.\n\nStarting up the GUI was different from before, of course. And it wanted to set things up in the root file system. To go elsewhere I had to do this horrible tree walking. Finally I got to where I wanted (/src/VirtualBox/echuca). Tried to create a new VM. “Can't overwrite machine folder...\". What does that mean? They should know better than to call a directory a folder, but what's a “machine folder”? Lots of experimentation, continually being returned to the /root directory and having to climb my way out again. What does “help” say? Nothing. I wonder if the port forgot to install something important. After a while I discovered that it really wanted the parent directory /src/VirtualBox, but then I ran into other issues.\n\nAfter some time decided to create a new VM with the old virtual disk. Link? Yes, but VirtualBox detected the UUID and used the old name.\n\nYes, there are other possibilities. But I think that the best is to go through my diary and extract the information that I need to do things sanely. And maybe I should use the commands rather than the GUI, which seems to be getting more stupid as time goes on.\n\nWhatsApp an Avatar? Topic: technology, general, opinion Link here\n\nYesterday I established that an Avatar is a earthly manifestation of a Hindu god, but WhatsApp apparently wants to elevate Yvonne and me to deities. Until then, only initials appear to identify us on calls.\n\nOK, how do we do that? Settings, of course, “make your own avatar”, “Create from selfie”. OK. Take a suitably horrified photo of myself. Briefly it showed “There was an error with the avatar gen...”, so briefly that I didn't see it the first three times. What does that mean? Why can't it finish its sentences? So instead it presented me with a manual generation.\n\nWhy? What does the half message mean? It's repeatable on two different phones. And there seems to be no way to just add a normal photo. What a mess!\n\nVirtualBox progress Topic: technology, opinion Link here\n\nSo what's wrong with my VirtualBox installation? My current situation was exactly what I had a year ago: most VMs worked, but Microsoft VMs had networking problems. They could send data, but they didn't see the replies, so they hung in ARP. I attributed that to the version of VirtualBox (6.1.50 r161033), so I waited until version 7 came out. And then I discovered that I had exactly the same problem.\n\nThat didn't help just getting things running. After some searching, discovered that VirtualBox stores a configuration in the home directory, ~/.config/VirtualBox/ with a number of files, including log files that have no business there, but importantly VirtualBox.xml. OK, make a copy of that on dereel, and how about that, VirtualBox came up with all the VMs I knew.\n\nStart disaster, the only VM that would fit in dereel's memory.\n\nVT-x is disabled in the BIOS for all CPU modes (VERR_VMX_MSR_ALL_VMX_DISABLED).\n\n\n\nOh. There was something there, but can the twins help? Yes, specifically for a ThinkCentre:\n\nOnce in the BIOS, use the arrow keys to navigate to the Advanced tab. From the Advanced menu, select CPU Setup and press Enter. Look for an option labeled Intel(R) Virtualization Technology and select it. Using the arrow keys, change the setting from Disabled to Enabled.\n\nAfter that and rebooting, and with a change of network adapter name, it still didn't start. I got this message:\n\nX86_CPUID_AMD_FEATURE_EDX_AXMMX is not supported by the host but has already exposed to the guest [ver=19 pass=final] (VERR_SSM_LOAD_CPUID_MISMATCH).\n\nMore help from the twins. The saved state includes information from an AMD processor (hydra), but this is Intel. Discard saved state and start again.\n\nAfter that, and with a change of network adapter name, it started. I got this message, which I haven't seen before, but which seems harmless:\n\nerror: XDG_RUNTIME_DIR is invalid or not set in the environment.\n\nThat variable isn't set on hydra either.\n\nWe're still not done. Trying to start an xterm from current gave me the message\n\nThe Virtual Machine reports that the guest OS does not support mouse pointer integration\n\nWhat's that? Gemini tells me:\n\nThe message \"The Virtual Machine reports that the guest OS does not support mouse pointer integration...\" in a FreeBSD virtual machine is common and means you need to install and configure the necessary guest additions for the mouse to work seamlessly. FreeBSD does not include these drivers out of the box, so you must install them yourself.\n\nThat sounds like the Ports Collection. But there is no additions package for VirtualBox 7.1, only for 6.50 and 5.2. Mañana.\n\nOn with disaster. So: ARP issue? While messing around on disaster, found the help message for ARP. It uses Unix-style option delimiters, and -s sets a permanent MAC address. OK, if this is an ARP issue, we can fix that:\n\nOh: Microsoft has a different format for MAC addresses. Try again:\n\nAnd that as Administrator . Time to ask the twins.\n\nQ: What does \"The ARP entry addition failed: Access is denied\" when running CMD as administrator under \"windows\" 10? A: The \"ARP entry addition failed: Access is denied\" error in Windows 10, even when running Command Prompt as an administrator, typically happens when trying to add a static Address Resolution Protocol (ARP) entry for a reason other than a permission issue.\n\nInteresting. “Access is denied” is not a permission issue? Something's wrong here, either Gemini or Microsoft. My money is on Microsoft.\n\nAnd that's what Gemini suggests too:\n\nUse netsh instead: In some cases, especially on newer versions of Windows, the arp command may have issues with Access is denied errors even when the user has administrator privileges.\n\nSo I ended up with this simple invocation:\n\nAnd how about that, it worked. Well, at least it put the address in the ARP table, and I was able to ping out, so disaster knew the address. But it still didn't hear any reply.\n\nYet another question to Gemini:\n\nWhat could cause a Microsoft guest under VirtualBox to send network data but not receive it, when other guests have no problem with the same configuration?\n\nThe obvious answer: firewall. Check to be on the safe side. No, no firewall enabled. How about an Ethernet adapter issue?\n\nIf you are using an Intel PRO/1000, try switching to a different type, such as the AMD PCnet-FAST III.\n\nOK, try that. No improvement. Next idea: this video\n\nOK, try anything once. Follow the instructions step by step, none of which showed any obvious issues. Change the interface back to (specifically) Intel PRO/1000 MT Deskop (8254EM). Not much hope there: that's what I had.\n\nBut it worked! My final configuration looks identical to the start configuration. What changed? There's something lurking under the surface that I don't understand. Can I now get it to run on hydra?\n\nMore VirtualBox pain Topic: technology, opinion Link here\n\nYesterday I finally got networking working using VirtualBox 7.1 and Microsoft “Windows” 10. Time to refine a few things. First, start the windows on hydra:0.0, a 1920×1080 display, rather than on hydra:0.1, which has 3840×2160, giving windows that are too small.\n\nBut it didn't work! I could start on hydra:0.1, but on hydra:0.0 nothing happened. Is there some kind of built-in memory in the configuration file?\n\nSo, time to upgrade current.lemis.com, another VM running FreeBSD-CURRENT. It was a year out of date.\n\nStart a make buildworld , not for the first time. But nothing happened!\n\nFurther investigation showed that I had a network hang. And disaster was also hanging! Shut down disaster and current regained network access—for a while. Then it hung again.\n\nThis seems worse than my experience on hydra with VirtualBox 6.5. Tried it there and it worked.\n\nWhat a pain! What does Google Gemini say?\n\nQ: Are there known networking issues with VirtualBox under FreeBSD? A: Yes, there are known networking issues and quirks with VirtualBox when used as a host on a FreeBSD system. While VirtualBox works, it is not an officially \"supported\" host platform by Oracle, which means users often have to rely on the community and package maintainers to troubleshoot and resolve issues. (much irrelevant information omitted) Users sometimes experience slow network speeds, particularly with upload speeds, when using bridged adapters. This can be more pronounced on specific emulated network card types. While VirtualBox can function as a host on FreeBSD, it is not a \"fire-and-forget\" solution... If you encounter speed or reliability issues, experimenting with different emulated network adapter types can often resolve the problem.\n\nThat's not encouraging, though it doesn't directly relate to my problems. But what else can it be? Two different versions of FreeBSD, two different machines, two different versions of VirtualBox. Does it work better on Linux? That would be a real let-down, but possibly I should try it. How much pain would that be?\n\nTesting RSS feeds Topic: technology Link here\n\nI write all my web markup myself, with the aid of a number of PHP scripts. The result is that the RSS feed looks nothing much like my sources. So when something goes wrong with the markup, it's hard to find where, not helped by things like the W3.org validator, which typically points to where the error is detected, not where it occurred, and which at the moment caches input, so even after fixing the problem it reports the old problem.\n\nCallum Gibson is the main user of RSS feeds whom I know of. He pointed me to this validator. It also points to where the error was found, but at least I can try things and repeat them. That fixed an issue I had with earlier this month, where the error was over 100 lines from where it was detected.\n\nChasing the VirtualBox bug Topic: technology Link here\n\nSo why was VirtualBox version 7.1 on dereel even worse than version 6.50 on hydra? One possibility might be that the VMs themselves were NFS mounted. OK, find a 1 TB disk and copy them there. Put it in in place of the DVD drive, and was amazed to find that it came up as /dev/ada0, relegating the system disk to /dev/ada1 and requiring manual intervention (/etc/fstab) to continue. How could that happen?\n\nThen copying the VMs from hydra. That took a few hours, of course, so I'll continue tomorrow.\n\nWhile looking for the disks also found one marked “MS “Windows” 10 disgust”, dated 10.XII.2020. Comparing with my diary, that proves to be the disk that came with the machine I'm working on. So I should be able to just put it in and run it. That's the next thing to do if I still can't get VirtualBox to run reliably.\n\nDxO PhotoLab 9: worth the trouble? Topic: photography, technology, opinion Link here\n\nI've spent a lot of time looking at the new features of DxO PhotoLab 9. Even better noise reduction, of course, but the big new thing is what appears to be excellent object recognition (“masking”). But that's only part of the story. Can I remove objects? Replace them with something else? It seems that the answer is “no”.\n\nSomewhere I also thought I saw a way to merge HDR images, but that seems to be a misunderstanding. Instead they have improved file handling, including collapsing related image groups and automatic file naming. None of them seem to be anywhere near as flexible as the method I worked out 13 years ago, so it's of no use to me.\n\nSo: what will the future bring? The masking is good, but is it enough to spend US $240 on? There's a very good chance that they'll come up with a version 10 in the not-too-distant future and want $120 for an upgrade. Maybe I should just wait.\n\nVicRoads: still in the 20th century Topic: general, technology, opinion Link here\n\nAfter scrapping my Hyundai Elantra at the end of July I was due a refund for the registration.\n\nAnd they sent me a cheque! I thought they went out of fashion well over a year ago. And yes, the bank refused to accept it.\n\nBut why? I really don't understand. They should have transferred it to my bank account, like any sane company. But no, I had to call their customer service line (1300 555 165, which looks suspiciously like a fake US phone number) and go through their silly authentication process (including a form of 2FA, sending a PIN to my phone. That would have helped a lot if I had been calling from that phone). But yes, relatively quickly they took the details and told me that the transfer would occur in the next 2 to 3 weeks. Receipt number HD1155831.\n\n2 to 3 weeks? Why? Ah, we need human intervention. Why? Nowadays we have computers. With only marginally good programming the money could have been in my bank account before the end of the call. But clearly they don't have that.\n\nMore VirtualBox insights Topic: technology, opinion Link here\n\nSo what's wrong with VirtualBox networking? Google Gemini had suggested that it might depend on the emulated network adapter, so spent some time trying different adapters, with no improvement. About the only thing that was clear was the ping time: from guest to host the expected 0.15 ms, but in the other direction much longer, and with wildly different times:\n\nround-trip min/avg/max/stddev = 29.752/61.679/175.892/36.953 ms\n\nGave that up and looked at some bug reports, which showed surprisingly few network issues. But one, by Ivan Rozhuk, was interesting:\n\nTry to disable HW offloads on NIC:\n\nifconfig igb0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n\n\nAnd how about that, that worked. So why is this not better known? There's also a wiki with surprisingly little of use.\n\nLater I discovered that my guest current.lemis.com had 8 CPUs, while the host dereel only has four. That's quite impressive that it worked at all. Reducing the number of CPUs on current got rid of the slow ping times.\n\nSo: are we done? I don't think so. I still need to find whether the Microsoft guests work reliably.\n\nBruce Evans' C compiler Topic: technology, opinion Link here\n\nMail in the TUHS mailing list today:\n\nSubject: [TUHS] Bruce Evans 386 Minix patches & compiler source\n\n\n\nIt's been quite a while since I was messing with Minix386 back in the days\n\nwhen Bruce Evans released a set of patches to bring 386 support.\n\nI'm pretty sure over on oldlinux.org the patch set exists, but I can only\n\nfind the one set of binaries of his 386 toolchain.\n\nI know it eventually evolved into the bin86 toolchain that Linus would go on\n\nto use to create real mode boot code, but I don't know if any of the source\n\ncode to his 1991/1992 386 toolchain ever got published?\n\n\n\nIs it somewhere on the disk images that Peter Jeremy saved? I haven't looked at them for over three years, and I only had the smaller ones that I could download. Sent off a message to the other people who have access, Warren Toomey (who also coincidentally runs TUHS) and Warner Losh, and only got a brief response from the first.\n\nBack to look at what I have: three files, /src/bde/ad1.img, /src/bde/ad2.img and /src/bde/ad3.img. I had only looked at /ad0.img, requiring gnop to access the individual partitions. There was a good reason: I had renamed ad2.img.xz to ad2.img without uncompressing it. Did that now and ended up with 60 GB of data.\n\nAnd the contents?\n\n=== root@dereel (/dev/pts/1) /bde 13 -> mdconfig -a -t vnode -f /src/bde/besplex/ad2.img\n\nmd0\n\n=== root@dereel (/dev/pts/1) /bde 14 -> l /dev/md0\n\nmd0 md0s1 md0s2 md0s2a md0s2b md0s2d md0s2e md0s2f md0s2g md0s2h\n\n\n\nAll the BSD partitions there! So I can just mount them:\n\n=== root@dereel (/dev/pts/1) /bde 15 -> mkdir a b d e f g h\n\n=== root@dereel (/dev/pts/1) /bde 16 -> l\n\ntotal 1\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 a\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 b\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 d\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 e\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 f\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 g\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 h\n\n=== root@dereel (/dev/pts/1) /bde 35 -> for i in `echo a b d e f g h`; do mount -o ro /dev/md0s2$i $i; done\n\nmount: /dev/md0s2a: No such file or directory\n\n=== root@dereel (/dev/pts/1) /bde 36 -> df\n\nFilesystem 1048576-blocks Used Avail Capacity Mounted on\n\n...\n\n/dev/md0s2b 3,952 3,542 93 97% /bde/b\n\n/dev/md0s2d 3,952 2,971 664 82% /bde/d\n\n/dev/md0s2e 3,952 3,658 -21 101% /bde/e\n\n/dev/md0s2f 3,952 3,514 121 97% /bde/f\n\n/dev/md0s2g 11,754 8,842 1,972 82% /bde/g\n\n/dev/md0s2h 29,525 14,599 14,926 49% /bde/h\n\n=== root@dereel (/dev/pts/1) /bde 37 ->\n\n\n\nAnd in one of the partitions I found a file /bde/e/besplex/home/bde/dist/minix.tar.gz, which may be just what Jason is looking for. That was much easier than I thought. Is it correct? That would be too easy.\n\nMore fun with VirtualBox and bde Topic: technology, opinion Link here\n\nMore playing around with VirtualBox today, with no breakthrough. I had paused dereel with zzz, and when I restarted it the networking had gone to hell again. Here a repeat of what I had done yesterday:\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 1 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500 options=4e524bb<RXCSUM,TXCSUM,VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,LRO,WOL_MAGIC,VLAN_HWFILTER,VLAN_HWTSO,RXCSUM_IPV6,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 2 -> ifconfig em0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 3 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500\n\noptions=4c120b8<VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,WOL_MAGIC,VLAN_HWFILTER,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n\n\nAfter that it worked normally again, but the Microsoft boxen still didn't want to know. Do I have to cold start them every time?\n\nAnd Bruce Evans' C compiler? I posted what I had and got no answer. I'm not convinced that I have the right files, though the name usr/src/mx386/bcc (from the archive e/bde/dist/minix.tar.gz) does raise some hope.\n\nPower fail! Topic: general, technology, opinion Link here\n\nAt 11:04, while preparing breakfast, we had a grid power failure. Not a problem: we have a PV system. But the power dropped totally! Almost before we knew it, it was back again. The inverter log shows less than a minute.\n\nThat's not the first time. It happens far too often, most recently two months ago. And today, as then, my main machines eureka and hydra lost power, because I still hadn't got round to getting a UPS installed. Today I made up for that: I have a ten-year-old 1000 VA 650 W UPS just lying around. It is still functional? In contrast to the CyberPower UPS that I bought 2½ years ago, it seems still to work. While the power was down, took the opportunity to tidy up the mess to the left of my desk top, removing this display card from eureka and making a cut in my fingertip in the process:\n\nThat once drove three of the four monitors then connected to eureka, but that was years ago, as the dust suggests.\n\nWhat caused the outage? Hard to say. The inverter logs show no sign of overvoltage before the outage, though afterwards the voltage hung over 250 V for over an hour. I suppose it's time to brave the potential issues and update the firmware.\n\nPowercor had a different view. An hour later I received a message:\n\nAnd then\n\nOn checking, I found that I also had similar messages from the day before, where there was no outage at all. Still, rather phantom outages than real ones.\n\nhydra upgrade Topic: technology, opinion Link here\n\nI've had hydra for nearly 2 years, and I still haven't got round to configuring it quite the way I want; much is in the X menus. But of course the system is now down-rev. What better time then after a power failure to bring it up to date?\n\nMy real concern after an update is that the ports will no longer work the way I want. Building a new world is relatively simple, and it took just shy of 1000 seconds to build the world and new kernel. And rebooting went relatively smoothly, though it no longer found the Ethernet card on the motherboard. I had suspected issues in that area (it's a 2.5 Gb/s Realtek card) and installed a second, which showed up as re0 , so all I needed to do was to change where I plugged in the network cable.\n\nAs I feared, the ports were a different matter. They were worse then ever before, taking 3 iterations to delete 100—no, 101—no, 103 ports, including chromium curl, emacs of course, enblend, exiv2, feh, ffmpeg, firefox, fusefs-curlftpfs, gdb, git, gnupg, groff, hugin, mplayer, mpv, mutt, rdesktop, rsync, rtorrent, vigra, virtualbox-ose, xpdf and xv. And even then I missed ImageMagick, which further annoys me with a change of name. Yes, convert is a subcommand of ImageMagic, but now they have decided that the name is too invasive, so I'll have to change all invocations to magick convert. I suppose that one's fair enough.\n\nAnd firefox has new messages, which it spews by the hundred where it presumably suspects nobody is looking, on the home terminal:\n\nconsole.warn: services.settings: Could not determine network status. Message: TypeError: can't access prop \"isLinkUp\", lazy.gNetworkLinkService is undefined\n\nGradually the issues became clear: I can no longer connect to eureka with ssh, nor at all to hydra. I was expecting issues with eureka, but not with hydra. Was it because it came up before the network was ready? I had to restart syslogd to get it to write to eureka, and to change the permissions on wake for normal users to use it.\n\nWhat am I left with? I can no longer use erc, the Emacs IRC command:\n\nerc: missing symbol (.at)\n\n⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.\n\n\n\nWhat does that mean? I'll find out some time. Fortunately it still works on eureka, so there's no hurry.\n\nAnd independently of all that I need to pay more attention to my X configuration. I still don't get my mice set up correctly at startup. But that's fun for another day.\n\nCompleting the upgrade Topic: technology, general, photography, opinion Link here\n\nInto the office this morning as usual. No mail from hydra. What happened there? /var/log/maillog showed a number of:\n\nSep 20 03:03:54 hydra postfix/cleanup[70392]: B1BC41AB5: message-id=<202509191703.58JH3sRP070451@hydra.lemis.com>\n\nSep 20 03:03:54 hydra sendmail[70451]: 58JH3sRP070451: to=root, ctladdr=root (0/0), delay=00:00:00, xdelay=00:00:00, mailer=relay, pri=33687, relay=[127.0.0.1] [127.0.0.1], dsn=2.0.0, stat=Sent (Ok: queued as B1BC41AB5)\n\nSep 20 03:03:54 hydra postfix/qmgr[1845]: B1BC41AB5: from=<root@hydra.lemis.com>, size=4303, nrcpt=1 (queue active)\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: unexpected attribute smtputf8 from local socket (expecting: sendopts)\n\nSep 20 03:03:54 hydra postfix/smtpd[70368]: disconnect from localhost[127.0.0.1] ehlo=1 mail=1 rcpt=1 data=1 quit=1 commands=5\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: deliver_request_get: error receiving common attributes\n\n\n\nWhat's smtputf8 ? Checking /usr/local/etc/postfix/ showed that a number of files, which should have been symlinks to the same directory on eureka, were missing. Forgot to mount a NFS file system. After mounting and restarting postfix, all was well. But what does the strange message mean? It seems that it's a default.\n\nAnd then there was Hugin. I had expected some issues, but not what I got: when I tried to start the “fast panorama preview” I got\n\nerror installing GLEW\n\nFast preview window can not be opened\n\nWhat does that mean? I have a package installed, which pkg reports as\n\nglew-2.2.0_3 OpenGL Extension Wrangler Library\n\nAnd there doesn't seem to be anything else that was there before. But when I retried the attempt, it worked. Where is the bug? Hugin or FreeBSD? In addition, irritatingly it resized the windows on every start. I thought I had got rid of that with some script magic, but it seems to be gone.\n\nAnd then there's the mouse. That's simple enough: instead of searching for the index for the mouse, it's easy enough to write\n\nxinput set-button-map \"Telink 2.4G Mouse\" 1 2 3 4 5 6 7 2 2 10\n\nOne of the messages I received was completely misleading:\n\n=== grog@hydra (/dev/pts/16) ~/Photos/20250920 47 -> (EE) event4 - Telink 2.4G Mouse, class 0/0, rev 1.10/1.00, addr 4: client bug: event processing lagging behind by 32ms, your system is too slow\n\n(EE) client bug: timer event4 debounce: scheduled expiry is in the past (-48ms), your system is too slow\n\n(EE) client bug: timer event4 debounce short: scheduled expiry is in the past (-61ms), your system is too slow\n\n\n\nThat's not hydra at all, despite the prompt. I started X on teevee from hydra, and this appears to be its way of saying “the cat got on my mouse”.\n\nAccessing systems with ssh from eureka Topic: technology Link here\n\neureka is now running a nearly 10 year old system, but I don't want to update it: it works.\n\nBut some issues remain. One was that I couldn't automatically log on with ssh: I had to enter a password, which is irritating in scripts. Once again Google Gemini to my aid. Add this to /etc/ssh/sshd_config:\n\nPubkeyAcceptedKeyTypes=ssh-ed25519,ssh-rsa,rsa-sha2-512,rsa-sha2-256\n\nNow I just need to see why I can't access eureka from hydra without a password.\n\nFinally the birding photos Topic: photography, animals, technology, opinion Link here\n\nIt's been 4 days since the latest OM System birding “workshop”, and I've only just got round to processing the best photos. Are these the best?\n\nIt's a lot of work making up my mind out of over 250 photos. Yvonne did it for me, and those were the ones she liked.\n\nMore ssh strangeness Topic: technology, opinion Link here\n\nI've already established issues with ssh sessions from hydra to eureka, but not from other systems. Once again Google Gemini to my aid, this time less useful. It tells me to allow ssh-rsa in /etc/ssh/sshd_config by adding this line:\n\nPubkeyAcceptedKeyTypes=+ssh-rsa\n\nWe've seen that before on the other side. But that's a non-starter: sshd doesn't want to know:\n\n=== root@eureka (/dev/pts/1) /etc/ssh 28 -> service sshd restart\n\nPerforming sanity check on sshd configuration.\n\n/etc/ssh/sshd_config: line 54: Bad configuration option: PubkeyAcceptedKeyTypes\n\n/etc/ssh/sshd_config: terminating, 1 bad configuration options\n\nOK, what about the alternative of using a key?\n\n=== root@eureka (/dev/pts/1) /etc/ssh 32 -> service sshd restart; date\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStopping sshd.\n\nWaiting for PIDS: 22656.\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStarting sshd.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\n\n\nWhy? It doesn't seem to affect other key forms. And comparing hydra and tiwi gives me on hydra:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: send_pubkey_test: no mutual signature algorithm\n\n\n\nBut on tiwi it works as expected:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: Server accepts key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\nAuthenticated to eureka.lemis.com ([192.109.197.137]:22) using \"publickey\".\n\n\n\nWhat's the difference?\n\nMutt problems Topic: technology, opinion Link here\n\nFirst thing I do in the morning is to read the overnight mail, typically a couple of hundred messages. But this morning I tried to delete the messages I had read, I received the message “unable to write mailbox” or something similar. Why? Normally I see a message like that when I'm out of disk space, but this wasn't the case. Return, painfully delete the messages again, and it worked. Is that an NFS issue? It has happened before. Was that also overnight? I'll have to look more carefully next time.\n\nMore ssh pain Topic: technology, general, opinion Link here\n\nInto the office this morning to find eureka maxed out with at least 35 ssh-add processes, all looping at 100% CPU time.\n\nWhy? This is not a new program:\n\n3054180 -r-xr-xr-x 1 root wheel 17576 25 Nov 2015 /usr/bin/ssh-add\n\nOnce again Google Gemini to my aid, coming with the suggestion that it could be that ssh-add was running already, and that I should put in code like\n\nssh-add -l >/dev/null || ssh-add\n\nThat worked up to a point, but it doesn't explain why it is only happening now, after nearly 10 years. It's much more likely that it's related to the playing around I have been doing lately, though it didn't affect ssh-add, and I had backed out the changes anyway. And in the course of the day I found another instance in my weather software, but that found further breakage: the external view of my weather stopped in early June when I got the new weather station. More to fix when the current problems are over.\n\nssh-add: A clue Topic: technology, opinion Link here\n\nI haven't done much to investigate the ssh-add problem for the moment. It seems that I call ssh-add in a number of places, all of which need fixing. But while playing around I found:\n\n=== grog@eureka (/dev/pts/3) ~/public_html 32 -> ssh-add < /dev/null\n\nEnter passphrase for /home/grog/.ssh/id_rsa:\n\nCould it be that the looping is the incorrect handling of a prompt? It doesn't help much in fixing it, but it could help understand.\n\nThe advantages of upgrades Topic: technology, opinion Link here\n\nAs expected, upgrading hydra caused a number of problems, most of which I have described. And this time it was Chromium, which has forgotten all its editing keys, or at least the ones I want. More searching required.\n\nOn the other hand, one bug has gone away: xv can now display PNG again. Not exactly a big improvement, but at least a fixed bug.\n\nThe daily Android bug Topic: technology, opinion Link here\n\nSomehow the Android operating system seems to be the least reliable I know. I'm gradually coming to terms with it, but today there was another one: trying to download files to a Real Computer, albo didn't respond, though it claimed to be working. Disable Wi-Fi, reeenable, and it worked. No change of connection.\n\nWhat a mess Android is!\n\nAnother web server overload Topic: technology, opinion Link here\n\nIt's been well over 4 months since I set up a new external web server, fra.lemis.com, to address the really heavy load, with load averages up to 170. And so, of course, it dropped back to under 1.\n\nBut now it's increasing again, both servers now well over 200. Why? I had thought it was related to the imagesizes parameter, but that doesn't seem to be the case. Let's see how long the overload lasts this time.\n\nFast postal service Topic: general, technology, opinion Link here\n\nI've bought a couple of cameras in the United Kingdom. The usual tracking information, with a twist:\n\nIt's in Leeds, but it'll be here tomorrow! Now that's a lot faster than Australia Post. Or just plain stupid.\n\nYour cameras have been delivered! Topic: technology, photography, general, opinion Link here\n\nYesterday's claim of fast delivery was amusing enough, but they haven't given up:\n\nThey have been delivered! How did we do?\n\nI'm amazed. Clearly the cameras are still in the United Kingdom. My best guess is that Royal Mail have delivered the cameras to the people who are currently in the process of sending them half way round the world, or at least they have received documentation from them. So from their limited viewpoint they have been delivered. No concept of them only having travelled a fraction of the distance.\n\nWeb server load: dropping Topic: technology Link here\n\nYesterday's web server overload didn't last long. It's back to round 1 again. I suppose that's what we're going to have to live with for the foreseeable future. It's interesting that even at this extreme overload people claimed that response was satisfactory. That's significantly different from last time, where some sites got timeouts.\n\nArtificially intelligent breakfast Topic: food and drink, technology, opinion Link here\n\nFor some reason we bought a quarter cabbage recently. I forget why, but it was intended for breakfast. All right, Google Gemini, give me some east asian recipes with fried cabbage.\n\nAnd the twins obliged: 手撕包菜 - Shǒu Sī Bāo Cài, “hand shredded cabbage\", which didn't look too bad, modulo these horrible cups measurements. I can't even blame the twins for that: so many recipes use it. But it's the biggest hindrance I can find for trying out recipes. OK, Gemini, give me a Chinese recipe with fried cabbage and noodles using metric units. OK, how about 包菜炒粉/麵, which Google Translate translates as “cabbage fried rice noodles”? A completely different recipe! The best I can guess from the two recipes is that 4 cups of cabbage weigh about 300 g.\n\nSpent some time—probably more than cooking—writing a sane version of the second recipe.\n\nSoftware upgrades: the sting in the tail Topic: technology, photography, opinion Link here\n\nHouse photos again today, the second time since I upgraded hydra to FreeBSD 14.3 last week. And once again I had pain.\n\nFirstly, creating HDR didn't work well. It took me a while to discover that it was an unrelated bug in one of my scripts: I managed to mix images from the OM System OM-1 Mark II with the correct images from the Olympus OM-D E-M1 Mark II. I had already expected problems like that, and /Photos/Tools/housephtos.awk contained appropriate comments. Here the fix:\n\n-# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n+# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n# Create a makejpeg file from housephoto.notes file.\n\nBEGIN {\n\ni = 0;\n\n-# XXX Only look at photos from E-M1 Mark II.\n\n+# Only look at photos from E-M1 Mark II.\n\n# Is this safe?\n\n-# Was: 4*.ORF, E-M1 /2 only\n\n- while (\"ls -rt *.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n+# It's better than the alternative.\n\n+ while (\"ls -rt 4*.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n\n\nThe problem was that I didn't limit the choice to photos from the E-M1 Mark II. Not an upgrade problem at all.\n\nThe other, though, seems to be related to the upgrade of Hugin, now version 2024.0.1. The screens appear in the wrong place and at the wrong (tiny) size, and the directories are wrong. That's almost certainly related to the scripts that I wrote over 16 years ago which frob the ~/.hugin file to get rid of this horrible directory name retention. But that's all they do, and somehow it doesn't seem to work. A small detail, but irritating. Will I get round to it by next week?\n\nRevisiting old photos Topic: photography, technology, opinion Link here\n\nLooking back through old photos, found some of my first panoramas:\n\nIt dates from 11 April 2009 with the Olympus E-510, so old that I don't even have Exif data for it. I had already attempted to improve it 8 years later:\n\nBut that was still with the Ashampoo Photo Optimizer, which I have stopped using. Another attempt with “Perfectly Clear” gave me further improvements. Here are the three together (run the cursor over an image to compare it with its neighbour):\n\nIn particular the highlights and shadows are greatly improved.\n\nfra rebooted! Topic: technology, general, opinion Link here\n\nThe vultures have rebooted fra! Yes, they warned they would do so because of some unspecific bug in Linux, so they rebooted my FreeBSD box as well. The good news is that it came back without any intervention on my part, but of course the up time has gone to hell.\n\nAnother bloody power fail Topic: technology, general, opinion Link here\n\nIn the evening, another grid power failure. And another directly behind it. Both were sub-second, but once again eureka and hydra failed. So much for the UPS.\n\nWhy? Yes, it's an old UPS, but it claims to have plenty of charge, and the failures were so short that most clocks in the kitchen kept going. Can it be that it was a power surge, and that this UPS didn't handle it? The UPSs for lagune, teevee and tiwi had no problems.\n\nAnd the fallout? I got things running relatively quickly, but firefox didn't recover its many tabs. I had to start a different profile to get anything. And of course X on teevee failed, because I had started it from hydra.\n\nSo what do I do now? Buy more of UPSs of the kind that power the other machines?\n\nTuesday, 30 September 2025 Dereel Top of page previous day\n\nMore firefox pain Topic: technology, general, opinion Link here\n\nSo what's wrong with firefox? My standard profile just hangs. Why? How do I debug such a mess?\n\nI tried setting up a different profile, losing a number of tabs in the process, but nothing I could do could get the font sizes right. Get them right for my diary (without any trickery) and they're far too small for things like Wikipedia and friends. Migrate from hydra:0.2 (3840×2160) to hydra:0.0 (1920×1080)? Yes, that works, but why did it happen?\n\nThen it occured to me: yes, the standard profile still hangs. But I can check the settings. And it seems that the big thing is the Zoom setting, which was at 150%. After setting that, things were OK. But why the difference between my diary and Wikipedia and Co.? And why are font sizes such an issue with firefox?",
      "source": "Lemis.com",
      "url": "http://www.lemis.com/grog/diary-sep2025.php?topics=c#D-20250909-004539",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "DxO PhotoLab 9: worth the trouble?",
      "content": "AI: enough! Topic: technology, general, opinion Link here\n\nSunday's detailed investigation of generative artificial intelligence should have been enough, but it occurred to me that there was one thing I hadn't tried: graphics. OK, draw me a caricature of Greg Lehey.\n\nGoogle Gemini came up with this:\n\nOf course I don't need to like the results, but this shows very little understanding: no mention of BSD, just Linux (or even “Linix”). Yvonne tells me that it looks nothing like me. Compared to the text results, quite disappointing.\n\nAnd that was all. My other bots all couldn't do it. But their attempts were worth mentioning:\n\nChatAI\n\nI'm unable to draw images directly, but I can help you imagine a caricature of Greg Lehey! Picture a gentleman with a thoughtful expression, perhaps with glasses perched on his nose, and a hint of a smile suggesting a keen sense of humor. His hair might be slightly tousled, giving him a scholarly yet approachable look. You could exaggerate his features, like giving him a larger forehead to symbolize his intellect or a prominent chin to represent determination. Add a background filled with books and computers to reflect his interests in technology and writing\n\nI suppose that's acceptable for as far as it goes.\n\nClaude\n\nClaude did the best with the diary entry, but it failed completely with the caricature:\n\nClaude: I'd be happy to help you create a caricature, but I'll need a bit more information! There are likely multiple people named Greg Lehey, and I want to make sure I'm drawing the right person..\n\nClaude, you know who I am. There are “likely” multiple people named Greg Lehey? That wasn't a problem on Sunday. And as it happens, there is nobody else that I can find with the same name as mine. But OK, draw me a caricature of Greg Lehey, the FreeBSD person.\n\nI can't create visual caricatures or drawings as I'm a text-based AI. However, I'd be happy to help you in other ways: Written description: I could write a humorous written \"caricature\" or character sketch of Greg Lehman (assuming you meant Greg Lehman, a notable FreeBSD contributor) that captures his programming style, contributions to FreeBSD, or personality traits in an exaggerated, caricature-like way.\n\nWhat a cop-out! Now it says that it can't draw. And it comes up with a fictive Greg Lehman. That's completely useless.\n\nDeepSeek\n\nAs before, DeepSeek is inventive:\n\nWhile I can't physically draw for you, I can create a detailed \"blueprint\" for a caricature of the legendary BSD developer Greg \"Groggy\" Lehey. An artist could follow this description to create the perfect caricature. Here is a description designed for an artist to illustrate. Caricature of Greg \"Groggy\" Lehey Concept: The caricature should capture his iconic, jovial, and slightly mischievous personality, deeply intertwined with his life's work: BSD and Unix. Key Features to Exaggerate: The Beard and Hair: This is the #1 feature. Exaggerate his magnificent, full, and sprawling white beard. Make it vast and wizard-like, almost as if it's its own entity. It should be big enough to have a Daemon (the BSD logo) peeking out from within the whiskers, as if it lives there. His hair (what's visible under his hat) should be similarly wild and unkempt. The Headwear: He is almost never seen without a hat. Draw a slightly battered, well-loved flat cap or a beret perched on his head at a jaunty angle. Where did it get the hat from? I am almost never seen with a hat. The Expression: A wide, knowing, and cheerful grin. His eyes should be crinkled with laughter and wisdom, suggesting he's both a kind mentor and someone who knows where all the bugs in the code are hidden. The Props & Surroundings: In his hand: Instead of a coffee mug, he should be holding a massive, steaming beer stein. This is a nod to his famous \"Buy me a beer\" link on his website and his good-humored nature. Steaming beer? I can't even imagine that. And instead of referring to my brewing activities, it refers to a fictive “buy me a beer” link, which may be related to Poul-Henning Kamp. Under his arm: A well-worn copy of his magnum opus, \"The Complete FreeBSD\" book. Background Element: Have a Tux (the Linux penguin) peeking from around a corner, looking slightly nervous or annoyed, while Groggy pays it no mind. This playfully hints at the good-natured rivalry between BSD and Linux. Code: Faint lines of C code ( #include <beard.h> , printf(\"Cheers!\n\n\"); ) can be subtly woven into the texture of his shirt or the background. Overall Vibe: The image should feel warm, intelligent, and full of character. He is the friendly, brilliant, and slightly eccentric \"Unix Beard\" wizard, a beloved figure in the open-source community. Color Palette: Warm tones. Earthy browns for the hat, a rich color for the shirt (green or blue), the brilliant white of the beard, and the gold of the beer.\n\nStill, I suppose that could produce something useful. But where are all the image generators? Do I want to look? I've spent enough time on this already.\n\nWhy don't people read any more? Topic: language, general, technology, opinion Link here\n\nRecently I saw (but didn't read) a newspaper article, possibly from the New York Times, asking why people don't read books any more. The answer appears simple: information overload. When I was a lad I read lots of books, but it has been some time since I finished reading any, and then the relatively thin “Brave New World”.\n\nBut then we watched A Town Like Alice, and Yvonne borrowed the book. I have always liked Nevil Shute, and I have a number of his books, so I read it when she finished. It took me two weeks. While reading I was continually following up on details mentioned in the book—that's what the web is for, after all. In general, I ended up with a much broader view than I would have had if I had just read the book.\n\nAnd how did I like it? Not much. Clearly it's two different stories stuck together: the ordeals in Malaya at the hand of the Japanese occupation and the transformation of a tiny bush village in Queensland into a small town. The latter, in particular, seems very improbable.\n\nThe geographical details are what interested me most. Particularly in Malay(si)a I knew most of the real places. But I'm puzzled about why Shute spends a lot of time in the area Maran and Jerantut in the Jengka Triangle, places that must have been almost completely unknown at the time, but puts the women in a place called Kuala Telang “about half-way between Kuantan and Kota Bahru”. There is a town in that position, but it's called Kuala Terengganu, and it's a big town (capital of the state of Terengganu), not a small village. My guess is that Shute had never heard of it.\n\nSpelling is also strange. In the first half of the book, Kota Bharu was spelt “Kota Bahru”, and in the second half “Khota Bahru”. Tennant Creek became “Tennants Creek”. These spellings are the same both in the online book and the physical book that I read. And there are a couple of irritating US Americanisms that I don't understand: the animals central to the theme are called alligators, not crocodiles. The stockmen use lariats.\n\nThen there's the question of racial attitudes. The local aborigines (or aboriginals, to use the modern politically correct term) are called “boongs” or “abos”. Both are offensive nowadays. And there was talk of racial segregation, a separate milk bar for the boongs. This would have been about 1948, the time of my birth. Did such segregation really exist then?\n\nMy favourite one, though, is when the main characters (Jean and Joe) fall in love, and she decides not to sleep with him until after they are married. Given that Joe had been crucified in the first half of the story, I was half guessing that he might have been castrated at the same time, and Jean would not have found out until too late.\n\nIn summary: reading books has become much more of an exercise than it used to be. For light entertainment we have TV. I don't think I'll read another novel for some time to come.\n\nPredicting the past Topic: general, technology, opinion Link here\n\nI keep a close eye on the weather forecasts from the Bureau of Meteorology, both of them. There's one on the web and another for mobile phones. They don't often agree with each other, and of course they're both frequently wrong.\n\nToday, though, the mobile phone app excelled itself. We finally have rain, 6 mm over the last 24 hours. Or, as the app put it,\n\nPart of the app is a rainfall map showing precipitation. That showed that there was much more rain. How can that happen?\n\nWhatsApp: bug after bug? Topic: technology, opinion Link here\n\nI've been trying for a week now to set up video telephony on fossil, Yvonne's mobile phone. Somehow the “modern” approach to user interfaces shows itself at its worst here. But I had come to the conclusion that if I can work beyond WhatsApps bizarre interface, and explain it to Yvonne so that she doesn't have a panic attack every time she uses it, we might have something useful, especially since WhatsApp can communicate by an Internet link, which could be much cheaper.\n\nOK, try out on hirse first. It doesn't have a SIM card, so any communication has to go by the Internet. Migrate my main number to hirse. No problem. Make a call. Some message like “need to use the phone network”. Oh.\n\nTry calling in. The problem: hirse has the phone number associated with a SIM card in albo, which has a different WhatsApp number. Which does WhatsApp call? albo! Somehow there's more to this than meets the eye.\n\nWhen Yvonne got back from shopping, I changed her WhatsApp number to the number of second SIM on her phone. All sorts of things didn't work, and it couldn't call the number on hirse. hirse claimed that she wasn't registered, though I had set the “notify contacts” during the migration. In the end I moved the number back to the old one. And things still didn't work correctly! In particular, I could call the number, but WhatsApp didn't respond in any way, not even registering a missed call. Went through the settings and set tones for all notifications. Still no response. Restart the app. No response.\n\nNothing for it, the Microsoft solution: reboot. And yes, now it responds. Clearly some kind of bug. And it repeats the call tone for every notification, including messages. Oh, my bad. Get rid of the tone. Sorry, there's no provision for that. Select something at random, since it's too polite to play the tone when you're selecting it. I still get the ring tone for messages! I can't see any explanation except that it's another bug. It was getting late, so I turned off sounds to wait until tomorrow.\n\nAll this is made worse by the horrible user interface. So far I haven't found a way to display the associated phone number in the contact details. At one point I made the mistake of using the same name (mine) for both my phones, so there was no way at all to find out what “number” it had called.\n\nI hate WhatsApp! Topic: technology, general, opinion Link here\n\nMore fun with WhatsApp today. The first question, which decides whether it's even worthwhile: can I make a call over the Internet? Yesterday's experiments were overshadowed by other bugs. Today I tried making a call from fossil (Yvonne's phone) to hirse, the one without a SIM card. I have set it up with the main number of albo, so a normal call to that number should go to albo, and a WhatsApp call should go to hirse. Does it?\n\nYes! So yesterday's issues were probably due to other bugs.\n\nAnd the incorrect notification tones? Gone since the last reboot, Yvonne says. But later she changed her mind: once again the wrong tone when all notification tones were turned off.\n\nDammit, begone, WhatsApp! Removed it. Reinstalled it. And how about that, setup was almost completely without problem. She lost her image (“Avatar”, “The manifestation of a god in bodily form on earth” according to the OED). We can live with that. And somehow now everything Just Works—until the next unpleasant surprise.\n\nApart from that and the horrible user interface, established that you can change an audio call into a video call simply by pressing the button with the box with a loudspeaker on the right:\n\nInterestingly, it only works in one direction. To go in the other direction requires that the person at the other end do the same.\n\nVirtualBox again Topic: technology, photography, opinion Link here\n\nDxO PhotoLab 9 is out, and it looks worth trying. Time to reinstate one of my Microsoft virtual machines, which run under VirtualBox.\n\nI stopped using VirtualBox on hydra a year ago, though it was the main reason that I had so much memory (192 GB): I ran into network problems that I couldn't fix.\n\nNow FreeBSD has a port of VirtualBox 7. Time to try again? Tried first on dereel, with only 24 GB of memory. Where's my HOWTO? All fine, but it doesn't tell me how to add an existing VM. It must be in this diary somewhere, but where? I really should keep these HOWTOs up to date.\n\nStarting up the GUI was different from before, of course. And it wanted to set things up in the root file system. To go elsewhere I had to do this horrible tree walking. Finally I got to where I wanted (/src/VirtualBox/echuca). Tried to create a new VM. “Can't overwrite machine folder...\". What does that mean? They should know better than to call a directory a folder, but what's a “machine folder”? Lots of experimentation, continually being returned to the /root directory and having to climb my way out again. What does “help” say? Nothing. I wonder if the port forgot to install something important. After a while I discovered that it really wanted the parent directory /src/VirtualBox, but then I ran into other issues.\n\nAfter some time decided to create a new VM with the old virtual disk. Link? Yes, but VirtualBox detected the UUID and used the old name.\n\nYes, there are other possibilities. But I think that the best is to go through my diary and extract the information that I need to do things sanely. And maybe I should use the commands rather than the GUI, which seems to be getting more stupid as time goes on.\n\nWhatsApp an Avatar? Topic: technology, general, opinion Link here\n\nYesterday I established that an Avatar is a earthly manifestation of a Hindu god, but WhatsApp apparently wants to elevate Yvonne and me to deities. Until then, only initials appear to identify us on calls.\n\nOK, how do we do that? Settings, of course, “make your own avatar”, “Create from selfie”. OK. Take a suitably horrified photo of myself. Briefly it showed “There was an error with the avatar gen...”, so briefly that I didn't see it the first three times. What does that mean? Why can't it finish its sentences? So instead it presented me with a manual generation.\n\nWhy? What does the half message mean? It's repeatable on two different phones. And there seems to be no way to just add a normal photo. What a mess!\n\nVirtualBox progress Topic: technology, opinion Link here\n\nSo what's wrong with my VirtualBox installation? My current situation was exactly what I had a year ago: most VMs worked, but Microsoft VMs had networking problems. They could send data, but they didn't see the replies, so they hung in ARP. I attributed that to the version of VirtualBox (6.1.50 r161033), so I waited until version 7 came out. And then I discovered that I had exactly the same problem.\n\nThat didn't help just getting things running. After some searching, discovered that VirtualBox stores a configuration in the home directory, ~/.config/VirtualBox/ with a number of files, including log files that have no business there, but importantly VirtualBox.xml. OK, make a copy of that on dereel, and how about that, VirtualBox came up with all the VMs I knew.\n\nStart disaster, the only VM that would fit in dereel's memory.\n\nVT-x is disabled in the BIOS for all CPU modes (VERR_VMX_MSR_ALL_VMX_DISABLED).\n\n\n\nOh. There was something there, but can the twins help? Yes, specifically for a ThinkCentre:\n\nOnce in the BIOS, use the arrow keys to navigate to the Advanced tab. From the Advanced menu, select CPU Setup and press Enter. Look for an option labeled Intel(R) Virtualization Technology and select it. Using the arrow keys, change the setting from Disabled to Enabled.\n\nAfter that and rebooting, and with a change of network adapter name, it still didn't start. I got this message:\n\nX86_CPUID_AMD_FEATURE_EDX_AXMMX is not supported by the host but has already exposed to the guest [ver=19 pass=final] (VERR_SSM_LOAD_CPUID_MISMATCH).\n\nMore help from the twins. The saved state includes information from an AMD processor (hydra), but this is Intel. Discard saved state and start again.\n\nAfter that, and with a change of network adapter name, it started. I got this message, which I haven't seen before, but which seems harmless:\n\nerror: XDG_RUNTIME_DIR is invalid or not set in the environment.\n\nThat variable isn't set on hydra either.\n\nWe're still not done. Trying to start an xterm from current gave me the message\n\nThe Virtual Machine reports that the guest OS does not support mouse pointer integration\n\nWhat's that? Gemini tells me:\n\nThe message \"The Virtual Machine reports that the guest OS does not support mouse pointer integration...\" in a FreeBSD virtual machine is common and means you need to install and configure the necessary guest additions for the mouse to work seamlessly. FreeBSD does not include these drivers out of the box, so you must install them yourself.\n\nThat sounds like the Ports Collection. But there is no additions package for VirtualBox 7.1, only for 6.50 and 5.2. Mañana.\n\nOn with disaster. So: ARP issue? While messing around on disaster, found the help message for ARP. It uses Unix-style option delimiters, and -s sets a permanent MAC address. OK, if this is an ARP issue, we can fix that:\n\nOh: Microsoft has a different format for MAC addresses. Try again:\n\nAnd that as Administrator . Time to ask the twins.\n\nQ: What does \"The ARP entry addition failed: Access is denied\" when running CMD as administrator under \"windows\" 10? A: The \"ARP entry addition failed: Access is denied\" error in Windows 10, even when running Command Prompt as an administrator, typically happens when trying to add a static Address Resolution Protocol (ARP) entry for a reason other than a permission issue.\n\nInteresting. “Access is denied” is not a permission issue? Something's wrong here, either Gemini or Microsoft. My money is on Microsoft.\n\nAnd that's what Gemini suggests too:\n\nUse netsh instead: In some cases, especially on newer versions of Windows, the arp command may have issues with Access is denied errors even when the user has administrator privileges.\n\nSo I ended up with this simple invocation:\n\nAnd how about that, it worked. Well, at least it put the address in the ARP table, and I was able to ping out, so disaster knew the address. But it still didn't hear any reply.\n\nYet another question to Gemini:\n\nWhat could cause a Microsoft guest under VirtualBox to send network data but not receive it, when other guests have no problem with the same configuration?\n\nThe obvious answer: firewall. Check to be on the safe side. No, no firewall enabled. How about an Ethernet adapter issue?\n\nIf you are using an Intel PRO/1000, try switching to a different type, such as the AMD PCnet-FAST III.\n\nOK, try that. No improvement. Next idea: this video\n\nOK, try anything once. Follow the instructions step by step, none of which showed any obvious issues. Change the interface back to (specifically) Intel PRO/1000 MT Deskop (8254EM). Not much hope there: that's what I had.\n\nBut it worked! My final configuration looks identical to the start configuration. What changed? There's something lurking under the surface that I don't understand. Can I now get it to run on hydra?\n\nMore VirtualBox pain Topic: technology, opinion Link here\n\nYesterday I finally got networking working using VirtualBox 7.1 and Microsoft “Windows” 10. Time to refine a few things. First, start the windows on hydra:0.0, a 1920×1080 display, rather than on hydra:0.1, which has 3840×2160, giving windows that are too small.\n\nBut it didn't work! I could start on hydra:0.1, but on hydra:0.0 nothing happened. Is there some kind of built-in memory in the configuration file?\n\nSo, time to upgrade current.lemis.com, another VM running FreeBSD-CURRENT. It was a year out of date.\n\nStart a make buildworld , not for the first time. But nothing happened!\n\nFurther investigation showed that I had a network hang. And disaster was also hanging! Shut down disaster and current regained network access—for a while. Then it hung again.\n\nThis seems worse than my experience on hydra with VirtualBox 6.5. Tried it there and it worked.\n\nWhat a pain! What does Google Gemini say?\n\nQ: Are there known networking issues with VirtualBox under FreeBSD? A: Yes, there are known networking issues and quirks with VirtualBox when used as a host on a FreeBSD system. While VirtualBox works, it is not an officially \"supported\" host platform by Oracle, which means users often have to rely on the community and package maintainers to troubleshoot and resolve issues. (much irrelevant information omitted) Users sometimes experience slow network speeds, particularly with upload speeds, when using bridged adapters. This can be more pronounced on specific emulated network card types. While VirtualBox can function as a host on FreeBSD, it is not a \"fire-and-forget\" solution... If you encounter speed or reliability issues, experimenting with different emulated network adapter types can often resolve the problem.\n\nThat's not encouraging, though it doesn't directly relate to my problems. But what else can it be? Two different versions of FreeBSD, two different machines, two different versions of VirtualBox. Does it work better on Linux? That would be a real let-down, but possibly I should try it. How much pain would that be?\n\nTesting RSS feeds Topic: technology Link here\n\nI write all my web markup myself, with the aid of a number of PHP scripts. The result is that the RSS feed looks nothing much like my sources. So when something goes wrong with the markup, it's hard to find where, not helped by things like the W3.org validator, which typically points to where the error is detected, not where it occurred, and which at the moment caches input, so even after fixing the problem it reports the old problem.\n\nCallum Gibson is the main user of RSS feeds whom I know of. He pointed me to this validator. It also points to where the error was found, but at least I can try things and repeat them. That fixed an issue I had with earlier this month, where the error was over 100 lines from where it was detected.\n\nChasing the VirtualBox bug Topic: technology Link here\n\nSo why was VirtualBox version 7.1 on dereel even worse than version 6.50 on hydra? One possibility might be that the VMs themselves were NFS mounted. OK, find a 1 TB disk and copy them there. Put it in in place of the DVD drive, and was amazed to find that it came up as /dev/ada0, relegating the system disk to /dev/ada1 and requiring manual intervention (/etc/fstab) to continue. How could that happen?\n\nThen copying the VMs from hydra. That took a few hours, of course, so I'll continue tomorrow.\n\nWhile looking for the disks also found one marked “MS “Windows” 10 disgust”, dated 10.XII.2020. Comparing with my diary, that proves to be the disk that came with the machine I'm working on. So I should be able to just put it in and run it. That's the next thing to do if I still can't get VirtualBox to run reliably.\n\nDxO PhotoLab 9: worth the trouble? Topic: photography, technology, opinion Link here\n\nI've spent a lot of time looking at the new features of DxO PhotoLab 9. Even better noise reduction, of course, but the big new thing is what appears to be excellent object recognition (“masking”). But that's only part of the story. Can I remove objects? Replace them with something else? It seems that the answer is “no”.\n\nSomewhere I also thought I saw a way to merge HDR images, but that seems to be a misunderstanding. Instead they have improved file handling, including collapsing related image groups and automatic file naming. None of them seem to be anywhere near as flexible as the method I worked out 13 years ago, so it's of no use to me.\n\nSo: what will the future bring? The masking is good, but is it enough to spend US $240 on? There's a very good chance that they'll come up with a version 10 in the not-too-distant future and want $120 for an upgrade. Maybe I should just wait.\n\nVicRoads: still in the 20th century Topic: general, technology, opinion Link here\n\nAfter scrapping my Hyundai Elantra at the end of July I was due a refund for the registration.\n\nAnd they sent me a cheque! I thought they went out of fashion well over a year ago. And yes, the bank refused to accept it.\n\nBut why? I really don't understand. They should have transferred it to my bank account, like any sane company. But no, I had to call their customer service line (1300 555 165, which looks suspiciously like a fake US phone number) and go through their silly authentication process (including a form of 2FA, sending a PIN to my phone. That would have helped a lot if I had been calling from that phone). But yes, relatively quickly they took the details and told me that the transfer would occur in the next 2 to 3 weeks. Receipt number HD1155831.\n\n2 to 3 weeks? Why? Ah, we need human intervention. Why? Nowadays we have computers. With only marginally good programming the money could have been in my bank account before the end of the call. But clearly they don't have that.\n\nMore VirtualBox insights Topic: technology, opinion Link here\n\nSo what's wrong with VirtualBox networking? Google Gemini had suggested that it might depend on the emulated network adapter, so spent some time trying different adapters, with no improvement. About the only thing that was clear was the ping time: from guest to host the expected 0.15 ms, but in the other direction much longer, and with wildly different times:\n\nround-trip min/avg/max/stddev = 29.752/61.679/175.892/36.953 ms\n\nGave that up and looked at some bug reports, which showed surprisingly few network issues. But one, by Ivan Rozhuk, was interesting:\n\nTry to disable HW offloads on NIC:\n\nifconfig igb0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n\n\nAnd how about that, that worked. So why is this not better known? There's also a wiki with surprisingly little of use.\n\nLater I discovered that my guest current.lemis.com had 8 CPUs, while the host dereel only has four. That's quite impressive that it worked at all. Reducing the number of CPUs on current got rid of the slow ping times.\n\nSo: are we done? I don't think so. I still need to find whether the Microsoft guests work reliably.\n\nBruce Evans' C compiler Topic: technology, opinion Link here\n\nMail in the TUHS mailing list today:\n\nSubject: [TUHS] Bruce Evans 386 Minix patches & compiler source\n\n\n\nIt's been quite a while since I was messing with Minix386 back in the days\n\nwhen Bruce Evans released a set of patches to bring 386 support.\n\nI'm pretty sure over on oldlinux.org the patch set exists, but I can only\n\nfind the one set of binaries of his 386 toolchain.\n\nI know it eventually evolved into the bin86 toolchain that Linus would go on\n\nto use to create real mode boot code, but I don't know if any of the source\n\ncode to his 1991/1992 386 toolchain ever got published?\n\n\n\nIs it somewhere on the disk images that Peter Jeremy saved? I haven't looked at them for over three years, and I only had the smaller ones that I could download. Sent off a message to the other people who have access, Warren Toomey (who also coincidentally runs TUHS) and Warner Losh, and only got a brief response from the first.\n\nBack to look at what I have: three files, /src/bde/ad1.img, /src/bde/ad2.img and /src/bde/ad3.img. I had only looked at /ad0.img, requiring gnop to access the individual partitions. There was a good reason: I had renamed ad2.img.xz to ad2.img without uncompressing it. Did that now and ended up with 60 GB of data.\n\nAnd the contents?\n\n=== root@dereel (/dev/pts/1) /bde 13 -> mdconfig -a -t vnode -f /src/bde/besplex/ad2.img\n\nmd0\n\n=== root@dereel (/dev/pts/1) /bde 14 -> l /dev/md0\n\nmd0 md0s1 md0s2 md0s2a md0s2b md0s2d md0s2e md0s2f md0s2g md0s2h\n\n\n\nAll the BSD partitions there! So I can just mount them:\n\n=== root@dereel (/dev/pts/1) /bde 15 -> mkdir a b d e f g h\n\n=== root@dereel (/dev/pts/1) /bde 16 -> l\n\ntotal 1\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 a\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 b\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 d\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 e\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 f\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 g\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 h\n\n=== root@dereel (/dev/pts/1) /bde 35 -> for i in `echo a b d e f g h`; do mount -o ro /dev/md0s2$i $i; done\n\nmount: /dev/md0s2a: No such file or directory\n\n=== root@dereel (/dev/pts/1) /bde 36 -> df\n\nFilesystem 1048576-blocks Used Avail Capacity Mounted on\n\n...\n\n/dev/md0s2b 3,952 3,542 93 97% /bde/b\n\n/dev/md0s2d 3,952 2,971 664 82% /bde/d\n\n/dev/md0s2e 3,952 3,658 -21 101% /bde/e\n\n/dev/md0s2f 3,952 3,514 121 97% /bde/f\n\n/dev/md0s2g 11,754 8,842 1,972 82% /bde/g\n\n/dev/md0s2h 29,525 14,599 14,926 49% /bde/h\n\n=== root@dereel (/dev/pts/1) /bde 37 ->\n\n\n\nAnd in one of the partitions I found a file /bde/e/besplex/home/bde/dist/minix.tar.gz, which may be just what Jason is looking for. That was much easier than I thought. Is it correct? That would be too easy.\n\nMore fun with VirtualBox and bde Topic: technology, opinion Link here\n\nMore playing around with VirtualBox today, with no breakthrough. I had paused dereel with zzz, and when I restarted it the networking had gone to hell again. Here a repeat of what I had done yesterday:\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 1 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500 options=4e524bb<RXCSUM,TXCSUM,VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,LRO,WOL_MAGIC,VLAN_HWFILTER,VLAN_HWTSO,RXCSUM_IPV6,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 2 -> ifconfig em0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 3 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500\n\noptions=4c120b8<VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,WOL_MAGIC,VLAN_HWFILTER,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n\n\nAfter that it worked normally again, but the Microsoft boxen still didn't want to know. Do I have to cold start them every time?\n\nAnd Bruce Evans' C compiler? I posted what I had and got no answer. I'm not convinced that I have the right files, though the name usr/src/mx386/bcc (from the archive e/bde/dist/minix.tar.gz) does raise some hope.\n\nPower fail! Topic: general, technology, opinion Link here\n\nAt 11:04, while preparing breakfast, we had a grid power failure. Not a problem: we have a PV system. But the power dropped totally! Almost before we knew it, it was back again. The inverter log shows less than a minute.\n\nThat's not the first time. It happens far too often, most recently two months ago. And today, as then, my main machines eureka and hydra lost power, because I still hadn't got round to getting a UPS installed. Today I made up for that: I have a ten-year-old 1000 VA 650 W UPS just lying around. It is still functional? In contrast to the CyberPower UPS that I bought 2½ years ago, it seems still to work. While the power was down, took the opportunity to tidy up the mess to the left of my desk top, removing this display card from eureka and making a cut in my fingertip in the process:\n\nThat once drove three of the four monitors then connected to eureka, but that was years ago, as the dust suggests.\n\nWhat caused the outage? Hard to say. The inverter logs show no sign of overvoltage before the outage, though afterwards the voltage hung over 250 V for over an hour. I suppose it's time to brave the potential issues and update the firmware.\n\nPowercor had a different view. An hour later I received a message:\n\nAnd then\n\nOn checking, I found that I also had similar messages from the day before, where there was no outage at all. Still, rather phantom outages than real ones.\n\nhydra upgrade Topic: technology, opinion Link here\n\nI've had hydra for nearly 2 years, and I still haven't got round to configuring it quite the way I want; much is in the X menus. But of course the system is now down-rev. What better time then after a power failure to bring it up to date?\n\nMy real concern after an update is that the ports will no longer work the way I want. Building a new world is relatively simple, and it took just shy of 1000 seconds to build the world and new kernel. And rebooting went relatively smoothly, though it no longer found the Ethernet card on the motherboard. I had suspected issues in that area (it's a 2.5 Gb/s Realtek card) and installed a second, which showed up as re0 , so all I needed to do was to change where I plugged in the network cable.\n\nAs I feared, the ports were a different matter. They were worse then ever before, taking 3 iterations to delete 100—no, 101—no, 103 ports, including chromium curl, emacs of course, enblend, exiv2, feh, ffmpeg, firefox, fusefs-curlftpfs, gdb, git, gnupg, groff, hugin, mplayer, mpv, mutt, rdesktop, rsync, rtorrent, vigra, virtualbox-ose, xpdf and xv. And even then I missed ImageMagick, which further annoys me with a change of name. Yes, convert is a subcommand of ImageMagic, but now they have decided that the name is too invasive, so I'll have to change all invocations to magick convert. I suppose that one's fair enough.\n\nAnd firefox has new messages, which it spews by the hundred where it presumably suspects nobody is looking, on the home terminal:\n\nconsole.warn: services.settings: Could not determine network status. Message: TypeError: can't access prop \"isLinkUp\", lazy.gNetworkLinkService is undefined\n\nGradually the issues became clear: I can no longer connect to eureka with ssh, nor at all to hydra. I was expecting issues with eureka, but not with hydra. Was it because it came up before the network was ready? I had to restart syslogd to get it to write to eureka, and to change the permissions on wake for normal users to use it.\n\nWhat am I left with? I can no longer use erc, the Emacs IRC command:\n\nerc: missing symbol (.at)\n\n⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.\n\n\n\nWhat does that mean? I'll find out some time. Fortunately it still works on eureka, so there's no hurry.\n\nAnd independently of all that I need to pay more attention to my X configuration. I still don't get my mice set up correctly at startup. But that's fun for another day.\n\nCompleting the upgrade Topic: technology, general, photography, opinion Link here\n\nInto the office this morning as usual. No mail from hydra. What happened there? /var/log/maillog showed a number of:\n\nSep 20 03:03:54 hydra postfix/cleanup[70392]: B1BC41AB5: message-id=<202509191703.58JH3sRP070451@hydra.lemis.com>\n\nSep 20 03:03:54 hydra sendmail[70451]: 58JH3sRP070451: to=root, ctladdr=root (0/0), delay=00:00:00, xdelay=00:00:00, mailer=relay, pri=33687, relay=[127.0.0.1] [127.0.0.1], dsn=2.0.0, stat=Sent (Ok: queued as B1BC41AB5)\n\nSep 20 03:03:54 hydra postfix/qmgr[1845]: B1BC41AB5: from=<root@hydra.lemis.com>, size=4303, nrcpt=1 (queue active)\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: unexpected attribute smtputf8 from local socket (expecting: sendopts)\n\nSep 20 03:03:54 hydra postfix/smtpd[70368]: disconnect from localhost[127.0.0.1] ehlo=1 mail=1 rcpt=1 data=1 quit=1 commands=5\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: deliver_request_get: error receiving common attributes\n\n\n\nWhat's smtputf8 ? Checking /usr/local/etc/postfix/ showed that a number of files, which should have been symlinks to the same directory on eureka, were missing. Forgot to mount a NFS file system. After mounting and restarting postfix, all was well. But what does the strange message mean? It seems that it's a default.\n\nAnd then there was Hugin. I had expected some issues, but not what I got: when I tried to start the “fast panorama preview” I got\n\nerror installing GLEW\n\nFast preview window can not be opened\n\nWhat does that mean? I have a package installed, which pkg reports as\n\nglew-2.2.0_3 OpenGL Extension Wrangler Library\n\nAnd there doesn't seem to be anything else that was there before. But when I retried the attempt, it worked. Where is the bug? Hugin or FreeBSD? In addition, irritatingly it resized the windows on every start. I thought I had got rid of that with some script magic, but it seems to be gone.\n\nAnd then there's the mouse. That's simple enough: instead of searching for the index for the mouse, it's easy enough to write\n\nxinput set-button-map \"Telink 2.4G Mouse\" 1 2 3 4 5 6 7 2 2 10\n\nOne of the messages I received was completely misleading:\n\n=== grog@hydra (/dev/pts/16) ~/Photos/20250920 47 -> (EE) event4 - Telink 2.4G Mouse, class 0/0, rev 1.10/1.00, addr 4: client bug: event processing lagging behind by 32ms, your system is too slow\n\n(EE) client bug: timer event4 debounce: scheduled expiry is in the past (-48ms), your system is too slow\n\n(EE) client bug: timer event4 debounce short: scheduled expiry is in the past (-61ms), your system is too slow\n\n\n\nThat's not hydra at all, despite the prompt. I started X on teevee from hydra, and this appears to be its way of saying “the cat got on my mouse”.\n\nAccessing systems with ssh from eureka Topic: technology Link here\n\neureka is now running a nearly 10 year old system, but I don't want to update it: it works.\n\nBut some issues remain. One was that I couldn't automatically log on with ssh: I had to enter a password, which is irritating in scripts. Once again Google Gemini to my aid. Add this to /etc/ssh/sshd_config:\n\nPubkeyAcceptedKeyTypes=ssh-ed25519,ssh-rsa,rsa-sha2-512,rsa-sha2-256\n\nNow I just need to see why I can't access eureka from hydra without a password.\n\nFinally the birding photos Topic: photography, animals, technology, opinion Link here\n\nIt's been 4 days since the latest OM System birding “workshop”, and I've only just got round to processing the best photos. Are these the best?\n\nIt's a lot of work making up my mind out of over 250 photos. Yvonne did it for me, and those were the ones she liked.\n\nMore ssh strangeness Topic: technology, opinion Link here\n\nI've already established issues with ssh sessions from hydra to eureka, but not from other systems. Once again Google Gemini to my aid, this time less useful. It tells me to allow ssh-rsa in /etc/ssh/sshd_config by adding this line:\n\nPubkeyAcceptedKeyTypes=+ssh-rsa\n\nWe've seen that before on the other side. But that's a non-starter: sshd doesn't want to know:\n\n=== root@eureka (/dev/pts/1) /etc/ssh 28 -> service sshd restart\n\nPerforming sanity check on sshd configuration.\n\n/etc/ssh/sshd_config: line 54: Bad configuration option: PubkeyAcceptedKeyTypes\n\n/etc/ssh/sshd_config: terminating, 1 bad configuration options\n\nOK, what about the alternative of using a key?\n\n=== root@eureka (/dev/pts/1) /etc/ssh 32 -> service sshd restart; date\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStopping sshd.\n\nWaiting for PIDS: 22656.\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStarting sshd.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\n\n\nWhy? It doesn't seem to affect other key forms. And comparing hydra and tiwi gives me on hydra:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: send_pubkey_test: no mutual signature algorithm\n\n\n\nBut on tiwi it works as expected:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: Server accepts key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\nAuthenticated to eureka.lemis.com ([192.109.197.137]:22) using \"publickey\".\n\n\n\nWhat's the difference?\n\nMutt problems Topic: technology, opinion Link here\n\nFirst thing I do in the morning is to read the overnight mail, typically a couple of hundred messages. But this morning I tried to delete the messages I had read, I received the message “unable to write mailbox” or something similar. Why? Normally I see a message like that when I'm out of disk space, but this wasn't the case. Return, painfully delete the messages again, and it worked. Is that an NFS issue? It has happened before. Was that also overnight? I'll have to look more carefully next time.\n\nMore ssh pain Topic: technology, general, opinion Link here\n\nInto the office this morning to find eureka maxed out with at least 35 ssh-add processes, all looping at 100% CPU time.\n\nWhy? This is not a new program:\n\n3054180 -r-xr-xr-x 1 root wheel 17576 25 Nov 2015 /usr/bin/ssh-add\n\nOnce again Google Gemini to my aid, coming with the suggestion that it could be that ssh-add was running already, and that I should put in code like\n\nssh-add -l >/dev/null || ssh-add\n\nThat worked up to a point, but it doesn't explain why it is only happening now, after nearly 10 years. It's much more likely that it's related to the playing around I have been doing lately, though it didn't affect ssh-add, and I had backed out the changes anyway. And in the course of the day I found another instance in my weather software, but that found further breakage: the external view of my weather stopped in early June when I got the new weather station. More to fix when the current problems are over.\n\nssh-add: A clue Topic: technology, opinion Link here\n\nI haven't done much to investigate the ssh-add problem for the moment. It seems that I call ssh-add in a number of places, all of which need fixing. But while playing around I found:\n\n=== grog@eureka (/dev/pts/3) ~/public_html 32 -> ssh-add < /dev/null\n\nEnter passphrase for /home/grog/.ssh/id_rsa:\n\nCould it be that the looping is the incorrect handling of a prompt? It doesn't help much in fixing it, but it could help understand.\n\nThe advantages of upgrades Topic: technology, opinion Link here\n\nAs expected, upgrading hydra caused a number of problems, most of which I have described. And this time it was Chromium, which has forgotten all its editing keys, or at least the ones I want. More searching required.\n\nOn the other hand, one bug has gone away: xv can now display PNG again. Not exactly a big improvement, but at least a fixed bug.\n\nThe daily Android bug Topic: technology, opinion Link here\n\nSomehow the Android operating system seems to be the least reliable I know. I'm gradually coming to terms with it, but today there was another one: trying to download files to a Real Computer, albo didn't respond, though it claimed to be working. Disable Wi-Fi, reeenable, and it worked. No change of connection.\n\nWhat a mess Android is!\n\nAnother web server overload Topic: technology, opinion Link here\n\nIt's been well over 4 months since I set up a new external web server, fra.lemis.com, to address the really heavy load, with load averages up to 170. And so, of course, it dropped back to under 1.\n\nBut now it's increasing again, both servers now well over 200. Why? I had thought it was related to the imagesizes parameter, but that doesn't seem to be the case. Let's see how long the overload lasts this time.\n\nFast postal service Topic: general, technology, opinion Link here\n\nI've bought a couple of cameras in the United Kingdom. The usual tracking information, with a twist:\n\nIt's in Leeds, but it'll be here tomorrow! Now that's a lot faster than Australia Post. Or just plain stupid.\n\nYour cameras have been delivered! Topic: technology, photography, general, opinion Link here\n\nYesterday's claim of fast delivery was amusing enough, but they haven't given up:\n\nThey have been delivered! How did we do?\n\nI'm amazed. Clearly the cameras are still in the United Kingdom. My best guess is that Royal Mail have delivered the cameras to the people who are currently in the process of sending them half way round the world, or at least they have received documentation from them. So from their limited viewpoint they have been delivered. No concept of them only having travelled a fraction of the distance.\n\nWeb server load: dropping Topic: technology Link here\n\nYesterday's web server overload didn't last long. It's back to round 1 again. I suppose that's what we're going to have to live with for the foreseeable future. It's interesting that even at this extreme overload people claimed that response was satisfactory. That's significantly different from last time, where some sites got timeouts.\n\nArtificially intelligent breakfast Topic: food and drink, technology, opinion Link here\n\nFor some reason we bought a quarter cabbage recently. I forget why, but it was intended for breakfast. All right, Google Gemini, give me some east asian recipes with fried cabbage.\n\nAnd the twins obliged: 手撕包菜 - Shǒu Sī Bāo Cài, “hand shredded cabbage\", which didn't look too bad, modulo these horrible cups measurements. I can't even blame the twins for that: so many recipes use it. But it's the biggest hindrance I can find for trying out recipes. OK, Gemini, give me a Chinese recipe with fried cabbage and noodles using metric units. OK, how about 包菜炒粉/麵, which Google Translate translates as “cabbage fried rice noodles”? A completely different recipe! The best I can guess from the two recipes is that 4 cups of cabbage weigh about 300 g.\n\nSpent some time—probably more than cooking—writing a sane version of the second recipe.\n\nSoftware upgrades: the sting in the tail Topic: technology, photography, opinion Link here\n\nHouse photos again today, the second time since I upgraded hydra to FreeBSD 14.3 last week. And once again I had pain.\n\nFirstly, creating HDR didn't work well. It took me a while to discover that it was an unrelated bug in one of my scripts: I managed to mix images from the OM System OM-1 Mark II with the correct images from the Olympus OM-D E-M1 Mark II. I had already expected problems like that, and /Photos/Tools/housephtos.awk contained appropriate comments. Here the fix:\n\n-# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n+# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n# Create a makejpeg file from housephoto.notes file.\n\nBEGIN {\n\ni = 0;\n\n-# XXX Only look at photos from E-M1 Mark II.\n\n+# Only look at photos from E-M1 Mark II.\n\n# Is this safe?\n\n-# Was: 4*.ORF, E-M1 /2 only\n\n- while (\"ls -rt *.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n+# It's better than the alternative.\n\n+ while (\"ls -rt 4*.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n\n\nThe problem was that I didn't limit the choice to photos from the E-M1 Mark II. Not an upgrade problem at all.\n\nThe other, though, seems to be related to the upgrade of Hugin, now version 2024.0.1. The screens appear in the wrong place and at the wrong (tiny) size, and the directories are wrong. That's almost certainly related to the scripts that I wrote over 16 years ago which frob the ~/.hugin file to get rid of this horrible directory name retention. But that's all they do, and somehow it doesn't seem to work. A small detail, but irritating. Will I get round to it by next week?\n\nRevisiting old photos Topic: photography, technology, opinion Link here\n\nLooking back through old photos, found some of my first panoramas:\n\nIt dates from 11 April 2009 with the Olympus E-510, so old that I don't even have Exif data for it. I had already attempted to improve it 8 years later:\n\nBut that was still with the Ashampoo Photo Optimizer, which I have stopped using. Another attempt with “Perfectly Clear” gave me further improvements. Here are the three together (run the cursor over an image to compare it with its neighbour):\n\nIn particular the highlights and shadows are greatly improved.\n\nfra rebooted! Topic: technology, general, opinion Link here\n\nThe vultures have rebooted fra! Yes, they warned they would do so because of some unspecific bug in Linux, so they rebooted my FreeBSD box as well. The good news is that it came back without any intervention on my part, but of course the up time has gone to hell.\n\nAnother bloody power fail Topic: technology, general, opinion Link here\n\nIn the evening, another grid power failure. And another directly behind it. Both were sub-second, but once again eureka and hydra failed. So much for the UPS.\n\nWhy? Yes, it's an old UPS, but it claims to have plenty of charge, and the failures were so short that most clocks in the kitchen kept going. Can it be that it was a power surge, and that this UPS didn't handle it? The UPSs for lagune, teevee and tiwi had no problems.\n\nAnd the fallout? I got things running relatively quickly, but firefox didn't recover its many tabs. I had to start a different profile to get anything. And of course X on teevee failed, because I had started it from hydra.\n\nSo what do I do now? Buy more of UPSs of the kind that power the other machines?\n\nTuesday, 30 September 2025 Dereel Top of page previous day\n\nMore firefox pain Topic: technology, general, opinion Link here\n\nSo what's wrong with firefox? My standard profile just hangs. Why? How do I debug such a mess?\n\nI tried setting up a different profile, losing a number of tabs in the process, but nothing I could do could get the font sizes right. Get them right for my diary (without any trickery) and they're far too small for things like Wikipedia and friends. Migrate from hydra:0.2 (3840×2160) to hydra:0.0 (1920×1080)? Yes, that works, but why did it happen?\n\nThen it occured to me: yes, the standard profile still hangs. But I can check the settings. And it seems that the big thing is the Zoom setting, which was at 150%. After setting that, things were OK. But why the difference between my diary and Wikipedia and Co.? And why are font sizes such an issue with firefox?",
      "source": "Lemis.com",
      "url": "http://www.lemis.com/grog/diary-sep2025.php?topics=c#D-20250909-003710",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Chasing the VirtualBox bug",
      "content": "AI: enough! Topic: technology, general, opinion Link here\n\nSunday's detailed investigation of generative artificial intelligence should have been enough, but it occurred to me that there was one thing I hadn't tried: graphics. OK, draw me a caricature of Greg Lehey.\n\nGoogle Gemini came up with this:\n\nOf course I don't need to like the results, but this shows very little understanding: no mention of BSD, just Linux (or even “Linix”). Yvonne tells me that it looks nothing like me. Compared to the text results, quite disappointing.\n\nAnd that was all. My other bots all couldn't do it. But their attempts were worth mentioning:\n\nChatAI\n\nI'm unable to draw images directly, but I can help you imagine a caricature of Greg Lehey! Picture a gentleman with a thoughtful expression, perhaps with glasses perched on his nose, and a hint of a smile suggesting a keen sense of humor. His hair might be slightly tousled, giving him a scholarly yet approachable look. You could exaggerate his features, like giving him a larger forehead to symbolize his intellect or a prominent chin to represent determination. Add a background filled with books and computers to reflect his interests in technology and writing\n\nI suppose that's acceptable for as far as it goes.\n\nClaude\n\nClaude did the best with the diary entry, but it failed completely with the caricature:\n\nClaude: I'd be happy to help you create a caricature, but I'll need a bit more information! There are likely multiple people named Greg Lehey, and I want to make sure I'm drawing the right person..\n\nClaude, you know who I am. There are “likely” multiple people named Greg Lehey? That wasn't a problem on Sunday. And as it happens, there is nobody else that I can find with the same name as mine. But OK, draw me a caricature of Greg Lehey, the FreeBSD person.\n\nI can't create visual caricatures or drawings as I'm a text-based AI. However, I'd be happy to help you in other ways: Written description: I could write a humorous written \"caricature\" or character sketch of Greg Lehman (assuming you meant Greg Lehman, a notable FreeBSD contributor) that captures his programming style, contributions to FreeBSD, or personality traits in an exaggerated, caricature-like way.\n\nWhat a cop-out! Now it says that it can't draw. And it comes up with a fictive Greg Lehman. That's completely useless.\n\nDeepSeek\n\nAs before, DeepSeek is inventive:\n\nWhile I can't physically draw for you, I can create a detailed \"blueprint\" for a caricature of the legendary BSD developer Greg \"Groggy\" Lehey. An artist could follow this description to create the perfect caricature. Here is a description designed for an artist to illustrate. Caricature of Greg \"Groggy\" Lehey Concept: The caricature should capture his iconic, jovial, and slightly mischievous personality, deeply intertwined with his life's work: BSD and Unix. Key Features to Exaggerate: The Beard and Hair: This is the #1 feature. Exaggerate his magnificent, full, and sprawling white beard. Make it vast and wizard-like, almost as if it's its own entity. It should be big enough to have a Daemon (the BSD logo) peeking out from within the whiskers, as if it lives there. His hair (what's visible under his hat) should be similarly wild and unkempt. The Headwear: He is almost never seen without a hat. Draw a slightly battered, well-loved flat cap or a beret perched on his head at a jaunty angle. Where did it get the hat from? I am almost never seen with a hat. The Expression: A wide, knowing, and cheerful grin. His eyes should be crinkled with laughter and wisdom, suggesting he's both a kind mentor and someone who knows where all the bugs in the code are hidden. The Props & Surroundings: In his hand: Instead of a coffee mug, he should be holding a massive, steaming beer stein. This is a nod to his famous \"Buy me a beer\" link on his website and his good-humored nature. Steaming beer? I can't even imagine that. And instead of referring to my brewing activities, it refers to a fictive “buy me a beer” link, which may be related to Poul-Henning Kamp. Under his arm: A well-worn copy of his magnum opus, \"The Complete FreeBSD\" book. Background Element: Have a Tux (the Linux penguin) peeking from around a corner, looking slightly nervous or annoyed, while Groggy pays it no mind. This playfully hints at the good-natured rivalry between BSD and Linux. Code: Faint lines of C code ( #include <beard.h> , printf(\"Cheers!\n\n\"); ) can be subtly woven into the texture of his shirt or the background. Overall Vibe: The image should feel warm, intelligent, and full of character. He is the friendly, brilliant, and slightly eccentric \"Unix Beard\" wizard, a beloved figure in the open-source community. Color Palette: Warm tones. Earthy browns for the hat, a rich color for the shirt (green or blue), the brilliant white of the beard, and the gold of the beer.\n\nStill, I suppose that could produce something useful. But where are all the image generators? Do I want to look? I've spent enough time on this already.\n\nWhy don't people read any more? Topic: language, general, technology, opinion Link here\n\nRecently I saw (but didn't read) a newspaper article, possibly from the New York Times, asking why people don't read books any more. The answer appears simple: information overload. When I was a lad I read lots of books, but it has been some time since I finished reading any, and then the relatively thin “Brave New World”.\n\nBut then we watched A Town Like Alice, and Yvonne borrowed the book. I have always liked Nevil Shute, and I have a number of his books, so I read it when she finished. It took me two weeks. While reading I was continually following up on details mentioned in the book—that's what the web is for, after all. In general, I ended up with a much broader view than I would have had if I had just read the book.\n\nAnd how did I like it? Not much. Clearly it's two different stories stuck together: the ordeals in Malaya at the hand of the Japanese occupation and the transformation of a tiny bush village in Queensland into a small town. The latter, in particular, seems very improbable.\n\nThe geographical details are what interested me most. Particularly in Malay(si)a I knew most of the real places. But I'm puzzled about why Shute spends a lot of time in the area Maran and Jerantut in the Jengka Triangle, places that must have been almost completely unknown at the time, but puts the women in a place called Kuala Telang “about half-way between Kuantan and Kota Bahru”. There is a town in that position, but it's called Kuala Terengganu, and it's a big town (capital of the state of Terengganu), not a small village. My guess is that Shute had never heard of it.\n\nSpelling is also strange. In the first half of the book, Kota Bharu was spelt “Kota Bahru”, and in the second half “Khota Bahru”. Tennant Creek became “Tennants Creek”. These spellings are the same both in the online book and the physical book that I read. And there are a couple of irritating US Americanisms that I don't understand: the animals central to the theme are called alligators, not crocodiles. The stockmen use lariats.\n\nThen there's the question of racial attitudes. The local aborigines (or aboriginals, to use the modern politically correct term) are called “boongs” or “abos”. Both are offensive nowadays. And there was talk of racial segregation, a separate milk bar for the boongs. This would have been about 1948, the time of my birth. Did such segregation really exist then?\n\nMy favourite one, though, is when the main characters (Jean and Joe) fall in love, and she decides not to sleep with him until after they are married. Given that Joe had been crucified in the first half of the story, I was half guessing that he might have been castrated at the same time, and Jean would not have found out until too late.\n\nIn summary: reading books has become much more of an exercise than it used to be. For light entertainment we have TV. I don't think I'll read another novel for some time to come.\n\nPredicting the past Topic: general, technology, opinion Link here\n\nI keep a close eye on the weather forecasts from the Bureau of Meteorology, both of them. There's one on the web and another for mobile phones. They don't often agree with each other, and of course they're both frequently wrong.\n\nToday, though, the mobile phone app excelled itself. We finally have rain, 6 mm over the last 24 hours. Or, as the app put it,\n\nPart of the app is a rainfall map showing precipitation. That showed that there was much more rain. How can that happen?\n\nWhatsApp: bug after bug? Topic: technology, opinion Link here\n\nI've been trying for a week now to set up video telephony on fossil, Yvonne's mobile phone. Somehow the “modern” approach to user interfaces shows itself at its worst here. But I had come to the conclusion that if I can work beyond WhatsApps bizarre interface, and explain it to Yvonne so that she doesn't have a panic attack every time she uses it, we might have something useful, especially since WhatsApp can communicate by an Internet link, which could be much cheaper.\n\nOK, try out on hirse first. It doesn't have a SIM card, so any communication has to go by the Internet. Migrate my main number to hirse. No problem. Make a call. Some message like “need to use the phone network”. Oh.\n\nTry calling in. The problem: hirse has the phone number associated with a SIM card in albo, which has a different WhatsApp number. Which does WhatsApp call? albo! Somehow there's more to this than meets the eye.\n\nWhen Yvonne got back from shopping, I changed her WhatsApp number to the number of second SIM on her phone. All sorts of things didn't work, and it couldn't call the number on hirse. hirse claimed that she wasn't registered, though I had set the “notify contacts” during the migration. In the end I moved the number back to the old one. And things still didn't work correctly! In particular, I could call the number, but WhatsApp didn't respond in any way, not even registering a missed call. Went through the settings and set tones for all notifications. Still no response. Restart the app. No response.\n\nNothing for it, the Microsoft solution: reboot. And yes, now it responds. Clearly some kind of bug. And it repeats the call tone for every notification, including messages. Oh, my bad. Get rid of the tone. Sorry, there's no provision for that. Select something at random, since it's too polite to play the tone when you're selecting it. I still get the ring tone for messages! I can't see any explanation except that it's another bug. It was getting late, so I turned off sounds to wait until tomorrow.\n\nAll this is made worse by the horrible user interface. So far I haven't found a way to display the associated phone number in the contact details. At one point I made the mistake of using the same name (mine) for both my phones, so there was no way at all to find out what “number” it had called.\n\nI hate WhatsApp! Topic: technology, general, opinion Link here\n\nMore fun with WhatsApp today. The first question, which decides whether it's even worthwhile: can I make a call over the Internet? Yesterday's experiments were overshadowed by other bugs. Today I tried making a call from fossil (Yvonne's phone) to hirse, the one without a SIM card. I have set it up with the main number of albo, so a normal call to that number should go to albo, and a WhatsApp call should go to hirse. Does it?\n\nYes! So yesterday's issues were probably due to other bugs.\n\nAnd the incorrect notification tones? Gone since the last reboot, Yvonne says. But later she changed her mind: once again the wrong tone when all notification tones were turned off.\n\nDammit, begone, WhatsApp! Removed it. Reinstalled it. And how about that, setup was almost completely without problem. She lost her image (“Avatar”, “The manifestation of a god in bodily form on earth” according to the OED). We can live with that. And somehow now everything Just Works—until the next unpleasant surprise.\n\nApart from that and the horrible user interface, established that you can change an audio call into a video call simply by pressing the button with the box with a loudspeaker on the right:\n\nInterestingly, it only works in one direction. To go in the other direction requires that the person at the other end do the same.\n\nVirtualBox again Topic: technology, photography, opinion Link here\n\nDxO PhotoLab 9 is out, and it looks worth trying. Time to reinstate one of my Microsoft virtual machines, which run under VirtualBox.\n\nI stopped using VirtualBox on hydra a year ago, though it was the main reason that I had so much memory (192 GB): I ran into network problems that I couldn't fix.\n\nNow FreeBSD has a port of VirtualBox 7. Time to try again? Tried first on dereel, with only 24 GB of memory. Where's my HOWTO? All fine, but it doesn't tell me how to add an existing VM. It must be in this diary somewhere, but where? I really should keep these HOWTOs up to date.\n\nStarting up the GUI was different from before, of course. And it wanted to set things up in the root file system. To go elsewhere I had to do this horrible tree walking. Finally I got to where I wanted (/src/VirtualBox/echuca). Tried to create a new VM. “Can't overwrite machine folder...\". What does that mean? They should know better than to call a directory a folder, but what's a “machine folder”? Lots of experimentation, continually being returned to the /root directory and having to climb my way out again. What does “help” say? Nothing. I wonder if the port forgot to install something important. After a while I discovered that it really wanted the parent directory /src/VirtualBox, but then I ran into other issues.\n\nAfter some time decided to create a new VM with the old virtual disk. Link? Yes, but VirtualBox detected the UUID and used the old name.\n\nYes, there are other possibilities. But I think that the best is to go through my diary and extract the information that I need to do things sanely. And maybe I should use the commands rather than the GUI, which seems to be getting more stupid as time goes on.\n\nWhatsApp an Avatar? Topic: technology, general, opinion Link here\n\nYesterday I established that an Avatar is a earthly manifestation of a Hindu god, but WhatsApp apparently wants to elevate Yvonne and me to deities. Until then, only initials appear to identify us on calls.\n\nOK, how do we do that? Settings, of course, “make your own avatar”, “Create from selfie”. OK. Take a suitably horrified photo of myself. Briefly it showed “There was an error with the avatar gen...”, so briefly that I didn't see it the first three times. What does that mean? Why can't it finish its sentences? So instead it presented me with a manual generation.\n\nWhy? What does the half message mean? It's repeatable on two different phones. And there seems to be no way to just add a normal photo. What a mess!\n\nVirtualBox progress Topic: technology, opinion Link here\n\nSo what's wrong with my VirtualBox installation? My current situation was exactly what I had a year ago: most VMs worked, but Microsoft VMs had networking problems. They could send data, but they didn't see the replies, so they hung in ARP. I attributed that to the version of VirtualBox (6.1.50 r161033), so I waited until version 7 came out. And then I discovered that I had exactly the same problem.\n\nThat didn't help just getting things running. After some searching, discovered that VirtualBox stores a configuration in the home directory, ~/.config/VirtualBox/ with a number of files, including log files that have no business there, but importantly VirtualBox.xml. OK, make a copy of that on dereel, and how about that, VirtualBox came up with all the VMs I knew.\n\nStart disaster, the only VM that would fit in dereel's memory.\n\nVT-x is disabled in the BIOS for all CPU modes (VERR_VMX_MSR_ALL_VMX_DISABLED).\n\n\n\nOh. There was something there, but can the twins help? Yes, specifically for a ThinkCentre:\n\nOnce in the BIOS, use the arrow keys to navigate to the Advanced tab. From the Advanced menu, select CPU Setup and press Enter. Look for an option labeled Intel(R) Virtualization Technology and select it. Using the arrow keys, change the setting from Disabled to Enabled.\n\nAfter that and rebooting, and with a change of network adapter name, it still didn't start. I got this message:\n\nX86_CPUID_AMD_FEATURE_EDX_AXMMX is not supported by the host but has already exposed to the guest [ver=19 pass=final] (VERR_SSM_LOAD_CPUID_MISMATCH).\n\nMore help from the twins. The saved state includes information from an AMD processor (hydra), but this is Intel. Discard saved state and start again.\n\nAfter that, and with a change of network adapter name, it started. I got this message, which I haven't seen before, but which seems harmless:\n\nerror: XDG_RUNTIME_DIR is invalid or not set in the environment.\n\nThat variable isn't set on hydra either.\n\nWe're still not done. Trying to start an xterm from current gave me the message\n\nThe Virtual Machine reports that the guest OS does not support mouse pointer integration\n\nWhat's that? Gemini tells me:\n\nThe message \"The Virtual Machine reports that the guest OS does not support mouse pointer integration...\" in a FreeBSD virtual machine is common and means you need to install and configure the necessary guest additions for the mouse to work seamlessly. FreeBSD does not include these drivers out of the box, so you must install them yourself.\n\nThat sounds like the Ports Collection. But there is no additions package for VirtualBox 7.1, only for 6.50 and 5.2. Mañana.\n\nOn with disaster. So: ARP issue? While messing around on disaster, found the help message for ARP. It uses Unix-style option delimiters, and -s sets a permanent MAC address. OK, if this is an ARP issue, we can fix that:\n\nOh: Microsoft has a different format for MAC addresses. Try again:\n\nAnd that as Administrator . Time to ask the twins.\n\nQ: What does \"The ARP entry addition failed: Access is denied\" when running CMD as administrator under \"windows\" 10? A: The \"ARP entry addition failed: Access is denied\" error in Windows 10, even when running Command Prompt as an administrator, typically happens when trying to add a static Address Resolution Protocol (ARP) entry for a reason other than a permission issue.\n\nInteresting. “Access is denied” is not a permission issue? Something's wrong here, either Gemini or Microsoft. My money is on Microsoft.\n\nAnd that's what Gemini suggests too:\n\nUse netsh instead: In some cases, especially on newer versions of Windows, the arp command may have issues with Access is denied errors even when the user has administrator privileges.\n\nSo I ended up with this simple invocation:\n\nAnd how about that, it worked. Well, at least it put the address in the ARP table, and I was able to ping out, so disaster knew the address. But it still didn't hear any reply.\n\nYet another question to Gemini:\n\nWhat could cause a Microsoft guest under VirtualBox to send network data but not receive it, when other guests have no problem with the same configuration?\n\nThe obvious answer: firewall. Check to be on the safe side. No, no firewall enabled. How about an Ethernet adapter issue?\n\nIf you are using an Intel PRO/1000, try switching to a different type, such as the AMD PCnet-FAST III.\n\nOK, try that. No improvement. Next idea: this video\n\nOK, try anything once. Follow the instructions step by step, none of which showed any obvious issues. Change the interface back to (specifically) Intel PRO/1000 MT Deskop (8254EM). Not much hope there: that's what I had.\n\nBut it worked! My final configuration looks identical to the start configuration. What changed? There's something lurking under the surface that I don't understand. Can I now get it to run on hydra?\n\nMore VirtualBox pain Topic: technology, opinion Link here\n\nYesterday I finally got networking working using VirtualBox 7.1 and Microsoft “Windows” 10. Time to refine a few things. First, start the windows on hydra:0.0, a 1920×1080 display, rather than on hydra:0.1, which has 3840×2160, giving windows that are too small.\n\nBut it didn't work! I could start on hydra:0.1, but on hydra:0.0 nothing happened. Is there some kind of built-in memory in the configuration file?\n\nSo, time to upgrade current.lemis.com, another VM running FreeBSD-CURRENT. It was a year out of date.\n\nStart a make buildworld , not for the first time. But nothing happened!\n\nFurther investigation showed that I had a network hang. And disaster was also hanging! Shut down disaster and current regained network access—for a while. Then it hung again.\n\nThis seems worse than my experience on hydra with VirtualBox 6.5. Tried it there and it worked.\n\nWhat a pain! What does Google Gemini say?\n\nQ: Are there known networking issues with VirtualBox under FreeBSD? A: Yes, there are known networking issues and quirks with VirtualBox when used as a host on a FreeBSD system. While VirtualBox works, it is not an officially \"supported\" host platform by Oracle, which means users often have to rely on the community and package maintainers to troubleshoot and resolve issues. (much irrelevant information omitted) Users sometimes experience slow network speeds, particularly with upload speeds, when using bridged adapters. This can be more pronounced on specific emulated network card types. While VirtualBox can function as a host on FreeBSD, it is not a \"fire-and-forget\" solution... If you encounter speed or reliability issues, experimenting with different emulated network adapter types can often resolve the problem.\n\nThat's not encouraging, though it doesn't directly relate to my problems. But what else can it be? Two different versions of FreeBSD, two different machines, two different versions of VirtualBox. Does it work better on Linux? That would be a real let-down, but possibly I should try it. How much pain would that be?\n\nTesting RSS feeds Topic: technology Link here\n\nI write all my web markup myself, with the aid of a number of PHP scripts. The result is that the RSS feed looks nothing much like my sources. So when something goes wrong with the markup, it's hard to find where, not helped by things like the W3.org validator, which typically points to where the error is detected, not where it occurred, and which at the moment caches input, so even after fixing the problem it reports the old problem.\n\nCallum Gibson is the main user of RSS feeds whom I know of. He pointed me to this validator. It also points to where the error was found, but at least I can try things and repeat them. That fixed an issue I had with earlier this month, where the error was over 100 lines from where it was detected.\n\nChasing the VirtualBox bug Topic: technology Link here\n\nSo why was VirtualBox version 7.1 on dereel even worse than version 6.50 on hydra? One possibility might be that the VMs themselves were NFS mounted. OK, find a 1 TB disk and copy them there. Put it in in place of the DVD drive, and was amazed to find that it came up as /dev/ada0, relegating the system disk to /dev/ada1 and requiring manual intervention (/etc/fstab) to continue. How could that happen?\n\nThen copying the VMs from hydra. That took a few hours, of course, so I'll continue tomorrow.\n\nWhile looking for the disks also found one marked “MS “Windows” 10 disgust”, dated 10.XII.2020. Comparing with my diary, that proves to be the disk that came with the machine I'm working on. So I should be able to just put it in and run it. That's the next thing to do if I still can't get VirtualBox to run reliably.\n\nDxO PhotoLab 9: worth the trouble? Topic: photography, technology, opinion Link here\n\nI've spent a lot of time looking at the new features of DxO PhotoLab 9. Even better noise reduction, of course, but the big new thing is what appears to be excellent object recognition (“masking”). But that's only part of the story. Can I remove objects? Replace them with something else? It seems that the answer is “no”.\n\nSomewhere I also thought I saw a way to merge HDR images, but that seems to be a misunderstanding. Instead they have improved file handling, including collapsing related image groups and automatic file naming. None of them seem to be anywhere near as flexible as the method I worked out 13 years ago, so it's of no use to me.\n\nSo: what will the future bring? The masking is good, but is it enough to spend US $240 on? There's a very good chance that they'll come up with a version 10 in the not-too-distant future and want $120 for an upgrade. Maybe I should just wait.\n\nVicRoads: still in the 20th century Topic: general, technology, opinion Link here\n\nAfter scrapping my Hyundai Elantra at the end of July I was due a refund for the registration.\n\nAnd they sent me a cheque! I thought they went out of fashion well over a year ago. And yes, the bank refused to accept it.\n\nBut why? I really don't understand. They should have transferred it to my bank account, like any sane company. But no, I had to call their customer service line (1300 555 165, which looks suspiciously like a fake US phone number) and go through their silly authentication process (including a form of 2FA, sending a PIN to my phone. That would have helped a lot if I had been calling from that phone). But yes, relatively quickly they took the details and told me that the transfer would occur in the next 2 to 3 weeks. Receipt number HD1155831.\n\n2 to 3 weeks? Why? Ah, we need human intervention. Why? Nowadays we have computers. With only marginally good programming the money could have been in my bank account before the end of the call. But clearly they don't have that.\n\nMore VirtualBox insights Topic: technology, opinion Link here\n\nSo what's wrong with VirtualBox networking? Google Gemini had suggested that it might depend on the emulated network adapter, so spent some time trying different adapters, with no improvement. About the only thing that was clear was the ping time: from guest to host the expected 0.15 ms, but in the other direction much longer, and with wildly different times:\n\nround-trip min/avg/max/stddev = 29.752/61.679/175.892/36.953 ms\n\nGave that up and looked at some bug reports, which showed surprisingly few network issues. But one, by Ivan Rozhuk, was interesting:\n\nTry to disable HW offloads on NIC:\n\nifconfig igb0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n\n\nAnd how about that, that worked. So why is this not better known? There's also a wiki with surprisingly little of use.\n\nLater I discovered that my guest current.lemis.com had 8 CPUs, while the host dereel only has four. That's quite impressive that it worked at all. Reducing the number of CPUs on current got rid of the slow ping times.\n\nSo: are we done? I don't think so. I still need to find whether the Microsoft guests work reliably.\n\nBruce Evans' C compiler Topic: technology, opinion Link here\n\nMail in the TUHS mailing list today:\n\nSubject: [TUHS] Bruce Evans 386 Minix patches & compiler source\n\n\n\nIt's been quite a while since I was messing with Minix386 back in the days\n\nwhen Bruce Evans released a set of patches to bring 386 support.\n\nI'm pretty sure over on oldlinux.org the patch set exists, but I can only\n\nfind the one set of binaries of his 386 toolchain.\n\nI know it eventually evolved into the bin86 toolchain that Linus would go on\n\nto use to create real mode boot code, but I don't know if any of the source\n\ncode to his 1991/1992 386 toolchain ever got published?\n\n\n\nIs it somewhere on the disk images that Peter Jeremy saved? I haven't looked at them for over three years, and I only had the smaller ones that I could download. Sent off a message to the other people who have access, Warren Toomey (who also coincidentally runs TUHS) and Warner Losh, and only got a brief response from the first.\n\nBack to look at what I have: three files, /src/bde/ad1.img, /src/bde/ad2.img and /src/bde/ad3.img. I had only looked at /ad0.img, requiring gnop to access the individual partitions. There was a good reason: I had renamed ad2.img.xz to ad2.img without uncompressing it. Did that now and ended up with 60 GB of data.\n\nAnd the contents?\n\n=== root@dereel (/dev/pts/1) /bde 13 -> mdconfig -a -t vnode -f /src/bde/besplex/ad2.img\n\nmd0\n\n=== root@dereel (/dev/pts/1) /bde 14 -> l /dev/md0\n\nmd0 md0s1 md0s2 md0s2a md0s2b md0s2d md0s2e md0s2f md0s2g md0s2h\n\n\n\nAll the BSD partitions there! So I can just mount them:\n\n=== root@dereel (/dev/pts/1) /bde 15 -> mkdir a b d e f g h\n\n=== root@dereel (/dev/pts/1) /bde 16 -> l\n\ntotal 1\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 a\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 b\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 d\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 e\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 f\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 g\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 h\n\n=== root@dereel (/dev/pts/1) /bde 35 -> for i in `echo a b d e f g h`; do mount -o ro /dev/md0s2$i $i; done\n\nmount: /dev/md0s2a: No such file or directory\n\n=== root@dereel (/dev/pts/1) /bde 36 -> df\n\nFilesystem 1048576-blocks Used Avail Capacity Mounted on\n\n...\n\n/dev/md0s2b 3,952 3,542 93 97% /bde/b\n\n/dev/md0s2d 3,952 2,971 664 82% /bde/d\n\n/dev/md0s2e 3,952 3,658 -21 101% /bde/e\n\n/dev/md0s2f 3,952 3,514 121 97% /bde/f\n\n/dev/md0s2g 11,754 8,842 1,972 82% /bde/g\n\n/dev/md0s2h 29,525 14,599 14,926 49% /bde/h\n\n=== root@dereel (/dev/pts/1) /bde 37 ->\n\n\n\nAnd in one of the partitions I found a file /bde/e/besplex/home/bde/dist/minix.tar.gz, which may be just what Jason is looking for. That was much easier than I thought. Is it correct? That would be too easy.\n\nMore fun with VirtualBox and bde Topic: technology, opinion Link here\n\nMore playing around with VirtualBox today, with no breakthrough. I had paused dereel with zzz, and when I restarted it the networking had gone to hell again. Here a repeat of what I had done yesterday:\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 1 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500 options=4e524bb<RXCSUM,TXCSUM,VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,LRO,WOL_MAGIC,VLAN_HWFILTER,VLAN_HWTSO,RXCSUM_IPV6,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 2 -> ifconfig em0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 3 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500\n\noptions=4c120b8<VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,WOL_MAGIC,VLAN_HWFILTER,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n\n\nAfter that it worked normally again, but the Microsoft boxen still didn't want to know. Do I have to cold start them every time?\n\nAnd Bruce Evans' C compiler? I posted what I had and got no answer. I'm not convinced that I have the right files, though the name usr/src/mx386/bcc (from the archive e/bde/dist/minix.tar.gz) does raise some hope.\n\nPower fail! Topic: general, technology, opinion Link here\n\nAt 11:04, while preparing breakfast, we had a grid power failure. Not a problem: we have a PV system. But the power dropped totally! Almost before we knew it, it was back again. The inverter log shows less than a minute.\n\nThat's not the first time. It happens far too often, most recently two months ago. And today, as then, my main machines eureka and hydra lost power, because I still hadn't got round to getting a UPS installed. Today I made up for that: I have a ten-year-old 1000 VA 650 W UPS just lying around. It is still functional? In contrast to the CyberPower UPS that I bought 2½ years ago, it seems still to work. While the power was down, took the opportunity to tidy up the mess to the left of my desk top, removing this display card from eureka and making a cut in my fingertip in the process:\n\nThat once drove three of the four monitors then connected to eureka, but that was years ago, as the dust suggests.\n\nWhat caused the outage? Hard to say. The inverter logs show no sign of overvoltage before the outage, though afterwards the voltage hung over 250 V for over an hour. I suppose it's time to brave the potential issues and update the firmware.\n\nPowercor had a different view. An hour later I received a message:\n\nAnd then\n\nOn checking, I found that I also had similar messages from the day before, where there was no outage at all. Still, rather phantom outages than real ones.\n\nhydra upgrade Topic: technology, opinion Link here\n\nI've had hydra for nearly 2 years, and I still haven't got round to configuring it quite the way I want; much is in the X menus. But of course the system is now down-rev. What better time then after a power failure to bring it up to date?\n\nMy real concern after an update is that the ports will no longer work the way I want. Building a new world is relatively simple, and it took just shy of 1000 seconds to build the world and new kernel. And rebooting went relatively smoothly, though it no longer found the Ethernet card on the motherboard. I had suspected issues in that area (it's a 2.5 Gb/s Realtek card) and installed a second, which showed up as re0 , so all I needed to do was to change where I plugged in the network cable.\n\nAs I feared, the ports were a different matter. They were worse then ever before, taking 3 iterations to delete 100—no, 101—no, 103 ports, including chromium curl, emacs of course, enblend, exiv2, feh, ffmpeg, firefox, fusefs-curlftpfs, gdb, git, gnupg, groff, hugin, mplayer, mpv, mutt, rdesktop, rsync, rtorrent, vigra, virtualbox-ose, xpdf and xv. And even then I missed ImageMagick, which further annoys me with a change of name. Yes, convert is a subcommand of ImageMagic, but now they have decided that the name is too invasive, so I'll have to change all invocations to magick convert. I suppose that one's fair enough.\n\nAnd firefox has new messages, which it spews by the hundred where it presumably suspects nobody is looking, on the home terminal:\n\nconsole.warn: services.settings: Could not determine network status. Message: TypeError: can't access prop \"isLinkUp\", lazy.gNetworkLinkService is undefined\n\nGradually the issues became clear: I can no longer connect to eureka with ssh, nor at all to hydra. I was expecting issues with eureka, but not with hydra. Was it because it came up before the network was ready? I had to restart syslogd to get it to write to eureka, and to change the permissions on wake for normal users to use it.\n\nWhat am I left with? I can no longer use erc, the Emacs IRC command:\n\nerc: missing symbol (.at)\n\n⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.\n\n\n\nWhat does that mean? I'll find out some time. Fortunately it still works on eureka, so there's no hurry.\n\nAnd independently of all that I need to pay more attention to my X configuration. I still don't get my mice set up correctly at startup. But that's fun for another day.\n\nCompleting the upgrade Topic: technology, general, photography, opinion Link here\n\nInto the office this morning as usual. No mail from hydra. What happened there? /var/log/maillog showed a number of:\n\nSep 20 03:03:54 hydra postfix/cleanup[70392]: B1BC41AB5: message-id=<202509191703.58JH3sRP070451@hydra.lemis.com>\n\nSep 20 03:03:54 hydra sendmail[70451]: 58JH3sRP070451: to=root, ctladdr=root (0/0), delay=00:00:00, xdelay=00:00:00, mailer=relay, pri=33687, relay=[127.0.0.1] [127.0.0.1], dsn=2.0.0, stat=Sent (Ok: queued as B1BC41AB5)\n\nSep 20 03:03:54 hydra postfix/qmgr[1845]: B1BC41AB5: from=<root@hydra.lemis.com>, size=4303, nrcpt=1 (queue active)\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: unexpected attribute smtputf8 from local socket (expecting: sendopts)\n\nSep 20 03:03:54 hydra postfix/smtpd[70368]: disconnect from localhost[127.0.0.1] ehlo=1 mail=1 rcpt=1 data=1 quit=1 commands=5\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: deliver_request_get: error receiving common attributes\n\n\n\nWhat's smtputf8 ? Checking /usr/local/etc/postfix/ showed that a number of files, which should have been symlinks to the same directory on eureka, were missing. Forgot to mount a NFS file system. After mounting and restarting postfix, all was well. But what does the strange message mean? It seems that it's a default.\n\nAnd then there was Hugin. I had expected some issues, but not what I got: when I tried to start the “fast panorama preview” I got\n\nerror installing GLEW\n\nFast preview window can not be opened\n\nWhat does that mean? I have a package installed, which pkg reports as\n\nglew-2.2.0_3 OpenGL Extension Wrangler Library\n\nAnd there doesn't seem to be anything else that was there before. But when I retried the attempt, it worked. Where is the bug? Hugin or FreeBSD? In addition, irritatingly it resized the windows on every start. I thought I had got rid of that with some script magic, but it seems to be gone.\n\nAnd then there's the mouse. That's simple enough: instead of searching for the index for the mouse, it's easy enough to write\n\nxinput set-button-map \"Telink 2.4G Mouse\" 1 2 3 4 5 6 7 2 2 10\n\nOne of the messages I received was completely misleading:\n\n=== grog@hydra (/dev/pts/16) ~/Photos/20250920 47 -> (EE) event4 - Telink 2.4G Mouse, class 0/0, rev 1.10/1.00, addr 4: client bug: event processing lagging behind by 32ms, your system is too slow\n\n(EE) client bug: timer event4 debounce: scheduled expiry is in the past (-48ms), your system is too slow\n\n(EE) client bug: timer event4 debounce short: scheduled expiry is in the past (-61ms), your system is too slow\n\n\n\nThat's not hydra at all, despite the prompt. I started X on teevee from hydra, and this appears to be its way of saying “the cat got on my mouse”.\n\nAccessing systems with ssh from eureka Topic: technology Link here\n\neureka is now running a nearly 10 year old system, but I don't want to update it: it works.\n\nBut some issues remain. One was that I couldn't automatically log on with ssh: I had to enter a password, which is irritating in scripts. Once again Google Gemini to my aid. Add this to /etc/ssh/sshd_config:\n\nPubkeyAcceptedKeyTypes=ssh-ed25519,ssh-rsa,rsa-sha2-512,rsa-sha2-256\n\nNow I just need to see why I can't access eureka from hydra without a password.\n\nFinally the birding photos Topic: photography, animals, technology, opinion Link here\n\nIt's been 4 days since the latest OM System birding “workshop”, and I've only just got round to processing the best photos. Are these the best?\n\nIt's a lot of work making up my mind out of over 250 photos. Yvonne did it for me, and those were the ones she liked.\n\nMore ssh strangeness Topic: technology, opinion Link here\n\nI've already established issues with ssh sessions from hydra to eureka, but not from other systems. Once again Google Gemini to my aid, this time less useful. It tells me to allow ssh-rsa in /etc/ssh/sshd_config by adding this line:\n\nPubkeyAcceptedKeyTypes=+ssh-rsa\n\nWe've seen that before on the other side. But that's a non-starter: sshd doesn't want to know:\n\n=== root@eureka (/dev/pts/1) /etc/ssh 28 -> service sshd restart\n\nPerforming sanity check on sshd configuration.\n\n/etc/ssh/sshd_config: line 54: Bad configuration option: PubkeyAcceptedKeyTypes\n\n/etc/ssh/sshd_config: terminating, 1 bad configuration options\n\nOK, what about the alternative of using a key?\n\n=== root@eureka (/dev/pts/1) /etc/ssh 32 -> service sshd restart; date\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStopping sshd.\n\nWaiting for PIDS: 22656.\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStarting sshd.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\n\n\nWhy? It doesn't seem to affect other key forms. And comparing hydra and tiwi gives me on hydra:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: send_pubkey_test: no mutual signature algorithm\n\n\n\nBut on tiwi it works as expected:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: Server accepts key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\nAuthenticated to eureka.lemis.com ([192.109.197.137]:22) using \"publickey\".\n\n\n\nWhat's the difference?\n\nMutt problems Topic: technology, opinion Link here\n\nFirst thing I do in the morning is to read the overnight mail, typically a couple of hundred messages. But this morning I tried to delete the messages I had read, I received the message “unable to write mailbox” or something similar. Why? Normally I see a message like that when I'm out of disk space, but this wasn't the case. Return, painfully delete the messages again, and it worked. Is that an NFS issue? It has happened before. Was that also overnight? I'll have to look more carefully next time.\n\nMore ssh pain Topic: technology, general, opinion Link here\n\nInto the office this morning to find eureka maxed out with at least 35 ssh-add processes, all looping at 100% CPU time.\n\nWhy? This is not a new program:\n\n3054180 -r-xr-xr-x 1 root wheel 17576 25 Nov 2015 /usr/bin/ssh-add\n\nOnce again Google Gemini to my aid, coming with the suggestion that it could be that ssh-add was running already, and that I should put in code like\n\nssh-add -l >/dev/null || ssh-add\n\nThat worked up to a point, but it doesn't explain why it is only happening now, after nearly 10 years. It's much more likely that it's related to the playing around I have been doing lately, though it didn't affect ssh-add, and I had backed out the changes anyway. And in the course of the day I found another instance in my weather software, but that found further breakage: the external view of my weather stopped in early June when I got the new weather station. More to fix when the current problems are over.\n\nssh-add: A clue Topic: technology, opinion Link here\n\nI haven't done much to investigate the ssh-add problem for the moment. It seems that I call ssh-add in a number of places, all of which need fixing. But while playing around I found:\n\n=== grog@eureka (/dev/pts/3) ~/public_html 32 -> ssh-add < /dev/null\n\nEnter passphrase for /home/grog/.ssh/id_rsa:\n\nCould it be that the looping is the incorrect handling of a prompt? It doesn't help much in fixing it, but it could help understand.\n\nThe advantages of upgrades Topic: technology, opinion Link here\n\nAs expected, upgrading hydra caused a number of problems, most of which I have described. And this time it was Chromium, which has forgotten all its editing keys, or at least the ones I want. More searching required.\n\nOn the other hand, one bug has gone away: xv can now display PNG again. Not exactly a big improvement, but at least a fixed bug.\n\nThe daily Android bug Topic: technology, opinion Link here\n\nSomehow the Android operating system seems to be the least reliable I know. I'm gradually coming to terms with it, but today there was another one: trying to download files to a Real Computer, albo didn't respond, though it claimed to be working. Disable Wi-Fi, reeenable, and it worked. No change of connection.\n\nWhat a mess Android is!\n\nAnother web server overload Topic: technology, opinion Link here\n\nIt's been well over 4 months since I set up a new external web server, fra.lemis.com, to address the really heavy load, with load averages up to 170. And so, of course, it dropped back to under 1.\n\nBut now it's increasing again, both servers now well over 200. Why? I had thought it was related to the imagesizes parameter, but that doesn't seem to be the case. Let's see how long the overload lasts this time.\n\nFast postal service Topic: general, technology, opinion Link here\n\nI've bought a couple of cameras in the United Kingdom. The usual tracking information, with a twist:\n\nIt's in Leeds, but it'll be here tomorrow! Now that's a lot faster than Australia Post. Or just plain stupid.\n\nYour cameras have been delivered! Topic: technology, photography, general, opinion Link here\n\nYesterday's claim of fast delivery was amusing enough, but they haven't given up:\n\nThey have been delivered! How did we do?\n\nI'm amazed. Clearly the cameras are still in the United Kingdom. My best guess is that Royal Mail have delivered the cameras to the people who are currently in the process of sending them half way round the world, or at least they have received documentation from them. So from their limited viewpoint they have been delivered. No concept of them only having travelled a fraction of the distance.\n\nWeb server load: dropping Topic: technology Link here\n\nYesterday's web server overload didn't last long. It's back to round 1 again. I suppose that's what we're going to have to live with for the foreseeable future. It's interesting that even at this extreme overload people claimed that response was satisfactory. That's significantly different from last time, where some sites got timeouts.\n\nArtificially intelligent breakfast Topic: food and drink, technology, opinion Link here\n\nFor some reason we bought a quarter cabbage recently. I forget why, but it was intended for breakfast. All right, Google Gemini, give me some east asian recipes with fried cabbage.\n\nAnd the twins obliged: 手撕包菜 - Shǒu Sī Bāo Cài, “hand shredded cabbage\", which didn't look too bad, modulo these horrible cups measurements. I can't even blame the twins for that: so many recipes use it. But it's the biggest hindrance I can find for trying out recipes. OK, Gemini, give me a Chinese recipe with fried cabbage and noodles using metric units. OK, how about 包菜炒粉/麵, which Google Translate translates as “cabbage fried rice noodles”? A completely different recipe! The best I can guess from the two recipes is that 4 cups of cabbage weigh about 300 g.\n\nSpent some time—probably more than cooking—writing a sane version of the second recipe.\n\nSoftware upgrades: the sting in the tail Topic: technology, photography, opinion Link here\n\nHouse photos again today, the second time since I upgraded hydra to FreeBSD 14.3 last week. And once again I had pain.\n\nFirstly, creating HDR didn't work well. It took me a while to discover that it was an unrelated bug in one of my scripts: I managed to mix images from the OM System OM-1 Mark II with the correct images from the Olympus OM-D E-M1 Mark II. I had already expected problems like that, and /Photos/Tools/housephtos.awk contained appropriate comments. Here the fix:\n\n-# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n+# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n# Create a makejpeg file from housephoto.notes file.\n\nBEGIN {\n\ni = 0;\n\n-# XXX Only look at photos from E-M1 Mark II.\n\n+# Only look at photos from E-M1 Mark II.\n\n# Is this safe?\n\n-# Was: 4*.ORF, E-M1 /2 only\n\n- while (\"ls -rt *.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n+# It's better than the alternative.\n\n+ while (\"ls -rt 4*.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n\n\nThe problem was that I didn't limit the choice to photos from the E-M1 Mark II. Not an upgrade problem at all.\n\nThe other, though, seems to be related to the upgrade of Hugin, now version 2024.0.1. The screens appear in the wrong place and at the wrong (tiny) size, and the directories are wrong. That's almost certainly related to the scripts that I wrote over 16 years ago which frob the ~/.hugin file to get rid of this horrible directory name retention. But that's all they do, and somehow it doesn't seem to work. A small detail, but irritating. Will I get round to it by next week?\n\nRevisiting old photos Topic: photography, technology, opinion Link here\n\nLooking back through old photos, found some of my first panoramas:\n\nIt dates from 11 April 2009 with the Olympus E-510, so old that I don't even have Exif data for it. I had already attempted to improve it 8 years later:\n\nBut that was still with the Ashampoo Photo Optimizer, which I have stopped using. Another attempt with “Perfectly Clear” gave me further improvements. Here are the three together (run the cursor over an image to compare it with its neighbour):\n\nIn particular the highlights and shadows are greatly improved.\n\nfra rebooted! Topic: technology, general, opinion Link here\n\nThe vultures have rebooted fra! Yes, they warned they would do so because of some unspecific bug in Linux, so they rebooted my FreeBSD box as well. The good news is that it came back without any intervention on my part, but of course the up time has gone to hell.\n\nAnother bloody power fail Topic: technology, general, opinion Link here\n\nIn the evening, another grid power failure. And another directly behind it. Both were sub-second, but once again eureka and hydra failed. So much for the UPS.\n\nWhy? Yes, it's an old UPS, but it claims to have plenty of charge, and the failures were so short that most clocks in the kitchen kept going. Can it be that it was a power surge, and that this UPS didn't handle it? The UPSs for lagune, teevee and tiwi had no problems.\n\nAnd the fallout? I got things running relatively quickly, but firefox didn't recover its many tabs. I had to start a different profile to get anything. And of course X on teevee failed, because I had started it from hydra.\n\nSo what do I do now? Buy more of UPSs of the kind that power the other machines?\n\nTuesday, 30 September 2025 Dereel Top of page previous day\n\nMore firefox pain Topic: technology, general, opinion Link here\n\nSo what's wrong with firefox? My standard profile just hangs. Why? How do I debug such a mess?\n\nI tried setting up a different profile, losing a number of tabs in the process, but nothing I could do could get the font sizes right. Get them right for my diary (without any trickery) and they're far too small for things like Wikipedia and friends. Migrate from hydra:0.2 (3840×2160) to hydra:0.0 (1920×1080)? Yes, that works, but why did it happen?\n\nThen it occured to me: yes, the standard profile still hangs. But I can check the settings. And it seems that the big thing is the Zoom setting, which was at 150%. After setting that, things were OK. But why the difference between my diary and Wikipedia and Co.? And why are font sizes such an issue with firefox?",
      "source": "Lemis.com",
      "url": "http://www.lemis.com/grog/diary-sep2025.php?topics=c#D-20250908-235445",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "An Officer and a Gentleman",
      "content": "Posted 08 September 2025 - 07:48 PM\n\nWhen, in the 1982 movie, Zack Mayo cries to Sgt. Emil Foley, \"I have no place else to go!\" I know how he must feel. Although I've owned one of these infernal machines since the first one was on the market, five-inch green-lettered screen, no hard drive, two floppy disks, I've been using them as a production tool so consistently that I haven't had the time nor energy to comb out much of an idea of how they work. For that reason I've been relying on the wizardry of Bleeping Computer for the save for close to ten years. Not once have you people ever steered me wrong.\n\nHere's my computer specs:\n\n2023 Velocity Micro Pro Magic HD80\n\nDevice name VM-900649\n\nProcessor AMD Ryzen 5 7600X 6-Core Processor (4.70 GHz)\n\nInstalled RAM 32.0 GB (31.2 GB usable)\n\nDevice ID 57C113A0-86B4-4E66-A907-7EE709105884\n\nProduct ID 00330-73771-05884-AAOEM\n\nSystem type 64-bit operating system, x64-based processor\n\nWindows 11 PRO OS\n\nNo pen or touch input is available for this display\n\nYears ago, when my computer of that era was acting weird, wouldn't do what I asked, screens weren't looking right, slow as grandma in a tar pit, you sent me an in-house program that stripped all the crap out and made that other computer run good as new. I'm just guessing, but I think this one might need one of those massages. I couldn't really count the times you have saved my adze, sometimes when deadlines were just short of lethal.\n\nNow it's half the speed when new, it does really ugly things like shifting screens to something I didn't want, taking a very long time to upload or download the internet, failure to cut-and-paste. One program interfering with another, won't copy a URL to my digital notebook in a manner that will run when clicked, adding belligerent software that I didn't order. A time or two it turned itself back on in the middle of the night after I had turned it off. Pop-ups popup even though I have a lot of software that is supposed to prevent that. This old friend is acting like it's possessed, which of course it might be, with a rider of some kind or a malignant virus scraped off from somewhere or something else dastardly.\n\nI work this unit pretty hard, using Presonus Studio One Pro + DAW, Final Draft screenwriting software and Chief Architect X15 Premier. I'm retired now so it seldom gets a rest. Maybe it's just bogged down like they get sometimes, but I wanted to ask you how to properly accomplish whatever it is that needs to be done so this great machine can get back to being great again without me making it any worse.\n\nThanks a million to all of you for the magnificent help you've given to me over the years. It's a pretty sure thing that I've sent over twenty customers to you since we met a decade ago. I'll continue with that until I fall over. Jason Brooks",
      "source": "BleepingComputer",
      "url": "https://www.bleepingcomputer.com/forums/t/810602/an-officer-and-a-gentleman/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Acrobat Pro DC 2025.001.20693",
      "content": null,
      "source": "Rlsbb.ru",
      "url": "https://post.rlsbb.ru/adobe-acrobat-pro-dc-2025-001-20693/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "AMD's New 25.9.1 GPU Driver Makes FSR 4 Available In Most FSR 3.1 Games",
      "content": "Yesterday, AMD released version 25.9.1 of its new Radeon GPU driver, bringing the total of fully-supported FSR 4 games to 85 (including the newly-released Borderlands 4) and adding a driver toggle to force FSR 4 into compatible FSR 3.1 games running under DirectX12.\n\n\n\n\n\nThis now means that most games supporting AMD FSR 3.1 games can be retrofitted with AMD FSR 4 without further developer support required, though this brute-force method is still limited to DirectX12 games that have a standard FSR 3.1 integration with an officially-signed FSR 3.1 DLL. Games that only support Vulkan or use a non-standard FSR 3.1 implementation unfortunately cannot be retrofitted with AMD's machine learning-accelerated FSR 4 implementation without developer updates. As always, AMD still hosts a full list of AMD FSR 4-supported games.\n\nFor gamers hoping to start using AMD FSR 4 right away, make sure that you're on a supported AMD RDNA 4 GPU, like the Radeon RX 9070 XT , since the latest AMD GPUs are required to make use of FSR 4, unlike previous versions of FSR. A simple driver update from your Radeon Software should do the job from there, but there's always the manual driver download page, if you need to use that.\n\n\n\n\n\nFortunately for AMD users, FSR 4's image quality has greatly improved compared to previous versions of FSR, providing an image more in line with NVIDIA's excellent DLSS upscaler thanks to making better use of the onboard RDNA 4 hardware. For RDNA 4 GPU users hoping to use FSR 4 in even more games, there's even a method utilizing OptiScaler allowing you to hack in FSR 4 to replace DLSS and XeSS in certain games, though your results may vary,\n\nImage Credit: AMD\n\nBesides updates to AMD FSR 4, the new GPU driver also fixes some issues impacting Mafia: The Old Country, WUCHANG: Fallen Feathers, and Monster Hunter Wilds, as well as a peculiar bug preventing PlayStation VR controllers being detected within SteamVR. The manual download page also lists some known issues impacting The Last of Us Part II, Call of Duty: Black Ops 6, FBC Firebreak, Cyberpunk 2077 (with path tracing), GTFO, and some stuttering on VR headsets connected to older AMD GPUs.",
      "source": "Hot Hardware",
      "url": "https://hothardware.com/news/amd-2591-gpu-driver-makes-fsr-4-available-in-most-fsr-31-games",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "RPCS3 Developer Claims AVX-512 Is Power-Efficient, Blames Skylake-X For Its Poor Reputation",
      "content": "Yesterday, developer of PS3 emulator RPCS3 Whatcookie posted a 20-minute YouTube video to their YouTube channel in defense of AVX-512, a maligned CPU instruction set that debuted with Intel's Skylake-X architecture in 2015 and didn't see adoption by AMD CPUs until 2022's Zen 4. Specifically, Whatcookie debunks claims that modern implementations of AVX-512 are inefficient by showcasing benchmarks of both RPCS3 and other pieces of software using AVX-512 on modern CPU architectures, showing that the instruction set still manages higher performance at the same wattage levels, the same performance at lower wattage levels, and much higher performance at slightly-higher wattage levels.\n\n\n\n\n\nWhatcookie doesn't stop there, though. He also includes a mini history lesson on the instruction set in his 20-minute video, highlighting how the initial Skylake-X implementation actually did substantially lower clock speeds and boost power draw when AVX-512 was in use. These issues were mitigated on Intel's high-end server-grade Xeon CPUs, and were seemingly artificially exaggerated on consumer-grade Skylake-X chips thanks to more severe downclocking enforced in firmware.\n\nTo those who have been keeping track of RPCS3 development or AVX-512 adoption in recent years, this actually shouldn't be that surprising. Back in 2022, we covered performance gains of up to 30% on RPCS3 when using AVX-512 ourselves, and just last month we reported on Phoronix's benchmarks showing major performance benefits of AVX-512 on the AMD Ryzen 9 9950X\n\n\n\n\n\nSadly, while modern benchmarks on modern hardware should seemingly have cleared AVX-512's name by now, popular consensus of the AVX-512 instruction set still points to a maligned reception tainted by Intel Skylake-X all these years later. Perhaps that shouldn't be surprising, though, considering how long Intel iterated upon Skylake's 12nm architecture before finally adopting an all-new 10nm architecture with Alder Lake in 2021— an architecture that outright disabled AVX-512 because the new E-cores couldn't support it, although P-cores could.\n\nImage Credit: Der8auer for Skylake-X delidded thumbnail, Whatcookie for RPCS3 benchmark images\n\nAll this isn't to say that AVX-512 is a perfect CPU instruction set, by any means. On modern architectures from Intel and AMD, some minor downclocking is still present when executing enough full-length AVX-512 instructions at once, but these are enforced by more typical thermal and power constraints, not firmware constraints as with consumer Skylake-X chips. This means that AVX-512 still shows much higher performance and efficiency were in use on modern CPUs compared to AVX2, and this discrepancy has already been highlighted by benchmarks from several sources including Phoronix and VideoLAN, not just RPCS3 development.Thankfully, AVX-512 seems to be a straightforward power and performance win on modern CPU architectures from Intel and AMD alike, despite how poorly it fared with Skylake-X's launch. That bitter aftertaste will linger for some time, though— and as Whatcookie highlights in a concluding skit, even the likes of the supposedly PhD-level GPT-5 still uncritically repeats critique of Skylake-X-distorted AVX-512 performance as gospel.",
      "source": "Hot Hardware",
      "url": "https://hothardware.com/news/rpcs3-developer-claims-avx-512-is-power-efficient-blames-skylake-x",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Advanced Micro Devices, Inc. (AMD) Becomes the Most Under-Owned U.S. Semiconductor Stock",
      "content": "Advanced Micro Devices, Inc. (NASDAQ:AMD) is included in our list of the 14 Tech Stocks to Sell Now According to Ken Fisher.\n\nAdvanced Micro Devices, Inc. (AMD) Becomes the Most Under-Owned U.S. Semiconductor Stock\n\nClose-up of Silicon Die are being Extracted from Semiconductor Wafer and Attached to Substrate by Pick and Place Machine. Computer Chip Manufacturing at Fab. Semiconductor Packaging Process.\n\nBank of America reported on September 3, 2025, that Advanced Micro Devices, Inc. (NASDAQ:AMD), despite being an outperformer in the sector, has become the most under-owned U.S. semiconductor stock among active managers. Active ownership fell to 20% in August from 23% in May and 39% a year earlier.\n\nMeanwhile, Advanced Micro Devices, Inc. (NASDAQ:AMD)’s relative weighting has gone down by 80% year-over-year compared to the S&P 500. This is in line with consensus forecasts, which project 22% sales growth and AMD’s continued gains over the Philadelphia Semiconductor Index. At the same time, the investment firm reiterated its ‘Buy’ rating on AMD, thanks to strong tailwinds from rising artificial intelligence adoption and the company’s sustained market share gains against Intel.\n\nAdvanced Micro Devices, Inc. (NASDAQ:AMD) focuses on designing and developing semiconductors, offering CPUs, GPUs, AI accelerators, and embedded solutions. It serves data centers, client computing, gaming, and specialized applications globally.\n\nWhile we acknowledge the potential of AMD as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 15 Stocks That Will Benefit From AI and 10 Must-Buy Canadian Stocks to Invest in.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/advanced-micro-devices-inc-amd-085831164.html",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "This Dell Laptop with Ryzen 7 and Crazy Specs Is 73% Off on Amazon, Stock Is Flying Out",
      "content": "Dell is a bit of a favorite when it comes to Windows laptops. They offer options for every budget but it’s rare to find one priced under $1,000. So, if you’re in the mood to hit the jackpot, there’s currently a Dell Inspiron 15.6-inch touchscreen laptop (32GB RAM, 1TB SSD, Windows 11 Pro, AMD Ryzen 7 7730U) valued at $3,000 going for $799 on Amazon—talk about a huge deal.\n\nSee at Amazon\n\nWhy Buy That Dell Laptop?\n\nThis laptop comes with a 15.6-inch widescreen display that delivers Full HD visuals with a resolution of 1920 by 1080 pixels. The screen uses Wide Viewing Angle technology, which means the colors stay crisp and accurate even when you’re not looking at the screen head-on. Furthermore, the anti-glare coating reduces reflections so you don’t strain your eyes doing work in a brightly lit room or near a window. The thin bezels on the sides of the screen give you more screen space without interruptions, and the LED backlight shines on the screen without wasting power so your battery will last longer.\n\nThe brain behind this machine is the AMD Ryzen 7 7730U processor, which clocks 4.5 GHz at its best: It’s optimized to provide snappy performance without draining the battery. So, if you’re doing work life seriously or studying, it won’t slow you down, and you’ll get decent battery life for it.\n\nInternally, the laptop comes with 32GB of RAM which is the memory that enables your computer to have several programs open at the same time without lagging. Put simply, the more RAM you have, the more smoothly things go when switching between tasks or working with large files. This laptop’s generous memory puts you ready to handle demanding programs, so you won’t find yourself waiting around for things to load. Besides that, it also comes with a generous 1TB solid-state drive where all of your apps and documents reside.\n\nYou’ll be running Windows 11 Pro, the professional version of Microsoft’s latest operating system. It’s designed for business and serious users and offers strong security features along with tools that make managing your work easier.\n\nWhat makes this deal even sweeter is the bundle of accessories included: You get a stylus pen for easy touchscreen operation, a camera privacy cover to ensure your privacy during video calls, a 128GB USB flash drive for extra portable storage, a dust plug to ensure the ports remain free from dust, a carrying sleeve for protective transport of the laptop, and a microfiber cleaning cloth to have everything spick and span.\n\nThis deal won’t last forever, make sure you don’t miss it.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/this-dell-laptop-with-ryzen-7-and-crazy-specs-is-73-off-on-amazon-stock-is-flying-out-2000624609",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Elon Musk Was Just Unseated as the World’s Richest Person",
      "content": "Oracle Chairman Larry Ellison is having a good morning.\n\nOracle’s stock is up more than 42% on Wednesday, thanks to an earnings call on Tuesday that left investors stunned.\n\nThe company missed earnings and revenue estimates, but the forward looking guidance alone was apparently good enough to get investors to rally around it. A bulk of that reaction had to do with the revenue that AI computing demand was expected to bring to Oracle’s cloud infrastructure service.\n\nThe shares skyrocketed in response. Oracle’s stock is now on pace to have its largest single session surge since the dot-com boom, according to CNBC.\n\nWith the current surge in shares, Ellison has increased his wealth by more than $100 billion, thanks to the roughly 1.16 billion shares he owns. This meteoric rise grabbed him the title of the richest person on Earth from the former title holder, Elon Musk, according to the Bloomberg Billionaires Index.\n\nAs of Tuesday, Ellison’s current total fortune was worth $295 billion, having increased by $100 billion in worth in just the past year. Today’s additional increase has catapulted him to a staggering $389 billion, surpassing Elon Musk’s whopping $384 billion fortune.\n\nMusk was first named the richest man in the world in 2021, and has since been up and down on the list. He has held the title consistently since last year and briefly became the first person to surpass $400 billion net worth in December. Although Ellison has overtaken him on the list, Musk might reverse that yet again soon. Musk is facing the potential of becoming the world’s first trillionaire, that is if the massive and unprecedented proposed pay package plan by the Tesla board gets approved by shareholders.\n\nOracle’s AI success story\n\nLarry Ellison co-founded Oracle in the late 1970s with the CIA as an early customer. Decades down the line, the database software company now specializes in AI-first cloud computing and competes with other giants like Microsoft’s Azure, Alphabet’s Google Cloud, and Amazon’s AWS. It’s the aggressively positive and AI-driven outlook for its cloud infrastructure business that has led to investor delight and the 81-year-old Ellison is benefiting handsomely from it.\n\nAlthough the revenue estimates were down, the company said it was expecting to collect more than half a trillion dollars extra thanks to four multi-billion-dollar contracts it signed in the past quarter. At the company’s earnings call, CEO Safra Catz mentioned OpenAI, Meta, Nvidia, AMD, and Elon Musk’s xAI as some of the company it has “significant cloud contracts with.”\n\nCompany executives shared that they are expecting to finalize even more multi-billion-dollar deals in the near future.\n\nOracle, and Ellison, are hell-bent on AI. The company recently made headlines for an alleged plan to spend more than $1 billion a year to run a new data center in Texas on gas generators rather than wait for approval and infrastructure to pull the electricity from the local grid. Oracle is also one of the partners in the Trump administration’s ambitious AI project Stargate.\n\nCloud computing is the hot name in AI earnings\n\nCloud computing might be one of the clearest early winners of the AI hype. AI companies are scouring for more computing capacity as they try to compete with each other and scale operations, and they are willing to spend a hefty amount of money for it. Enter cloud infrastructure providers, like Oracle and Microsoft, that provide computing power for large AI models. Both the companies showed a meteoric stock increase after their recent earnings report.\n\nIn its latest earnings report in July, Microsoft reported that sales were up 18% from last year and that revenue for its cloud computing platform Azure had surpassed $75 billion this year, up 34% from last. Despite these numbers accompanying Microsoft’s largest ever quarterly capital expenditure forecast, the market went crazy for it. The shares jumped and the tech giant briefly became the second-ever company to hit $4 trillion market valuation.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/elon-musk-was-just-unseated-as-the-worlds-richest-person-2000656741",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Despite cutting the gags, Borderlands 4's PC specs say it still needs 100GB of SSD space",
      "content": "Two days before launch, Borderlands 4 has its PC system requirements. They’re generally on the higher side without teetering over into full-on tech demo lunacy – the RTX 2070 is a minimum-spec graphics card, for instance – though anyone with a smaller SSD will need to make room for the looty FPS sequel’s bumper-size 100GB storage requirement.\n\nI have mixed feelings about this. On the one hand, gargantuan install sizes are kind of obnoxious (even the infamously bloated Call of Duty agrees), and are partly caused by merely visual, high-resolution textures that we increasingly need madly expensive GPUs to even enable. Or at least, to enable without simultaneously committing framerateicide.\n\nOn the other hand, 100 is a very round and satisfying number. Just look at it. Way better than 112 or some garbage. I do wonder if anyone working in Gearbox’s gigabyte dieting department saw it was possible to compress it down to 99GB, potentially avoiding the shock of entering the triple digits, but left it at 100GB just because it’s vaguely nicer. I suspect I’d do the same.\n\nAnyway, here’s the hardware:\n\nBorderlands 4 minimum PC specs\n\nOS: Windows 10 / 11\n\nWindows 10 / 11 CPU: Intel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum)\n\nIntel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum) RAM: 16GB\n\n16GB GPU: Nvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum)\n\nNvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum) Storage: 100GB (SSD required)\n\nBorderlands 4 recommended PC specs\n\nOS: Windows 10 / Windows 11\n\nWindows 10 / Windows 11 CPU: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nIntel Core i7-12700 / AMD Ryzen 7 5800X RAM: 32GB\n\n32GB GPU: Nvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nNvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580 Storage: 100GB (SSD required)\n\nSolid state hungriness aside, it’s a bit strange seeing the Arc B580 in the recommended tier, alongside the RTX 3080 and RX 6800 XT – it’s a good little budget card but not on the same level as those two older, yet bonafide high-end GPUs. Though maybe that means Borderlands 4 performs better-than-recommended on this Nvidia/AMD kit?\n\nAlso, 2K’s post doesn’t mention it specifically, but DLSS 4 Multi Frame Generation is supported as well. This needs a GeForce RTX 50 series card to operate at full pelt, with RTX 40 models making do with DLSS 3-style 2x frame gen.\n\nI’m generally in the 'wait and see how it is' camp on Fourderlands, with its new planet and its many billions of randomly generated firearms, having previously been interested enough to mulch through Borderlands 3 with mates but jointly concluding it wasn’t worth our time. This new one is something of a reset, with its lead writer Taylor Clark claiming it won’t have as many jokes. Which is, at once, likely an improvement and also a weird thing to make a selling point of. B4's out on September 12th.",
      "source": "Rock Paper Shotgun",
      "url": "https://www.rockpapershotgun.com/despite-cutting-the-gags-borderlands-4s-pc-specs-say-it-still-needs-100gb-of-ssd-space",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Intel promises 'leadership across the board on desktop' when its next-gen Nova Lake CPU launches in late 2026",
      "content": "Intel's been on a roll of late in all the wrong ways. Borked CPUs, failing fabs, haemorrhaging cash, run-ins with the President of the USA. The woes never end. Until next year, that is, and the launch of Nova Lake. That's right, peeps, when Intel's next-gen CPU architecture arrives at the end of 2026, Intel will ascend to a leadership position across the board on desktop.\n\nTo quote John Pitzer, Intel's Corporate Vice President of Corporate Planning & Investor Relations, precisely, \"as Nova Lake comes out at the end of next year into 2027, I think we're going to have a leadership position across the board on desktop.\"\n\nThat is one heck of a bold claim, even for a chip that's rumoured to pack up to 52 cores. Of course, it will at least in part hinge on the quality of Intel's upcoming 18A process, the node formerly known as the one upon which Pat Gelsinger bet the entire company, but latterly more of a stepping stone back to profitability, with 14A being the node on which Intel's hopes to build chips for customers now depends on.\n\nUnsurprisingly, Pitzer is bullish on 18A, too. He says Intel is planning to spend heavily on tooling up to produce lots of chips on 18A and return Intel to profitability. Famously, or you might say notoriously, both of Intel's latest CPU families, namely Arrow Lake and Lunar Lake, are largely manufactured by TSMC.\n\nIntel will start the process of moving that production in-house with Panther Lake. However, Panther Lake is a mobile CPU and is also aimed at more power-efficient laptops as opposed to larger desktop-replacement rigs. More to the point, it's thought only certain versions of Panther Lake will have CPU dies made by Intel. The bulk of production may well end up being handled by Taiwanese chip foundry TSMC.\n\nLunar Lake is a good mobile chip, but Intel pays TSMC handsomely to manufacture it. (Image credit: Intel)\n\nIn other words, Panther Lake will only entail fairly limited quantities of Intel's 18A silicon. That changes with Nova Lake. \"Nova Lake itself being both a notebook and a desktop part has pretty meaningful implications for the amount of wafer starts that we need on 18A,\" Pitzer says.\n\nAnd that should mean improved profitability because it means Intel won't have to pay those pricey TSMC wafer fees. \"As you look at it through the lens of Intel Foundry, the move from Intel 7 to Intel 18A, ASPs per wafer will go up three times faster than their cost. And so just driving more volume through the fab on 18A is a pretty profitable dynamic for Intel Foundry,\" Pitzer.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nMorever, Pitzer says Intel can get back to making money just by executing on its own products, it doesn't absolutely need to win big foundry customers. \"We don't need to see a lot of external foundry revenue to breakeven exiting 2027,\" he says.\n\nThe question is, can Intel actually deliver on its own products? If you examine Intel's recent CPU families, it's not altogether promising. The Raptor Lake generation has turned out to suffer from major bugs, the Meteor Lake mobile architecture was underwhelming, and Intel's latest desktop chips, known as Arrow Lake arrived half baked and even after a little tweaking remain well behind AMD by most estimates.\n\nThe only unambiguous exception to all that has been Lunar Lake, which is a decent low-power mobile CPU, but according to Intel itself, isn't a money spinner on account of being made mostly by TSMC and having integrated memory, which limits configuration options for laptop makers.\n\nWe'll get an initial feel for whether Intel is getting back on track with Panther Lake at the end of this year, which will be our first taste of the 18A process. But that's another low-power CPU. So, it will really be Nova Lake at the end of 2026; that's the real test.\n\nNova Lake will span the whole gambit from lower-power laptops to high-performance desktops and is shaping up to be an absolutely vital processor family for Intel. Nova Lake simply has to be at least competitive with AMD if Intel is going to turn things around.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/processors/intel-promises-leadership-across-the-board-on-desktop-when-its-next-gen-nova-lake-cpu-launches-in-late-2026/",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "AMD Megapod set to face Nvidia's Superpod with a 256-GPU rack full of Instinct MI500 chips",
      "content": "AMD MegaPod design emphasizes raw GPU count and interconnect efficiency\n\nNvidia’s packaging method complicates direct comparisons with AMD’s approach\n\nThree racks will form the backbone of AMD’s MegaPod, and each compute tray may combine Verano CPUs with MI500 accelerators\n\nAMD appears to be preparing a new large-scale computing system aimed at high-performance computing.\n\nAccording to industry analysis, the so-called \"MegaPod\" is projected to house a large number of accelerators, positioning it as a direct response to Nvidia’s established \"SuperPod.\"\n\nThe first signs of its design point to an emphasis on raw GPU count and interconnect efficiency, although exact details remain speculative.\n\nA system with 256 MI500 chips\n\nReports suggest that AMD will arrange the MegaPod across three separate racks.\n\nThe two outer racks are expected to hold 32 compute trays each, while the central rack will contain 18 trays for networking switches.\n\nWithin each compute tray, a single Verano CPU may be paired with four Instinct MI500 GPUs.\n\nThis layout would deliver 32 CPUs and 128 GPUs per rack, producing a total of 64 CPUs and 256 GPUs for the entire system.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe proposed design, sometimes referred to as \"UAL256,\" reflects AMD’s intent to expand capacity in ways meant to outmatch competitors.\n\nThe comparison between AMD’s MegaPod and Nvidia’s SuperPod is not straightforward.\n\nOn paper, the AMD system would offer 256 physical or logical GPU packages, while Nvidia’s Kyber VR300 NVL576 lists only 144.\n\nHowever, Nvidia’s architecture organizes four GPUs per package, yielding 576 GPUs overall.\n\nAMD’s reliance on single-GPU packages means its structure may appear larger in physical package count but not necessarily in total core density.\n\nThis complicates any attempt to declare one system as superior. For now, the MegaPod looks positioned more as a counterbalance than a clear leap ahead.\n\nThe central rack of the projected system is designed for switching infrastructure.\n\nAnalysts expect AMD’s new Vulcano network cards, derived from the Pensando line, to be deployed here.\n\nThe use of these cards could determine whether the MegaPod can deliver enough bandwidth to make full use of its GPU-heavy configuration.\n\nWhile the physical layout of racks and trays seems straightforward, network latency and throughput will play as critical a role as raw GPU numbers.\n\nThe system is expected toward the end of 2027, placing it on the same development horizon as other major HPC installations and large-scale data centers, including the German Herder supercomputer.\n\nAMD has acknowledged plans to combine Verano CPUs, MI500 accelerators, and Pensando Vulcano network cards, but exact details of the MegaPod remain unverified.\n\nVia Computerbase (originally in German)",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/amd-megapod-set-to-face-nvidias-superpod-with-a-256-gpu-rack-full-with-instinct-mi500-chips",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Why Is Advanced Micro Devices (AMD) Stock Jumping Today?",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_856ccd2f-0ce1-4af4-bfb4-66b7e9116ac0",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Borderlands 4 PC hardware requirements ask for an RTX 2070 as a minimum, but a 3080 is recommended",
      "content": "Borderlands 4 releases on 12th September, and just in time developer Gearbox has revealed the PC hardware specs you'll need to run the game at a decent or intended level - essentially the minimum and recommended PC specs.\n\nGearbox says that the minimum hardware requirements will let you run the game with solid performance on older PCs, while the recommended specs will let you play Borderlands 4 with high performance and graphical detail the studio set out to deliver.\n\nImage credit: Gearbox Software\n\nBorderlands 4 PC Specs Borderlands 4 Minimum PC Hardware requirements: Requires a 64-bit processor and operating system\n\nRequires SSD\n\nOS: Windows 10 / 11\n\nProcessor: Intel Core i7-9700 / AMD Ryzen 7 2700X\n\nMemory: 16 GB RAM\n\nGraphics: NVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580\n\nRequires 8 CPU Cores for processor and 8 GB VRAM for graphics.\n\nStorage: 100 GB available space Borderlands 4 Recommended PC Hardware requirements: Requires a 64-bit processor and operating system\n\nRequires SSD\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nMemory: 32 GB RAM\n\nGraphics: NVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nStorage: 100 GB available space Borderlands 4 PC graphics settings: Basic: Display Mode: Fullscreen, Windowed Fullscreen, Windowed\n\nResolution (Varies by setup)\n\nDisplay Stats: None, FPS, All\n\nLimit Frame Rate: Off, On\n\nCustom FPS Limit (Varies by setup)\n\nVertical Sync: Off, On\n\nField of View (ultrawide monitors supported)\n\nVehicle Field of View (ultrawide monitors supported) Advanced: Graphics Preset: Low, Medium, High, Very High, Badass\n\nAnti-Aliasing: Disabled, Enabled\n\nResolution Scaling\n\nUpscaling Method: Disabled, DLSS, FSR, TSR, XeSS\n\nUpscaling Quality: Ultra Performance, Performance, Balanced, Quality, Full Resolution\n\nSpatial Upscaling Quality: Performance, Balanced, Quality, Ultra Quality, Disabled\n\nScene Capture Quality: Low, High, Full Resolution\n\nFrame Generation: Off, On\n\nNVIDIA Reflex Low Latency: Off, On, Boost Environment: HLOD Loading Range: Near, Medium, Far\n\nGeometry Quality: Low, Medium, High\n\nTexture Quality: Low, Medium, High, Very High\n\nTextures Streaming Speed: Medium, High, Very High\n\nAnisotropic Filtering Quality: Off, x1, x2, x4, x8, x16\n\nFoliage Density: Off, Very Low, Low, Medium, High, Very High\n\nVolumetric Fog: Low, Medium, High, Very High\n\nVolumetric Cloud: Low, Medium, High, Very High\n\nShadow Quality: Low, Medium, High, Very High\n\nDirectional Shadow Quality: Low, Medium, High, Very High\n\nVolumetric Cloud Shadows: Disabled, Enabled\n\nLighting Quality: Low, Medium, High, Very High\n\nReflections Quality: Low, Medium, High, Very High\n\nShading Quality: Low, Medium, High Post-Processing: Post-Process Quality: Low, Medium, High, Very High\n\nMotion Blur Amount\n\nMotion Blur Quality: Off, Low, Medium, High, Very High\n\nBorderlands 4's accessibility features have also been detailed by Gearbox, as listed below:",
      "source": "Eurogamer.net",
      "url": "https://www.eurogamer.net/borderlands-4-pc-hardware-requirements-ask-for-an-rtx-2070-as-a-minimum-but-a-3080-is-recommended",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "3 Solid Stocks to Buy on Steady Growth in Semiconductor Sales",
      "content": "The semiconductor market has seen steady growth this year after an impressive 2024, thanks to the continued optimism surrounding artificial intelligence and demand from a range of industries. Revenues have soared over the past two quarters, and the third quarter has started on a high note.\n\nIn fact, semiconductors have played a key role in the overall tech rally, which has been driving the broader market.\n\nGiven this scenario, it would be ideal to invest in semiconductor stocks, such as Advanced Micro Devices AMD, NVIDIA Corporation NVDA and Advanced Energy Industries, Inc. AEIS. Each of these stocks carries a Zacks Rank #1 (Strong Buy) or 2 (Buy). You can see the complete list of today’s Zacks #1 Rank stocks here.\n\nChip Sales Continue to Soar\n\nGlobal semiconductor sales totaled $62.1 billion in July 2025, jumping a solid 20.6% year over year and 3.6% sequentially from June’s total of $59.9 billion, the Semiconductor Industry Association (SIA) said last week.\n\nSIA also said that regional sales rose at an impressive pace on an annual basis. Year over year, semiconductor sales rose 35.6% in the Asia Pacific/All Other. In the Americas and China, sales rose 29.3% and 19.4%, respectively.\n\nThe impressive July figures come after a robust second quarter, wherein sales totaled $179.7 billion, up 7.8% from the previous quarter.\n\nSemiconductor Sales Poised to Grow\n\nEarlier this year, semiconductor sales slowed unexpectedly after worries emerged about U.S. tech firms losing ground to China’s low-cost AI platform, DeepSeek. However, the concerns were short-lived as experts quickly called DeepSeek overhyped and not a serious challenge to American companies.\n\nSales have mostly been growing at a steady pace this year. After an impressive 2024 — when global semiconductor revenues hit $627.6 billion, up 19.1% from $526.8 billion in 2023 — both the first and second quarters of 2025 have shown solid growth.\n\nMuch of this momentum comes from soaring demand for data center chips and memory products. With AI investments continuing to accelerate, analysts expect the semiconductor market to sustain double-digit growth throughout 2025.\n\n3 Semiconductor Stocks With Upside\n\nAdvanced Micro Devices\n\nAdvanced Micro Devices has strengthened its position in the semiconductor market on the back of its evolution as an enterprise-focused company from a pure-bred consumer-PC chip provider. AMD has emerged as a strong challenger to NVIDIA's dominance in the graphic processing unit or GPU market based on its Radeon chips.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/3-solid-stocks-buy-steady-141300903.html",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "\"Every PC will be an AI PC in four, maximum five years\" — Lenovo lays out a radical vision for computing's future at IFA",
      "content": "IFA 2025, the annual tech convention hosted in Berlin, was a huge event for Lenovo. From a new TrackPoint-less ThinkPad in a Glacier White color scheme to new foldable phones to AR glasses, gaming handhelds, and laptop prototypes, the company showed off a full gamut of new hardware.\n\nLuca Rossi, Lenovo's Executive Vice President and President of Intelligent Devices Group, hosted the IFA keynote speech before sitting down in a roundtable discussion at which I was present.\n\nThe topic? AI and AI PCs, of course.\n\nDespite growing concerns about AI causing an explosive market bubble, the fact that only about 5% of AI pilot projects make it beyond an incubation stage, or that AI is stealing jobs from young professionals at an alarming rate, Lenovo's senior leadership believes AI PCs are primed to completely take over the market.\n\nAll PCs will be AI PCs within five years — here's how that happens\n\nLenovo's new ThinkPad X9 is a big step away from the traditional ThinkPad aesthetic; yes, it's an AI PC. (Image credit: Future)\n\nPutting Lenovo's AI PC progress into perspective, so far in 2025, global AI PC penetration has hit roughly 5%. Lenovo's share of that is about 30%, and Rossi claims that the percentage will likely rise to 50% in a year or a year and a half.\n\nWhat comes after that? \"Every PC will be an AI PC in four, maximum five years\" is Rossi's prediction.\n\nIt's easy to assume that it's the killer AI features and apps that are driving that growth. Unfortunately, those don't yet exist. And if they did exist, Rossi doesn't believe that the vast majority of consumers would actually grasp and seek out AI capabilties.\n\nI think there is a relatively modest percentage of users that fully understand and fully embrace their AI. [...] I will not give you a percentage, but I would say it's not a large majority of users. Luca Rossi, Lenovo\n\nRight now, the AI PC market is largely being driven by hardware.\n\nAI PCs \"are typically very sleek, very nice with 12 hour battery life,\" explains Rossi, \"so they are very compelling, even if you take out the AI element.\" I can't argue with that, and the 2025 ASUS Zenbook A14 — one of the best Windows laptops we've ever tested even without considering the AI aspect — is proof.\n\nThere's also the matter of Windows 10's end-of-life fiasco that is forcing many users to upgrade PCs prematurely. Nevertheless, Rossi believes that AI PC growth will continue after the Windows 11 upgrade wave settles, even if that growth is slower than expert predictions.\n\nPC hardware is ready for AI; now the software must catch up\n\nA look at Microsoft's new Copilot Mode for the Edge browser. (Image credit: Future | Daniel Rubino)\n\nAI PCs only really arrived in 2024, making a big splash as Microsoft announced Copilot+ laptops with AI features unique to Windows 11.\n\nAt launch, only Qualcomm's Snapdragon X Systems-on-Chip (SoC) had a Neural Processing Unit (NPU) powerful enough to run the Copilot+ features. Intel and AMD were quick to catch up, and you can now easily find Copilot+ PCs with all three brands of CPU inside.\n\nRossi aptly brands 2024 as the year that the groundwork for AI hardware was established. 2025 can be seen as the year where that hardware matured, with stronger NPUs more capable of running AI locally without tapping the cloud.\n\nThe near future, says Rossi, is now the software's time to come into its own. He names Microsoft and Adobe as being leaders in this area, but many of Lenovo's Independent Software Vendors (ISVs) are also clamoring to make use of local AI hardware.\n\nThis is the part where the industry is not yet there in terms of software, but based on our understanding and our conversations with ISVs, there are at least 80 to 100 ISVs that are now porting their applications to have the ability to use the NPU in the CPU and get the workload done. Luca Rossi, Lenovo\n\nWhen pressed about one \"must-have\" AI app that becomes the main selling point of an AI PC, Rossi says that's still to come.\n\nRossi's argument is that NPUs are a relatively new innovation that have only been on the market for a couple of years. The software hasn't had time to mature. Rossi compares the AI software situation to that of the early days of phone app stores, when it was hard to find that one app that really made a difference.\n\n👉 Related: Best AI laptops in 2025\n\nCompare that to now, and there are countless hundreds of apps that we all rely on to function in the modern world.\n\nReturning to Copilot+ PCs, despite all of the marketing around Microsoft's initiative, it has failed to capture the attention of the masses. My colleague, Richard Devine, recently expressed his opinion about Copilot+, stating that he still doesn't care about it after a year of availability.\n\nThe future of AI computing is intent-based\n\nLenovo believes the future of AI computing is intent-based. (Image credit: Getty Images)\n\nWhile we're still waiting on the AI app that makes AI PCs a must-have, Rossi explains that he foresees computing moving toward an \"intent-based world.\"\n\nThe operating systems for which Lenovo currently builds hardware, including Windows and Android, aren't going anywhere. At least not yet. But Rossi imagines a form of advanced assistant called \"super agent\" that blends brands and ecosystems, all the while delivering that intent-based future.\n\nThat means the machine or the agent will anticipate your needs and will trigger the application or the task you need autonomously over time. That means there will be a layer, which is the agent or super agent. Luca Rossi, Lenovo\n\nRossi explains that super agents are already a reality in China, where AI seamlessly blends AI across desktops, laptops, wearables, and phones.\n\nWith Lenovo's dual-ecosystem OEM role and its CPU partnerships, Rossi believes Lenovo is in a unique position to pioneer this future of AI computing.\n\nHow will this new approach affect hardware design? It will be a slow progression of change, says Rossi. We'll still have the notebooks we know and love, but voice, gesture, and contextual awareness will begin to take over for keyboards and mice.\n\nRossi believes that wearables, like AR glasses, have the most potential for AI integration. Humans are already used to eyeglasses, they're comfortable to wear, and they could deliver AI directly within our field of view.\n\nOf course, hurdles like compute power, battery life, and lens technology refinement must be taken into consideration.\n\nIt's all gas and no brakes for Lenovo's AI ambitions\n\nIf Lenovo's forecasts are correct, the AI PC market will eventually consume the PC market as we know it today. Super agents will seamlessly blend platforms and devices, and AI software will be too good to not be using.\n\nAre you excited about that future, or are you skeptical of the envisioned AI future? Let me know in the comments section below!",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/lenovo/lenovo-ai-pc-predictions-luca-rossi-ifa-2025",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Spectre haunts CPUs again: VMSCAPE vulnerability leaks cloud secrets",
      "content": "If you thought the world was done with side-channel CPU attacks, think again. ETH Zurich has identified yet another Spectre-based transient execution vulnerability that affects AMD Zen CPUs and Intel Coffee Lake processors by breaking virtualization boundaries.\n\nThe attack, dubbed VMSCAPE (CVE-2025-40300), is said to be the first Spectre-based exploit that allows a malicious guest user in a cloud environment to leak secrets from the hypervisor in the host domain without code changes – injected Return-oriented programming gadgets – and in default configuration.\n\nThe technique is described in a paper [PDF] published on Thursday, \"VMSCAPE: Exposing and Exploiting Incomplete Branch Predictor Isolation in Cloud Environments,\" by Jean-Claude Graf, Sandro Rüegge, Ali Hajiabadi, and Kaveh Razavi. The paper is set to be presented at the 47th IEEE Symposium on Security and Privacy.\n\nCloud computing depends upon virtualization to securely partition physical computing resources into virtual ones, managed by a hypervisor. VMSCAPE targets the Kernel Virtual Machine (KVM) and QEMU (Quick Emulator), as the hypervisor and as the userspace component of the hypervisor in the host.\n\n\"VMSCAPE can leak the memory of the QEMU process at the rate of 32 B/s on AMD Zen 4,\" the authors state in their paper. \"We use VMSCAPE to find the location of secret data and leak the secret data, all within 772 s, extracting the cryptographic key used for disk encryption/decryption as an example.\"\n\nAMD Zen 1-5 processors are affected, as are Intel Coffee Lake processors, which debuted in 2017. Hardware fixes aren't feasible, the authors say, so Linux maintainers have addressed the issue in software. This comes at a cost, however, in terms of performance overhead.\n\nSpectre, a set of vulnerabilities based on processor microarchitecture, has allowed attackers to access sensitive host memory to varying degrees since its disclosure in 2018, alongside another flaw known as Meltdown.\n\nOne of these is known as Spectre v2 or Branch Target Injection, a way to abuse CPU indirect branch predictors, which control speculative execution – executing predicted instructions before they're called for in code, in order to improve performance.\n\nVarious mitigations have been developed and deployed to defend against Spectre-based attacks, generally at the cost of performance. These include: Indirect Branch Restricted Speculation (IBRS), Enhanced IBRS (eIBRS), Automatic IBRS (AutoIBRS), Indirect Branch Prediction Barrier (IBPB), and Single Threaded Indirect Branch Predictor (STIBP).\n\nBut, to date, Spectre v2 attacks have not had much impact because, as the authors note, they assume the attacker has the ability to run local code on the user's system.\n\nThe ETH Zurich boffins took a look at the way AMD and Intel processors handle host-guest boundaries and found the separation isn't sufficient on AMD Zen CPUs and older Intel CPUs. The branch target buffer (BTB) entries between host and guest are not isolated, so the branch predictor mingles predictions across host and guest domains. VMSCAPE exploits this with the help of a set of new attack primitives that the researchers call vBTI (virtualization Branch Target Injection).\n\nAn AMD spokesperson told The Register that a Security Brief will be issued that acknowledges the potential vulnerability. But the fix will be in software.\n\nIn a statement provided to The Register, an Intel spokesperson said, \"Existing mitigations on Intel processors can be used to mitigate this issue. Intel has previously provided guidance for Branch Target Injection (BTI), Branch History Injection (BHI), and Indirect Target Selection (ITS), and Intel engineers are working with Linux to ensure that the appropriate mitigations for these issues as described in these guidance documents are applied to Linux userspace hypervisor software. Linux mitigations are expected to be available on the VMSCAPE public disclosure date, and a CVE for this issue will be assigned by Linux.\"\n\nThe Linux patch, we're told, will be ported to various Linux distributions after its release.\n\nThe authors proposed a mitigation called \"IBPB-on-VMExit\" that Linux developers have optimized under the name \"IBPB before exit to userspace.\" According to the researchers, the overhead depends on the workload and the frequency of userspace exits.\n\n\"For emulated devices (default for QEMU), userspace exits are much more frequent than for virtualized devices (commonly used in enterprise systems),\" the authors observe in a summary note. \"Our benchmarking indicates an overhead of ~10 percent when using an emulated device.\"\n\nWith Zen 4, the authors' benchmark testing suggests \"a marginal 1 percent overhead\" post-patch.\n\nThe Linux mitigation is said to be active for all affected systems, including Zen 5 and even recent Intel CPUs that were not exploitable such as Lunar Lake and Granite Rapids. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/11/vmscape_spectre_vulnerability/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "'No asterisk generation' : AMD promises its MI450 AI GPU will be faster than ANYTHING Nvidia has, yes, that includes even Rubin Ultra",
      "content": "AMD positions MI450 as its no asterisk generation aimed at AI leadership\n\nCompany compares future GPU launch to 2021 Milan CPUs breaking Intel’s dominance\n\nNvidia remains overwhelmingly ahead with Rubin set to challenge MI450 in 2026\n\nAMD has made a startlingly confident claim regarding its upcoming Instinct MI450 GPUs.\n\nSpeaking at a recent investor conference, data center chief Forrest Norrod declared the firm’s new chips will outperform any rival hardware, including Nvidia’s Rubin Ultra.\n\nHe described the product as the company’s “no asterisk generation,” aimed at delivering leadership in both AI training and inference.\n\nMilan moment\n\nNorrod compared the launch to AMD’s 2021 “Milan moment,” when its EPYC server CPUs helped the company break Intel’s dominance in the server market.\n\n“MI450 is perhaps akin to our Milan moment for people that are familiar with our EPYC roadmap,” he said. “It will be, we believe, and we are planning for it to be the best training, inference, distributed inference, reinforcement learning solution available on the market.”\n\nThe MI450 will follow the current MI355, which is intended to strengthen training capabilities after earlier models were primarily optimized for inference.\n\nAMD says that the new generation has been designed with both silicon and software improvements in mind, alongside full system-level support.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nNorrod stressed that the hardware and software roadmap had been carefully staged to deliver competitiveness at every step.\n\nAt present, Nvidia utterly dominates the AI accelerator market, with estimates placing its share between 70 and 95 percent.\n\nAMD’s most advanced GPU today, the MI355X, still lags behind Nvidia’s Blackwell Ultra, although it shows clear progress over its predecessor.\n\nThe MI450 is expected to launch in 2026, arriving as Nvidia readies Rubin, which is forecast to deliver up to triple the performance of Blackwell Ultra. That will set up a direct test of AMD’s claims.\n\nAlthough the chip giant is describing the future launch as a turning point, history suggests customer adoption will depend not just on raw speed but also on software ecosystem maturity and data center integration.\n\nThis is something AMD is preparing for, as it has already said that the MI450 will ship with rack-level solutions designed for compatibility with existing infrastructure.\n\nAcknowledging Nvidia's current dominance, Norrod said, \"Nvidia is a fantastic company. They’ve done a fantastic job, and they were well ahead. We had to catch up.\"\n\nHe added, \"We decided, with this multigenerational roadmap, to put the objective in place of, okay, when we get to 450, we’re going to be there the same time as when Vera Rubin was intended to be there, and we’re going to be there with that part that’s fully performant, the software stack that’s fully there, at least for the 80% of the market that’s constituted by the top 20% or so customers. We’ve focused on getting there in the 450 so that for training, there’s no excuses, and there’s no impediment, there’s no hesitation of, hey, if I’m training, I’ll be behind in this generation if I go with AMD. That’s been the learning for us, and that’s been the realization.\"",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/no-asterisk-generation-amd-promises-its-mi450-ai-gpu-will-be-faster-than-anything-nvidia-has-yes-that-includes-even-rubin-ultra",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Nvidia's RTX 5000 Super GPUs might not arrive until CES 2026 – and that could be great news for AMD",
      "content": "Nvidia's rumored RTX 5000 Super GPU launch is reportedly delayed\n\nCES 2026 now seems the more likely time for a reveal\n\nAMD could capitalize on this if it can push out the rumored RX 9080 XT GPU\n\nNvidia's RTX 5000 series GPU line-up is set to receive a major update with rumored Super models, and it was thought that these could be close on the horizon - but apparently that isn't the case.\n\nAccording to a reputable hardware leaker, Hongxing2020 on X, Nvidia's RTX 5000 Super refreshes have been delayed. Although technically, they've not even been confirmed yet, so talk of a 'delay' presumably refers to rescheduling of launch timeframes by Nvidia.\n\nRumors have been floating around that the Super refreshes could launch in Q4 of this year, but as VideoCardz reports, according to graphics card makers, the expectation is for a CES 2026 reveal from Nvidia.\n\nIndeed, it seems a more realistic prospect that Nvidia might want to wait for a big event to showcase new RTX 5000 Super graphics cards, rather than pushing them out at the end of 2025.\n\nIt's also worth noting that recent speculation from multiple sources has implied that prices for these Super GPU models could turn out relatively reasonable, and that these boards will feature more VRAM. The RTX 5080 Super could get a boost to 24GB of VRAM over the current model's 16GB, and the RTX 5070 Ti Super may also run with 24GB.\n\n(Image credit: Future)\n\nAnalysis: AMD has a chance to capitalize here\n\nIf we take this rumor at face value, and Nvidia has indeed pushed back its launch plans here, this gives AMD more breathing room for a potential launch of its rumored Radeon RX 9080 XT. That is purportedly set to be a high-end GPU that could rival the RTX 5080.\n\nOn top of that, Intel has another rumored more powerful GPU - the Arc B770 - in the pipeline, with the packaging for that Battlemage graphics card seemingly in the works (as also reported by VideoCardz).\n\nGet daily insight, inspiration and deals in your inbox Sign up for breaking news, reviews, opinion, top tech deals, and more. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAll of these remain rumors, of course, as does Nvidia's Super refresh itself. But if AMD does have an RX 9080 XT GPU in the works, and Nvidia is now focused on launching its RTX 5000 Super series in Q1 2026, I'd love for Team Red to act between now and the end of 2025 with a reveal of a more powerful current-gen graphics card. Ideally, AMD shouldn't wait around if it has a chance to overshadow its rival here.\n\nHowever, a CES 2026 reveal for the rumored RX 9080 XT seems more likely. It's an ideal stage to reveal a new high-end GPU, after all, and CEO Lisa Su is confirmed as giving AMD's keynote.\n\nWe can talk about launch timing all we want, but the real key to the success of these purported GPUs will be pricing. We can hope that competition between these rumored launches could help keep price tags relatively competitive - but GPU inflation and real world pressures may present a different story.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/computing/gpu/nvidias-rtx-5000-super-gpus-might-not-arrive-until-ces-2026-and-thatd-be-great-news-for-amd",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "I finally tried OpenAI's 120 billion parameter open-source LLM — and without needing thousands of dollars worth of hardware",
      "content": "I'll admit that until an email dropped into my inbox, I wasn't even aware DuckDuckGo had an AI chatbot akin to ChatGPT on the go. But now I do, and per said email, it's now able to run OpenAI's gpt-oss:120b LLM.\n\nTraditionally an open source model such as this is one you would run locally through a tool such as Ollama or LMStudio, but thanks to DuckDuckGo anyone can use it, use it privately, and for free.\n\nWhy does this matter? If you were to download gpt-oss:120b in all of its 120 billion parameter glory to use at its best in Ollama, you would need more VRAM than you would get from a pair of RTX 5090s.\n\nIt's 65GB in size, so unless you have some monstrous GPU power in your rack, or something like an AMD Strix Halo-powered PC with all that lovely unified memory, it's pretty tough to run on consumer hardware.\n\nEspecially tough to run well.\n\nFast, free, private access to a sizable open-source LLM. (Image credit: Windows Central)\n\nWhat Duck.ai is providing is free access to this model, but using their servers, not your own machine. As it's provided by DuckDuckGo, a company well known for its commitment to privacy, it's probably as trustworthy as you'll get from an online tool of this kind.\n\nDuckDuckGo even flat out states that all chats are anonymized, and like other free-to-use models, you don't have to have an account. No sign-ups, no email address, just open the web page and start prompting your behind off.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nSo, how is it? It's fast. As if it wouldn't be when it's being powered by some massive cluster of hardware somewhere that isn't your home. In my limited time playing with it so far, it seems at least as quick at generating responses as the 20b model does on my RTX 5090 — Duck.ai doesn't show the tokens per second figure — but with one difference I'm not sure how I feel about yet.\n\nUsing gpt-oss:120b in Duck.ai, you don't see the content of the thinking that's done, it just throws out the response. The more I've been using gpt-oss on my own machine, the more I've started to appreciate being able to see this information.\n\nUsing thinking models such as gpt-oss locally with Ollama, you can see the thought process that delivers your response. Duck.ai doesn't have this. (Image credit: Windows Central)\n\nMaybe it's just me, but it's always interesting, and sometimes enlightening, seeing how the model created the output that it serves. In some cases this is how I've learned where mistakes have been made, and I feel like it's valuable information. I'd love it if Duck.ai even offered it as an option in settings to either show it or not.\n\nYou also can't upload your own files to use with the model. Some of the other options have image upload support, but as far as I can tell, none allow you to upload other files such as documents or examples of code. This is perhaps part of the privacy angle, but it does add a limitation to how you may want to use it.\n\nIt's generally really good, though, and since it's built inside a web app that feels a lot like ChatGPT or Google Gemini, it's welcoming and easy to use. It saves your recent chats in the sidebar, and the settings on hand to tweak how you want your responses are pretty thorough. These all apply, of course, to any of the models you use on Duck.ai, not just gpt-oss:120b.\n\nI might have found a new gem in my own AI arsenal here, but to decide on that, I'll have to play with it some more. For now, I'm just happy I can try gpt-oss:120b without having to have a GPU farm. Or an NVIDIA Blackwell Pro.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/artificial-intelligence/i-finally-tried-openais-120-billion-parameter-open-source-llm-and-without-needing-thousands-of-dollars-worth-of-hardware",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Slimbook Evo Linux laptops now available with AMD Ryzen AI 9 365 Strix Point",
      "content": "The Slimbook Evo 14 and Slimbook 15 Evo are thin and light laptops with high-resolution, 120 Hz displays, and support for up to 128GB of RAM and 16TB of storage. Slimbook recently announced updated models powered by Ryzen AI 9 365 Strix Point processors, and they’re now available for €1077 ($1265) and up.\n\nWhat makes these laptops a little different from most is that those starting prices include free installation of your choice of GNU/Linux distro. Options include Ubuntu, Debian, Fedora, Manjaro, and others. You can also have Windows installed, but you’ll have to pay a little more for a license.\n\nSlimbook also offers plenty of configuration options. Each model has two SODIMM slots for DDR5-5600 memory and two M.2 2280 slots for PCIe 4.0 NVMe SSDs.\n\nThe base price will get you a laptop with 16GB of RAM (two 8GB SODIMMS) and a single 500GB SSD plus a WiFi 6 card. But you can pay extra for systems with up to 128GB of total RAM and 8TB of total storage. There’s also a WiFi 7 card available for purchase, but Slimbook notes that it “currently” works as a WiFi card when running Linux, so you may need to wait for a driver update or install Windows to get the most use out of that upgrade.\n\nEach version of the laptop has AMD’s Ryzen AI 9 365 processor, which features a 10-core, 20-thread CPU, Radeon 880M 12-core integrated graphics, and a 50 TOPS Ryzen AI NPU.\n\nThe Slimbook Evo 14 has a 14 inch, 2880 x 1800 pixel IPS LCD display with a 120 Hz refresh rate and up to 500 nits brightness, an 80 Wh battery, and an aluminum body that measures 16.9mm (0.67 inches) thick and weighs 1.4kg (3.1 pounds).\n\nSlimbook’s Evo 15, meanwhile, has a 15.3 inch, 2560 x 1600 pixel, 120 Hz IPS LCD display that tops out at 400 nits brightness. The larger model also has a larger 99 Wh battery. This model also has a numeric keypad on the right side of the keyboard, but at 18.1mm (0.71 inches) thick and 1.6 kg (3.5 pounds), the Slimbook Evo 15 is a little thicker and heavier than its 14 inch sibling.\n\nBoth laptops feature dual fans for active cooling, and both feature 1080p webcams with IR cameras, dual microphones, stereo speakers, and white LED backlit keyboards. Ports include:\n\n1 x USB4 (40 Gbps w/DP 1.4 and 100W USB-PD)\n\n1 x USB 3.2 Gen 2 Type-C (10 Gbps w/DP 1.4 and 100W USB-PD)\n\n2 x USB 3.2 Gen 1 Type-A (5 Gbps)\n\n1 x USB 2.0 Type-A (480 Mbps)\n\n1 x SDXC card reader (SD 7.0, up to 985MB/s)\n\n1 x HDMI 2.1\n\n1 x Gigabit Ethernet\n\n1 x 3.5mm audio\n\nvia 9to5Google\n\nSupport Liliputing Liliputing's primary sources of revenue are advertising and affiliate links (if you click the \"Shop\" button at the top of the page and buy something on Amazon, for example, we'll get a small commission). But there are several ways you can support the site directly even if you're using an ad blocker* and hate online shopping. Contribute to our Patreon campaign or... Contribute via PayPal * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a guide that may help you disable it.",
      "source": "Liliputing",
      "url": "https://liliputing.com/slimbook-evo-linux-laptops-now-available-with-amd-ryzen-ai-9-365-strix-point/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Apple downgraded, Nvidia upgraded: Wall Street's top analyst calls",
      "content": "The most talked about and market moving research calls around Wall Street are now in one place. Here are today's research calls that investors need to know, as compiled by The Fly.\n\n\n\nTop 5 Upgrades:\n\n\n\nDA Davidson upgraded Nvidia (NVDA) to Buy from Neutral with a price target of $210, up from $195, citing the belief the growth in AI compute demand will drive enough demand to sustain growth into next year and likely beyond.\n\nDeutsche Bank upgraded Chewy (CHWY) to Buy from Hold with a price target of $45, up from $38, post the fiscal Q2 report. The company's growth investments in the second half of 2025 will drive earnings estimate cuts, but buy-side expectations are \"now in a better place,\" the firm tells investors in a research note. Seaport Research also upgraded Chewy to Buy from Neutral with a $47 price target.\n\nBarclays upgraded Thermo Fisher (TMO) to Overweight from Equal Weight with a price target of $550, up from $490. The company's valuation, both on an absolute and relative basis, is now at attractive levels, the firm tells investors in a research note.\n\nWolfe Research upgraded Bill (BILL) to Outperform from Peer Perform with a $70 price target. The shares are down 37% year-to-date and the company faces better prospects into fiscal 2026, the firm tells investors in a research note.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/apple-downgraded-nvidia-upgraded-wall-134736182.html",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "This ultra slim mini PC is essentially a Core i9 laptop with an RTX 5070 laptop GPU, but sans a battery, keyboard, and screen",
      "content": "Minisforum G7 Pro delivers laptop-level performance in a compact Mini PC chassis\n\nNVIDIA RTX 5070 Laptop GPU powers desktop-class graphics in a small device\n\nDual-channel DDR5 RAM and two M.2 PCIe 4.0 slots support heavy workloads\n\nAt IFA 2025, Minisforum unveiled a series of mini PCs, including the G7 Pro, which uses an Intel Raptor Lake-HX CPU and condenses high-end business laptop performance into a compact device.\n\nThe G7 Pro is a small-form-factor (SFF) gaming mini PC featuring an Intel Core i9-14900HX processor with 24 cores and 32 threads, reaching up to 5.8GHz.\n\nIts graphics are powered by an Nvidia GeForce RTX 5070 Laptop GPU, providing desktop-class performance.\n\nPowerful memory, fast storage, and versatile connectivity\n\nThis mini PC supports up to 96GB of dual-channel DDR5 RAM and offers storage via two M.2 PCIe 4.0 SSD slots.\n\nConnectivity options include HDMI 2.1, USB4, multiple USB-A and USB-C ports, RJ45 Ethernet, Wi-Fi 7, Bluetooth 5.4, and an SD card reader.\n\nThe chassis features an ultra-slim design with a mode toggle button for flexible operation.\n\nThis makes it suitable for workspaces with limited room, while still delivering desktop-level performance.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe absence of a built-in display or keyboard allows users to select peripherals that fit their needs.\n\nTechnically, this device is a laptop stripped of its battery, display, and keyboard.\n\nYet, it still delivers full Core i9 performance, making it both a portable option and a capable workstation for professional or gaming applications.\n\nThe absence of a battery means that this device is powered directly via an AC power connection using an external power adapter, similar to a desktop PC.\n\nHowever, this can be highly inconvenient for people without a stable power supply.\n\nThe price information for the G7 Pro remains unknown at the time of writing.\n\nThis will be important in determining whether users can afford to purchase it along with a separate keyboard and monitor, otherwise, a laptop might be a more convenient option.\n\nIn addition to the G7 Pro, Minisforum also presented three additional systems at IFA 2025.\n\nThe G1 Pro, powered by Ryzen 9 8945HX and an RTX 5060 desktop GPU, targets gamers who prefer a console-style mini PC.\n\nThe MS-S1 MAX is positioned as an AI workstation supporting up to 128GB of LPDDR5X memory and USB4 v2.\n\nThe NS Pro focuses on NAS use cases, with AMD Strix Point processors and high-speed storage connectivity.\n\nVia Videocardz",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/this-ultra-slim-mini-pc-is-essentially-a-core-i9-laptop-with-an-rtx-5070-laptop-gpu-but-sans-a-battery-keyboard-and-screen",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Top China silicon figure calls on country to stop using Nvidia GPUs for AI — says current AI development model could become 'lethal' if not addressed",
      "content": "Wei Shaojun, vice president of China Semiconductor Industry Association, and a senior Chinese academic and government adviser, has called on China and other Asian countries to ditch using Nvidia GPUs for AI training and inference. At a forum in Singapore, he warned that reliance on U.S.-origin hardware poses long-term risks for China and its regional peers, reports Bloomberg.\n\nWei criticized the current AI development model across Asia, which closely mirrors the American path of using compute GPUs from Nvidia or AMD for training large language models such as ChatGPT and DeepSeek. He argued that this imitation limits regional autonomy and could become 'lethal' if not addressed. According to Wei, Asia's strategy must diverge from the U.S. template, particularly in foundational areas like algorithm design and computing infrastructure.\n\nAfter the U.S. government imposed restrictions on the performance of AI and HPC processors that could be shipped to China in 2023, it created significant hardware bottlenecks in the People's Republic, which slowed down the training of leading-edge AI models. Despite these challenges, Wei pointed to examples such as the rise of DeepSeek as evidence that Chinese companies are capable of making significant algorithmic advances even without cutting-edge hardware.\n\nHe also noted Beijing's stance against using Nvidia's H20 chip as a sign of the country’s push for true independence in AI infrastructure. At the same time, he acknowledged that while China's semiconductor industry has made progress, it is still years behind America and Taiwan, so the chances that China-based companies will be able to build AI accelerators that offer performance comparable to that of Nvidia's high-end offerings are thin.\n\nWei proposed that China should develop a new class of processors tailored specifically for large language model training, rather than continuing to rely on GPU architectures, as they were originally aimed at graphics processing. While he did not outline a concrete design, his remarks are a call for domestic innovation at the silicon level to support China’s AI ambitions. However, he did not point out how China plans to catch up with Taiwan and the U.S. in the semiconductor production race.\n\nHe concluded on a confident note, stating that China remains well-funded and determined to continue building its semiconductor ecosystem despite years of export controls and political pressure from the U.S. The overall message was clear: China must stop following and start leading by developing unique solutions suited to its own technological and strategic needs.\n\nNvidia GPUs became dominant in AI because their massively parallel architecture was ideal for accelerating matrix-heavy operations in deep learning, offering far greater efficiency than CPUs. Also, the CUDA software stack introduced in 2006 enabled developers to write general-purpose code for GPUs, paving the way for deep learning frameworks like TensorFlow and PyTorch to standardize on Nvidia hardware.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nOver time, Nvidia reinforced its lead with specialized hardware (Tensor Cores, mixed-precision formats), tight software integration, and widespread cloud and OEM support, making its GPUs the default compute backbone for AI training and inference. Nvidia's modern architectures like Blackwell for data centers have plenty of optimizations for AI training and inference and have almost nothing to do with graphics. By contrast, special-purpose ASICs — which are advocated by Wei Shaojun — are yet to gain traction for either training or inference.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/artificial-intelligence/top-china-silicon-figure-calls-on-country-to-stop-using-nvidia-gpus-for-ai-says-current-ai-development-model-could-become-lethal-if-not-addressed",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Cramer Flags Oracle Rally As 'Strange,' Says Nvidia And AMD Aren't Getting Any Love",
      "content": "Benzinga and Yahoo Finance LLC may earn commission or revenue on some items through the links below.\n\nOracle Corp. (NYSE:ORCL) may be one of Wall Street's hottest AI bets, but CNBC's Jim Cramer says something isn't adding up. Despite Oracle's stock strength, chipmakers that would logically benefit from the company's data center growth, like Nvidia Corp. (NASDAQ:NVDA) and Advanced Micro Devices Inc. (NASDAQ:AMD), are barely moving.\n\n\"It's almost as if nobody believes anyone benefits besides Oracle,\" Cramer wrote on X, calling the divergence \"all very strange,\" he posted on X.\n\nOracle's AI Momentum Hits An Odd Speed Bump\n\nOracle has emerged as a surprise winner in the AI race, with investors betting on its cloud infrastructure to challenge leaders like Amazon.com Inc‘s (NASDAQ:AMZN) Amazon Web Services and Microsoft Corp‘s (NASDAQ:MSFT) Azure.\n\nTrending: The same firms that backed Uber, Venmo and eBay are investing in this pre-IPO company disrupting a $1.8T market — and you can too at just $2.90/share.\n\nORCL stock is up over 100% YTD, and was trading higher by over 40% at the time of publication on Wednesday, despite the company reporting a miss as it reported second quarter earnings on Tuesday. The company's recent surge reflects optimism about partnerships and AI-driven workloads that could expand its market share.\n\nTypically, such optimism would also fuel gains for semiconductor giants, as AI adoption drives demand for GPUs and chips to power data centers.\n\nChipmakers Sit Out The Rally\n\nYet Nvidia, the market's AI bellwether, and AMD, a rising competitor, are showing little movement alongside Oracle's momentum. This divergence may reflect skepticism that Oracle's growth translates into meaningful chip orders, especially given supply constraints and existing backlogs at Nvidia.\n\nSemiconductor valuations are also near record highs after a multi-quarter AI-fueled rally, leaving little room for sympathy trades without fresh catalysts.\n\nSee Also: If there was a new fund backed by Jeff Bezos offering a 7-9% target yield with monthly dividends would you invest in it?\n\nInvestor Caution Creeps In\n\nCramer's comment highlights a broader caution creeping into AI-related trades. Investors appear selective, rewarding Oracle for its narrative but reluctant to extend enthusiasm across the supply chain. Whether this signals overbought conditions in chip stocks or doubts about Oracle's ability to sustain its momentum, the divergence is a rare crack in the AI trade's usual correlations.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/cramer-flags-oracle-rally-strange-033102051.html",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "AMD Ryzen(TM) プロセッサー、GeForce RTX(TM) 5000シリーズ搭載Acer Nitroから量販店モデル4機種を一挙登場！",
      "content": "日本エイサー株式会社（本社：東京都新宿区、代表取締役社長：ボブ・セン）は、カジュアルゲーマーからコアゲーマーまで幅広いユーザーに向けたゲーミングブランド Nitro（ニトロ） より、16インチゲーミングノートPC 新製品 「Nitro 16S AI」 の2機種「AN16S-61-A76Z57T/E」「AN16S-61-N76Z56/E」と、「Nitro V 16S AI」 の2機種「ANV16S-41-A76Y56/E」「 ANV16S-41-A76Y55/E」の計4機種を、本日9月11日よりヨドバシカメラ、ビックカメラグループ、またその他量販店ECサイトにて順次発売いたします。\n\n「AN16S-61-A76Z57T/E」「AN16S-61-N76Z56/E」は、4機種の中でも上位モデルに位置づけられます。「ANV16S-41-A76Y56/E」「 ANV16S-41-A76Y55/E」との主な違いは、以下の4点です。\n\nCPU： AMD Ryzen™ AI 7 350 プロセッサーを採用 メモリ：32GBを搭載 ストレージ：1TB SSDを搭載 液晶パネル：NVIDIA® G-SYNC® に対応した WQXGA（2560×1600）解像度パネル を搭載\n\nNitro 16S AI（AN16S-61-A76Z57T/E、AN16S-61-N76Z56/E）\n\nいずれもAMD Ryzen™ AI 7 350 プロセッサー を搭載し、32GBメモリー と 大容量1TB（1024GB）SSD を標準装備。4K HDRストリーミング、ゲーミング、クリエイティブワークなど幅広い用途で高いパフォーマンスを発揮します。また高効率なマルチコア構成と AMD同時マルチスレッディングテクノロジー により、ゲームプレイ時の処理やマルチタスク時でもスムーズな操作を実現します。\n\nさらに、最大 50TOPS の処理能力を誇る AMD Ryzen AI NPU が、背景ぼかしや音声ノイズ除去などの機能を強化。Copilot+ PC による、プロンプトからのコンテンツ生成といったAI体験が、創造性と生産性を飛躍的に高めます。また電力効率の最適化により、長時間の使用でも発熱や騒音を抑制し、バッテリー駆動も効率化。ゲーミングPCとしての高性能と日常使いの柔軟性を兼ね備えた次世代AI PC です。\n\nNitro V 16S AI（ANV16S-41-A76Y56/E、ANV16S-41-A76Y55/E）\n\nAMD Ryzen™ 7 260 プロセッサー、16GBメモリー、512GB SSD を搭載。ゲーム、配信、クリエイティブワークなど、幅広い用途で安定したパフォーマンスを発揮します。高効率なマルチコア構成と AMD同時マルチ・スレッディング・テクノロジー により、ゲームプレイに必要な処理速度と、同時アプリ利用時の軽快な操作感を両立。複数のアプリ利用でもゲームがスムーズに動作し、画面切り替えや並行作業も軽快に行えます。\n\nさらに、AMD Ryzen AI（最大16 TOPS NPU） により、背景ぼかしや音声ノイズ除去などのAIサポート機能を強化。ゲーム配信やオンライン通話をより快適にし、新しいAIアプリケーションにも対応します。電力効率にも優れ、長時間の使用でも発熱や騒音を抑えた安定動作を実現。ゲーミングPCとしての性能と、日常使いの柔軟性を兼ね備えたバランスの取れた一台です。\n\n最新 GPU による圧倒的グラフィックス性能\n\n最上位機種「AN16S-61-A76Z57T/E」には NVIDIA® GeForce RTX™ 5070 Ti Laptop GPU を搭載。「AN16S-61-N76Z56/E」「ANV16S-41-A76Y56/E」には GeForce RTX™ 5060 Laptop GPU を、「AN16S-61-N76Z56/E」には GeForce RTX™ 5050 Laptop GPU をそれぞれ採用しています。また最新の NVIDIA Blackwell アーキテクチャと RTX Tensor コアにより、Nitro シリーズは表現力をさらに進化。消費電力を抑えつつ、前世代の RTX 40 シリーズから着実に性能を向上しています。さらに、AI 処理・生成 AI・映像制作など 150 以上の最適化アプリケーションに対応し、プロフェッショナルからクリエイターまで幅広いユーザーのワークフローを快適にサポート。DLSS 4 とリアルタイム Ray Tracing によるニューラルレンダリング技術が、圧倒的な美しさとスピードを両立した次世代の映像体験を提供します。\n\n目に優しく色彩と没入かんを極めたゲーミングディスプレイ\n\n「AN16S-61-A76Z57T/E」「AN16S-61-N76Z56/E」にはNVIDIA® G-SYNC® 対応の16インチ WQXGA（2560×1600）を、「ANV16S-41-A76Y56/E」「 ANV16S-41-A76Y55/E」には16インチWUXGA（1920×1200）を搭載し、いずれも解像度16:10 アスペクト比の IPS パネルを採用しています。\n\nノングレア（非光沢）仕様により、長時間のプレイでも目に優しく、外光の映り込みを抑えてクリアな視認性を確保。さらに、180Hz の高リフレッシュレートがティアリングやカクつきを防ぎ、素早いモーションも滑らかに描き出します。瞬時の操作を正確に反映することがｆ、FPSやアクションゲームにおける優位性を発揮することができるのです。\n\n加えて、sRGB 100% の広色域により深みのある色彩表現を実現。暗所での敵の動きや質感までも鮮やかに映し出し、集中力を高めながら、かつてない臨場感あふれるゲーム体験を提供します。\n\n長時間プレイでも安心の冷却性能\n\n高負荷なゲームプレイでもパフォーマンスを損なわない冷却性能を備えています。最新のサーマル設計により、デュアルファンとクアッド吸排気システムが冷却性能を飛躍的に向上。上部のキーボード面とボタンカバーの両方から取り込んだ冷気を、2つのファンが連動して強力に循環させ、システムの両側面と背面に配置された通気口から効率的に熱を排出します。この高性能な冷却構造が、CPUとGPUの性能を最大限に引き出し、長時間のプレイでも熱によるパフォーマンス低下を抑制。安定性と冷却効率を兼ね備え、ゲームが白熱してもPCは常にクールに保たれます。磨き抜かれた熱設計が、限界を超えるゲーミング体験を支えます。\n\nさらに、「AN16S-61-A76Z57T/E」「AN16S-61-N76Z56/E」には、液体金属熱グリスを採用。従来の熱グリスと比べ熱容量が14.5%※向上し、熱の蓄積を抑えます。\n\n※同じ条件下で液体金属熱グリスと従来の熱グリスを比較した Acer 社内テストに基づく性能向上。実際の性能は、システム、使用方法、環境によって異なる場合があります。\n\n美しさと堅牢性を兼ね備えたデザイン\n\n厚さ約19.9mm※のスリムなボディに、スタイルとパフォーマンスを凝縮。メタルケースに収められた洗練されたデザインは、モダンな美しさと堅牢さを兼ね備え、エレガンスとパワーを完璧に融合します。印象的なRGBライティングロゴや4ゾーンRGBライティング対応キーボードは、鮮やかな発光パターンをカスタマイズ可能。直感的な操作でゲームの没入感を高め、ワークスペースにも個性を演出します。\n\n※GeForce RTX™ 5070 Tiを搭載した最上位機種「AN16S-61-A93Z57T/E」のみ厚さ約21mmとなります。\n\n立体音響と AI 機能で進化する音と映像\n\nDTS:X® Ultraによる立体音響が、敵の気配を捉え、ゲームの世界を隅々までリアルに再現。足音、銃声、環境音が空間的に広がり、瞬時の判断力を研ぎ澄ませます。さらに、Acer PurifiedVoice™ のAIノイズリダクション機能が、プレイヤーの声をクリアに届け、仲間からの声も鮮明に表現。戦術的なコミュニケーションを妨げません。WebカメラにはAcer PurifiedView™ を搭載。背景ぼかしや視線補正、自動フレーミングなどのAI機能で、ビデオ通話や配信でも自然で鮮明な印象を実現します。音と映像の両面から支えるスマートなテクノロジーです。\n\nAI 機能を一元管理できる NitroSense\n\nNitroSense™ は、ゲーミングPCのパフォーマンスを直感的にコントロールできる専用アプリケーションです。独立した NitroSense キーを押すだけで起動し、システム温度、電力設定、使用状況をリアルタイムで監視可能。さらに、4つの動作モード（静音・バランス・パフォーマンス・エコ）を切り替えることで、使用シーンに応じた最適な冷却・静音・省電力環境を実現します。また、Experience Zone では AI 関連機能をひとつに集約。ゲームプレイから日常作業まで役立つスマートな機能に簡単にアクセスできます。Acer PurifiedVoice™ による AI ノイズリダクションや、PurifiedView™ の自動映像補正もここから一括管理可能。快適で効率的なユーザー体験を提供します。\n\nさらに、Wi-Fi 6EとBluetooth 5.2により、安定性と応答性に優れたワイヤレス接続を実現。ラグの少ないオンライン対戦やスムーズなストリーミング体験を可能にします。USB4®ポート（Type-C、最大40Gbps、映像出力対応）は、高速データ転送と高解像度映像出力を両立し、外部モニターやストレージ接続もスピーディに完了。作業もゲームも思いのままに加速します。\n\nインターフェース\n\n各モデルには、用途に応じた豊富なインターフェースを搭載しています。\n\nNitro 16S AI（AN16S-61-A76Z57T/E、AN16S-61-N76Z56/E）\n\nUSB4 ポート×1（Type-C、最大40Gbps、映像出力対応）（リア）、USB 3.2ポート×1（Type-C、Gen 2、最大10Gbps、映像出力対応）（リア）、USB 2.0ポート×1（レフト）、USB 3.2ポート×2（Type-A、Gen 2、最大10Gbps、うち1ポートは電源オフUSB充電機能付き）、ヘッドセット/スピーカー・ジャック×1、HDMI出力ポート×1、DCジャック×1\n\nNitro V 16S AIシリーズ（ANV16S-41-A76Y56/E、 ANV16S-41-A76Y55/E）\n\nUSB4 ポート×1（Type-C、最大40Gbps、映像出力対応）（リア）、USB 3.2ポート×1（Type-A、Gen 1、最大5Gbps）、USB 3.2ポート×2（Type-A、Gen 2、最大10Gbps、うち1ポートは電源オフUSB充電機能付き）、ヘッドセット/スピーカー・ジャック×1、HDMI出力ポート×1、DCジャック×1\n\n製品公式ページ 「Nitro 16S AI」:\n\nhttps://www.acer.com/jp-ja/laptops/nitro/nitro-16s-ai-amd\n\n製品公式ページ 「Nitro V 16S AI」:\n\nhttps://www.acer.com/jp-ja/laptops/nitro/nitro-v-16s-ai-amd\n\nプレスリリースページ\n\nhttps://www.acer.com/jp-ja/about/news/20250911\n\nAcerについて\n\nAcer は世界160か国以上で事業を展開するグローバルICTカンパニーです。1976年の創業以来、人々の生活を豊かにするパソコン、モニター、プロジェクター、タブレットなどのハードウェアやソフトウェア、サービスを提供しています。Acerは現在、全世界約7,500人の従業員とともに、“Breaking barriers between people and technology（人とテクノロジーの垣根を壊す）”のミッションのもと、製品の研究、デザイン、マーケティングおよび販売とサポートを行っています。\n\n日本エイサー株式会社について\n\n社名 ：日本エイサー株式会社\n\n所在地：東京都新宿区西新宿6-24-1 西新宿三井ビルディング 18F\n\n代表者：代表取締役社長 詹 國良（ボブ・セン）\n\n公式サイト： https://www.acer.com/\n\n公式facebook： https://www.facebook.com/AcerJapan\n\n公式X ： https://www.twitter.com/AcerJapan\n\nGaming公式X: https://twitter.com/PredatorJPN\n\n公式Instagram： https://www.instagram.com/acer_japan/\n\nGaming公式Instagram： https://www.instagram.com/predatorgamingjapan/\n\n公式YouTube： https://www.youtube.com/user/AcerJapanChannel\n\n© 2024 Acer Inc. All rights reserved. AcerとAcerロゴはAcer Inc.の登録商標です。その他商標、登録商標、サービスマーク等の著作物の著作権は、帰属表明の有無に関わらず、それぞれの権利者に帰属します。発表内容は予告なしに変更または削除されることがありますのであらかじめご了承ください。\n\n© 2024 Acer Inc. All rights reserved. Acer and the Acer logo are registered trademarks of Acer Inc. Other trademarks, registered trademarks, and/or service marks, indicated or otherwise, are the property of their respective owners. All offers subject to change without notice or obligation and may not be available through all sales channels.",
      "source": "Prtimes.jp",
      "url": "https://prtimes.jp/main/html/rd/p/000001031.000000640.html",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Borderlands 4 Dev Gearbox Asks PC Gamers to Keep Playing for at Least 15 Minutes After They Tweak Settings to See How Performance Has Changed, as Negative Steam Reviews Pile Up",
      "content": "Borderlands 4 has launched on Steam to big concurrent player numbers, but the release was marred by complaints about PC performance that have resulted in a ‘mixed’ user review rating on Valve’s platform.\n\nBorderlands 4 peaked at 207,479 concurrent player numbers on Steam yesterday, September 11, which was significantly higher than any previous Borderlands before it. However, the game launched to ‘mostly negative’ Steam reviews over performance issues and crashing, before recovering overnight to ‘mixed.’\n\nThe complaints revolve around poor performance even on high powered PCs, with some affected by crashing that makes the game difficult to even start.\n\n“Terrible optimization. Another Unreal Engine 5 casualty. Not worth buying in its current state unless you have a NASA PC,” said one person in a negative review.\n\n“Terrible, terrible performance. Worst I've ever seen. Turned it down to Low graphics presets and couldn't hit 60 FPS, even with FSR upscaling on my RX 6900 XT,” said another.\n\nIn response, Gearbox posted a Borderlands 4 Nvidia Optimization guide on Steam, advising players how to optimize their graphics settings for “better performance and framerates” on PC with the Nvidia app.\n\n“As PC gamers begin their Vault-hunting journeys in Borderlands 4, we've seen early feedback from the community surrounding graphics settings and how to achieve optimal performance,” Gearbox said, before outlining the “expected results” for the Borderlands 4 PC specs:\n\nMinimum PC specs - 1080p @ 30FPS with Low Preset settings\n\nRecommended PC specs - 1440p @ 60FPS with Medium Preset settings\n\nGearbox then issued a piece of advice to PC gamers that to me reads like an effort to prevent players from making knee-jerk reactions to the game's performance as soon as they’ve changed their settings: “Please note that any time you change any of your graphics settings, your shaders will need to recompile. Please keep playing for at least 15 minutes to see how your PC's performance has changed.”\n\nGearbox went on to show the “Optimal Settings” charts provided by Nvidia with suggestions for which graphics settings may work best for your combination of GPU and desired display resolution. Meanwhile, it recommended using the Nvidia app to download and install Nvidia’s newest Game Ready Driver (581.29) and “optimize for your system.” If all else fails, “please contact 2K Support for direct assistance.”\n\nBorderlands 4 Review Screenshots View 159 Images\n\nGearbox and publisher 2K Games will be keen to address the performance complaints early, given the impact negative reviews on Steam can have on a video game’s success. Ahead of launch, Gearbox development chief Randy Pitchford had said the Borderlands 4 Day 1 patch “does a lot,” amid concern about the performance of the looter shooter. Pitchford had responded to concern about Borderlands 4’s pre-release performance on PC from some users on X / Twitter.\n\nDespite the Day 1 patch, playing Borderlands 4 on older hardware won't miraculously unlock \"buttery smooth performance,\" Pitchford added. It should be expected that Borderlands 4 is “unplayable” if you’re trying to use a PC below min-spec, he said, and, generally, playing new AAA games on older hardware won't achieve impressive results.\n\nHere’s Pitchford's comment in full:\n\nThe Day 1 patch does a lot! That said, the expectation for using a below min-spec machine should be that the game is unplayable. That the game runs at all on your system is a miracle. That you can get 55 - 60 fps out of heavy combat is actually incredible given how the engine and what's going on under the hood. Your specification doesn't indicate if you're on SDD or HDD, but that could also explain some of the hitching. It's a big, bold, new, seamless world and I'm sorry to say that older hardware may not provide buttery smooth performance for the latest gen AAA games, as has always been the case since the dawn of PC gaming.\n\nAs a reminder, here are Borderlands 4’s PC specs:\n\nBorderlands 4 System Requirements:\n\nMinimum:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-9700 / AMD Ryzen 7 2700X\n\nMemory: 16 GB RAM\n\nGraphics: NVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. Requires 8 CPU Cores for processor. Requires 8 GB VRAM for graphics. SSD storage required\n\nRecommended:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nMemory: 32 GB RAM\n\nGraphics: NVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. SSD storage required\n\nIf you are delving into Borderlands 4 don't go without our updated hourly SHiFT codes list. We've also got a huge interactive map ready to go and a badass Borderlands 4 planner tool courtesy of our buds at Maxroll. Plus check out our expert players' choices for which character to choose (no one agreed).\n\nWesley is Director, News at IGN. Find him on Twitter at @wyp100. You can reach Wesley at wesley_yinpoole@ign.com or confidentially at wyp100@proton.me.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/borderlands-4-dev-gearbox-asks-pc-gamers-to-keep-playing-for-at-least-15-minutes-after-they-tweak-settings-to-see-how-performance-has-changed-as-negative-steam-reviews-pile-up",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "PowerColor AMD Radeon RX 9060 XT Reaper Dual Fan 16GB GDDR6 PCIe 5.0 Graphics Card $350 + Free Store Pickup",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18600991-powercolor-amd-radeon-rx-9060-xt-reaper-16gb-gddr6-pcie-5-0-graphics-card-350-free-store-pickup",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "GIGABYTE B650E AORUS ELITE X AX ICE AM5 ATX Mobo + 120mm Montech AX 120 ARGB Fan $107.90 + Free Shipping",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired BeigeRoad455 posted Item 1 of 2 Item 1 of 2 expired BeigeRoad455 posted GIGABYTE B650E AORUS ELITE X AX ICE AM5 ATX Mobo + 120mm Montech AX 120 ARGB Fan + Free Shipping $108 $263 58% off Newegg 37 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 8,356 Views Visit Newegg Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18601741-gigabyte-b650e-aorus-elite-x-ax-ice-am5-atx-mobo-120mm-montech-ax-120-argb-fan-107-90-free-shipping",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "New Spectre-based CPU vulnerability allows guests to steal sensitive data from the cloud",
      "content": "ETH Zurich researchers found a new Spectre-BTI attack called VMSCAPE that lets a VM steal host data\n\nIt affects cloud setups using KVM/QEMU on AMD and Intel CPUs, bypassing existing defenses\n\nThey propose flushing the branch predictor on VMEXIT as a low-cost fix\n\nIf Ghostbusters taught us anything, it’s that spectres are notoriously difficult to get rid of.\n\nSecurity researchers from the Swiss public university, ETH Zurich, recently discovered a new Spectre-BTI (Branch Target Injection) attack that allows a malicious virtual machine (VM) to leak sensitive data from the host system, without modifying host software.\n\nThe research team - Jean-Claude Graf, Sandro Rüegge, Ali Hajiabadi, and Kaveh Razavi - conducted a systematic analysis of branch predictor isolation, targeting environments using KVM/QEMU virtualization on AMD Zen 4 and Zen 5 CPUs.\n\nFixing the flaw\n\nIn early June, they developed an exploit and named it VMSCAPE.\n\nAccording to the research paper published earlier this week, VMSCAPE is proof that default mitigations (hardware and software defenses that were previously considered sufficient for speculative execution attacks such as Spectre) are not enough to prevent speculative execution attacks across VM boundaries, and that secrets like disk encryption keys can be leaked in real-world cloud setups.\n\nAll cloud providers running virtualized workloads on vulnerable CPUs using KVM/QEMU are affected by the bug, the researchers further explained, which includes AMD Zen 1-5, and Intel’s Coffee Lake chips. KVM/QEMU is a powerful virtualization stack commonly used in Linux-based cloud environments.\n\nThe bug is now tracked as CVE-2025-40300, but the severity score has not yet been determined.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nChipmakers are already on the move, as well. An AMD spokesperson told The Register that the company is preparing a security brief, as well as a software fix.\n\nAn Intel representative told the same publication that existing mitigations can be used to address this flaw. “Linux mitigations are expected to be available on the VMSCAPE public disclosure date, and a CVE for this issue will be assigned by Linux,\" they added.\n\nThe paper’s authors propose flushing the CPU’s branch predictor using IBPB on VMEXIT as a mitigation for VMSCAPE, as this prevents a malicious guest VM from influencing speculative execution paths in the host. They also stressed that the tests showed negligible performance overhead, and that the fix was practical for deployment.\n\nVia The Register",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/security/new-spectre-based-cpu-vulnerability-allows-guests-to-steal-sensitive-data-from-the-cloud",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Intel Talent Bleed Continues",
      "content": "Intel's long-time Xeon chief architect Ronak Singhal is leaving the company after nearly 30 years , marking yet another high-profile departure amid Intel's leadership churn and intensifying competition from AMD and Arm-based cloud CPUs. The Register reports:",
      "source": "Slashdot.org",
      "url": "https://slashdot.org/story/25/09/12/2136201/intel-talent-bleed-continues",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "How AMD, Nvidia, Broadcom Can Ride Oracle’s $455B Cloud Surge",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/12/how-amd-nvidia-broadcom-can-ride-oracles-455b-cloud-surge/",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Get this Ryzen 7 mini PC with 32GB RAM for a crazy low $339",
      "content": "Nowadays, your home or office setup can feature a mini PC without issue because these things aren’t just powerful, but also affordable. The Beelink SER5 Max mini PC is only $339 right now, which is 24 percent off its MSRP at Amazon.\n\nThis tiny device runs on an AMD Ryzen 7 6800H CPU and an amazing 32GB LPDDR5 RAM, which means this thing’ll be uber fast, handling all the tasks you need to get done throughout the day. The 1TB SSD will add plenty of storage space for apps and files, while also booting your system in a blink.\n\nThis Beelink SER5 Max mini PC also supports triple 4K monitors, so you get to multitask like never before.\n\nIf you want a different configuration, there are plenty of mini PCs on sale these days. Here are some alternatives:\n\nFor $319 (20% off) , you can get the Beelink EQi12 with an Intel i5 CPU, 16GB DDR4, a 500GB SSD, and dual screen support.\n\n, you can get the Beelink EQi12 with an Intel i5 CPU, 16GB DDR4, a 500GB SSD, and dual screen support. If you’d rather get a Ryzen system, the Acemagic K1 is down to $315 (28% off) , featuring an AMD Ryzen 7 CPU, 32GB DDR4, a 1TB SSD, and triple display support.\n\n, featuring an AMD Ryzen 7 CPU, 32GB DDR4, a 1TB SSD, and triple display support. If you want something even cheaper, the Acemagic V1 is down to $188.1 (41% off) , featuring an Intel Twin Lake N150 CPU, 16GB DDR4 RAM, and 1TB SSD, as well as dual display support.\n\n, featuring an Intel Twin Lake N150 CPU, 16GB DDR4 RAM, and 1TB SSD, as well as dual display support. The Kamrui GK3Plus is another good option, featuring an Alder Lake N95 CPU, 16GB RAM, and a 512GB SSD, as well as triple-screen support. This one’s only $160, which is 20% under its MSRP, but its CPU will be significantly slower than the Ryzen found in the Beelink SER5 Max.\n\nAll of these are good options, but it does depend on what type of system you prefer and just how much power you’ll need to get your tasks done.\n\nThe Beelink SER5 Max has a fantastic discount, and getting this speedy configuration for $339 is a great deal.\n\nGet a powerful mini PC for $339",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2898428/get-this-ryzen-7-mini-pc-with-32gb-ram-for-a-crazy-low-339.html",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Linux 6.17 Fix Lands To Address Regression With \"Serious Breakage\" In Hibernation",
      "content": "\"Commit 12ffc3b1513e (\"PM: Restrict swap use to later in the suspend sequence\") incorrectly removed a pm_restrict_gfp_mask() call from hibernation_snapshot(), so memory allocations involving swap are not prevented from being carried out in this code path any more which may lead to serious breakage.\n\n\n\nThe symptoms of such breakage have become visible after adding a shrink_shmem_memory() call to hibernation_snapshot() in commit 2640e819474f (\"PM: hibernate: shrink shmem pages after dev_pm_ops.prepare()\") which caused this problem to be much more likely to manifest itself.\n\n\n\nHowever, since commit 2640e819474f was initially present in the DRM tree that did not include commit 12ffc3b1513e, the symptoms of this issue were not visible until merge commit 260f6f4fda93 (\"Merge tag 'drm-next-2025-07-30' of https://gitlab.freedesktop.org/drm/kernel\") that exposed it through an entirely reasonable merge conflict resolution.\"\n\n\"The issue here is that as of 6.17.0-rc1, running hibernate (disk) more than 7 times causes instability on most machines. The hibernate can be run with /sys/power/disk set to any value. The issue is the hibernate image itself becoming corrupted. The instability appears in user space as the timeout and failure of any or all of these commands:\n\n\n\nsudo systemctl is-active systemd-journald\n\nsudo shutdown\n\nsudo reboot\n\nsudo -i exit\n\n\n\nThe system cannot be soft shutdown or rebooted, it has to be power cycled. I believe the init process memory itself is corrupted and thus anything that goes through the init process times out.\"\n\nThis week's round of power management fixes for the in-development Linux 6.17 kernel are on the more notable side with fixes for both AMD and Intel P-State drivers plus addressing a system hibernation issue that could lead to \"serious breakage\" and stems from a Linux 6.16 regression.Intel engineer and power management subsystem maintainer Rafael Wysocki kicked off this week's power management pull request by noting a fix for a \"nasty hibernation regression introduced during the 6.16 cycle.\" The fix elaborates on that nasty regression and ends up being a one-liner to resolve. Wysocki explained in that commit:The issue was brought to light a few days ago in a bug report In addition to fixing that hibernation regression, there are also a few fixes too for the Intel and AMD P-State CPU frequency scaling drivers:- Fix setting of CPPC.min_perf in the active mode with performance governor in the amd-pstate driver to restore its expected behavior changed recently (Gautham Shenoy)- Avoid mistakenly setting EPP to 0 in the amd-pstate driver after system resume as a result of recent code changes (Mario Limonciello)\"Those fixes in the pull request were merged on Thursday ahead of the Linux 6.17-rc6 release coming on Sunday.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.17-PM-Hibernation-FIxes",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "China’s souring on Nvidia. Here’s why",
      "content": "Beijing is souring on Nvidia.\n\nChina, which used to be one of Nvidia’s largest markets, seems largely conflicted about reaccepting Nvidia’s lower-tech H20 chips that Trump administration finally allowed to resume sales of in July. The Chinese tech industry might be excited about the Nvidia chip flow resuming, but the government is allegedly not.\n\nChinese authorities have discouraged local tech companies from purchasing Nvidia chips citing national security concerns, and even questioned industry titans like Tencent over their purchases of Nvidia chips, according to Reuters.\n\nIn response, tech giants like Alibaba and Baidu have begun using their own chips to train smaller AI models, the Information reported on Thursday, but they will reportedly continue to use some Nvidia chips.\n\n“The competition has undeniably arrived,” an Nvidia spokesperson told Gizmodo. “Customers will choose the best technology stack for running the world’s most popular commercial applications and open-source models. We’ll continue to work to earn the trust and support of mainstream developers everywhere.”\n\nChinese development is ramping up. China chip stocks have experienced a major boom so big that the Beijing-based company Cambricon had to warn investors recently. Tech giants like Huawei and Alibaba are leading the push, but smaller companies are also making strides.\n\nShanghai-based tech company MetaX told the Wall Street Journal last month that it’s preparing to start mass production of a new chip that has bigger memory than Nvidia’s H20.\n\nStill, largely no chip offering so far has been considered completely up to par with Nvidia’s best offerings. Reuters reported last week that top Chinese tech firms like Alibaba and ByteDance are still very keen to get their hands on Nvidia chips. That’s despite the fact that the Nvidia chips that are being sold to China are downgraded versions of existing models, developed to abide by U.S. exports restrictions.\n\nThe chips saga\n\nSome experts in Washington think any supply of American tech to China has sizable national security risks attached to it. They also claim the chips can assist China in outpacing American AI innovation.\n\nThe Biden administration was first to enforce export restrictions on Nvidia chips sold to China, in an effort to curb the entry of high-tech chips into China off of those fears.\n\nBeijing landed a particularly big blow to domestic AI confidence earlier this year with Deepseek’s R1, an AI model that rivaled the best of American companies offerings using lower cost chips, inadvertently showing Americans that Chinese innovation did not require the top Nvidia chips.\n\nThat fueled the blanket ban decision which turned out to be less effective than expected when a Financial Times report found that Nvidia’s highest tech chips were being smuggled into China in the absence of the lower tech H20s.\n\nThe decision was also a big hit to Nvidia: executives shared in a May earnings call that they had to revise revenue expectations down for the quarter by about $8 billion due to the restrictions.\n\nAfter an intense lobbying effort by Nvidia CEO Jensen Huang, Trump reversed his decision in July, allowing H20 chips sales to China. In exchange, Trump demanded that Nvidia, and fellow American chipmaker AMD, both give the U.S. government a 15% cut of all of their chips revenue in China.\n\nJust when Nvidia thought all was finally well, Beijing started raising concerns about the new Nvidia chips coming into China having kill switches and backdoors, urging Chinese companies to not use them. Nvidia has denied the claim.\n\nThe remaining political uncertainty has continued to cast a shadow on Nvidia’s performance in China. The company conceded in its latest earnings call that they were facing disappointing numbers from the region still and were yet to begin H20 shipments.\n\nWhy did Beijing change its mind?\n\nChina has a long relationship with Nvidia. The downturn in that relationship began after the first export restrictions went into effect, ramped up after an antitrust probe in December and has developed a life of its own under Trump’s trade war.\n\nChinese officials have voiced security concerns related to the latest round of chips set to enter the country, but this attitude change has less to do with Nvidia itself and more about China’s own chip industry.\n\nChinese AI industry is currently dependent on American chipmakers like Nvidia, and that gives Americans an edge. In the absence of Nvidia chips, China will have to develop their own high-tech chips that can rival and even surpass the quality of Nvidia chips. If that happens, the United States can be at jeopardy to lose its hold on the global chips demand, and China is the runner-up.\n\nThe country is making a big bet on AI, announcing an $8.2 billion AI-investment fund earlier this year, in an effort to spur innovation and reach independence.\n\n“It’s unfortunate to see that we in Asia, including China, are emulating the U.S. when it comes to developing algorithms and large models,” Wei Shaojun, an adviser to senior Chinese government officials and a professor at top Beijing university Tsinghua University told a forum in Singapore on Thursday. He warned that staying on this path of dependence could be “lethal” for the region, according to Bloomberg.\n\nAlong with the chips push, the country has increasingly emphasized global cooperation in AI, and center to that initiative is Beijing’s desire to cement itself at the center of the global AI trade.\n\nIt seems China is coming to terms with the fact that aspiration won’t be achievable as long as the industry is dependent on the U.S. for chips, especially when Washington has demonstrated that its trade policy decisions are volatile.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/chinas-souring-on-nvidia-heres-why-2000657632",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "ASUS Introduces the Most Powerful ProArt P16 Yet With New OLED Display and RTX 5090 GPU",
      "content": null,
      "source": "Fstoppers",
      "url": "https://fstoppers.com/gear/asus-introduces-most-powerful-proart-p16-yet-new-oled-display-and-rtx-5090-gpu-711392",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "AMD's RDNA4 GPU Architecture at Hot Chips 2025",
      "content": "RDNA4 is AMD’s latest graphics-focused architecture, and fills out their RX 9000 line of discrete GPUs. AMD noted that creating a good gaming GPU requires understanding both current workloads, as well as taking into account what workloads might look like five years in the future. Thus AMD has been trying to improve efficiency across rasterization, compute, and raytracing. Machine learning has gained importance including in games, so AMD’s new GPU architecture caters to ML workloads as well.\n\nFrom AMD’s perspective, RDNA4 represents a large efficiency leap in raytracing and machine learning, while also improving on the rasterization front. Improved compression helps keep the graphics architecture fed. Outside of the GPU’s core graphics acceleration responsibility, RDNA4 brings improved media and display capabilities to round out the package.\n\nMedia Engine\n\nThe Media Engine provides hardware accelerated video encode and decode for a wide range of codecs. High end RDNA4 parts like the RX 9070XT have two media engines. RDNA4’s media engines feature faster decoding speed, helping save power during video playback by racing to idle. For video encoding, AMD targeted better quality in H.264, H.265, and AV1, especially in low latency encoding.\n\nLow latency encoder modes are mostly beneficial for streaming, where delays caused by the media engine ultimately translate to a delayed stream. Reducing latency can make quality optimizations more challenging. Video codecs strive to encode differences between frames to economize storage. Buffering up more frames gives the encoder more opportunities to look for similar content across frames, and lets it allocate more bitrate budget for difficult sequences. But buffering up frames introduces latency. Another challenge is some popular streaming platforms mainly use H.264, an older codec that’s less efficient than AV1. Newer codecs are being tested, so the situation may start to change as the next few decades fly by. But for now, H.264 remains important due to its wide support.\n\nTesting with an old gameplay clip from Elder Scrolls Online shows a clear advantage for RDNA4’s media engine when testing with the latency-constrained VBR mode and encoder tuned for low latency encoding (-usage lowlatency -rc vbr_latency). Netflix’s VMAF video quality metric gives higher scores for RDNA4 throughout the bitrate range. Closer inspection generally agrees with the VMAF metric.\n\nRDNA4 does a better job preserving high contrast outlines. Differences are especially visible around text, which RDNA4 handles better than its predecessor while using a lower bitrate. Neither result looks great with such a close look, with blurred text on both examples and fine detail crushed in video encoding artifacts. But it’s worth remembering that the latency-constrained VBR mode uses a VBV buffer of up to three frames, while higher latency modes can use VBV buffer sizes covering multiple seconds of video. Encoding speed has improved slightly as well, jumping from ~190 to ~200 FPS from RDNA3.5 to RDNA4.\n\nDisplay Engine\n\nThe display engine fetches on-screen frame data from memory, composites it into a final image, and drives it to the display outputs. It’s a basic task that most people take for granted, but the display engine is also a good place to perform various image enhancements. A traditional example is using a lookup table to apply color correction. Enhancements at the display engine are invisible to user software, and are typically carried out in hardware with minimal power cost. On RDNA4, AMD added a “Radeon Image Sharpening” filter, letting the display engine sharpen the final image. Using dedicated hardware at the display engine instead of the GPU’s programmable shaders means that the sharpening filter won’t impact performance and can be carried out with better power efficiency. And, AMD doesn’t need to rely on game developers to implement the effect. Sharpening can even apply to the desktop, though I’m not sure why anyone would want that.\n\nPower consumption is another important optimization area for display engines. Traditionally that’s been more of a concern for mobile products, where maximizing battery life under low load is a top priority. But RDNA4 has taken aim at multi-monitor idle power with its newer display engine. AMD’s presentation stated that they took advantage of variable refresh rates on FreeSync displays. They didn’t go into more detail, but it’s easy to imagine what AMD might be doing. High resolution and high refresh rate displays translate to high pixel rates. That in turn drives higher memory bandwidth demands. Dynamically lowering refresh rates could let RDNA4’s memory subsystem enter a low power state while still meeting refresh deadlines.\n\nPower and GDDR6 data rates for various refresh rate combinations. AMD’s monitoring software (and others) read out extremely low memory clocks when the memory bus is able to idle, so those readings aren’t listed.\n\nI have a RX 9070 hooked up to a Viotek GN24CW 1080P display via HDMI, and a MSI MAG271QX 1440P capable of refresh rates up to 360 Hz. The latter is connected via DisplayPort. The RX 9070 manages to keep memory at idle clocks even at high refresh rate settings. Moving the mouse causes the card to ramp up memory clocks and consume more power, hinting that RDNA4 is lowering refresh rates when screen contents don’t change. Additionally, RDNA4 gets an intermediate GDDR6 power state that lets it handle the 1080P 60 Hz + 1440P 240 Hz combination without going to maximum memory clocks. On RDNA2, it’s more of an all or nothing situation. The older card is more prone to ramping up memory clocks to handle high pixel rates, and power consumption remains high even when screen contents don’t change.\n\nCompute Changes\n\nRDNA4’s Workgroup Processor retains the same high level layout as prior RDNA generations. However, it gets major improvements targeted towards raytracing, like improved raytracing units and wider BVH nodes, a dynamic register allocation mode, and a scheduler that no longer suffers false memory dependencies between waves. I covered those in previous articles. Besides those improvements, AMD’s presentation went over a couple other details worth discussing.\n\nScalar Floating Point Instructions\n\nAMD has a long history of using a scalar unit to offload operations that are constant across a wave. Scalar offload saves power by avoiding redundant computation, and frees up the vector unit to increase performance in compute-bound sequences. RDNA4’s scalar unit gains a few floating point instructions, expanding scalar offload opportunities. This capability debuted on RDNA3.5, but RDNA4 brings it to discrete GPUs.\n\nWhile not discussed in AMD’s presentation, scalar offload can bring additional performance benefits because scalar instructions sometimes have lower latency than their vector counterparts. Most basic vector instructions on RDNA4 have 5 cycle latency. FP32 adds and multiples on the scalar unit have 4 cycle latency. The biggest latency benefits still come from offloading integer operations though.\n\nSplit Barriers\n\nGPUs use barriers to synchronize threads and enforce memory ordering. For example, a s_barrier instruction on older AMD GPUs would cause a thread to wait until all of its peers in the workgroup also reached the s_barrier instruction. Barriers degrade performance because any thread that happened to reach the barrier faster would have to stall until its peers catch up.\n\nRDNA4 splits the barrier into separate “signal” and “wait” actions. Instead of s_barrier, RDNA4 has s_barrier_signal and s_barrier_wait. A thread can “signal” the barrier once it produces data that other threads might need. It can then do independent work, and only wait on the barrier once it needs to use data produced by other threads. The s_barrier_wait will then stall the thread until all other threads in the workgroup have signalled the barrier.\n\nMemory Subsystem\n\nThe largest RDNA4 variants have a 8 MB L2 cache, representing a substantial L2 capacity increase compared to prior RDNA generations. RDNA3 and RDNA2 maxed out at 6 MB and 4 MB L2 capacities, respectively. AMD found that difficult workloads like raytracing benefit from the larger L2. Raytracing involves pointer chasing during BVH traversal, and it’s not surprising that it’s more sensitive to accesses getting serviced from the slower Infinity Cache as opposed to L2. In the initial scene in 3DMark’s DXR feature test, run in Explorer Mode, RDNA4 dramatically cuts down the amount of data that has to be fetched from beyond L2.\n\nRDNA2 still does a good job of keeping data in L2 in absolute terms. But it’s worth noting that hitting Infinity Cache on both platforms adds more than 50 ns of extra latency over a L2 hit. That’s well north of 100 cycles because both RDNA2 and RDNA4 run above 2 GHz. While AMD’s graphics strategy has shifted towards making the faster caches bigger, it still contrasts with Nvidia’s strategy of putting way more eggs in the L2 basket. Blackwell’s L2 cache serves the functions of both AMD’s L2 and Infinity Cache, and has latency between those two cache levels. Nvidia also has a flexible L1/shared memory allocation scheme that can give them more low latency caching capacity in front of L2, depending on a workload’s requested local storage (shared memory) capacity.\n\nA mid-level L1 cache was a familiar fixture on prior RDNA generations. It’s conspicuously missing from RDNA4, as well as AMD’s presentation. One possibility is that L1 cache hitrate wasn’t high enough to justify the complexity of an extra cache level. Perhaps AMD felt its area and transistor budget was better allocated towards increasing L2 capacity. To support this theory, L1 hitrate on RDNA1 was often below 50%. At the same time, the RDNA series always enjoyed a high bandwidth and low latency L2. Putting more pressure on L2 in exchange for reducing L2 misses may have been an enticing tradeoff. Another possibility is that AMD ran into validation issues with the L1 cache and decided to skip it for this generation. There’s no way to verify either possibility of course, but I think the former reasons make more sense.\n\nBeyond tweaking the cache hierarchy, RDNA4 brings improvements to transparent compression. AMD emphasized that they’re using compression throughout the SoC, including at points like the display engine and media engine. Compressed data can be stored in caches, and decompressed before being written back to memory. Compression cuts down on data transfer, which reduces bandwidth requirements and improves power efficiency.\n\nTransparent compression is not a new feature. It has a long history of being one tool in the GPU toolbox for reducing memory bandwidth usage, and it would be difficult to find any modern GPU without compression features of some sort. Even compression in other blocks like the display engine have precedent. Intel’s display engines for example use Framebuffer Compression (FBC), which can write a compressed copy of frame data and keep fetching the compressed copy to reduce data transfer power usage as long as the data doesn’t change. Prior RDNA generations had compression features too, and AMD’sdocumentation summarizes some compression targets. While AMD didn’t talk about compression efficiency, I tried to take similar frame captures using RGP on both RDNA1 and RDNA4 to see if there’s a large difference in memory access per frame. It didn’t quite work out the way I expected, but I’ll put them here anyway and discuss why evaluating compression efficacy is challenging.\n\nThe first challenge is that both architectures satisfy most memory requests from L0 or L1. AMD slides on RDNA1 suggest the L0 and L1 only hold decompressed data, at least for delta color compression. Compression does apply to L2. For RDNA4, AMD’s slides indicate it applies to the Infinity Cache too. However, focusing on data transfer to and from the L2 wouldn’t work due the large cache hierarchy differences between those RDNA generations.\n\nDCC, or delta color compression, is not the only form of compression. But this slide shows one example of compression/decompression happening in front of L2\n\nAnother issue is, it’s easy to imagine a compression scheme that doesn’t change the number of cache requests involved. For example, data might be compressed to only take up part of a cacheline. A request only causes a subset of the cacheline to be read out, which a decompressor module expands to the full 128B. Older RDNA1 slides are ambiguous about this, indicating that DCC operates on 256B granularity (two cachelines) without providing further details.\n\nIn any case, compression may be a contributing factor in RDNA4 being able to achieve better performance while using a smaller Infinity Cache than prior generations, despite only having a 256-bit GDDR6 DRAM setup.\n\nSoC Features\n\nAMD went over RAS, or reliability, availability, and serviceability features in RDNA4. Modern chips use parity and ECC to detect errors and correct them, and evidently RDNA4 does the same. Unrecoverable errors are handled with driver intervention, by “re-initializing the relevant portion of the SoC, thus preventing the platform from shutting down”. There’s two ways to interpret that statement. One is that the GPU can be re-initialized to recover from hardware errors, obviously affecting any software relying on GPU acceleration. Another is that some parts of the GPU can be re-initialized while the GPU continues handling work. I think the former is more likely, though I can imagine the latter being possible in limited forms too. For example, an unrecoverable error reading from GDDR6 can hypothetically be fixed if that data is backed by a duplicate in system memory. The driver could transfer known-good data from the host to replace the corrupted copy. But errors with modified data would be difficult to recover from, because there might not be an up-to-date copy elsewhere in the system.\n\nOn the security front, microprocessors get private buses to “critical blocks” and protected register access mechanisms. Security here targets HDCP and other DRM features, which I don’t find particularly amusing. But terminology shown on the slide is interesting, because MP0 and MP1 are also covered in AMD’s CPU-side documentation. On the CPU side, MP0 (microprocessor 0) handles some Secure Encrypted Virtualization (SEV) features. It’s sometimes called the Platform Security Processor (PSP) too. MP1 on CPUs is called the System Management Unit (SMU), which covers power control functions. Curiously AMD’s slide labels MP1 and the SMU separately on RDNA4. MP0/MP1 could have completely different functions on GPUs of course. But the common terminology raises the possibility that there’s a lot of shared work between CPU and GPU SoC design. RAS is also a very traditional CPU feature, though GPUs have picked up RAS features over time as GPU compute picked up steam.\n\nInfinity Fabric\n\nOne of the most obvious examples of shared effort between the CPU and GPU sides is Infinity Fabric making its way to graphics designs. This started years ago with Vega, though back then using Infinity Fabric was more of an implementation detail. But years later, Infinity Fabric components provided an elegant way to implement a large last level cache, or multi-socket coherent systems with gigantic iGPUs (like MI300A).\n\nSlide from Hot Chips 29, covering Infinity Fabric used in AMD’s older Vega GPU\n\nThe Infinity Fabric memory-side subsystem on RDNA4 consists of 16 CS (Coherent Station) blocks, each paired with a Unified Memory Controller (UMC). Coherent Stations receive requests coming off the graphics L2 and other clients. They ensure coherent memory access by either getting data from a UMC, or by sending a probe if another block has a more up-to-date copy of the requested cacheline. The CS is a logical place to implement a memory side cache, and each CS instance has 4 MB of cache in RDNA4.\n\nTo save power, Infinity Fabric supports DVFS (dynamic voltage and frequency scaling) to save power, and clocks between 1.5 and 2.5 GHz. Infinity Fabric bandwidth is 1024 bytes per clock, which suggests the Infinity Cache can provide 2.5 TB/s of theoretical bandwidth. That roughly lines up with results from Nemes’s Vulkan-based GPU cache and memory bandwidth microbenchmark.\n\nAMD also went over their ability to disable various SoC components to harvest dies and create different SKUs. Shader Engines, WGPs, and memory controller channels can be disabled. AMD and other manufacturers have used similar harvesting capabilities in the past. I’m not sure what’s new here. Likely, AMD wants to re-emphasize their harvesting options.\n\nFinally, AMD mentioned that they chose a monolithic design for RDNA4 because it made sense for a graphics engine of its size. They looked at performance goals, package assembly and turnaround time, and cost. After evaluating those factors, they decided a monolithic design was the right option. It’s not a surprise. After all, AMD used monolithic designs for lower end RDNA3 products with smaller graphics engines, and only used chiplets for the largest SKUs. Rather, it’s a reminder that there’s no one size fits all solution. Whether a monolithic or chiplet-based design makes more sense depends heavily on design goals.\n\nFinal Words\n\nRDNA4 brings a lot of exciting improvements to the table, while breaking away from any attempt to tackle the top end performance segment. Rather than going for maximum performance, RDNA4 looks optimized to improve efficiency over prior generations. The RX 9070 offers similar performance to the RX 7900XT in rasterization workloads despite having a lower power budget, less memory bandwidth, and a smaller last level cache. Techspot also shows the RX 9070 leading with raytracing workloads, which aligns with AMD's goal of enhancing raytracing performance.\n\nSlide from RDNA4’s Launch Presentation not Hot Chips 2025\n\nAMD achieves this efficiency using compression, better raytracing structures, and a larger L2 cache. As a result, RDNA4 can pack its performance into a relatively small 356.5 mm² die and use a modest 256-bit GDDR6 memory setup. Display and media engine improvements are welcome too. Multi-monitor idle power feels like a neglected area for discrete GPUs, even though I know many people use multiple monitors for productivity. Lowering idle power in those setups is much appreciated. On the media engine side, AMD’s video encoding capabilities have often lagged behind the competition. RDNA4’s progress at least prevents AMD from falling as far behind as they have before.\n\nIf you like the content then consider heading over to the Patreon or PayPal if you want to toss a few bucks to Chips and Cheese. Also consider joining the Discord.",
      "source": "Chipsandcheese.com",
      "url": "https://chipsandcheese.com/p/amds-rdna4-gpu-architecture-at-hot",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "5 reasons you need to be more careful with RAM on Ryzen",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/ryzen-memory-compatibility-stinks-but-so-does-arrow-lake/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Linux's New \"Sheaves\" Per-CPU Caching Layer Showing Massive Wins For AMD Performance",
      "content": "\"I ported this patch series on top of v6.17 and ran some benchmarks: will-it-scale, hackbench, redis, unixbench and kernbench. I ran the benchmarks on Intel Granite Rapids (480 cores), AMD Turin (512 cores) and ARM (80 cores)\n\n\n\nSummary of the results:\n\n\n\n- Significant change (meaning >10% difference between base and experiment) on will-it-scale tests in AMD.\n\n- No significant change on other benchmarks ran.\"\n\nEarlier this week I wrote about Sheaves as an opt-in, per-CPU array-based caching layer likely coming for Linux 6.18. The sheaves patches have been queued into the \"slab/for-next\" Git branch ahead of the Linux 6.18 kernel merge window. Patches posted now by Google are showing the Linux Sheaves code having a massive beneficial impact for large AMD systems.Google engineer Sudarsan Mahendran posted some benchmarks of the SLUB per-CPU Sheaves patches on Friday. The patches were applied to a Linux 6.17 base and tested across AMD, Intel, and ARM servers. For the AMD EPYC Turin server the Sheaves work ended up being a massive win for performance on a number of benchmarks but also some regressions.Sudarsan Mahendran commented on the mailing list:Going over his benchmarks on that LKML thread were exciting when seeing \"+28.58%\" mean improvements to get started, but also some 13~20% regressions... But when getting to the higher process counts for these scalability benchmarks was when it was getting really wild with +70.59%, +126.89%, +112.89%, and other massive wins. See all of the Google engineer's data in this thread It will be exciting to see how the Sheaves patches play out in more real-world workloads. Once these patches hit the mainline kernel presumably for Linux 6.18, I'll be firing up a number of benchmarks on my own hardware and thankfully have a lot of AMD EPYC Turin hardware and more for some exciting benchmarks ahead.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-Sheaves-AMD-Performance",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Another vendor launches an AMD Radeon RX7600M XT external GPU - and this one even comes with Thunderbolt 5",
      "content": "OneXGPU Lite RX 7600M XT offers 2,048 stream processors with 8GB GDDR6\n\nInfinity Cache is limited to 32 MB, restricting bandwidth efficiency gains\n\nDelivers 120 W power draw and up to 65 W power output for connected external devices\n\nExternal GPUs are often marketed as a way to extend the capabilities of thin laptops, and the OneXGPU Lite follows that trend.\n\nThis new device, which weighs 500g and can clip into a handbag, is built around the AMD Radeon RX 7600M XT, a mobile RDNA3 chip with 2,048 stream processors, 8GB of GDDR6 memory, and 32MB of Infinity Cache.\n\nIt is rated for 120W power draw and can provide up to 65W to connected devices, although it still relies on a separate 240W power brick.\n\nHardware and connection standards\n\nThe graphics dock supports HDMI 2.1 and DisplayPort 2.0, with advertised output up to 4K at 120Hz.\n\nFor connectivity, the product description repeatedly mentions “USB 5.0” and “USB-C 5.0,” even though such standards do not exist.\n\nIt is more likely the device supports USB4 v2 or Thunderbolt 5, both of which deliver 80Gbps in each direction but cap PCIe bandwidth at 64Gbps.\n\nThe company itself uses the Thunderbolt 5 label, although proper certification details have not been shared.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nGiven this uncertainty, the practical value of such a device depends on how well it translates into real-world use.\n\nA laptop that once struggled with layered editing projects could, in theory, become serviceable as a photo editing PC.\n\nLikewise, high-resolution rendering timelines in software packages may run more smoothly, making the same system workable as a video editing PC.\n\nThe catch, as always, is that bandwidth limits and thermal constraints reduce efficiency compared with a desktop solution.\n\nThe OneXGPU Lite is priced at 3,899 RMB, around $535, with shipping expected from September 25.\n\nThat cost is comparable to standalone midrange cards, although those cards would typically be installed in full desktops with access to the best GPU performance in the segment.\n\nHere, the buyer is paying for portability and compatibility rather than raw speed, but the package also includes a proprietary USB 5.0 cable, listed at a $27 value.\n\nVia Videocardz",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/another-vendor-launches-an-amd-radeon-rx7600m-xt-external-gpu-and-this-one-even-comes-with-thunderbolt-5",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "HSBC: Wall Street Underestimating Advanced Micro Devices Inc. (AMD)’s AI GPU Business",
      "content": "Advanced Micro Devices, Inc. (NASDAQ:AMD) is one of the best tech stocks to buy for the long term. On September 9, HSBC reiterated a ‘Buy’ rating on the stock but cut its price target to $185 from $200. The price target cut comes amid concerns about the average selling price of the company’s M1355 chip.\n\nHSBC: Wall Street Underestimating Advanced Micro Devices Inc. (AMD)'s AI GPU Business\n\nPosonskyi Andrey/Shutterstock.com\n\nAccording to HSBC, the price target cut was necessitated by the fact that the average selling price of AMD’s M1355 chip would be $23,000, down from the previous $25,000 per unit. The lower average selling price has prompted HSBC to lower its 2026 AI GPU revenue from $15.1 billion to $13.9 billion.\n\nDespite the reduced AI GPU revenue estimate due to a lower average selling price, it is still 20% above consensus estimates. Likewise, HSBC insists Wall Street is underestimating AMD’s AI GPU business despite the slight price revision.\n\nAdditionally, HSBC anticipates that AMD will benefit from major cloud service providers, including Meta, Microsoft, and Oracle, as they begin testing its M1400 rack solution. The push is expected to diversify the company’s revenue base.\n\nAdvanced Micro Devices Inc. (NASDAQ:AMD) is a semiconductor company that designs and develops high-performance computing and visualization products, including CPUs, GPUs, and adaptive computing solutions. Its technologies are used in PCs, gaming, data centers, and embedded systems to advance markets such as artificial intelligence (AI), cloud computing, and others.\n\nWhile we acknowledge the potential of AMD as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 12 Best Consumer Goods Stocks Billionaires Are Quietly Buying and Goldman Sachs Penny Stocks: Top 12 Stock Picks.\n\nDisclosure: None. This article is originally published at Insider Monkey.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/hsbc-wall-street-underestimating-advanced-135320942.html",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "GIGABYTE B650 AORUS Elite AX Motherboard $169.99 + Free Shipping",
      "content": "Deal History includes data from multiple reputable stores, such as Best Buy, Target, and Walmart. The lowest price among stores for a given day is selected as the \"Sale Price\".\n\n\n\nSale Price does not include sale prices at Amazon unless a deal was posted by a community member.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18603382-gigabyte-b650-aorus-elite-ax-motherboard-169-99-free-shipping",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "HP OmniBook 7 Laptop Computer 13.3\" WQXGA AMD Ryzen AI 7 32 GB memory;2 TB SSD $862.39 EPP EDU",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired N3RD_01 posted Item 1 of 2 Item 1 of 2 expired N3RD_01 posted HP OmniBook 7 Laptop Computer 13.3\" WQXGA AMD Ryzen AI 7 32 GB memory;2 TB SSD $862.39 EPP EDU $862 $1,300 33% off HP Small & Medium Business 11 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 5,982 Views Visit Retailer Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details\n\nProcessor: AMD Ryzen™ AI 7 350 (up to 5.0 GHz max boost clock, 16 MB L3 cache, 8 cores, 16 threads)\n\nStorage: 2 TB PCIe® Gen4 NVMe™ TLC M.2 SSD\n\nMemory: 32 GB LPDDR5x-7500 MT/s (onboard)\n\nGraphics: Integrated: AMD Radeon™ 860M Graphics\n\nDisplay: 13.3\" diagonal, WQXGA (2560 x 1600), IPS, micro-edge, anti-glare, 400 nits, 100% sRGB\n\n\n\nHP EPP/ EDU accounts $862.39\n\n\n\nhttps://www.hp.com/us-en/shop/pdp...t3f0ua-aba HP OmniBook 7 Laptop Computer 13.3\" WQXGA AMD Ryzen AI 7 32 GB memory;2 TB SSDProcessor: AMD Ryzen™ AI 7 350 (up to 5.0 GHz max boost clock, 16 MB L3 cache, 8 cores, 16 threads)Storage: 2 TB PCIe® Gen4 NVMe™ TLC M.2 SSDMemory: 32 GB LPDDR5x-7500 MT/s (onboard)Graphics: Integrated: AMD Radeon™ 860M GraphicsDisplay: 13.3\" diagonal, WQXGA (2560 x 1600), IPS, micro-edge, anti-glare, 400 nits, 100% sRGBHP EPP/ EDU accounts Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster N3RD_01 Follow Give Rep Message 753 Deal Posts 1,191 Comments Posts 974 Reputation Points 918 Votes Submitted Deal Details Community Notes About the Poster\n\nProcessor: AMD Ryzen™ AI 7 350 (up to 5.0 GHz max boost clock, 16 MB L3 cache, 8 cores, 16 threads)\n\nStorage: 2 TB PCIe® Gen4 NVMe™ TLC M.2 SSD\n\nMemory: 32 GB LPDDR5x-7500 MT/s (onboard)\n\nGraphics: Integrated: AMD Radeon™ 860M Graphics\n\nDisplay: 13.3\" diagonal, WQXGA (2560 x 1600), IPS, micro-edge, anti-glare, 400 nits, 100% sRGB\n\n\n\nHP EPP/ EDU accounts $862.39\n\n\n\nhttps://www.hp.com/us-en/shop/pdp...t3f0ua-aba HP OmniBook 7 Laptop Computer 13.3\" WQXGA AMD Ryzen AI 7 32 GB memory;2 TB SSDProcessor: AMD Ryzen™ AI 7 350 (up to 5.0 GHz max boost clock, 16 MB L3 cache, 8 cores, 16 threads)Storage: 2 TB PCIe® Gen4 NVMe™ TLC M.2 SSDMemory: 32 GB LPDDR5x-7500 MT/s (onboard)Graphics: Integrated: AMD Radeon™ 860M GraphicsDisplay: 13.3\" diagonal, WQXGA (2560 x 1600), IPS, micro-edge, anti-glare, 400 nits, 100% sRGBHP EPP/ EDU accounts",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18602317-hp-omnibook-7-laptop-computer-13-3-wqxga-amd-ryzen-ai-7-32-gb-memory-2-tb-ssd-862-39-epp-edu",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "AI-driven search engine running inside a laundry room aims to rival Google, and you can try it yourself — programmer harnesses old server parts and AI to deliver quality results",
      "content": "A programmer wants to take on Google Search, starting with two PCs that sit in his laundry room. Ryan Pearce, who worked in both enterprise software and game development roles, was curious about what it takes to build a search engine. According to Fast Company, Pearce built two search engines: Searcha Page and its incognito variant, Seek Ninja. These two engines both have a database with over 2 billion entries. Although it’s less than half a percent of Google’s 400-billion-strong search index, it’s still a considerable number, and he expects to double it in the next six months or so.\n\nThis self-hosted search engine sits in Pearce’s home — but instead of going with a low-powered Raspberry Pi or a mini-PC that most people use when self-hosting, he opted for a used 32-core AMD EPYC 7532, which was one of the best workstation CPUs when it launched in 2020. After all, if you want to create a massive search engine, you’d need something punchier than an entry-level CPU. Nevertheless, since that processor is already five years old at the time of writing, you can now easily get a used copy for less than $200. “I could have gotten another chip for the same price, which would have had twice as many threads, but it would have produced too much heat,” the programmer told Fast Company.\n\nIt’s for this reason that the two servers sit inside his laundry room. Pearce initially had them installed in his bedroom, but the heat generated by the system prevented him from sleeping comfortably. So, he moved them to his utility room, with one device sitting on a ledge, and the other supporting unit propped on a couple of small stools. The two devices are plugged into an extension cord, and the network cable that connects them to the internet is routed through a hole he drilled into the wall. There was also a makeshift vent that allowed the heat generated by the machines to escape from his home. “The heat hasn’t been absolutely terrible,” Pearce said to the publication. “But if the door is closed for too long, it is a problem.”\n\nThe secret to how one programmer can run a massive search engine is AI — but it’s not the kind of AI that most people would think of. Pearce does not employ front-facing AI tools that summarize search results and do the thinking for you. Instead, he uses machine learning algorithms to expand the keywords used in the query and help understand the user's context. This enables search engines to deliver relevant results with a fraction of the resources that Google has.\n\nPearce said that he’s building his search engine piece by piece, and that he’s already written around 150,000 lines of code. However, he says that he’s done so much more than that, and that he has iterated over 500,000 lines of code. Most of these changes were made to reduce the code’s reliance on large language models and make it work without relying on AI. This technique enabled him to create a complex system and then lock in modules that work by removing the variable of AI.\n\nRyan said that he’s considering moving the search engine out of his home and into a data center-like facility. However, since he dislikes cloud services, it will likely be at a location near his house, where he can easily access the servers and work on them on-site as necessary. But, in the meantime, Pearce said that he’s doing affiliate-style advertising to help him achieve that goal.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/software/search-engines/ai-driven-search-engine-running-inside-a-laundry-room-aims-to-rival-google-and-you-can-try-it-yourself-programmer-harnesses-old-server-parts-and-ai-to-deliver-quality-results",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Podcast #836 – Intel & AMD CPU News, NVIDIA GPU Marketshare, Sapphire B850, SK hynix and Samsung SSD Reviews, Ubisoft kills games + MORE!",
      "content": "After a week off – Join us as we battle illness to bring you the pithy, erudite commentary you crave. That you deserve even. Start with software designed cores, mix in some Nvidia domination, season with the largest DDoS attack EVaR, then Ubisoft kills games and finish with fast SSDs. What an evening you are in for.\n\nOh, and we’re taking next week off too. So much stacked up vacation we need to use by EOY!\n\nWe must thank our Patreon members, because without you … we would be gone. New folks and current ones that are bumping their patronage are greatly appreciated.\n\nThis show cannot go on without you – you know who you are, please consider helping our efforts. It most definitely helps keep us on the air. And helps Josh buy burgers. Thank you!",
      "source": "PC Perspective",
      "url": "https://pcper.com/2025/09/podcast-836/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Supermicro (SMCI): Evaluating Valuation Following Launch of Blackwell Ultra AI Data Center Solutions",
      "content": "Super Micro Computer (SMCI) has just started shipping its highly anticipated NVIDIA Blackwell Ultra solutions worldwide, a move that is capturing plenty of investor attention. These new systems represent more than incremental upgrades. They promise to deliver rapid deployment and enhanced performance for some of the most demanding AI data center projects. With pre-validated racks, plug-and-play installation, and cutting-edge cooling innovations, Super Micro is making a bold play to lead the next wave of AI infrastructure.\n\nThis launch arrives at a pivotal moment for Super Micro. After a stretch of volatility, the stock jumped 4% on the news of these volume shipments, signaling a renewed sense of optimism in the company’s growth story. Over the past year, SMCI shares have wavered with a small year-over-year dip, but momentum has started building again in 2025, helped along by AI-driven product expansions and major partnerships. While there has been a near 50% year-to-date gain, recent months have seen some pullback, reminding investors that expectations remain high but not assured.\n\nAfter a big announcement and a sharp move, the big question remains. Is Super Micro ready for another leg up, or is the market already factoring in all that future growth?\n\nMost Popular Narrative: 39.6% Undervalued\n\nAccording to the most popular narrative, Super Micro Computer is considered significantly undervalued. The argument hinges on robust projected growth and strong positioning in the AI infrastructure market.\n\nPartnerships with NVDA, AMD, xAI and Intel position them as one of the most attractive providers of GPU data center infrastructure. They are also profiting from growth in other related industries such as Cloud, 5G and Storage. Using the SWS Fair Value tool and management guidance of $23bn for 2025 and $40bn for 2026, I decided to use a revenue growth rate of 50% to reach an estimated revenue of $50bn for 2028, which I consider conservative.\n\nCurious about what drives this bold undervaluation call? The key lies in aggressive growth assumptions and a premium multiple historically reserved for industry giants. Want to see how these strategic forecasts transform into a game-changing price target and why this narrative is gaining traction? The most intriguing projections are just one click away.\n\nResult: Fair Value of $74.53 (UNDERVALUED)\n\nHave a read of the narrative in full and understand what's behind the forecasts.\n\nHowever, risks remain, including potential regulatory hurdles and execution missteps. Either of these factors could challenge even the most optimistic projections for Super Micro.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/supermicro-smci-evaluating-valuation-following-125543430.html",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Sony PlayStation 6 Leak: Here’s What We Know About The Specs",
      "content": "Reputed hardware leaker ‘Moore’s Law Is Dead’ just dropped another bombshell, and this time the claims about Sony’s next-generation console are so outrageous they almost sound like wishful thinking from a PlayStation fanboy’s fever dream. The latest leak suggests the PS6 could pack hardware that rivals Nvidia’s upcoming RTX 5090, which would be absolutely bonkers for a console launching around 2027. But before we get carried away, let’s dig into what’s actually being claimed and whether any of this makes sense.\n\nThe headline grabber here is the claim that Sony’s next console could pack an AMD “Orion” APU with up to 10 Zen 6 cores and a GPU sporting 52-54 compute units of RDNA 5 architecture. We’re talking about 34-40 teraflops of raw computing power, with ray tracing performance supposedly matching Nvidia’s upcoming RTX 5090. For context, that’s a graphics card that’ll likely cost more than an entire console when it launches.\n\nNow, before you start planning your 2027 gaming setup, let’s pump the brakes a bit. Console manufacturers are masters of creative accounting when it comes to performance claims, and these numbers feel aggressively optimistic. Sure, AMD will have advanced their architecture significantly by the time the PS6 launches, likely in late 2027, but matching flagship PC hardware while maintaining console pricing is a tall order.\n\nWhat feels more realistic is the continued evolution of Sony’s custom silicon approach. The PS5 already showed us how specialized chips like the Tempest audio processor can punch above their weight. Adding dedicated AI acceleration for upscaling and background tasks makes perfect sense, especially as technologies like FSR and DLSS become gaming staples.\n\nThe more mundane rumors actually carry more weight. Multiple sources suggest the PS6 will stick with the detachable disc drive model introduced with the PS5 Slim, acknowledging that physical media isn’t dead but isn’t exactly thriving either. There’s also chatter about a companion handheld device, which would be Sony’s second attempt at portable gaming after the Vita’s mixed reception.\n\nPricing speculation suggests Sony might be targeting aggressive numbers to compete with Microsoft’s next Xbox, which some leakers claim could cost significantly more. If true, that competitive pressure could force both companies to eat larger losses on hardware to win market share.\n\nThe reality check here is simple: we’re still years away from any official announcement, and development priorities can shift dramatically. These leaks paint a picture of Sony aiming for a generational leap that goes beyond typical console upgrades, but the gap between engineering ambition and manufacturing reality often tells a different story. Still, if even half of these claims pan out, PlayStation fans have plenty to get excited about.",
      "source": "Yanko Design",
      "url": "https://www.yankodesign.com/2025/09/14/sony-playstation-6-leak-heres-what-we-know-about-the-specs/",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "NVIDIA and OpenAI CEOs accompanying President Trump's UK state visit — major AI projects on the agenda",
      "content": "U.S. President Donald Trump is about to do something none of his predecessors have — make a second full state visit to the UK. Ordinarily, a President in a second term of office visits, meets with the monarch, but doesn't get a second full state visit.\n\nOn this one it seems he'll be accompanied by two of the biggest faces in the ever-growing AI race; OpenAI CEO, Sam Altman, and NVIDIA CEO, Jensen Huang.\n\nThis is according to a report by the Financial Times, which claims that the two are accompanying President Trump to announce a \"large artificial intelligence infrastructure deal.\"\n\nThe deal is said to support a number of data center projects in the UK, another deal towards developing \"sovereign\" AI for another of the United States' allies.\n\nThe report claims that the two CEOs will announce the deal during the Trump state visit, and will see OpenAI supply the technology, and NVIDIA the hardware. The UK will supply all the energy required, which is handy for the two companies involved.\n\nUK energy is some of the most expensive in the world (one reason I'm trying to use my gaming PC with an RTX 5090 a lot less!)\n\nThe exact makeup of the deal is still unknown, and, naturally, neither the U.S. nor UK governments have said anything at this point.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAI has helped push NVIDIA to the lofty height of being the world's most valuable company. (Image credit: Getty Images | Kevin Dietsch)\n\nThe UK government, like many others, has openly announced its plans to invest in AI. As the next frontier for tech, you either get on board or you get left behind. And President Trump has made no secret of his desires to ensure the U.S. is a world leader.\n\nOpenAI isn't the only company that could provide the software side, but it is the most established. While Microsoft may be looking towards a future where it is less reliant on the tech behind ChatGPT for its own AI ambitions, it makes total sense that organizations around the world would be looking to OpenAI.\n\nNVIDIA, meanwhile, continues to be the runaway leader on the hardware front. We've seen recently that AMD is planning to keep pushing forward, and a recent Chinese model has reportedly been built to run specifically without NVIDIA GPUs.\n\nBut for now, everything runs best on NVIDIA, and as long as it can keep churning out enough GPUs to fill these data centers, it will continue to print money.\n\nThe state visit is scheduled to begin on Wednesday, September 17, so I'll be keeping a close eye out for when this AI deal gets announced.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/artificial-intelligence/nvidia-and-openai-ceos-accompanying-president-trumps-uk-state-visit-major-ai-projects-on-the-agenda",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Linux 6.17-rc6 Released With VMSCAPE Mitigation, FLYDIGI APEX 5 Support & Fixes",
      "content": "The newest weekly test release of Linux 6.17 is now available as we work toward the stable kernel release around the end of September.Linux 6.17-rc6 was just released by Linus Torvalds. Pulled into Linux 6.17-rc6 is a fix to address some \"serious breakage\" around system hibernation support as a regression introduced in Linux 6.16. Fixes to both the Intel and AMD P-State drivers also landed this week as part of the Linux 6.16-rc7 material.Some new material for Linux 6.17-rc6 since it just amounts to new device/vendor IDs is FLYDIGI APEX 5 gaming controller support for those expensive game controller options.This week also saw the public announcement of VMSCAPE as a new CPU security vulnerability issue affecting both AMD and Intel processors . VMSCAPE mitigation support was merged to Linux Git upon embargo lift and also since back-ported to the stable Linux kernel series. Linux 6.17-rc6 has the mitigation if you aren't a daily Git rider.\n\n\"Things remain pretty calm, and for some reason this release seems to just not have a ton of problems. Hopefully I'm not jinxing it.\n\n\n\nIt might just have been people being on vacation in August (read: Europe) which has caused this release to be nice and calm, but whatever the reason I'm certainly not complaining.\n\n\n\nSomewhat unusually, almost a third of the patch is from filesystem fixes, but that seems to be pure coincidence: not because there are any particularly large fixes, but because we just happened to independently have fixes in several different filesystems (ceph, smb client, nfs, erofs, btrfs). So just random timing.\n\n\n\nAnother third is driver fixes (gpu being half of it, the rest being other random drivers), and the final third is just \"misc other stuff\": core networking, another CPU speculation mitigation, somedocumentation fixes, some selftest updates, and minor noise elsewhere.\n\n\n\nBut really, none of it is very large. So everything seems slated for a normal release in two weeks.\"\n\nLinus Torvalds wrote with the 6.17-rc6 announcement There are a lot of great features and improvements in Linux 6.17 with this stable kernel version hopefully coming out two weeks from today on 28 September.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.17-rc6-Released",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Select Qualcomm X Elite Laptops Seeing IRIS Video Acceleration On Linux",
      "content": "Adding to the list of feature caveats around the different Qualcomm Snapdragon X Elite laptops and the varying Linux state is video acceleration support. But patches were posted this week by a Linaro engineer enabling hardware accelerated video playback for two X Elite laptop models.Linaro engineer Stephan Gerhold posted the patches enabling IRIS video acceleration decoding for the X1 Elite Compute Reference Design (CRD) and the Lenovo ThinkPad T14s. The CRD support isn't too useful for consumers themselves. The Lenovo ThinkPad T14s continues to benefit as one of the best supported X Elite laptops under Linux with even having firmware files upstream in linux-firmware.git.The patches posted on Thursday add the IRIS video acceleration code for the DeviceTree used on the Qualcomm reference board as well as the Lenovo ThinkPad T14s. Besides the DT support, there is also an IRIS firmware requirement.These new patches for those having either X1E platform can find them on the LKML . In time hopefully the other popular X Elite laptop models will also see this support in place.It was back in Linux 6.15 earlier this year that the Qualcomm IRIS video decode driver was upstreamed . In initial form a V4L2 video driver with H.264 decode.\n\nIn case you missed it for more details on the recent X Elite Linux experience, see the recent tests in Qualcomm Snapdragon X Elite Linux Performance Improving But Short Of AMD Ryzen & Intel Core Ultra",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Qualcomm-X-Elite-IRIS-Video",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "HSBC Trims AMD Target Amid Revised Pricing Assumptions",
      "content": "Advanced Micro Devices, Inc. (NASDAQ:AMD) is one of the AI Stocks on Wall Street’s Radar. On September 9, HSBC analyst Frank Lee lowered the price target on the stock to $185.00 (from $200.00) while maintaining a Buy rating.\n\nThe lower price target comes after the firm revised its assumptions regarding AMD’s MI355 chip average selling price (ASP). The firm now estimates the price to be $23,000 rather than $25,000 per unit, calling it a more “prudent assumption given differential pricing for different customers.”\n\nThe firm’s revenue estimates are still above consensus estimates, it noted, stating that it continues to believe that the street is underestimating the pricing potential.\n\n“In our 10 July upgrade note Back in the AI game with a bang, we had highlighted that the pricing power of the MI355 might surprise the market and drive the upside potential in 2026e. The management also acknowledged a significant pricing uplift from MI325 in its latest earnings call. We slightly revise down our ASP estimates from USD25k to USD23k as we believe that it is a more prudent assumption given differential pricing for different customers.\"\n\n\"Driven by our revised ASP assumptions, we lower our 2026e AI GPU revenue estimates from USD15.1bn to USD13.9bn, still 20% above consensus estimates as we continue to believe that the street is still underestimating the pricing potential. Additionally, we expect most CSPs including Meta, Microsoft, Oracle, and xAI are starting to enter the testing phase with the MI400 rack solution, with results potentially by 4Q25 or early 1Q26. Hence, we expect to see better order visibility emerging by 1Q26 regarding MI400 revenue potential.”\n\nAdvanced Micro Devices, Inc. (NASDAQ:AMD) develops and sells semiconductors, processors, and GPUs for data centers, gaming, AI, and embedded applications.\n\nWhile we acknowledge the potential of AMD as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 10 AI Stocks In The Spotlight For Investors and 10 AI Stocks on Wall Street’s Radar.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/hsbc-trims-amd-target-amid-000337435.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Enthusiast builds entire PC setup with Lego-style bricks — Includes desktop terminal-style OLED monitor & keyboard, with an iPhone 6-powered desk clock",
      "content": "We all start somewhere in our PC building journey, but seldom does an opportunity present itself to make our first system as unique as u/OkDebate6649. That's exactly what happened with the aforementioned Reddit user who built his computer literally brick-by-brick using Lego. Known as \"Choi,\" our resident enthusiast took Lego-style bricks and made not only a full PC case, but also a monitor featuring an OLED panel, along with a mechanical keyboard — desktop terminal style.\n\nOne of the best parts is that this was Choi's first-ever custom PC, as he's only used pre-builts before this. You might think that he's some sort of Lego master builder, but he has no prior experience in that department either. In fact, the only reason he even got his hands on Lego in the first place was to hit the minimum requirement for a discount while shopping online. Once he got the bricks, though, he quickly figured this would make for a fun experiment and got to work.\n\nChoi worked on the case, the monitor and the keyboard separately. Speaking to PC Gamer, he described how everything was constructed with modularity in mind. The monitor, which uses a 1080p OLED panel from AliExpress, is enclosed inside a custom body fully built from Lego. That frame can then attach to a similar keyboard housing and form a desktop terminal, akin to the Apple II. Not only that, but the case itself can be connected below the monitor.\n\nImage credit: u/OkDebate6649 on Reddit Image credit: u/OkDebate6649 on Reddit\n\nChoi has posted his escapades across different subreddits; we embedded the most detailed post above where he showcases the build from the inside. As you can see, there's no dedicated GPU in there — the PC is powered by a Ryzen 5 5600G because Choi is sacrilegiously a PlayStation gamer and only needs this PC for office work. That 5600G is paired with equally-modest hardware like 16GB of memory, a basic ITX motherboard, and an AMD stock cooler. The build has two 120mm fans mounted externally for air intake.\n\nImage credit: u/OkDebate6649 on Reddit Image credit: u/OkDebate6649 on Reddit Image credit: u/OkDebate6649 on Reddit\n\nNow, what if the transforming desktop terminal and the PC case were to get together and have a baby? Thankfully, our curious tinkerer has thought ahead and already made a \"retro Commodore-style monitor case.\" Details on this project are scarce, but Choi has used a 4:3 monitor and put it inside a custom Lego housing that can also fit an entire PC in there. There's a USB hub up front, too, for quick access. Unlike the 5600G build, though, this one has space for a dedicated GPU, but Choi is only using it as a secondary monitor for now.\n\nThe DIY madness doesn't stop here, either. Clearly, Choi loved the Lego theme and ran with it even further, building projects like a desk clock powered by an iPhone 6, an audio deck made to look like an old radio, and also a Lego mouse that we spotted in the pictures, which Choi never mentioned in the text. Everything is neatly placed in the corner of a room, encapsulating the perfect Lego setup. Sure, there's no high-end hardware powering this stuff, but the ingenuity behind this is far beyond anything extra money alone could buy.\n\nImage 1 of 3 (Image credit: u/OkDebate6649 on Reddit) (Image credit: u/OkDebate6649 on Reddit) (Image credit: u/OkDebate6649 on Reddit)\n\nChoi had no prior experience with custom PCs or Lego, yet he somehow ended up combining the best of both worlds to create something truly unique. It's a testament to the creative child that lives within all of us, and how easily that spark can surface when we let go of preconceived notions about what’s “too difficult.\" What starts as a fun diversion can turn into something special very quickly. If you're interested in DIY creations like this, make sure to check out these Joycon-style Steam Deck controllers, or the time someone made their entire PC out of cardboard.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/desktops/pc-building/enthusiast-builds-entire-pc-setup-with-lego-style-bricks-includes-desktop-terminal-style-oled-monitor-and-keyboard-with-an-iphone-6-powered-desk-clock",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Dave & Buster's (PLAY) Q2 Earnings: What To Expect",
      "content": "Arcade company Dave & Buster’s (NASDAQ:PLAY) will be announcing earnings results this Monday afternoon. Here’s what you need to know.\n\nDave & Buster's met analysts’ revenue expectations last quarter, reporting revenues of $567.7 million, down 3.5% year on year. It was a slower quarter for the company, with a significant miss of analysts’ EPS estimates and a slight miss of analysts’ same-store sales estimates.\n\nIs Dave & Buster's a buy or sell going into earnings? Read our full analysis here, it’s free.\n\nThis quarter, analysts are expecting Dave & Buster’s revenue to grow 1% year on year to $562.7 million, slowing from the 2.8% increase it recorded in the same quarter last year. Adjusted earnings are expected to come in at $0.92 per share.\n\nDave & Buster's Total Revenue\n\nHeading into earnings, analysts covering the company have grown increasingly bearish with revenue estimates seeing 3 downward revisions over the last 30 days (we track 9 analysts).\n\nLooking at Dave & Buster’s peers in the leisure facilities segment, some have already reported their Q2 results, giving us a hint as to what we can expect. AMC Entertainment delivered year-on-year revenue growth of 35.6%, beating analysts’ expectations by 3.1%, and Live Nation reported revenues up 16.3%, topping estimates by 3.4%. AMC Entertainment traded up 4.6% following the results while Live Nation was also up 3%.\n\nRead our full analysis of AMC Entertainment’s results here and Live Nation’s results here.\n\nThere has been positive sentiment among investors in the leisure facilities segment, with share prices up 7.6% on average over the last month. Dave & Buster's is down 7.4% during the same time and is heading into earnings with an average analyst price target of $32.71 (compared to the current share price of $23.70).\n\nUnless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.\n\nStockStory is growing and hiring equity analyst and marketing roles. Are you a 0 to 1 builder passionate about the markets and AI? See the open roles here.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/dave-busters-play-q2-earnings-030056656.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "【ゲーム】『ドラクエ7』リメイク発表！　おれ6がダントツで好きなんだけど異端扱いされるんだよな",
      "content": "異端といえば9じゃない？\n\n批判されてるのは転職システムと特技みたいなゲーム的な部分\n\n大丈夫俺もドラクエの中だけじゃなく全てのゲームの中でドラクエ６が一番好きだから\n\n丁寧につくってさすがドラクエとは思ったけどそれだけやな、\n\n1 名前：muffin ★[] 投稿日：2025/09/13(土) 02:35:45.85 ID:kBTir7eb9.net9/12(金) 22:36任天堂は12日、ゲームの新情報を発表する番組『Nintendo Direct』（ニンテンドーダイレクト）をYouTubeなどで配信した。Nintendo Switch、Switch2ソフトとなる『ドラゴンクエスト7』のリメイク『ドラゴンクエストVII Reimagined』が発表され、来年2月5日に発売される。『ドラクエ7』は、2000年8月26日にプレイステーションで発売され、その斬新な世界観や圧倒的なボリュームのストーリーが話題となった『ドラゴンクエストVII エデンの戦士たち』が原作。ニンテンドー3DSでも、その後発売された人気タイトルになっている。物語のはじまりは、世界にたったひとつしかない島「エスタード島」から。この島で暮らす主人公とその友達・キーファの日課となっていた島での探検がきっかけとなり、冒険の舞台は誰も見たことがない“新たな世界”へと一気に広がっていく。たどり着いた異世界では、エスタード島にはいなかった存在、モンスターの姿が。さらに、冒険で行きつく先ではさまざまな人物やダンジョン、そして強敵たちが主人公たちを待ち受けている。リメイク版『ドラゴンクエストVII Reimagined』は、グラフィックだけではなく、シナリオ、バトル、寄り道要素、システム面、すべて一から再構築。バトルの要となるのが職業システムも、各職業に固有の「職業とくせい」があり、バトル中にバーストチャージという状態になると、「職業とくせい」を発動させることができる。冒険をすすめると職業の「かけもち」が解放され、同時にふたつの職業につけるように。呪文や特技、職業とくせいもふたつ分に増えるので、パーティの戦力も大幅にアップしていく。動画ドラゴンクエストVII Reimagined [Nintendo Direct 2025.9.12]https://www.youtube.com/watch?v=NV70S9CI91chttps://newsatcl-pctr.c.yimg.jp/t/amd-img/20250912-00052276-famitsu-000-2-view.jpghttps://newsatcl-pctr.c.yimg.jp/t/amd-img/20250912-00000034-impgmw-000-2-view.jpg他記事「石板探しは楽になっていますよ」堀井雄二氏がリメイク『ドラクエ7』について語る。人形を3Dスキャンして制作、シナリオを再編し新エピソード追加もhttps://www.famitsu.com/article/202509/52327https://cimg.kgl-systems.io/camion/files/52327/thumbnail_ACsb.jpg98 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 03:53:43.65 ID:qu1H82kB0.netおれ6がダントツで好きなんだけど異端扱いされるんだよな1番面白いしキャラもストーリーもいいと思うけど101 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 03:59:16.10 ID:auwNNk1N0.net>>98俺も面白いと思ったけど、何故かまたやりたいみたいな気持ちにならなかった3とか4はまたやりたくなる何かがあった103 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 04:00:38.67 ID:jrFVYJsf0.net [3/3]>>98108 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 04:03:55.29 ID:IeNa05wo0.net [3/5]>>98特技が強すぎてイオナズンの出番がなかった記憶109 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 04:05:49.71 ID:NJX0vcyu0.net [5/7]>>98キャラもストーリーもいいけど142 名前：名無しさん＠恐縮です[sage] 投稿日：2025/09/13(土) 04:49:45.28 ID:LGMzNh9n0.net [1/3]>>98250 名前：名無しさん＠恐縮です[] 投稿日：2025/09/13(土) 06:03:47.80 ID:0IbAWgx/0.net [3/3]>>98333 名前：名無しさん＠恐縮です[sage] 投稿日：2025/09/13(土) 06:54:36.23 ID:jorSawUN0.net [2/11]>>98９と10以外はみんな面白さがあるからランキングする必要もないちょっとしたゲームバランスの差でしかない",
      "source": "Livedoor.biz",
      "url": "https://honwaka2ch.livedoor.biz/archives/10926150.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Has Nvidia Lost Sight of the Core Consumer?",
      "content": "As seen in the above, datacenters made up a significantly smaller portion of NVDA's revenue prior to 2021 and the focus was on their core consumer grade gaming segment. However, with the popularization of generative AI tools like DALL-E and Chat-GPT by OpenAI in 2021 which sparked a race among the top tech companies to invest in and create the best generative models as a result we saw a more than 3x surge in AI investment market-wide between 2019 and 2021 which has since come to a plateau following a huge spike in 2021, after many of these companies including Microsoft and Google announced that they would be slowing down on their AI related spending and/or exploring in-house solutions to save on CapEx.\n\nBut today, It's all about AI and enterprise contracts. The headlines out of their most recent CES keynote weren't about consumer-grade GPUs or gaming, they were about new datacenter products and AI reasoning models with names like Nemotron and Llama in focus rather than the standard consumer power focused terms like CUDA and RTX. The everyday consumer will have minimal to no practical use for these AI reasoning models displayed by NVDA yet this was the focus of the showcase and really put things into perspective for me that NVDA seems to be abandoning its core consumer base in favor of satisfying its newly found AI enterprise markets. It was not so long ago that gaming was NVDA's top revenue source as detailed here in their 2021 Annual 10k filing;\n\nIn the past, NVIDIA events were all about Productivity, Games, GPUs, and Raw graphics horsepower aimed at consumer interests like pushing frames per second higher, powering better visuals, improving encoding performance, power efficiency, and exciting the consumer base by which Nvidia's $4 trillion foundation was built upon.\n\nVery little attention was given to the Next-gen consumer focused RTX-50 series graphics cards during the showcase. I found this to be disappointing because this was at an annual event meant to showcase Consumer Electronics, yet Nvidia consumers essentially took a backseat to all of these more Enterprise focused AI products/concepts.\n\nAt the start of 2025, there was a lot of optimistic chatter about what Nvidia's stock might do during this year's Central Electronics Showcase. Thinking back to this timeline it almost seemed as if every headline, every social media post, and the majority of online commentary surrounding Nvidia's CES press conference focused on Nvidia forwarding their growth in AI markets ranging from: AI PCs built for developers to more efficiently run LLMs, AI powered Robotics platforms, and their partnerships with various players within the Autonomous Automobile industry such as Toyota and Tesla.\n\nStory Continues\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Quid & Stanford University: 2025 AI Index\n\nThis AI investment surge has been congruent with the recent trend in NVDA's datacenter segment overtaking their gaming segment by an exponentially wide margin as seen a more recent 10k filing:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nIt is worth noting however that the corporate investments into AI only began to plateau in 2021-present, during this time we saw the top companies in the industry collectively aim to reduce their AI CapEx spend was also in alignment with the start of a sharp continuous decline in US Consumer Sentiment as released by the University of Michigan:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nFurthermore, this decline in consumer sentiment has not only been observed in the US but China as well as China Consumer Sentiment has nose-dived to and even further extent during the same period;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Organization for Economic Co-operation and Development via FRED\n\nThis sudden decline in the consumer sentiment has led to the pulling of investment capital not just in AI as detailed earlier, but also in adjacent industries like EVs;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: IEA\n\nI have referenced the chart above in a previous article, which delves into my concerns revolving around a recent slowdown in TSLA Cash Flows. If TSLA keeps going on the path that it currently is, their Non-adjusted Free Cash Flows will once again turn negative. Given that TSLA is one of NVDA's top B2B customers, I see this as a worrying trend as this has all aligned with the drop in consumer sentiment starting in 2021.\n\nEven as big tech investment into AI pulls back and the consumer sentiment declines, we can still see an exponential growth in the amount of newly funded Generative AI companies popping up on the frontend.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: Quid & Stanford University: 2025 AI Index\n\nThese newfound startups could find themselves entering into what was a booming industry, now entering a cooldown period, if that's the case these companies will be unlikely to find success in chasing the Gen-AI trend now as the CapEx liquidity once provided to this industry by big tech players dries up.\n\nConcerningly, when evaluating NVDA's 2025 annual 10k filing it can be seen that 34% of this newfound revenue came from only three of their direct enterprise customers;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nThough Nvidia did not name their customers directly, it can be inferred through Omida Research's Q32023 report of H100 Shipments that NVDA's top customers were Microsoft, Meta, Google, and Amazon with notable business from TSLA, Oracle, Tiktok, and CoreWeave.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nGiven that many of these customers are the same companies that have begun to cut back on external AI CapEx spending, likely in alignment with the fall of the consumer, it is very likely that NVDA sees an exceptionally greater direct hit in not only their profit margins but also their total revenue as these companies seek internal solutions and competition from potentially more balanced companies such as Intel enters the fray.\n\nThe goal of many of these companies are to balance capex spend with their revenues and right now they are focusing on creating the best product for their core consumer base to fall back on, as these companies reduce spending, develop in-house solutions, or find better and most likely cheaper competitors to NVDA, we will see more and more of NVDA's overly focused B2B model dwindle. In times like these it would be great for NVDA to not only have a functioning B2B base but to also maintain its base consumer as a foundation to fall back on in hard times just some of NVDA's most successful corporate customers do, but in the effort to chase a growing AI trend NVDA has lost sight of that foundation and is leaving itself open to a massive pull of liquidity. The time may soon be coming when a company such as NVDA would want to have a strong consumer base to fall back on because as of now when reading into NVDA's QoQ Net Margins, a peak can already be observed, rounding down since the start of 2024 with a declines being experienced the in Q2, 2025.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MicroTrends.net\n\nThe last time we experienced any such decline in margins like this was at the start of 2022 which proceeded a 62% drop from $28.95 a share to $10.81 near the 89-month EMA all within the same year. If things were to go similarly this time around we could experience a similar 60-70% decline to around $50 per share aligning with the 89-month EMA in white.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: TradingView\n\nNVDA currently trades at a 57x multiple with a $3.15 EPS, I'd suspect that NVDA has the capacity to correct down to around a 15-20x multiple If it experienced a severe repricing due to its AI endeavors being priced out by the market and there's even the risk of EPS going down due to falling margins. If EPS drops significantly to $1.15, setting it back a year a 20x multiple of that would align with NVDA trading down to $23 a share in the coming months.\n\nIntel: Back to the consumer\n\nIntel, is taking the opposite approach of Nvidia.\n\nAt CES 2025, Intel rolled out its Core Ultra 200 series processors. These cover everything from thin-and-light laptops to high-performance desktops. Unlike Nvidia's corporate-heavy pitch, Intel's message was simple: more power, less energy, and prices that make sense for consumers.\n\nThe Core Ultra 200HX and H series aims to bring serious improvements to creators and gamers, better multi-thread performance, integrated Arc graphics, and even built-in NPUs for AI acceleration. The 200U series targets mainstream laptops, while the 200S series brings efficient yet power a high 16-20+ core count 125-watt chips to desktops.\n\nIntel is also targeting the mobile and notebook space directly, going up against Qualcomm and ARM and unlike Nvidia, Intel manufacture the majority of its chips in the United States. This puts them ad a great advantage when it comes to managing the ongoing tariffs and is likely to Nvidia heavy reliance on TSMC for production and Samsung for memory chips, which puts Nvidia in the crosshairs of these tariffs in which U.S based and sourced companies such as Intel and Micron could greatly benefit.\n\nAs NVDA has shifted its focus away from the consumer INTC has been aggressive in building its product lineup in the favor of the consumer and it really shows when looking at the chart of the historic video card market share:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: PassMark\n\nThe data here shows that NVDA's consumer video card market share dropped from 61.8% in 2022, to 54.2% in 2025, AMD remained stagnant, and during the same period, Intel's share rose from 16.1% to 21%.\n\nObserving the chart, it would appear that NVDA's market share is on a downwards trajectory with more declines likely as competition, mainly the now pro-consumer focused Intel continues to gain ground within NVDA's lost, yet core industry as Intel's product lineup right now puts the core consumer base first and remains easily accessible. Unlike NVDA, INTC is not talking about abstract AI models with gimmicky names that sound like they were ripped out of some sci-fi film; they're instead talking about battery life, power efficiency, security features, and real improvements that everyday people will notice when they buy their next laptop or desktop.\n\nA familiar trap?\n\nIn many ways, this is reminiscent to when Microsoft fumbled with the new generations of Xbox with the Kinect. Microsoft had a winning product in the Xbox 360 but got distracted by the gimmicks introduced with the Kinect, focusing on getting rid of the traditional controller in favor of motion controls, becoming an all in one media hub, and enforcing always online requirements for Xbox One with Kinect; a practice none of the consumers ever approved of yet Microsoft pushed it for years. It seems likely that Microsoft's obsession with motion controls came from their desire to chase after the success of the Nintendo Wii, which released in 2006, introduced motion controls to the masses, and ended up being the best-selling seventh generation console of that generation by far.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nBut by the time the eighth generation rolled in, the novelty of motion controls had long played it course and that was made very apparent with the fall in the Nintendo Wii's yearly sales as well as to complete failure of the Wii U.\n\nDuring the start of the eighth generation in 2013, we would see Sony, with its PS4 release, focus on games and gamer alike, showcasing pro-consumer features such as game sharing along with the ability to play games without the need of an internet connection; all backed by a strong lineup of game releases to boot. Sony did all of this and even took direct jabs at Microsoft, their competition, who was not then concerned with these pro-consumer moves at the time. Despite these open jabs from Sony, Microsoft would carry on with its anti-consumer practices in favor of the Kinect as it continued to push the all-in-one media hub features which was likely an attempt to compete with the then trending streaming markets, as well as pushing the motion controls which was a dying fad. As a result, a new trend would emerge of yearly PS4 sales consistently being double that of Xbox One sales;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nOne year later the CEO of Microsoft would appoint Phil Spencer as the new head of Xbox who then would undo the anti-consumer practices set in motion by the previous head, Don Mattrick, starting with the unbundling of the kinect and a more consumer friendly approach to gamer by offering backwards compatibility, and reverting back to the brand's roots; Unfortunately it was too late as the previous leadership had already sullied the brand's relationship with its core customer base and many of those that might have considered coming back to Xbox were already comfortably on PlayStation and later on, thanks to a much improved marketing campaign, Nintendo Switch; the result of Xbox's previous years of not focusing on the core consumer and even antagonizing the consumer at times made it very tough to take back market share against Nintendo and Sony, which remained, focused on their core gaming audience throughout.\n\nEven all these years later in the ninth generation of consoles, as Microsoft has spent the last 13 years reversing course on all of these anti-consumer practices, they remain significantly behind Nintendo and Sony generations later as the consumer base has already settled within their perspective ecosystems and winning them back has proven to be very hard for Microsoft to do with PS5 sales now being triple that of Xbox Series X/S.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: VGChartz\n\nNvidia risks falling into the same trap: chasing enterprise AI hype while forgetting about the consumer market that made it a household name in the first place and in time of economic slowdown Nvidia will need to lean back on this core base but by the time they do another competitor would have likely scooped up a significant portion of this core base and just like Microsoft with the Xbox, it could take years before Nvidia can rebuild all of that lost consumer trust.\n\nValuation Overview:\n\nWhen taking in account NVDA's slowdown in profit margins mainly attributed to the slowdown in enterprise revenue paired with their loss in market share to INTC within the consumer base, it makes sense to consider INTC as the alternative investment to NVDA. Despite INTC's recent shaky history of EPS misses, it is worth considering the fact that the stock price trades at a very low price to sales multiple of 1.98x:\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nThis low price to sales value contrasts with NVDA's which currently trades at a 25.95x multiple to its sales;\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nThis in my opinion is a massive oversight in the market that shows speculative growth being priced into NVDA while ignoring the current actual contraction NVDA is currently facing, as a result, the comparison of these ratios tells us that sales growth is failing to keep up with the high speculative valuations of the current market.\n\nMeanwhile the market has severely undervalued INTC, not taking into consideration the fact that it is currently gaining a significant core market share against NVDA and AMD alike in a trend that seems likely to continue.\n\nLooking into other valuation data we can also see that INTC trades at a 1.01x book value which ultimately confirms that despite INTC's recent growth, the stock market still hasn't priced in any growth at all within the company which means that the stock is currently at its fairest value right now.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nMeanwhile when looking at NVDA's price to book we can see that in spite of recent contractions, the market is still valuing NVDA's stock at a 42.33x multiple to its book value.\n\nHas Nvidia Lost Sight of the Core Consumer?\n\nSource: MacroTrends\n\nTaking in the totality of the data it would be in my opinion a valuable opportunity to capitalize on the arbitrage between NVDA and INTC's valuation and performance by investing long term into INTC rather it be shares or Long Call LEAPS (1 year or more of theta), while reducing share allocation or even buying some longer dated 300+ DTE OTM puts in NVDA or at least hedging current long positions in NVDA more aggressively with covered calls. As this arbitrage closes, I would anticipate NVDA's market cap valuation to contract while INTC's expands, narrowing the current spread between NVDA's $4.4T and INTC's $100B market cap valuations.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-lost-sight-core-consumer-185126232.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "GIGABYTE X870 Eagle WIFI7 AMD AM5 LGA 1718 Motherboard $199.99 + Free Shipping (1 replies)",
      "content": "Deal History includes data from multiple reputable stores, such as Best Buy, Target, and Walmart. The lowest price among stores for a given day is selected as the \"Sale Price\".\n\n\n\nSale Price does not include sale prices at Amazon unless a deal was posted by a community member.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18603412-gigabyte-x870-eagle-wifi7-amd-am5-lga-1718-motherboard-199-99-free-shipping",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "SoundHound AI (SOUN) Stock Trades Up, Here Is Why",
      "content": "What Happened?\n\nShares of voice AI technology company SoundHound AI (NASDAQ:SOUN) jumped 2.1% in the afternoon session after it received continued positive commentary from Wall Street analysts.\n\nThe move follows several bullish actions, including DA Davidson analyst Gil Luria maintaining a \"Strong Buy\" rating and increasing the price target from $15 to $17 on September 10. Additionally, Wedbush's Daniel Ives reiterated a \"Buy\" rating on September 11. This optimistic analyst sentiment is supported by the company's strong performance, with a recent report noting that SoundHound AI's revenue tripled in the second quarter compared to the previous year. The company's voice AI platform has now surpassed 1 billion queries per month, positioning it to capitalize on the growing use of AI in devices, cars, and homes.\n\nAfter the initial pop the shares cooled down to $14.37, up 1.8% from previous close.\n\nIs now the time to buy SoundHound AI? Access our full analysis report here, it’s free.\n\nWhat Is The Market Telling Us\n\nSoundHound AI’s shares are extremely volatile and have had 92 moves greater than 5% over the last year. In that context, today’s move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.\n\nThe previous big move we wrote about was 5 days ago when the stock dropped 4.9% on the news that markets pulled back, reversing early gains, as investor sentiment remained cautious despite a softer-than-expected inflation reading.\n\nStocks rose in the morning session after an unexpected drop in the Producer Price Index (PPI) for August signaled easing inflation and raised expectations for a potential Federal Reserve interest rate cut. The U.S. Bureau of Labor Statistics reported that the PPI, which measures wholesale prices, edged down 0.1% last month, contrary to analyst expectations for a 0.3% rise. This data gives the Federal Reserve more flexibility to consider lowering interest rates to stimulate the economy.\n\nSoundHound AI is down 28.7% since the beginning of the year, and at $14.37 per share, it is trading 40.7% below its 52-week high of $24.23 from December 2024. Investors who bought $1,000 worth of SoundHound AI’s shares at the IPO in April 2022 would now be looking at an investment worth $1,915.\n\nUnless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/soundhound-ai-soun-stock-trades-183609103.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "\"Some need to learn how their PCs work\" — Borderlands 4 head fires back as optimal settings for 68 GPUs released",
      "content": "Borderlands 4, the latest looter-shooter in the beloved series from Gearbox Software, launched on September 11, 2025. Less than a week later, it's sitting at a \"Mixed\" review score on Steam with more than 16,500 entries. The prevailing issue forcing the review score down? Dreadful PC optimization.\n\nThe game's developer has now released a couple of lengthy PC optimization guides for both NVIDIA and AMD GPUs (via Videocardz). There are 68 different GPUs listed, with optimal settings for 1080p, 1440p, and 4K resolutions. NVIDIA's cards range from the RTX 2070 to the mighty RTX 5090, while AMD's cards range from the RX 5700 XT to the RX 9070 XT.\n\nUnless you're using an RTX 3060 Ti or newer, you can expect about 30 FPS at 1080p. For 1440p, you'll want at least an RTX 3070 Ti to run the game at 30 FPS. Want to play at 4K? You'll want at least an RTX 3090 Ti to hit 60 FPS.\n\nBorderlands 4's poor PC performance doesn't sit well with gamers\n\nA look at recommended NVIDIA GPU settings for playing Borderlands 4 at 1440p. (Image credit: 2K Games)\n\nMy current GPU, NVIDIA's RTX 5070 Ti, is listed under the 4K section. In order to achieve 60+ FPS, I'll need DLSS 4's Multi Frame Generation cranked up to 4x with texture quality set to Medium (and many other settings dropped to Low).\n\nIf I want to hit 60+ FPS at 1440p, I'll still need DLSS MFG 4x, though textures and other quality can be cranked up a bit. I think perhaps I'll wait a bit longer before trying the game to see if any more performance updates are released.\n\nDespite knowing months ahead of launch that Borderlands 4's PC specs were very demanding — more than 50% of Steam users may need an upgrade to play the game, at least judging by Steam's frequent hardware surveys — players are trashing the game for its brutal performance.\n\nPoor optimization and PC performance were topics of our Borderlands 4 review.\n\nDespite playing the game on an NVIDIA RTX 3080 and AMD Ryzen 9 5900X — older hardware that should nevertheless be relevant today — our reviewer experienced some brutal performance woes that mostly continued after a patch.\n\nTerrible, terrible performance. Worst I've ever seen. Turned it down to Low graphics preset and couldn't hit 60 FPS, even with FSR upscaling on my RX 6900 XT. Steam user \"Etiko\"\n\nRandy Pitchford, CEO of Gearbox Software, hasn't been shy about stating his case for Borderlands 4's performance. The game, which runs on the controversial Unreal Engine 5, is demanding, and Pitchford says gamers need to come to terms with lowering the resolution or in-game settings to achieve stability.\n\n\"Borderlands 4 is a premium game made for premium gamers,\" said Pitchford in an X reply to a gamer struggling to play on older hardware.\n\nThe minimum and recommended specs are published. The most common hardware is a four year old cell phone. Borderlands 4 is a premium game made for premium gamers. Just as Borderlands 4 cannot run on a PlayStation 4, it cannot be expected to run on too-old PC hardware. Unlike on…September 13, 2025\n\nConsidering NVIDIA's RTX 3060 and RTX 4060 GPUs continue to hold the top spots on Steam's GPU survey list, many players are struggling to come to terms with how a AAA game can launch at a $70 price tag and run so poorly.\n\nOn the other side of the hardware fence, console players have bemoaned the lack of an FOV slider and a motion blur toggle. Considering that both of these common settings can directly contribute to motion sickness, it's not a good look for Gearbox.\n\nIf you are indeed one of Borderlands 4's launch adopters, I recommend giving the recommended GPU specs laid out by Gearbox a shot. At this point, any extra frames are appreciated.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/gaming/pc-gaming/borderlands-4-official-amd-nvidia-gpu-settings",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "AMD Continues Enhancing AMDGPU/AMDKFD Drivers For Checkpoint/Restore",
      "content": "CRIU is for Checkpoint/Restore in Userspace to be able to freeze a running container or app, preserve its state to disk, and later restore said running workload. A few years ago we saw AMD working on being able to checkpoint/restore running ROCm workloads . As seemingly the first work in a while on the matter by the AMDGPU/AMDKFD kernel drivers, there are some new CRIU elements coming for Linux 6.18.Last week's AMDGPU pull request of additional material for Linux 6.18 adds CRIU support for GEM memory management objects. CRIU support for GEM objects is also added to the AMDKFD compute kernel driver.As part of the CRIU support for GEM objects to AMDGPU and AMDKFD drivers, there is a new user-space API for handling it. Over in user-space is this pending CRIU pull request for DMA-BUF IPC support on AMDGPU.\n\nIn addition to this new AMD CRIU activity, this pull request brings UVD and DPM fixes for aging Southern Islands graphics cards. That work for the aging AMD Southern Islands GPUs is important as part of enhancing the GCN 1.0 and GCN 1.1 support on the AMDGPU driver as an alternative to the default Radeon DRM driver.Plus this pull request has more updates for Cyan Skillfish, continued user-queue \"UserQ\" work, exposing the vBIOS build number to user-space via sysfs, eDP updates, and various other fixes.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/AMDGPU-CRIU-Linux-6.18",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "The best \"Steam Deck killer\" launched months ago, but you still can't buy this Windows 11 handheld — are tariffs to blame for another fumbled competitor?",
      "content": "A new trend in PC gaming was popularized by Valve's excellent Steam Deck, a handheld option that brought console-style convenience to the masses who wanted to play titles locked to the platform, whether that's via Steam or any other storefront. I have my own, and it remains a huge part of my almost-daily gaming routine, but its Linux-based presentation is starting to be overshadowed by Windows-based alternatives.\n\nFirst, the ASUS ROG Ally showed promising signs of supporting Microsoft's operating system in a package that could challenge Valve's leading handheld. It was even one-upped internally by its bigger brother, the highly praised ROG Ally X. However, the original, with its AMD Ryzen Z1 Extreme processor, stuck with me for months as a viable Steam Deck alternative. That is, at least, until I got my hands on the MSI Claw 8 AI+ and fell in love with it.\n\nMSI dared to pass on AMD's offerings as it already enjoyed total domination, its earlier chips appearing in the Steam Deck, and Ryzen Z1 variants appearing in Lenovo's 'Nintendo Switch-esque' Legion Go. Instead, the Claw would use Intel's mobile chips, starting with codenamed Meteor Lake processors in the previous generation Claw 7 A1M and refreshed with Lunar Lake versions in the Claw 8 AI+. It all sounds fantastic, but there's a glaring issue — you'll hardly ever find the thing in stock.\n\nRunning fast and cool, the MSI Claw 8 AI+ proved that Intel Arc graphics are more than capable, if expensive. (Image credit: Rebecca Spear / Windows Central)\n\nIt's an axe I'll grind down to the handle, because it'll always frustrate me. The high-scoring MSI Claw 8 AI+ should have seen a few price-reducing deals by now, bringing it to a more realistic cost that resembles the post-$100 savings that ASUS has previously bestowed upon the ROG Ally X — but that's not the case — in fact, it's much worse than that.\n\nEvery week, I'll check on the MSI Claw 8 AI+ at Best Buy to see that its $999.99 price tag hasn't budged. Not only that, but the availability tracker sticks with an unmoving \"Sold Out\" message despite a handful of user reviews that suggest people have been lucky enough to bag one from this prominent retailer in the past, and they seem similarly happy with it.\n\nMSI Claw 8 AI+ $999 at Amazon Check Walmart It's the best Windows-based PC gaming handheld I've ever tested, but the Claw 8 AI+ is so consistently out of stock that it's almost impossible to recommend.\n\nThen again, if you pay over the odds, Walmart might hook you up for a Claw 8 AI+ at $1,249, but it's via a third-party seller, not the store itself. It's the same story at Amazon US; either it's stocked with an inflated price by a third-party seller, or it's completely invisible. Even a $999.99 listing at the official MSI US digital store can offer to notify you of restocks, but it can't sell you a Claw 8 AI+ today. At this point, it's a struggle to recommend it.\n\nNow, sometimes you might see something in stock alongside the elusive Claw 8 AI+, and it might seem like my complaints are unnecessary when you see it. However, the \"MSI Claw 8 AI+ A2VM Polar Tempest Edition\" (yes, it's a mouthful) is little more than a white recolor with a higher price tag. It was supposed to launch with a 2TB variant for more game storage, but at least for now, it's just a $25 price hike to replace the unique \"Sandstorm\" shade of the original.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe Polar Tempest Edition should have offered a 2TB SSD, but I've yet to see one in stock. (Image credit: MSI)\n\nPrice and availability problems keep coming back to the topic of tariffs, which has probably been the hottest topic in tech throughout 2025. We already saw the MSI Claw 8 AI+ and the Claw 7 AI+ increasing their price by $100 back in April this year, and neither has dropped back to their previous MSRP listings since. Raising the price is one thing, but if it isn't paired with any solutions for issues surrounding supply and demand, then what's the point? Even if the Claw returned to its previous price, there's no guarantee that any stock would follow.\n\nRaising the price is one thing, but if it isn't paired with any solutions for issues surrounding supply and demand, then what's the point?\n\nIt's mostly frustrating because I see a lot of generic, boilerplate responses from brands when inquiring about sudden component changes or reductions in their hardware categories, never wanting to point the blame directly at import/export tariffs. That, and I have to temper my expectations for modern-day gamers who are constantly mocked by gaming hardware that bloats its prices far above any intended MSRP, particularly with GPUs. The MSI Claw 8 AI+ is not a budget handheld gaming PC by any stretch of the imagination.\n\nThe MSI Claw 8 AI+ still deserves its 'best' award, even if you might never find one. (Image credit: Windows Central | Rebecca Spear)\n\nOn the other hand, the Claw 8 AI+ is the best Windows handheld I've ever used. It ran everything; I couldn't find anything in my Steam library (or GOG, Epic Games Store, etc) that it wouldn't shred. That, and it did it all without raising the fan noise, an ode to Intel's success with Lunar Lake's much-professed efficiency bump for its mobile processors.\n\nSure, it had its downsides, mostly related to software gripes and other issues that could be fixed with patches, but none of them detracted from my gaming enjoyment.\n\nI could spend all day praising MSI and Intel's partnership, but again, if you can't buy the thing, then who cares? I wanted to see Lunar Lake devices thrive, and some may have, but it still feels like the Claw 8 AI+ redeemed all of its predecessors' missteps for ultimately no reason. These days, I'm more eagerly awaiting the AMD-based ROG Xbox Ally X and its (presumably) similarly premium price point — which is fine, but it's still a shame to see a competitor fall off.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/handheld-gaming-pc/the-best-steam-deck-killer-launched-months-ago-but-you-still-cant-buy-it",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "\"NVIDIA violated the anti-monopoly law\" — China's ongoing investigation digs up antitrust violations as trade tensions mount",
      "content": "NVIDIA, the US company supplying most of the world with GPUs built specifically for powering AI, finds itself once again at odds with Chinese authorities.\n\nFollowing a preliminary investigation into the matter, Chinese antimonopoly regulators claim that NVIDIA broke antitrust laws (via Business Insider) in connection with the acquisition of Israeli chip design company Mellanox.\n\nNVIDIA announced it had reached a $6.9 billion deal with Mellanox in March 2019. China, shortly after the announcement, stated it had conditionally approved the deal.\n\nHowever, the antitrust investigation was initiated in December 2024 by China's State Administration for Market Regulation (SAMR). The investigation remains ongoing, say SAMR officials in the press release.\n\n[...] the State Administration for Market Regulation decided to conduct further investigation in accordance with the law.\n\nThe SAMR dropped the antitrust news at the same time that Chinese and US officials are attempting to negotiate trade intricacies in Madrid. Trade tensions have been on the rise for most of 2024 and 2025, with both sides making some bold claims regarding AI GPUs and how they're being used.\n\nA brief history of US, China, and NVIDIA trade tensions\n\nTwo cargo ships, one with a Chinese flag and the other with an American flag. (Image credit: Getty Images | Yaorusheng)\n\nA lot of recent trade tension between the US and China has NVIDIA sitting in the center. The GPU company's H20 AI chip, created specifically for the Chinese market as a less-powerful alternative to US AI chips, is highly sought after by China's AI firms.\n\nHowever, the NVIDIA chip was fully banned from being sold to China in April 2025 by the Trump administration. The cause of the ban centered on concerns that China was using the H20 chips to bolster its military and to develop further domestic AI models that could challenge US firms.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe ban was walked back in July, when NVIDIA CEO Jensen Huang reached a deal with President Trump following a White House visit. Huang's argument? It's better to have all AI models running on US technology.\n\nIt didn't take long for Huang to announce that NVIDIA was ordering 300,000 more H20 AI chips from TSMC in order to meet Chinese demand. And that was on top of the 600,000 to 700,000 H20 chips already stockpiled and awaiting buyers.\n\nAs a final part of the deal with the US government, NVIDIA and AMD agreed to pay a 15% chip tax for the export licenses needed to sell to China. The unprecedented deal remains informally approved. While Chinese AI firms clambered to place orders for the unbanned H20 AI GPUs, state officials began pressuring the firms to avoid the US hardware over fears of tracking devices, spyware, and other hidden back doors.\n\nNVIDIA responded by firmly stating that it wasn't placing any sort of trackers or malware in its AI GPUs.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/nvidia/nvidia-violated-anti-monopoly-laws-chinese-officials",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Open source Cloud Hypervisor adds (maybe futile) no-AI-code policy",
      "content": "The Cloud Hypervisor project has introduced a No AI code policy.\n\nCloud Hypervisor started life in 2018 as a joint effort between Google, Intel, Amazon, and Red Hat – all of which wanted to share their work on virtualization components to speed their respective efforts to create virtual machine monitors and hypervisors. The participants decided that work was best undertaken using Rust and the rust-vmm project is the result.\n\nIntel took the project in a slightly different direction and led to the creation of Cloud Hypervisor, a Virtual Machine Monitor for cloud workloads. The Linux Foundation took on the project in 2021, when Alibaba, ARM, ByteDance, and Microsoft were also part of the project, alongside Intel.\n\nAMD, Ampere, Germany’s Cyberus Technology and China’s Tencent Cloud have since become supporters, and the project now describes itself as “an open source Virtual Machine Monitor that runs on top of the KVM hypervisor and the Microsoft Hypervisor.” It’s mostly used by public clouds as the hypervisor in their IaaS services, and is customized to work with the hardware they buy in bulk.\n\nThe project delivered version 48 last week, complete with the new policy to “decline any contributions known to contain contents generated or derived from using Large Language Models.”\n\nAs detailed in the project’s documentation for contributors, the reasons for the ban are “… to avoid ambiguity in license compliance and optimize the use of limited project resources, especially for code review and maintenance.”\n\nThat wording suggests Cloud Hypervisor’s maintainers fear legal complications and/or contributions comprised of AI slop.\n\nAI coding tools are almost certainly trained on open source code, but it’s hard for developers to know if the LLMs helping them to write software also snarfed copyrighted code or projects published under restrictive licenses. All of Cloud Hypervisor’s contributors are likely targets for lawsuits, so politely declining to accept AI makes sense.\n\nEven though the project’s participants know it’s probably a futile gesture.\n\nIn a thread debating the policy, Cyberus Technology’s Philipp Schuster expressed concern “that this policy will basically be violated starting from day 0 after being merged. We never can ensure code is not at least enhanced with/from LLM.”\n\nIn response, a contributor named Bo Chen suggested “we need a procedure to make sure the policy is explicitly acknowledged. One option is to add a pull request template that includes a mandatory checkbox, requiring contributors to affirm they have read and agree to our contribution guide.”\n\nA notable inclusion in version 48 is documentation on how to run Windows 11 guests, which should help those creating cloudy desktop-as-a-service products.\n\nOther additions that may interest include:\n\nLifting the maximum number of supported vCPUs on x86_64 hosts using KVM from 254 to a whopping 8192;\n\nRemoving support for Intel’s Software Guard Extensions (SGX);\n\nAdding support for inter-VM shared memory;\n\nFaster pausing for VMs that run on many vCPUs.\n\n®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/15/cloud_hypervisor_no_ai_policy/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "China's entry-level GPU with AMD RX 550-level of performance is ready for tapeout — Loongson 9A1000 is finally off the drawing board and headed to fabs",
      "content": "Having started its development in 2023, Loongson Technology's 9A1000 graphics card is one step closer to the finishing line. According to Chinese media outlet ITHome, the development of the 9A1000 has been completed, and the graphics card will begin tapeout in the third quarter of this year.\n\nThe 9A1000 is Loongson's first graphics card, marking a significant milestone for the Chinese manufacturer, which had previously focused mainly on processors. The company positions the 9A1000 as an entry-level graphics card that supports AI acceleration. Therefore, it doesn't compete in the same segment as the Lisuan G100, another Chinese graphics card, that allegedly rivals the GeForce RTX 4060.\n\nAlthough we've been aware of the 9A1000 for some time, we still don't know its exact specifications. Loongson has kept details under wraps, only hinting that it offers performance similar to the Radeon RX 550, a card that was released eight years ago. However, it's too early to call it a win for Loongson, since the manufacturer still has to evaluate the 9A1000 after the tapeout.\n\nThe latest update on the 9A1000 indicates that Loongson has apparently reduced the area of the stream processor by 20%. The manufacturer also claims that it has increased the 9A1000's operating frequency by 25%, while optimizing power consumption during light loads by 70%. In terms of feature set, the 9A1000 supports OpenGL 4.0 and OpenCL ES 3.2 APIs.\n\nAccording to Looongson, the 9A1000 is up to 4X faster than the LG200, the integrated graphics unit inside the 2K3000 processor. The 9A1000 also provides up to 40 TOPS of AI computing power, which is slightly below that of AMD's XDNA 2 NPU inside the Ryzen AI Max+ (codenamed Strix Halo) chips, which deliver up to 50 TOPS.\n\nThe 9A1000 isn't the only graphics card on Loongson's plate. The company is also working on the 9A2000, which it claims is up to 10X faster than the 9A1000, with performance levels comparable to those of the GeForce RTX 2080. There are also plans for a 9A3000, a follow-up to the 9A2000, but no known specifications are available yet.\n\nAlthough it may not be immediately apparent, numerous Chinese corporations and startups have entered the graphics card industry. However, many of these entities fail and subsequently cease operations. Therefore, we only hear news about the more prominent firms, such as Biren, Moore Threads, and, in recent years, Loongson and Lisuan Technology.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/gpus/chinas-entry-level-gpu-with-amd-rx-550-level-of-performance-is-ready-for-tapeout-loongson-9a1000-is-finally-off-the-drawing-board-and-headed-to-fabs",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Condor Technology to Fly \"Cuzco\" RISC-V CPU into the Datacenter",
      "content": "Once a hyperscaler or a cloud builder gets big enough, it can afford to design custom compute engines that more precisely match its needs. It is not clear that the companies that make custom CPUs and XPUs are saving money, but they are certainly gaining control and that is worth something.\n\nArm made a push based on the power-efficient nature its architecture, and Nvidia has become a key player in AI with its powerful GPUs and now its “Grace” Arm server CPUs. A reinvigorated AMD has given system makers an x86 alternative to an Intel that is still trying to find its footing after a few years of missteps and missed deadlines. And now, the community for RISC-V, the open, modular, and highly customizable architecture overseen by the RISC-V International collective, is looking to make inroads into datacenters.\n\nIt is still early days for RISC-V, much as it was for Arm in the datacenter back in 2010, but the RISC-V architecture is being embraced by a range of well-known tech vendors, from Intel, Western Digital, Google, Nvidia, Meta Platforms, and Qualcomm, and a growing number of pure-plays and startups, such as Andes Technology, SiFive, Microchip Technology, Ventana, and Lattice Semiconductor.\n\nThere also is money backing the effort. Most recently, the European Union continued its on-again, off-again courting of RISC-V for supercomputers and other HPC systems in the region with the launch in March of DARE – Digital Autonomy with RISC-V in Europe – to oversee a six-year, $260 million effort.\n\nCondor Takes Flight\n\nAndes is two decades old and, despite its name, is based in Taiwan, not in Colombia, Chile, Peru, or Argentina where the mountain range of that name is located on the western coast of South America. The company is a founding member of RISC-V International and a maker of efficient and low-power processor cores based on the architecture.\n\nMark Evans, director of business development at Andes and now its Condor Computing subsidiary that was established in Austin, Texas to get indigenous to the United States, gave an overview of the company in a session at the AI Infra Summit in Santa Clara last week. The week before that Ty Garibay, Condor’s founder and president, and Shashank Nemawarkar, Condor’s director of architecture, walked everyone through the “Cuzco” core that the company has created to begin its assault on the datacenter in earnest.\n\nEvans says that Andes has shipped its intellectual property in over 17 billion RISC-V chips since 2005, and further that it has been growing sales at a compound annual growth rate of 29 percent between 2018 and now. Evans put some numbers on it, saying that Andes had $42 million in sales in 2024, and that its IP was present in 30 percent of RISC-V SoCs that were shipped last year.\n\nThe Andes customer base is pretty broad across various industry sectors, including MediaTek and Novatek in mobile devices, Phison in storage, and Meta Platforms and SK Telecom in AI compute engines.\n\nEvans says that 39 percent of the revenue that Andes had in 2024 came from the AI sector, significantly including the MTIA v1 and MTIA v2 coprocessors from Meta.\n\nThat brings us to the “Cuzco” RISC-V core that Condor was showing off at the Hot Chips 2025 conference.\n\nIn July, Condor successfully did full hardware emulation of the Cuzco core, booting multiple operating systems, including Linux, with the first users expected to get the processor sometime in the last quarter. This high-performance RISC-V core has microarchitectural tweaks, including the way it issues instructions and organizes execution units, all with the aim of creating what Garibay said will be “the world’s highest performance licensable RISC-V CPU IP,” with a broad range of use cases.\n\n“We’re entirely focused on bringing an innovative new microarchitecture to the RISC-V CPU market,” Garibay said during a presentation at Hot Chips. “We intend to demonstrate that RISC-V can be competitive in any high-performance computing application, from datacenters to handsets to automotive. … Our goal is to provide much better performance than other high-performance, licensable CPUs while operating at a similar power envelope.”\n\nCuzco is based on the latest RISC-V profile for datacenter computing – RVA-23 – so ensure high software compatibility, can support up to eight cores with up to 8 MB private L2 cache in a coherent cluster with a shared 256 MB L3 cache, and a 12-stage pipeline. There are functional units that execute through a pool after the eight-instruction dispatch. The CPU itself is standard, with fetch, instruction queue, and instruction decode, he said.\n\nBelow is a more detailed block diagram of the Cuzco core:\n\nHere is the cache memory architecture:\n\nAnd here is the socket architecture:\n\nThe structure of the core is what is really interesting with Cuzco, so we are going to spend our time there.\n\nOne area Condor focused on was the structure of the execution units, which Garibay said are pair into two pipelines called a “slice,” with each of the four slices being identical and each having its own pipelines and resources.\n\n“Each slice fully implements RISC-V compatibility,” he said. “The machine is scalable, in theory, down to one slice or pair of pipelines, although. practically probably, only anyone would ever implement is two slices. As a minimum machine, the overhead becomes unwieldy at that point. But it is scalable to six pipelines, three slices by default – eight pipelines, four slices – and then we will extend this architecture into the future, with added features as we grow the slice count.\n\nThe intent, he said, “was to ease the implementation of this in high-performance processes.”\n\nThen comes the time-based architecture for instruction sequencing. The chip starts out with what Nemawarkar called “a standard pipeline for the out-of-order machines. Typically, this is a 12-log stage pipeline. The instruction fetch, nothing different than most of it you have seen.”\n\nChanges come from the point of where instruction decode happens, Nemawarkar said. That’s where the time-based issuing logic kicks in. Most chips use Tomasulo’s algorithm, a process for the out-of-order scheduling of instructions. In these cases, the chips use content-addressable memories (CAMs) to point to instructions to send downstream. CAMs can eat up a lot of power, given the match-line switching and precharge cycles needed.\n\nCuzco uses its register scoreboard to record the write time of an instruction to a register, which then becomes the read time. The scoreboard says when the instruction is available for execution and tracks the future of write time of instructions. The chip’s time resource metrix (TRM) records the use of resources like arithmetic logic units (ALUs), buses, and load and store queues to help predict ahead of time what resource will be available, which enables predictive scheduling. Instructions can be issued with an understand of exact future cycles for operands and resources, according to Andes.\n\nIt also does away with the power-hungry CAMs.\n\n“The reasoning behind that is this allows us to reduce the complexity, which typically happens in the global scheduling or a local scheduling or combination of that, when the machines start to become wider and wider,” Nemawarkar said. “Everybody knows that being a huge problem. Then essentially, with each execution unit, you need to start looking at which instructions are ready, how do I execute based on the priority for which instruction to be given, etc.”\n\nIt’s something that other implementations haven’t tried before, according to Garibay.\n\n“It is a departure, and it’s a good departure in that we’re looking to reduce the overall power and area of what has become the most power-and-area-hungry part of these wide, out-of-order machines – instruction scheduling,” Garibay added.\n\nEnterprises and HCP centers will be able to put Cuzco to the test by the end of the year so see how the new execution units and out-of-order instruction scheduling will work for them.",
      "source": "The Next Platform",
      "url": "https://www.nextplatform.com/2025/09/15/condor-technology-to-fly-cuzco-risc-v-cpu-into-the-datacenter/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Intel Is Losing Ground in the High-End CPU Segment. Can the US Government Save the Legacy Company?",
      "content": "Key takeaways: AMD dominates the high-end CPU market with its Ryzen 9000 and X3D chips, reducing Intel’s premium market share even though Intel still leads in total unit sales.\n\nwith its Ryzen 9000 and X3D chips, reducing Intel’s premium market share even though Intel still leads in total unit sales. Intel’s decline is partly self-inflicted , marked by missed mobile and AI revolutions, fab delays, $2.9B quarterly losses, and 24,000 layoffs that threaten to hollow out critical talent.\n\n, marked by missed mobile and AI revolutions, fab delays, $2.9B quarterly losses, and 24,000 layoffs that threaten to hollow out critical talent. The US government and Nvidia have stepped in with Washington investing $8.9B and Nvidia contributing $5B, providing Intel with fresh capital, political support, and the integration of RTX GPU chiplets into future CPUs.\n\nwith Washington investing $8.9B and Nvidia contributing $5B, providing Intel with fresh capital, political support, and the integration of RTX GPU chiplets into future CPUs. Intel’s survival might come at the expense of its independence: it now has credibility and room to breathe but risks becoming a junior partner to Nvidia and relying on U.S. policy rather than leading innovation itself.\n\nFor decades, Intel was the undisputed leader in the CPU market: a company so dominant that its name became a synonym for computing power. Today, that reputation has diminished.\n\nOnce dominated by Intel, the high-end consumer and professional CPU markets are now shifting toward AMD. This shift is well justified: AMD’s Ryzen 9000 and X3D chips consistently outperform Intel’s flagship models in benchmarks, efficiency, stability, and long-term platform support.\n\nMeanwhile, Nvidia has surged to a market capitalization of over $4.2 trillion, riding the AI wave and becoming the most valuable company in history.\n\nIntel, by contrast, has lost its lead. The company reported a $2.9 billion loss in Q2 2025, announced plans to cut 24,000 jobs, and shelved multi-billion-dollar European projects.\n\nIts CEO even admitted in July that Intel no longer ranks among the world’s top ten semiconductor companies: an admission that would have been unexpected just a decade ago.\n\nBut Intel’s story isn’t just about its decline: two influential supporters have now stepped in. The US government bought a 10% stake in Intel this August, investing $8.9 billion in the company’s vital role in domestic chip production.\n\nAnd this week, Nvidia announced a $5B investment in Intel, promising to incorporate its RTX GPU technology into upcoming Intel processors.\n\nThe stakes couldn’t be higher. Could this new influx of capital signal the start of Intel’s recovery, or is it just life support for a fading giant?\n\nIntel’s Market Position Under Siege\n\nIntel’s biggest challenge isn’t just internal mistakes; it’s the ongoing decline of its market standing in high-end consumer CPUs. Intel was known for high performance for years, but AMD has changed that narrative.\n\nPowered by the Ryzen 9000 series and its innovative X3D chips, AMD has shifted from underdog to leader in benchmarks, efficiency, and value. The numbers reveal a change redefining the power balance in the CPU market.\n\nAMD’s High-End Dominance\n\nAlthough Intel still leads in overall CPU sales, AMD has consistently gained ground in the high-end market where performance and profit margins are key.\n\nIn Q2 2025, Intel accounted for about 75% of consumer CPU unit sales, but AMD’s revenue share increased to 27.8%, nearly 10% higher year-over-year. The key point: Intel sells more chips overall, but AMD is gaining ground with higher-value models.\n\nThe desktop CPU market is experiencing an even more significant shift. AMD’s revenue share increased by 20.5% year-over-year to 39.3%, with unit sales reaching 32.2%.\n\nThe surge is driven by the Ryzen 9000 series and X3D chips, praised for gaming performance, energy efficiency, and extended support through the AM5 socket (supported until at least 2027).\n\nBenchmarks highlight this imbalance. According to PassMark, AMD occupies all top 30 slots for professional workloads: a clean sweep that underscores how far Intel’s top-tier CPUs have slipped.\n\nAlt: Table showing PassMark’s top-end CPU list with Intel CPUs only making an appearance at #31.\n\nThe trend over time reveals the stakes. In 2016, Intel outsold AMD by 9:1. By 2023, it was 4:1. Now, in 2025, it’s just 2:1. If momentum continues, AMD could outsell Intel outright within five years: a scenario once hard to imagine.\n\nAlt: Market share line chart showing Intel’s waning lead over AMD.\n\nAMD has genuinely earned its users’ trust over time. Its chips regularly offer better real-world performance and use less power, while Intel has faced issues with stability and reliability in recent releases. AMD is becoming the more reliable choice for gamers, creators, and enterprise buyers alike.\n\nIntel may still lead in volume, but losing the high-end halo segment risks more than just revenue. Premium chips shape brand identity and influence future innovation. And once that perception shifts — as it now has toward AMD — reclaiming it becomes a much taller challenge.\n\nIntel’s Self-Inflicted Wounds\n\nMuch of Intel’s struggles comes from fierce competition, but some of its decline has been self-inflicted.\n\nOver the past decade, the company has repeatedly failed at crucial moments. It missed the mobile revolution by ceding smartphones to ARM-based processors and then missed the AI boom, while competitors like Nvidia built their fortunes around GPU-accelerated machine learning.\n\nEven Intel’s highly anticipated foundry expansion has fallen behind schedule, causing the US to remain dependent on Taiwan’s TSMC for advanced manufacturing.\n\nThe company’s own leadership has acknowledged this reality. In July 2025, CEO Lip-Bu Tan admitted bluntly:\n\n“We are not in the top 10 semiconductor companies,” – a stunning confession from a firm that once set the industry’s pace.\n\nFinancially, the impact has been substantial. Intel reported a $2.9 billion loss in Q2 2025 and announced it would lay off 24,000 employees, reducing its workforce from nearly 100,000 to about 75,000.\n\nAlong with the layoffs, Intel canceled plans for huge fabs in Germany and Poland and closed its automotive division, wiping out years of investment in those sectors.\n\nAnalysts warn that these cuts could further weaken Intel. Unless Washington facilitates talent-sharing or supply chain guarantees with Nvidia, AMD, and TSMC, Intel risks depleting the workforce needed to develop competitive chips in the next decade.\n\nAlt: Timeline showing Intel’s missteps over the past decade\n\nCPU Performance and Reliability Crisis\n\nIntel once set the standard in the high-end consumer market. However, its latest flagship has fallen short. The $600 Core i9-12900K consistently trails behind AMD’s Ryzen 9 7950X across key benchmarks.\n\nIndependent testing shows Ryzen delivering 34% higher FPS (194.8 vs. 144.9), significantly more L3 cache (144MB vs. 76MB), and lower power consumption. AMD’s AM5 platform also guarantees support until 2027, appealing to buyers who want to future-proof their builds.\n\nBut raw performance isn’t the only issue. Intel’s latest chips have encountered widespread stability and reliability problems.\n\nLinux developer Michael Stapelberg, a long-time Intel user, reported his 285K system failing twice in months despite normal thermal conditions.\n\nLong-running workloads caused crashes and unresponsiveness, forcing him to switch from Intel to AMD. Similar complaints have spread across forums and retailer reviews, indicating high RMA rates and instability in real-world use.\n\nThese issues directly undermine Intel’s value proposition. Enthusiasts might accept quirks, but enterprises executing AI-intensive workloads cannot afford unreliable hardware.\n\nAt a time when computing reliability is more critical than ever, Intel’s flagship CPUs seem slower than AMD’s and less trustworthy: a risky combination in the competition for high-end market share.\n\nIntel’s Political and Financial Lifelines\n\nIntel’s struggle is no longer just a corporate issue; it’s clearly a national concern. Over the past year, the U.S. government and Nvidia have stepped in to provide Intel with unmatched support.\n\nThese interventions emphasize how vital Intel is to America’s technological sovereignty, even as its commercial competitiveness declines.\n\nThe U.S. Government’s $8.9B Stake\n\nIn August 2025, the Trump administration made headlines by acquiring a 9.9% stake in Intel for $8.9 billion, effectively labeling the chipmaker as “too big to fail.”\n\nUnlike the 2008 auto industry bailouts, this move wasn’t mainly about saving jobs; it was about geopolitics.\n\nThe US remains heavily dependent on Taiwan Semiconductor Manufacturing Company (TSMC), which controls 64% of the global foundry market and supplies about 44% of US logic chip imports as of 2021. Given China’s ongoing claims over Taiwan, Washington views this reliance as a strategic vulnerability.\n\nThe CHIPS Act of 2022 allotted $52B to support domestic semiconductor manufacturing, but progress is slow, and building advanced fabs takes years.\n\nConversely, Trump’s direct investment in Intel provided immediate political influence and capital, positioning Intel as the “national champion” of US chipmaking.\n\nStill, risks persist. Intel has found it challenging to attract outside customers to its foundry business, and concerns remain about whether Washington can compel AMD, Nvidia, or others to use Intel-manufactured chips if performance falls short of TSMC. Without competitive products, political support alone may not be sufficient.\n\nAlt: Graphic of the US Capitol dome with the Intel logo in the foreground\n\nNvidia’s $5B Lifeline\n\nIf the US stake was the first political lifeline, then Nvidia’s $5B investment in September was the second. Announced at a high-profile press conference, the deal involves Nvidia purchasing common stock in Intel and partnering on both consumer CPUs and AI-focused data center products.\n\nThe most striking feature is the plan to incorporate RTX GPU chiplets into upcoming Intel CPUs, effectively providing an alternative to AMD’s popular Ryzen APUs.\n\nThis could be a game-changer for thin laptops, handhelds, and small-form PCs by adding real gaming capabilities and AI acceleration to Intel-powered devices.\n\nOn the data center side, the alliance could reshape the x86 ecosystem. Nvidia already dominates AI servers through its GPUs and proprietary NVLink interconnects.\n\nBy partnering with Intel’s CPUs, Nvidia broadens its influence while giving Intel access to fast-growing AI markets it has largely overlooked. Nvidia CEO Jensen Huang estimates the partnership could target a $50B market opportunity.\n\nThe market reaction to this news was swift:\n\nIntel stock surged nearly 30% , the biggest one-day gain in years.\n\n, the biggest one-day gain in years. Nvidia rose 3% , adding $120B in market cap: more than 20 times its actual investment.\n\n, adding $120B in market cap: more than 20 times its actual investment. AMD fell 4%, a sign that investors fear it could be boxed out of future datacenter and consumer markets.\n\nAlt: Price chart showing Intel (INTC) surging nearly 30% premarket following news of Nvidia’s investment.\n\nPolitically, the deal benefits U.S. strategic interests. Nvidia CEO Jensen Huang said the White House had no direct involvement, though Commerce Secretary Howard Lutnick was “very supportive.”\n\nAnalysts widely believe Washington encouraged Nvidia to support Intel, playing its part to ensure that America’s legacy chipmaker wouldn’t collapse just as AI reshapes the global economy.\n\nFor Intel, the partnership restores much-needed credibility. For Nvidia, it gains goodwill in Washington while keeping options open to shift manufacturing away from TSMC if geopolitics require it.\n\nThe Future of Intel’s Technology\n\nIntel’s $8.9B US government lifeline and Nvidia’s $5B partnership have bought the company valuable time, but its survival depends on execution.\n\nThe immediate concern is whether these alliances enhance or weaken Intel’s technology roadmap, making the company a junior partner in its own industry.\n\nWhat About Intel GPUs?\n\nNvidia’s $5B investment raises one of the biggest questions about what it means for Intel’s GPU ambitions.\n\nOn paper, Intel is committed to continuing its Arc discrete graphics and Xe architecture roadmaps. An Intel spokesperson told PCWorld that the Nvidia partnership is “complementary to Intel’s roadmap” and does not replace its GPU efforts.\n\nBut it’s reasonable to be skeptical of this. Intel’s discrete GPUs have struggled to gain traction, with Nvidia controlling around 94% of the GPU market as of Q2 this year. If future Intel CPUs start integrating Nvidia’s RTX chiplets, what incentive remains to develop Arc further?\n\nAlt: Roadmap graphic showing Xe3 Celestial potentially integrating RTX chiplets\n\nThere’s also a historical reason for skepticism. Intel previously tried a hybrid design in Kaby Lake-G, which combined Intel CPUs with AMD Radeon GPUs. The product failed, hindered by driver problems and a short lifespan. Nova Lake-AX, Intel’s next SoC platform, might revisit this concept: but this time, with Nvidia GPUs instead of AMD’s.\n\nIntel maintains it will keep developing its own GPUs, but the new partnership looms large. Over time, Intel risks relying on Nvidia’s graphics dominance instead of fighting directly.\n\nRisks and Rewards of the Intel–Nvidia Alliance\n\nThe Nvidia deal is being hailed as a “historic collaboration” by both companies, but its implications are double-edged.\n\nOpportunities\n\nTechnical lift : Nvidia’s GPU chiplets could make Intel CPUs competitive in thin-and-light gaming laptops and mini-PCs, where AMD’s APUs have held the edge.\n\n\n\n: Nvidia’s GPU chiplets could make Intel CPUs competitive in thin-and-light gaming laptops and mini-PCs, where AMD’s APUs have held the edge. Datacenter dominance: Nvidia extends its AI ecosystem by pairing its GPUs with Intel’s x86 CPUs, creating a powerful rival to AMD’s EPYC processors.\n\nInvestor confidence: Intel stock surged 30% after the announcement, while Nvidia added around $120B to its market cap.\n\nRisks\n\nJunior partner status : Intel may become a vessel for Nvidia’s strategy rather than an innovator in its own right.\n\n\n\n: Intel may become a vessel for Nvidia’s strategy rather than an innovator in its own right. GPU ambitions sidelined : Intel’s Arc and Xe families risk irrelevance if Nvidia becomes the preferred GPU inside Intel chips.\n\n\n\n: Intel’s Arc and Xe families risk irrelevance if Nvidia becomes the preferred GPU inside Intel chips. Geopolitical uncertainty: Both companies remain dependent on TSMC for manufacturing despite US backing. Nvidia CEO Jensen Huang himself emphasized that “you just can’t overstate the magic that is TSMC.”\n\nThe big picture is clear: Intel now relies on two key supporters, Washington and Nvidia. Together, they provide Intel with breathing room and market credibility.\n\nIn return, however, Intel might have to sacrifice some of its independence, acting less like a global leader and more like a US-backed ecosystem partner. said, this won’t happen in the blink of an eye. It will take time and precious resources, which is precisely why the US government decided to get involved.\n\nCan Intel Really Be Saved?\n\nIntel’s unchecked-dominance arc of its story is firmly in the past; now, its focus is on survival. Once the symbol of US chip supremacy, the company is now at the nexus of government policy and private partnership.\n\nThe $8.9B US stake confirms that Intel is too strategic to fail, while Nvidia’s $5B investment adds both credibility and technical driving force.\n\nIn the short term, these moves have steadied the ship. Intel’s stock surged 30% on the Nvidia news, investors regained confidence, and the company now has a clearer roadmap for consumer PCs and data centers. Make no mistake: this is a much-needed early win for new CEO Lip-Bu Tan.\n\nBut the long-term challenges are very real. Intel must prove it can deliver reliable high-end CPUs, compete with AMD’s performance edge, and carve out space in AI: a sector already dominated by Nvidia. Worse still, it risks becoming a junior partner, leaning on others’ innovation instead of forging its own path.\n\nSo now, the question is no longer whether Intel can survive. With both Washington and Nvidia invested, it almost certainly will. The real question is whether Intel can reclaim its role as a global leader, or whether its future will be defined as a dependent ally in a new semiconductor world order. As they say, time will tell.\n\nMonica is a tech journalist and content writer with over a decade of professional experience and more than 3,000 published articles. Her work spans PC hardware, gaming, cybersecurity, consumer tech, fintech, SaaS, and digital entrepreneurship, blending deep technical insight with an accessible, reader-first approach. Her writing has appeared in Digital Trends, TechRadar, PC Gamer, Laptop Mag, SlashGear, Tom’s Hardware, The Escapist, WePC, and other major tech publications. Outside of tech, she's also covered digital marketing and fintech for brands like Whop and Pay.com. Whether she’s explaining the intricacies of GPU architecture, warning readers about phishing scams, or testing a liquid-cooled gaming PC, Monica focuses on making complex topics engaging, clear, and useful. She’s written everything from deep-dive explainers and product reviews to privacy guides and e-commerce strategy breakdowns. Monica holds a BA in English Language and Linguistics and a Master’s in Global Media Industries from King’s College London. Her background in language and storytelling helps her craft content that’s not just informative, but genuinely helpful—and a little bit fun, too. When she’s not elbow-deep in her PC case or neck-deep in a Google Doc file, she's probably gaming until the early hours or spending time with her spoiled-rotten dog. View all articles by Monica J. White\n\nRelated Articles",
      "source": "Techreport.com",
      "url": "https://techreport.com/news/intel-losing-high-end-cpu-segment-can-us-govt-save-it/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "These portable operating systems are so light you don’t even need to install them",
      "content": null,
      "source": "MakeUseOf",
      "url": "https://www.makeuseof.com/these-portable-operating-systems-light-dont-need-to-install/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Testing Reveals AMD FSR 4 on RDNA 2 GPUs Improves Image Quality With Minor Performance Hit",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/testing-reveals-amd-fsr-4-on-rdna-2-gpus-improves-image-quality-with-minor-performance-hit/",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Dean of Valuation Aswath Damodaran Says He’d Rather Have His Money in Intel Than NVIDIA (NVDA)",
      "content": "We recently published These 10 Stocks are Buzzing After Important Analyst Calls. NVIDIA Corp (NASDAQ:NVDA) is one of the stocks analysts were recently talking about.\n\nAswath Damodaran, NYU Stern School of Business professor of finance, often known as the “deal of valuation,” recently said in a program on CNBC that he’s still owning a stake in Nvidia, but called the stock “richly priced.” Damodaran said his Intel investment has done better than his Nvidia position.\n\n“I own half of the NVIDIA Corp (NASDAQ:NVDA) that I owned a year ago. And I’m okay with that even though it’s gone up because I think it is so richly priced that I’d rather have my money in Intel than in NVIDIA Corp (NASDAQ:NVDA). And actually my Intel investment’s done better since September of last year than my NVIDIA Corp (NASDAQ:NVDA) investment. Yeah, Intel Intel’s caught a nice wave here.”\n\nAswath Damodaran Says He’d Rather Have His Money in Intel Than NVIDIA (NVDA)\n\nNvidia’s Hopper Infrastructure and now Blackwell form the core of AI infrastructure for LLM training and inference. But Nvidia’s growth is slowing compared to previous quarters amid competition and capex spending limitations from major companies. In the recently reported quarter, Nvidia’s annual revenue growth came in at 56%, compared with nearly 100% YoY growth in the past.\n\nWith its strong position in the data center market and rising demand, Nvidia is likely to keep growing, though not at the same pace it has in the past. Increasing competition from major companies like Broadcom is also expected to impact Nvidia’s margins in the long term.\n\nNvidia recently impressed the market by signing an AI infrastructure deal with Intel. Nvidia will invest $5 billion in Intel. Jensen Huang said the deal would open up $50B in TAM for both companies in the data center and PC business.\n\nAnalysts believe the deal would allow Nvidia to take market share from AMD in the data center and PC business and diversify away from Arm-based designs.\n\nMacquarie Core Equity Fund stated the following regarding NVIDIA Corporation (NASDAQ:NVDA) in its second quarter 2025 investor letter:\n\n“NVIDIA Corporation (NASDAQ:NVDA) performed strongly in the quarter on renewed AI optimism and reduced concern that an individual customer or two will moderate capital expenditures. Though the Fund’s weight was among our largest positions at over 4.5% during the quarter, the relative underweight (the benchmark weight averaged 6.3%) negatively affected relative returns.”\n\nWhile we acknowledge the potential of NVDA as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/dean-valuation-aswath-damodaran-says-133245375.html",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Windows ML is Generally Available with Windows App SDK 1.8.1",
      "content": "Microsoft today announced the first stable release of Windows ML, its AI inferencing runtime for Windows 11. Windows ML (Windows Machine Learning) is optimized for inferencing on-device AI models, like those used by Copilot+ PCs, though it offers streamlined model dependency management across CPUs, GPUs and NPUs. It’s also the basis for the Windows AI Foundry, which was originally called the Windows Copilot Runtime.\n\n“The future of AI is hybrid, utilizing the respective strengths of cloud and client while harnessing every Windows device to achieve more,” Microsoft distinguished engineer Logan Iyer explains. “At Microsoft, we are reimagining what’s possible by bringing powerful AI compute directly to Windows devices, unlocking a new era of intelligence that runs where you are. With groundbreaking advancements in silicon, a modernized software stack and deep OS integration, Windows 11 is transforming into the world’s most open and capable platform for local AI.”\n\nMicrosoft first announced Windows ML (and the Windows AI Foundry) at Build 2025 this past May, so this is a pretty quick turnaround. (Compare this to the Windows Copilot Runtime, which was announced at Build 2024 and never shipped in stable.) With this release, developers can use Windows ML capabilities in production, and that tells me that there must be a new stable release of the Windows App SDK, the framework that developers use to access Windows ML. And there is: Windows App SDK 1.8.1 is now available with support for Windows 11 version 24H2 and newer. (You can download that here.)\n\nIn keeping with the nature of Windows itself, Windows ML acts as a hardware abstraction layer so that developers can target specific local AI capabilities without worrying about which hardware architectures or chipsets are available on the PCs on which their apps will run. Apps built with Windows ML will automatically download any necessary execution providers, so they don’t need to be bundled with specific (or multiple) runtimes. But developers can also create device policies to optimize their apps for low power (NPU) or high performance (GPU), or to specify the silicon used for a model.\n\n“Windows 11 has a diverse hardware ecosystem that includes AMD, Intel, NVIDIA and Qualcomm and spans the CPU, GPU and NPU. Consumers can choose from a range of Windows PCs and this variety empowers developers to create innovative local AI experiences,” Iyer continues. “Windows ML can fully leverage their latest CPUs, GPUs and NPUs for AI workloads … Leading software app developers such as Adobe, BUFFERZONE, Dot Inc., McAfee, Reincubate, Topaz Labs and Wondershare are among many others working on adopting Windows ML in their upcoming releases, accelerating the proliferation of local AI capabilities across a broad spectrum of applications.”\n\nYou can learn more about Windows ML on the Microsoft Learn website.",
      "source": "Thurrott.com",
      "url": "https://www.thurrott.com/a-i/327165/windows-ml-is-generally-available-with-windows-app-sdk-1-8-1",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "WUCHANG: Fallen Feathers Patch 1.6 Introduces Significant VRAM Optimization, Performance Improvements on PC",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/wuchang-fallen-feathers-patch-1-6-vram-performance-visuals-improvements/",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Adobe Acrobat Pro + Microsoft Office Professional 2019 License Bundle for $89",
      "content": "Easily Create, Edit, Convert, and Protect Your Documents on Mac or Windows Without Connecting to Cloud\n\nBoost your productivity with the essential offline solution for all your PDF needs. With Adobe Acrobat Pro 2024, you can easily create, edit, convert, and protect your documents on Windows and Mac without connecting to the cloud. Start a document, create a new form from scratch, and manage your documents efficiently with new features, including enhanced accessibility tools. The updated Acrobat interface also means that you’ll be able to easily find the tools you need to complete PDF tasks faster than ever. You can own this software for a full three years, no subscription required.\n\nAdobe Acrobat Pro 2024 and is provided by Adobe Inc.\n\nWhat you can do with Adobe Acrobat Pro 2024\n\nDesktop-Only PDF Tools: Work securely offline — without connecting to the cloud\n\nWork securely offline — without connecting to the cloud Enhancements to Existing Features Edit text & images and reorder and delete pages in a PDF Convert PDFs to Microsoft Word, Excel, or PowerPoint files while preserving fonts, formatting & layouts\n\nForms: Easily create, fill & sign forms\n\n\n\nEasily create, fill & sign forms Security Features: Password-protect documents or redact sections of a PDF to keep sensitive information secure.\n\nPassword-protect documents or redact sections of a PDF to keep sensitive information secure. Star a Document: Mark documents as favorites or tag them for follow-up\n\nMark documents as favorites or tag them for follow-up Extract Discontinuous Pages: Remove specific pages from a PDF to focus on what you need\n\nRemove specific pages from a PDF to focus on what you need Accessibility Updates: Improved tagging for better accessibility for people with disabilities\n\nImproved tagging for better accessibility for people with disabilities New Acrobat Experience: A modern interface that makes finding & using PDF tools easier",
      "source": "Stacksocial.com",
      "url": "https://www.stacksocial.com/sales/adobe-acrobat-pro-microsoft-office-professional-2019-license-bundle?utm_medium=RSS&amp;aid=&amp;utm_source=cultofmac&amp;utm_campaign=feed",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Adobe Acrobat Pro + Microsoft Office Professional 2019 License Bundle for $89",
      "content": "Easily Create, Edit, Convert, and Protect Your Documents on Mac or Windows Without Connecting to Cloud\n\nBoost your productivity with the essential offline solution for all your PDF needs. With Adobe Acrobat Pro 2024, you can easily create, edit, convert, and protect your documents on Windows and Mac without connecting to the cloud. Start a document, create a new form from scratch, and manage your documents efficiently with new features, including enhanced accessibility tools. The updated Acrobat interface also means that you’ll be able to easily find the tools you need to complete PDF tasks faster than ever. You can own this software for a full three years, no subscription required.\n\nAdobe Acrobat Pro 2024 and is provided by Adobe Inc.\n\nWhat you can do with Adobe Acrobat Pro 2024\n\nDesktop-Only PDF Tools: Work securely offline — without connecting to the cloud\n\nWork securely offline — without connecting to the cloud Enhancements to Existing Features Edit text & images and reorder and delete pages in a PDF Convert PDFs to Microsoft Word, Excel, or PowerPoint files while preserving fonts, formatting & layouts\n\nForms: Easily create, fill & sign forms\n\n\n\nEasily create, fill & sign forms Security Features: Password-protect documents or redact sections of a PDF to keep sensitive information secure.\n\nPassword-protect documents or redact sections of a PDF to keep sensitive information secure. Star a Document: Mark documents as favorites or tag them for follow-up\n\nMark documents as favorites or tag them for follow-up Extract Discontinuous Pages: Remove specific pages from a PDF to focus on what you need\n\nRemove specific pages from a PDF to focus on what you need Accessibility Updates: Improved tagging for better accessibility for people with disabilities\n\nImproved tagging for better accessibility for people with disabilities New Acrobat Experience: A modern interface that makes finding & using PDF tools easier",
      "source": "Stacksocial.com",
      "url": "https://www.stacksocial.com/sales/adobe-acrobat-pro-microsoft-office-professional-2019-license-bundle?utm_campaign=feed&amp;aid=&amp;utm_medium=RSS&amp;utm_source=slashdot",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "AMD-powered ASUS ExpertBook P3 now available from $1,149",
      "content": "Asus has launched AMD versions of its ExpertBook P3 Copilot + PC's for businesses. Unveiled last month, the ExpertBook P3 come with with AMD Ryzen AI Pro 300 chips in both 14\" and 16\" variants with a max memory of 32GB and 1TB storage.\n\n4 Reviews ← exclude selected types\n\nThe latest notebooks from Asus are the AMD-powered siblings of the ExpertBook P3 series: the 14-inch PM3406 and 16-inch PM3606. The Taiwanese company has equipped them with Krackan Point chips and lets users choose between AMD Ryzen AI Pro 7 350 and AI Pro 5 330 processors.\n\nBoth laptops have WUXGA (1920 × 2100) anti-glare displays with a 144Hz refresh rate, backlit chiclet keys and 70 Wh battery life. Like the Intel-based versions, they work with triple band WiFi 7 and Bluetooth 5.4, and come with a bevy of ports including two USB 3.2 Gen2 Type-C ports, two Type-A ports, an HDMI port and an audio jack. Asus is marketing the ExpertBook P3 for professional and enterprise settings which justifies the inclusion of a 2.5m nano Kensington lock slot.\n\nThere are some bold ruggedness claims made here. These notebooks have reportedly passed MIL-STD-810H testing, giving them what Asus calls \"military-grade durability\". Among other things, the tests include a 100mm drop while the notebook is powered on, although attempting to replicate these results on your own will conveniently void the warranty.\n\nThe PM3406 and PM3606 variants of Asus' AMD-powered ExpertBook P3 are available in only two possible configurations. The four-core AMD Ryzen AI Pro 5 330 chip comes with 16GB RAM, a 512GB SSD and is priced at $1,149.99 for the 14-inch version or $1,179.99 for the 16-inch display. The higher-end processor (AMD Ryzen AI Pro 7 350) is paired with 32GB memory and 1TB of storage, and costs either $1,479.99 or $1,509.99, depending on the choice of display.\n\nAsus mentions in its press release that additional configurations are forthcoming in Q4 of 2025. All models are available for order on Asus' product page, with discounts on Amazon.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/AMD-powered-ASUS-ExpertBook-P3-now-available-from-1-149.1121667.0.html",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "AI Transformation in Radiology: Navigating Rising Scans, Stagnant Headcounts, and Evolving Reimbursements",
      "content": "Dublin, Sept. 23, 2025 (GLOBE NEWSWIRE) -- The \"World Market for AI in Medical Imaging 2025-2032\" report has been added to ResearchAndMarkets.com's offering.\n\n\n\nRadiology faces a triple squeeze: rising scan volumes, stagnant radiologist head-count, and fast-evolving reimbursement that now rewards computer-assisted detection, triage, and quantification.\n\nAI is no longer experimental; it is operational. Capital allocation is shifting, yet market signals remain noisy - valuations, attach-rate assumptions, and regulatory pace vary sharply by geography and modality. This report cuts through that noise and offers a single, evidence-weighted source of truth.\n\n\n\nThe World Market for AI in Medical Imaging 2025-2032 report quantifies and explains the fastest-growing slice of diagnostic imaging: software algorithms that detect, triage, quantify or automate findings across CT, MRI, X-ray/DR, Ultrasound and PET/Nuclear studies. The global market reached US $ 2.7 billion in 2023 and is projected to climb to US $ 28.4 billion by 2032 - a 29.9 % CAGR driven by enterprise \"AI-store\" contracts, payer reimbursement codes (NTAP, CADx CPT, Chinese subsidies) and rising scan volumes amid radiologist shortages. North America remains the single largest dollar contributor, but APAC overtakes Europe in growth rate after 2027.\n\nCT and MRI account for >60 % of spend today, while Oncology AI overtakes Neurology by 2028. Seven proprietary frameworks - M, TEM, ARC, GTM Growth-Maturity, Platform-Leverage, Ecosystem Collaboration, and Solution Adoption & Growth - translate thousands of datapoints into four-quadrant visuals that flag where evidence, technical readiness and go-to-market execution converge. Volume One provides the macro view, market analyses + forecasts, strategic frameworks, and Volume Two provides a vendor-level lens on 120 companies.\n\n\n\nReport Scope\n\nDeliverables: Two-volume package - Volume 1 \"Market Analysis & Forecasts\" and Volume 2 \"Company Briefs\".\n\nTwo-volume package - Volume 1 \"Market Analysis & Forecasts\" and Volume 2 \"Company Briefs\". Segmentation depth: Forecasts cut by five imaging modalities, seven clinical application areas, five geographic regions (twelve individual countries plus regional clusters), three revenue streams, five end-use or buyer segments / organizations, six AI technology categories.\n\nForecasts cut by five imaging modalities, seven clinical application areas, five geographic regions (twelve individual countries plus regional clusters), three revenue streams, five end-use or buyer segments / organizations, six AI technology categories. Time frame: 2023-24 actuals with 2025-2032 outlook;\n\n2023-24 actuals with 2025-2032 outlook; Key proprietary analytical frameworks: M Matrix (size vs CAGR hotspots), TEM Map (technology maturity), ARC Index (approvals + reimbursement + clinical evidence), GTM Growth-Maturity Quadrant (vendor trajectory), Platform-Leverage Strip (ARR stickiness), Ecosystem Collaboration, and Solution Adoption & Growth Matrix (suite depth vs scaling velocity).\n\nM Matrix (size vs CAGR hotspots), TEM Map (technology maturity), ARC Index (approvals + reimbursement + clinical evidence), GTM Growth-Maturity Quadrant (vendor trajectory), Platform-Leverage Strip (ARR stickiness), Ecosystem Collaboration, and Solution Adoption & Growth Matrix (suite depth vs scaling velocity). Company Briefs: 120 Company profiles with frameworks & proprietary tools (Platform Leverage Strip, Growth & Maturity Heatmap, Attach-Rate Model, Reg-P Matrix. These briefs are decision tools. Numbers are directional, normalized for comparability, and best read alongside the underpinning sensitivity tables. Insights highlight levers - attach rate, modality expansion, and regulatory cadence. Use the Growth & Maturity Heatmap to gauge trajectory; deploy the Insight scenarios to stress test your own assumptions; consult the Watch Items to track each company's execution risk.\n\n120 Company profiles with frameworks & proprietary tools (Platform Leverage Strip, Growth & Maturity Heatmap, Attach-Rate Model, Reg-P Matrix. These briefs are decision tools. Numbers are directional, normalized for comparability, and best read alongside the underpinning sensitivity tables. Insights highlight levers - attach rate, modality expansion, and regulatory cadence. Use the Growth & Maturity Heatmap to gauge trajectory; deploy the Insight scenarios to stress test your own assumptions; consult the Watch Items to track each company's execution risk. Intended users: OEM and pure-play AI SW comapanies, investors sizing attach-rate upside, hospitals vetting vendor evidence before purchase, and regulators monitoring SaMD clearance velocity.\n\nKey Topics Covered:\n\n\n\nSECTION 1 - EXECUTIVE SUMMARY\n\nWhy This Market Matters? - the 25-second Read\n\nGlobal Growth at a Glance\n\nFive Strategy Headlines to Internalize\n\nWhere Growth Concentrates - Modality & Clinical Slices\n\nRegional Pulse - Inflection Points & Watchouts\n\nCompetitive Heat - the Five Moves to Track\n\nThree-year KPI Outlook (2024-2027)\n\nSix Board-level Actions for the Next 12?Months\n\nMethodology Summary\n\nSECTION 2 - RESEARCH METHODOLOGY\n\nSECTION 3 - STRATEGIC MARKET ANALYSIS & FRAMEWORKS\n\nOutlook (2025-2030)\n\nGlobal Market & Procedure Volumes: Contextual Overview.\n\nImaging Procedure Volumes\n\nMarket Drivers and Restraints\n\nWorld Market Forecast by Region (2023-2032)\n\nRegional Growth Pattern\n\nStrategic Implications for Vendors\n\nMarket Size vs. 2024-32 CAGR\n\nMarket Phases\n\nMarket Sensitivity - Tariffs & FX (2024-26)\n\nMarkintel Technology Evolution Matrix (TEM)\n\nTDIT Stage Definitions & Horizon\n\nTDIT Quantitative Impact Tags\n\nKey Inflection Drivers\n\nPotential Roadblocks\n\nActionable Insights\n\nMarkintel Solution Adoption & Growth Matrix - Worldwide\n\nImmediate Strategic Recommendations\n\nMarktintel ARC Index (Approvals, Reimbursement, Clinical Validation)\n\nMarkintel ARC Index by Use Case\n\nRationale for ARC Index Score by Use Case\n\nMarkintel ARC Index Score by Clinical Area\n\nRegulatory and Compliance Trends\n\nFDA Approvals: Key Details\n\nGlobal Regulatory Landscape\n\nFDA Clearances & Emerging Regulatory Landscapes\n\nRegulatory & Reimbursement Snapshot - Update to Apr 2025\n\nFDA Imaging-AI Clearances Heatmap, 2018 - 2025 YTD.\n\nReimbursement Timeline Snapshot\n\nFDA Clearances by Modality (cumulative Apr 2025)\n\nReimbursement Timeline Detail\n\nMarkintel GTM Growth Maturity Matrix - World Market\n\nCompetitive Dataset - World Market for AI Imaging\n\nKey Takeaways\n\nGrowth & Maturity Highlights (selected)\n\nCompetitive Landscape and Clusters\n\nImaging OEM AI Suites\n\nAI-first Software Vendors\n\nCloud & Platform Enablers\n\nRegional Champions\n\nSpecialist Niches\n\nSECTION 4 - WORLD MARKET ANALYSIS & FORECAST\n\nRegional Growth Picture\n\nWorld Market Forecast by Region (2023-2032, $ Mill)\n\nBig-5 Regions CAGR Waterfall\n\nWorld Market Analysis by Clinical Area\n\nGlobal Forecast by Clinical Area (2023-2032, USD Mill)\n\nOncology Imaging AI Market Worldwide\n\nMarket Forecast by Region - Oncology Imaging AI (2023-2032, USD Mill)\n\nOncology Imaging AI: From Niche App to Enterprise Platform.\n\nRegional Growth Snapshot (2023-2032)\n\nStrategic Implications for Vendors\n\nMarket Momentum & Outlook\n\nGrowth & Maturity Highlights (All Vendors)\n\nFast-Mover M&A Targets (Oncology AI)\n\nRegulatory Velocity - New FDA Clearances Oncology Imaging AI\n\nModality-Reach Heatmap - Oncology Imaging AI 2024\n\nProcedure Volumes\n\nAI Applications & Adoption Trajectories\n\nCardiology Imaging AI Market Worldwide\n\nMarket Forecast by Region (2023-2032, USD Mill)\n\nCardiology AI - Why Adoption is Breaking Out\n\nMarkintel GTM Growth Maturity Framework - Cardiology Imaging AI Worldwide\n\nCompetitive Dataset - Cardiology AI-Imaging\n\nCompetitive Context - Cardiology AI\n\nGrowth & Maturity Highlights - Cardiology Imaging AI\n\nM&A Watch - Fast-Moving Rising Stars\n\nRegulatory Velocity - New Cardiology AI Imaging Clearances (Mar 2024 to June 2025)\n\nModality-Reach Heatmap - Cardiology AI 2024\n\nProcedure Volumes\n\nAI Applications & Adoption\n\nFuture Directions\n\nNeurology Imaging AI Market Worldwide\n\nMarket Forecast by Region (2023-2032, USD Mill)\n\nWhy Adoption is Moving Beyond Stroke Triage\n\nRegional Growth Snapshot\n\nStrategic Implications\n\nMarkintel GTM Growth Maturity Framework - Neurology Imaging AI Worldwide\n\nFast-Mover M&A Watch-List - Neurology AI\n\nRegulatory Velocity - New Neuro-AI Clearances - Neurology AI Imaging (Mar '24 - Jun '25)\n\nModality Reach Heat-Map - Neurology AI 2024\n\nProcedure Volumes - Neurology Imaging AI\n\nAI Use-Cases\n\nMarket Evolution\n\nRespiratory Imaging AI Market Worldwide\n\nMarket Forecasts by Region (2023 - 2032, USD Mill)\n\nWhat Ignited the 2024 Breakout\n\nRegional Growth Snapshot\n\nStrategic Implications\n\nMarkintel GTM Growth Maturity Framework - Respiratory Imaging AI - World\n\nFast-Mover M&A Watchlist\n\nRegulatory Velocity - New Respiratory-AI Clearances (Mar '24 - Jun '25)\n\nModality Reach Heat-Map - Respiratory Imaging AI Worldwide - 2024\n\nOrthopedic/MSK Imaging AI Market Worldwide\n\nMarket Forecasts by Region (2023 - 2032, USD Mill)\n\nWhat is Driving Acceleration\n\nRegional Growth Snapshot\n\nStrategic Implications\n\nMarkintel GTM Growth Maturity Framework - Orthopedic/MSK Imaging AI - World\n\nFast-Mover M&A Watchlist\n\nRegulatory Velocity - Orthopedic (MSK) Imaging AI Worldwide - (Mar '24 - Jun '25)\n\nUse Cases\n\nAI Solutions\n\nModality Reach Heat-Map - Orthopedic (MSK) AI\n\nOther Clinical Areas Imaging AI Market Worldwide\n\nMarket Forecasts by Region (2023 - 2032, USD Mill)\n\nRevenue Breakdown - \"Other\" Clinical Areas Worldwide (2024)\n\nSub-Areas, Use Cases, Vendors\n\nReimbursement Readiness Heatmap\n\nRegulatory Velocity - Other Clinical Areas Imaging AI (Mar '24 - Jun '25)\n\nWorld Market Analysis by Imaging Modality\n\nModality Outlook: Where AI Value Pools Shift Through 2032\n\nGlobal Forecast by Modality (2023-2032, USD Mill)\n\nMarket Math & Diffusion Pattern\n\nStrategic Takeaways for Vendors\n\nModality Definitions\n\nCT Modality Imaging AI Market Worldwide\n\nMarket Forecast by Region - CT Imaging AI (2023 - 2032, USD Mill)\n\nRegional mix in 2032\n\nAdoption Accelerators\n\nStrategic implications for vendors\n\nMarkintel GTM Growth and Maturity Matrix - CT Imaging AI - World\n\nCompetitive Dataset - CT AI-Imaging\n\nGrowth and Maturity Highlights - CT AI-Imaging Companies\n\nCompetitive Context - CT modality AI\n\nStrategic Takeaways for 2024-2027\n\nM&A Watchlist - Global CT AI\n\nRegulatory Velocity - CT-Specific Clearances\n\nAttach-Rate by Region (CT only, 2024)\n\nRevenue Split (Factory vs Retrofit) by Region - CT\n\nProcedure Volumes & Applications\n\nMRI Modality Imaging AI Market Worldwide\n\nMarket Forecast by Region - MRI Imaging AI (2023 - 2032, USD Mill)\n\nRegional Mix in 2032\n\nCompetitive Dataset - MRI AI-Imaging\n\nGrowth and Maturity Highlights - MRI AI-Imaging Companies\n\nCompetitive Context - MRI AI Modality\n\nStrategic Takeaways for 2024 - 2027\n\nM&A Watchlist - Global MRI AI\n\nRegulatory Velocity (MRI-AI Clearances)\n\nAttach-Rate by Region - MRI\n\nFactory vs Retrofit Revenue Split (MRI, 2024)\n\nProcedure Volumes & Applications\n\nX-ray Modality Imaging AI Market Worldwide\n\nMarket Forecast by Region - X-ray Imaging AI (2023-2032, USD Mill)\n\nRegional Split - 2032\n\nAdoption Accelerators\n\nStrategic implications\n\nMarkintel GTM Growth and Maturity Matrix - X-ray Imaging AI - World\n\nCompetitive Dataset\n\nGrowth and Maturity Highlights - X-ray AI-Imaging Companies\n\nCompetitive Context - X-ray Modality AI\n\nStrategic Takeaways 2024-27\n\nAttach-Rate by Region (X-ray, 2024)\n\nFactory vs Retrofit Revenue Split (X-ray, 2024)\n\nMarket & Procedure Volumes\n\nUltrasound Modality Imaging AI Market Worldwide\n\nMarket Forecast by Region - Ultrasound Imaging AI (2023-2032, USD Mill)\n\nRegional Split - 2032\n\nAdoption Accelerators\n\nStrategic Market Implications\n\nMarkintel GTM Growth and Maturity Matrix - Ultrasound AI - World\n\nCompetitive Dataset - FY-2024 Ultrasound AI-Imaging (Worldwide)\n\nGrowth & Maturity Highlights - Ultrasound AI\n\nCompetitive Context - Ultrasound AI\n\nStrategic Takeaways 2024-2027\n\nAI M&A Watchlist - Global Ultrasound\n\nRegulatory Velocity - Ultrasound AI (Mar-23-Mar-24)\n\nAttach-Rate by Region (Ultrasound)\n\nFactory vs Retrofit Revenue Split (Ultrasound)\n\nMarket & Procedure Volumes\n\nNuclear/PET Modality Imaging AI Market Worldwide\n\nMarket Forecast by Region (2023-2032, USD Mill)\n\nMarkintel GTM Growth and Maturity Matrix - Nuclear/PET imaging AI - World\n\nCompetitive Dataset - Nuclear/PET AI-Imaging\n\nGrowth & Maturity Highlights - Nuclear / PET AI\n\nCompetitive Context - Nuclear/PET AI\n\nStrategic Takeaways\n\nM&A Watchlist - Nuclear/PET Imaging\n\nRevenue-Stream Dynamics\n\nWorld Market Analysis by Clinical Application\n\nForecast by Clinical Application (2023-2032, USD Mill)\n\nAI Clinical Solutions\n\nWorld Market Analysis by End-Use Organization\n\nForecast by End-Use Organization (2023-2032, $US Mill)\n\nWorld Market Analysis by AI Technology\n\nForecast by AI Technology (2023-2032, $US Mill)\n\nAI Technology Definitions and Applications\n\nDeep Learning\n\nComputer Vision (Classical)\n\nMachine Learning (Traditional)\n\nNatural Language Processing (NLP)\n\nRobotics\n\nExpert Systems\n\nSummary Comparison of AI Technologies\n\nSECTION 5 - REGIONAL MARKET ANALYSIS & FORECAST\n\nCompanies Featured\n\n4D Medical Ltd.\n\nAccuray Inc.\n\nAdiposs SA\n\nAdvanced Micro Devices (AMD)\n\nAgfa HealthCare\n\nAidoc\n\nAIQ Solutions\n\nAirdoc\n\nAnnalise.ai\n\nAlign X-ray Insights\n\nArtrya\n\nAstute Imaging\n\nAvicenna.ai\n\nAZmed\n\nBaidu\n\nBayer Radiology\n\nBioMind\n\nBlackford Analysis Ltd.\n\nBracco Imaging S.p.A.\n\nBrainlab AG\n\nBrainomix Ltd.\n\nBrightHeart.ai\n\nButterfly Network, Inc. (NYSE: BFLY)\n\nCancerCenter.ai\n\nCanon Medical Systems\n\nCarestream\n\nCaristo Diagnostics\n\nCARPL.ai\n\nCathWorks\n\nCellmatiq GmbH\n\nCerebra AI\n\nClarius Mobile Health\n\nCleerly\n\nCombinostics Oy\n\nContextFlow GmbH\n\nCoreTechs Labs\n\nCureMetrix\n\ndeepc GmbH\n\nDeepHealth (RadNet)\n\nDeepMind (Google)\n\nDeepSight Technology\n\nDeepTek.ai\n\nDEEPNOID INC\n\nDeepwise\n\nDiagnocat\n\nDigital Diagnostics Inc\n\nEchoNous\n\nElucid BioImaging\n\nEnlitic\n\nEnvisionit Deep AI\n\nExo Inc\n\nFerrum Health\n\nFujifilm\n\nGE Healthcare\n\nGleamer\n\nGuerbet SA\n\nHeartflow, Inc.\n\nHeartFocus\n\nHeuron\n\nHologic Inc\n\nHuawei\n\nHuiyihuiying (HY Medical)\n\nHyperfine\n\nicometrix\n\nImageBiopsy\n\nImagen Technologies\n\nIncepto Medical SAS\n\nInfervision\n\nJLK Inc\n\nKoios Medical\n\nKonica Minolta\n\nLPIXEL\n\nLantheus Holdings\n\nLunit Inc.\n\nMediaire GmbH\n\nMedian Technologies\n\nMedtronic PLC\n\nMerative L.P.\n\nMicrosoft\n\nMindray Ltd\n\nMSKai\n\nNanox Imaging Ltd.\n\nNico-Lab B.V.\n\nNIRAMAI\n\nNVIDIA\n\nOlea Medical\n\nOracle\n\nOxipit\n\nPerimeter Medical Imaging\n\nPerspectum\n\nPhilips Healthcare\n\nPro Medicus, Ltd.\n\nQure.AI\n\nQuibim\n\nRadiobiotics\n\nRad AI\n\nRapidAI\n\nSamsung Healthcare\n\nScreenPoint Medical\n\nSegami Corporation\n\nShenzhen Keya Medical Technology Co., Ltd\n\nShukun Technology / Careverse\n\nSiemens Healthineers\n\nSirona Medical\n\nSmart Soft Healthcare (CoLumbo)\n\nSpectral AI\n\nStryker Corp\n\nSubtle Medical\n\nSynapsica\n\nTata Elxsi\n\nTempus AI\n\nTencent Holdings\n\nTherapixel\n\nUltromics\n\nUnited Imaging\n\nUs2.ai\n\nVara AI\n\nVista AI\n\nViz.ai\n\nVoxelCloud\n\nVUNO\n\nZimmer Biomet\n\nFor more information about this report visit https://www.researchandmarkets.com/r/x3z0ua\n\nAbout ResearchAndMarkets.com\n\nResearchAndMarkets.com is the world's leading source for international market research reports and market data. We provide you with the latest data on international and regional markets, key industries, the top companies, new products and the latest trends.",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/23/3154945/28124/en/AI-Transformation-in-Radiology-Navigating-Rising-Scans-Stagnant-Headcounts-and-Evolving-Reimbursements.html",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "EQR7: Beelink releases new mini-PC globally with 'near-silent' fan and 32 GB RAM",
      "content": "GMKtec releases affordable NucBox M2 Pro S mini-PC globally\n\nECS Liva Z11 Plus mini PC debuts with up to Intel Arrow Lake processor\n\nD12 Plus: New OCuLink-wielding mini-PC now available with AMD Krackan Point or AMD Strix Point and up to 128 GB RAM\n\nBase GMK EVO-X2 mini PC with top-end AMD Strix Halo APU falls below $1,400\n\nPerformance-focused Minisforum MS-S1 Max with USB4 v2 and dGPU support goes global\n\nFramework Desktop runs more efficiently than the GMK EVO-X2 with the exact same Ryzen AI Max+ 395 processor\n\nAMD Ryzen AI Max+ 395 is powering some of the fastest mini PCs available\n\nGMKtec intros affordable NucBox M5 Ultra mini PC with launch discounts\n\nAsus ExpertCenter PB64: New mini PC comes with Core Ultra 7 and up to 64GB RAM\n\nMaxtang intros new mini PC with up to Ryzen AI 9 HX 370 and compact form factor\n\nQuiet budget mini PC for the home office: review of the Ninkear M7 with Ryzen 5 APU for office & multimedia\n\nBlackview MP100: AMD-powered mini PC with up to 64GB RAM launches in new configuration\n\nAoostar Maco: Compact mini-PC primed for global release with OCuLink expansion\n\nMinisforum reveals MS-S1 Max sporting up to 128 GB RAM with global launch date also confirmed\n\nVerdict on the Geekom A9 Max: Best Geekom AI mini PC with AMD Ryzen AI 9 HX 370\n\nRedragon announces affordable mini PC with Ryzen 7 8845HS and USB 4.0",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/EQR7-Beelink-releases-new-mini-PC-globally-with-near-silent-fan-and-32-GB-RAM.1122098.0.html",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Deploying AI: Balancing Power, Performance and Place",
      "content": "Tech Monitor recently consulted Scandinavia’s IT leaders about the practicality of deploying AI within their businesses. First stop: Copenhagen. (Photo: fantasyform / Shutterstock)\n\nThis month, Tech Monitor found itself back in the northern latitudes of Scandinavia, almost a year after it consulted the region’s IT leaders about the efficiency-creating potential of AI for their businesses. Our first stop was Copenhagen, to take stock of AI deployments throughout Denmark and to explore how companies in the country are balancing power, performance and place.\n\nWhat became clear during a lively two-hour discussion in Copenhagen’s Nimb Hotel is that maturity levels have risen. Today, most organisations are either deploying AI applications or are in the advanced stages of moving from proof of concept to rollout.\n\nThe merits of generative AI, especially when it comes to serving internal users and bringing efficiencies to internal processes, is clear. Less apparent is what AI means for the future of the workforce, coding, or the IT department itself. As a result, these existential questions – rather than the day-to-day concerns about infrastructure, compute power and the merits of cloud computing as home for AI experimentation – dominated the roundtable.\n\nAttendees at a Tech Monitor roundtable in Copenhagen, held in association with AMD. (Photo: Tech Monitor)\n\nThe end of the IT department?\n\nOne of the senior technology leaders present offered a vision of the future organisation that doesn’t include a traditional, centralised IT function. Given how GenAI is democratising software engineering, he argued that there is an opportunity to federate application development to every organisational function that requires it, from marketing to human resources and from finance to operations.\n\nNot only do these functions know best what they need (and control their own budgets), AI now allows them to build what they need, too. The net result? Devolved IT leaving the proponent of this argument not only talking himself out of a job but threatening the employment status of most people around the table, too.\n\nUnsurprisingly, not everyone was ready to accept this future vision. As another attendee pointed out, multiple departments responsible for their own development means multiple processes, multiple visions of business need, and, most likely, multiple versions of the same software tools. Another attendee put it simply: “It’s a disaster for compliance, complexity, and cost.”\n\nNot everyone thought this way, however. Some felt compliance could be centralised in this federated model and that the IT function could be reinvented as a quality assurance-led department.\n\nThe future of coding\n\nIf not the end of the IT department, what about the demise of the human coder? Most organisations represented around the table – drawn from sectors including financial services, healthcare, and retail – are currently augmenting human coders with coding co-pilots. Broadly speaking, they are automating the “grunt work,” leaving software engineers to specify needs, build requirements, and validate outcomes (though the co-pilots happen to be pretty good at validation, too).\n\nThat is the division of labour, for now at least. But what if we no longer need developers at all? That question was posed by an attendee who, like others around the table, has spent his career being taught the value of coding.\n\nDespite this, he wasn’t sentimental about its potential demise. Rather, he questioned an ongoing necessity in its manual incarnation. Another attendee compared today with Johannes Gutenberg’s invention of the movable-type printing press in the mid-15th century. For the monks whose job it had been to transcribe holy manuscripts, new technology rendered their role – but, critically, not their overall purpose – redundant.\n\nFor the tech optimist, automation opens up new opportunities. Human expertise gets deployed elsewhere, more effectively. And, to extend the comparison, in at least one telling of the arrival of the Gutenberg Press, few 15th-century scribes lamented the passing of a tedious job that took place in damp, cold conditions and increased the likelihood of poor and deteriorating eyesight.\n\nThe talent gap\n\nBeyond questions of potentially deskilling a future generation, some organisations are struggling to plug wider gaps in their AI talent pool. As one attendee put it, it’s no longer a problem for firms to figure out where AI can help. “We have 140 use cases,” they said. Rather, “it’s about figuring out how to do it”. For her, it is now a question of how to identify and prioritise talent need. Data modelling, validation and implementation are among the skills that are in short supply, she said. Legal and compliance oversight capabilities are also lacking.\n\nElsewhere, organisations are seeking to reskill their existing workforce to reflect changing requirements. One, for example, is committed to providing at least ten hours of training per employee per year. The mission: to transform the organisation so it is AI-ready. This is perhaps an example of organisations playing catch-up when it comes to artificial intelligence. Once again, the speed of the AI opportunity means organisational readiness is a long way behind the capability and availability of the technology.\n\n‘Deploying AI: Balancing Power, Performance and Place’ – a Tech Monitor / AMD executive roundtable discussion – took place on Tuesday, 16 September 2025 at the Nimb Hotel, Copenhagen, Denmark.",
      "source": "Techmonitor.ai",
      "url": "https://www.techmonitor.ai/sponsored/deploying-ai-balancing-power-performance-and-place/",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Can't upgrade your Windows 10 PC? You have 5 options - and 3 weeks to act",
      "content": "DimaSobko/iStock/Getty Images Plus\n\nFollow ZDNET: Add us as a preferred source on Google.\n\nZDNET's key takeaways\n\nWindows 10 support ends on Oct. 14, 2025.\n\nYou have free and paid options for extended updates.\n\nDoing nothing is not a safe option.\n\nHave you decided what to do with your old Windows 10 PCs when they reach their official end-of-support date in two weeks?\n\nThe official deadline is October 14, 2025. Microsoft is not going to back down at the last minute and offer an extension. The hardware requirements aren't going to change, either. So, if you have a laptop or desktop PC that doesn't pass the compatibility checks, Microsoft will block you from upgrading through Windows Update, and they will encourage you to buy a new PC instead.\n\nBut you have other alternatives, including some new ways to continue getting security updates for an extra year at no cost. Don't procrastinate, though -- if you're responsible for one or more Windows 10 PCs that fail Microsoft's Windows 11 compatibility tests, you need to choose one of these five options soon.\n\nAlso: How to get free Windows 10 security updates through Oct. 2026\n\nEven if you and your business aren't affected by this deadline, it's likely that you have friends and family members who own older PCs that are still perfectly functional but can't be upgraded to Windows 11. They've probably been ignoring warning messages for a few months now, but those messages are going to get more insistent as the deadline approaches. You can help them out by sending them a link to this article.\n\n1. Sign up for extended security updates\n\nMicrosoft will continue developing security updates for Windows 10, but they won't be free for everyone. Extended Security Updates (ESUs) for Windows 10 will be available on a subscription basis for up to three years.\n\nAlso: Consumer Reports calls Microsoft 'hypocritical' for stranding millions of Windows 10 PCs\n\nHow much are these paid-for updates going to cost? That depends.\n\nConsumers have the option to receive security updates for one additional year after the end-of-support date, with the deadline pushing out to October 2026. The list price for that subscription is $30 a year, but you can cut the cost to zero by using Microsoft Rewards points earned by using the Bing search engine or the Windows Backup tool. (For details, see How to get Windows 10 extended security updates for free.) That's the obvious choice if you simply want to postpone the decision. Just be aware that the consumer ESU subscription is only good for one year. At the end of that year, you'll have an unsupported PC once again, so make sure you use that time to figure out your exit strategy for October 2026.\n\nAlso: I replaced my Microsoft account password with a passkey - and you should, too\n\nIf you're an administrator at an educational institution with a deployment of Windows 10 Education edition, you're in luck. You can purchase extended updates for up to three years, and the cost will bea mere pittance: $1 per machine for the first year, $2 for the second year, and $4 for the third and final year, taking you all the way to October 2028.\n\nIT pros who manage a fleet of business PCs aren't so lucky and will need to pay dearly to stick with Windows 10. A license for the Extended Security Updates program is sold as a per-device subscription. For the first year, the cost is $61 per PC. For year two, the price doubles, and it doubles again for year three. Do the math, and the cost is staggering: a three-year ESU subscription will cost $61 + $122 + $244, for a total of $427.\n\n2. Buy a new PC (or rent a virtual PC)\n\nMicrosoft and its partners would like you to replace that unsupported hardware with a new PC. You might even be tempted by one of the shiny new Copilot+ PCs, with their dedicated neural processing units, or maybe a powerful gaming PC. But throwing away a perfectly good computer seems wasteful, and it's not an option if you're hanging on to Windows 10 because you have mission-critical software or an expensive hardware device that's incompatible with Windows 11.\n\nAlso: I never pay full price for PCs or Macs, thanks to these 7 money-saving tricks\n\nYou also have the option to rent a new virtual PC by signing up for Windows 365, which allows you to connect remotely to your own Windows 11-powered virtual PC in Microsoft's cloud. A Windows 365 subscription works on Windows 10 and includes extended security updates for the host PC for up to three years. Windows 365 isn't cheap (plans start at $28 a month), but that option probably costs less than a new PC.\n\nFor businesses, replacing a PC that is more than six years old is absolutely the correct option. Ask your CPA about depreciation deductions.\n\n3. Upgrade your 'incompatible' hardware to Windows 11\n\nThat pesky compatibility checker might insist that you can't upgrade your Windows 10 PC to Windows 11, but there are indeed documented ways to bypass those restrictions. You just have to jump through a few technical hoops. Frankly, if you have a PC that is less than 10 years old, this is the easiest, cheapest, and most reliable option.\n\nAlso: The 10 apps I can't live or work without - on Windows, Mac, and mobile\n\nYou can find all the details in this article: How to upgrade your 'incompatible' Windows 10 PC to Windows 11. Here's the short version:\n\nFor PCs originally designed for Windows 10 (basically anything designed in 2016 or later), you need to make one small registry edit and then ensure that your PC is configured to use Secure Boot with the Trusted Platform Module (TPM) enabled. Even an old TPM 1.2 chip will do. As many readers have confirmed via email, this process works seamlessly as long as you've got those configuration details set properly. This option will work even with PCs that are 10 years old.\n\nFor older PCs originally designed for Windows 7 or Windows 8.1, you might need to use a third-party tool called Rufus to bypass installation challenges. That's especially true on PCs that use a legacy BIOS instead of UEFI firmware and for those that don't have access to a TPM. Make sure you have the most recent version of Rufus (version 4.9 or later) to keep up with Microsoft's latest compatibility checks.\n\nThose upgrade options can't save a device whose CPU lacks support for two specific instruction sets -- POPCNT and SSE 4.2. Most PCs built using Intel CPUs from 2009 or later will pass this test; AMD CPUs from 2015 or later should also be OK. As I note in this article, there is no workaround if you own one of those very old PCs that fail this test.\n\nAlso: How to upgrade from Windows 11 Home to Pro - without overpaying\n\nIf you do use one of these upgrade hacks, don't be alarmed by the threatening message you might see when trying to do an unsupported upgrade: \"If you proceed with installing Windows 11, your PC will no longer be supported and won't be entitled to receive updates. Damages to your PC due to lack of compatibility aren't covered under the manufacturer warranty.\"\n\nThat's deliberately misleading language from Microsoft. As I've noted before, that warning doesn't really say that Microsoft is going to cut off your access to updates; it simply says your PC is no longer supported, and you're no longer \"entitled\" to those updates. That bit of legalese is a tell on Microsoft's part, disclaiming corporate responsibility without actually saying what it will do.\n\nIf you don't want to mess with the registry and you're willing to do a clean install on a system that has a TPM but fails the CPU check, just use Rufus to create a bootable Windows 11 installation drive, which bypasses the compatibility checker completely. You'll need to restore your data files from a backup or from the cloud, and you'll also need to install your software from scratch, but that's no more difficult than setting up a new PC.\n\n4. Ditch Windows completely\n\nYou could keep your old hardware and replace Windows 10 with the flavor of Linux you prefer. If you've got the technical know-how and experience to manage the transition, that option is worth considering. Thanks to Google Workspace, Microsoft 365, and a million or so web-based services, you can do just about all your basic work in a web browser these days. You might not even notice what operating system is running that browser.\n\nAlso: Yes, you can run Windows apps on Linux - here are my top 5 ways\n\nSwitching to Google's free ChromeOS Flex might also be possible, although the compatibility requirements for that alternative are just as likely to get in your way. I wrote about my experience here: Installing ChromeOS Flex? 5 things you need to do first to avoid headaches. As I pointed out, \"If you've got an old PC or Mac and you're thinking of installing ChromeOS Flex on it, don't do anything until you check Google's official ChromeOS Flex certified models list.\"\n\nPay special attention to the end-of-support date for the PC you're thinking of upgrading. It doesn't make much sense to replace Windows 10 with a release of ChromeOS Flex that's also set to end support in the next year.\n\nAlso: 7 most Windows-like Linux distros - if you're ready to ditch Microsoft\n\nSwitching to Linux or some derivative of Linux might be a good way to repurpose an old PC. For consumers and businesses with existing investments in Windows software, it might not be a realistic alternative, but it's worth considering.\n\n5. Ignore the end-of-support deadline completely\n\nYou could do nothing at all -- just continue running your unsupported operating system and hope for the best. That's a bad idea that exposes you to the very real possibility that you'll fall prey to a security exploit. Unfortunately, a lot of people are going to do just that. Some percentage of them will end up regretting their decision.\n\nI've heard from some folks who believe that being extra careful and using third-party antivirus software will protect them from harm. I wouldn't bet my business on that strategy.\n\nAlso: Stop paying for antivirus software. Here's why you don't need it\n\nIf you're intent on doing so, consider installing the third-party 0patch agent to deal with any security issues that aren't addressed by Microsoft. The free 0patch personal plan includes patches for known 0-day vulnerabilities, but if you want all Windows 10 patches, or if the PC is used for business or enterprise tasks, you'll need to pay for a 0patch Pro plan at a per-PC rate of €24.95 per year -- for customers in the US, at current exchange rates, that equates to less than $2.50 a month.\n\nI wouldn't recommend that for a PC that you use for business, but if you have a device you use for casual tasks at home, you might be willing to take the risk.\n\nWhat does 'end of support' mean?\n\nFor nearly a quarter-century, Microsoft has had a formal policy of supporting each major operating system release for 10 years. Windows 10 was released in 2015, so its 10 years are up, as expected, in 2025.\n\nThe end date is right there on the Microsoft Support document that lists products retiring or reaching the end of support in 2025. Every retail edition of Windows, as well as the Enterprise and Education editions, is slated for retirement.\n\nIf you have a Windows 10 PC, it faces mandatory retirement in 2025 Screenshot by Ed Bott/ZDNET\n\nThat schedule is defined by Microsoft's Modern Lifecycle Policy, which is documented on the Microsoft Lifecycle page: \"Windows 10 will reach end of support on Oct. 14, 2025. The current version, 22H2, will be the final version of Windows 10, and all editions will remain in support with monthly security update releases through that date.\" In a separate support article, Microsoft reiterates that as of Oct. 14, 2025, it will no longer provide technical support or security and reliability fixes for PCs running Windows 10.\n\nAlso: How to upgrade your 'incompatible' Windows 10 PC to Windows 11 - for free\n\nWhen a Windows version reaches its end-of-support date, the software keeps working, but Windows Update stops delivering security and reliability fixes:\n\n[There] will be no new security updates, non-security updates, or assisted support. Customers are encouraged to migrate to the latest version of the product or service. Paid programs may be available for applicable products.\n\nThat part in the middle sounds encouraging, doesn't it? \"Customers are encouraged to migrate to the latest version of the product or service.\" Unfortunately, that's not a supported option for customers running Windows 10 on hardware that doesn't meet the stringent hardware compatibility requirements of Windows 11. If you try to upgrade one of those PCs to Windows 11, you'll encounter an error message.\n\nAnd then you'll have to choose one of the five options above.",
      "source": "ZDNet",
      "url": "https://www.zdnet.com/article/cant-upgrade-your-windows-10-pc-you-have-5-options-and-3-weeks-to-act/",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Why Intel's US$16 billion lifeline won't solve its foundry crisis?",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250923PD219/intel-funding-pc-chips-nvidia.html",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Adobe Acrobat Pro + Microsoft Office Professional 2019 License Bundle for $89",
      "content": "Easily Create, Edit, Convert, and Protect Your Documents on Mac or Windows Without Connecting to Cloud\n\nBoost your productivity with the essential offline solution for all your PDF needs. With Adobe Acrobat Pro 2024, you can easily create, edit, convert, and protect your documents on Windows and Mac without connecting to the cloud. Start a document, create a new form from scratch, and manage your documents efficiently with new features, including enhanced accessibility tools. The updated Acrobat interface also means that you’ll be able to easily find the tools you need to complete PDF tasks faster than ever. You can own this software for a full three years, no subscription required.\n\nAdobe Acrobat Pro 2024 and is provided by Adobe Inc.\n\nWhat you can do with Adobe Acrobat Pro 2024\n\nDesktop-Only PDF Tools: Work securely offline — without connecting to the cloud\n\nWork securely offline — without connecting to the cloud Enhancements to Existing Features Edit text & images and reorder and delete pages in a PDF Convert PDFs to Microsoft Word, Excel, or PowerPoint files while preserving fonts, formatting & layouts\n\nForms: Easily create, fill & sign forms\n\n\n\nEasily create, fill & sign forms Security Features: Password-protect documents or redact sections of a PDF to keep sensitive information secure.\n\nPassword-protect documents or redact sections of a PDF to keep sensitive information secure. Star a Document: Mark documents as favorites or tag them for follow-up\n\nMark documents as favorites or tag them for follow-up Extract Discontinuous Pages: Remove specific pages from a PDF to focus on what you need\n\nRemove specific pages from a PDF to focus on what you need Accessibility Updates: Improved tagging for better accessibility for people with disabilities\n\nImproved tagging for better accessibility for people with disabilities New Acrobat Experience: A modern interface that makes finding & using PDF tools easier",
      "source": "Stacksocial.com",
      "url": "https://www.stacksocial.com/sales/adobe-acrobat-pro-microsoft-office-professional-2019-license-bundle",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Talk Python to Me: #520: pyx - the other side of the uv coin (announcing pyx)",
      "content": "pyx brings Python packaging closer to fast, predictable, and boring by pairing a smart server with the smart clients many of us already use. If PyPI is the public square, pyx is your team’s front desk: it mirrors the world, applies your rules, and keeps installs humming from everyday web apps to CUDA-heavy ML stacks. The result is less friction, more reliability, and a packaging flow that respects your time.\n\nHere are resources to go deeper on the themes from this episode, from beginner Python to modern packaging and ML installs. Course links include a tracking parameter so we know these came from the podcast.\n\n\"The biggest PyTorch wheels are like almost three gigs, I think.\" -- Charlie Marsh\n\n\"You also don't have to use pyx to use uv obviously.\" -- Charlie Marsh\n\nAstral’s ecosystem context: Ruff, uv, and pyx pyx joins Ruff and uv to form a coherent toolchain focused on performance and reliability for Python at scale. The blog history shows steady investment across these tools.\n\nFits existing publishing and packaging flows Package authors can keep building wheels and sdists, push via Twine, and follow the canonical PyPA guidance. Ops teams can layer promotion and retention policies in the registry rather than bespoke scripts.\n\nRelease philosophy: conservative about dates, quality first Astral avoids promising dates publicly to keep quality high and reduce pressure on shipping. In the episode, Charlie describes this as a deliberate policy to prevent over-promising. (From the transcript.)\n\nNot a PyPI replacement, but a complement PyPI remains the public commons; pyx is an organization’s front door. Mirror the world, host private packages, and apply your rules without breaking compatibility with standard clients.\n\nWhy this matters to app devs and data scientists App teams get faster CI and fewer resolution surprises; data scientists get correct CUDA-matched wheels and less time fighting install matrices. The result is more time building and less time debugging environments.\n\nSecurity and supply-chain posture improves with mirroring and policy A controlled mirror helps you react to supply-chain issues and reduce exposure to typosquatting or account-takeover campaigns that target public indexes. This builds on PyPI’s ongoing security initiatives.\n\nGPU-aware installs target real ML pain points Installing GPU stacks is tricky because CUDA versions, OS, Python versions, and large binary wheels must align. pyx focuses on making the PyTorch path smoother by serving the right artifacts for your environment and avoiding unnecessary rebuilds.\n\nCentralized policy and composition give orgs control Rather than scattering config across developer machines, pyx lets teams set server-side rules: prefer internal packages, mirror from PyPI, and control what gets promoted or blocked. That turns the registry into a system of record for your Python artifacts.\n\nSmart client + smart server is the design pattern Uv is already fast at resolving and installing; pairing it with a registry that understands Python packaging details reduces edge cases and enables new optimizations. This is the \"meet in the middle\" model adopted by mature ecosystems.\n\nWorks with pip, uv, and standard publishing tools pyx speaks the same registry protocols, so you can install with pip or uv and continue publishing with Twine . Using uv with pyx can unlock additional fast paths, but it is not required. (Stated in the episode and aligned with docs.)\n\npyx is a Python-native package registry that mirrors PyPI and adds team-friendly controls pyx runs on the server side and mirrors PyPI while exposing Python-focused features for speed and reliability. It slots into existing workflows so teams can keep using familiar tools while gaining predictability and performance.\n\nIf package installs have felt slow or flaky, this episode explains why and how smarter tooling fixes it. You’ll hear how registries (servers like PyPI or pyx) and clients (tools like pip or uv) cooperate, why wheels are faster to install than building from source, and why GPU-heavy stacks like PyTorch complicate versioning and artifact selection. Skim the PyPI overview and PyTorch’s install matrix to follow along: pypi.org and pytorch.org/get-started/locally .\n\nCharlie Marsh is the founder and CEO of Astral, the team behind Ruff (a fast Python linter and formatter) and uv (a high-performance Python package manager). In this episode he announces pyx , Astral’s Python-native package registry, and explains how it complements PyPI and today’s tooling to make installs faster and more predictable.\n\nCollapse transcript\n\n00:00 A couple years ago, Charlie Marsh lit a fire under Python tooling with Ruff and then uv.\n\n00:05 Today, he's back with something on the other side of that coin, pyx. pyx isn't a PyPI replacement.\n\n00:13 Think server, not just index. It mirrors PyPI, plays fine with pip or uv, and aims at making installs faster and predictable by letting a smart client talk to a smart server. When the client and server understand each other like uv and pyx do, you get new fast paths, fewer edge cases, and the kind of reliability teams beg for. If your Python packaging has felt like friction, this conversation is traction. This is Talk Python To Me, episode 520, recorded Tuesday, September 2nd, 2025.\n\n01:02 Welcome to Talk Python To Me, a weekly podcast on Python. This is your host, Michael Kennedy.\n\n01:07 Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython, both accounts over at fosstodon.org, and keep up with the show and listen to over nine years of episodes at talkpython.fm. If you want to be part of our live episodes, you can find the live streams over on YouTube. Subscribe to our YouTube channel over at talkpython.fm/youtube and get notified about upcoming shows.\n\n01:32 This episode is brought to you by Six Feet Up, the Python and AI experts who solve hard software problems. Whether it's scaling an application, driving insights from data, or getting results from AI, Six Feet Up helps you move forward faster. See what's possible with Six Feet Up. Visit talkpython.fm/sixfeetup. Charlie, welcome back to Talk Python.\n\n01:55 It's awesome to have you here. I'm glad to be back. It's always a pleasure.\n\n01:58 Yes, it is. I want to say, ty, thank you for you to come back. How about that? Last time you were\n\n02:03 here, we talked about ty with you and Carl Meyer, right? That was fun. Yes. And we're hard at work.\n\n02:08 I mean, I get asked basically every day, but we're hard at work working towards the beta release, which will be soon. We have a date for it internally, but we tend to have a policy of not\n\n02:18 sharing deadlines externally. Let us all take AI, that is Apple intelligence, as a deep lesson in corporate history for not getting out over the skis and not releasing.\n\n02:30 I mean, they were running like suites of ads about all the feature for Apple intelligence before even the features existed.\n\n02:37 And then they had to cancel them, which is a little hard.\n\n02:39 So no, I'm here for you.\n\n02:41 I'm here with it.\n\n02:41 Yeah, I think for us, it's like we put enough pressure on ourselves to get it out.\n\n02:45 So we don't need the external pressure to get it out.\n\n02:49 But yeah, we do have a deadline set and we're working hard towards it.\n\n02:51 A lot of this stuff does happen in GitHub.\n\n02:54 So there's ability to like peek over the fence and see what's happening at least, right?\n\n02:57 Yes, if you closely watch our GitHub, Nothing is like ever a surprise.\n\n03:01 Except for that it is a surprise.\n\n03:02 Like Red Knot kind of snuck in there.\n\n03:04 That was the original name for ty.\n\n03:06 Yeah.\n\n03:06 Yeah, exactly.\n\n03:07 Up until the day that we did your podcast.\n\n03:09 Yes, that's right.\n\n03:10 That was awesome.\n\n03:11 I think that was literally the day that we changed the name for Red Knot to ty.\n\n03:14 And I had to tell you, hey, this is what it's going to be done.\n\n03:17 Yeah, I was scrambling like, oh, I got to change my notes.\n\n03:19 Like this morning it's renamed.\n\n03:21 Okay.\n\n03:22 I had to change the title in like the YouTube stream and all that.\n\n03:25 That's right.\n\n03:26 Well, it ended up being a good forcing function for us because we were basically like, Okay, we have to choose a public name by the time we do the Talk Python show.\n\n03:34 I love it. I love it.\n\n03:35 Because we don't want to go on and use the code name.\n\n03:36 Exactly. It's just too hard to find and replace an audio.\n\n03:39 Okay, well, that was really cool.\n\n03:42 I think maybe give us the elevator pitch on Charlie Marsh and Astral.\n\n03:46 Just who are you? I know most people know you from various ways, but at the same time, there's plenty of listeners who don't.\n\n03:51 Yeah, totally. So my name is Charlie. I'm the founder and CEO of Astral.\n\n03:56 we build what we call high performance python tooling so we built a couple of different tools you might be familiar with some or all or none of them the first tool we built was called rough it's a python linter a code formatter and it does a lot of code transformation so it tries to like find issues and fix them for you then we built uv which is our python package manager also manages like your python tool chain everything like that it's kind of meant to be you install it and it hopefully takes care of all your packaging and running Python problems. We're also building a tool called ty, which Michael just mentioned, which is our type checker and language server.\n\n04:30 It's kind of like an alternative to like mypy, Pyright, also PyLance. So you can use it to check your Python types, all that kind of stuff. I've been working on this stuff for about two and a half, three years. So we try to build Python tooling that hopefully solves a lot of the user experience problems I think that people have when they get started with Python, but also tries to\n\n04:49 scale to very large projects. Yeah, it's really interesting. I don't know if people necessarily believed that we had a Python tooling problem. I know they thought we had a packaging problem in the sense that why does Conda and Anaconda exist at all? It's because there were platforms where you basically could not, or it would be very difficult to install a thing, right? Like, oh, do you not have the Fortran compiler? Oh, you do have the Fortran compiler, but it's the new one, not the old. It's like, are you serious? This is the thing I need, But, you know, sometimes there's just weird edge cases.\n\n05:22 So I know people knew they had that, but I don't know they necessarily felt they had a performance problem until they saw Ruff and uv and they're like, oh, okay, that's different.\n\n05:31 What's the reaction been?\n\n05:32 I was a little bit wondering about that question too when I like started working on Ruff, because when I started working on Ruff, I mean, I felt like there was a little bit of a performance problem because I had tried to work on some large projects and they'd struggled a little bit.\n\n05:45 And when I released Ruff, I kind of wanted to see like, well, if things are way faster, would people really care? And so I think it's turned out that if I'd asked people at the time if they cared a lot about a faster linter, I think a lot of people would have probably discouraged me from investing a lot of time into that.\n\n06:00 It's never going to go anywhere. This will never amount to nothing.\n\n06:03 But since then, that's one of the reasons I started working on this stuff full-time is because the interest was just... The adoption was just so fast. And I think a lot of it is with performance, you kind of don't realize that things can be really different until you've experienced it.\n\n06:16 Like with uv now, you can install things much, much faster. And if you go back to a different tool, it can be a little bit jarring to be like, oh, wow, that's really different. So it turns out that people actually really, if you can give them a tool that you hope is, one of the things that we look to do a lot was like, we want this to be kind of as close to a drop-in replacement as we can, but also solve some more problems. And so it was like, if we give you a tool that we think is kind of a drop-in replacement, but it's also way faster, the value proposition was really strong.\n\n06:43 people are like, well, why wouldn't I use this? I've started adding rough commands to just places that they wouldn't normally exist. Like for normal linting type of operations, like in all of my editors that I work with, like the save or format document is just run ruff on that. I have a permanent rules file for when I'm doing agentic coding that says anything that you touch, run ruff format and rough check dash fix on it. Yeah, me too. And it's like, yeah, that was like one of\n\n07:16 the cool things for me was like, it can really change how you use the tool. Like you can run it on a keystroke. Whereas before it was like some expensive heavy step that had to paralyze across all your, like maybe made your machine take off a little bit and like could only run in CI, stuff like that. So yeah, that's been a big part of what we want to try and do.\n\n07:33 Yeah. Instead of being something you've got to choose, I'm going to take a moment and do this.\n\n07:36 It's just so fast that it can just happen automatically on like file save or on get commit or whatever.\n\n07:43 I think that we've learned over time is that the stuff that we're working on, it's not just about performance.\n\n07:49 Like I think performance is a great, it's a, anything we build, we want it to be extremely fast and ideally a lot faster than anything else out there.\n\n07:56 But we're also trying to solve kind of like other problems.\n\n07:58 And I think uv is like a good example of that where yes, performance is a big part of it.\n\n08:03 But I think we also have a lot of users where like the performance doesn't really matter.\n\n08:07 And what they actually care about is the like the overall experience that we're trying to deliver, which is like you install the thing.\n\n08:14 It installs Python for you.\n\n08:15 It manages the virtual environment abstraction for you.\n\n08:18 It does all these things for you.\n\n08:19 And you don't really have to like think and worry about like trying to make a bunch of problems go away.\n\n08:23 Sure.\n\n08:23 And I think you've done that super well.\n\n08:24 I remember when we first talked about uv three episodes ago, maybe before you had come up with the uv lock concept and the package.\n\n08:35 It was the uv pip CLI, yeah.\n\n08:36 Yeah, exactly.\n\n08:37 There was a lot of pushback from people like, why are you not just doing uv install package?\n\n08:44 There's like this uv pip install package.\n\n08:46 And you and I at the time spoke about how you wanted to save space, like room in the namespace for future work.\n\n08:54 I think that came out well, don't you?\n\n08:55 I'm really happy with how it played out.\n\n08:57 There was a period of time where I almost folded because like when we came out was uv pip install. Everyone was like, can we please not write the pip? Can you just make it uv install? And yeah, the whole thing for us was like, we were saying, well, yeah, but we want uv install. I ended up being, we used the name uv sink, but we were like, we want like a very different CLI, like a totally different experience. And so that's why we're doing that. And at the time when we launched with just the uv pip stuff, I mean, that actually grew quite a lot even before we launched the uv sink like that. And it's still like a fully supported, like first class thing in the in uv but when we came out with that yeah there was a period of time where i was like hey maybe we should consider like getting rid of this because people keep complaining about it but we because we do listen we listen when people have feedback we listen when people yeah of course have criticism but we stuck to it and i think ultimately that was the right decision yeah i do too yeah it just meant that we i think things became clearer too once we launched like that other set of apis like uv sync uv run uv lock because then there was like some contrast And it is still a lot to explain, but we're trying to do a hard thing of like both supporting like all these existing workflows, this huge existing ecosystem and innovate on top of it.\n\n10:05 Sure.\n\n10:06 Yeah.\n\n10:06 We kind of try to support those two worlds and I think we made good decisions there, but yeah, it is.\n\n10:11 I'm glad we stuck to it.\n\n10:12 Very good.\n\n10:13 To me, I was kind of like, I don't get the drama because I don't type any of that stuff anyway.\n\n10:19 I have aliases that are way shorter that used to do stuff with pip.\n\n10:24 So I edited my RC file and I put a uv space in front of the commands.\n\n10:27 I'm like, okay, well, that transformation is done.\n\n10:29 We're good to go.\n\n10:30 You know what I mean?\n\n10:31 That was the goal.\n\n10:32 Yeah.\n\n10:33 So for me, I actually feel like it kept it pretty straightforward.\n\n10:36 But yeah, there was...\n\n10:37 But once you came out with the sync concept, the uv tool, maybe riff a little bit on uv tool before we get into pyx and stuff too much, because I think that's actually a bit of a hidden gem.\n\n10:48 And I'll say why, but I want you to riff on it first.\n\n10:49 Tell people about the tool and the script running sort of aspect that maybe is less\n\n10:54 then. uv tool is this, you know, we think of a tool as like an executable application that you can install. So like often, right, when you're using Python, you're like working on a project and you install a bunch of libraries that you need to import. But, you know, there's also a very different way of like installing and using Python packages, which is a lot of packages are just executables. So like when youinstall ruff as a Python package, it's actually really just like a binary that you like unpack and run. When you run uv tool,install ruff, like we just basically install that executable and like make it available on your path. The nice thing about uv tool is like, there are lots of applications and tools that you can install. Like just, you just run like uv tool install or whatever, and then like black or rough or my pie or whatever gets added to your path and you can use it. And we also have this alias uvx. So you can do like uvx rough check.\n\n11:44 That's actually like typically what I use, which is an alias for like install this tool and run it.\n\n11:49 So if you just run like uvx rough check, it will install and run ruff.\n\n11:54 Or if it's already installed, obviously just execute it.\n\n11:56 So like for me, when I'm just like trying to execute random Python tools, a lot of the time I'm just going through uv and it abstracts away this idea of like, have I installed the thing?\n\n12:06 What version did I install?\n\n12:07 Like, where is it?\n\n12:07 All of that.\n\n12:08 It's super nice.\n\n12:09 And the hidden gem part of it, I think, as you talked about an executable, certainly with Rust, that is 100% true.\n\n12:15 I think something that's really interesting is if there's an entry point in the package, or I think it's a scripts declaration in the PyProject.toml, which says this command maps to this function, which might take command line arguments or something, and you uvtool install that package, those become just machine-wide commands that you just have.\n\n12:37 And so I think the reason I think that's so powerful is we've traditionally had a really hard time shipping just machine-wide installed tooling for Python people or anything, as long as they're willing to run the command to install it.\n\n12:50 Because that used to be, well, okay, here's what you're going to, just follow me now.\n\n12:53 What you're going to do, you're going to create a virtual environment, but then you're going to put part of it in the path.\n\n12:57 And then you're going to activate it.\n\n12:58 You're going to pip install that thing.\n\n13:00 And then once you go in there, you'll be able to run this command long as it's active because you don't want to mess up the system Python.\n\n13:05 No, no.\n\n13:06 And it was just like, whoa, all right, well, let's not do that.\n\n13:08 That's a hassle.\n\n13:08 But now if you can just uv tool install, you name it, and it works, well, then all of a sudden, that's a real viable way to ship tooling globally to anyone, even if they don't know anything about Python.\n\n13:19 And we actually see that with a lot of companies that we talk to.\n\n13:22 It's like uv becomes the easiest way for them to actually distribute and run small tools.\n\n13:26 And it's cool because like a lot of things in uv, a lot of this is basically enabled by standards.\n\n13:31 And it's like us just trying to make things that are enabled by standards, like a little more like accessible or like easy to use. Like that idea of defining scripts in your PyProject Toml is just like a standardized concept. And it's just us, we install the thing and we kind of create those little entry points, which are basically Python scripts that run the function.\n\n13:48 Similarly, like a lot of people, I mean, me included like the, these like standalone Python scripts. I don't know if you use those at all, where you have the metadata in the header. So you can have a single file script that says like, I depend on these things. And if you uv run that script, we'll install the packages into like this isolated environment and run the script in that environment. And that too is like, that's not even something that we invented. That's like a standard that, that was put forward. I think it's PEP 723. And again, it's take those standards and those like good ideas and just try to find ways to make them like ergonomic and accessible to people.\n\n14:21 So I don't know. It's something I reflected on a lot, which is like, I don't think those aren't even necessarily great examples of this, but like, it's not actually clear to me that we could really build uv like a few years ago because so much stuff got standardized. Like things that people, things that most users probably don't really think much about, like build backends and like build isolation. And there's just a lot of things that were basically came up organically in packaging and then got standardized. And now that they're standardized, we could actually build a tool that like does all the stuff. And it's not just, it's not like pip is the only tool that can be an installer. Like anyone could build an installer because so much of this has been standardized.\n\n14:59 Yeah, Franklin out of the audience says, uv tool install plus brew install equals heaven.\n\n15:03 Yes, indeed.\n\n15:04 Oh, nice.\n\n15:05 It's definitely good stuff.\n\n15:07 This portion of Talk Python To Me is brought to you by Six Feet Up.\n\n15:10 Let me ask you a question.\n\n15:12 What's stopping you?\n\n15:13 Maybe it's an application that won't scale or an AI initiative that just isn't delivering.\n\n15:18 That's where Six Feet Up comes in.\n\n15:20 With deep expertise in Python and AI, they solve hard software problems, modernize platforms, and get teams to market faster.\n\n15:29 These folks have been doing Python since version one.\n\n15:32 They know the frameworks and ecosystems like the back of their hands.\n\n15:35 Six Feet Up's impact speaks for itself.\n\n15:38 Automated healthcare pipelines for hospitals, helping NASA explore Pluto, building severe weather prediction tools, and applying AI to connect farmers with vital crop data.\n\n15:48 When the stakes are high and the problems are hard, Six Feet Up is the partner that delivers.\n\n15:53 See what's possible with Six Feet Up.\n\n15:55 Visit talkpython.fm/sixfeetup.\n\n15:58 the link is on the episode page and in your podcast player show notes thanks to six feet up for sponsoring the show i think people got a sense for uv i do want to actually let's talk about one one thing i was just talking to some folks this morning and they're like hey uv python upgrade awesome new feature oh yeah and i said i have no idea what you're talking about they said it's a new feature of uv i'm like okay after this media i'm gonna go check it out but then i didn't so you\n\n16:21 have to tell me about it what is this is brand new stuff right i mean it kind of does what it sounds like, which is it lets you upgrade Python. It sounds really straightforward, but here's the\n\n16:29 thing. I have, if I go look, if I go run uv tool list, I've got, I don't know, more than a page worth of things. And some of them are super minor, but I've got things like just path, which is a cool thing that shows you stuff that you put in your path that might still be lingering in your path settings, however they come about in the environment, but those folders don't exist anymore.\n\n16:49 So, hey, these are errors. Maybe you should like clean up your path settings a little bit. They're if that gets, if I don't run that very often, like, but it's around, but I have PLS. Are you familiar with PLS? The, instead of LS, the pretty LS? No, I probably, sounds like I should be.\n\n17:07 Oh my God. It's so beautiful. So when you do LS, it will use like the nerd font. So you have to have a nerd font at nerdfonts.com. I think it is nerd font for your terminal. But then like, if there's a Python file, I have a Python logo next to it. And if there's a GitHub, a Git ignore, it'll have like a GitHub logo.\n\n17:25 And it does things like looks at the Git ignore and determines which hidden files to show actually and which hidden files to actually hide or other stuff.\n\n17:32 So like your Git ignore will appear even though it's a regular LS and.vnv will appear and it has like a, anyway, nice.\n\n17:39 If that thing goes wrong, LS stops working on my system.\n\n17:41 And I got to go like a stone man going around typing slash bin slash LS until I can fix the virtual environment.\n\n17:47 So if I like remove the Python that uv installed when I said tool install that thing and I want a newer one.\n\n17:55 And then I try to run it.\n\n17:56 It's like, well, the Python is gone.\n\n17:57 Ah, right.\n\n17:58 Is this uv Python upgrade related to that or is it unrelated to this?\n\n18:02 I was just trying to look at the documentation because I'm trying to remind myself.\n\n18:07 I'm trying to remind myself what's in preview and what's not.\n\n18:09 Yeah, sure.\n\n18:10 We have like a preview mode, which lets you like opt into newer features.\n\n18:16 And one of the things that we wanted to solve with uv Python upgrade and with Python installs in general is basically this, which is when you create like an executable script, you have to put the path to the Python interpreter in the header, like literally the path to it goes in the file.\n\n18:29 So if that path contains like the patch version of Python, like 3.13.0, and then you upgrade your machine to like 3.13.1, suddenly those scripts can break because they point to interpreters that no longer exist.\n\n18:42 So we implemented, again, I don't remember off the top of my head if it's in preview or not, but we implemented a solution to this, which is we basically do some like kind of fancy sim linking stuff so like we have a sim link that's like 3.13 that like points to 3.13.1 and like we read the sim link to those files so if you upgrade\n\n19:01 from 3.13.0 to 3.13.1 we upgrade the sim link and the files i see everything else is transparent because there's like two sim links so you got that level of abstraction to swap it out with right yeah\n\n19:12 i think we took this from homebrew i think homebrew actually does it this way which is they create It's kind of like a sim link for the minor version, like 3.13.\n\n19:19 And then that points to the specific patch version.\n\n19:21 And so when we upgrade the patch version, we also update the sim link.\n\n19:24 And then everything else kind of just works.\n\n19:26 But I can't remember if this is only if you pass preview.\n\n19:30 You all are shipping fast.\n\n19:31 By the time most people hear this, probably it'll be.\n\n19:34 By the time people are here, it won't be in preview, yeah.\n\n19:36 Exactly, yeah.\n\n19:38 I use uv tool install all the time.\n\n19:39 I really love it.\n\n19:41 A lot of neat tools there.\n\n19:42 I think it's the stealth secret way of like, you now have ways of installing CLI apps that are just published at PyPI and a single line to go.\n\n19:51 And that doesn't quite give us full GUIs and things that go into the docs with icons and stuff.\n\n19:56 But that's okay.\n\n19:56 It's definitely a positive step in the right direction.\n\n19:59 We're also trying to make that like Python upgrade experience a lot better.\n\n20:02 So I'm glad that you were told about it and that we had a second to shout about it.\n\n20:06 Like, how am I missing all this hype?\n\n20:07 What have I missed?\n\n20:08 Exactly.\n\n20:09 It's super good.\n\n20:10 It's super good.\n\n20:10 Okay.\n\n20:11 So let's talk about the next step in Python packaging.\n\n20:15 What is this pyx?\n\n20:16 And so I think the first thing I would like you to go on record for people, because I still to this day have debates with people, whether it's...\n\n20:23 How to pronounce it?\n\n20:24 Yes.\n\n20:25 People are like, yeah, I got it from PyPy.\n\n20:27 I'm like, yeah.\n\n20:29 And I'll say PyPy.\n\n20:29 And they're like, you're saying it wrong, Michael.\n\n20:31 I'm like, maybe, but everyone who works on it says it the same way.\n\n20:34 So I think I might be saying it the right way.\n\n20:36 Yeah.\n\n20:36 Let's get the pronunciation good.\n\n20:38 It's kind of funny because like we basically have this problem with like all of our tools.\n\n20:41 And it's like very common advice that like when naming things, they shouldn't be like ambiguously pronounced.\n\n20:46 And we've kind of just ignored it.\n\n20:49 So like, like ty is the same.\n\n20:51 People call it like some people call it Ty, right?\n\n20:54 I don't know what you call it.\n\n20:55 I call it ty.\n\n20:55 I call it ty as well.\n\n20:56 I mean, because you called it ty.\n\n20:58 Right.\n\n20:58 In general for us, it's always the initialization.\n\n21:01 So like uv.\n\n21:02 I love R-U-F-F.\n\n21:03 No, just kidding.\n\n21:04 Yeah.\n\n21:04 Okay.\n\n21:05 Ruff is the one exception.\n\n21:06 That's because I created Ruff before we started the company and before we had any of these patterns. Like I didn't really know what it was going to be. Of course. And we talked about that\n\n21:13 on the show. We talked about that on the show. First time I had you on was about rough before\n\n21:17 you started Astral, I believe. Yeah. So it's uv, ty, and then here it's pyx.\n\n21:22 When I have some kind of AI read it back to me, because a lot of times I'll have a lot of stuff to read and I'm like, oh, let me throw it into some kind of like text to speech thing so I can listen while I'm driving and then I'll be able to talk. And it's like, oh yeah, of is amazing. I'm\n\n21:40 And this is our kind of our first hosted infrastructure product. So it's a big, I guess I would say expansion for us in terms of problems we're trying to solve. Historically, everything we've built so far has been focused on command line tooling, like rough UVTY. These are tools that you install, they run in your terminal. They're kind of, they just run on the client. And this for us is the first thing that has a server. It is a live thing that we run as a service for companies. And it's sort of the counterpart to uv in some ways. So like uv is the client in that sense, pyx is the server. pyx is our package registry, also does a lot of other things, but ultimately it's kind of like a backend that accompanies uv and lets us solve a bunch of problems that otherwise we were kind of limited from solving in the past. I think a lot of the motivation for actually building this and the specific features that we're working on, et cetera, they basically come from like the uv issue tracker. It's like talking to users, hearing about their problems and being like, well, we actually can't really solve that for you because like that's the responsibility of the server and we're just the client. And QIX is in a lot of ways our response to that being like, well, but if we had a server, then we actually could solve that problem. Maybe we could solve like all these other problems. And so for me, it was kind of a natural evolution of what we were already doing with uv was to say, well, if we have all these users who have all these problems that we think we can solve or hope we can solve by building our own server, then we should do that. And because it's a server, because we have to run the server and we have to serve packages, we can charge money for it. And because it's a product that competes in a space of things that people already pay money for, we can charge money for it. And that will be the first thing that we basically charge money for and try to build our business around,\n\n23:22 which is this package register. Definitely wanting to talk about the business model.\n\n23:25 I think that's a really important thing. Yeah, of course.\n\n23:27 But before we get to it, let's think of some of the problems that might be solvable on the server, but not solvable.\n\n23:34 Because uv has certainly made a dramatic splash in how many people are using it just out of nowhere, which is really impressive.\n\n23:41 That, count me among them, that really is really an awesome tool.\n\n23:45 But maybe, let me throw out some ideas and you can tell me if I'm on or off the track.\n\n23:50 So one of the things I think that was really challenging is to resolve the right versions.\n\n23:55 Like I have this version of requests and this version of beautiful soup and this version, whatever.\n\n24:02 And maybe one of them has the same dependency on another with constraints.\n\n24:06 You got to like work that out, right?\n\n24:07 So maybe something you could do with a server is just go, here are all the packages and versions resolve that.\n\n24:12 And then once you figure it out once on the server, you could cache like, well, this combination always resolves to these go like instantly index database query, give me the answer.\n\n24:21 So you basically share the resolution across all of humanity instead of every time an install happens, it starts over.\n\n24:29 Are these the types of...\n\n24:30 That is an example of a kind of thing we could do.\n\n24:32 Okay.\n\n24:33 I think in general, there's maybe two or more ways to think about what we're trying to do here.\n\n24:38 So pyx is not really a PI competitor.\n\n24:42 We're not trying to host public packages for people to consume.\n\n24:46 This is a product that's aimed at companies, enterprises, teams, people who have these problems.\n\n24:52 Maybe they already pay for some kind of alternate registry solution that's not API.\n\n24:57 And so one class of problems is basically, what are things that teams need or have that they can't get from API around packaging and package hosting?\n\n25:07 And some subset there is basically people who come to the uv issue tracker and they use some other registry and they have a bunch of problems with it.\n\n25:13 And we actually can't, we can't solve those because we're like, we can't fix your registry.\n\n25:17 And so like the table stakes thing is like a great private registry, which means something that's really like Python first.\n\n25:25 These alternative solutions that support Python also support like a bunch of different ecosystems and Python is typically like a small thing.\n\n25:31 And so often those registries are...\n\n25:33 We're going to host like, here's your binary artifact.\n\n25:35 And then whatever your thing does to get the artifact, it's just going to get it.\n\n25:39 And like, and that's kind of more or less what might be happening there, right?\n\n25:42 not like deep understanding. For us, it's like, okay, we want a registry that like,\n\n25:46 it should support all the latest standards. It should be really optimized for Python. And we should just provide like a great Python experience because it's Python, like Python is a first class thing. And so that's part of it is like, how do we build just a great private registry that is super modern, is really fast. A lot of the private registries are very slow for a variety of reasons, some of them related to standards. But our goal is like, we want to provide a great experience for that use case. So if you're a company that needs to host private Python packages, especially if you're using uv, we should just be like, well, we want to be the obvious choice for those companies.\n\n26:19 All right. Well, let's say, hold on before we leave that topic. Why would anybody do that?\n\n26:23 Why would anyone do what? Sorry. Want private package hosting?\n\n26:25 A private package. What is this about?\n\n26:27 It's very common. So especially if you get beyond a company of a certain size, maybe you have code that you need to share across the organization, like packages that subsets of your project that you want to be able to use, reuse elsewhere.\n\n26:39 Sometimes at small scale, you'll solve that with like Git dependencies or something.\n\n26:42 Like maybe you just depend on the Git repo.\n\n26:44 But typically as you scale, people will tend to start creating actual packages that they publish.\n\n26:48 In some cases, you also want to be able to do like fine-grained access control around that.\n\n26:53 Like maybe you want to be able to publish code that like only certain people can access within the org or maybe like select customers can access.\n\n27:00 Like these are all use cases we want to be able to serve, which you can't do on PyPI, which is we want to host packages that are not totally public.\n\n27:08 and we want to be able to control who can use them because they contain IP or, well, yeah, I mean, I guess that would be the main reason they control us to contain random IP.\n\n27:16 We want to be able to ship versions of our library to all the other teams at our organization, right?\n\n27:22 Like we wrote the definitive Python library to talk to some service we have running internally.\n\n27:28 We don't want people, everyone recreating some Python library, working with different versions.\n\n27:33 If we roll out a new version of that service, we want to just push to our little internal repository.\n\n27:38 a new version that works with that new and all the projects get it, right?\n\n27:41 Like that kind of thing seems real valuable.\n\n27:43 It's like a library reuse story.\n\n27:46 For those same users, like enterprises that care about this kind of thing, even if they're not publishing private packages, there are other things that we can do here.\n\n27:53 Like we have this, I was going to say pretty cool.\n\n27:55 I think it's pretty cool.\n\n27:56 We have this pretty cool system where you can define what we call like views, which are composed filtered subsets of other registries.\n\n28:04 So you could create like an index URL that represents API, but like frozen at a given point in time. And that's like enforced on the server or even like API, but like only things that are at least a week old. That's like a common thing that people use to guard against malware because malware tends to get removed within a short amount of time. And you can also compose them. So you could create like a single index URL that's like, if we uploaded a package of a certain name, then like get it from our upload. Otherwise, like fall back to API. You could also like disallow specific versions, specific packages.\n\n28:35 You can disallow based on like CVE counts.\n\n28:38 So you can do all this.\n\n28:39 Like we have a DSL for it.\n\n28:40 You basically like write Python code to like define the configuration.\n\n28:44 And then we give you like a single index URL.\n\n28:46 So that's both like simplifying a lot of what's happening.\n\n28:49 Like often you have some subset of this logic in your uv configuration.\n\n28:52 And now it's like, as a team, you can actually centralize like and enforce like compliance rules and give you like a single URL that defines this logic for you and is enforced on the server.\n\n29:02 So again, it's about things that like, these are things that companies care about, right?\n\n29:06 Like if you're an open source project, you probably don't care about this as much.\n\n29:09 But for companies who care a lot about visibility and control and security and this kind of shared centralized logic, it's a really helpful, we found it's a very helpful thing.\n\n29:21 So that's part of it is like companies that need to manage private packages or need to manage like their packaging setup.\n\n29:27 And that I just consider kind of like the table stakes of like what we can provide.\n\n29:31 It's like a great, fast, modern Python registry that kind of doesn't exist, in my opinion, doesn't really exist in the market.\n\n29:38 And it should be really like a natural thing if you're already using uv.\n\n29:42 Then there are some other things we're doing that are kind of maybe a little bit more crazy, but hopefully in a good way.\n\n29:47 The thing that we're trying to do is like, we want to build, it's kind of a similar philosophy that we've taken to the rest of our tooling, which is like pyx, you don't like have to use uv to use pyx.\n\n29:56 Like this is like a registry that implements like the simple API, like the upload API, which is not really standardized.\n\n30:02 But anyway, we implement like all the APIs that other registries implement.\n\n30:06 So you can use like pip and Twine or like whatever with pyx and that's fine.\n\n30:11 You also don't have to use pyx to use uv.\n\n30:13 Obviously you can use uv with like whatever registry you want.\n\n30:16 But our goal is like, if you use uv and pyx together, there are certain things we should be able to do to like deliver a really good experience.\n\n30:22 And some of those are obvious, like authentication is a little bit more seamless.\n\n30:25 Like you can, we kind of like know that you need the credentials.\n\n30:29 We know to prompt you to log in, that kind of thing.\n\n30:31 But there's also a lot of stuff we can do around performance.\n\n30:33 Like if we are the, if we under, if the client and the server kind of know each other, there are different like fast paths we can take to try and make things a lot faster.\n\n30:40 So there's a lot we want to explore there around kind of like, how can we vertically integrate these things while also remaining compatible with the rest of the ecosystem?\n\n30:48 And then there's also this bullet on the bottom, right?\n\n30:50 This GPU aware thing, which is another piece that we should talk about.\n\n30:54 Do AI people, maybe AI people use this? I don't know. That's probably going to be a fad, but you guys might want to add it anyway. Yeah.\n\n31:01 This AI stuff, it's going to be a fad, I'm sure.\n\n31:03 I guess sort of as an aside, it's kind of interesting for us because we don't have or build anything that's AI powered, but we power a lot of AI infrastructure companies. So I don't know, if you think of a big AI company without naming names, they're probably using our stuff. And so it's kind of an interesting position to be in, which is we build a lot of infrastructure that's used by AI companies and also by like end users and even by agents, right? Like if you're running an agent, it's like invoking uv and stuff, but nothing that we build is actually like AI powered in that way, which is kind of a funny position to be in. But basically since the start, we've spent a lot of time in uv trying, I will say specifically trying to make the PyTorch experience good because the PyTorch experience is kind of like, it's not the only thing in GPUs. There's a lot of stuff going on, but PyTorch is just super popular. And so we've always gotten tons of issues around how do I make this PyTorch setup work? Or how do I make, I ran into this error, like what's going on? Or I have this other package that like builds on top of PyTorch and I'm like having trouble getting into work together. So we spend a lot of time trying to make that experience good in uv because it's just super popular. And one of the things that we've come back to many times is like there are problems that, again, there are problems we could solve if we had a server that we kind of can't solve on the client. Like an example would be, there are all these pieces of software that like built, like I said, build against PyTorch and build against certain versions of CUDA, which is like NVIDIA's GPU accelerator library. And those things tend to be hard to build.\n\n32:30 And it's also very hard to make sure that you're getting like compatible versions of them, because there are basically some gaps in the Python standards that make that hard that we're working on. But it's very hard to install like a compatible version of PyTorch and a compatible version of Flash Attention. And it's not really anyone's fault. There are basically gaps in the standards that make that hard. But if we have our own client in our own server, especially actually, even if we just have our own server, there's a bunch of stuff we can do because we can kind of pre-build those for people. We can curate the metadata in certain ways in a way that's all standards compliant, but we could pre-build all those things. And the goal is give people an index that they can point to that will have rebuilt versions of a lot of this stuff that's consistent. The metadata is compatible. They don't have to worry about how do I build it from source?\n\n33:13 They don't have to worry about how do I make sure that all the versions that I'm installing are like mutually compatible. Like that's like another one of the problems that we're trying to solve.\n\n33:20 And again, it's the kind of thing that like we want, we've wanted to be able to offer users for\n\n33:24 a long time, but like there's only so much we can do on the client. This portion of Talk Python To Me is brought to you by our latest course, Just Enough Python for Data Scientists. If you live in notebooks, but need your work to hold up in the real world, check out Just Enough Python for Data scientists. It's a focused code first course that tightens the Python you actually use and adds the habits that make results repeatable. We refactor messy cells into functions and packages, use Git on easy mode, lock environments with uv and even ship with Docker. Keep your notebook speed, add engineering reliability. Find it at Talk Python Training. Just click courses in the nav bar at talkpython.fm. Let's dive into this just a little bit. So is the problem, I am a consumer of LLMs and AI, and I also have written programs that themselves use LLMs, but I have not built an LLM, so I don't really have much experience with this. So is the problem that it's kind of a source distribution that you've got to compile for PyTorch and maybe some other things, or they actually come as binary wheels, but they're incompatible with each other, even though they're pre-compiled?\n\n34:31 What is it that you're kind of doing to make it work here?\n\n34:34 It depends a little bit.\n\n34:34 So like for PyTorch, just as PyTorch itself, like the Python package, like import Torch, we just think about that.\n\n34:41 They do build, they do pre-build wheels, but a lot of the complexity comes from the fact that there's this access that isn't really captured by Python standards, which is the GPU accelerator.\n\n34:53 So on your machine, if you want to run PyTorch, like typically you have a GPU like plugged into your machine.\n\n34:59 And that could be like an NVIDIA GPU, it could be an AMD GPU. And each of those use very different software stacks. And those software stacks are also versioned. So like when they build PyTorch, and they publish to their registry, it's not just like one build. And it's not even just the standard build matrix of like Python version and architecture and operating system. There's like another axis, which is accelerator slash accelerator version. And there's actually no way to capture that really in Python met standards right now. So what they end up doing is they create separate indexes for each of those accelerators. So if you've ever installed PyTorch, there's sort of like a UI on the PyTorch page where you click through like, this is my GPU, this is my operating system, this is my Python version, and it gives you an index URL. And they have different index\n\n35:45 URLs for the different accelerators. Oh, wow. So it shows that multiple projects on PyPI.\n\n35:49 No. So on PyPI, they still basically, those wheels aren't even published on PyPI.\n\n35:56 in general. So they do publish on the API, but they can only publish one, basically one wheel.\n\n36:01 So they publish for one of those GPU versions and all the rest go on the PyTorch index. So like the first, like one source of complexity is as a PyTorch user, how do I like get the right version of PyTorch that's prebuilt? And then there's like a next level of complexity, which is then I have libraries that build against PyTorch and like Flash Attention. So when you build Flash Attention, that's a source distribution and it needs to build against a specific version of PyTorch, Not in a specific version of the GPU.\n\n36:27 So it's yet another dimension.\n\n36:29 It's not just, because it's also specific to like CUDA 12.8 or whatever.\n\n36:34 But in addition, it's also specific to the PyTorch version.\n\n36:37 So they have to publish wheels for each combination of PyTorch version and accelerator.\n\n36:41 And none of those go on PyPI.\n\n36:44 So they publish those to a GitHub releases page, but PyPI is just the source distribution.\n\n36:48 And like the root cause of that problem, of those problems are really some gaps in the standards that are hard to, that are hard to solve.\n\n36:55 it. And we're also working on some standards, some sort of like proposed evolutions to solve this in standards. But ultimately it means that like, it's kind of hard to install the right version of Torch. And then if you need to install these other things, like, like, again, these won't mean anything to you unless you've really used them. But like VLLM is, it's the most popular piece of software that people use for actually serving models. So if you wanted to do inference, like serve an LLM, VLLM would be a very popular choice. And like that has to build against a specific version of Torch and it's built for specific accelerators. And so basically you have these many levels of complexity of how do I get this thing to build? How do I make sure I get the\n\n37:31 right version? And we want to kind of abstract that away from people. I see. It gets combinatorially bad the more you work with pieces. The flash attention build matrix, if you think about it,\n\n37:42 it has, so for a single flash attention version, you have to build across Python version, operating system, architecture, CUDA version, which is like NVIDIA GPU version, and then PyTorch version. And so it's a very big build matrix and it's very hard to get right. Let's talk about\n\n37:59 security a little bit. You talked about some of the things. I really like the idea of just put a delay in there, like a week, a month, whatever. That's pretty new, pretty cutting edge. But by the time something's gone through there, if it's something we're using, it's going to be found out.\n\n38:13 Someone's going to report it, pull it off of PyPI and basically block it. We also recently hired\n\n38:19 William Woodruff joined the team who was an author on the like attestations pep. He implemented a lot of the trusted publishing work in PyPI. So he's done like a lot of the sort of like cutting edge security work in the PyPI ecosystem. And we basically have some ideas for kind of like more outlandish things we can do around security or sorry, outlandish is the wrong word. Maybe like ambitious things we can do around security that we want to explore. Like, I don't know if we'll actually do any of these things, but there's basically things that we can learn from other ecosystems around how to do like more secure workflows for packaging. So like we want that to be a big part of what we're doing. But I think like something that's important for me about this product is like when you think about a registry, like a private registry, a lot of the time it's motivated by like security and compliance. And that is an important piece of what we want to do.\n\n39:09 Like we do want to build a registry that's like very strong in security and compliance, But we also want to solve problems that I think people never really associated with a private registry.\n\n39:20 We want to solve some problems, like the GPU stuff, for example.\n\n39:23 Those are just user experience problems.\n\n39:25 We're trying to use the registry as a way to solve user experience and developer experience problems, even for companies where otherwise they would never have considered using a private registry.\n\n39:34 So our goal is that over time, we build more things into pyx that help with the overall Python experience.\n\n39:40 How do we make your Python team more productive?\n\n39:42 It's not just about how do we help them be more secure.\n\n39:45 That is part of it.\n\n39:47 But like, ultimately, we love building things that make people more productive and like remove problems that they have to like even think about.\n\n39:54 And so ultimately we want to use this as a position to solve more problems.\n\n39:57 Like this PyTorch example you talked about.\n\n40:00 Like the PyTorch example.\n\n40:01 Is there going to be an API for pyx?\n\n40:04 Like if I am a customer of yours and I want to control some things, can I set up automation or are there ways to put code running in pyx that will check on things additionally to webhooks or any of that kind of stuff? Like what is the, I want to participate in pyx sort of thing. I mean, we have a bunch of APIs. So we implement some of the standard,\n\n40:25 what I would call like standardized APIs. So like, obviously like the way that we query package metadata and download packages is based on the simple API. And then we also implement the upload API. So basically uploading and downloading packages follows, that's like public API that follows basically like standards slash what other registries do. Sorry, the upload API is a little bit strange because it tends to be people just do what API does. Outside of that, we do have APIs that we're kind of like considering how we want to expose them. I talked before about this idea of custom views, like being able to sort of declaratively write code to create an index URL, like that should all be scriptable and that should all be public API over time.\n\n41:06 I'll give you a sense of what I'm thinking.\n\n41:07 Like if I'm in charge of developer security, developer package security, supply chain security, I guess I would say at a big organization or any level of organization where it really matters or I care enough to buy your service, maybe I would do something like I would subscribe or I would have an automated system subscribe to a bunch of RSS feeds for security places, right?\n\n41:29 Like leaving computer and others and look at all the articles.\n\n41:32 and if I see PyPI show up, then maybe like, well, let's feed that to an LLM and ask like, okay, well, what packages are actually affected?\n\n41:39 And then if I can determine something we're using, or even if it's not, we're using it, just something relevant that we care about.\n\n41:45 Maybe I want to call an API back to you guys and say, block this one permanently or block it back for like three months ago.\n\n41:52 Like it's us right now.\n\n41:53 We're going to put it on a timeout and make it go back.\n\n41:55 You know what I mean?\n\n41:56 Something like that.\n\n41:57 We should definitely support all of that.\n\n41:59 I have to think about like, whether that's in a position where we'd like make it available to customers yet.\n\n42:04 But in theory, they could absolutely script against that today.\n\n42:07 That is also something you guys could write once and like have it, all right, a little preemptive sort of thing.\n\n42:12 Yes.\n\n42:12 PyPI, what is the role?\n\n42:14 Like I want to publish a package that is a public thing.\n\n42:17 Do I upload it to you guys?\n\n42:19 Do I just publish it to PyPI?\n\n42:21 But are you guys a proxy?\n\n42:22 You mentioned that you're not a replacement for PyPI, but what does that really mean?\n\n42:26 We're not trying to be like the public source of record for like four packages.\n\n42:30 So like for people who are publishing packages, like PyPI is still the place that they should go to like publish those.\n\n42:35 We do mirror in PI.\n\n42:37 So like you can use PIX to install things that ultimately come from PI.\n\n42:42 But you don't necessarily have to proxy through.\n\n42:43 You could just instantly go and pull like a faster local version.\n\n42:47 We kind of like pull those over onto our own infrastructure, which is pretty common,\n\n42:52 like as in other mirrors do this kind of thing too.\n\n42:55 But the nice thing is that like PyPI has like very good uptime.\n\n43:00 But the nice thing is if you depend on us, it also means that you're not introducing like more sources of failure, basically, because we mirror the stuff ourselves.\n\n43:08 So like, obviously we could go down in some sense, but like, you know, you're not relying on both us and PyPI to serve packages, which can be helpful.\n\n43:17 But, you know, the basic idea for us is like, I were obviously like a big fans of API and we, I won't speak for them, but like we spend time with the API team.\n\n43:26 I talked to them about this before we announced it.\n\n43:30 And Ivy PI is a critical piece of a healthy Python ecosystem.\n\n43:34 And we're not trying to displace PI PI as the public source of record for traffic.\n\n43:40 Our goal is we're trying to build something effectively on top, sort of on top of PI PI, a slightly different layer that's more focused on the needs that enterprises have and companies have, which is a little different than what PI is trying to do.\n\n43:53 In my opinion, they could obviously come out and say something.\n\n43:55 I don't, again, I don't want to speak for them, but at least from my perspective, it's a little different than PyPI's mandate. And so for us, I think I said online something like pyx's success depends on the success of PI and like we basically operate that way. So we'll like continue to support. I think it's a hard thing to, to message out succinctly, which is why it's nice to be able to talk about it with you. But like, we're trying to build something that we think addresses like a different gap and it's less focused on how do we compete with like PyPI. And it's more focused on how do we compete with like Artifactory or like other products that are private registries that people pay for? And how can we provide something that's a little bit different than what those people are providing? Is there going to be an on-premise option?\n\n44:35 Oh, such a good question. What are you, a customer? I'm like, we're not doing on-prem right now, but we do have a lot of, we do have a decent amount of people who want it. And I think it will be ultimately be important. But like in the early days of the product, obviously we're very focused on trying to iterate with customers as quickly as we can. And so the fastest feedback there tends to be from, basically we want to be able to deploy this quickly to people and get feedback on it quickly. So on-prem is a much bigger investment and also something that we would...\n\n45:05 Is on-prem the entire implementation? Is it just a proxy server? If you've seen this request before, you've already downloaded it. It's like a little VM that's hanging out in our data center. Just pass it out. That's pretty low hanging fruit. Whereas we want to give you the entire thing in that's a different deal.\n\n45:20 Yeah, we've also experimented with some kind of interesting hybrid models where like all the packages, I shouldn't even say this because then people are going to like come ask for it\n\n45:29 and like I don't really want to support it.\n\n45:30 Don't speak it into existence.\n\n45:32 No, it's kind of a cool idea though.\n\n45:33 It's basically like all the packages would live in an S3 bucket that the customer controls and that we don't even have access to.\n\n45:39 And we could actually support that.\n\n45:41 So we would be like the server that understands metadata about what packages exist and where they are, but we wouldn't actually have access to the contents.\n\n45:48 And there are basically cool ways that we could make that work, which is kind of an interesting hybrid model.\n\n45:53 But anyway, yeah, right now we're pretty focused on not doing on-prem, but I'm sure we will eventually.\n\n45:58 Maybe someday, yeah.\n\n45:59 Yeah.\n\n45:59 Somebody comes with a big enough check and they're like, you know what?\n\n46:02 On-prem is a good idea.\n\n46:03 Let's do that.\n\n46:04 For the right price, on-prem is definitely available.\n\n46:08 I think this is the perfect transition.\n\n46:09 And I know that this has been something that has been discussed on and off basically since uv.\n\n46:17 And for some reason, I don't think it was at all discussed with Ruff.\n\n46:19 I don't know.\n\n46:20 You make that make sense.\n\n46:21 Maybe you can.\n\n46:22 I can't.\n\n46:22 Well, I'll tell you if you're right, depending on what the question is.\n\n46:25 The question is, a lot of people are like, oh my God, uv is incredible.\n\n46:29 We have to switch everything to uv.\n\n46:31 And then there's always someone that says, but it's owned by a company.\n\n46:34 It's not 100% open source.\n\n46:37 What if that changes?\n\n46:38 What if its usage model changes?\n\n46:40 Like, what if Charlie and team decide, like, it's a tenth of a cent per package install and then, like, we're out, right?\n\n46:46 That's certainly been a lingering issue.\n\n46:48 I don't think it was with Ruff.\n\n46:49 People weren't like, well, what if it's like a thousandth of a cent per line of code?\n\n46:53 You know what I mean?\n\n46:54 For some reason about uv, I think it's just more foundational.\n\n46:57 Stuff runs because of uv.\n\n46:59 Stuff is nicer because of Ruff, maybe.\n\n47:00 I don't know.\n\n47:02 There's even a comment by Chris in the audience.\n\n47:04 What if you guys change your mind?\n\n47:06 And I know you've been very open about saying, that's not our intention.\n\n47:08 We intend to build products around it.\n\n47:10 When I saw this announcement, I'm like, wonderful.\n\n47:13 This is the first glimpse into what you guys are building that supports uv, supports Ruff, and all this other stuff you're doing in a way that is not like, well, we took that feature out of uv because it only encourages you to make uv even better.\n\n47:27 So maybe just talk about that for people who are listening around the business model.\n\n47:31 How does this solidify the stuff that you've mentioned and the more abstract?\n\n47:35 I think about this all the time from the start.\n\n47:38 It was something that came up when we talked about Ruff, but I think I've kind of sensed a long, I don't know about a long time, but I've since for a while, there's like kind of two sources of anxiety around this from users. And one form is like, oh, what if we depend on all this stuff?\n\n47:53 And the company goes under, the company disappears. The other form is like, you know, what if we depend on all this stuff? And then they like pull the rug out from under us.\n\n48:00 And the first one is like kind of a little bit easier, I think, to talk about just because we have like a good amount of funding. We're not going to like disappear in the next year or anything like that. We're very well supported. But the second one is, yeah, the second one's obviously more complicated because I'm very transparent. And I've said, I'll say a bunch of things on this podcast that I've said a bunch of other times in other places, but ultimately people, I think we have to basically prove out trust over time. I will say things right here, obviously, I've said, we have no rough uv, our tools should be free forever. And we want to keep them free and open source. And that's like very important. And, but ultimately we have to like earn that trust over time. I think like I can say all these things, but there will still be people who will be skeptical.\n\n48:49 Ultimately our model, it's been the same from the start really, which is, or well, I don't know from the start is wrong. Cause I sort of had no idea what I was doing when I started the company, but like the intention has been, we want to build this like open source that what we think of like as our open source tools, which is like rough UVTY, this tool chain, and that should be free, permissively licensed. And we should be incentivized to like keep investing in it and like to see it grow. And what we want to do from there is monetize services that we build that are kind of like natural extensions of, or I think what I said in the post is something along the lines of the natural next thing you need if you're already using our tooling. And for me, the registry is a really good example of that. Because basically, if you're already using uv, and you're a company that has or needs a registry, we should be the obvious choice for that. And people pay for, not if you're just using PyPI, this might not resonate with you, but a lot of people pay a lot of money for products in that space, for registries. And we should be able to build a better registry and gain a lot of distribution and visibility by building the open source. The open source should basically be in addition to something that we continue to invest in and solves a lot of problems for users and gives value to most people not paying us any money, right? Even in the limit, I think most users of our open source tool will not pay us any money, but like it should be a way for us to get distribution. Like companies should be like, oh, we use this open source thing. We need a solution for this. Okay. That's from the same people. It probably plays really well with the tools. It can probably solve more problems for us. And so that's been very consistent, which is like the tooling should be free, open source, permissively licensed. And we have absolutely no plans to change that. It should always be that way. And what we want to do instead is we view pyx as a different class of things. That's our hosted services as opposed to our open source tools. And we'll keep pushing in that direction. And I shouldn't really say this, but I've been thinking a lot about how people... I've been a software engineer my whole career.\n\n50:46 And we as software engineers have sort of been trained to really distrust corporate open source.\n\n50:52 And it's not without reason. There are a lot of companies that have done things that feel users feel burned by. And I'm very empathetic to that. And so I, as I said, I will be as open and transparent and honest as possible, which is like, we don't want to do that with the tooling.\n\n51:09 Like the tooling is, it's like too important. It's too valuable. It's too like to the community to do that. And so our goal is to like, keep building that stuff. We're investing a lot in continuing to make it great. And then we want to, our goal here with pyx is to build a business on top of it and we'll keep pushing in that direction. So I think there will be hard, I'm sure there will be hard decisions for us around like what goes in the open source and what doesn't. We want as much\n\n51:34 as possible. Single sign-on can go in the closed source. We want as much as possible to like set up\n\n51:40 an incentive structure whereby we actually don't have to like worry about that. Like that's something that I've been trying to do, which is to say like, okay, if there's a problem that we can solve and we can just solve it in the open source, then like we should solve it in the open source. If there's a problem that we can that we can't solve in the open source but we could solve with the server then we should do it there and like that for us at least now that's kind of like our guiding\n\n52:00 how we got our thinking to me it seems super clear that this is not significantly in the way of uv advancing if anything it just puts more energy to uv because as people use pyx well they're effectively customers of uv as well i think the critical thing right that like i can just keep\n\n52:18 saying is we don't we don't want to realize our tools we do not want to charge people money to use our tools i think we find ourselves in a position to do that like as a company we're in serious trouble anyway so i like that is that's something that i'll never do and we're just going to continue to focus on the strategy that we've had from the start which is like we build the free open source tooling we're incentivized to grow it as much as we can that's the thing that we love doing and now we're going to go and try to solve more problems and hopefully problems people will pay for you\n\n52:46 look at the GitHub repository, you guys have almost 67,000 GitHub stars. First of all, congratulations. That's insane. Oh, thanks. When you started this, doesn't that count as success?\n\n52:56 You're like, we have almost as many stars as Django. Like that's pretty wild. I don't know.\n\n53:01 I mean, I think when I started working on this stuff, I would have thought a hundred stars was crazy. I hear you. I totally hear you. I was not like a person who like did a lot of open source.\n\n53:10 And like, so like I said, I, or I not on this show, but I think I've said this before. It's like, I was just average consumer of open source.\n\n53:17 Like I was using open source software all the time, but I wasn't contributing or maintaining or anything.\n\n53:22 And so like for us now, yeah, I don't even like look at the stars anymore.\n\n53:25 I don't know.\n\n53:26 It's like.\n\n53:28 I feel like it's gotta be on star history, right?\n\n53:31 In addition to that, I feel like the reason I brought that up is because worst case scenario, this is not me speaking for me.\n\n53:37 This is me speaking for like the people who are speaking to the people out there who are like, I can't believe what if, like sort of a doom sort of thing.\n\n53:44 It's still out there under a permissive license on GitHub in 2004.\n\n53:48 Because that's pretty likely that there's going to be a version out there.\n\n53:51 But here's your star history.\n\n53:53 Looks pretty good.\n\n53:54 That's cool.\n\n53:54 Yeah.\n\n53:56 It's going strong.\n\n53:56 It's going real strong.\n\n53:57 Yeah.\n\n53:58 Wow, that's a lot.\n\n53:59 It's still going up.\n\n54:01 I know.\n\n54:01 I'll put that link to it in the show notes.\n\n54:03 That's wild.\n\n54:04 Yeah, I know.\n\n54:04 And I mean, we do think a lot too about project governance.\n\n54:08 I remember when, thankfully most people weren't really thinking about this, But when, do you remember when SVB went under Silicon Valley Bank?\n\n54:17 Oh yeah, I absolutely remember.\n\n54:19 That was, yeah, I was very much tracking that.\n\n54:21 Basically all our money was in Silicon Valley Bank.\n\n54:23 Was it?\n\n54:23 Oh no, I didn't even put that together.\n\n54:25 Oh my gosh.\n\n54:26 Okay.\n\n54:26 I mean, which was us and every other startup.\n\n54:29 But at the time we were a pretty small team.\n\n54:32 It was obviously very worrying, but there was also a sense that it would be resolved.\n\n54:36 And, but I remember at the time I got on the phone with the founder of another company that I won't name, but it's a developer tools company.\n\n54:42 And he was like, yeah, I had like a real moment where I was like, wow, if the company goes under, at least the open source project will be totally fine because we've really invested in governance and like it could run like totally without us.\n\n54:55 And I was like, wow, that's amazing because I think like that's what I would like to get to.\n\n55:00 We do think about that.\n\n55:01 It is governance is hard, is very hard.\n\n55:04 And over time, we're trying to build up a bigger contributor base.\n\n55:07 but that's basically the north star for me of like what I would like to get to is like ideally even if the company didn't exist the project could keep going I'm not saying I'm we are absolutely we're not there yet and like I'm fine to admit that but like that's like what I would like to get\n\n55:19 to I guess wrapping this that part of it up I think the concerns about that are overblown people say well I got to learn a new tool like well you just put the letters uv in front of what you're doing before it's probably fine you know what I mean it's like it's not that huge of a investment in terms of like a disruption.\n\n55:34 And I think I, for one, am a wholehearted adopter of uv and the tools and appreciate it every day.\n\n55:41 Thanks. Yeah. No, I appreciate that.\n\n55:42 I mean, I just like, I just love building this stuff, honestly.\n\n55:46 And I just love like solving problems for people.\n\n55:49 Like, it's sort of sad because I find myself with less and less time to just like, like I, a day where I can just hang on the issue tracker and just like close bugs and help people is like the greatest.\n\n56:01 And so I'm trying to find ways to keep doing as much of that as I can.\n\n56:05 But as a team that's grown, obviously my attention gets split in a lot of different ways.\n\n56:08 But basically like a lot of what we're trying to do is just like build, like build a company, right?\n\n56:13 That lets us continue to invest in what is effectively R&D to like build out all this open source tooling.\n\n56:19 And so hopefully, hopefully we can make that work.\n\n56:23 And that's like the push that we're going towards.\n\n56:24 We're pretty much out of time here.\n\n56:25 So let's close it out with people are interested in this.\n\n56:28 What do they do?\n\n56:29 Can they try it out?\n\n56:30 Is it available yet?\n\n56:31 is it for random individual developer type? Yeah, not yet. So like we're starting with\n\n56:36 what we're calling like a closed beta. So we basically launched in private with some customers through like direct outreach, just talking with teams that we'd already been working with. And that's why when we did the public launch, you can see we had a couple of customers already listed on there. And then we put on interest form on, it's linked on the pyx page and in the blog post.\n\n56:53 That's the best thing for people to do is fill out the interest form. We got a lot of responses to the interest form, which is great, but it's also going to take us time to get through them, like many thousands.\n\n57:04 So we started basically going through that list and onboarding people and we'll keep doing that and we'll basically ramp it up over time.\n\n57:11 So we're working towards a GA release and then hopefully everything, the plan then is for everything to be self-serve and for people to try it out themselves.\n\n57:18 But right now we're doing kind of this slow rollout just as we scale up the product and also just like spend more time learning from the early customers.\n\n57:24 You have an idea for what people want, but you've got to actually see.\n\n57:27 Even they might have a thing.\n\n57:28 They might ask.\n\n57:29 We have to actually build it.\n\n57:30 Yeah.\n\n57:32 Well, people also say we want this, but in fact, they actually want something slightly differently, potentially, right?\n\n57:37 I mean, the cool thing is, yeah, we're live in production with companies.\n\n57:41 The amount of traffic's going up and it's, I mean, it's a little scary, but, you know.\n\n57:45 Yeah, I was going to say the bandwidth build is probably not non-trivial.\n\n57:48 And then you start talking to the ML people, their packages are like half a gig, not half a meg, right?\n\n57:53 Yeah, the biggest PyTorch builds are like, like the biggest PyTorch wheels are like, almost three gigs, I think.\n\n57:59 Cool.\n\n57:59 Well, congratulations so far.\n\n58:02 And thanks for coming on and checking in with us and talking about pyx and updates on uv and all that.\n\n58:07 Yeah, thanks for having me back on.\n\n58:08 No, it's always fun.\n\n58:09 And I appreciate the opportunity just to talk more about what we're doing and try to explain what we're building and why.\n\n58:14 And yeah, I'm excited to come back on hopefully at some point in the future.\n\n58:18 Yeah.\n\n58:18 When you're ready to share more, you're always welcome.\n\n58:20 So thanks for being on.\n\n58:21 Appreciate it.\n\n58:21 See you later.\n\n58:21 Thanks a lot.\n\n58:22 Take care.\n\n58:22 Yep.\n\n58:23 Bye.\n\n58:23 Bye.\n\n58:24 This has been another episode of Talk Python To Me.\n\n58:27 Thank you to our sponsors.\n\n58:29 Be sure to check out what they're offering.\n\n58:30 It really helps support the show.\n\n58:32 Thanks again to Six Feet Up, the Python and AI experts you call for the hardest software problems.\n\n58:38 From scaling applications to simplifying data complexity and unlocking AI outcomes, they help you move forward faster.\n\n58:45 See what's possible with Six Feet Up.\n\n58:47 Visit talkpython.fm/sixfeetup.\n\n58:51 Want to level up your Python?\n\n58:52 We have one of the largest catalogs of Python video courses over at Talk Python.\n\n58:56 Our content ranges from true beginners to deeply advanced topics like memory and async.\n\n59:01 And best of all, there's not a subscription in sight.\n\n59:04 Check it out for yourself at training.talkpython.fm.\n\n59:07 Be sure to subscribe to the show, open your favorite podcast app, and search for Python.\n\n59:12 We should be right at the top.\n\n59:13 You can also find the iTunes feed at /itunes, the Google Play feed at /play, and the direct RSS feed at /rss on talkpython.fm.\n\n59:23 We're live streaming most of our recordings these days.\n\n59:25 If you want to be part of the show and have your comments featured on the air, be sure to subscribe to our YouTube channel at talkpython.fm/youtube.\n\n59:34 This is your host, Michael Kennedy.\n\n59:35 Thanks so much for listening.\n\n59:37 I really appreciate it.\n\n59:38 Now get out there and write some Python code.\n\n59:52 *music*",
      "source": "Talkpython.fm",
      "url": "https://talkpython.fm/episodes/show/520/pyx-the-other-side-of-the-uv-coin-announcing-pyx",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Quick CPU Pro 5.2.0",
      "content": "Posted on Sept 23rd, 2025 at 8:41 pm in Applications Windows by Ash\n\nDescription: Quick CPU is a powerful CPU monitoring and performance tuning application designed for both Intel® and AMD® processors. It provides real-time visibility and control over key system parameters such as CPU temperature, power, voltage, frequency, core usage, core parking, performance, voltage, current and power management features.\n\nThe application also includes customizable power plan controls, turbo power limit configuration, core performance ratios, and detailed charts for analyzing workload, thermal distribution, and frequency scaling across all CPU cores. While certain advanced CPU settings (such as Speed Shift and FIVR control) are currently available for Intel CPUs, Quick CPU offers comprehensive functionality for all users looking to optimize performance, power efficiency, and system responsiveness.\n\nKey Features of Quick CPU\n\nExplore powerful tools to fine-tune CPU performance, manage energy consumption, and take control of your system.\n\nCPU Core Parking\n\nControl how Windows parks CPU cores based on system load. Optimize power usage or unlock full core performance depending on your needs.\n\nFrequency Scaling\n\nDynamically adjust CPU frequency based on system demand to balance performance and efficiency.\n\nTurbo Boost & Boost Policies\n\nManage Intel Turbo Boost and AMD Precision Boost settings to ensure maximum performance when it matters most.\n\nPerformance Hint & Power Modes\n\nFine-tune how your CPU prioritizes performance over energy savings using built-in Windows performance hints and power overlays.\n\nAdvanced CPU Settings (Intel)\n\nAccess low-level tuning for Intel CPUs, including Fully Integrated Voltage Regulator (FIVR), Turbo Power Limits, Speed Shift and other power, performance or voltage controls.\n\nReset Settings to Default\n\nMade changes you're unsure about? Quickly revert power plans or CPU settings to system defaults or previous backups.\n\nControl P-Cores and E-Cores\n\nUse heterogeneous scheduling policies to restrict or prioritize P-Cores or E-Cores on Intel hybrid architecture CPUs.\n\nWindows Power Plan Management\n\nCreate, activate, clone, or export custom power plans and restore system defaults. Fine-tune how Windows balances performance and energy usage.\n\nSystem Tray Monitoring\n\nMonitor CPU, memory, and GPU activity in real time from the system tray. Customize display options and interaction behavior for instant access.\n\nQuick CPU Documentation\n\nLearn more about the Quick CPU functionality and specific features by visiting the application documentation page.\n\nRelease Name: Quick CPU Pro 5.2.0\n\nSize: 39 MB\n\nLinks: HOMEPAGE – NFO – Torrent Search\n\nDownload: RAPiDGATOR",
      "source": "Rlsbb.to",
      "url": "https://post.rlsbb.to/quick-cpu-pro-5-2-0/",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Blackmagic Design Fusion Studio 20.2.1",
      "content": "Description: The world’s most advanced visual effects, 3D, VR and motion graphics solution! Fusion is the world’s most advanced compositing software for visual effects artists, broadcast and motion graphic designers, and 3D animators. Over the last 30 years, Fusion has been used on thousands of Hollywood blockbuster movies and television shows.\n\nFusion features a powerful node based interface that lets you quickly and easily create sophisticated effects by connecting different types of image processing tools together! You get a massive range of tools, incredible VR and 3D support, GPU accelerated performance, unlimited network rendering and more! Fusion gives you everything you need to create exciting broadcast graphics, dramatic titles, and even major feature film visual effects!\n\nWhat’s New in Fusion 20:\n\nCompositions you create on the Fusion page can now be saved as a template and used on the edit or cut page! New animation curve modifiers can be used to automatically retime animations when you change their duration in an edit. Audio playback with waveform display makes it easier to create precisely timed animations, there are shared markers with the edit page and more. In addition, 27 GPU accelerated Resolve FX have been added to the Fusion page, including the noise reduction and sharpening tools from the color page! New node view bookmarks make it easy to navigate large comps, the toolbar can be customized with your favorite tools, and vertical layouts are supported in the node editor.\n\nBuild Your Own Effects with Customizable Templates\n\nFusion effect templates let you create any effect imaginable and apply them to clips on the edit and cut pages! Simply build a composition, save it as a macro, define the parameters you want to make visible, and save it in the correct location. Just drag Fusion effect from the library onto any clip!\n\nAutomatically Retime Animations\n\nAnimation curve modifiers let you easily stretch or squish keyframes and add bounce, mirror or loop animations that automatically change when the duration of the composition changes. When you drop Fusion titles or effects onto the timeline and change its duration, the animation adjusts accordingly!\n\nSync Audio. Animations\n\nThe Fusion page can now playback audio from the edit or cut page timeline. You can choose a mix down from the timeline, or you can listen to the source clip’s audio. Waveforms are displayed in the keyframe editor, allowing you to create precisely timed animations that are in sync with the audio!\n\nCustom Vector Shapes\n\nVector shape tools make it easier to create motion graphics! You get ellipsis, rectangles, polygons and stars, along with boolean operators for combining shapes to create intricate designs. Grid, jitter, offset and transform, let you customize animations. Shapes can also be used as particle sources!\n\nGPU Accelerated Resolve FX\n\nThe Fusion page has 27 new GPU accelerated Resolve FX. This includes the color page’s noise reduction and sharpening tools, along with lens blur, light effects, color effects, revival image restoration tools and more. You also get texture and stylize, temporal effects, warping and beauty tools.\n\nPersonalize Your Workflow\n\nNode tree bookmarks let you quickly navigate to any part of the node tree in a large composition. Customizable toolbars let you quickly switch toolbars based on the current task. Vertical node tree layouts give you more room to view the spline and keyframe editors when creating animations, and more.\n\nHollywood’s Biggest Blockbusters\n\nThousands of Hollywood’s biggest blockbusters and hit television shows use Fusion to create their groundbreaking visual effects. Fusion has been used on feature films like Ant-Man, Red Sparrow and London Has Fallen, as well as hit television shows like Empire, NCIS and Emergence. Fusion also plays a major role in the development of cinematics for major video games such as Dawn of War III, Halo 5 and more!\n\nNodes are a Much Faster Way to Work!\n\nNodes are incredibly easy to use, especially as scenes become more complex. Fusion’s nodes are small icons that represent effects, filters and other image processing operations. Nodes can be easily connected together to build larger and more complex visual effects. Tools, images, and objects can be combined in any order to create unlimited visual effects. Simply click on a node to quickly adjust any single part of your project. That’s much faster than a timeline based tool because you don’t need to hunt through nested stacks of confusing layers and filters!\n\nGet the most Powerful VFX Software Available!\n\nWhether you need to pull a key, track objects, retouch images, animate titles, or create amazing particle effects, Fusion has a massive toolset that lets you tackle the most demanding jobs. You get a true 3D workspace along with tools for compositing, keying, painting, animation, virtual reality, stereoscopic 3D and more. Fusion combines effects and motion graphics, along with 3D modeling and rendering into a single toolset. That means you can import and render 3D models and scenes with the rest of your composite in Fusion. You don’t have to pre‑render assets or transfer between multiple applications!\n\nAnd more…\n\nMinimum System Requirements for Windows\n\nWindows 10 Creators Update.\n\n16 GB of system memory or 32 GB when using Fusion.\n\nFor monitoring, Blackmagic Design Desktop Video 12.9 or later.\n\nIntegrated GPU or discrete GPU with at least 4 GB of VRAM.\n\nGPU which supports OpenCL 1.2 or CUDA 12.8.\n\nAMD/Intel official drivers from your GPU manufacturer.\n\nNVIDIA Studio driver 570.65 or newer.\n\nRelease Name: Blackmagic Design Fusion Studio 20.2.1\n\nSize: 5.5 GB\n\nLinks: HOMEPAGE – NFO – Torrent Search\n\nDownload: RAPiDGATOR",
      "source": "Rlsbb.to",
      "url": "https://post.rlsbb.to/blackmagic-design-fusion-studio-20-2-1/",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "The Agony of Trump’s Oligarchs",
      "content": "But things didn’t go according to plan. Instead of taxes and regulations they got a rickety, ad hoc, and highly personalized form of government control. And though they claim Trump’s “state-driven capitalism”—which I think is more accurately termed fascist corporatism—offends their sense of patriotism, what they really seem to resent is having routinely to pay Trump tribute, either by enriching him personally or by helping him try to plug the $3 trillion revenue hole he created with his idiot “big, beautiful bill.” This is government by shakedown, and they are the mark. Couldn’t happen to a nicer bunch.\n\nSeventy-one percent of the CEOs said Trump’s tariffs have hurt their businesses, and three-quarters said the tariffs were illegal, which of course they are. Seventy-one percent said Trump has eroded the independence of the Federal Reserve (the sole regulatory agency they respect), and 80 percent said Trump’s pressure on the Fed to lower interest rates is harmful, which of course it is.\n\nWhat they most especially hated, though, was (per Sonnenfeld’s summary in a September 21 Fortune article co-authored with his Yale colleague Stephen Henriques) “the Trump administration’s drift toward a quasi-socialist statism, seizing ownership from private shareholders, dictating staffing, and selectively blocking moves into strategic markets based upon politics and kickbacks.” Among the policies of which they “firmly disapproved” were the federal government taking equity stakes in Intel and MP Materials, skimming a cut from Nvidia’s and AMD’s chip sales to China, and reserving for the federal government a “golden share” in the U.S. Steel-Nippon merger.",
      "source": "The New Republic",
      "url": "https://newrepublic.com/article/200775/agony-trump-oligarchs",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "AI startup Modular raises $250 million, seeks to challenge Nvidia dominance",
      "content": "AI startup Modular said on Wednesday it raised $250 million in a funding round valuing it at $1.6 billion, as it aims to challenge Nvidia's software stranglehold on the AI computing market.\n\nThe funding, which nearly tripled the company's valuation from two years ago, was led by U.S. Innovative Technology fund. DFJ Growth and all existing investors, including GV, General Catalyst and Greylock also joined the round.\n\nFounded in 2022 by veteran engineers at Apple and Google, Modular's platform is designed to allow developers to run their AI applications across a variety of computer chips without having to rewrite code for each one. It now serves cloud providers such as Oracle and Amazon, as well as chipmakers Nvidia and AMD.\n\nNvidia controls over 80 per cent of the high-end AI chip market, partly thanks to its proprietary CUDA software, which locks over 4 million global developers into its ecosystem.\n\nSubscribe to our Chief Editor’s Week in Review Our chief editor shares analysis and picks of the week's biggest news every Saturday. This service is not intended for persons residing in the E.U. By clicking subscribe, I agree to receive news updates and promotional material from Mediacorp and Mediacorp’s partners. Loading Loading\n\nModular says it has adopted what it calls a \"Switzerland\" strategy to be a neutral software layer.\n\nChris Lattner, co-founder and CEO of Modular, said the goal is not to defeat the market leader. \"What we're focused on is not like pushing down Nvidia or crushing them. It's more about enabling a level playing field so that other people can compete,\" he said.\n\nIt plans to sell the software directly to enterprises on a consumption basis and through revenue-sharing partnerships with cloud providers.\n\nThe company's strategy has attracted investors betting on a multi-vendor future for AI hardware. Sam Fort, partner at DFJ Growth, compared Modular to \"VMware for the AI era\", which supported companies to work across CPUs.\n\n\"Modular is trying to create the AI hypervisor that will allow you to port workloads across different vendors,\" Fort said.\n\nThe company, with about 130 employees, plans to use the new capital to expand its engineering and go-to-market team. The funds will also help the company expand from its current focus on AI inference into the AI training market.",
      "source": "CNA",
      "url": "https://www.channelnewsasia.com/business/ai-startup-modular-raises-250-million-seeks-challenge-nvidia-dominance-5367226",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Meet the Snapdragon X2 Elite, Qualcomm's new 18-core PC chip that rivals the Apple M4",
      "content": "Qualcomm has officially announced the evolution of its PC chip endeavors with the Snapdragon X2 Elite, a chip that is comprised of a whopping 18 cores and promises to pump out some serious performance.\n\nWhen it comes to PCs, there are really only two major companies that you’ll see chips from in laptops and desktops—Intel and AMD. In 2024, Qualcomm came along with its Snapdragon X Elite chip, giving consumers an alternative to the two biggest options. The first Lenovo laptops with the Snapdragon X Elite launched last May, and Dell put out a laptop a month later.\n\nWhile there were several benefits to Qualcomm’s chip inside a laptop, one of the most important ones was battery life. Qualcomm was boasting long battery life on a single charge. This isn’t something you get often with laptops. The good news is that Qualcomm is back and promising even better battery life for laptops powered by the Snapdragon X2 Elite. So, if long battery life is what you’re looking for, then you’ll want to keep your eye on these laptops.\n\nQualcomm says the just-announced Snapdragon X2 Elite can offer multi-day battery life to laptops\n\nIf a laptop lasting for multiple days on battery doesn’t entice you, then you must love the tedious nature of having to plug your devices in every single day. That being said, if you hate charging your stuff all the time, then Snapdragon X2 Elite-powered laptops are likely to be your new best friend.\n\nQualcomm says this new chip can offer multi-day battery life. That could mean two days, or it could mean three or more. What’s really important, however, is that it’s more than one. Qualcomm doesn’t mention specifics, but it says users won’t have to compromise on performance to get more hours out of their machine. The firm also claims that the chip rivals the Apple M4, beating it out in benchmarks. Qualcomm made a similar claim with the first version of this chip when compared to the Apple M3. It outperformed Intel’s Core Ultra, too. So it’s not too hard to imagine the new model continuing this trend.\n\nThere will be three different models of the chip\n\nQualcomm says it’s launching three different models of the Snapdragon X2 Elite, so there should be a varying range of laptops at different price points. First, there’s the X2E-80-100. This is the least powerful version, coming with 12 cores instead of 18. It also has a smaller cache of 34MB. Despite these tweaks, it still offers the same frequencies. Its boost frequency is up to 4.7GHz for the single core and up to 4.4GHz for the dual-core. This is similar to the second variant, which is impressive.\n\nNext up there’s the X2E-88-100, which comes with a total of 18 cores. While its frequencies are similar to the lower-tier model, it does come with some key benefits. It has a 53MB total cache, and it supports up to 12 PCIe Gen 5 lanes as opposed to 8. It also has a slightly higher boost frequency with dual-core of 4.7GHz. Lastly, there’s the Snapdragon X2 Elite Extreme, or the X2E-96-100. This bumps the max boost frequency up to 5.0GHz for both single-core and dual-core. Other benefits consumers can expect from this chip are support for Bluetooth 5.4, Bluetooth LE, and up to Wi-Fi 7 speeds, just to name a few.",
      "source": "Android Headlines",
      "url": "https://www.androidheadlines.com/2025/09/qualcomm-snapdragon-x2-elite.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Qualcomm's new Snapdragon X2 Elite Extreme and Elite chips for PCs stretch up to a record 5 GHz — 3nm Arm chips sport new Oryon Prime cores",
      "content": "Qualcomm is back for round two of its push into Windows PCs . At its Snapdragon Summit in Maui, Hawaii, the company revealed its Snapdragon X2 Elite and X2 Elite Extreme. These chips will serve as the high-end offerings in Qualcomm's second generation of Arm-based chips for laptops and other PC form factors.\n\nThe Elite Extreme is a new tier above the standard Elite, which was the top chip in the original X-series line. The Snapdragon X2 Elite Extreme will offer up to 18 cores, and Qualcomm claims it's the first Arm chip to hit 5 GHz (on up to two cores).\n\nThe company says its Elite chips will be made on a 3-nanometer process node. The Snapdragon X2 Elite uses a mix of Qualcomm Oryon Prime cores and what it calls Performance CPU cores. This is seemingly a standard Performance/Efficiency layout with different names. At normalized power, Qualcomm says it offers up to 75% more performance than its competitors. In multitasking, it claims the new chips will offer up to 31% faster performance at a normalized ISO power, while needing 43% less power than last-gen chips. We don't yet have benchmarks to share, and Qualcomm didn't note the exact TDPs for these chips.\n\n(Image credit: Qualcomm)\n\nThe Elite Extreme has higher clock speeds in both single- and dual-core boost and multi-core max than the other two Snapdragon X2 Elite variants. The Snapdragon X2 Elite Extreme is model X2E-96-100, while the standard Elites are X2E-88-100 and X2E-80-100. The Extreme and the 88-100 each have 18 cores, while the 80-100 has 12 cores.\n\nThere's also a new Qualcomm Adreno GPU, which the company says brings a 2.3x increase in performance per watt and power efficiency compared to the last generation. The new 80 TOPS NPU looks to be the fastest in a laptop (with INT8 math), with 78% more TOPS than the previous generation, 45 TOPS NPU. In its press release, Qualcomm writes that this NPU \"is designed to handle Copilot+ and concurrent AI experiences.\" (Copilot+ doesn't include actual Copilot, the assistant that runs largely in the cloud.)\n\nSwipe to scroll horizontally Header Cell - Column 0 Snapdragon X2 Elite Extreme Snapdragon X2 Elite Snapdragon X2 Elite Part number X2E-96-100 X2E-88-100 X2E-80-100 Cores (Prime / Performance) 12 / 6 12 / 6 6 / 6 Boost frequency (Single-core / dual-core) 5.0 GHz / 5.0 GHz 4.7 GHz / 4.7 GHz 4.7 GHz / 4.4 GHz Multi-core max frequency 3.6 GHz 3.4 GHz 3.4 GHz Total cache 53 MB 53 MB 34 MB Qualcomm Adreno GPU part X2-90 X2-90 X2-85 Max frequency (GPU) 1.85 GHz 1.70 GHz 1.70 GHz NPU TOPS (INT8) 80 80 80 Memory Type LPDDR5X-9523 LPDDR5X-9523 LPDDR5X-9523 Max memory capacity 128+ GB 128 GB 128 GB Bus width 192-bit 128-bit 128-bit Bandwidth 228 GB/s 152 GB/s 152 GB/s Image Signal Processor Qualcomm Spectra ISP Qualcomm Spectra ISP Qualcomm Spectra ISP Cellular Modem-RF Snapdragon X75 5G Modem-RF System Snapdragon X75 5G Modem-RF System Snapdragon X75 5G Modem-RF System Connectivity Up to Wi-Fi 7, Bluetooth 5.4 Up to Wi-Fi 7, Bluetooth 5.4 Up to Wi-Fi 7, Bluetooth 5.4\n\nThe X2 Elite chip supports Qualcomm's x75 5G modem-RG system, with up to 10 Gbps peak downloads. It also works with Qualcomm FastConnect 7800 for Wi-FI 7/6/6E and Bluetooth 5.4 LE. Qualcomm's new Guardian is an out-of-band management feature for business-focused remote oversight, akin to Intel’s vPro.\n\nImage 1 of 5 (Image credit: Qualcomm) (Image credit: Qualcomm) (Image credit: Qualcomm) (Image credit: Qualcomm) (Image credit: Qualcomm)\n\nQualcomm says that it expects systems with the X2 Elite to ship in the first half of 2026. That may mean we’ll see a device or two at CES 2026 in Las Vegas, before launch. Notably, Qualcomm's images and a sizzle reel both suggest that the X2 Elite will appear in both laptops and mini PCs.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n(Image credit: Qualcomm)\n\nIt's been over a year since the initial batch of Snapdragon X Elite chips were announced. Subsequently, a full lineup including the X Plus (in both 10-core and 8-core variants) and a standard Snapdragon X chip were released. The top-end chips appeared in designs from major manufacturers, including Microsoft, Samsung, Dell, HP, Asus, Lenovo, and Acer.\n\nThe initial chips showed off their efficiency through long battery life, and we hope to see the X2 SoCs build on that. They didn't, however, work with some applications (namely games) and we want to see better emulation support there. Windows on Arm, however, didn't exactly take over the market, so we'll see what the new chips bring to the table.\n\nQualcomm is announcing these chips pretty early. The Snapdragon Summit comes ahead of Apple's next major release (Apple is Qualcomm's biggest rival in Arm-based systems), which is rumored to be early next year. And of course, by the time many X2 devices make it to market in the first half of 2026, AMD and Intel may also have next-gen x86 chips ready to compete.\n\nNext year is shaping up to be an eventful one for those looking to buy a new laptop, which should be good for consumers and the industry as a whole. After a fairly quiet 2025 on the mobile front, it’ll also be nice to have some fresh silicon to test.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/qualcomms-new-snapdragon-x2-elite-extreme-and-elite-chips-for-pcs-stretch-up-to-a-record-5-ghz-3nm-arm-chips-sport-new-oryon-prime-cores",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Lenovo Legion 5: 15.6\" FHD IPS 144Hz, Ryzen 7 7840HS, RTX 4060, 16GB DDR5, 512GB SSD $799 (0 replies)",
      "content": "Product Description:\n\nThe Lenovo 83EG0001US is part of the Legion 5 15APH9 series—a gaming powerhouse built for performance and immersive experiences. AI Engine+ dynamically optimizes system performance based on your usage RTX 4060 GPU supports real-time ray tracing and DLSS for lifelike graphics DDR5 RAM and PCIe Gen4 SSD ensure lightning-fast load times 15.6″ FHD IPS screen with 144Hz refresh rate and 100% sRGB color accuracy Storm Grey chassis with aluminum top cover for a premium feel",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18628684-lenovo-legion-5-15-6-fhd-ips-144hz-ryzen-7-7840hs-rtx-4060-16gb-ddr5-512gb-ssd-799",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Qualcomm announces Snapdragon X2 Elite and Extreme for Windows PCs",
      "content": "is a senior editor and founding member of The Verge who covers gadgets, games, and toys. He spent 15 years editing the likes of CNET, Gizmodo, and Engadget.\n\nPosts from this author will be added to your daily email digest and your homepage feed.\n\nLast year, after well over a decade of trying, Qualcomm finally made Windows on Arm laptops a thing, putting both Intel and AMD on notice and shoving Intel out of consumer-grade Microsoft Surface machines. Today, we’re learning about the second generation of the chip that made it happen, one which’ll now come in two distinct flavors: the Snapdragon X2 Elite and Snapdragon X2 Elite Extreme.\n\nQualcomm is making a gigantic claim right in the headline of its press release: it says these are “the fastest and most efficient processors for Windows PCs.” I’m sure Intel and AMD will have something to say about that!\n\nFrom Qualcomm’s Snapdragon Summit video. Image: Qualcomm\n\nBut for now, the company claims its 3nm chips offer up to 31 percent faster CPU performance than the previous-gen Snapdragon X Elite at the same power, or can require 43 percent less power, and with up to 2.3x the GPU performance per watt (not a pure performance boost) from a new 1.85GHz GPU. On the CPU side, it’s using a 3rd-gen Oryon CPU that’ll also feature in Qualcomm’s new mobile flagship Snapdragon 8 Elite 5 chip, but here with up to 18 cores, 12 of which can run up to 4.4GHz, or up to two of them at 5GHz — a clockspeed which Qualcomm says is a first for Arm CPUs.\n\nYou can see more specs below, and at Qualcomm’s website and overview PDF.\n\nImage: Qualcomm\n\nThere’s also a new 80 TOPS Hexagon NPU, for AI tasks, that offers 37 percent more performance with a 16 percent power consumption improvement, and the company claims it’s the fastest laptop NPU by far:\n\nImage: Qualcomm\n\nQualcomm’s characterizing all of this as a “legendary leap in performance,” claiming the Elite Extreme in particular offers “up to 75 percent faster CPU performance” than competitors at the same power.\n\nWhile it doesn’t say which competitors it’s talking about in the press release, it appears that Qualcomm is comparing against some of the most powerful (and power-hungry) laptop chips in the market, including the Intel Core Ultra 9 285H and AMD Ryzen AI 9 HX 370, and you can see Qualcomm isn’t labeling both axes of its graphs:\n\nImage: Qualcomm Image: Qualcomm\n\nImage: Qualcomm\n\nQualcomm also claims these power savings will lead to “multi-day battery life,” but that’s what the company already said about last year’s Snapdragon X Elite. (We saw 14 to 18 hours from last year’s laptops, so perhaps that’s multi-day defined as “two eight-hour workdays.”)\n\nImage: Qualcomm\n\nStill, these sound like very solid improvements, and some of them come from distinct new portions of the silicon. Gaming on Arm, which still needed work last year, will get a boost from a dedicated new 18MB of high speed cache that Qualcomm’s calling “Adreno High Performance Memory.”\n\nAnd Qualcomm says Adobe creators will see big improvements over last year’s laptops: 28 percent faster photo editing in Photoshop, 43 percent faster exports from Lightroom, and a similar boosts to Premiere video analysis. Razer’s Min-Liang Tan also announced today that Razer will bring its Synapse software to Windows on Snapdragon, which is likely to be a polarizing announcement. He notably did not promise that Razer will make a Snapdragon-based gaming laptop.\n\nIt’s intriguing to see that the company’s testing its X2 Elite Extreme at over 50W of power; last year, Snapdragon chips were just for thin and light laptops, but 50W lets them scale into bigger PCs.\n\nNote that when Qualcomm had its coming out party with Microsoft last year, the laptops arrived later that year. That’s not happening this time around: they’re “expected to be available 1H26,” the company writes.\n\nQualcomm’s announcement also doesn’t mention whether these chips will feature in its hinted-at collaboration with Google on Android for PC, but Sameer Samat, Google’s president of Android Ecosystem, suggested that the merger ChromeOS and Android might be on a similar schedule. “That combination is something we’re super excited about for next year,” he says.\n\nCorrection, September 24th: The new GPU boasts 2.3x performance per watt than the previous generation, not 2.3x the performance overall.",
      "source": "The Verge",
      "url": "https://www.theverge.com/news/785068/qualcomm-announces-snapdragon-x2-elite-and-extreme-for-windows-pcs",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "First Atlantic Nickel Renames Atlantic Nickel Project to Pipestone XL to Reflect 100% Ownership of 30 km Pipestone Ophiolite Complex and Provides Updates on RPM Phase 2x Program",
      "content": "GRAND FALLS-WINDSOR, Newfoundland and Labrador, Sept. 24, 2025 (GLOBE NEWSWIRE) -- First Atlantic Nickel Corp. (TSXV: FAN) (OTCQB: FANCF) (FSE: P21) (\"First Atlantic\" or the \"Company\") is pleased to announce that it has renamed its flagship Atlantic Nickel Project to Pipestone XL, reflecting the Company's 100% ownership of the entire 30-kilometer Pipestone Ophiolite Ultramafic Complex. The new name emphasizes the district-scale potential of the project, which hosts multiple zones of awaruite (Ni3Fe) nickel alloy mineralization, including the high-priority RPM Zone, the Super Gulp Zone, the historical Atlantic Lake Zone, and additional discoveries of visible awaruite mineralization discovered during the Company’s 2025 regional exploration program throughout the complex. The RPM Phase 2 drilling program will now be referred to as Phase 2X, underscoring the Company's objective to double (“2X”) both the strike length and expand the width of awaruite mineralization established during the Phase 1 drill program at the RPM Zone. The Pipestone XL name also highlights the project's clean energy potential, including ongoing geologic hydrogen research in partnership with Colorado School of Mines announced March 19, 2025 .\n\nFollowing a series of acquisitions in the first half of 2024 that consolidated the entire 30-kilometer Pipestone Ophiolite Complex, First Atlantic has advanced the geological understanding of this serpentinized ultramafic complex through systematic exploration. The Company's technical team, led by Senior Project Geologist Michael Piller, author of the 2011 Memorial University thesis \"An Examination of Awaruite (Ni₃Fe) Formation During Serpentinization of the Pipestone Pond Ophiolitic Complex in the Atlantic Lake Area, Central Newfoundland\" researched in conjunction with Cliffs Natural Resources Inc. (now Cleveland-Cliffs - a large US steel producer) and Altius Resources Inc., recognized that historical exploration focused primarily on the northern Atlantic Lake area, while the southern regions remained underexplored. This district-scale approach led to the discovery of the RPM and Super Gulp zones during surface exploration in late summer 2024, followed by the first drill testing that fall.\n\nPipestone XL represents a continuous, 30 km belt of heavily faulted, serpentinized ultramafic rocks enriched in nickel and chromium and characterized by a strong magnetic anomaly. Importantly, awaruite mineralization occurs at surface, offering a significant advantage for mineral exploration and potential development. The Company's Phase 1 drilling program delineated a 400m x 500m area of disseminated awaruite mineralization at the RPM Zone, returning the highest awaruite nickel grades drilled to date at Pipestone XL. Mineralization observed at the RPM zone to date extends from surface to 495 meters downhole and remains open at depth. Davis Tube Recovery (DTR) metallurgical testing confirmed magnetic concentrate grades averaging 1.38% nickel and 1.67% chromium, yielding an average DTR nickel grade of 0.12% with a mass pull of 9.08%. The Phase 2X program is now underway, embodying the Company's mission to double (2X) the strike length and width of the RPM Zone, while incorporating new geological insights from district-scale exploration across all three mineralized zones. In parallel, investigations into Pipestone XL's geologic hydrogen potential continue through the Company’s research collaboration with the Colorado School of Mines.\n\nHIGHLIGHTS\n\nPipestone XL: Reflects First Atlantic’s 100% ownership of a 30 km continuous belt of ultramafic rocks enriched in awaruite nickel and chromium, characterized by a distinct magnetic signature anomaly.\n\nReflects First Atlantic’s 100% ownership of a 30 km continuous belt of ultramafic rocks enriched in awaruite nickel and chromium, characterized by a distinct magnetic signature anomaly. Multiple Target Zones: Three drill-confirmed zones (RPM, Super Gulp, and Atlantic Lake) across the 30-kilometer belt, plus numerous additional surface occurrences of visible awaruite mineralization.\n\nThree drill-confirmed zones (RPM, Super Gulp, and Atlantic Lake) across the 30-kilometer belt, plus numerous additional surface occurrences of visible awaruite mineralization. RPM Phase 2X Program: Focused on doubling (2X) both the strike length and expanding the width of mineralization beyond the Phase 1 discovery area of 400 m x 500 m.\n\nFocused on doubling (2X) both the strike length and expanding the width of mineralization beyond the Phase 1 discovery area of 400 m x 500 m. Top Mining Jurisdiction: Newfoundland ranks among the world’s top 10 mining jurisdictions, offering streamlined permitting, a skilled workforce, and pro-mining government policies.\n\nNewfoundland ranks among the world’s top 10 mining jurisdictions, offering streamlined permitting, a skilled workforce, and pro-mining government policies. Strategic Infrastructure: Road access, proximity to clean hydroelectric power, and established mining infrastructure support efficient project development.\n\nRoad access, proximity to clean hydroelectric power, and established mining infrastructure support efficient project development. Simplified Processing: Awaruite's magnetic properties allow concentration without smelting, enhancing alignment with North American critical mineral supply chain independence.\n\nFor further information, questions, or inquiries, call Rob Guzman - Investor Relations at First Atlantic Nickel by phone at +1 844 592 6337 or via email at rob@fanickel.com .\n\nFigure 1: Pipestone XL Project Map showing the principal mineralized zones: RPM Zone, Chrome Pond, Super Gulp and Atlantic Lake\n\nPIPESTONE XL PROJECT OVERVIEW AND HISTORY\n\nThe Pipestone XL project comprises the entire 30-kilometer Pipestone Ophiolite Ultramafic Complex, a continuous belt of serpentinized ultramafic rocks enriched in nickel and chromium and characterized by a distinct magnetic anomaly. First Atlantic secured 100% ownership of the complex through multiple acquisitions in 2024, followed by systematic exploration that revealed numerous surface outcrops of visible awaruite mineralization. From this work, the RPM and Super Gulp Zones emerged as priority drill targets. The ophiolite's harzburgite and dunite composition, combined with extensive faulting and serpentinization, creates optimal conditions for awaruite nickel mineralization.\n\nHistorical drilling in 1978 at the Atlantic Lake zone in the northern portion of the ophiolite complex, intersected 0.22% nickel over 87.15 meters (DDH78-AL-1, NFLD/3284). The hole ended in mineralization without testing deeper, highlighting untested potential at depth. Previous exploration efforts largely concentrated on this northern area, while the southern extent of the complex remained underexplored until First Atlantic's systematic approach led to the discovery of the RPM Zone, located 26 kilometers south of Atlantic Lake and 10 kilometers south of Super Gulp.\n\nPhase 1 drilling at RPM successfully intersected disseminated awaruite mineralization in all holes from surface to depth. DTR testing confirmed magnetically recoverable nickel grades averaging 0.12% DTR across all drilled intervals, with magnetic concentrate grades of 1.38% nickel. These results demonstrate consistent awaruite nickel mineralization across the entire 400 m x 500 m Phase 1 footprint, which remains open in all directions and underscores the potential for large-scale bulk tonnage mineralization. Building on this success, the Phase 2X program’s goal is to double the strike length and expand the width of the mineralized zone.\n\nRPM PHASE 2X DRILL PROGRAM\n\nThe Phase 2X program aims to double the size of the RPM Zone from its current 400-meter by 500-meter area, where Phase 1 drilling confirmed widespread magnetically recoverable awaruite nickel averaging 0.12% DTR across all drilled intervals.\n\nBased on improved geological understanding showing that the mineralization dips to the west, the Company will aim to drill with an optimal primary orientation from east to west. This approach will better intersect the mineralized zones at the proper angle and provide more accurate measurements of their true thickness. This represents a strategic adjustment from the initial westward drilling direction used at the Super Gulp zone.\n\nThe drilling program will systematically expand outward from the known mineralized area using step-out holes, targeting large volumes of disseminated awaruite suitable for bulk mining. The Company has identified that nickel grades vary by rock type: narrower dunite layers within the peridotite typically contain less 0.08% DTR nickel, while the broader peridotite (harzburgite) units contain higher grades of 0.10-0.17% DTR nickel and can extend for over 500 meters in drilled width. This knowledge of how grades are distributed across different rock types will help optimize drill targeting as the Company pursues its goal of doubling the size of the RPM Zone.\n\nFigure 2: Drill Core from RPM Phase 2X Program preparing for shipment to analytical lab for assay and davis tube metallurgical testing.\n\nTable 1: Summary of Magnetically Recovered Nickel Results from 2024 and 2025 Diamond Drill Holes – RPM Zone Drilling at the Pipestone XL (formerly Atlantic Nickel project)\n\nDrill Hole Zone Section From meters To meters Interval meters Magnetically Recovered (DTR)\n\nNickel % Magnetic Concentrate Nickel\n\nGrade (Ni %) Mass Pull (%)\n\n\n\nComment AN 24 - 02 RPM S1 11.0 394.1 383.1 0.13 1.37 9.50 NR - March 12, 2025 AN 24 - 03 RPM S1 18.0 234.0 216.0 0.11 1.32 9.12 NR - April 15, 2025 AN 24 - 04 RPM S1 12.0 378.0 366.0 0.14 1.46 9.53 NR- June 24, 2025 AN 24 - 05 RPM S2 6.0 357.0 351.0 0.12 1.47 8.21 NR - July 9, 2025 AN 25 - 06 RPM S2 5.65 453 447.35 0.11 1.27 9.02 NR - August 12, 2025 AN 25 - 07 RPM S2 495.0 pending pending samples submitted AN 25 - 08 RPM S3 491.0 pending pending samples submitted AN 25 - 09 RPM S3 480.0 pending pending samples submitted AN 25 - 10 RPM S1 samples submitted\n\n\n\n\n\n\n\nFigure 3: RPM Zone Phase 2X drilling map at Pipestone XL.\n\nCEO STATEMENT\n\nAdrian Smith, CEO of First Atlantic, commented: \"The Pipestone XL name reflects our 100% ownership of the 30-kilometer ophiolite belt of ultramafic rocks and the multi-zone potential of this district-scale discovery. At RPM, we have already demonstrated consistent DTR nickel mineralization across a 400m x 500m area, now being expanded through Phase 2X drilling. Combined with recent Super Gulp discovery and numerous untested targets along trend, we are beginning to demonstrate the true scale of the Pipestone Ophiolite Complex. The recent announcement by FPX Nickel and JOGMEC (Japan Organization for Metals and Energy Security) designating the Advocate property in Newfoundland as their first designated project - selected from more than 50 targets across 10 jurisdictions worldwide - further validates the exceptional potential of ophiolite-hosted awaruite deposits in our province. As nickel demand grows to support batteries, stainless steel and future technologies, Pipestone XL is well positioned to become a crucial North American source of this essential metal. Our awaruite's unique magnetic properties enable direct concentration without traditional smelting, offering a cleaner, more sustainable pathway to supply the industries and infrastructure that power our modern economy.\"\n\nNEWFOUNDLAND MINING ADVANTAGE\n\nNewfoundland and Labrador consistently ranks in the world’s top 10 mining jurisdictions, according to the Fraser Institute's 2024 Annual Survey of Mining Companies. The province combines world-class geology with supportive government policies and well-established infrastructure. As the survey notes: \"Two Canadian provinces, Saskatchewan and Newfoundland & Labrador, appear in the list of top ten most attractive jurisdictions for mining investment.\"1 Newfoundland and Labrador also offers one of the most efficient regulatory environments in Canada. The province's streamlined permitting process has enabled First Atlantic to advance from acquisition to drilling in under 12 months, with exploration permits often granted in as little as three weeks.\n\nFigure 4: Ranking of attractive mining destinations in North America, from the Fraser Institute’s 2024 Annual Survey of Mining Companies2.\n\nThe recent successful construction and commissioning of Equinox Gold's Valentine Lake Mine demonstrate Newfoundland's ability to support major mining projects from exploration through to production. On September 15, 2025, Equinox Gold Corp. announced its first gold pour at Valentine Lake, noting: \"Once fully operational, Valentine will be Equinox Gold's second-largest mine, the largest gold mine in Atlantic Canada.\"3 Located in central Newfoundland, Valentine Lake validates the region's infrastructure and skilled workforce, both critical for advancing large-scale mining operations.\n\nIn addition, FPX Nickel's partnership with JOGMEC to acquire the Advocate awaruite project in Newfoundland, announced on September 23, 20254, highlights growing international recognition of the province's potential for this rare nickel mineral. FPX has been a pioneer in awaruite exploration through their Decar project in British Columbia, and its entry into Newfoundland further validates the prospectivity of the region's ultramafic rock belts.\n\nAWARUITE - RARE & PURE NATURAL NICKEL-IRON-COBALT ALLOY MINERAL\n\nThe sulfur-free nature of awaruite (Ni 3 Fe), a naturally occurring nickel-iron-cobalt alloy already in metallic form, eliminates the need for secondary processes such as smelting, roasting or acid leaching that are typical of sulfide or laterite nickel ores. Unlike sulfides, which are not natural alloys, awaruite avoids the challenge of sourcing smelter capacity - a bottleneck in North America's nickel supply chain. With an average nickel grade of approximately 76%, awaruite significantly exceeds the ~25%5 nickel grade characteristic of pentlandite. Awaruite's strong magnetic properties enable concentration through magnetic separation, as demonstrated by Davis Tube Recovery (DTR) testing at First Atlantic's RPM Zone drill core.\n\nAwaruite eliminates the electricity requirements, emissions, and environmental impacts associated with conventional smelting, roasting or acid leaching processes of common nickel minerals. Moreover, awaruite's sulfur-free composition removes the risks of acid mine drainage (AMD) and related permitting challenges commonly posed by sulfide minerals.6 As noted by the United States Geological Survey (USGS) in 2012: \"The development of awaruite deposits in other parts of Canada may help alleviate any prolonged shortage of nickel concentrate. Awaruite, a natural iron-nickel alloy, is much easier to concentrate than pentlandite, the principal sulfide of nickel.\"\n\nFigure 5: Quote from USGS on Awaruite Deposits in Canada\n\nInvestor Information\n\nThe Company's common shares trade on the TSX Venture Exchange under the symbol \"FAN\", the American OTCQB Exchange under the symbol “FANCF” and on several German exchanges, including Frankfurt and Tradegate, under the symbol \"P21\".\n\nInvestors can get updates about First Atlantic by signing up to receive news via email and SMS text at www.fanickel.com . Stay connected and learn more by following us on these social media platforms:\n\nhttps://x.com/FirstAtlanticNi\n\nhttps://www.facebook.com/fanickelcorp\n\nhttps://www.linkedin.com/company/firstatlanticnickel/\n\nFOR MORE INFORMATION:\n\nFirst Atlantic Investor Relations\n\nRobert Guzman\n\nTel: +1 844 592 6337\n\nrob@fanickel.com\n\n\n\nDisclosure\n\nAdrian Smith, P.Geo., a director and the Chief Executive Officer of the Company is a qualified person as defined by NI 43-101. The qualified person is a member in good standing of the Professional Engineers and Geoscientists Newfoundland and Labrador (PEGNL) and is a registered professional geoscientist (P.Geo.). Mr. Smith has reviewed and approved the technical information disclosed herein.\n\nAnalytical Method & QA/QC\n\nSamples were split in half on site, with one half remaining in the core box for future reference and the other half securely packaged for laboratory analysis. The QA/QC protocol included the insertion of blanks, duplicates, and certified reference material (standards), with one QA/QC sample being inserted every 20 samples to monitor the precision and accuracy of the laboratory results. All analytical results successfully passed QA/QC screening at the laboratory, and all Company inserted standards and blanks returned results within acceptable limits.\n\nSamples were submitted to Activation Laboratories Ltd. (“Actlabs”) in Ancaster, Ontario, an ISO 17025 certified and accredited laboratory operating independently of First Atlantic. Each sample was crushed, with a 250 g sub-sample pulverized to 95% - 200 mesh. A magnetic separate was then generated by running the pulverized sub-sample through a magnetic separator which splits the sub-sample into magnetic and non-magnetic fractions. This involves running a 30 g split of the pulp through a Davis Tube magnetic separator as a slurry using a constant flow rate, a magnetic field strength of 3,500 Gauss, and a tube angle of 45 degrees to produce magnetic and non-magnetic fractions.\n\nThe magnetic fractions are collected, dried, weighed and the magnetic fraction is fused with a lithium metaborate/tetraborate flux and lithium bromide releasing agent and then analyzed on a wavelength dispersive XRF for multiple elements including nickel, cobalt, iron and chromium. The magnetically recovered nickel grade was then calculated by multiplying the XRF fusion nickel value by the weight of the magnetic fraction and dividing by the total recorded feed weight or magnetic mass pulled from the sample.\n\nTrue widths are currently unknown. However, the nickel bearing ultramafic ophiolite and peridotite rocks being targeted and sampled in the Phase 1 drilling program at the Pipestone XL (formerly the Atlantic Nickel Project) are mapped on surface and in drilling as several hundred meters to over 1 kilometer wide and approximately 30 kilometers long.\n\nAbout First Atlantic Nickel Corp.\n\nFirst Atlantic Nickel Corp. (TSXV: FAN) (OTCQB: FANCF) (FSE: P21) is a Canadian mineral exploration company developing the 100%-owned Pipestone XL (formerly the Atlantic Nickel Project), a large-scale nickel project strategically located near existing infrastructure in Newfoundland, Canada. The Project's nickel occurs as awaruite, a natural nickel-iron-cobalt alloy containing approximately 75% nickel with no-sulfur and no-sulfides. Awaruite's properties allow for smelter-free magnetic separation and concentration, which could strengthen North America's critical minerals supply chain by reducing foreign dependence on nickel smelting. This aligns with new US Electric Vehicle US IRA requirements, which stipulate that beginning in 2025, an eligible clean vehicle may not contain any critical minerals processed by a FEOC (Foreign Entities Of Concern)7.\n\nFirst Atlantic aims to be a key input of a secure and reliable North American critical minerals supply chain for the stainless steel and electric vehicle industries in the USA and Canada. The company is positioned to meet the growing demand for responsibly sourced nickel that complies with the critical mineral requirements for eligible clean vehicles under the US IRA. With its commitment to responsible practices and experienced team, First Atlantic is poised to contribute significantly to the nickel industry's future, supporting the transition to a cleaner energy landscape. This mission gained importance when the US added nickel to its critical minerals list in 2022, recognizing it as a non-fuel mineral essential to economic and national security with a supply chain vulnerable to disruption.\n\nNeither the TSX Venture Exchange nor its Regulation Services Provider (as that term is defined in policies of the TSX Venture Exchange) accepts responsibility for the adequacy or accuracy of this release.\n\nForward-looking statements:\n\nThis news release may include \"forward-looking information\" under applicable Canadian securities legislation. Such forward-looking information reflects management's current beliefs and are based on a number of estimates and/or assumptions made by and information currently available to the Company that, while considered reasonable, are subject to known and unknown risks, uncertainties, and other factors that may cause the actual results and future events to differ materially from those expressed or implied by such forward-looking information.\n\nForward-looking information in this news release includes, but is not limited to: statements regarding: the timing, scope and results of the Company’s Phase 1 and Phase 2X drilling programs; future project developments; the Company’s objectives, goals, and future plans; statements and estimates of market conditions; the viability of magnetic separation as a low-impact processing method for awaruite; the strategic and economic implications of the Company’s projects; and expectations regarding future developments and strategic plans; Readers are cautioned that such forward-looking information are neither promises nor guarantees and are subject to known and unknown risks and uncertainties including, but not limited to, general business, economic, competitive, political and social uncertainties, uncertain and volatile equity and capital markets, lack of available capital, actual results of exploration activities, environmental risks, future prices of base and other metals, operating risks, accidents, labour issues, delays in obtaining governmental approvals and permits, and other risks in the mining and clean energy industries. Additional factors and risks including various risk factors discussed in the Company’s disclosure documents which can be found under the Company’s profile on http://www.sedarplus.ca. Should one or more of these risks or uncertainties materialize, or should assumptions underlying the forward-looking statements prove incorrect, actual results may vary materially from those described herein as intended, planned, anticipated, believed, estimated or expected.\n\nThe Company is presently an exploration stage company. Exploration is highly speculative in nature, involves many risks, requires substantial expenditures, and may not result in the discovery of mineral deposits that can be mined profitably. Furthermore, the Company currently has no mineral reserves on any of its properties. As a result, there can be no assurance that such forward-looking statements will prove to be accurate, and actual results and future events could differ materially from those anticipated in such statements. The Company undertakes no obligation to update forward-looking information, except as required by applicable securities laws.\n\n1 https://www.fraserinstitute.org/studies/annual-survey-mining-companies-2024\n\n2 https://www.fraserinstitute.org/studies/annual-survey-mining-companies-2024\n\n3 https://www.equinoxgold.com/news/equinox-gold-delivers-first-gold-at-its-valentine-gold-mine-in-newfoundland-and-labrador-canada/\n\n4 https://fpxnickel.com/news/fpx-nickel-and-jogmec-select-the-advocate-nickel-property-in-newfoundland-to-be-advanced-as-a-designated-project/\n\n5 https://fpxnickel.com/projects-overview/what-is-awaruite/\n\n6 https://d9-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/mineral-pubs/nickel/mcs-2012-nicke.pdf\n\n7 https://home.treasury.gov/news/press-releases/jy1939\n\nPhotos accompanying this announcement are available at\n\nhttps://www.globenewswire.com/NewsRoom/AttachmentNg/d02fee9b-90a4-408b-9358-89a3547d785c\n\nhttps://www.globenewswire.com/NewsRoom/AttachmentNg/e86fc609-3137-49d5-8fa6-51748aadbe35\n\nhttps://www.globenewswire.com/NewsRoom/AttachmentNg/37482804-5cb6-47a4-8d8a-372b9ae13ec6\n\nhttps://www.globenewswire.com/NewsRoom/AttachmentNg/97624e04-62cf-4771-981b-adb96691d677\n\nhttps://www.globenewswire.com/NewsRoom/AttachmentNg/f12b20b4-3f80-47d0-b44d-afdd092f005e",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/24/3155290/0/en/First-Atlantic-Nickel-Renames-Atlantic-Nickel-Project-to-Pipestone-XL-to-Reflect-100-Ownership-of-30-km-Pipestone-Ophiolite-Complex-and-Provides-Updates-on-RPM-Phase-2x-Program.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Compute, Capture, Compete: Europe’s Playbook for Digital Energy",
      "content": null,
      "source": "EURACTIV",
      "url": "https://www.euractiv.com/opinion/compute-capture-compete-europes-playbook-for-digital-energy/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "AMD Zen 3-Based Ryzen 3 5100 Cezanne CPU Spotted; Features 4 Cores, 8 Threads Configuration",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/amd-zen-3-based-ryzen-3-5100-cezanne-cpu-spotted-features-4-cores-8-threads-configuration/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Microsoft is resorting to laser etching AI-designed cooling channels directly into data center chips to tame their massive heat",
      "content": "Introducing microfluidic cooling: a breakthrough in chip cooling technology - YouTube Watch On\n\nIf you think the power consumption of today's gaming graphics cards is bad, it's nothing compared to how energy the massive processors in AI and data systems use. All that power ends up as heat, resulting in chip cooling being a serious challenge. Microsoft reckons it has a great solution, though, and it's all about getting water into the processors themselves.\n\nThe most complex direct-die, liquid cooling loops you'll see in a gaming PC all involve using a chamber that mounts on top of the CPU. At no point does the coolant ever touch the chip directly. In a recently published blog, Microsoft explains how it has developed a system that does precisely that.\n\nBy etching the surface of the processor die with an intricate pattern of tiny channels, water can then be pumped directly into the silicon itself, albeit to a very shallow depth.\n\nThe keyword to describe this is microfluidics, a technology that's been around for many decades, and if the history of consumer tech is anything to go by, it'll be a phrase plastered across every CPU cooler within a couple of years (though not actually do anything).\n\nThis might all just seem like Microsoft is cutting a few grooves into the chip and having water to flow through it, but it's far more complicated than that. For a start, the channels themselves are no wider than a human hair, and they're not just simple lines either. Microsoft employed the services of Swiss firm Corintis, which used AI to determine the best pattern for maximum heat transfer.\n\n(Image credit: Microsoft)\n\nThe end result is a network of microchannels that genuinely look organic, though at first glance, you'd be forgiven for thinking the complex patterns were just manufacturing defects. It certainly looks super cool (pun very much intended).\n\nMicrosoft claims the tech is up to three times more effective at removing heat from a massive AI GPU than a traditional cold plate (aka waterblock), citing a 65% reduction in the maximum temperature rise of the silicon.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nSince all the coolant transfer apparatus doesn't need to be right on top of the microchannels, the system can also be applied to stacked chips, with each one etched before mounting. This way, each die within the stack is cooled individually, meaning they can operate closer to their maximum specifications than with a normal cold plate.\n\nTake AMD's X3D processors, for example. These all have one stacked chip underneath the heatsink: a Core Complex Die (CCD) bonded to a 3D V-Cache die. Each one acts as a thermal barrier to the other, though the CCD does generate much more heat than the cache die. If these could be both cooled via microfluidics, you'd be able to operate them both at higher clock speeds.\n\nOf course, such complex tech isn't cheap to develop or implement, and the likelihood of it ever appearing at the consumer level is very slim. But I wouldn't be surprised if somebody takes an RTX 5090, rips off the heatsink, and swaps it for a homebrewed microfluidic cooler.\n\nThere again, if ramping up power consumption is the only way AMD, Intel, and Nvidia can keep improving chip performance, perhaps we might see etched processors and direct-die cooling being standard fare in our gaming PCs. After all, it wasn't that long ago when heatpipes and vapour chambers were phrases never to be uttered by a PC component manufacturer, but now they're in coolers of every kind.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/cooling/microsoft-is-resorting-to-laser-etching-ai-designed-cooling-channels-directly-into-data-center-chips-to-tame-their-massive-heat/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "AMD ROCm 6.4.4 Brings PyTorch Support On Windows For Radeon 9000, Radeon 7000 GPUs, & Ryzen AI APUs",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/amd-rocm-6-4-4-pytorch-support-windows-radeon-9000-radeon-7000-gpus-ryzen-ai-apus/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Canadian A.I. Startup Cohere Reaches $7B Valuation After Raising Another $100M",
      "content": "Cohere, the Toronto-based A.I. startup, is riding a surge of investor interest. The company announced today (Sept. 24) that its valuation has climbed to $7 billion following a fresh $100 million capital injection. The new funding comes from the Business Development Bank of Canada and Nexxus Capital Management. It’s part of Cohere’s $500 million round in August, which was led by Radical Ventures and Ionia Capital and saw the participation of Nvidia, AMD and Salesforce.\n\nSign Up For Our Daily Newsletter Sign Up Thank you for signing up! By clicking submit, you agree to our <a href=\"http://observermedia.com/terms\">terms of service</a> and acknowledge we may use your information to send you emails, product samples, and promotions on this website and other properties. You can opt out anytime. See all of our newsletters\n\nFounded in 2019 by former Google researchers Aidan Gomez, Ivan Zhang and Nick Frosst, Cohere has carved out a niche by focusing exclusively on serving companies and governments. It exclusively designs A.I. products for the enterprise market and has avoided pursuing consumer-first tools like OpenAI’s ChatGPT.\n\n“We believe that Cohere’s A.I. solutions are meeting an ignored demand in the market for technology that truly improves the efficiency of business and governments, while keeping full control of their data in their own hands,” said Francois Chadwick, Cohere’s chief financial officer, in a statement. The company’s sustained investor demand represents “a big endorsement of our momentum deploying secure and sovereign A.I. for the enterprise,” he added.\n\nCohere said the new funding will help scale the adoption of its products globally across both public and private sectors. Earlier this year, the startup launched its latest model family, the Command A series, which includes systems for reasoning, machine translation and visual data. Its agentic A.I. platform, North, is designed to handle sensitive information for regulated industries and governments.\n\nNorth users include AMD, which today announced plans to integrate the platform across its enterprise portfolio. Under an expanded partnership, Cohere’s products will also be powered by AMD’s Instinct GPUs.\n\nOther major customers include Fujitsu, Bell and the Royal Bank of Canada. The startup has nearly tripled its annualized revenue this year, from $35 million in March to more than $100 million in May. Growth is also being fueled by government demand: last month, Cohere signed a non-binding deal with Canada’s federal government to integrate its technology into public service operations.",
      "source": "Observer",
      "url": "https://observer.com/2025/09/canadian-ai-cohere-7b-valuation/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Kodiak Sciences (NASDAQ:KOD) Coverage Initiated by Analysts at Jefferies Financial Group",
      "content": "Equities research analysts at Jefferies Financial Group initiated coverage on shares of Kodiak Sciences (NASDAQ:KOD – Get Free Report) in a note issued to investors on Monday, Marketbeat reports. The firm set a “buy” rating and a $15.00 price target on the stock. Jefferies Financial Group’s price objective suggests a potential upside of 9.33% from the stock’s current price.\n\nOther analysts have also recently issued research reports about the stock. HC Wainwright increased their price target on shares of Kodiak Sciences from $3.00 to $5.00 and gave the stock a “neutral” rating in a research report on Monday, August 18th. Barclays lifted their price target on shares of Kodiak Sciences from $4.00 to $7.00 and gave the stock an “underweight” rating in a research note on Thursday, August 14th. Finally, JPMorgan Chase & Co. upgraded shares of Kodiak Sciences from an “underweight” rating to a “neutral” rating and set a $15.00 price objective on the stock in a report on Thursday, August 14th. One research analyst has rated the stock with a Buy rating, two have issued a Hold rating and one has assigned a Sell rating to the company. Based on data from MarketBeat, the stock currently has a consensus rating of “Hold” and an average price target of $10.50.\n\nGet Kodiak Sciences alerts:\n\nView Our Latest Research Report on KOD\n\nKodiak Sciences Stock Performance\n\nShares of KOD opened at $13.72 on Monday. The stock has a market capitalization of $724.69 million, a PE ratio of -3.61 and a beta of 2.45. Kodiak Sciences has a 1 year low of $1.92 and a 1 year high of $16.30. The company’s 50-day simple moving average is $8.78 and its 200-day simple moving average is $5.36.\n\nKodiak Sciences (NASDAQ:KOD – Get Free Report) last issued its quarterly earnings results on Wednesday, August 13th. The company reported ($1.03) earnings per share (EPS) for the quarter, missing the consensus estimate of ($1.01) by ($0.02). On average, sell-side analysts predict that Kodiak Sciences will post -3.45 earnings per share for the current year.\n\nHedge Funds Weigh In On Kodiak Sciences\n\nHedge funds have recently added to or reduced their stakes in the stock. Acadian Asset Management LLC increased its stake in Kodiak Sciences by 27.0% in the first quarter. Acadian Asset Management LLC now owns 1,946,134 shares of the company’s stock valued at $5,454,000 after purchasing an additional 413,821 shares during the last quarter. Jacobs Levy Equity Management Inc. increased its stake in Kodiak Sciences by 90.1% in the first quarter. Jacobs Levy Equity Management Inc. now owns 685,198 shares of the company’s stock valued at $1,922,000 after purchasing an additional 324,722 shares during the last quarter. Nuveen LLC purchased a new position in Kodiak Sciences in the first quarter valued at approximately $392,000. Adage Capital Partners GP L.L.C. increased its stake in Kodiak Sciences by 16.3% in the first quarter. Adage Capital Partners GP L.L.C. now owns 1,325,707 shares of the company’s stock valued at $3,719,000 after purchasing an additional 186,180 shares during the last quarter. Finally, GSA Capital Partners LLP increased its stake in Kodiak Sciences by 163.6% in the first quarter. GSA Capital Partners LLP now owns 205,833 shares of the company’s stock valued at $577,000 after purchasing an additional 127,748 shares during the last quarter. 89.06% of the stock is currently owned by hedge funds and other institutional investors.\n\nKodiak Sciences Company Profile\n\n(Get Free Report)\n\nKodiak Sciences Inc, a clinical stage biopharmaceutical company, researches, develops, and commercializes therapeutics to treat retinal diseases. Its lead product candidate is tarcocimab tedromer (KSI-301), an anti-vascular endothelial growth factor antibody biopolymer that is in Phase IIb/III clinical study to treat wet age-related macular degeneration (AMD), as well as Phase III clinical study for the treatment of diabetic macular edema, naïve macular edema due to retinal vein occlusion, and non-proliferative diabetic retinopathy.\n\nFeatured Articles\n\nReceive News & Ratings for Kodiak Sciences Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Kodiak Sciences and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/24/kodiak-sciences-nasdaqkod-coverage-initiated-by-analysts-at-jefferies-financial-group/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Modular raises $250M to simplify AI deployment across hardware",
      "content": null,
      "source": "SiliconANGLE News",
      "url": "https://siliconangle.com/2025/09/24/modular-raises-250m-simplify-ai-deployment-across-hardware/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Huawei Connect 2025: Building AI Infrastructure In A Sanctioned World",
      "content": null,
      "source": "Forrester.com",
      "url": "https://www.forrester.com/?p=275738",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "AMD Expands Cohere Partnership To Power Enterprise AI On Instinct Chips",
      "content": "Advanced Micro Devices (NASDAQ:AMD) expanded its global partnership with enterprise artificial intelligence firm Cohere on Wednesday.\n\nUnder the new agreement, Cohere will make its full suite of enterprise AI products—including Command A, Command A Vision, Command A Translate, and North—available on AMD’s Instinct graphics processing unit (GPU)-powered infrastructure.\n\nThe move gives enterprises and sovereign AI initiatives in Canada and worldwide greater flexibility to scale their AI deployments while meeting performance, security, and cost-efficiency targets.\n\nAlso Read: AMD Hits AI Speed Bump—Customers Aren’t Buying (Yet)\n\nAMD also said it will adopt Cohere’s North platform for its internal engineering and enterprise workloads, making Cohere’s AI technology a core part of its operations.\n\nExecutives from both companies emphasized that the combination of AMD’s high-performance, energy-efficient infrastructure with Cohere’s secure AI models provides an attractive option for governments and enterprises pursuing sovereign AI strategies that comply with national data and security requirements.\n\nAMD stock gained over 33% year-to-date, topping the Nasdaq 100 index’s 17% returns as its data center and AI products gain traction.\n\nThe announcement builds on AMD and Cohere’s prior work to optimize large language models for AMD Instinct GPUs designed for enterprise deployments.\n\nWith Cohere’s emphasis on privacy and AMD’s strength in hardware efficiency, the collaboration aims to deliver trusted AI systems.\n\nAMD Price Action: Advanced Micro Devices shares were up 1.34% at $163.04 at the time of publication on Wednesday. The stock is trading within its 52-week range of $76.48 to $186.65, according to Benzinga Pro data.\n\nRead Next:\n\nPhoto via Shutterstock\n\nUp Next: Transform your trading with Benzinga Edge's one-of-a-kind market trade ideas and tools. Click now to access unique insights that can set you ahead in today's competitive market.\n\nGet the latest stock analysis from Benzinga?\n\nThis article AMD Expands Cohere Partnership To Power Enterprise AI On Instinct Chips originally appeared on Benzinga.com\n\n© 2025 Benzinga.com. Benzinga does not provide investment advice. All rights reserved.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/amd-expands-cohere-partnership-power-140315649.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Laptop vs. Stationary Pc: What Is Best for The Home Office?",
      "content": "The morning commute has become a short walk down the hallway for millions of professionals worldwide. Remote work, once considered a temporary solution, has fundamentally transformed how we approach our professional lives. This shift has placed unprecedented demands on our home computing setups, forcing many to reconsider whether their trusty laptop or aging desktop can meet the challenges of full-time remote work.\n\nThe decision between a laptop and a stationary PC for your home office goes beyond simple preference. Each option brings distinct advantages and limitations that can significantly impact productivity, comfort, and work quality. Understanding these differences becomes essential when your living space doubles as your workplace.\n\nThe Case for Laptop Flexibility\n\nLaptops have emerged as the Swiss Army knives of remote work. Their portability transforms any corner of your home into a potential workspace, from the kitchen table during breakfast to the comfort of your couch in the evening. This flexibility proves invaluable when household dynamics demand adaptability, whether you’re avoiding renovation noise or seeking better natural light throughout the day.\n\nModern laptops pack impressive processing power into remarkably slim profiles. Current generation processors from Intel and AMD deliver performance that rivals many desktop configurations, particularly for standard office tasks like video conferencing, document processing, and web-based applications.\n\nFor professionals who split time between home and occasional office visits, or those who travel regularly, a laptop maintains consistency across different work environments. The ability to work from virtually anywhere has become particularly valuable, whether you’re collaborating at a coffee shop, catching up on emails during lunch, or even taking a quick break to play at an online casino during your downtime, all from the same device you use for professional tasks.\n\nDesktop Dominance in Performance\n\nStationary PCs continue to reign supreme when raw performance matters most. The freedom from size and thermal constraints allows desktop systems to accommodate more powerful processors, dedicated graphics cards, and extensive cooling solutions. Video editors, software developers, and data analysts often find that desktop systems handle resource-intensive tasks with greater efficiency and stability.\n\nCustomization represents another significant advantage of desktop computing. Components can be individually selected, upgraded, or replaced as needs evolve or technology advances. A graphics card upgrade might extend a desktop’s useful life by several years, while laptop users typically face the choice of complete replacement when performance falls behind requirements.\n\nThe ergonomic benefits of desktop setups deserve serious consideration. Full-sized mechanical keyboards , precision mice, and adjustable monitor stands promote better posture and reduce strain during extended work sessions. Multiple large displays, easily supported by desktop systems, enhance multitasking capabilities and reduce the constant window switching that hampers productivity on smaller screens.\n\nFinancial Considerations Beyond Initial Cost\n\nComparisons of laptop and desktop prices reveal interesting patterns. Entry-level desktops generally offer superior specifications for the same investment as comparable laptops. A thousand-dollar desktop typically features faster processors, more storage, and superior graphics capabilities compared to a laptop at the same price point.\n\nLong-term costs tell a different story. Desktop systems, with their modular nature, allow incremental upgrades that extend operational lifespan. Replacing a failing hard drive or adding memory costs a fraction of purchasing a new system. Laptop repairs, conversely, often approach or exceed the value of the device itself, particularly for older models where parts become scarce.\n\nMaking the Right Choice\n\nThe optimal choice between a laptop and a desktop ultimately depends on individual work patterns and priorities. Creative professionals handling large files or running demanding applications often benefit from desktop power and expandability. Writers, consultants, and administrative professionals might find laptop portability aligns better with their workflow needs.\n\nFuture flexibility matters too. Remote work situations evolve, and what works today might prove limiting tomorrow. Some professionals find success with hybrid approaches, using powerful desktops for intensive work while maintaining lightweight laptops for meetings and mobile tasks. Others invest in high-end laptops with docking stations, achieving desktop-like functionality when needed while preserving portability options.",
      "source": "Ahouseinthehills.com",
      "url": "https://ahouseinthehills.com/laptop-vs-stationary-pc-what-is-best-for-the-home-office/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "High-End Intel Arc GPUs See Another Lifeline as Intel Hires More Engineers",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/high-end-intel-arc-gpus-see-another-lifeline-as-intel-hires-more-engineers/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Watch These Micron Stock Price Levels After Memory Chip Maker Reports Strong Earnings",
      "content": "Key Takeaways Micron shares were little changed in premarket trading Wednesday after the memory chip maker posted better-than-expected quarterly results and issued a rosy forecast amid surging AI-related demand.\n\nDuring Wednesday’s trading session, investors should watch out for a potential breakout above a recently formed pennant pattern, a move that would indicate a continuation of the stock's strong uptrend.\n\nBars pattern analysis projects a potential upside target on Micron's chart around $240, while key support levels sit near $155 and $129.\n\nMicron (MU) shares were little changed in premarket trading Wednesday after the memory chip maker posted better-than-expected quarterly results and issued a rosy forecast amid surging AI-related demand.\n\nThe company said late Tuesday it expects to generate fiscal first-quarter revenue of $12.20 billion to $12.80 billion. The midpoint of that range comes in well ahead of the $11.94 billion expected by analysts, with the guidance driven by booming demand for the company’s high-bandwidth memory chips and favorable pricing dynamics.\n\nHeading into the earnings report, the Nvidia (NVDA) and Advanced Micro Devices (AMD) partner's shares had nearly doubled since the start of the year and surged 40% in September. The gains have been fueled by customers investing billions in AI chips to build data centers tasked with powering increasingly memory-intensive applications. The stock was down 0.2% at around $166 in recent premarket trading.\n\nBelow, we use technical analysis to identify important post-earnings price levels worth watching out for.\n\nPennant Pattern in Focus\n\nAfter finding support near the 50-day moving average, Micron shares trended sharply higher before consolidating in a pennant pattern over the past week.\n\nWhile this month’s strong uptrend has coincided with the relative strength index crossing into overbought territory, the indicator remains below its June peak, signaling that the stock has further room to climb.\n\nDuring Wednesday’s trading session, it’s worth watching out for a breakout above the pennant, a move that would indicate a continuation of the recent bullish move.\n\nLet’s turn to Micron’s chart to forecast an upside price target and also identify important support levels amid the possibility for earnings-related volatility.\n\nChart-Based Upside Price Target\n\nIf a post-earnings breakout move occurs, investors can use bars pattern analysis to project an upside target.\n\nWhen applying the technique to Micron’s chart, we take the price bars comprising the strong move higher this month and reposition them from the pennant pattern’s top trendline. This forecasts a target of around $240, 44% above Tuesday’s closing price.\n\nWe selected this earlier trend to predict how a continuation move higher may play out on the chart if the stock has a similar bullish upward leg.\n\nImportant Support Levels Worth Monitoring\n\nDuring retracements in the stock, investors should initially keep a close eye on the $155 level. This area on the chart could provide support near the base of the pennant pattern and a brief pause in the stock’s strong uptrend earlier this month.\n\nFinally, selling below this level could spark a fall toward $129. Investors may seek to accumulate Micron shares in this location near the June and August peaks, which currently sit just above the upward sloping 50-day MA.\n\nThe comments, opinions, and analyses expressed on Investopedia are for informational purposes only. Read our warranty and liability disclaimer for more info.\n\nAs of the date this article was written, the author does not own any of the above securities.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/watch-these-micron-stock-price-levels-after-memory-chip-maker-reports-strong-earnings-11816010",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "AMD Stock Climbs on New Cohere AI Deal Supercharges Chip Momentum",
      "content": "This article first appeared on GuruFocus.\n\nSep 24 Advanced Micro Devices (NASDAQ:AMD) saw its shares rise nearly 2% Wednesday morning after unveiling a deeper collaboration with enterprise AI company Cohere. The move signals AMD's push to strengthen its position in the fast-growing artificial intelligence market.\n\nCohere, a Canadian startup specializing in enterprise large language models (LLMs) and natural language processing (NLP), will use AMD's Instinct GPUs to power its suite of AI products. Those include Command A, Command A Vision, Command A Translate, and North. This means Cohere customers gain direct access to AMD's high-performance infrastructure to run advanced AI workloads.\n\nAMD also plans to adopt Cohere's North platform into its own enterprise AI operations. By integrating the tool internally, the chipmaker aims to improve its engineering and business processes with Cohere's technology.\n\nVamsi Boppana, senior vice president of AI at AMD, said the collaboration makes Cohere's AI stack deployable on AMD Instinct infrastructure, offering organizations a way to scale AI with strong performance and efficiency.\n\nThis partnership builds on earlier efforts between the two firms to optimize Cohere's LLMs for AMD Instinct GPUs, giving AMD a stronger foothold in the enterprise AI space.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/amd-stock-climbs-cohere-ai-184859132.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Snapdragon 8 Elite Gen 5 Claims the Mobile Performance Crown",
      "content": "With all major phone launches over for 2025, it is time to see what the next year has to offer. Qualcomm just presented its top-of-the-line mobile processor for 2026 during its Snapdragon Summit keynote: The Snapdragon 8 Elite Gen 5 is expected to power the flagship phones for next year, and the company even claims it is the “world’s fastest mobile system-on-a-chip”. But how can they say that?\n\nWith MediaTek timing its 2026 flagship SoC launch right before the Snapdragon Summit, we now know the details of the two main chips powering the fastest Android phones next year—unless Samsung surprises with its rumored Exynos 2600.\n\nFor the Snapdragon 8 Elite Gen 5, Qualcomm highlights two main improvements: faster multitasking/app switching and longer gameplay sessions with better power efficiency. A welcome change after years of companies launching products that talked about AI and features not yet ready for consumers…\n\nQualcomm\n\nSnapdragon 8 Elite Gen 5 MediaTek\n\nDimensity 9500 Qualcomm\n\nSnapdragon 8 Elite Samsung\n\nExynos 2500 Google Tensor G5 MediaTek\n\nDimensity 9400 Apple A19 Pro Apple A19 Prime core 2x Oryon @ 4.6 GHz 1x ARM C1-Ultra @ 4.21 GHz 2x Oryon @ 4.32 GHz 1x Cortex-X925 @ 3.3 GHz 1x Cortex -X4 @ 3.78 GHz 1x Cortex-X925 @ 3.62 GHz 2x Apple @ 4.26 GHz 2x Apple @ 4.26 GHz Performance core 6x Oryon @ 3.62 GHz 3x ARM C1-Premium @ 3.5 GHz 4x Oryon @ 3.53 GHz 2x Cortex-A725 @ 2.75 GHZ\n\n5x Cortex-A725 @ 2.36 GHz 5x Cortex-A725 @ 3.05 GHz 3x Cortex-X4 @ 3.3 GHz Efficiency core 4x ARM C1-Pro @ 2.7 GHz 2x Cortex-A520 @ 1.8 GHz 2x Cortex-A520 @ 2.25 GHz 4x Cortex-A720 @ 2.4 GHz 4x Apple @ 2.60 GHz 4x Apple @ 2.60 GHz RAM LPDDR5x-10600\n\n4x 16-bit @ 5300 MHz (84.8 GB/s) LPDDR5x-10667\n\n4x 16-bit @ 5333 MHz (85.4 GB/s) LPDDR5x-10600\n\n4x 16-bit @ 5300 MHz (84.8 GB/s) LPDDR5x LPDDR5x LPDDR5x-10667\n\n4x 16-bit @ 5333 MHz (85.4 GB/s) LPDDR5x-9600\n\n4x 16-bit @ 4800 MHz\n\n(75.8 GB/s) LPDDR5x-8533\n\n4x 16-bit @ 4266 MHz\n\n(68.2 GB/s) GPU Adreno @ 1.2 GHz 12x ARM Mali G1-Ultra @ 1.7 GHz\n\n(5271 GFLOPs) Adreno 830 @ 1.1 GHz\n\n(3379 GFLOPs) AMD Radeon RDNA2 @ 1 GHz\n\n(4091 GFLOPs) PowerVR DXT-48-1536\n\n(1536 GFLOPs) 12x ARM Immortalis-G925 @ 1.6 GHz\n\n(4952 GFLOPs) 6x Apple GPU 5x Apple GPU 5G modem Snapdragon X85\n\n(12.5/3.7 Gbps) MediaTek Snapdragon X80\n\n(10/3.5 Gbps) Exynos\n\n(12.1/3.6 Gbps) Exynos 5400i MediaTek\n\n(7/3.5 Gbps) External Snapdragon External Snapdragon Connectivity FastConnect 7900\n\nWi-Fi 7\n\nBluetooth 6.0\n\nUWB Wi-Fi 7\n\nBluetooth 6.0 FastConnect 7900\n\nWi-Fi 7\n\nBluetooth 6.0\n\nUWB Wi-Fi 7\n\nBluetooth 5.4 Wi-Fi 7\n\nBluetooth 6.0 Wi-Fi 7\n\nBluetooth 5.4 Apple N1\n\nWi-Fi 7\n\nBluetooth 6\n\nThread Apple N1\n\nWi-Fi 7\n\nBluetooth 6\n\nThread Process node TSMC N3P TSMC N3P TSMC N3E Samsung 3GAP TSMC N3 TSMC N3E TSMC N3P TSMC N3P\n\nNew CPU for Better Performance\n\nQualcomm’s claims of best mobile performance come from its new, third-generation Oryon CPU core. The previous-generation chip already surprised us with its fast clock speeds, but the Snapdragon 8 Elite Gen 5 takes frequencies even further, clocking its two prime cores at up to 4.6 GHz, while the remaining 6 CPU cores can reach 3.62 GHz. RAM support is unchanged, offering LPDDR5x-10600, which strikes a good balance between power consumption and performance.\n\nThe company estimates a 20% performance increase, with 35% better power efficiency on the CPU alone. There is, of course, a new Adreno GPU, with 23% better graphics performance.\n\nFrom the looks of it, it seems that Qualcomm is claiming to have the “fastest mobile CPU” simply based on the fact that it clocks the new Snapdragon 8 Elite Gen 5 higher than its competitors. Both MediaTek and Apple reach 4.2 GHz on their recent premium mobile chips, which are lower-clocked than the first-generation Snapdragon 8 Elite.\n\nThe new chip is expected to be used by all major phone brands. / © Qualcomm\n\nBetter photos and videos\n\nThe image processor on the Snapdragon 8 Elite Gen 5 boasts a 4x improvement in dynamic range, promising better low-light photography and more realistic colors. For content creators, Qualcomm included support for the Advanced Professional Video (APV) format, which is roughly Android’s answer to Apple’s ProRes codec. In practice, APV offers better image quality video with better support for processing in the popular DaVinci Resolve video editor, for example.\n\nQualcomm also announced a partnership with the video specialists at ArcSoft to integrate AI features into video processing, exclusively for the new Snapdragon. It aims to achieve better color reproduction, contrast, and shadow detail, mirroring the evolution of computational photography for video recording. It remains to be seen if this new feature will require special work from phone makers or will be automatically integrated into all Snapdragon 8 Elite Gen 5 phones.\n\nFaster Snapdragon 5G\n\nThe integrated Snapdragon X85 modem was also upgraded, after a few generations with only small upgrades. Cellular connections on the Snapdragon 8 Elite Gen 5 can reach up to 12.5 Gbps (compared to 10 in the previous model), and uploads also got a small upgrade from 3.5 to 3.7 Gbps. Of course, those numbers are for theoretical uplink/downlink, and real-world numbers will be much lower.\n\nSupport for other wireless standards remains the same as in the original Snapdragon 8 Elite, with the FastConnect 7900 core offering Wi-Fi 7, Bluetooth 6.0, and Ultra-Wide Band (UWB).\n\n“Coming soon”\n\nQualcomm announced that phones powered by the new Snapdragon 8 Elite Gen 5 will be “launched in the coming days”. The list of brands that will offer phones with the new chip includes basically everyone: Asus ROG, Honor, Oppo/OnePlus, Realme, Samsung, Sony, Vivo/Iqoo, Xiaomi/Redmi/Poco, and ZTE/Nubia/RedMagic.",
      "source": "Nextpit.com",
      "url": "https://www.nextpit.com/news/snapdragon-8-elite-gen-5-mobile-processor-launch-specifications",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Only $314 right now! This Ryzen mini PC runs Windows 11 like butter",
      "content": "If you’re tired of your sluggish PC and want to upgrade but don’t have the funds for a well-specced laptop or desktop, then what you need is a mini PC like this Acemagician Kron K1. On top of offering solid performance, it’s extremely affordable now that it’s on sale for just $314.10 (was $419). That’s with this Prime-exclusive discount which you can score just by signing up for a 30-day free trial of Prime. (And why wouldn’t you? With Prime Big Deal Days coming in early October, you can also use that free trial to score superb deals during that sales event!)\n\nThe value of this mini PC is hard to overstate. For starters, it packs an AMD Ryzen 7 5825U processor that’s only three years old and still fast enough to handle modern apps with responsive smoothness. Throw in the 32GB of RAM and you have a lovely combo that won’t get bogged down by Windows 11 or excessive browser tabs. The 1TB SSD is a nice cherry on top in this price range. It’s the perfect home office PC.\n\nBut it gets even better when you realize it can support up to three 4K@60Hz external monitors via its HDMI, DisplayPort, and USB-C video connections. External drives and peripherals are also no problem thanks to a whopping six fast USB-A ports, and it’s all rounded out by an Ethernet port, 3.5mm audio, Wi-Fi 6, and Bluetooth 5.2.\n\nThis is frankly an insane price for a machine of this caliber, so don’t pass up this chance to get the Acemagician Kron K1 for only $314.10. Remember you’ll need a Prime membership for this exclusive discount (sign up for a free 30-day Prime trial) and be sure to clip the on-page coupon to snag that extra $30 off and get this extra-low price.\n\nSave 25% on this excellent home mini PC that runs Windows 11 like butter",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2920860/only-314-right-now-this-ryzen-mini-pc-runs-windows-11-like-butter.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Snapdragon X2 Elite Promises the Fastest and Most Efficient Windows CPUs",
      "content": "Qualcomm just announced the successor to its Snapdragon X Windows PC processors at its annual Snapdragon Summit. The new Snapdragon X2 Elite chips are not only faster than the previous generation, but Qualcomm claims they are the “Fastest and Most Efficient Processors for Windows PCs”. Can they really beat Intel and AMD at their own game?\n\nAfter years of trying to make Windows PCs with ARM chips a reality, the Snapdragon X Elite family finally reached the mainstream in 2024, with laptops from all major PC brands, both for consumer and enterprise use. Not only that, in combination with Windows 11, the new chips finally brought good compatibility with existing apps, including ARM versions of some of the most popular software.\n\nSnapdragon X2 Elite Snapdragon X Elite Snapdragon X Plus Apple M4 Max Apple M4 Performance core 12x Oryon @ 4.4 GHz 12x Oryon @ 3.8 GHz 10x Oryon @ 3.4 GHz 12x custom @ 4.51 GHz 4x custom @ 4.40 GHz Efficiency core 6x Oryon @ 3.6 GHz - - 4x custom @ 2.75 GHz 6x custom @ 2.85 GHz RAM LPDDR5x-9523\n\n12x 16-bit @ 4761 MHz\n\n(228 GB/s) LPDDR5x-8448\n\n8x 16-bit @ 4224 MHz\n\n(135 GB/s) LPDDR5x-8448\n\n8x 16-bit @ 4224 MHz\n\n(135 GB/s) LPDDR5x-8533\n\n32x 16-bit @ 4266 MHz\n\n(546 GB/s) LPDDR5x-7500\n\n8x 16-bit @ 3750 MHz\n\n(120 GB/s) GPU \"Adreno\" @ 1.85 GHz\n\nDirectX 12 \"Adreno\"\n\nDirectX 12\n\n(4.6 TFLOPS) \"Adreno\"\n\nDirectX 12\n\n(3.8 TFLOPS) 40x Apple custom GPU\n\n\n\n(17 TFLOPS) 10x Apple custom GPU\n\n\n\n(4.26 TFLOPS) Cellular modem 5G (sub-6GHz+mmWave)\n\n(Snapdragon X75) 5G (sub-6GHz+mmWave)\n\n(Snapdragon X65) 5G (sub-6GHz+mmWave)\n\n(Snapdragon X65) n/a n/a Connectivity Wi-Fi 7\n\nBluetooth 5.4\n\n(FastConnect 7800) Wi-Fi 7\n\nBluetooth 5.4\n\n(FastConnect 7800) Wi-Fi 7\n\nBluetooth 5.4\n\n(FastConnect 7800) Wi-Fi 6E\n\nBluetooth 5.3 Wi-Fi 6E\n\nBluetooth 5.3 Process node TSMC N3E\n\n(\"3 nm\") TSMC N4\n\n(\"4 nm\") TSMC N4\n\n(\"4 nm\") TSMC N3E\n\n(\"3 nm\") TSMC N3E\n\n(\"3 nm\")\n\n5.0 GHz ARM cores\n\nWith the Snapdragon X2 Elite, Qualcomm promises even better performance, with up to 18 cores in its largest configuration. The 3rd generation custom Oryon CPU cores have a multi-core maximum speed of 4.4 GHz, but can be boosted to 5.0 GHz on two cores. The X2 Elite also includes lower clocked efficiency cores for less demanding tasks to save energy, and those CPU cores can run at up to 3.6 GHz.\n\nAccording to Qualcomm, the new top-of-the-line Snapdragon X2 Elite Extreme is 2.3x superior in performance per watt when compared to the first-generation chip. And against its X86 rivals, the company claims to be 75% faster when compared at the same power consumption.\n\nQualcomm Snapdragon X2 Elite CPU Overview / © Qualcomm\n\nPart of the performance increase is thanks to the high clock speeds, enabled by using TSMC’s 3nm process. But under the hood, the Snapdragon X2 Elite Extreme supports faster memory access, which should result in better multitasking performance and faster loading of apps or AI models.\n\nConnectivity on the go\n\nOne area in which Qualcomm holds a significant advantage compared not only to Intel and AMD but also Apple (for now, at least) is wireless connectivity. The Snapdragon X2 Elite family supports the Snapdragon X75 5G modem for connections at up to 10 Gbps (with 3.5 Gbps uplink). It also includes the Fastconnect 7800 core for Wi-Fi 7 and Bluetooth 5.4 support (no BT6 here).\n\nPrepare to see this logo on many laptops in 2026. / © Qualcomm\n\nSnapdragon X2 Elite availability\n\nQualcomm expects that the first laptops powered by the new Snapdragon X2 Elite chips will reach the market in the first half of 2026. Different from its mobile counterpart, there is no list of brands launching PCs powered by the X2 Elite, but we expect to learn more at CES 2026.",
      "source": "Nextpit.com",
      "url": "https://www.nextpit.com/news/qualcomm-snapdragon-x2-elite-launch-specifications",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Chromebooks vs. PC: The Differences Between Chrome OS and Windows",
      "content": "Chromebooks have been around for almost 15 years, and since their launch, they've made some noble attempts to evolve into something beyond just a super cheap laptop for students. It's been a difficult image for Google to shake, despite its successes in turning Android into a more premium brand over the years.\n\nHaving tested the best Chromebooks and Windows laptops across the spectrum in price, I'm constantly evaluating where Chromebooks are today and if they're worth it, student or not. Here's everything you need to know about how they compare to Windows laptops in the market.\n\nWhat Chromebooks Can and Can’t Do\n\nOn the surface, Windows laptops and Chromebooks look quite similar. Chromebooks are laptops that come in a variety of sizes, from 13- and 16-inch clamshells to 11-inch tablets. There isn’t nearly as much variety as you’ll find in the Windows ecosystem, which includes categories like gaming laptops, but there's a surprising amount of variety in the Chromebook space. When in doubt, you’ll find the “Chrome” badge on the lid of all Chromebooks, which is the dead giveaway.\n\nSoftware is where things diverge significantly. We’re all familiar with Microsoft’s trusty Windows, but Chromebooks run on Google’s ChromeOS operating system. First announced in 2009, it represents the third primary option to Windows and macOS (outside of Linux). As it’s often been called, ChromeOS remains a glorified Chrome web browser. Everything you can do in a web browser on a MacBook or Windows laptop can be done on a Chromebook.\n\nYou can have dozens of tabs, you can access extensions, and you can use any web app you need. For many people, this represents the majority of what they do on those laptops anyway. It also has a conventional file system, an app drawer, a desktop, and a lot of the other elements you’d be familiar with coming from Windows or Mac.",
      "source": "Wired",
      "url": "https://www.wired.com/story/chromebooks-vs-windows-laptops/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "AMD Enables PyTorch on Radeon RX 7000/9000 GPUs with Windows and Linux Preview",
      "content": "AMD has rolled out a public preview of ROCm 6.4.4 that finally lets PyTorch run natively on Windows and Linux for a broad swath of its consumer silicon. The update brings official framework support to Radeon RX 9000 (RDNA 4) and RX 7000 (RDNA 3) GPUs, as well as to select Ryzen AI 300 \"Strix\" and Ryzen AI MAX \"Strix Halo\" APUs, fulfilling a promise AMD made at Computex 2025 to make ROCm more cross-platform and developer-friendly. \"At Computex this year, I shared our commitment to making ROCm a true cross-platform, developer-first stack. I said we'd bring ROCm to Radeon on Windows and Linux in the second half of 2025. I'm proud to say that today, we're delivering on that promise,\" says Andrej Zdravkovic, Senior Vice President and Chief Software Officer.For Windows users, this is a genuine quality-of-life change: no more dual-booting, convoluted workarounds, or constant reliance on cloud instances to test and run AI models locally. AMD describes the release as a foundation rather than a finished product. The preview provides native PyTorch wheels, allowing developers to prototype, benchmark, and provide feedback while AMD iterates on performance and feature coverage. The company positions this step as part of a broader effort to extend ROCm beyond the data center and into the everyday machines of creators and developers. At the same time, enterprise customers continue to get higher-scale optimizations through the ROCm 7.0 family for Instinct and EPYC platforms. If community testing is successful, users can expect more frequent updates and enhanced Windows support in the next release cycle.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341329/amd-enables-pytorch-on-radeon-rx-7000-9000-gpus-with-windows-and-linux-preview",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Up 300% in 2025, Should You Buy This Red-Hot AI Data Center Stock Here?",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/35038276/up-300-in-2025-should-you-buy-this-red-hot-ai-data-center-stock-here",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Intel eyes Apple investment to fuel revival",
      "content": "After locking in a $5 billion investment from Nvidia and another $2 billion from SoftBank, Intel reportedly wants Apple as its next major backer.\n\nApple was once a long-time customer of Intel. However, it eventually shifted to its own in-house chips after Intel failed to innovate quickly enough.\n\nIntel begs Apple for money\n\nIntel once dominated the CPU market, but the last decade tells a different story. The chipmaker has struggled to deliver meaningful breakthroughs in computing performance, while smaller rival AMD has surged ahead in both power and efficiency. As a result, longtime partners and vendors have begun looking elsewhere, frustrated by Intel’s stagnation.\n\nAll this has affected Intel’s bottom line, forcing the company to reduce its spending significantly. Earlier this year, it cut 15% of its workforce to save money. Even the U.S. government picked up a 10% stake in the chipmaker last month. Now, fresh after securing a $5 billion investment from Nvidia, Intel is seeking a big investment from Apple.\n\nAs Bloomberg reports, both companies are in the early stages of negotiations, with Apple not committing to anything yet. They have also discussed how they can work together more closely.\n\nGiven the strained history between the two companies, it would be interesting to see if Apple makes any investment commitment to Intel. And even if it does, there’s no chance Apple would go back to using Intel chips in its devices.\n\nIntel needs more than money to survive\n\nApple executives previously explained in detail why they moved away from Intel to Apple silicon for their products. The decision paid off, with Apple silicon-powered Macs setting a new benchmark in performance and efficiency.\n\nIntel CPUs, meanwhile, failed to keep pace with the rapid progress of Apple’s chips. The chips often face criticism for excessive power consumption and underwhelming year-over-year performance improvements. This widening gap between Intel chips and Apple silicon has only reinforced Cupertino’s decision to cut ties and chart its own roadmap.\n\nBeyond CPUs, Intel also supplied Apple with baseband chips for iPhones. However, Intel’s failure to deliver a 5G modem on schedule forced Apple to strike a multiyear licensing deal with Qualcomm (after settling a legal dispute). Following this failure, Intel sold its modem business to Apple for $1 billion and exited the baseband market entirely.\n\nEven if Intel lands an investment from Apple, it won’t be enough to end the chipmaker’s troubles. What the company needs is to spend that money wisely and get back to innovating.",
      "source": "Cult of Mac",
      "url": "https://www.cultofmac.com/news/intel-eyes-apple-investment-to-fuel-revival",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Cathie Wood Makes Trading Blitz: Buys Alibaba Stock Woth $11 Million, Dumps AMD And This AI Stock",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/950ccdddba7d4324",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Qualcomm Compares Snapdragon X2 Elite CPU Performance Against Intel & AMD, Claims Up To 44% Faster In Single, 75% Faster In Multi-Core, & 52% Faster In Graphics Tests At Same Power, Up To 5.7x Faster NPU",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/qualcomm-snapdragon-x2-elite-cpu-gpu-npu-performance-versus-intel-amd/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "How to upgrade your 'incompatible' Windows 10 PC to Windows 11 - for free today",
      "content": "BrasilNut1/iStock/Getty Images Plus\n\nFollow ZDNET: Add us as a preferred source on Google.\n\nZDNET's key takeaways\n\nMost PCs from the last 15 years can run Windows 11, even if they fail compatability.\n\nPCs sold with Windows 10 can usually upgrade after a quick registry edit.\n\nOn older or unusually configured PCs, a third-party utility gets the job done.\n\nOn Oct. 14, 2025, Microsoft will stop delivering security updates to your Windows 10 PC unless you enroll that PC in the Extended Security Updates program.\n\nIf you try to upgrade to Windows 11 on a PC that's more than five or six years old, you'll probably encounter an error message telling you -- in no uncertain terms -- that your old PC doesn't qualify because its CPU isn't on the official list of compatible processors. Microsoft has stated, forcefully, that it will not revise those requirements. You will also hit roadblocks if your PC doesn't have a Trusted Platform Module (TPM) version 2.0, or if the TPM is not enabled.\n\nAlso: How to get free Windows 10 security updates through October 2026\n\nThat might be the official policy, but -- as with everything Windows-related -- it pays to read the fine print.\n\nThose pesky restrictions prevent you from automatically upgrading to Windows 11 using Windows Update or the Windows 11 Installation Assistant. Yet, as hundreds of ZDNET readers have reported this year alone, there are documented workarounds for most PCs that were originally built for Windows 10.\n\nAlso: Can't upgrade your Windows 10 PC? You have 5 options - and 3 weeks to act\n\nOver the past few years, Microsoft has played a cat-and-mouse game with enthusiasts, adding occasional speed bumps that make it more difficult to bypass these compatibility checks. There are workarounds for most modern PCs, but some older devices, especially those built using AMD processors, might be out of luck. The instructions below take all those developments into account.\n\nThese instructions also assume that you have a PC with an x64 CPU (not ARM and not 32-bit), running a retail or OEM edition of Windows 10 (Home or Pro), and that you are signed in as an administrator on the PC you want to upgrade.\n\nWhich option should you choose?\n\nPlease don't skip over this section.\n\nThis article describes two upgrade options. To take advantage of the workaround described in option 1 below, your computer must meet all the other requirements for Windows 11.\n\nIt must be configured to start up using UEFI, not a legacy BIOS configuration.\n\nSecure Boot must be supported, although it does not need to be enabled. (But seriously, folks, you should enable Secure Boot.)\n\nA TPM must be enabled; version 1.2 is OK, but a system without any TPM or with the TPM disabled will fail. Any PC that was originally designed for Windows 10 should include a TPM 2.0.\n\nTo check these details on a PC you're considering upgrading, run the System Information utility, Msinfo32.exe, and look at the System Summary page. Pay special attention to the BIOS Mode value. If it says \"Legacy,\" you'll need to reconfigure your system to UEFI mode (and convert your system disk from MBR to GPT partitioning) before you can install Windows 11 as a normal upgrade.\n\nTo see whether your PC has a TPM enabled, run the Trusted Platform Module Management tool, Tpm.msc. If your computer includes a TPM and it's turned on, this app will display information about it. Under the TPM Manufacturer Information heading, check the specification version to confirm that it is 2.0. If there's no TPM, or if the TPM is disabled in firmware settings, you'll see a message that says \"Compatible TPM cannot be found.\"\n\nIf you're unable (or unwilling) to change from Legacy BIOS to UEFI, or if you have an older PC that doesn't have a TPM option at all, you'll need to use the second option, which takes advantage of an undocumented hack that allows you to bypass the compatibility checks and complete the upgrade. Skip to the Option 2 section of this post for details on how to use the free Rufus utility to perform this upgrade.\n\nFinally, note that Microsoft added a new set of restrictions as part of the Windows 11 version 24H2 update. These changes require a CPU that supports specific instructions -- SSE4.2 and PopCnt. Most PCs with Intel CPUs from 2009 or later will meet this standard. AMD CPUs from 2013 or later should also meet these requirements. But it is impossible to upgrade to Windows 11 version 24H2 on a PC that was built in 2008 or earlier. For details, see \"Microsoft blocked your Windows 11 upgrade? This trusty tool can (probably) fix that.\"\n\nAlso: Microsoft said these 400 readers couldn't upgrade to Windows 11. They did it anyway\n\nIf you plan to perform a clean installation of Windows 11, you can boot from installation media and run Windows Setup. That option skips the CPU compatibility check completely (but still requires a TPM and Secure Boot support). After the installation completes, you'll need to reinstall all your apps, restore your data files, and tweak settings to personalize your system preferences.\n\nWant to avoid all that hassle? Choose the option that's appropriate for your hardware.\n\nOption 1: Use this simple registry edit\n\nWith this registry edit, you can bypass CPU checks and accept any TPM version. Please be aware that this option requires that you run the Setup program from within your current Windows installation. You can't boot from a USB flash drive and install Windows 11 this way.\n\nThis process requires four steps.\n\n1. Change one key in the Windows registry You need to make one small change to the Windows registry. For more than three years, this change was documented at Microsoft's support website, but the company removed those instructions in December 2024. (Here's an archived version of that support article.) This change tells the Windows 11 Setup program to skip the check for compatible CPUs and to allow installation on a PC with an older TPM (version 1.2). The usual warnings apply when working with the registry; I recommend you make a complete backup before proceeding. Open Registry Editor (Regedit.exe) and navigate to the following key: HKEY_LOCAL_MACHINE\\SYSTEM\\Setup\\MoSetup If the MoSetup key doesn't exist, you need to create it. Right-click the node for HKEY_LOCAL_MACHINE\\SYSTEM\\Setup in the left-hand navigation pane, then choose New > Key. Name it MoSetup and press Enter. Also: Wiping your Windows laptop? Here's the simplest way to erase all personal data Select the MoSetup key and then right-click in any empty space in the pane on the right. Choose the option to create a new DWORD value. (Don't choose the QWORD option!) Replace the default name for that key by typing the text AllowUpgradesWithUnsupportedTPMOrCPU and then press Enter. Then double-click the new value and change the \"Value data\" box to 1. The result should look like this: Show more\n\nUse this registry tweak to override the Windows 11 CPU compatibility check. You must have a TPM (any version) and Secure Boot must be enabled. Screenshot by Ed Bott/ZDNET\n\nCheck for errors before proceeding -- Windows is frustratingly literal about the contents of the registry, and if you misspell the key or value name, or if you create the required value in the wrong location, your upgrade will fail. Click OK to save your change, and then restart your PC.\n\n2. Download the Windows 11 ISO On the PC you want to upgrade, go to the Windows 11 Download page (aka.ms/DownloadWindows11) and choose the option at the bottom of the page, \"Download Windows 11 Disk Image (ISO) for x64 devices.\" Save the ISO file in your Downloads folder. Note that this is a big file. Depending on the speed of your internet connection, the download could take a while. Also: Your complete Windows 11 upgrade guide: Everything to know - before you ditch Windows 10 For those running Windows with English (UK) as the selected language, you might run into problems during the installation process. The default download is English (United States) but you also have the option to choose English (International) when prompted for a product language. Several readers have reported that choosing the wrong language results in an upgrade that does not allow you to keep installed apps and data files. If that happens, back out of the upgrade, download the other language option, and try again. Show more\n\n3. Mount the ISO file in File Explorer After the download completes, open File Explorer and double-click the ISO file you downloaded in the previous step. Doing so mounts the file as a virtual DVD drive in its own folder, with its own drive letter. Show more\n\n4. Run Windows Setup In File Explorer, find the Setup.exe file in the virtual drive you opened in the previous step and double-click it to begin the upgrade. You'll see a stern warning about compatibility issues and the possibility that performing an upgrade will mean you are not entitled to future updates. You can safely click Accept to move past this message. (For details on what that warning message really means, see \"Is Microsoft really going to cut off security updates for your 'unsupported' Windows 11 PC?\" Spoiler: They are not going to cut off security updates.) After you click OK on that dialog box, your upgrade should proceed without any serious issues. Also: Why Windows 11 requires a TPM - and how to get around it If you're upgrading from the same edition (Home or Pro), you'll have three options: You can keep your apps, settings, and files (Full Upgrade); keep your data files but start fresh with apps and settings (Keep Data Only); or start completely fresh (Clean Install). One last piece of advice: Watch carefully at the beginning of Setup for an option labeled \"Change how setup downloads updates.\" To increase your chances of a successful upgrade, click that link and choose the \"Not right now\" option. That should allow Windows Setup to finish faster -- you'll have a chance to download those updates after the upgrade is complete. Show more\n\nIf you encounter any difficulties or if the upgrade fails, check this article for detailed advice on what to do to find and fix the problem: Windows 11 upgrade failed? These are my 4 most powerful troubleshooting secrets\n\nOption 2: Use the free Rufus utility\n\nOn older PCs without a TPM and on PCs that don't support Secure Boot and UEFI, you'll need to use an undocumented hack to bypass the compatibility checker. It is technically possible to do this manually by replacing the Appraiserres.dll file (in the Sources subfolder on the Windows 11 installer drive) with a zero-byte version and then making a series of registry edits. But it's simpler to use the free, open-source Rufus utility to create installation media (on a USB flash) drive that includes these tweaks automatically.\n\nTo get started, download Rufus version 4.6 or later. Earlier versions won't work, thanks to changes Microsoft made in October 2024 to its compatibility checking tools. For details of how the newer versions work, see \"Microsoft blocked your Windows 11 upgrade? This just-released tool can get the job done.\" In addition, be aware that using Rufus will not allow you to bypass the new restrictions on very old PCs that were introduced with Windows 11 version 24H2.\n\nIf you have a PC with a CPU that lacks support for SSE4.2 and PopCnt instructions, not even Rufus can help. (Of course, any PC that fails that test is nearly 20 years old and probably deserves to be retired.)\n\nAlso: You can still upgrade old PCs to Windows 11, even if Microsoft says no: Readers prove it\n\nTo get started, you'll need to download the Windows 11 ISO from aka.ms/DownloadWindows11. Choose the option at the bottom of the page, \"Download Windows 11 Disk Image (ISO) for x64 devices.\" Save the ISO file in the Downloads folder of your Windows system drive so you can find it easily. You'll also need a USB flash drive of at least 16 GB in size. You will reformat this drive as part of the process, so back up any data on that drive first -- and do not store the Windows 11 ISO here!\n\nDownload Rufus from the developer's site or from the Microsoft Store and run the app. In Rufus, choose the USB drive and then choose the \"Disk or ISO image\" option. Click the Select button, choose the Windows 11 ISO you downloaded earlier (hint: it's in your Downloads folder), and then click Start. In the Windows User Experience dialog, select the first checkbox to remove hardware requirements, as shown in the screenshot below. Adjust any other settings as you prefer. Click OK to accept those changes and then click Start to begin creating the bootable installation drive.\n\nBe sure to choose the top checkbox here to bypass the compatibility check for the Windows 11 upgrade. Screenshot by Ed Bott/ZDNET\n\nAfter Rufus successfully creates your installer, open that USB drive in File Explorer, and double-click Setup. Do not try to upgrade by booting from that USB drive and performing a clean install; it won't work.\n\nSeveral readers have reported that Setup failed prematurely and displayed an error message (\"An unsupported operation was attempted\") when run from media created using Windows 11 version 24H2 and the latest version of Rufus. The fix? Watch carefully at the beginning of Setup for an option labeled \"Change how setup downloads updates.\" Click that link and choose the \"Not right now\" option, as shown here. That should allow setup to continue without interruption.\n\nIf Setup quits unexpectedly with an error message, try again but choose this option insted. Screenshot by Ed Bott/ZDNET\n\nAs is the case with the other option, you'll see a warning about compatibility issues. It's a scare tactic. (For details on what the language in that warning message actually means, see \"Is Microsoft really going to cut off security updates for your 'unsupported' Windows 11 PC?\") After you click Accept on that dialog box, your upgrade should proceed without any serious issues.\n\nAlso: Consumer Reports slams Microsoft for Windows 10 mess, urges extension of free updates\n\nMy ZDNET colleague Lance Whitney has more details on the other options available with Rufus in \"How to install Windows 11 the way you want (and bypass Microsoft's restrictions).\"\n\nDid your upgrade work?\n\nIf you've tried this upgrade, I want to hear about your experience. If it worked, please share the details. If you run into snags, send me an email so we can figure out what's going wrong.\n\nBe sure to include details -- the make and model of your PC and screenshots of any error messages. If you're able to create a report using the SetupDiag utility, please include that as well -- you'll find detailed instructions in my Windows 11 upgrade troubleshooting guide. I've set up a special inbox just for this feedback: Win11Upgrade [at] realworldwindows.com.\n\nThis article was originally published on April 9, 2022, but has been updated multiple times since then to add new details and incorporate feedback from readers. It was last updated on Sept. 25, 2025.",
      "source": "ZDNet",
      "url": "https://www.zdnet.com/article/how-to-upgrade-your-incompatible-windows-10-pc-to-windows-11-for-free-today/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "ROG Xbox Ally pre-orders are almost here, Asus shares update",
      "content": "Asus has revealed that pre-orders for the ROG Xbox Ally handheld will drop today. The post does not mention the ROG Xbox Ally X so it could be that the more-powerful handheld will be available later for pre-order.\n\n4 Reviews ← exclude selected types\n\nEver since the announcement of the ROG Xbox Ally and ROG Xbox Ally X handheld, rumors about pricing and pre-orders have been circulating online. Microsoft and Asus have confirmed that both the devices will launch on October 16 but till now, there was no information on pre-orders. Turns out, they are almost here.\n\nAsus has teased on Facebook that pre-orders for the ROG Xbox Ally are “dropping soon.” There is a countdown that ends at 8 PM ET / 5 PM PT today (September 25). So, in a few hours, those who are interested in the new handhelds will be able to reserve their units and pricing will be revealed to the public. The post mentions the white ROG Xbox Ally but not the ROG Xbox Ally X so it is possible that pre-orders for the more powerful variant will start a day or two later.\n\nThe Facebook post was spotted by The Verge but it doesn’t seem to be available on Asus ROG’s US account. The Singapore account, however, does have the post in the form of a story.\n\nRumors and leaks have hinted at the pricing for the two handhelds. Last month, it was reported that the ROG Xbox Ally is priced between $500 and $600. Best Buy, however, briefly posted a $550 price tag for the lower-end model and $900 for the Xbox ROG Ally X. More recently, a UK retailer’s leaked promotional material had the non-X model listed for £500 (approx. $667 USD).\n\nRegardless, we should get official confirmation soon. The ROG Xbox Ally is powered by the AMD Ryzen Z2A and a 60Wh battery while the ROG Xbox Ally X is powered by the Ryzen Z2 Extreme with an 80Wh battery. Both come with a 7‑inch 1080p/120Hz 500‑nit display and dual USB Type‑C ports.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/ROG-Xbox-Ally-pre-orders-are-almost-here-Asus-shares-update.1124364.0.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Китай планирует, Америка реагирует",
      "content": null,
      "source": "Project Syndicate",
      "url": "https://www.project-syndicate.org/commentary/trump-reactive-industrial-policy-cannot-compare-to-china-five-year-plans-by-stephen-s-roach-2025-09/russian",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "4 key takeaways from Qualcomm’s Snapdragon Summit in Hawaii: New smartphone and laptop Chips, 6G, and Google’s PC comeback",
      "content": "At this year’s Snapdragon Summit, the story went well beyond the new processors that Qualcomm announces every year in Maui, Hawaii. It was refreshing to see how Qualcomm placed the ecosystem at the center, putting its technologies at the heart of the products that will begin reaching the market in the days and months ahead.\n\nOf course, we learned about the latest chip, the Snapdragon 8 Elite Gen 5, which will power upcoming flagship Android smartphones, as well as brand-new computing chips set to arrive in the next generation of PCs. However, it was Google’s confirmation that Android and ChromeOS will merge to create a new Operating System for computers next year that stole the limelight, and for good reason. That’s a lot to unpack, all things considered.\n\nIn case you missed out catching the livestream or you want to rewatch one of the biggest announcements from the event, here’s a refresher from the Snapdragon Summit (including my takeaways from the event)\n\nStory continues below this ad\n\nA new flagship smartphone chip\n\nQualcomm’s bread and butter remains developing mobile processors for smartphones, including a critical component of a smartphone’s inner workings: the processor, or the “brain” of the phone – along with associated technologies like the modem. After all, these are the biggest revenue generators for the San Diego-based company. As expected at the Snapdragon Summit, Qualcomm unveiled the Snapdragon 8 Elite Gen 5, the processor that will power upcoming Android flagship phones, with Samsung, Xiaomi, Honor, and OnePlus leading the first wave of devices built around the new chip.\n\nQualcomm claims its Snapdragon 8 Elite Gen 5 is the “fastest mobile CPU in the world,” boasting a record clock speed of 4.6 GHz (compared to Apple’s A19 Pro, which powers the iPhone 17 Pro Max, at 4.26 GHz). The company touts significant performance gains, including a 23 per cent faster GPU and a 37 per cent faster NPU. Whether these claims hold up will be determined once review units arrive, but a faster GPU could have an especially big impact on mobile gaming.\n\nA Qualcomm executive presents performance benchmarks for creator tools at the Snapdragon Summit 2025, highlighting up to 64 per cent faster CPU performance and 45 per cent faster photo effects with the new Snapdragon X2 Elite chip. (Image: Anuj Bhatia/The Indian Express) A Qualcomm executive presents performance benchmarks for creator tools at the Snapdragon Summit 2025, highlighting up to 64 per cent faster CPU performance and 45 per cent faster photo effects with the new Snapdragon X2 Elite chip. (Image: Anuj Bhatia/The Indian Express)\n\nLike Apple, Qualcomm also claims its new mobile processor brings speed improvements to a phone’s performance. However, there are three particularly interesting aspects of the new chip that haven’t been highlighted. One of them is Qualcomm’s Personal Scribe – an agentic AI assistant powered by the new Sensing Hub that learns your habits to make recommendations and act on your behalf. Deeply integrated at the chip level, the assistant delivers a highly personalised experience. It will be interesting to see how smartphone brands implement this feature, which learns about your behaviour and operates across your apps and services.\n\nAnother highlight of the new Snapdragon chip is how Qualcomm is going after the creator market with an advanced video recording feature in the Professional Video Codec, bringing crisp HDR footage that’s easier to edit without quality loss. While each smartphone maker does a lot of finetuning to the camera, this new chip-level feature offers a recording feature that’s aimed at content creators. The “near-lossless” codec, created in partnership with Samsung, is an answer to Apple’s ProRes format.\n\nStory continues below this ad\n\nThe new mobile chip also includes Snapdragon Audio Sense, a microphone technology with wind noise rejection, audio zoom, and HDR audio, enabling 24-bit audio recording in any environment without needing external microphones.\n\nAlso Read | As Qualcomm unveils new AI Chips for smartphones and laptops, CEO Cristiano Amon sets course to make company an ecosystem player\n\nWhile the Snapdragon 8 Elite Gen 5 remains a flagship processor, Qualcomm pulled a surprise by announcing a second premium-tier processor. Details are limited for now, but the Snapdragon 8 Gen 5 will sit below the flagship model. The strategy mirrors Apple’s two-chip iPhone approach: offering two mobile chips, with the latter expanding on the premium smartphone experience at a slightly lower price.\n\nNew chips like these are critical for a company like Qualcomm to stay competitive. Although competition from MediaTek and Apple is getting stiff, smartphones still remain the de facto centerpiece of the incumbent ecosystem. Qualcomm may already be talking about agentic AI and AI assistants that could one day replace apps, and eventually, smartphones might no longer be central, potentially giving way to smart glasses. Truth be told, phones aren’t going anywhere, at least for now. While the longevity of smartphones is increasing and fewer consumers are willing to replace their phones every year as they used to, smartphones are not likely to be replaced by smart glasses anytime soon.\n\nBeefier computing chips, with a focus on business customers\n\nAlthough Qualcomm is still a new player in the PC market, it aims to compete with veteran players like Intel and AMD, as well as Apple, which designs its own M-series chips for Mac computers. The company’s newly announced X2 Elite and X2 Elite Extreme chips, which will appear in some of the top laptops and other PCs over the next year, are powerful, with the latter processor reaching clock speeds of up to 5 GHz. The new processors feature the third-generation Oryon CPU with up to 18 cores – six more than their predecessors. Qualcomm’s big bet with these processors is that by distributing workloads across the CPU, GPU, and NPU, power consumption will be optimized without any drop in performance.\n\nStory continues below this ad\n\nQualcomm’s X2 Elite and X2 Elite Extreme chips take on PC processors from Intel, AMD and Apple. (Image credit: Anuj Bhatia/ Qualcomm’s X2 Elite and X2 Elite Extreme chips take on PC processors from Intel, AMD and Apple. (Image credit: Anuj Bhatia/ Indian Express\n\nThese chips also lean heavily on AI, bringing multimodal content generation and agentic AI to the forefront. In fact, the X2 Elite can deliver up to 80 TOPS of AI processing, enabling the most advanced Windows-powered Copilot Plus PCs. Meanwhile, Qualcomm’s partnership with Adobe, which offers a creative suite of apps including Photoshop, Lightroom, and Premiere Pro, means laptops powered by the new chips will deliver up to 47 per cent faster performance.\n\nIn addition, Qualcomm’s new PC chips support lightning-fast 5G with speeds up to 10 Gbps, a major advantage for connectivity. The focus on PC gaming also promises faster performance and smoother graphics, allowing demanding games to run seamlessly. The big takeaway is that Qualcomm is gradually targeting enterprises and business (and even PC gamers) users with these new chips, which will power some of the best and fastest Windows laptops starting next year.\n\nQualcomm promises “pre-commercial 6G devices” will be here in three years\n\n5G is everywhere. Maybe it’s no longer talked about much, but a few years ago, it was the most buzzed-about technology. Similarly, we may start hearing a lot about 6G, the new wireless connectivity standard, in the coming months. Qualcomm says 6G is coming soon and will eventually replace 5G. You might be wondering what 6G actually means. Sure, it will be super fast and increase network speeds, but it’s expected to be very different from 5G – at least in terms of use cases.\n\nDuring the Snapdragon Summit keynote, Qualcomm CEO Cristiano Amon drew attention to 6G, the next-gen connectivity standard. (Image credit: Anuj Bhatia/Indian Express) During the Snapdragon Summit keynote, Qualcomm CEO Cristiano Amon drew attention to 6G, the next-gen connectivity standard. (Image credit: Anuj Bhatia/Indian Express)\n\nDuring the Snapdragon Summit keynote, Qualcomm CEO Cristiano Amon said, “6G is designed to be the connection between the cloud and edge devices.” What does that mean? Amon explains that it will be “a network intelligent enough to perceive sensor data.” He implies that a new level of connectivity is needed for a world where AI must process sensor data at the edge, whether from your phone or a pair of smart glasses, and then train on that data from the real world around you. Amon adds that 6G will focus on “connecting the edge and the cloud, merging not only the physical and digital, but also creating entirely new experiences.”\n\nStory continues below this ad\n\nAmon further predicted that the change is already underway. “We are ready to have pre-commercial devices as early as 2028. When that happens, we have context-aware intelligence at scale – and it’s going to happen everywhere.” Expect to hear more about 6G early next year.\n\nGoogle’s comeback into the PC market\n\nChromeOS is dead, whether Google admits it or not. Nor is Android a replacement for ChromeOS. Perhaps Google has a solution to this problem… why not merge Android and ChromeOS? Well, that’s going to happen next year. Rick Osterloh, senior vice president of platforms and devices at Google, and Android chief Samir Samant both took the stage at this week’s Snapdragon Summit in Hawaii to confirm that Android for PC is coming next year.\n\nGoogle’s Sameer Samat explains the next chapter for Android and ChromeOS. (Image credit: Anuj Bhatia/Indian Express) Google’s Sameer Samat explains the next chapter for Android and ChromeOS. (Image credit: Anuj Bhatia/Indian Express)\n\nOsterloh, who oversees both Google’s hardware and Android divisions, shared some details about the project. “We’re building together a technical foundation for our products on PCs and desktop computing systems,” he said. “This is another way we can leverage all of the great work we are doing on our AI stack, our full stack, bringing Gemini models, the Assistant, and our applications and developer community into the PC domain.”\n\nExactly how the combined OS will look is still unknown, but Qualcomm’s involvement indicates that both companies are up to something. It’s just that neither is ready to share more details.\n\nStory continues below this ad\n\n“If you think about the laptop form factor, we have had ChromeOS for a long time, and we are super committed to that platform. It’s been really successful for us, and we have learned a lot from it. We also have Android tablets that have been very successful; they are becoming more productivity-focused all the time. So the opportunity we see is how we can accelerate all the AI advancements we are doing on Android and bring them to the laptop form factor as rapidly as possible, while ensuring the laptop and the rest of the Android ecosystem work seamlessly together,” Samant said about merging Android and ChromeOS at the Snapdragon Summit.\n\n“So what we are doing is basically taking the ChromeOS experience and re-baselining the technology underneath it on Android. That combination is something we’re very excited about for next year, and we are working with partners on it, and we can’t wait.”\n\nChromeOS has long been a lightweight OS for computers and laptops. The OS has seen many changes over the years, but it has sadly never evolved to become something like Windows or macOS. However, with Google going all-in on Gemini, it may bring new experiences to the company’s big-screen OS, giving it a clear purpose in the AI-ready world.",
      "source": "The Indian Express",
      "url": "https://indianexpress.com/article/technology/tech-news-technology/4-key-takeaways-from-qualcomms-snapdragon-summit-in-hawaii-new-chips-6g-and-googles-pc-10270076/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Cathie Wood Makes Trading Blitz: Buys Alibaba Stock Worth $11 Million, Dumps AMD And This AI Stock (CORRECTED)",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/68cc56e9b05bf2f0",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Intel Seeks Investment from Apple to Bolster Turnaround Bid",
      "content": "Intel has reportedly approached Apple about securing an investment in the ailing chipmaker as part of efforts to strengthen a business that is now partially owned by the U.S. government.\n\nBloomberg reports that Intel has reached out to Apple to discuss the possibility of an investment in the struggling chipmaker. According to sources close to the matter, who wished to remain anonymous due to the private nature of the discussions, Intel is seeking to secure funding from Apple as part of its ongoing turnaround efforts, which have been bolstered by partial U.S. government ownership.\n\nThe talks between the two tech giants have also included discussions on how they can work more closely together, although the exact nature of this potential collaboration remains unclear. While the negotiations are still in the early stages and may not result in a finalized agreement, the news has already had a significant impact on Intel’s stock, which rose 6.4 percent to $31.22 on Wednesday following the initial reports.\n\nThis potential deal with Apple follows a series of investments in Intel from other major players in the tech industry. Last week, Nvidia Corp. announced a $5 billion investment in the chipmaker, with plans to work together on chips for personal computers and data centers. Additionally, SoftBank Group Corp., the Japanese tech giant looking to expand its presence in the U.S., revealed a $2 billion investment in Intel last month.\n\nBreitbart News previously reported on the Nvidia investment:\n\nThe deal is not just about capital. Nvidia and Intel have agreed to jointly develop new products for data centers and personal computing, leveraging each company’s strengths. Intel will manufacture Nvidia-custom x86 CPUs, which Nvidia will integrate into its AI infrastructure platforms. Additionally, Intel will build chip systems for Nvidia chiplets, the modular components that power next-generation PCs. This collaboration is expected to expand both companies’ ecosystems and lay the groundwork for what Nvidia CEO Jensen Huang calls “the next era of computing.”\n\nDespite these investments and the backing of the federal government, Intel still faces significant challenges in its bid to regain its former dominance in the semiconductor industry. The company has lost its long-held technological edge and market share to competitors such as AMD. Furthermore, Intel has struggled to capitalize on the growing demand for AI hardware, a market in which Nvidia has dominated.\n\nUnder the leadership of CEO Lip-Bu Tan, Intel is attempting to turn the tide and reclaim its position as a leading chipmaker. The company has pursued a strategy of becoming a chip foundry, producing semiconductors for external clients. However, securing enough customers to support its factory expansion plans has proven difficult.\n\nIntel’s turnaround began with the Trump administration taking an equity stake in the company in exchange for CHIPS act funding. As Breitbart News reported:\n\nTrump has pursued government investment in semiconductors and rare earth materials, which includes a stake in chipmaker Nvidia and MP Materials. “We should get an equity stake for our money,” Commerce Department Secretary Howard Lutnick said this week. “So we’ll deliver the money, which was already committed under the Biden administration. We’ll get equity in return for it.”\n\nRead more at Bloomberg here.\n\nLucas Nolan is a reporter for Breitbart News covering issues of free speech and online censorship.",
      "source": "Breitbart News",
      "url": "https://www.breitbart.com/tech/2025/09/25/intel-seeks-investment-from-apple-to-bolster-turnaround-bid/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Dell bets on disaggregated infrastructure to reshape private cloud for the AI era",
      "content": null,
      "source": "SiliconANGLE News",
      "url": "https://siliconangle.com/2025/09/25/ai-multi-hypervisor-environments-dellsmarterprivatecloud/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Broadcom and AMD Are Set to Share This Much of the $475 Billion AI Chip Market by 2030",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/17d0debb3b23ffc6",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "(PR) HighPoint Technologies Introduced the Rocket 7638D, Industry's First Hardware Architecture for GPU-Direct NVMe Storage",
      "content": "Revolutionary Hardware Architecture: The Rocket 7638D is the first PCIe Gen 5 switch adapter to provides the foundational hardware for a GPU-direct NVMe storage solution.\n\nDedicated Bandwidth for Maximum GPU Utilization: Our proven PCIe Switching Technology dynamically allocates 48 lanes of Gen 5 bandwidth, guaranteeing dedicated x16 pathways to both the GPU and NVMe storage. This eliminates the I/O bottleneck, ensuring your GPU is never starved for data.\n\nUncompromised CDFP-CopprLink Connectivity: Ensures reliable, high-bandwidth GPU-to-host data transfers, supporting NVIDIA's most powerful GPUs and external enclosures for flexible deployment.\n\nFlexible Dual-MCIO 8i Ports: The Rocket 7638D dual MCIO 8i ports are capable of supporting up to 16 NVMe drives for a staggering 2 Petabytes of storage. This high-density adapter is purpose-built to handle the largest AI datasets, from petabytes of scientific imaging data to vast training sets for large language models (LLMs).\n\nBroad Platform Compatibility: Works with Intel, AMD, and Arm platforms\n\nOptimized for AI Workflows: Provides a hardware platform for GPU Direct Storage (GDS), reducing CPU overhead, lowering latency, and accelerating data preprocessing.\n\nFRU (Field Replaceable Unit): VPD stored by each adapter enables service providers to easily procure replacements with the correct firmware/hardware combination.\n\nHighPoint Technologies, a leader in high-performance storage solutions, has announced the launch of the Rocket 7638D, a revolutionary PCIe Gen 5 switch adapter engineered to solve the most critical bottleneck in modern AI/ML workflows: data starvation. The adapter's groundbreaking hardware architecture provides a foundational platform for GPU-Direct NVMe storage, enabling NVIDIA GPUs to directly access massive datasets without the performance penalties of CPU bottlenecks. The Rocket 7638D is designed to help AI professionals maximize their return on investment by ensuring their GPUs are always at full utilization, accelerating model training, inference, and data preprocessing to unprecedented speeds.For decades, the path from storage to compute has been a bottleneck. Data has had to travel from an NVMe drive, through the host CPU, and into the GPU's memory—a slow, inefficient process that wastes valuable compute cycles. The Rocket 7638D shatters this conventional model. It is the first 48-lane Gen 5 PCIe switch adapter engineered with a dedicated x16 Gen 5 pathway for both an external GPU and NVMe storage from a single slot. This architecture creates a direct, peer-to-peer data channel that bypasses the host CPU entirely.The result is a transformative leap in performance. By eliminating latency and reducing CPU overhead, the Rocket 7638D ensures that precious GPU compute cycles are no longer wasted on I/O. HighPoint's innovative hardware architecture provides a direct data path that, when paired with a compatible third-party software solution, enables a full GPU Direct Storage (GDS) stack. For deep learning, this translates directly to faster epochs, reduced model training time, and a significant boost in inference throughput, providing a competitive edge for any data-intensive application.This ensures that powerful GPUs and other accelerators are not sitting idle, but are constantly processing data at their maximum potential, dramatically accelerating workflows and increasing overall system efficiency.Despite its advanced capabilities, the Rocket 7638D has been engineered to streamline installation, deployment and field service. The hardware is natively supported by all major operating system platforms, eliminating the need for additional software or complex driver installation. This plug-and-play functionality allows AI/ML, HPC, and Scientific Imaging professionals to quickly install the card and begin building a GPU-accelerated storage solution. For peace of mind, HighPoint's user-friendly MPT utility enables administrators to quickly view firmware information, monitor PCIe bus speed, and check the health of the adapter's switch chipset in real time.In essence, the Rocket 7638D is the missing link for any NVIDIA-accelerated workflow. It's innovative hardware architecture fundamentally changes the relationship between compute and storage. By unlocking the full potential of your GPU hardware and enabling the fastest possible data pipelines, the Rocket 7638D ensures your ROI is fully realized.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341324/highpoint-technologies-introduced-the-rocket-7638d-industrys-first-hardware-architecture-for-gpu-direct-nvme-storage",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Get HP’s Snapdragon touchscreen laptop with 16GB RAM for just $439",
      "content": "Snapdragon-powered laptops haven’t made a huge splash in the PC world—or here at PCWorld—perhaps because they’re just too expensive without a ton of extra functionality versus AMD or Intel machines. But what if you could get one for under $500? Such is the case with this HP refurbished model, which is on sale for $439 on eBay right now.\n\nWhen PCWorld reviewed the HP OmniBook X AI 14 last year, Mark Knapp called it “a fine laptop offering excellent battery life,” but noted that it wasn’t worth its $1,200 asking price. But now, at just over a third of that, it looks a lot more appealing. The 14-inch 2240×1400 touchscreen is excellent and the Snapdragon X Elite processor is an upgrade over most other Qualcomm-based laptops in this price range. 16GB of RAM (the lowest I’d recommend for Windows 11) and 1TB of storage are nice, too.\n\nAt 2.95 pounds, this OmniBook is on the lighter side, especially considering the 59 watt-hour battery that can outlast bigger and more powerful designs with 18 hours of video playback. (Expect less battery life for regular work, but still more than enough to get you through an untethered work day.) The only real downside I can find with the design, other than Snapdragon’s poor gaming performance, is a lack of ports—you get only two USB-C and one USB-A on this ultra-thin design.\n\nThe eBay seller is participating in the official “eBay refurbished” program and rates this laptop as “good.” That means “used,” to be frank, but the silver lining here is that it’s been refurbished by a professional shop and comes with a 1-year Allstate warranty—much better than the usual 90 days for a refurb. If that sours you on this particular deal, check out PCWorld’s roundup of the best laptops.\n\nSave 63% on this HP OmniBook X AI 14 with Snapdragon X Elite CPU",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2921218/get-hps-snapdragon-touchscreen-laptop-with-16gb-ram-for-just-439.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Global and China Electronic Rearview Mirror Industry Report 2025: Commercial Vehicle CMS Gains Traction Faster, with Some Manufacturers' Cumulative Installation Volume Exceeding 10,000 Units",
      "content": "Dublin, Sept. 25, 2025 (GLOBE NEWSWIRE) -- The \"Global and China Electronic Rearview Mirror Industry Report, 2025\" report has been added to ResearchAndMarkets.com's offering.\n\nBased on the installation location, electronic rearview mirrors can be divided into electronic interior rearview mirrors (i.e., streaming media rearview mirrors) and electronic exterior rearview mirrors (Camera Mirror System, hereinafter referred to as CMS).\n\nStreaming Media Rearview Mirrors Witness Rapid Growth, with Yuanfeng Technology Leading in Sales for Eight Consecutive Years\n\nAccording to statistics from the database, in the whole year of 2024, the installations of streaming media rearview mirrors in China's passenger car pre-installation market reached 647,000 units, a year-on-year increase of 11.5%. From January to May 2025, the installations of streaming media rearview mirrors reached 383,000 units, with a year-on-year growth of 86.2%. In terms of installation rate, from January to May 2025, that of streaming media rearview mirrors also increased, rising from 2.8% in the whole year of 2024 to 4.5%.\n\nIn terms of equipped models, from January to May 2025, there were a total of 114 passenger car models in China that were equipped with streaming media rearview mirrors and had sales volume. Among them, many models of multiple brands began to be equipped with streaming media rearview mirrors as standard. For example, the streaming media rearview mirror products of many popular models such as Xpeng P7+ / X9 are all provided by Yuanfeng Technology.\n\nIn terms of supplier share, Yuanfeng Technology has accounted for more than 55% of the market share for eight consecutive years. From January to May 2025, the market share of Yuanfeng Technology's streaming media rearview mirrors reached 59.0%, and it is expected to exceed 70% for the whole year of 2025. At present, Yuanfeng Technology's supporting customers include more than 15 domestic and foreign brands such as several leading emerging OEMs (including Xpeng), SAIC-GM, Great Wall Motor, GAC Trumpchi, and Mercedes-Benz, and it has cooperated in the mass production of more than 60 vehicle models.\n\nAt present, Yuanfeng Technology's streaming media rearview mirror has developed to the fifth generation. This product adopts an extremely narrow-bezel design, which balances ultra-high display screen brightness and extremely low system latency. Moreover, the fifth-generation product applies an AI image optimization algorithm to achieve effects such as super-sensitive noise reduction, night vision enhancement, rain and fog penetration, and super-resolution. It breaks through the image quality limit of traditional ISP image processing and realizes continuous optimization through continuous iterative learning.\n\nPassenger Car CMS Transforms from Product Access to Product Upgrade\n\nIn terms of installations, CMS is still in a stage of slow growth. In 2024, there were only 5 passenger car models that were pre-installed with CMS and had sales volume. From January to May 2025, this number increased to 10. From July 2023, when CMS was approved for installation on vehicles, to May 2025, the cumulative assembly volume of CMS for passenger cars has not yet exceeded 10,000 units.\n\nCMS has now completed the process from scratch, and will gradually move towards the path of product iteration and upgrade in the future. From the perspective of the composition of CMS products, the future product upgrade may start from three aspects:\n\nCamera: Advancing from 2MP to 5MP, or Even 8MP\n\nAs the `eyes` of the CMS system, the most fundamental requirement of the system is to see clearly and see far. The pixel of CMS cameras is upgrading from the early 1.2 - 2MP to 5MP or even 8MP.\n\nAccording to the information disclosed by OFILM, it is currently developing 8MP CMS camera. Previously, OFILM launched a 2MP CMS camera with a heating function.\n\nAnother key technical indicator of the camera is HDR. To cope with extreme light change scenarios such as tunnel entrances and exits and strong night light, HDR has advanced from 120dB to 140dB. This ensures that images of the CMS system will not be overexposed or underexposed under any lighting conditions.\n\nDisplay Screen: Developing from LCD to OLED and Mini LED\n\nThe display screen serves as the observation window for users. Users' demand for high-quality displays may drive the development of CMS display screens from LCD to OLED and Mini LED. At present, LCD is still used in some vehicle models due to its cost advantage. However, OLED has become the first choice for mid-to high-end CMS solutions because of its high contrast, wide viewing angle, and fast response time. In addition, Mini LED is also a cost-effective option. Its higher brightness and more precise local dimming capability can better suppress night glare and provide a display effect close to that of OLED.\n\nSystem Upgrade\n\nRegulations and user experience requirements have jointly promoted the improvement of system-level performance indicators. For example, regulations require that the imaging time be less than 55ms, the system latency be less than 200ms, and the minimum system frame rate be at least 30Hz (at least 15Hz under low-light conditions). All these indicator requirements are to ensure the fluency and real-time performance of the picture and avoid misjudgment by drivers due to latency or stuttering. At present, the system latency of CMS products of most manufacturers has basically been controlled within 60ms, and some manufacturers have even achieved 40ms. In addition, the system must have a complete fault detection and alarm mechanism to deal with extreme failure scenarios such as `black screen` and `picture freezing` and ensure functional safety.\n\nYuanfeng Technology's CMS has a pixel of more than 3MP. The product provides three types of display screens for selection, namely LCD, Mini LED, and OLED. Moreover, the display screen supports touch adjustment of angle, brightness, color temperature, and other parameters. The system is equipped with functional safety guarantees such as LED flicker suppression, picture delay detection, and picture freezing detection to ensure driving safety.\n\nCommercial Vehicle CMS Gains Traction Faster, with Some Manufacturers' Cumulative Installation Volume Exceeding 10,000 Units\n\nCompared with passenger cars, the advantage effect of CMS in commercial vehicles is more obvious. Taking the MirrorCam applied in Mercedes-Benz trucks as an example, according to the actual test of Mercedes-Benz trucks, heavy trucks equipped with electronic rearview mirrors can reduce fuel consumption by 1.3% compared with models with traditional rearview mirrors. Assuming that a Mercedes-Benz truck has a fuel consumption of 28 liters per 100 kilometers, with a fuel price of 7 yuan per liter and an annual driving distance of 200,000 kilometers, the use of electronic rearview mirrors can save 5,096 yuan in fuel costs per year. As leading foreign CMS manufacturers, Stoneridge and MEKRA Lang have both disclosed that their CMS products can reduce fuel consumption by about 2%.\n\nKey Topics Covered:\n\nChapter 1 Overview of the Electronic Rearview Mirror Industry\n\nDefinition of Traditional Automotive Rearview Mirror Products\n\nDefinition of Electronic Rearview Mirror Products\n\nCMS Industry Chain\n\nElectronic Interior Rearview Mirrors\n\nProduct Structure and Characteristics of Electronic Interior Rearview Mirrors\n\nSummary of Electronic Interior Rearview Mirror Manufacturers\n\nElectronic Exterior Rearview Mirrors (Camera Mirror System, CMS)\n\nProduct Structure of CMS\n\nMain Functions and Development Characteristics of CMS\n\nWeight Explanation of Each Item in CMS Regulations\n\nCore Content of CMS Regulation Tests\n\nComponent Performance of CMS\n\nPanoramic Diagram of the CMS Industry Chain\n\nKey Component 1 of CMS: Camera\n\nKey Component 2 of CMS: Display\n\nTechnical Solutions for CMS\n\nIndustry Challenges and Difficulties of CMS\n\nUser Concerns about CMS\n\nSummary of CMS Manufacturers: Passenger Cars\n\nChapter 2 Application Cases of Electronic Rearview Mirrors\n\nApplication Cases of Electronic Interior Rearview Mirrors\n\nSummary of Pre-installed Mass-Produced Vehicle Models with Electronic Interior Rearview Mirrors\n\nApplication Vehicle Model Case of Electronic Interior Rearview Mirrors in SAIC Maxus\n\nApplication Vehicle Model Case of Electronic Interior Rearview Mirrors in Xpeng\n\nApplication Vehicle Model Case of Electronic Interior Rearview Mirrors in Avatr\n\nApplication Vehicle Model Case of Electronic Interior Rearview Mirrors in Avatr\n\nApplication Vehicle Model Case of Electronic Interior Rearview Mirrors in Li Auto\n\nApplication Vehicle Model Case of Electronic Interior Rearview Mirrors in Dongfeng Motor\n\nApplication Vehicle Model Case of Electronic Interior Rearview Mirrors in Polestar\n\nApplication Vehicle Model Case of Electronic Interior Rearview Mirrors in Honda\n\nApplication Vehicle Model Case of Electronic Interior Rearview Mirrors in AITO\n\nApplication Cases of CMS in Passenger Cars\n\nSummary of Brands and Models Equipped with CMS\n\nGeely Lotus\n\nChangan Avatr\n\nBAIC\n\nSAIC Maxus\n\nDongfeng Motor\n\nBYD\n\nHonda\n\nMercedes-Benz\n\nVolvo\n\nFAW Jiefang\n\nYutong\n\nOthers\n\nIveco CMS Application Vehicle Model Case\n\nKenworth CMS Application Vehicle Model Case\n\nFoton Daimler CMS Application Vehicle Model Case\n\nFarizon Auto CMS Application Vehicle Model Case\n\nShaanxi Automobile CMS Application Vehicle Model Case\n\nJAC Heavy Truck CMS Application Vehicle Model Case\n\nDeepway CMS Application Vehicle Model Case\n\nHybot CMS Application Vehicle Model Case\n\nQingling Motors CMS Application Vehicle Model Case\n\nWeichai New Energy Commercial Vehicle CMS Application Vehicle Model Case\n\nBYD Commercial Vehicles CMS Application Vehicle Model Case\n\nSenptec Automotive CMS Application Vehicle Model Case\n\nNextVPU Automotive CMS Application Vehicle Model Case\n\nChapter 3 Tier 1 Suppliers of Electronic Rearview Mirrors\n\nFicosa\n\nYuanfeng Technology\n\nDesay SV\n\nHefei Jiangcheng Technology\n\nJingwei Hirain\n\nTianhan Technology\n\nShanghai Voyager Technology\n\nAutocruis\n\nShanghai G-Pulse\n\nADAYO\n\nStoneridge\n\nSenptec Electronics\n\nRongsheng Technology\n\nMinth Technology\n\nOthers\n\nGauzy Smart-Vision Products\n\nOFILM Passenger Car CMS Solutions\n\nNingbo Huaxiang Passenger Car CMS Solutions\n\nHirige CMS Solutions\n\nAZIMUT Commercial Vehicle CMS Solutions\n\nTianma Microelectronics\n\nHope Technology Electronic Rearview Mirrors\n\nSoling Co., Ltd. CMS\n\nHaiwei Technology CMS Systems\n\nChapter 4 CMS Supply Chain Solutions\n\nCameras\n\nOFILM\n\nSUNNY SMARTLEAD\n\nSENSING\n\nOthers\n\nAiptek Electronic Rearview Mirror Systems and Camera Module Solutions\n\nTS-Precision Technology Electronic Rearview Mirror Camera Module Solutions\n\nSUNWING Electronic Rearview Mirror Camera Module Solutions\n\nVIA Optronics CMS Cameras\n\nDisplay Screens\n\nBOE Varitronix\n\nTianma Microelectronics\n\nSamsung Display\n\nChips\n\nChip Technology Solutions in CMS\n\nAmbarella\n\nAMD Xilinx\n\nBlack Sesame Technologies\n\nAXERA\n\nORITEK\n\nIndie Microelectronics\n\nOthers\n\nQualcomm Electronic Rearview Mirror Chip Solutions\n\nOmniVision Technologies CMS Chips\n\nSemiDrive Electronic Rearview Mirror Chip Solutions\n\nSigmaStar Technology Electronic Rearview Mirror Chip Solutions\n\nGeehy Semiconductor CMS Application Solutions\n\nNextVPU Electronics\n\nHPMicro\n\nFlagchip\n\nChapter 5 Development Trends of Electronic Rearview Mirrors\n\nHow to Optimize the Issue of Insufficient Sense of Distance in CMS\n\nFor more information about this report visit https://www.researchandmarkets.com/r/7i8v4t\n\nAbout ResearchAndMarkets.com\n\nResearchAndMarkets.com is the world's leading source for international market research reports and market data. We provide you with the latest data on international and regional markets, key industries, the top companies, new products and the latest trends.",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/25/3156022/28124/en/Global-and-China-Electronic-Rearview-Mirror-Industry-Report-2025-Commercial-Vehicle-CMS-Gains-Traction-Faster-with-Some-Manufacturers-Cumulative-Installation-Volume-Exceeding-10-00.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "RetinalGenix Technologies Advances Home and Remote Monitoring Patent Portfolio, Positioning for the Future of Ocular and Systemic Disease Care",
      "content": "APOLLO BEACH, Fla., Sept. 25, 2025 (GLOBE NEWSWIRE) -- RetinalGenix Technologies Inc. (OTCQB:RTGN) (“RetinalGenix” or the “Company”), a pioneering developmental-stage ophthalmic monitoring and biopharmaceutical company focused on early detection and treatments for eye and systemic diseases, is proud to announce significant advancements in its patent portfolio, helping to position it at the forefront of home and remote health monitoring for ocular and systemic diseases.\n\nRecently granted patents, including U.S. Patent Application No. 2024/0099581 Al, cover key aspects of real-time home and remote ocular monitoring and scalable physician alert systems.\n\nThe current patent, filed in 2023 and approved after three years, focuses on the need to expand the mapping of the peripheral retina. This mapping is crucial for identifying various diseases, including the earliest retinal changes associated with diabetes. Additionally, it includes biomarkers such as beta-amyloid protein, which is linked to Alzheimer's disease and other disorders. This patent enhances the Company’s already strong diagnostic capabilities, which involve assessing any ocular structure and enabling home monitoring, by integrating the expanded mapping of the retinal landscape. These patents provide foundational protection for both the hardware and workflow involved in these technologies. They enable high-resolution retinal imaging to be conducted in the home and remotely, offering real-time alerts and facilitating early-stage disease detection for patients and healthcare providers, regardless of their location.\n\nRetinalGenix’s proprietary DNA/RNA/GPS Pharmaco-Genetic Mapping™ platform, along with its related test kits, is planned to integrate with the Company’s high-resolution retinal imaging system. This combination is designed to empower both patients and clinicians with actionable biomarker information, facilitating rapid clinical triage. Ultimately, the goal is to reduce the frequency of office visits and streamline critical care workflows. These systems are intended for widespread deployment across various settings, including homes, clinics, urgent care centers, nursing homes, and more.\n\nJerry Katzman, MD, CEO of RetinalGenix, stated: “Our patented remote monitoring system is expected to revolutionize both eye care and systemic disease detection. Our cutting-edge technology is intended to allow patients and physicians to gain 24/7, real-time access to health data, enabling early intervention and supporting new models of care. We believe we are leading a paradigm shift toward accessible, affordable, and patient-centered diagnostics and screening.”\n\nRetinalGenix patents are among the industry’s broadest, providing strong protection for device, system, and digital workflow innovations. This intellectual property portfolio sets the Company apart and is expected to position it for new partnerships, licensing, and expansion.\n\nThese patent achievements directly benefit RetinalGenix shareholders by securing exclusive commercialization rights, enhancing strategic competitive advantage, and helping to expand opportunities for partnership and revenue generation in the fast-growing telemedicine, ophthalmology, and healthcare technology sectors.\n\nFor media inquiries and investor relations, please contact:\n\nRetinalGenix Technologies Investor Relations\n\nT: 800-331-5446\n\nIR@retinalgenix.com\n\nAbout RetinalGenix Technologies Inc.\n\nRetinalGenix is an ophthalmic research and development company seeking to revolutionize early disease detection and improve patient outcomes across multiple disease areas by integrating genetic screening, advanced imaging, and therapeutic development. Its proprietary High-Resolution Retinal Imaging and RetinalGenix DNA/RNA/GPS Pharmaco-Genetic Mapping™ technologies are designed to help prevent blindness by detecting initial physiological changes that could indicate future ocular and systemic diseases affecting neurodegenerative, cardiovascular, vascular, and metabolic systems, as well as diabetic conditions, Alzheimer’s disease and Parkinson’s disease. RetinalGenix is also developing therapeutic drugs for dry age-related macular degeneration (dry AMD) and Alzheimer’s disease/dementia.\n\nSafe Harbor Statement\n\nThis press release contains certain forward-looking statements within the meaning of the safe harbor provisions of the Private Securities Litigation Reform Act of 1995. These statements are identified by the use of the words “could,” “believe,” “anticipate,” “intend,” “estimate,” “expect,” “may,” “continue,” “predict,” “potential,” “project” and similar expressions that are intended to identify forward-looking statements and include statements regarding positioning the Company at the forefront of home and remote health monitoring for ocular and systemic diseases, integrating RetinalGenix’s DNA/RNA/GPS Pharmaco-Genetic Mapping™ platform, along with its related test kits, with its high-resolution retinal imaging system, the combination empowering both patients and clinicians with actionable biomarker information, facilitating rapid clinical triage, reducing the frequency of office visits and streamlining critical care workflows, deploying the systems across various settings, including homes, clinics, urgent care centers, nursing homes, and more, the Company’s patented remote monitoring system revolutionizing both eye care and systemic disease detection, providing patients and physicians 24/7, real-time access to health data, enabling early intervention and supporting new models of care, leading a paradigm shift toward accessible, affordable, and patient-centered diagnostics and screening, RetinalGenix patents providing strong protection for device, system, and digital workflow innovations, being positioned it for new partnerships, licensing, and expansion and expanding opportunities for partnership and revenue generation in the fast-growing telemedicine, ophthalmology, and healthcare technology sectors. These forward-looking statements are based on management’s expectations and assumptions as of the date of this press release and are subject to a number of risks and uncertainties, many of which are difficult to predict, that could cause actual results to differ materially from current expectations and assumptions from those set forth or implied by any forward-looking statements. Important factors that could cause actual results to differ materially from current expectations include, among others, the Company’s ability to successfully complete research and further development and commercialization of Company products, the timing, cost and uncertainty of obtaining regulatory approvals for the Company’s products, the Company’s ability to deploy its the systems across various settings, including homes, clinics, urgent care centers and nursing homes, the Company’s ability to revolutionize both eye care and systemic disease detection, the Company’s ability to enter into new partnerships and licensing arrangements, the Company’s ability to generate revenue, the Company’s ability to protect its intellectual property and the risk factors described in the Company’s Annual Report on Form 10-K for the year ended December 31, 2024 and the Company’s subsequent filings with the SEC, including subsequent periodic reports on Forms 10-Q and 8-K. The information in this release is provided only as of the date of this release, and we undertake no obligation to update any forward-looking statements contained in this release on account of new information, future events, or otherwise, except as required by law.\n\nMedia Contact:\n\nFor further information, please contact:\n\nRetinalGenix Technologies Inc.\n\nMedia and Investor Relations\n\nir@retinalgenix.com\n\n(800) 331-5446",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/25/3156103/0/en/RetinalGenix-Technologies-Advances-Home-and-Remote-Monitoring-Patent-Portfolio-Positioning-for-the-Future-of-Ocular-and-Systemic-Disease-Care.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Trump's TikTok deal payment criticized as 'shake-down scheme' by experts",
      "content": "Trump's TikTok deal payment criticized as 'shakedown scheme' by experts\n\ntoggle caption Andrew Harnik/Getty Images\n\nThe Trump administration recently approached a coalition of U.S. investors set to take over TikTok's U.S. operations with an ask: Will the group make a payment to the federal government \"in the low billions,\" according to a person with direct knowledge of the talks.\n\nThe response from the investors, which includes tech mogul Larry Ellison, the Murdochs and venture capital heavyweight Andreessen Horowitz, was an unequivocal yes.\n\n\"Not a single member balked,\" said the person, who was not authorized to speak publicly. \"They see it as something of a finders' fee.\"\n\nWelcome to President Trump's new business agenda: extracting payments as if the federal government is brokering deals like a white-shoe consulting firm fueled by lucrative \"fees for service.\"\n\nSponsor Message\n\nWhether it's the U.S. taking 15% of Nvidia and AMD's chip sales to China, the federal government securing a \"golden share\" in U.S. Steel or the Trump administration reportedly seeking an equity stake in Lithium Americas as part of a government loan negotiation, the White House is on a campaign of squeezing businesses with few parallels in modern history.\n\n\"At a minimum, this now means there is a tax imposed on every major business transaction,\" said Luigi Zingales, a professor of finance at the University of Chicago. \"But even worse, businesses will no longer be focused on innovating and creating value and instead the whole game now is rent-seeking. It's all about ingratiating yourself with Trump.\"\n\nThe White House did not return a request for comment.\n\nAsked on Thursday about the multibillion-dollar fee expected to be tacked onto the TikTok deal, which was earlier reported by The Wall Street Journal, Trump was evasive.\n\n\"We're going to be announcing different things, but the U.S. comes out great,\" Trump said from the Oval Office.\n\ntoggle caption Mario Tama/Getty Images\n\nTrump has been more direct about defending his administration's private business interventions, including after Intel agreed to sell a 10% stake of the company to the U.S. government following Trump's calls for its chief executive to resign.\n\nSponsor Message\n\n\"The United States paid nothing for these Shares, and the Shares are now valued at approximately $11 Billion Dollars. This is a great Deal for America and, also, a great Deal for INTEL,\" Trump posted last month.\n\nMany media companies capitulate to Trump pressure\n\nThis pattern has played out across media, where Trump's longtime war against news organizations has escalated into marshaling the might of the federal government to force concessions.\n\nThe parent companies for ABC and CBS both paid $16 million to settle lawsuits Trump lawsuits filed alleging mistreatment by the networks. The payments went to Trump's presidential library foundation and Trump's legal fees. Shortly after CBS' payment, federal regulators approved the sale of its parent company, Paramount, to Skydance Media, which is controlled by the Ellison family.\n\nMedia companies were already signaling their acquiescence to Trump before he won a second term.\n\nAhead of the election, the billionaire owners of The Washington Post and The Los Angeles Times killed parallel editorial endorsements of Kamala Harris. They soon rewired their editorial pages to be less critical of Trump. Both owners — Amazon founder Jeff Bezos for the Post and medical innovator Dr. Patrick Soon-Shiong for the Los Angeles Times — have major business interests that hinge on decisions by federal officials.\n\nThen there is Jimmy Kimmel. Last week, Disney — which owns ABC — suspended the late-night host after Federal Communications Chairman Brendan Carr threatened action over Kimmel's remarks about the assassination of conservative activist Charlie Kirk. After a public outcry, including from First Amendment scholars, Kimmel returned on Tuesday with the blessing of ABC and Disney.\n\ntoggle caption Michael Loccisano/Getty Images\n\nTrump lashed out at the network's reversal.\n\n\"I can't believe ABC Fake News gave Jimmy Kimmel his job back,\" Trump wrote on Truth Social, writing in the same post: \"I think we're going to test ABC out on this. Let's see how we do. Last time I went after them, they gave me $16 Million Dollars.\"\n\nSponsor Message\n\nTrump allies landing deals sparks criticism of \"crony capitalism\"\n\nAmong those the Trump White House has lined up to take the reins of TikTok's U.S. operation are Rupert and Lachlan Murdoch, the controlling owners of Fox News, The New York Post and The Wall Street Journal.\n\nFrom one view, it can be seen as recognition of the friendly coverage the president often receives from Fox and The Post.\n\nBut Trump and Murdoch have also been at odds. That strife was highlighted in July when Trump sued The Journal and Murdoch over the paper's reporting on the disgraced late financier Jeffrey Epstein.\n\nThe Murdochs' role in the takeover of America's most popular video app is a remarkable victory for the family and follows a relationship that has at times been combative.\n\ntoggle caption Monica Schipper/Getty Images\n\n\"If you look at Fox News on the one hand and The Wall Street Journal editorial page on the other, I think it's very clear that Rupert Murdoch wants to have bets on every square on the roulette table,\" says Richard Tofel, who was the former assistant publisher of The Wall Street Journal prior to Murdoch's 2007 acquisition of the paper.\n\nBut most of the stakeholders in the TikTok investment group are business leaders who have shown sustained loyalty to the president, which makes the deal look like a reward for fealty, Tofel says.\n\n\"There is a growing set of examples of crony capitalism that the Trump administration is putting into place across this country,\" says Tofel, a lawyer who later went on to become president of the nonprofit investigative news site ProPublica. \"American industry — which would have regarded this behavior from a Democrat as anathema and inconsistent with the tenets of unfettered capitalism — is rolling over for it time after time.\"\n\nExperts say U.S. economy being undermined by \"shakedown schemes\"\n\nThe exact template has varied. In the case of TikTok, the administration is seeking a fee for service. With Intel, the federal government is acquiring an equity stake. For chipmakers Nvidia and AMD, meanwhile, the demand was for a slice of future profits. And with the network television settlements, the payouts arose after personal legal disputes.\n\nSponsor Message\n\n\"There is no consistent principle at play, just the exercise of Trump's personal power over other people's money,\" said Dael Norwood, associate professor of history at the University of Delaware, who notes that the winners and losers are clear.\n\n\"All Americans — taxpayers, investors, customers, and workers — lose with crony capitalism,\" he said. \"It increases everyone's costs, makes everyone more vulnerable to extortion (or worse), and profoundly degrades our expectations for honesty and fair dealing, society-wide.\"\n\nIn public, corporate executives show support to the president and appear to back such deals, but behind closed doors, some business leaders are expressing deep concern.\n\nYale School of Management professor Jeffrey Sonnenfeld recently helped organize a gathering of more than 100 top CEOs, and he said there was near-unanimous consensus in surveys conducted at the event that Trump's interventions in private business are undermining America's free market principles.\n\n\"These are shakedown schemes. It's a gross violation of what capitalism is supposed to stand for. I'd even call it extortion,\" Sonnenfeld said. \"Privately, CEOs are horrified.\"\n\nBut Sonnenfeld said executives are not banding together to push back on Trump, as top business leaders did following Trump's election denialism in November 2020.\n\n\"CEOs need to speak up, like they did then, but they aren't doing it publicly,\" Sonnenfeld said. \"Fear of retaliation is motivating the silence, but there has got to be a trigger line to stop this. We just don't know what that is yet.\"\n\nTalks with American investors for a potential acquisition of TikTok's U.S. enterprise have been moving in fits and starts for the past five years, starting back when the Trump administration declared the Chinese-owned hit video app to be a national security threat and sought to have it banned.\n\nSince Trump's about-face and embrace of TikTok, it has been clear that software and cloud-computing company Oracle would be a major player in the bid to take over the app's American presence.\n\nSponsor Message\n\nOracle co-founder Larry Ellison is a close confidante of Trump and the president has said both publicly and in private that he'd like to see TikTok controlled by Oracle.\n\nAccording to the source with direct knowledge of the talks, many of the deal's provisions have been under discussion for months, including that Oracle will host and oversee all of Americans' TikTok data. Beijing-based ByteDance will license its algorithm to the U.S. entity to be retrained based only on the 170 million U.S. users of the app and ByteDance will keep a minority stake in the company.\n\nThe one part of the agreement that caught investors by surprise? The multibillion-dollar fee request.\n\n\"They were taken aback when they were told they'd have to kick in,\" the source said. \"But I think they see it as just the price of doing business right now.\"",
      "source": "NPR",
      "url": "https://www.npr.org/2025/09/26/g-s1-90598/tiktok-deal-trump-oracle",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Couples in Mumbai can now apply for fast-track amd weekend marriage registration services online",
      "content": "\n\n\n\nMumbai: BMC BMC has initiated an online application process for its newly launched fast-tracked and weekend marriage registration services.It has also expanded the marriage registration services to Christian, Jewish and Parsi couples from the same religion. For Sikhs, in addition to the current facility, registration of marriages under the Anand Marriage Act, 1909, has also been made available now.BMC has also removed the condition, wherein registration of marriage with civic offices was possible only if the wedding was held in Maharashtra. So now, couples who have tied the knot anywhere in the world can register their marriage in the BMC ward where either of the partners reside.Further, marriage registration certificates will now be issued with a QR Code, making it available for instant verification. The certificates could also be included in the DigiLocker facility in future, said officials.With BMC discontinuing the manual application process for regular marriage registrations, couples can seek appointments online on the civic website, said civic officials. Services like issuing certificates, photographs of married couples have also been made available online.Earlier, officials added, marriage registration of couples belonging to only Hindu, Muslim, Buddhist, Sikh and Jain religions were done at civic offices. Now, the service has been extended to couples of other religions too.On Sunday, BMC introduced marriage registration services on weekends from 9am to 1pm and also reserved 20% of the daily slots on weekdays for same-day registration and certificate issuance as part of its fast-track marriage registration service. To access either service, couples will have to complete all documentation, pay the regular registration fee, along with an additional Rs 2,500, and appear in person with witnesses, said civic officials.Mumbaikars can avail the weekend marriage registration services on Saturdays at 13 BMC ward offices — A, C, E, F-South, G-South, H-East, K-East, P-South, P-North, R-Central, L, M-West, and S — and on Sundays at 12 BMC ward offices — B, D, F-North, G-North, H-West, K-West, P-East, R-South, R-North, N, M-East, and T, said civic officials.",
      "source": "The Times of India",
      "url": "https://timesofindia.indiatimes.com/city/mumbai/couples-in-mumbai-can-now-apply-for-fast-track-amd-weekend-marriage-registration-services-online/articleshow/124168496.cms",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Heavy hand: Free-market US tested as Trump takes stakes in private companies",
      "content": "As a condition of allowing the sales of US Steel to Nippon, President Donald Trump demanded a government 'golden share' in the enteprise - Copyright GETTY IMAGES NORTH AMERICA/AFP/File Drew Angerer\n\nThe Trump administration is in talks to take an equity stake in Lithium Americas, which would insert the government into another private enterprise in the latest challenge to American free-market traditions.\n\nThe move comes on the heels of Trump announcements establishing government holdings in struggling semiconductor giant Intel and the rare earth company MP Materials. Trump also secured a “golden share” for Washington in United States Steel as a condition of its sale to Japan’s Nippon Steel.\n\nTalks are still ongoing on the Lithium Americas stake, part of a renegotiation of a US Department of Energy loan held by the Canadian mining company and General Motors, said a Trump administration official.\n\nThe White House has characterized the stock holding arrangements as a boon for taxpayers that points to Trump’s prowess as a dealmaker, while asserting that day-to-day management will be left to companies.\n\nBut free-market advocates have reacted with various degrees of alarm to a trend they see as undermining the strength of the US system and stoking crony capitalism. In the US system, the government sets up the rules governing the private sector but generally stays out of it thereafter as firms respond to market signals.\n\n“It undermines competition,” said Fred Ashton, director of competition policy at American Action Forum, who believes inserting the state into private enterprise leads to inefficiency and benefits politically favored firms over those less connected.\n\n“We know the president likes to win so there’s no way the government lets these firms fail,” Ashton said.\n\nTrump administration officials recently made use of the US Steel golden share. The company had planned to keep paying 800 workers while idling an Illinois factory, but decided to keep the plant running after Commerce Secretary Howard Lutnick invoked the golden share, according to a Wall Street Journal report.\n\n“You need to let an executive of the company conclude the best use of the capital,” said governance expert Charles Elson of the University of Delaware, who criticized the White House intervention.\n\n“The government is not in the business of picking winners and losers in the capital system,” he said. “That’s why we have a capital system.”\n\n– Bipartisan consensus –\n\nIt is not unprecedented for the US government to hold equity stakes. In response to the 2008 financial crisis, the US government amassed holdings in insurer AIG, General Motors and fellow automaker Chrysler as a condition of government support packages.\n\nBut the Treasury Department sold off the shares after the crisis ended, reflecting a bipartisan consensus, according to Michael Strain of the American Enterprise Institute think tank, who said presidents from Ronald Reagan to Barack Obama embraced the free market.\n\n“Obama would have laughed out of the room the suggestion that the government take an equity stake in a manufacturing company,” Strain said in a recent column that also criticized the White House’s tying of Nvidia and AMD export licenses to payments to the government.\n\nObama “understood that in America’s system of democratic capitalism, the government does not own or shake down private companies,” Strain said in the piece headlined “Is Trump a State Capitalist?”\n\nStrain, in an interview, predicted a “massive amount of crony capitalism” under Trump compared with the norm, but said the shifts will be too limited to significantly tilt the US macroeconomy given its size and tradition.\n\nAshton said he agrees that US status as a free market economy is not seriously in question. But he believes Trump’s conduct is distorting company behavior, noting reports that Apple may take a stake in Intel following Apple CEO Tim Cook’s August White House visit when he presented Trump with a 24-carat gold piece.\n\n“It’s become so murky,” Ashton said. “We don’t know whether it’s a business decision because it’s a business decision or whether it’s a business decision because they have to please the White House in some way.”",
      "source": "Digital Journal",
      "url": "https://www.digitaljournal.com/world/heavy-hand-free-market-us-tested-as-trump-takes-stakes-in-private-companies/article",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Acer、IFA 2025でグローバル向け最新モデルを公開",
      "content": "日本エイサー株式会社（本社：東京都新宿区、代表取締役社長：ボブ・セン）は、先日ドイツ・ベルリンにて開催された「Acer グローバルプレスカンファレンス」にて発表された新製品についてお知らせいたします。なお、これらのモデルの日本市場への導入可否や導入時期、想定売価は現時点では未定です。今後の発表にご期待ください。\n\n発表製品一覧\n\nノートパソコン製品\n\nデスクトップパソコン製品\n\nプロジェクター製品\n\nルーター製品\n\nモニター製品\n\nタブレット製品\n\nキーボード製品\n\nハイライト\n\n薄型・軽量ノートPC「Swift」シリーズの新モデル Swift Air 16\n\nSwift Air 16 (SFA16-61M)\n\n最新性能 ：AMD Ryzen™ AI 300シリーズ・プロセッサーを搭載し、AIアプリケーションの高速処理と省電力性を両立。Copilot+ PCとして Recall（プレビュー）、Click to Do（プレビュー）、改良版Windows SearchなどのAI機能に対応。\n\n超軽量設計 ：マグネシウム-アルミニウム合金の筐体で、16インチクラスながら重量1kg未満。4色のカラーバリエーションを展開。\n\nディスプレイ ：16インチWQXGA+ AMOLED（120Hz／DCI-P3対応／400nit）またはWUXGA IPS（60Hz）から選択可能。\n\n主要機能 ：FHD IRカメラ（Windows Hello対応／プライバシーシャッター付）、デュアルスピーカー＆マイク。\n\n接続性：USB Type-C（フル機能）×2、USB 3.2 Type-A、HDMI 1.4、Wi-Fi 6E、Bluetooth最新規格。\n\nMediaTek Kompanio搭載 Chrombook Plus\n\nAcer Chromebook Plus Spin 514 (CP514-5HN)\n\n最新AI対応プロセッサー ：MediaTek Kompanio Ultra 搭載。50 TOPSのAI処理性能により生成AIやリアルタイム自動化をサポート。\n\n高効率＆長時間駆動 ：Arm Immortalis-G925 MC11 GPUで優れたグラフィックス性能を実現し、最大17時間のバッテリー駆動を提供。\n\nGoogle AI機能統合 ：スマートグルーピングやオンデバイス画像編集、Quick Insertキー、Lens検索など生産性を高めるAI機能を搭載。\n\n特典プラン：12か月間のGoogle AI Proプラン利用権を無償提供。GeminiやNotebookLMの高度AI機能に加え、2TBのクラウドストレージを利用可能。\n\nハイエンドAI開発からコンテンツ制作、ゲーミングまで幅広いニーズに応える新型ノートPC\n\nPredator Helios 18P AI (PH18P-73)\n\nプロセッサー ：最大 Intel® Core™ Ultra 9 285HX（Intel® vPro®対応）、ハードウェアレベルのセキュリティと安定性を提供。\n\nメモリ ：最大192GB ECCメモリ搭載、データエラーを検出・修正し高信頼性を実現。\n\nGPU ：最大 NVIDIA® GeForce RTX™ 5090 Laptop GPU（DLSS 4対応）。\n\nストレージ & 接続 ：最大6TB PCIe Gen5 SSD、Thunderbolt™ 5、Killer™ Ethernet E5000B、Wi-Fi 7。\n\nディスプレイ ：18型 16:10、Mini LED 4K WQUXGA（3840×2400）、HDR 1000nit、DCI-P3 100%。\n\n冷却機構：第6世代AeroBlade™メタルファン（0.05mm）、液体金属グリス、ベクターヒートパイプ採用。\n\n大規模AIモデルをローカルで実行できる超小型ワークステーション\n\nVeriton GN100 AI Mini Workstation (GN100)\n\nハードウェア性能： NVIDIA® GB10 Grace Blackwell Superchip 搭載。FP4 AI性能最大1 PFLOPS、20コアArm CPU、128GBユニファイドメモリ、4TB NVMe M.2 SSD。\n\nAI開発環境： NVIDIA AIソフトウェアスタックを標準搭載し、PyTorch、Jupyter、Ollamaなど主要ツールをサポート。\n\nスケーラビリティ： NVIDIA ConnectX-7 NICにより2台連結し、最大4,050億パラメータ規模のAIモデル運用が可能。\n\n接続性・セキュリティ：Wi-Fi 7、USB 3.2 Type-C×4、HDMI、Ethernet、Kensingtonロック対応。\n\nゲーマーからクリエイター、プロフェッショナルまで幅広く対応するフラッグシップデスクトップ\n\nPredator Orion 7000 (PO7-667)\n\nプロセッサー & GPU： 最大 Intel® Core™ Ultra 9 285K（NPU内蔵）＋NVIDIA® GeForce RTX™ 5090、DLSS 4やNIMマイクロサービス対応でAIワークロードも強化。\n\n冷却性能： Predator CycloneX 360＋CPU液冷クーラー採用で冷却効率15％向上。基板温度を最大9℃低減。\n\nメモリ & ストレージ： 最大128GB DDR5 7200MT/s XMP RGB RAM、最大6TB SSD＋最大4TB HDD対応（3.5インチ×2ベイ）。\n\n接続性：Killer Ethernet E3100G、Wi-Fi 7、Thunderbolt 4で低遅延＆高速通信を実現。\n\n新型ゲーミングデスクトップ 「Nitro 70」「Nitro 50」\n\nAcer Nitro 70 (N70X3D-100) / Acer Nitro 50 (N50-100)\n\nNitro 70（N70X3D-100）： 最大 AMD Ryzen™ 9 9950X3D プロセッサー＋NVIDIA® GeForce RTX™ 5090 GPU、3,352 AI TOPS。最大128GB DDR5 6000MT/s RAM、2TB PCIe Gen4 SSD対応。\n\nNitro 50（N50-100）： 最大 AMD Ryzen™ 7 8700G プロセッサー＋NVIDIA® GeForce RTX™ 5080 GPU。最大128GB DDR5 5200MT/s RAM、2TB PCIe SSD対応。\n\n共通機能： Nitro CycloneX 360 冷却システム（冷却効率15％向上）、Wi-Fi 7、Acer Intelligence Space（内蔵AIツール）、強化ガラスケース＋ARGBライティング。\n\n環境対応：45Lシャーシのプラスチック素材に65％PCR（再生プラスチック）を採用。\n\nエリートゲーマーのためのウルトラ高速モニター\n\nPredator X27U F8\n\n高速リフレッシュレート ：26.5型 OLED IPS／WQHD（2560×1440）、最大540Hz、DFRでHD（1280×720）最大720Hz切替対応\n\n鮮やかな映像表現 ：99％ DCI-P3色域カバー、VESA DisplayHDR 500 True Black認証による深い黒と高コントラスト。\n\n滑らかなゲーム体験 ：AMD FreeSync™ Premium Pro対応で、ティアリングやスタッタリングを防止。\n\nエリートゲーマー仕様：超高速応答と高画質を両立したフラッグシップモデル。\n\nすべてのゲーマーに没入の映像体験を\n\nNitro XV275K V6\n\n高解像度ディスプレイ ：27型 4K UHD（3840×2160）、リフレッシュレート180Hz。\n\n高速応答と滑らかさ ：1ms VRB Pro、AMD FreeSync™ Premium対応でティアリングのない快適なゲーム体験。\n\n鮮やかな映像表現 ：ピーク輝度1,000nit（HDR10%）、DCI-P3 97％、10.7億色（8bit+FRC）。\n\n豊富な接続性：HDMI 2.1×2、DisplayPort 1.4を搭載。ゲーミングやマルチメディア環境に対応。\n\nクリエイターへ。ゲーマーへ。OLED 280Hz WQHDモニター\n\nAcer CE270U Z\n\n高精細・高速表示 ：26.5型 OLED／WQHD（2560×1440）、リフレッシュレート280Hz。\n\n滑らかな映像体験 ：AMD FreeSync™ Premium Pro、応答速度0.03ms、HDR時ピーク輝度1,000nit、DCI-P3 99%色域。\n\n快適な視聴環境 ：チルト角最大25°に対応し、長時間の使用でも快適。\n\n臨場感あるサウンド：3Wスピーカー内蔵で映像と音を一体で楽しめる。\n\n世界に向けて発表するAmadanaブランドモニター\n\nAmadana 16APM1QJ / Amadana 27ART0 P1 (※英語サイト)\n\namadana 16APM1QJ（15.6型）： 超薄型・軽量（0.65kg）のポータブルIPSモニター。広視野角、最大90°チルト対応スタンドを内蔵し、mini-HDMI／USB Type-C入力に対応。生産性とエンターテインメントの両方で活躍。\n\namadana 27ART0 P1（27型）：ゼロフレームデザインのIPSディスプレイ。144Hzリフレッシュレート、Dynamic Refresh Rate（120Hz／60Hz）、sRGB 99％色域対応。HDMI／VGA入力、アクセサリ用小型ドックを備えた多用途モデル。\n\nその他の発表製品については、以下をご覧ください。\n\n特設サイト\n\nhttps://www.acer.com/jp-ja/events/nextatacer\n\nグローバルプレスリリースおよび製品写真\n\nhttps://drive.google.com/drive/folders/1k6NiPXN_9CLo2cBy6pw0Wcx8wglJuwuH\n\nプレスリリースページ\n\nhttps://www.acer.com/jp-ja/about/news/20250926\n\nAcerについて\n\n1976年に設立されたAcerは、世界160以上の国と地域に展開する世界有数のテクノロジー企業です。コンピューターやディスプレイをはじめとする幅広い製品群において革新を取り入れつつ、新たな事業領域にも進出することで進化を続けています。Acerはまた、持続可能な成長にも取り組み、環境および社会的責任に沿った新たな機会を追求しています。Acerグループには9,000名以上の従業員が在籍し、製品・ソリューション・サービスの研究、設計、マーケティング、販売、サポートを通じて、人とテクノロジーの間にある障壁を取り払うことに貢献しています。詳細は www.acer.com をご覧ください。\n\n日本エイサー株式会社について\n\n社名 ：日本エイサー株式会社\n\n所在地：東京都新宿区西新宿6-24-1 西新宿三井ビルディング 18F\n\n代表者：代表取締役社長 詹 國良（ボブ・セン）\n\n公式サイト： https://www.acer.com/\n\n公式facebook： https://www.facebook.com/AcerJapan\n\n公式X ： https://www.twitter.com/AcerJapan\n\nGaming公式X: https://twitter.com/PredatorJPN\n\n公式Instagram： https://www.instagram.com/acer_japan/\n\nGaming公式Instagram： https://www.instagram.com/predatorgamingjapan/\n\n公式YouTube： https://www.youtube.com/user/AcerJapanChannel\n\n© 2025 Acer Inc. All rights reserved. AcerとAcerロゴはAcer Inc.の登録商標です。その他商標、登録商標、サービスマーク等の著作物の著作権は、帰属表明の有無に関わらず、それぞれの権利者に帰属します。発表内容は予告なしに変更または削除されることがありますのであらかじめご了承ください。\n\n© 2025 Acer Inc. All rights reserved. Acer and the Acer logo are registered trademarks of Acer Inc. Other trademarks, registered trademarks, and/or service marks, indicated or otherwise, are the property of their respective owners. All offers subject to change without notice or obligation and may not be available through all sales channels. Prices listed are manufacturer suggested retail prices and may vary by location. Applicable sales tax extra.",
      "source": "Prtimes.jp",
      "url": "https://prtimes.jp/main/html/rd/p/000001034.000000640.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "EnergyBook Pro Ultra: New laptop promises up to 7 days standby time and 28 hours of intensive office use",
      "content": "4 Reviews ← exclude selected types\n\nEnergizer is no longer a stranger on the laptop market, having just officially announced a new notebook, the EnergyBook Pro Ultra. The main selling point of this model is its large 192 Wh battery, which reportedly provides up to 28 hours of office use. But there are other notebooks without gigantic batteries that also have similarly long battery life, as our review of the Asus Vivobook S16 proves. The large battery capacity of the EnergyBook Pro Ultra is, of course, a double burden: Firstly, it is likely to increase the weight. Secondly, devices with a battery capacity of 100 or 160 Wh are usually not permitted on passenger aircraft. The extent to which this rule is enforced and whether the EnergyBook Pro Ultra will attract the attention of airport staff is debatable. In the worst case, the notebook would have to be left behind when traveling.\n\nExact technical specifications in the form of a data sheet are not yet available, but concrete information about the features has been provided. An AMD Ryzen 5 processor and 16 GB of DDR4 RAM are expected. A 512 GB NVMe SSD is installed, and the 18-inch screen is said to have a resolution of 1,920 x 1,200, which isn't exactly sharp. USB Type-C, HDMI, USB, a memory card reader, and a headphone jack are available. A price of €449 ($525) has been announced, but availability is not yet known.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/EnergyBook-Pro-Ultra-New-laptop-promises-up-to-7-days-standby-time-and-28-hours-of-intensive-office-use.1125368.0.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Linux 6.17 Gets Ready For Release With Intel Panther Lake & More Performance",
      "content": "The Linux 6.17 kernel is tracking well for its planned stable release on Sunday. Here is a look back at some of the most interesting changes to find with this next kernel version.Linux 6.17 is another hearty release and is what's set to power Ubuntu 25.10, Fedora 43, and other end of year 2025 Linux distribution releases. Some of the most interesting changes to find with Linux 6.17 include:- Intel Xe3 graphics for Panther Lake are now enabled by default in advance of Intel formally launching the next-generation Panther Lake chips for laptops.- The Linux 6.17 kernel now makes multi-core SMP support unconditionally enabled.- Attack Vector Controls for more easily managing different groups of CPU security vulnerabilities/mitigations depending upon the class of attacks you / the Linux administrator are concerned about and such as whether you are running any (untrusted) virtual machines, etc.- The Intel IPU7 driver was added as part of the web camera support for select Lunar Lake and Panther Lake laptops.- Apple M1 and M2 Macs can now reboot with the mainline kernel thanks to the Apple System Management Controller (SMC) driver being upstreamed.- A mainline driver for the Raspberry Pi 5's RP1 I/O chip.- Initial support for Intel Wildcat Lake graphics as well as IVPU driver support for the Wildcat Lake NPU.- SR-IOV support for Intel Arc Pro B-Series GPUs as well as Intel preparations for multi-GPU as part of their Project Battlematrix.- AMD SmartMux support for better handling of hybrid GPU laptops.- EXT4 file-system scalability performance improvements.- Lenovo Legion Gaming Drivers for better Lenovo Legon Go S gaming handheld support on Linux.- The gconfig utility for configuring the Linux kernel builds with a GTK UI has been ported to the GTK3 toolkit.- Various performance optimizations and other enhancements.See the Phoronix feature overview of Linux 6.17 for a more comprehensive look at the dozens of interesting new changes to find with Linux 6.17. Linux v6.17 stable is expected to be tagged on Sunday if no last minute issues materialize and then following that will be the start of the Linux v6.18 merge window, which is also expected to become this year's LTS kernel version.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.17-Features-Reminder",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "ROG Xbox Ally Handhelds Now Available for Pre-Order in Canada, Starting at $799",
      "content": "Xbox and Asus have opened up the preorders for the ROG Xbox Ally and ROG Xbox Ally X gaming handhelds. Both devices launch on October 16.\n\nThe ROG Xbox Ally and ROG Xbox Ally X are powered by AMD’s Ryzen GPU technology and offer a boutique and Xbox UI experience. Preorders are available for the two devices.\n\nBoth devices support a 7-inch IPS screen, offering up to 120Hz support. The standard ROG Xbox Ally features 720p fidelity, while the ROG Xbox Ally X features up to 1080p resolutions.\n\nThe ROG Xbox Ally X is the high-end device of the pair and is powered by the AMD Ryzen AI Z2 Extreme chipset. According to Asus, the device is able to offer a 30 percent increase when playing Indiana Jones and the Great Circle and Doom: The Dark Ages when compared to the original ROG Ally X. It also supports twice the battery life when playing a game like Hollow Knight: Silksong.\n\nThe ROG Xbox Ally X is available for $1,299 in Canada.\n\nAsus’ ROG Xbox Ally is the entry-level model, sporting the AMD Ryzen Z2 A chip. When compared to the standard ROG Ally handheld, the new model offers a boost of up to 20 percent performance when playing Forza Horizon 5 and Gears of War: Reloaded. The company also claims it’ll offer up to 110 percent more battery life.\n\nThe ROG Xbox Ally is available for $799 in Canada.\n\nWith the use of AMD’s Ryzen chips, both models support AMD FidelityFX Super Resolution (FSR), Radeon Super Resolution (RSR), and AMD Fluid Motion Frames (AFMF) frame generation. With the use of AFMF, the handhelds can support 60 percent better frame rates. The ROG Xbox Ally X also offers an onboard NPU for AI features.\n\nPreorders can be found at the following retailers:\n\nXbox and Asus also confirm the device will become available later at launch at Costco, MDG, the Microsoft Store, Newegg and Visions.",
      "source": "iPhone in Canada",
      "url": "https://www.iphoneincanada.ca/2025/09/26/rog-xbox-ally-handhelds-now-available-for-pre-order-in-canada-starting-at-799/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "AX210 Проблемы с bluetooth на manjaro",
      "content": "Иногда проблемы в линуксе есть из-за реализации «сосуществования» вайфая и блютуса на устройстве. Для этого в некоторых модулях предусмотрена опция bt_coex или как-то так. Тебе может даже и карту менять не надо было, только включить эту опцию.\n\nСейчас у тебя AX210, посмотри параметры модуля для неё: modinfo iwlwifi\n\nparm: debug:debug output mask (uint) parm: swcrypto:using crypto in software (default 0 [hardware]) (int) parm: 11n_disable:disable 11n functionality, bitmap: 1: full, 2: disable agg TX, 4: disable agg RX, 8 enable agg TX (uint) parm: amsdu_size:amsdu size 0: 12K for multi Rx queue devices, 2K for AX210 devices, 4K for other devices 1:4K 2:8K 3:12K (16K buffers) 4: 2K (default 0) (int) parm: fw_restart:restart firmware in case of error (default true) (bool) parm: nvm_file:NVM file name (charp) parm: uapsd_disable:disable U-APSD functionality bitmap 1: BSS 2: P2P Client (default: 3) (uint) parm: enable_ini:0:disable, 1-15:FW_DBG_PRESET Values, 16:enabled without preset value defined,Debug INI TLV FW debug infrastructure (default: 16) (uint) parm: bt_coex_active:enable wifi/bt co-exist (default: enable) (bool) parm: led_mode:0=system default, 1=On(RF On)/Off(RF Off), 2=blinking, 3=Off (default: 0) (int) parm: power_save:enable WiFi power management (default: disable) (bool) parm: power_level:default power save level (range from 1 - 5, default: 1) (int) parm: disable_11ac:Disable VHT capabilities (default: false) (bool) parm: remove_when_gone:Remove dev from PCIe bus if it is deemed inaccessible (default: false) (bool) parm: disable_11ax:Disable HE capabilities (default: false) (bool) parm: disable_11be:Disable EHT capabilities (default: false) (bool)\n\nВидишь bt_coex_active? Вот тебе надо выяснить, для начала, включен у тебя этот параметр, или нет. Посмотри в /sys/module/iwlwifi/parameters/ там всё есть, а если нет, то значение, можно предположить, умолчанию. Потом почитайэту ссылку: https://community.intel.com/t5/Wireless/AX210-Bluetooth-adapter-not-shwowing-...",
      "source": "Linux.org.ru",
      "url": "https://www.linux.org.ru/forum/linux-hardware/18093141",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "One of the most powerful mini PCs of 2025! Minisforum MS-S1 Max review - AMD Strix Halo Power, 128 GB RAM & Radeon 8060S for professionals & AI",
      "content": "Transparency\n\nThe selection of devices to be reviewed is made by our editorial team. The test sample was provided to the author as a loan by the manufacturer or retailer for the purpose of this review. The lender had no influence on this review, nor did the manufacturer receive a copy of this review before publication. There was no obligation to publish this review. As an independent media company, Notebookcheck is not subjected to the authority of manufacturers, retailers or publishers.\n\nThis is how Notebookcheck is testing\n\nEvery year, Notebookcheck independently reviews hundreds of laptops and smartphones using standardized procedures to ensure that all results are comparable. We have continuously developed our test methods for around 20 years and set industry standards in the process. In our test labs, high-quality measuring equipment is utilized by experienced technicians and editors. These tests involve a multi-stage validation process. Our complex rating system is based on hundreds of well-founded measurements and benchmarks, which maintains objectivity. Further information on our test methods can be found here.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/One-of-the-most-powerful-mini-PCs-of-2025-Minisforum-MS-S1-Max-review-AMD-Strix-Halo-Power-128-GB-RAM-Radeon-8060S-for-professionals-AI.1124332.0.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "AMD gets PyTorch working on Windows",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/amd-gets-pytorch-working-on-windows/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "MSI MPG B650 Edge WiFi AMD AM5 ATX Motherboard $159.99 + Free Shipping",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18637801-msi-mpg-b650-edge-wifi-amd-am5-atx-motherboard-159-99-free-shipping",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Asus ROG Xbox Ally X – The Final Preview",
      "content": "The ROG Xbox Ally consoles launch on October 16th, marking the first time that Microsoft has released an official gaming handheld – albeit in heavy cooperation with Asus, makers of the original ROG Ally devices. The new ROG Xbox Ally and Ally X promise unique hardware and software improvements and could be priced aggressively, but can they compete against the Steam Deck, Switch 2 and a growing field of handheld gaming PCs?\n\nHere's what we know so far, based on our hands-on testing at Gamescom and a host of official announcements.\n\nThis is an Xbox – but not as you might expect. So what are they?\n\nTo be clear, these aren't proper handheld Xboxes that will play any Xbox game, despite the \"this is an Xbox\" branding. However, they're still capable handheld gaming machines that can play a huge number of PC games natively, or stream Xbox games, either from an Xbox console or Microsoft's cloud streaming service.\n\nROG Xbox Ally X – Images View 7 Images\n\nCompared to the old Ally devices, the new Xbox models have been spruced up with new AMD Z2 processors and a streamlined Windows operating system. That should translate into better performance and a step forward in usability, and could make these the best Steam Deck competitors so far.\n\nTwo models with significantly different levels of performance\n\nIt's worth knowing the difference between the two Xbox Ally models arriving in October: the Xbox Ally and the fancier Xbox Ally X.\n\nFirst up, the vanilla Xbox Ally offers Steam Deck level performance from its AMD Ryzen Z2 A chip, plus a higher-res screen, easier SSD upgradeability and wider game compatibility thanks to running Windows out of the box. However, the Steam Deck is available in an OLED model, is easier to drive given its lower 800p resolution, and runs the sleeker, often more performant Steam OS.\n\nThe more interesting Xbox Ally X uses AMD's brand new Ryzen AI Z2 Extreme chip, which promises the best performance we've seen in a PC gaming handheld, some exclusive Xbox features and more capable hardware. That could make it the device of choice for enthusiasts able to justify its high price – something we'll discuss later.\n\nROG Xbox Ally X – Product Specifications Chipset AMD Ryzen AI Z2 Extreme Memory 24GB LPDDR5X-8000 Storage 1TB M.2 2280 SSD Display 7\" 1080p 120Hz VRR IPS I/O 1x USB 4 Type-C, 1x USB 3.2 Gen 2 Type-C, 1x UHS-II MicroSD card reader, 1x 3.5mm Wireless WiFi 6E + Bluetooth 5.4 Battery 80Wh Dimensions 291x122x51mm Weight 715g\n\nHow fast will the new handhelds be?\n\nSo what will that performance difference look like? Looking at the hardware, the four Zen 2 cores and 8 RDNA 2 cores of the Xbox Ally ought to deliver roughly Steam Deck level performance at 15W, or a bit more at its maximum 20W TDP.\n\nMeanwhile, the Ryzen AI Z2 Extreme's eight Zen 5 cores and 16 RDNA 3.5 graphics cores should be significantly faster than the Steam Deck. Some early Z2 Extreme test results show a ballpark 15% performance advantage over the Z1 Extreme ROG Ally at maximum power. Interestingly, these results also show higher performance differentials at lower wattages, as well as lower power draw at matched frame-rates, suggesting that overall efficiency has improved.\n\nHowever, both Asus and Microsoft have said there's plenty of optimisation work to be done, so we'll need to wait for final hardware, software and drivers – and a chance to perform our own testing – before we can say anything definitive about performance.\n\nROG Xbox Ally – Product Specifications Chipset AMD Ryzen Z2 A Memory 16GB LPDDR5X-6400 Storage 512GB M.2 2280 SSD Display 7\" 1080p 120Hz VRR IPS I/O 2x USB 3.2 Gen 2 Type-C, 1x UHS-II MicroSD card reader, 1x 3.5mm Wireless WiFi 6E + Bluetooth 5.4 Battery 60Wh Dimensions 291x122x51mm Weight 670g\n\nAI features coming in 2026 – for the Xbox Ally X only\n\nThe Z2 Extreme also comes with dedicated AI hardware, with 50 TOPs of AI throughput, so what is it capable of? Out of the box, not much, but a few tantalising AI features are scheduled for 2026.\n\nThe most interesting is Auto SR, an FSR1-like post-process upscaling that has a fixed latency cost. This was an impressive option when it debuted on Snapdragon X Windows laptops, and this will be the first time it's more widely available.\n\nMicrosoft's marketing also notes a highlight reel feature, which promises to automatically generate clips of boss takedowns or multi-kills for social media.\n\nA thicker, comfier design with upgraded controls and impressive specs\n\nLet's talk about design. First, the vanilla Xbox Ally has a white shell, while the Xbox Ally X comes in black. Despite their varying capabilities, both Xbox Ally models are the same size, at 291 x 122 x 51mm, with a thicker design than the OG ROG Ally. That allows for proper Xbox-style controls and a comfier grip. Both models come with the same seven-inch 1080p 120Hz VRR LCD display as the original ROG Ally too.\n\nThe Xbox Ally X is 45g heavier than the standard Xbox Ally. A lot of that is due to a battery upgrade, from 60 watt hours to 80 watt hours, and the inclusion of dual-motor Impulse triggers. The X also upgrades one of the two USB-C 3.2 Gen 2 ports on the vanilla model to USB 4, unlocking full speed access to DisplayPort 2.1 and Thunderbolt 4 devices – including external graphics cards.\n\nInside, the vanilla model gets 512GB of storage and 16GB of 6400MT/s RAM, while the X gets 1TB of storage and 24GB of 8000MT/s RAM. Both models use large M.2 2280 SSDs for easy upgradeability, rather than the smaller 2230 standard used on the original ROG Ally and Steam Deck. Finally, both devices come with a 65W charger and a stand in the box.\n\nWhat we said about the original Asus ROG Ally X The Asus ROG Ally X is simply the best handheld gaming PC on the market\n\nright now. With more and faster memory and double the battery as the\n\noriginal Ally, the Ally X will run any modern game without dying in an\n\nhour and a half. – Jacqueline Thomas, Jul 21, 2024 Score: 9 Read the full Asus ROG Ally X review.\n\nA redesigned interface, a wider launcher and more software updates\n\nAs well as some promising hardware, the Xbox Ally uses a new \"Xbox Full Screen Experience\" that promises a more gamepad-friendly interface and better performance than prior Windows gaming handhelds. For example, you can log in using the gamepad, rather than needing to enter your PIN via touch or use a fingerprint reader, which loads you into a full-screen Xbox app. Gamepad controls should work everywhere here, and you can hold down the dedicated Xbox button to quickly swap between games and apps or close them. There are also phone-style touch gestures to access the Game Bar or change apps.\n\nThe core Xbox app has seen some key improvements, including new library features that automatically bring in games from other launchers like Steam or GOG – though you'll need to actually install these games in the desktop Windows mode. However, once installed, you can see all of your games in the same place.\n\nXbox Ally X - Xbox App UI View 7 Images\n\nMicrosoft is also debuting an evolution on the Steam Deck Verified idea, with separate ratings for handheld optimisation and performance. The Handheld Optimised badge indicates a game that has a suitable interface and gamepad controls, while the Windows Performance Fit shows whether it'll run in excess of 30 or 60fps on your device.\n\nThere's even a Gaming Copilot that you should be able to ask for tips to progress in-game, or check your achievement progress, with the AI receiving a screenshot of your current game to help you. If you've used an ROG Ally handheld before, you'll be familiar with the Asus Armoury Crate app. This software will still be used for changing performance profiles, showing overlays and so on.\n\nAnd while Microsoft imagines that you'll spend most of your time in the new handheld-optimised mode, you can still access a full version of Windows 11, which spools up services like the desktop window manager that don't start in the default gaming mode. Afterwards, you can reboot to ensure you're getting full performance, or go straight back into the gaming UI if you're expecting to dip back and forth a few times.\n\nHands-on impressions from Gamescom\n\nSo how does the Xbox Ally actually play? Based on our hands-on time at Gamescom, both machines feel capable. They sport the same bright and responsive LCD display as the original Xbox Ally, but with improved ergonomics that are more in line with the Steam Deck than the Switch 2. The new user experience felt a little buggy, requiring a reboot on our first tester unit, but the improved launcher, touch gestures and fast game switching felt good and saved time.\n\nWith their Windows performance optimisations, plus extra power under the hood on Xbox Ally X, these could be some of the most capable gaming handhelds on the market… but we'll have to wait for final hardware and software before rendering a verdict.\n\nOfficial Xbox Ally pricing has finally been announced\n\nMicrosoft has confirmed that the lower-end Xbox Ally will retail for $599, while the full-fat Xbox Ally X will cost $999. In the UK, the Ally X will cost £799, while the Ally will cost £499. The EU reference prices are similar, at €899 and €599.\n\nThese prices suggest the Xbox Ally could be a shade cheaper than other Z2 Extreme-powered handhelds, like the MSI Claw A8 at £850 (about $1160) or the Lenovo Legion Go 2 at $1350, but still painful compared to, say, $650 for the most expensive Steam Deck.\n\nAs gaming gets even more expensive across the board, this handheld Xbox is a pricey privilege, no doubt. For its part, Microsoft is doubtlessly incentivized to keep prices as low as possible, in order to reap Game Pass subscriptions and game sales from a wider install base, but Asus is also looking to justify its long investment into PC handhelds – and create meaningful separation from its existing ROG Ally models. Ultimately, the value question comes down to the quality of the software and the strength of the silicon, both of which are still unknown quantities.\n\nAre you planning to get the Xbox Ally or another handheld gaming PC? Yes, I'm getting the ROG Xbox Ally X Yes, the ROG Xbox Ally Yes, the Lenovo Legion Go 2 or MSI Claw A8 No, I'm waiting for the next Steam Deck No, I'm not interested in handhelds Answer See Results\n\nCan Microsoft's secret sauce elevate the Xbox Ally consoles above other PC handhelds?\n\nIt feels like the Xbox Ally handhelds were originally pitched as offering both unique hardware and software, but consumers will be able to pick up other Z2 Extreme handhelds from MSI and Lenovo around the same time – though the Xbox-style controls remain unique. The unique software promise is time-limited too, as Microsoft has said that its handheld optimisations will arrive on other PC handhelds, and the revised launcher is already available on existing devices.\n\nRegardless, the Xbox Ally and Ally X could be the best value PC gaming handhelds at their respective price points, and it'll be fascinating to see whether Microsoft's console expertise pushes them to the top of what is an increasingly competitive field.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/asus-rog-xbox-ally-x-the-final-preview",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Asus ROG Xbox Ally and Ally X available for pre-order worldwide – U.S. pricing starts at $599 and $999 respectively",
      "content": "The ROG Xbox Ally and Ally X, the latest handheld consoles developed by Asus and Microsoft, are now officially available for pre-order. The ROG Xbox Ally X is priced at $999, while the standard ROG Xbox Ally comes in at $599. Customers can reserve either of the models by visiting Asus’ or Microsoft’s respective online stores,\n\nSeveral third party retailers are also taking pre-orders including Amazon, Best Buy, Ant Online, and Walmart. Interestingly, the ROG Xbox Ally X is going to sell exclusively on Best Buy, while the ROG Xbox Ally is open for other retailers.\n\nPre-order on Best Buy Asus ROG Xbox Ally X: $999 at Best Buy The Asus ROG Xbox Ally X is the latest handheld console made in collaboration with Microsoft. It comes with AMD's newest Ryzen AI Z2 Extreme processor and a special Xbox-based UI optimized for handhelds.\n\nPre-order on Best Buy Asus ROG Xbox Ally : $599 at Best Buy The Asus ROG Xbox Ally is the latest handheld console made in collaboration with Microsoft. It features more modest hardware compared to the ROG Xbox Ally X including the Ryzen Z2 A processor, 16GB of memory and a 512GB SSD.\n\nCustomers in the U.S. who pre-order through the Asus Shop will also be enrolled in a sweepstake where they get a chance to win various accessories including the ROG Strix Arion external SSD enclosure, an ROG Raikiri controller, a set of ROG Cetra Wireless earbuds, an ROG Bulwark TV dock/USB-hub or an ROG Xbox Ally 2-in-1 premium case\n\nFirst showcased in June at Microsoft's Xbox Games showcase, the ROG Xbox Ally and ROG Xbox Ally X adopt large, contoured grips inspired by Xbox controllers, as well as features like impulse triggers and a dedicated Xbox button. The consoles boot into an Xbox-optimized interface which is layered over Windows 11 and offer support for third party game launchers.\n\nThe hardware differs significantly between the two as the standard Ally is built around an AMD Ryzen Z2 A chip with 16GB of LPDDR5X-6400 memory, a 512GB SSD, and a 60Wh battery. The more powerful Ally X steps up with the Ryzen AI Z2 Extreme processor, 24GB LPDDR5X-8000 memory, a 1TB SSD, and an 80Wh battery. Both models feature the same 7-inch 1080p 120Hz IPS panel with FreeSync Premium support, Wi-Fi 6E, Bluetooth 5.4, and dual USB-C ports (one of which on the Ally X supports USB 4/Thunderbolt 4).\n\nBoth handhelds are also available for pre-order across multiple international markets with pricing set at €599 / £499 / $799 CAD / 1,599 AUD for the standard Ally and €899 / £799 / $1,299 CAD / 1,799 AUD for the Ally X. Pre-orders are live across various countries including Australia, Canada, most of Europe, the UK, Japan, South Korea, Mexico, the Middle East, and parts of Asia, with some markets offering only one of the two models.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/video-games/handheld-gaming/asus-rog-xbox-ally-and-ally-x-available-for-pre-order-worldwide-u-s-pricing-starts-at-usd599-and-usd999-respectively",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Redisearch New Vector Quantization",
      "content": "We are excited to announce that Redis Query Engine now supports Quantization and Dimensionality Reduction for vector search. This is based on an Intel and Redis partnership leveraging Intel SVS-VAMANA with multiple compression strategies.\n\nRedis has always been the go-to choice for agents and applications demanding blazing-fast performance, and our community knows this comes with a direct relationship: memory usage equals operational cost. As vector search has become increasingly popular for powering AI applications, from recommendation engines to powering specialized agents, we've consistently heard from developers and operations teams about a common challenge: the memory footprint of high-dimensional embeddings can quickly become a budget concern.\n\nHere's the reality: when you're running vector search workloads on Redis, every vector stored in memory directly impacts your infrastructure costs. A typical deployment with millions of 768-dimensional vectors (common with modern embedding models) can consume hundreds of gigabytes of RAM. For organizations scaling their AI applications, this memory requirement often becomes the primary cost driver.\n\nBut what if you could dramatically reduce that memory footprint without sacrificing the search quality and performance that made you choose Redis in the first place? With a comprehensive compression strategy - Quantization and Dimensionality Reduction, we can reduce the total memory footprint by 26–37%, while preserving search quality and performance.\n\nDive into the compression technology\n\nModern vector similarity search faces a fundamental challenge: as datasets scale to billions of vectors with hundreds or thousands of dimensions, memory footprint becomes the dominant deployment constraint and memory bandwidth emerges as a primary performance bottleneck. Traditional approaches to million-scale similarity search have struggled with the dual pressure of maintaining search accuracy while managing memory footprint, particularly when dealing with the random memory access patterns inherent in graph-based algorithms.\n\nFor context, storing 100 million vectors with 1536 dimensions in single-precision floating-point format requires 572GB of memory. This scale makes traditional exact nearest vector search (like using FLAT index in Redis) impractical, necessitating approximate methods that can operate within reasonable memory constraints while maintaining acceptable accuracy levels.\n\nIntel SVS-VAMANA foundations\n\nSVS-VAMANA combines the Vamana graph-based search algorithm, introduced by Subramanya et al., with Intel’s compression technology: LVQ and LeanVec.\n\nVamana is similar to HNSW in its use of proximity graphs for efficient search. Unlike HNSW’s multi-layered structure, Vamana builds a single-layer graph and prunes edges during construction based on a tunable parameter. Both algorithms are capable of achieving very strong search performance but require substantial memory for both the graph structure and full-precision vectors, making compression essential for large-scale deployments.\n\nTraditional vector compression methods face critical limitations in the context of graph-based search:\n\nProduct Quantization (PQ) limitations: while popular for similarity search, it presents significant challenges for in-memory graph-based indices. When used for high-throughput graph search, PQ either requires keeping full-precision vectors in memory for re-ranking (defeating compression benefits) or accepts severely degraded accuracy.\n\nScalar Quantization (SQ) challenges: standard scalar quantization with global bounds for entire datasets or per-dimension bounds fails to efficiently utilize available quantization levels, resulting in suboptimal compression ratios.\n\nPrecision meets performance: The LVQ & LeanVec advantage\n\nThe key idea behind Locally-adaptive Vector Quantization (LVQ) is to apply per-vector normalization and scalar quantization, adapting the quantization bounds individually for each vector. This local adaptation ensures efficient use of the available bit range, resulting in high-quality compressed representations (see Figure 1). LVQ introduces minimal decompression overhead, enabling fast, on-the-fly distance computations. Its advantage lies in this balance: it significantly reduces memory bandwidth and storage requirements while maintaining high search accuracy and throughput, outperforming traditional methods.\n\nFigure 1: Empirical distributions of vector values in the deep-96-1M dataset\n\nFor 95% of the vectors, global and per-dimension normalization methods utilize only about 60% and 75% of the available value range, respectively. In contrast, LVQ normalization more closely approximates a uniform distribution, effectively using the full range and resulting in a more accurate and representative encoding. Figure from LVQ paper.\n\nLeanVec builds on top of LVQ by first applying linear dimensionality reduction, then compressing the reduced vectors with LVQ. This two-step approach significantly cuts memory and compute costs, enabling faster similarity search and index construction with minimal accuracy loss—especially for high-dimensional deep learning embeddings.\n\nThe compression gains are substantial. LVQ achieves a four-fold reduction of the vector size while maintaining search accuracy. A typical 768-dimensional float32 vector that normally requires 3072 bytes can be reduced to just a few hundred bytes through this quantization process— this is how we can achieve 51–74% reduction in the graph index and 26-37% overall memory footprint reduction.\n\nTwo-level vector compression\n\nFor high-dimensional vectors (like the 768-dimensional embeddings common in large language models) or when maximum accuracy is required, both techniques use a two-level approach (see Figure 2). .\n\nLVQ’s two-level compression works by first quantizing each vector individually to capture its main structure, then encoding the residual error—the difference between the original and quantized vector—using a second quantization step. This allows fast search using only the first level, with the second level used for re-ranking to boost accuracy when needed. In LVQ, LVQB₁xB₂ means the first level uses B₁ bits and the second level uses B₂ bits per vector dimension. For example, LVQ4x8 uses 4 bits for the main vector and 8 bits for the residual (i.e., a total of 12 bits per dimension).\n\nSimilarly, LeanVec uses a two-level approach: the first level reduces dimensionality and applies LVQ to speed up candidate retrieval, while the second level applies LVQ to the original high-dimensional vectors for accurate re-ranking. For example, LeanVec4x8 means the reduced-dimension vector is quantized with LVQ using 4 bits per dimension, while the original high-dimensional vector is quantized with 8 bits per dimension. Note that the original full-precision embeddings were never used by either LVQ or LeanVec, as both operate entirely on compressed representations.\n\nFigure 2. Two-level vector compression implementation with LVQ and LeanVec\n\nOptimized for performance\n\nIs this performant, since I’m doing all this computation? The engineering achievement is in the performance optimization. LeanVec improves search performance with a two-fold acceleration while operating on compressed vectors. The core performance optimization behind LVQ and LeanVec lies in their ability to maintain the sub-millisecond search times that Redis is known for while operating on a fraction of the original memory footprint. This is possible because graph-based similarity search is memory-bound—most of the time is spent fetching vectors from memory rather than computing distances. LVQ and LeanVec preserve enough accuracy that the slight increase in search effort doesn’t outweigh the gains from reduced memory bandwidth usage. As a result, the improved memory efficiency directly translates into faster search performance.\n\nA second key factor is LVQ’s extremely low decompression overhead. Techniques like Turbo LVQ optimize the memory layout of quantized vectors to align with SIMD-friendly access patterns. Instead of storing dimensions sequentially, Turbo LVQ permutes the layout to pack 128 dimensions into 64 bytes, allowing 16 dimensions to be unpacked with just two assembly instructions—compared to seven in traditional layouts. This enables highly efficient distance computations, effectively amortizing the cost of compression during search.\n\nTogether, these optimizations allow Redis powered by SVS-VAMANA with LVQ and LeanVec to deliver fast, accurate search with a much smaller memory footprint—without ever needing to access the original full-precision vectors. Check out the rule of thumbs and what compression option suits your use case.\n\nLeveraging Redis asynchronous vector indexing\n\nRedis vector indexes use a tiered index architecture designed to offload the heavy computational work required for inserting and deleting elements in graph-based vector indexes such as HNSW and the new SVS-VAMANA.\n\nIn this architecture, the Redis main thread, which is responsible for handling client requests, does not perform the full insertion directly. Instead, it temporarily stores new vectors in a bounded buffer. Background worker threads then asynchronously insert those vectors into the underlying graph structure (see Figure 3).\n\nThe same principle applies to deletions: the main thread only marks vectors as deleted, while background threads handle the expensive task of repairing graph links and reclaiming memory.\n\nA similar approach is applied when running queries, which is particularly beneficial for vector searches. By handling the heavy computation asynchronously, Redis ensures that the main thread remains responsive to other client requests. This design significantly increases both write and read throughput and enables efficient memory management, without compromising index quality or query accuracy.\n\nRedis Query Engine integrates SVS-VAMANA using this tiered index mechanism. As a result, users can sustain heavy vector write workloads while Redis continues to remain responsive, serving queries in parallel and consistently over dynamically evolving data.\n\nFigure 3. Redis Query Engine tiered index architecture\n\nBenchmark comparisons for memory, throughput, latency and ingestion time\n\nTo assess SVS-VAMANA performance we’ve used the vector-db-benchmark tool, focusing on high precision and high concurrency scenarios, across 3 different datasets, and 3 different CPU vendors (Intel, AMD, and ARM) using GCP, given SVS behaves differently, i.e. uses different algorithms, depending on the underlying hardware.\n\nOn Intel chips SVS-VAMANA can use LVQ and LeanVec, as described before. As a rule of thumb, you should use LVQ for vectors with dimensions lower than 768 and, use LeanVec for vectors with dimensions equal to or larger than 768. The benchmark methodology followed this recommendation.\n\nOn non Intel CPUs, i.e. AMD and ARM, and on Redis Open Source version, compression will fall back to SQ8. Developers can opt-in for install the SVS optimizations on Redis Open Source follow this guide.\n\nWe’ll deep dive into memory savings, throughput, latency improvements, and ingestion tradeoffs taking into account all 3 CPU types when the data is relevant for ARM/AMD, and always compare to the HNSW baseline. Ultimately, we want you to fully understand the benefits and tradeoffs of SVS-VAMANA after reading the following section.\n\nMemory gains\n\nOne of the most immediate benefits of the new Redis-Intel SVS compression is memory efficiency. Across all datasets we tested (detailed list on the appendix), SVS-VAMANA consistently delivered 26–37% total memory savings compared to HNSW, and when looking only at the vector index, the reductions were even more dramatic: 51–74% less memory used.\n\nChart 1. SVS-VAMANA memory efficiency vs. HNSW\n\nChart 1 highlights memory efficiency gains of SVS-VAMANA LVQ8 config per dataset compared to HNSW across multiple datasets and embedding sizes (Laion 512d, Cohere 768d, and DBpedia 1536d) for FP32 data. In every case, SVS-VAMANA significantly reduced total memory usage by up to 37%.\n\nIn practice, this means you can reduce your cloud footprint, or run larger workloads on the same hardware. SVS-VAMANA compression not only optimizes query performance, it also turns memory into a lever for cost efficiency, ensuring your vector search can scale sustainably.\n\nAccuracy trade-off, is there any?\n\nA natural concern with any new indexing method is whether accuracy suffers compared to HNSW. Our testing shows that it doesn’t: all SVS-VAMANA variants (LeanVec and LVQ) can match the high precision levels of HNSW, also confirming what Intel has documented in their Scalable Vector Search deep dive.\n\nChart 2. Precision vs. QPS for SVS-VAMANA and HNSW\n\nFrom Chart 2 we can see that at t every precision point—from ~0.92 up to 0.99—SVS-VAMANA tracks alongside HNSW in accuracy while consistently delivering higher queries per second (QPS). The advantage is visible both at lower precision targets, where SVS-VAMANA pulls ahead aggressively, and at higher precision levels, where it sustains up to 1.5× better throughput at the same precision.\n\nWith SVS-VAMANA you get HNSW-grade accuracy, plus the performance and efficiency benefits on top.\n\nUnlocking QPS and latency improvements with SVS-VAMANA\n\nBeyond memory savings while keeping accuracy, SVS-VAMANA unlocks meaningful performance improvements in real-world search workloads. Let’s start with throughput: which cases have benefits, and which ones not that much.\n\nChart 3. SVS-VAMANA vs. HNSW throughput per dataset\n\nOn FP32 datasets, throughput gains are substantial: up to 144% higher QPS on COHERE (768d, dot product) and up to 60% on DBpedia (1536d, cosine). These improvements are visible across the recommended SVS-VAMANA quantization method for vectors with dimensions equal to or higher than 768, LeanVec 4x8, and hold even at high precision thresholds (see Chart 3). You can check the COMPRESSION options and datasets details in the appendix.\n\nNot all datasets behave the same, however. On LAION (512d, cosine), SVS-VAMANA yields only marginal improvements—0–15% in most cases, with some degradation. It’s worth noting that these results still come with a reduction in memory footprint, which can be attractive to customers even in cases without significant performance gains. This makes SVS-VAMANA most appealing for medium-to-large embedding workloads (768–3,072 dimensions), where both memory and compute savings amplify its advantages.\n\nThroughput is only half the story. For many production workloads, what really matters is latency—how fast results come back when systems are under load. Looking at p50 and p95 latencies, SVS-VAMANA consistently outperforms HNSW, cutting response times even as query concurrency scales.\n\nOn FP32, the gains are striking: on Cohere (768d, dot product), SVS-VAMANA reduced latency by 60% at p50 and 57% at p95 compared to HNSW. DBpedia (1536d, cosine) also showed strong improvements, with 46% lower p50 and 36% lower p95, for high concurrency benchmarks (see Chart 4).\n\nChart 4. SVS-VAMANA vs. HNSW search latency per dataset for FP32 datatype\n\nWith FP16 (Chart 5), the picture is consistent but the drops are smaller, with the largest advantage being on Cohere dataset dropping latencies up to 43%. 43%/40% on Cohere, and 11% on DBpedia. This is expected: SVS-VAMANA accelerates search primarily by reducing memory accesses, so when each vector already consumes less memory (as with FP16) the relative advantage naturally shrinks. Even then, SVS-VAMANA still delivers meaningful latency improvements where workloads are memory-bound.\n\nChart 5. SVS-VAMANA vs HNSW search latency per dataset for FP16 datatype\n\nAcross datasets, these reductions translate into faster responses for end users under heavy traffic. While LAION (512d) shows little to no change on latency while still reducing memory, the medium- and high-dimensional workloads—Cohere and DBpedia—demonstrate that SVS-VAMANA not only improves throughput but also keeps response times reliably low at scale while saving memory at the same time.\n\nFor all data-dependent compression methods, the benefits naturally vary across datasets, as they are influenced by factors such as dimensionality, the structure of the embedding manifold, and overall compressibility. Cohere and DBpedia, being higher-dimensional, show greater benefits than LAION. Differences between Cohere and DBpedia likely stem from variations in their embedding manifolds. Even though LAION shows smaller gains, it still maintains performance while using significantly fewer bits—half compared to float16 and a quarter compared to float32—demonstrating the strength of LVQ compression.\n\nIngestion trade-offs – computing compression\n\nThe main cost of SVS-VAMANA lies in ingestion. To illustrate it, we’ve selected 2 datasets, one for each SVS-VAMANA variant (LAION for SVS LVQ8 and DBPEDIA for LeanVec 4x8), see Chart 6 and Chart 7.\n\nChart 6. SVS-VAMANA LVQ upload time overhead vs. HNSW\n\nChart 7. SVS-VAMANA LeanVec upload time overhead vs. HNSW\n\nAs shown in Chart 7, index construction times are higher than HNSW. On x86 platforms (Intel and AMD) the overhead is manageable.\n\nSVS-VAMANA is currently not optimized for ingestion performance, so slowdowns compared to HNSW are expected. These differences stem from several factors, including the additional overhead introduced by vector compression, differences in the graph edge pruning strategies used in each algorithm, and the concurrency control approach used in SVS-VAMANA, which relies on a global lock during ingestion.\n\nIngestion with LeanVec is generally faster than with LVQ, primarily because search is significantly faster with LeanVec, which typically operates on dimensionally reduced vectors quantized with 4 bits per dimension—resulting in highly compressed representations. We plan to investigate these aspects further and work on targeted optimizations for future releases.\n\nFor Intel:\n\nLeanVec can accelerate upload times in some cases (e.g., up to 25% faster on Intel FP32), but it may also be up to 33% slower depending on the dataset. These differences stem mostly from how dataset characteristics like dimensionality, embedding structure, and compressibility influence the effectiveness of data-dependent compression methods.\n\ncan accelerate upload times in some cases (e.g., up to on Intel FP32), but it may also be up to depending on the dataset. These differences stem mostly from how dataset characteristics like dimensionality, embedding structure, and compressibility influence the effectiveness of data-dependent compression methods. LVQ is generally slower, with ingestion times reaching up to 2.6× longer than HNSW.\n\nFor AMD, the fallback algorithm (SQ8) showcased either improvements on the upload time for FP32 or small regressions depending on the configuration. Nonetheless, and as mentioned above, the overhead is smaller.\n\nChart 8. ARM SVS-VAMANA SQ8 fallback upload time overhead vs. HNSW\n\nOn ARM, the story is different. Ingestion times can be 9× slower (see Chart 8) than HNSW, making SVS-VAMANA impractical on ARM platforms today. This gap is less about ARM hardware capabilities and more about the fact that SVS-VAMANA optimizations are primarily tuned for x86, and the fallback algorithm (SQ8) is not optimized for ARM. In other words, SVS-VAMANA and its fallback, isn’t yet optimized for ARM ingestion workloads.\n\nComparison with other CPUs. Choosing the right fit\n\nOur benchmarks show that the best algorithm depends on the underlying hardware, considering the regular quantization (SQ8 fallback) versus Intel optimizations. Both x86 (Intel and AMD) and ARM have strengths — but they shine in different ways.\n\nTo prove it, we’ve charted below (Charts 9 and 10) the achievable QPS at a 0.95 precision for the DBPEDIA dataset across Intel (c4), AMD (c4d), and ARM (c4a) instances on GCP. We also included an additional SVS-VAMANA configuration tuned for performance, LeanVec Dimensions/4, obtained by setting REDUCE, the target dimension used in the dimensionality reduction step, to 384 (i.e., dim/4 = 1536/4 = 384).\n\nChart 9. CPU RPS comparison for FP32 for SVS-VAMANA and HNSW\n\nChart 10. CPU RPS comparison for FP16 for SVS-VAMANA and HNSW\n\nThe results confirm a clear theme: the best algorithm depends heavily on the underlying hardware.\n\nOn x86 platforms, SVS-VAMANA really comes into its own. On Intel platforms, large performance gains are achieved by leveraging Intel's compression technologies, while on AMD, strong performance is enabled through the SQ8 fallback, delivering:\n\nHigher query throughput — up to 144% improvement over HNSW in some datasets.\n\n— up to 144% improvement over HNSW in some datasets. Lower latency — p50 and p95 reduced by up to 60%.\n\n— p50 and p95 reduced by up to 60%. Smaller memory footprint — 26–37% less overall memory, 51–74% less index memory.\n\nFor high-throughput, FP32 workloads where performance and memory efficiency matter most, x86 + SVS-VAMANA is the recommended configuration.\n\nFurthermore, the performance-tuned LeanVec dim/4 configuration improves ingestion time, always outperforming HNSW.\n\nOn ARM platforms, the story is different. ARM already runs HNSW exceptionally well — in fact, our benchmarks show ARM HNSW can even edge ahead of x86 HNSW by ~10% in search throughput depending on the use-case. For teams standardizing on ARM infrastructure, this means you can achieve competitive performance with HNSW at lower cost and power efficiency, and that the fallback algorithm on ARM, which is Scalar Quantization 8, is not yielding better results than HNSW.\n\nToday, SVS-VAMANA on ARM does not yet match its x86 performance. Upload times are longer, and query throughput lags behind Intel and AMD. This is primarily due to the lack of ARM-native vector acceleration for SVS-VAMANA and an optimized implementation of the fallback algorithm used (SQ8 like mentioned previously). However, ARM’s excellent HNSW results make it a strong choice for production workloads until further optimizations arrive.\n\nTakeaway:\n\nIf you are on x86, SVS-VAMANA offers top-tier speed, latency, and memory savings—delivering major gains on Intel and strong results on AMD even without the optimized version.\n\nIf you’re on ARM, HNSW continues to be the go-to option — delivering competitive search performance and excellent efficiency.\n\nDifferences in configurations and comparison of benefits for LVQ & LeanVec\n\nFrom a developer perspective, new Redis SVS-VAMANA integrates seamlessly into your existing Redis workflows. When creating vector indices with FT.CREATE, you can now specify the new SVS-VAMANA algorithm along with compression options directly in your VECTOR field definitions.\n\nAs mentioned in the previous sessions, the ultimate gains came from Intel hardware optimizations (LVQ and LeanVec), while in others platforms the option always falls in a regular quantization method using 8-bit (SQ8). For developers, it’s transparent, since the optimization is triggered in Redis Enterprise as soon as the Intel hardware is detected.\n\nCode on Redis Open Source, using regular SQ8 and leverage the optimizations for Intel on Enterprise. Please check the documentation instructions on how to trigger the optimizations also on Redis Open Source.\n\nNote:\n\nHere's how simple it is to enable COMPRESSION using SVS-VAMANA:\n\n```\n\nFT.CREATE myindex SCHEMA\n\nembedding VECTOR SVS-VAMANA 6\n\nCOMPRESSION LVQ8\n\nTYPE FLOAT32\n\nDIM 768\n\nDISTANCE_METRIC COSINE\n\n```\n\nOn the query side, your application code remains unchanged—the same search commands return the same high-quality results, just with improved memory efficiency. The quantization happens transparently during indexing, and Redis Query Engine handles all the complexity of encoding, storage, and fast similarity computation.\n\nWhether you're working with FLOAT16 or FLOAT32 vectors, compression is supported across both data types, giving you the flexibility to choose the precision that best fits your application requirements while still benefiting from the memory savings.\n\nIn order to understand better what compression to use, it’s important to understand the different embedding options and applications for a given use case see Figure 4.\n\nCommon embedding types & their characteristics\n\nFigure 4. Decision tree for selecting the right quantization\n\nDifferent embedding models create vectors with distinct properties that affect quantization and compression performance:\n\nText Embeddings (OpenAI, BERT, Cohere, SentenceTransformers): These models typically produce 384 to 1536-dimensional vectors that are dense and semantically rich.\n\nImage Embeddings (CLIP, ResNet, ViT): Usually exceeding 1024 dimensions, these vectors exhibit higher variability and noise due to the complexity of visual data.\n\nMultimodal Embeddings (CLIP, unified models): These vectors combine text and image characteristics, creating mixed data patterns that often require more sophisticated quantization strategies to preserve recall across different modalities.\n\nCustom Embeddings (anomaly detection, feature engineering): Domain-specific vectors may need calibration or profiling to determine optimal quantization settings, but SVS-VAMANA adaptive approach typically handles these variations effectively.\n\nThe SVS-VAMANA with LVQ and LeanVec configurations reflects the number of bits allocated per dimension at each level of compression.\n\nNaming convention: LVQ<B₁>x<B₂>\n\nB₁: Number of bits per dimension used in the first-level quantization.\n\nB₂: Number of bits per dimension used in the second-level quantization (residual encoding).\n\nLVQ Applies per-vector normalization and scalar quantization LVQ8, LVQ4x4, LVQ4x8 LeanVec Combines dimensionality reduction with LVQ, applying quantization after reducing vector dimensions. LeanVec4x8, LeanVec8x8\n\nAs an example, we elaborate in Table 1 with different embedding types and use cases, and the suggested Compression to use. Depending on the type and dimensionality chosen, these numbers may vary considerably.\n\nEmbedding Category Optimal Use Cases Example Embeddings (Dimension) Compression Strategy Index Reduction Text Embeddings Document search, semantic similarity, Q&A systems Cohere embed-multilingual-v3 (1024) OpenAI text-embedding-ada-002 (1536) LeanVec 4x8 (following REDUCE adjustments if required) ~3x compression Image Embeddings Visual similarity search, content-based retrieval ResNet-152 (2048) LeanVec 4x8 ~3x compression Multimodal Cross-modal search, unified content systems CLIP ViT-B/32 (512) LVQ8 ~3.5x compression Custom/Domain Anomaly detection, specialized feature matching Cohere embed-v3 (1024) LeanVec 4x8 ~3x\n\nTable 1. Compression strategy per use-case.\n\nWhile optimizing the memory footprint using vector compression, it may require slightly changing the `SEARCH_WINDOW_SIZE` (equivalent to HNSW’s `EF_RUNTIME`) to match search accuracy. See the entire list of advanced parameters for tuning the Index and Query in our documentation.\n\nBuilding the future\n\nOn our road to sustain our tripod of speed, accuracy and cost, we will keep extending the coverage of a comprehensive compression, leveraging multiple techniques for other indexes, such as HNSW, and index types. As part of our partnership with Intel, we plan to incorporate other SVS library optimizations into the Redis Query Engine. One key enhancement is the use of LeanVec for handling out-of-distribution (OOD) queries—a major challenge in cross-modal retrieval—through a query-aware dimensionality reduction approach.\n\nMulti-vectors support is also part of the roadmap, which brings different challenges in keeping memory footprint and computing efficiency.\n\nKey takeaways\n\nProduct quantization and scalar quantisation with global constants alone don't do the magic If you’re on x86, SVS-VAMANA unlocks the best combination of speed, latency, and memory savings. If you’re on ARM, HNSW continues to be the go-to option — delivering competitive search performance and excellent efficiency. Rule of Thumb: Leverage LeanVec for high-dimensional vectors (>=768) while LVQ will be better suitable for smaller dimensionality vectors (<768)\n\nAcknowledgments\n\nWe would like to acknowledge the outstanding collaboration between Intel and Redis in bringing the Intel SVS library into the Redis Query Engine. From Intel, Aaron Lin, Ishwar Bhati, Mihai Capotă, Cecilia Aguerrebere, Ethan Glaser, Andreas Huber, Yue Jiao, Nikolay Petrov, Alexander Andreev, Maria Petrova, Sergey Yakovlev, Martin Dimitrov, Marcin Pozniak, Rafik Saliev, and Maria Markova contributed their deep expertise in optimization, quantization, and systems engineering. From Redis, Alon Reshef, Meirav Grimberg, Dor Forer, Omer Lerman, Adriano Amaral, Manvinder Singh, Pieter Caillaiu, Filipe Oliveira, Paulo Souza, Nathan Dunford, and Patrick Campbell worked closely to integrate and validate these capabilities. This joint effort has resulted in significant memory savings and performance improvements, advancing the state of vector search within Redis.\n\nAppendix: Datasets and compression used\n\nWe used datasets representing various use cases.\n\nWe selected the following datasets to cover a wide range of dimensionalities and distance functions. This approach ensures that we can deliver valuable insights for various use cases, from simple image retrieval to sophisticated text embeddings in large-scale AI applications.\n\nDatasets Number of vectors Vector dimensionality Distance function Description laion-img-emb-512-1M-cosine 1,000,000 512 Cosine Image embeddings derived from the LAION-5B dataset. cohere-768-1M 1,000,000 768 Dot Product English Wikipedia embeddings generated with Cohere’s multilingual encoder. dbpedia-openai-1M-angular 1,000,000 1536 Cosine OpenAI’s text embeddings dataset of DBpedia entities, using the text-embedding-ada-002 model.\n\nTable 2. Datasets\n\nCompression configurations\n\nBelow you can find the index build and runtime configuration parameters used in our benchmarks, covering the different compression strategies evaluated.\n\nDuring the query stage of the benchmarks , EF_RUNTIME (for HNSW) and SEARCH_WINDOW_SIZE (for SVS-VAMANA) are automatically tuned during calibration until the search reaches 0.95 precision.\n\nVariation Compression Index Build Params Runtime Params HNSW None M = varied from 16 to 32; EF_CONSTRUCTION = 200 EF_RUNTIME varied to reach @0.95 precision in the benchmark tool. SVS-VAMANA LVQ8 LVQ8 GRAPH_MAX_DEGREE = varied from 32 to 64; CONSTRUCTION_WINDOW_SIZE = 200 SEARCH_WINDOW_SIZE calibrated to reach @0.95 precision in the benchmark tool. SVS-VAMANA LVQ4x8 LVQ4x8 GRAPH_MAX_DEGREE = varied from 32 to 64, CONSTRUCTION_WINDOW_SIZE = 200 SEARCH_WINDOW_SIZE calibrated to reach @0.95 precision in the benchmark tool. SVS-VAMANA LVQ4x4 LVQ4x4 GRAPH_MAX_DEGREE = varied from 32 to 64; CONSTRUCTION_WINDOW_SIZE = 200 SEARCH_WINDOW_SIZE calibrated to reach @0.95 precision in the benchmark tool. SVS-VAMANA LeanVec4x8 LeanVec4x8 GRAPH_MAX_DEGREE = varied from 32 to 64; CONSTRUCTION_WINDOW_SIZE = 200 SEARCH_WINDOW_SIZE calibrated to reach @0.95 precision in the benchmark tool. SVS-VAMANA LeanVec4x8-div/4 LeanVec4x8 (REDUCE = dim/4) GRAPH_MAX_DEGREE = varied from 32 to 64; CONSTRUCTION_WINDOW_SIZE = 200 SEARCH_WINDOW_SIZE calibrated to reach @0.95 precision in the benchmark tool.\n\nTable 3. Benchmarking configuration parameters.",
      "source": "Redis.io",
      "url": "https://redis.io/blog/tech-dive-comprehensive-compression-leveraging-quantization-and-dimensionality-reduction/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "ROG Xbox Ally and ROG Xbox Ally X Now Available for Pre-Order in Canada",
      "content": "KEY POINTS\n\nOrder now: Pre-orders for ROG Xbox Ally X and ROG Xbox Ally start at 8:00 p.m. ET on September 25, 2025, in select regions\n\nPre-orders for ROG Xbox Ally X and ROG Xbox Ally start at 8:00 p.m. ET on September 25, 2025, in select regions Serious gen-on-gen performance: AMD Ryzen™ AI Z2 Extreme and Z2 A processors offer exceptional gaming experiences and battery life improvements\n\n\n\n\n\nTORONTO, Sept. 25, 2025 (GLOBE NEWSWIRE) -- ASUS Republic of Gamers (ROG) today announced that pre-orders for the new ROG Xbox Ally and ROG Xbox Ally X handheld gaming console devices will begin in select markets at 8 p.m. ET (5 p.m. PT) on September 25, 2025, with pre-orders in other markets coming soon.\n\nDeveloped in partnership with Xbox, the ROG Xbox Ally and ROG Xbox Ally X offer exceptional ergonomics, a full-screen experience, and other standout features that marry the best of console and PC gaming in a cohesive package.\n\nLaunching globally on October 16, the ROG Xbox Ally and ROG Xbox Ally X are tailored to match individual playstyles. Pricing is set at an Estimated Retail Price (ERP) for each device:\n\nThe ROG Xbox Ally, the essential gaming handheld for the casual player to the avid enthusiast, will be available for C$799.\n\nThe ROG Xbox Ally X, the ultimate high-performance handheld gaming device built for the most demanding players, will be available for C$1,299.\n\nPre-orders are available today in Canada and select regions1. The ROG Xbox Ally pre-orders are available through Amazon, the ASUS Store, Best Buy, Canada Computers, EB Games, London Drugs, Memory Express, Staples, and Walmart, and will be available later at launch at Costco, MDG, the Microsoft Store, Newegg and Visions.\n\nThe ROG Xbox Ally X pre-orders are available through the ASUS Store and Best Buy, and later at launch on the Microsoft Store.\n\nThe ROG Xbox Ally is powered by an AMD Ryzen™ Z2 A Processor that delivers incredible energy efficiency, while the ROG Xbox Ally X boasts the new AMD Ryzen AI Z2 Extreme Processor for next-level performance in AAA titles. Both devices offer significant gen-on-gen improvements over the previous ROG Ally, giving gamers the best handheld Windows 11 gaming experiences available.\n\nFor more product details please visit ROG Xbox Ally X and ROG Xbox Ally.\n\nOrder now\n\nGamers in select regions can pre-order the ROG Xbox Ally and ROG Xbox Ally X from 8 p.m. ET (5 p.m. PT) on September 25, 2025. With unmatched ergonomics, a full-screen experience familiar to both console and Windows 11 gamers, an aggregated gaming library with access to installed games from leading PC storefronts, and more, these devices offer top-tier gaming performance and flexibility at a competitive price.\n\nAs a special launch promotion in Canada, the first 150 customers to pre-order the ROG Xbox Ally X on the ASUS Store will receive a complimentary ROG OMNI figurine2, valued at C$54.99.\n\nSerious gen-on-gen performance\n\nThe ROG Xbox Ally X features the new AMD Ryzen AI Z2 Extreme Processor for a perfect balance of performance and battery life. Combined with software optimizations from Xbox and Windows, the ROG Xbox Ally X delivers next-gen handheld performance.\n\nDuring testing on pre-release hardware, the ROG Xbox Ally X delivered up to 30% performance increase3 in Indiana Jones and the Great Circle and Doom: The Dark Ages compared to the previous-generation ROG Ally X. The battery endurance of the ROG Xbox Ally X gives it up to twice the battery life when playing Hollow Knight: Silksong4. As for the ROG Xbox Ally, performance is boosted up to 20% in Forza Horizon 5 and Gears of War: Reloaded5, and has up to 110% more battery life versus ROG Ally X6. Both the AMD Ryzen AI Z2 Extreme Processor and the AMD Ryzen Z2 A Processor are primed to take advantage of Radeon’s latest software suite for graphical and performance improvements, including AMD FidelityFX™ Super Resolution (FSR), Radeon Super Resolution (RSR), and AMD Fluid Motion Frames (AFMF) frame generation, with the latter offering up to 60% better frame rates for improved smoothness. The ROG Xbox Ally X also includes an onboard NPU to ensure it’s ready for AI features in games.\n\nThe ROG Xbox Ally series offers the power of Xbox, the craftsmanship of ROG, and the versatility of Windows all in one cohesive device.\n\nAVAILABILITY & PRICING\n\nThe ROG Xbox Ally is now available for pre-orders at C$799 available through Amazon, the ASUS Store, Best Buy, Canada Computers, EB Games, London Drugs, Memory Express, Staples, and Walmart, and will be available later at launch at Costco, MDG, the Microsoft Store, Newegg and Visions.\n\nThe ROG Xbox Ally X is now available for pre-orders at C$1,299 through the ASUS Store and Best Buy, and later at launch on the Microsoft Store.\n\nNOTES TO EDITORS\n\nASUS Homepage: https://www.asus.com/ca-en/\n\nROG Homepage: https://rog.asus.com/ca-en/\n\nROG Xbox Ally Series: https://rog.asus.com/ca-en/content/rog-xbox-ally/\n\nROG Xbox Ally: https://rog.asus.com/ca-en/gaming-handhelds/rog-ally/rog-xbox-ally-2025/\n\nROG Xbox Ally X: https://rog.asus.com/ca-en/gaming-handhelds/rog-ally/rog-xbox-ally-x-2025/\n\nROG Xbox Ally Series ASUS Store: https://shop.asus.com/ca-en/rog-xbox-ally-2025.html\n\nASUS Pressroom: http://press.asus.com\n\nASUS Canada Facebook: https://www.facebook.com/asuscanada/\n\nASUS Canada Instagram: https://www.instagram.com/asus_ca\n\nASUS Canada YouTube: https://ca.asus.click/youtube\n\nASUS Global X (Twitter): https://www.x.com/asus\n\nSPECIFICATIONS 7\n\nROG Xbox Ally X\n\nOperating System Windows 11 Home Ergonomics & input Contoured grips inspired by Xbox Wireless Controllers deliver all-day comfort, complete with impulse triggers for enhanced control.\n\n\n\nABXY buttons / D-pad / L & R impulse triggers / L & R bumpers / Xbox button / View button / Menu button / Command Center button / Library button / 2 x assignable back buttons / 2 x full-size analog sticks / HD haptics / 6-Axis IMU Processor AMD Ryzen™ AI Z2 Extreme Display 7” FHD (1080p) IPS, 500 nits, 16:9\n\n\n\n120Hz refresh rate\n\n\n\nAMD FreeSync™ Premium (Variable Refresh Rate)\n\n\n\nCorning® Gorilla® Glass Victus®\n\n\n\nCorning DXC Anti-Reflection Memory 24GB LPDDR5X-8000 Storage 1TB M.2 2280 SSD Wireless Wi-Fi 6E (2 x 2) + Bluetooth® 5.4 I/O ports 1 x USB4® with DisplayPort™ 2.1 / Power Delivery 3.0, Thunderbolt™ 4 compatible\n\n\n\n1 x USB 3.2 Gen 2 Type-C® with DisplayPort™ 2.1 / Power Delivery 3.0\n\n\n\n1 x UHS-II microSD card reader (supports SD, SDXC and SDHC; UHS-I with DDR200 mode)\n\n\n\n1 x 3.5mm Combo Audio Jack Battery 80Wh Color Black Size 290.8 x 121.5 x 50.7mm (W x D x H) (11.45” × 4.78” × 2.00”) Weight 715g (1.58 lbs) Includes ROG Xbox Ally X\n\n\n\n65W charger\n\n\n\nStand Estimated Retail Price (ERP) C$1,299 Where to buy (pre-orders) ASUS Store\n\n\n\nBest Buy\n\n\n\nROG Xbox Ally (2025)\n\nOperating System Windows 11 Home Ergonomics & input Contoured grips inspired by Xbox Wireless Controllers deliver all-day comfort.\n\n\n\nABXY buttons / D-pad / L & R Hall Effect analog triggers / L & R bumpers / Xbox button / View button / Menu button / Command Center button / Library button / 2 x assignable back buttons / 2 x full-size analog sticks / HD haptics / 6-Axis IMU Processor AMD Ryzen™ Z2 A Display 7” FHD (1080p) IPS, 500 nits, 16:9\n\n\n\n120Hz refresh rate\n\n\n\nAMD FreeSync™ Premium (Variable Refresh Rate)\n\n\n\nCorning® Gorilla® Glass Victus®\n\n\n\nCorning DXC Anti-Reflection Memory 16GB LPDDR5X-6400 Storage 512GB M.2 2280 SSD Wireless Wi-Fi 6E (2 x 2) + Bluetooth® 5.4 I/O ports 2 x USB 3.2 Gen 2 Type-C® with DisplayPort™ 1.4 / Power Delivery 3.0\n\n\n\n1 x UHS-II microSD card reader (supports SD, SDXC and SDHC)\n\n\n\n1 x 3.5mm Combo Audio Jack Battery 60Wh Color White Size 290.8 x 121.5 x 50.7mm (W x D x H) (11.45” × 4.78” × 2.00”) Weight 670g (1.48 lbs) Includes ROG Xbox Ally\n\n\n\n65W charger\n\n\n\nStand Estimated Retail Price (ERP) C$799 Where to buy (pre-orders) Amazon\n\n\n\nASUS Store\n\n\n\nBest Buy\n\n\n\nCanada Computers\n\n\n\nEB Games London Drugs\n\n\n\nMemory Express\n\n\n\nStaples\n\n\n\nWalmart\n\n\n\nAbout ROG\n\nRepublic of Gamers (ROG) is an ASUS sub-brand dedicated to creating the world’s best gaming hardware and software. Formed in 2006, ROG offers a complete line of innovative products known for performance and quality, including motherboards, graphics cards, system components, laptops, desktops, monitors, smartphones, audio equipment, routers, peripherals and accessories. ROG participates in and sponsors major international gaming events. ROG gear has been used to set hundreds of overclocking records and it continues to be the preferred choice of gamers and enthusiasts around the world. To become one of those who dare, learn more about ROG at http://rog.asus.com.\n\n1 Pre-orders are available today Australia, Belgium, Canada, Czech Republic, Denmark, Finland, France, Germany, Hong Kong, Ireland, Italy, Japan, Mexico, Netherlands, New Zealand (ROG Xbox Ally only), Norway, Philippines, Poland, Portugal, Republic of Korea, Romania, Saudi Arabia, Singapore, Spain, Sweden, Switzerland (ROG Xbox Ally X only), Taiwan, Turkey, United Arab Emirates, United Kingdom, United States, and Vietnam.\n\nBoth ROG Xbox Ally handhelds will also launch on October 16 in Egypt, Greece, Hungary, Malaysia, India, Philippines, Indonesia, Slovenia, South Africa, Thailand, and Ukraine, with pre-orders starting today.\n\nMore pre-order opportunities are coming soon in other markets, including Brazil and China (ROG Xbox Ally X).\n\n2 Offer valid only for customers in Canada. Limited to the first 150 pre-orders of an ROG Xbox Ally X placed through the ASUS Store. Limit one (1) ROG OMNI figurine per customer, while supplies last. ASUS reserves the right to amend or cancel this promotion without prior notice.\n\n3 Tested in Indiana Jones and the Great Circle & Doom: The Dark Ages. Gameplay: 1080p, In-game default setting. Operating mode: Turbo, plugged in (AC) and on battery (DC).\n\n4 Tested in Hollow Knight: Silksong, 720p, FPS limit: 60, In-game graphics: low. Operating mode: Silent. The above comparison data is based on ROG Xbox Ally X (RC73XA, AMD Ryzen™ AI Z2 Extreme processor & 80Wh battery) vs. ROG Ally X (RC72LA, AMD Ryzen™ Z1 Extreme processor & 80Wh battery).\n\n5 Tested in Forza Horizon 5 and Gears of War: Reloaded. Gameplay: 720p, FPS limit: 60, In-game default settings. Operating mode: Performance, plugged in (AC) and on battery (DC)\n\n6 Tested in Hollow Knight: Silksong (720p, FPS limit: 60, in-game graphics: Low; operating mode: Silent) and Forza Horizon 5 (720p, FPS limit: 60, in-game default settings; operating mode: Performance)The above comparison data is based on ROG Xbox Ally (RC73YA, AMD Ryzen™ Z2 A processor & 60Wh battery) vs. ROG Ally (RC71L, AMD Ryzen™ Z1 processor & 40Wh battery).\n\n7 Specifications, content and product availability are all subject to change without notice and may differ from country to country. Actual performance may vary depending on applications, usage, environment and other factors. Full specifications are available at http://www.asus.com\n\nA photo accompanying this announcement is available at https://www.globenewswire.com/NewsRoom/AttachmentNg/c096f65e-05c5-4550-bd80-74b6cb61f84f",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/26/3156799/0/en/ROG-Xbox-Ally-and-ROG-Xbox-Ally-X-Now-Available-for-Pre-Order-in-Canada.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Macular Edema and Macular Degeneration Market Size to Worth USD 22.51 Billion by 2034",
      "content": "Ottawa, Sept. 26, 2025 (GLOBE NEWSWIRE) -- The global macular edema and macular degeneration market size was valued at USD 10.33 billion in 2024 and is predicted to hit around USD 22.51 billion by 2034, rising at a 7.34% CAGR, a study published by Towards Healthcare a sister firm of Precedence Research.\n\nThe Complete Study is Now Available for Immediate Access | Download the Sample Pages of this Report @ https://www.towardshealthcare.com/download-sample/5375\n\nAI Impact\n\nAI to the management and assessment of macular edema and macular degeneration. It involves deep learning (DL), which can be used effectively to diagnose AMD, predict the risk of hospitalization in the short term, and determine the need for injections in the next 2 years. In addition, deep learning methods can adjust anti-VEGF treatment options with higher accuracy than human experts. In addition, the use of ML models can provide patients with accurate predictions of VA response to treatment, which can increase patient compliance with treatment under appropriate conditions.\n\nThe development and use of intelligent tools have the potential to increase the efficiency of DME management and provide patients with the most appropriate treatment, thereby reducing the cost of treating diseases for retinal doctors and providing significant cost savings to patients through better care will help support the growth of the macular edema and macular degeneration market.\n\nMarket Overview and Industry Potential\n\nThe macular edema and macular degeneration market is expected to see sophisticated growth owing to increased diabetes cases and lifestyle changes in recnt years. Also, the aging population factor is gaining traction with investment firms and analysts. Furthermore, advanced therapies like anti-VEGF have contributed to the industry's potential consumer shift towards drug therapies instead of surgeries.\n\nIndustry Opportunity\n\nThe development of long-acting drug delivery systems may facilitate strategic positioning for manufacturing firms during the forecast period. Also, the patients are seeking long-acting drugs instead of the frequent injections, which are costly and painful. Furthermore, the manufacturers can gain substantial market advantages by developing sustained-release formulations, which are likely to transform patient compliance.\n\nMarket Restraint\n\nThe higher cost and complex approval regulations are expected to create industry hurdles for the drug manufacturers in the coming years. Moreover, the treatment, like anti-VEGF, requires sterile handling and maximum clinical trials, which can create growth barriers for future market growth.\n\nYou can place an order or ask any questions, please feel free to contact us at sales@towardshealthcare.com\n\nMacular Edema and Macular Degeneration Market Key Regional Analysis:\n\nWhat has made North America the Leader in Industry in Recent Years?\n\nNorth America held the dominant share of the macular edema and macular degeneration market in 2024, owing to increased awareness of age-related vision disorders in recent years. Furthermore, the country has modern and innovative technology access, which is contributing to the growth of the industry. Also, the global population has actively shifted their treatments to the North America region owing to the advanced healthcare infrastructure in the current period.\n\nEurope Emerges as an Upcoming Beneficial Market\n\nEurope is expected to expand notably during the forecast period, owing to a sudden shift towards the early screening programs and greater investment in the ophthalmic research by major pharmaceutical brands. Also, the regional countries like the U.K., Germany, and others have been pushing the healthcare initiatives, including eye care, with greater insurance and health services in recent years.\n\nMacular Edema and Macular Degeneration Market Segmentation Analysis\n\nBy Treatment Type:\n\nWhy Did the Drug Therapy Segment Dominate the Market in 2024?\n\nThe drug therapy segment held the largest share of the macular edema and macular degeneration market in 2024 due to its offerings as non-invasive, fast-acting, and repeatable solutions. Furthermore, drugs like anti-VEGF and corticosteroids have received major industry attention in recent years by targeting abnormal blood vessel growth. Also, the individuals are seen as demanding these types of therapies instead of the surgical approaches in the current period.\n\nBy Application Type:\n\nHow Does the Macular Degeneration Segment Maintain Its Dominance in the Current Industry?\n\nThe macular degeneration segment held the largest share of the market in 2024 because it affects a much larger aging population compared to macular edema, which often occurs as a complication of diabetes or retinal conditions. Age-related macular degeneration (AMD) is one of the leading causes of vision loss in people over 50, creating a massive patient base.\n\nBy End User Type:\n\nWhy Did the Hospitals Segment Dominate the Market in 2024?\n\nThe hospitals segment held the largest share of the macular edema and macular degeneration market in 2024 because patients with macular diseases often require advanced Imaging, injections, and multidisciplinary care that smaller clinics cannot always provide. Hospitals are equipped with OCT (optical coherence tomography) machines, laser devices, and specialized staff for retinal treatment, making them the go-to centers for diagnosis and therapy.\n\nBecome a valued research partner with us - https://www.towardshealthcare.com/schedule-meeting\n\nMacular Edema and Macular Degeneration Market Top Companies\n\nKubota Pharmaceutical Holdings Co. Ltd\n\nAlimera Sciences Inc\n\nAbbVie Inc\n\nNovartis AG\n\nF. Hoffmann-La Roche Ltd\n\nRegeneron Pharmaceuticals Inc.\n\nRegen X Bio Inc.\n\nGlaxoSmithKline Plc\n\nBayer AG\n\nBausch Health Companies Inc.\n\nWhat is Going Around the Globe?\n\nIn July 2024, Genentech, a member of the Roche Group, announced the reactivation of Susvimo, 100 mg/mL, for the intravitreal treatment of U.S. patients with wet eye disease due to implantation following spontaneous resolution or neovascularization. Age-related macular degeneration (AMD) conditions (U.S.).\n\nIn May 2024, Biocon Biologics Ltd (BBL), an integrated global biosimilars company and a subsidiary of Biocon Ltd., announced that the U.S. Food and Drug Administration (FDA) approved the initial submission of Yesafili, the company's biosimilar replacement for aflibercept.\n\nIn October 2024, Kubota Vision Inc., a clinical-stage specialty ophthalmology company and a wholly owned subsidiary of Kubota Pharmaceutical Holdings Co., Ltd., announced that a private clinical trial conducted at Shinshu University Hospital has advanced to the next phase of testing eyeMO*1. It is a portable, low-cost, home, remote, and in-office ophthalmology device for monitoring eye disease.\n\nIn June 2024, Faricimab for the treatment of neovascular age-related macular degeneration and diabetic macular edema: from preclinical studies to phase 3 results.\n\nBrowse More Insights of Towards Healthcare:\n\nThe global direct-to-consumer laboratory testing market size began at US$ 3.47 billion in 2024 and is forecast to rise to US$ 3.78 billion by 2025. By the end of 2034, it is expected to surpass US$ 8.16 billion, growing steadily at a CAGR of 8.94%.\n\nsize began at US$ 3.47 billion in 2024 and is forecast to rise to US$ 3.78 billion by 2025. By the end of 2034, it is expected to surpass US$ 8.16 billion, growing steadily at a CAGR of 8.94%. The pathology laboratories market size is calculated at US$ 380.95 billion in 2024, grew to US$ 412.19 billion in 2025, and is projected to reach around US$ 834.44 billion by 2034. The market is expanding at a CAGR of 8.2% between 2025 and 2034.\n\nsize is calculated at US$ 380.95 billion in 2024, grew to US$ 412.19 billion in 2025, and is projected to reach around US$ 834.44 billion by 2034. The market is expanding at a CAGR of 8.2% between 2025 and 2034. The global diagnostic testing market size reached US$ 203.3 billion in 2024 and is anticipate to increase to US$ 209.48 billion in 2025. By 2034, the market is forecasted to achieve a value of around US$ 274.53 billion, growing at a CAGR of 3.04%.\n\nsize reached US$ 203.3 billion in 2024 and is anticipate to increase to US$ 209.48 billion in 2025. By 2034, the market is forecasted to achieve a value of around US$ 274.53 billion, growing at a CAGR of 3.04%. The U.S. immunoassay market size is calculated at US$ 8.99 billion in 2024, grew to US$ 9.43 billion in 2025, and is projected to reach around US$ 14.22 billion by 2034. The market is expanding at a CAGR of 4.93% between 2025 and 2034.\n\nsize is calculated at US$ 8.99 billion in 2024, grew to US$ 9.43 billion in 2025, and is projected to reach around US$ 14.22 billion by 2034. The market is expanding at a CAGR of 4.93% between 2025 and 2034. The global point of care infectious disease testing market size is calculated at US$ 11.9 billion in 2024, grew to US$ 12.42 billion in 2025, and is projected to reach around US$ 17.75 billion by 2034. The market is expanding at a CAGR of 4.34% between 2025 and 2034.\n\nMacular Edema and Macular Degeneration Market Segmentation:\n\nBy Treatment Type\n\nDrug Therapy\n\nLaser Treatment\n\nBy Application\n\nMacular Edema\n\nDiabetic Macular Edema (DME)\n\nCystoid Macular Edema (CME)\n\nMacular Degeneration\n\nDry age-related macular degeneration\n\nWet age-related macular degeneration\n\nBy End User\n\nHospitals\n\nClinics\n\nOthers\n\n\n\nBy Region\n\nNorth America U.S. Canada\n\nEurope U.K. Germany France\n\nAsia Pacific China India Japan South Korea\n\nMiddle East & Africa\n\nLatin America\n\nImmediate Delivery Available | Buy This Premium Research @ https://www.towardshealthcare.com/price/5375\n\nAccess our exclusive, data-rich dashboard dedicated to the healthcare market - built specifically for decision-makers, strategists, and industry leaders. The dashboard features comprehensive statistical data, segment-wise market breakdowns, regional performance shares, detailed company profiles, annual updates, and much more. From market sizing to competitive intelligence, this powerful tool is one-stop solution to your gateway.\n\nAccess the Dashboard: https://www.towardshealthcare.com/access-dashboard\n\nAbout Us\n\nTowards Healthcare is a leading global provider of technological solutions, clinical research services, and advanced analytics, with a strong emphasis on life science research. Dedicated to advancing innovation in the life sciences sector, we build strategic partnerships that generate actionable insights and transformative breakthroughs. As a global strategy consulting firm, we empower life science leaders to gain a competitive edge, drive research excellence, and accelerate sustainable growth.\n\nYou can place an order or ask any questions, please feel free to contact us at sales@towardshealthcare.com\n\nEurope Region: +44 778 256 0738\n\nNorth America Region: +1 8044 4193 44\n\nAPAC Region: +91 9356 9282 04\n\nWeb: https://www.towardshealthcare.com\n\nOur Trusted Data Partners\n\nPrecedence Research | Statifacts | Towards Packaging | Towards Automotive | Towards Food and Beverages | Towards Chemical and Materials | Towards Consumer Goods | Towards Dental | Towards EV Solutions | Nova One Advisor | Healthcare Webwire | Packaging Webwire | Automotive Webwire\n\nFind us on social platforms: LinkedIn | Twitter | Instagram | Medium | Pinterest",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/26/3157083/0/en/Macular-Edema-and-Macular-Degeneration-Market-Size-to-Worth-USD-22-51-Billion-by-2034.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Overclocked Ryzen MAX 395 : Unlocking its True Power & Absolute Limits",
      "content": "\n\nWhat happens when you take a processor already designed to push boundaries and push it even further? The AMD Ryzen AI Max Plus 395, with its 16 cores, 32 threads, and integrated Radeon 8060SIG iGPU, is no ordinary chip, it’s a powerhouse built for versatility. But in a world where performance enthusiasts are never satisfied with “good enough,” we decided to see just how far this processor could go. By cranking up its CPU and GPU clocks, tweaking its thermal design power (TDP), and fine-tuning every possible setting, we unlocked a level of performance that’s as thrilling as it is unexpected. The results? Let’s just say the combination of raw power and the compact Beink GTR9 mini PC delivered a ride that was nothing short of wild.\n\nBelow ETA Prime reveals the highs, lows, and surprises of overclocking the Ryzen AI Max Plus 395. You’ll discover how this compact setup managed to deliver desktop-level performance, the delicate balance between heat management and power, and whether the integrated Radeon 8060SIG iGPU can truly hold its own in demanding gaming and creative workloads. Along the way, we’ll share the benchmarks, real-world gaming tests, and the challenges of pushing hardware to its limits, all while staying within the constraints of a mini PC. If you’ve ever wondered what happens when innovative hardware meets the relentless pursuit of performance, this coverage is for you. Sometimes, the best stories are the ones where the limits are redefined.\n\nKey Features of the Ryzen AI Max Plus 395\n\nTL;DR Key Takeaways : The AMD Ryzen AI Max Plus 395, paired with the Beink GTR9 mini PC, offers a compact yet powerful platform with 16 cores, 32 threads, and an integrated Radeon 8060SIG iGPU, suitable for gaming, productivity, and creative workloads.\n\nOverclocking experiments increased CPU boost clocks to 5.3 GHz, GPU clock speeds to 3100 MHz, and TDP to 180 watts, achieving a balance between performance gains and thermal constraints.\n\nPerformance benchmarks, including Geekbench 6, Cinebench R24, and 3DMark Time Spy, showed measurable improvements, highlighting the processor’s scalability under optimized conditions.\n\nGaming tests demonstrated the integrated Radeon 8060SIG iGPU’s ability to handle demanding titles like Forza Horizon 5, Doom: The Dark Ages, and Cyberpunk 2077 at high settings with technologies like FidelityFX Super Resolution (FSR).\n\nThermal management was critical due to increased heat output during overclocking, with the CPU peaking at 84.9°C, emphasizing the importance of effective cooling solutions in compact systems like the Beink GTR9 mini PC.\n\nThe Ryzen AI Max Plus 395 stands out as a high-performance processor tailored for demanding tasks. Its base clock of 5.1 GHz and integrated Radeon 8060SIG iGPU make it a versatile choice for users seeking a balance between CPU and GPU performance. When paired with the Beink GTR9 mini PC, the system provides advanced BIOS options, allowing users to fine-tune performance settings. This combination delivers desktop-level power in a small form factor, making it ideal for overclocking experiments.\n\nWhat makes this processor particularly appealing is its ability to handle a wide range of applications, from gaming to content creation. The integrated Radeon 8060SIG iGPU offers respectable graphics performance, while the advanced BIOS features of the Beink GTR9 allow users to push the hardware further. This compact yet capable setup is a testament to how modern processors can deliver high performance without requiring a large footprint.\n\nOverclocking Methodology\n\nTo explore the full potential of the Ryzen AI Max Plus 395, we focused on three critical areas of overclocking:\n\nCPU Boost Clocks: Increased from the default 5.1 GHz to 5.3 GHz, providing faster processing speeds for demanding tasks.\n\nIncreased from the default 5.1 GHz to 5.3 GHz, providing faster processing speeds for demanding tasks. GPU Clock Speeds: Raised to 3100 MHz, enhancing the performance of the integrated Radeon 8060SIG iGPU for gaming and graphical workloads.\n\nRaised to 3100 MHz, enhancing the performance of the integrated Radeon 8060SIG iGPU for gaming and graphical workloads. TDP Adjustment: Increased to 180 watts, allowing the processor to sustain higher performance levels under heavy loads.\n\nThese adjustments were achieved using a combination of advanced BIOS settings and third-party tuning software. Optimizing the fan curves was a crucial step to ensure thermal stability during the overclocking process. By carefully balancing performance gains with heat management, we achieved a stable configuration suitable for benchmarking and real-world applications.\n\nRyzen AI Max 395 Overclocking Demonstration\n\nCheck out more relevant guides from our extensive collection on AMD Ryzen AI that you might find useful.\n\nPerformance Benchmarks and Observations\n\nOverclocking the Ryzen AI Max Plus 395 resulted in measurable improvements across various benchmarks. These tests provided insights into how the processor scales under optimized conditions:\n\nGeekbench 6: Both single-core and multi-core scores showed noticeable improvements, reflecting enhanced efficiency and processing power.\n\nBoth single-core and multi-core scores showed noticeable improvements, reflecting enhanced efficiency and processing power. Cinebench R24: Rendering performance saw modest gains, showcasing the CPU’s ability to handle intensive creative workloads.\n\nRendering performance saw modest gains, showcasing the CPU’s ability to handle intensive creative workloads. 3DMark Time Spy: Incremental increases in total, CPU, and GPU scores highlighted the impact of overclocking on graphics performance.\n\nWhile the performance gains were not dramatic, they demonstrated the processor’s ability to scale effectively when pushed beyond its stock settings. These results underscore the Ryzen AI Max Plus 395’s potential for users who require additional performance for specific tasks.\n\nGaming Performance and Real-World Applications\n\nTo evaluate the practical benefits of overclocking, we tested the system with several popular games. The results highlighted the capabilities of the integrated Radeon 8060SIG iGPU:\n\nForza Horizon 5: Delivered smooth gameplay at 4K extreme settings, showcasing the iGPU’s ability to handle graphically demanding scenarios.\n\nDelivered smooth gameplay at 4K extreme settings, showcasing the iGPU’s ability to handle graphically demanding scenarios. Doom: The Dark Ages: Ran seamlessly at 1440p with FidelityFX Super Resolution (FSR) enabled, boosting frame rates while maintaining visual quality.\n\nRan seamlessly at 1440p with FidelityFX Super Resolution (FSR) enabled, boosting frame rates while maintaining visual quality. Cyberpunk 2077: Achieved playable performance at 1440p with ray tracing ultra settings and FSR frame generation, demonstrating the system’s capability to handle innovative graphics technologies.\n\nThese gaming tests revealed that the Radeon 8060SIG iGPU, when paired with advanced upscaling technologies like FSR, can deliver a satisfying gaming experience even at higher resolutions. This makes the Ryzen AI Max Plus 395 a viable option for gamers who prioritize compact systems without sacrificing performance.\n\nThermal Management and Power Considerations\n\nOverclocking inevitably increases power consumption and heat output, and the Ryzen AI Max Plus 395 was no exception. By raising the TDP to 180 watts, the processor maintained peak performance during heavy workloads. However, this came at the cost of higher temperatures, with the CPU peaking at 84.9°C during stress tests. Effective cooling solutions, such as high-performance thermal paste and optimized airflow, were essential to prevent thermal throttling and ensure system stability.\n\nThe compact design of the Beink GTR9 mini PC presented additional challenges in managing heat. Despite these limitations, the system performed reliably under sustained loads, demonstrating the importance of balancing performance with thermal efficiency.\n\nChallenges and Future Testing Directions\n\nWhile overclocking the Ryzen AI Max Plus 395 delivered measurable performance gains, the improvements were moderate due to the constraints of the Beink GTR9’s compact design. The limited thermal headroom and power delivery capabilities of the mini PC prevented more aggressive overclocking. Nonetheless, the processor’s stock performance remains impressive, particularly for an integrated graphics unit.\n\nLooking ahead, further testing could explore alternative operating systems, such as Steam OS, to evaluate the system’s versatility. Additionally, subjecting the processor to more demanding scenarios, including 4K gaming and advanced productivity tasks, could provide deeper insights into its capabilities. These future experiments will help uncover the full potential of the Ryzen AI Max Plus 395 and its suitability for various use cases.\n\nMedia Credit: ETA PRIME\n\n\n\nLatest Geeky Gadgets Deals\n\nSome of our articles include affiliate links. If you buy something through one of these links, Geeky Gadgets may earn an affiliate commission. Learn about our Disclosure Policy",
      "source": "Geeky Gadgets",
      "url": "https://www.geeky-gadgets.com/ryzen-ai-max-plus-395-overclocking-performance/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Heavy Hand: Free-market US Tested As Trump Takes Stakes In Private Companies",
      "content": null,
      "source": "International Business Times",
      "url": "https://www.ibtimes.com/heavy-hand-free-market-us-tested-trump-takes-stakes-private-companies-3784508",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Microsoft’s new AI feature will organize your photos automatically",
      "content": "Microsoft has begun testing a new AI-powered feature in Microsoft Photos, designed to categorize photos automatically on Windows 11 systems.\n\nDubbed Auto-Categorization, it is currently limited to sorting screenshots, receipts, identity documents, and notes, and it's rolling out to Copilot+ PCs across all Windows Insider channels with Microsoft Photos version 2025.11090.25001.0 or higher.\n\nMicrosoft says the feature utilizes a language-agnostic AI model that identifies document types regardless of the language used in the image. It works by grouping photos into predefined folders automatically, based on their visual content, such as handwritten notes, receipts, or printed documents.\n\nThe Photos app will help users find categorized images instantly, using the categories in the left navigation sidebar or the Search bar to locate them quickly. Users will also be able to change categories manually or \"provide feedback to improve accuracy.\"\n\n\"This release brings a powerful new feature on Copilot+ PCs that leverages AI to organize photos into categories for easier recall,\" Microsoft senior product manager Ronnie Myers said in a Friday blog post.\n\n\"Auto-Categorization automatically detects and organizes your photo collection into meaningful categories like screenshots, receipts, identity documents, and notes using AI. It's designed to save time, reduce clutter, and make your photo library easier to navigate.\"\n\nBleepingComputer reached out to a Microsoft spokesperson to ask whether this AI feature sends any information to Microsoft's servers or uses a local AI model, but a response was not immediately available.\n\nPhotos Auto-Categorization (Microsoft)\n\n​Today, the company has also started rolling out super resolution to AMD and Intel Copilot+ PCs, an AI-powered feature that enhances and enlarges images up to eight times the original size.\n\nIn March, Redmond added the Copilot button at the top of the Photos Viewer to provide editing tips and offer framing suggestions.\n\nSeveral months later, in June, Windows 11 Insiders with Copilot+ PCs also began testing an improved photo search feature with natural language and Relight, a feature that adds dynamic lighting controls to images.\n\nIn an effort to expand the reach of Copilot to more users, Microsoft is also testing new AI features in Windows 11 File Explorer, rolling out Copilot Chat to Office applications for Microsoft 365 business customers who are on a paid plan, and will automatically install the Microsoft 365 Copilot app on Windows devices outside the EEA region that have the Microsoft 365 desktop client apps.\n\nMore recently, Redmond began rolling out its AI-powered Gaming Copilot to select Windows 11 systems and announced that Notepad is getting free AI-powered text writing capabilities on Copilot+ PCs with Windows 11.",
      "source": "BleepingComputer",
      "url": "https://www.bleepingcomputer.com/news/microsoft/microsofts-new-ai-feature-will-organize-your-photos-automatically/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Tired of shader compilation screens? Microsoft is rolling out its own solution, but we won't feel the benefits immediately",
      "content": "Last month, Microsoft introduced Advanced Shader Delivery, a mechanism that claims to solve one of the biggest annoyances PC gamers face these days: shader compilation. Although the technology will initially be limited to the Asus ROG Xbox Ally handhelds and games purchased through the Xbox app, an update to Agility SDK means that other vendors and merchants can now get started on supporting it too.\n\nMicrosoft's Agility software development kit (SDK) is a collection of tools that game developers can use to implement the latest DirectX features, without having to wait for them to be integrated into Windows itself. In the latest 1.618 version, Agility now supports Advanced Shader Delivery, which was announced last month.\n\nThe rather unassuming name is for a complex database system that will hopefully be the ultimate solution to all problems relating to shader compilation. Modern 3D graphics involve tens of thousands of different shaders, and APIs such as DirectX, Vulkan, or Metal generate them in a common format. For your graphics card to be able to process them, they need to be compiled specifically for that hardware.\n\nFor gaming PCs, that process is carried out by the GPU drivers, and it's why your CPU's fan suddenly goes wild when you load up certain games. Depending on when and how the compilation stage has been implemented by a game's developer, you can either get a long, grinding stage before you even get to the main menu or problems during gameplay as the drivers struggle to compile shaders that have been missed.\n\nAdvanced Shader Delivery solves all of this by removing the whole compilation process from your PC's hands (well, processors) and doing it 'offline', i.e. by the game developers themselves. The idea is to have a database that stores the compiled shaders for any given game, for every hardware configuration that's able to run it.\n\nYou really don't want to skip the shader compilation.... (Image credit: GSC Game World)\n\nThen, when you download a game from the likes of Steam, the pre-compiled shaders are bundled with it. And hey presto! No lengthy compilation screens, no screaming CPU fans, no shader stutters mid-battle.\n\nConsole gamers already enjoy this because that's how it's done for PlayStation, Switch, and Xbox games. However, the database only needs to deal with one or two hardware setups, so it's a much easier affair to manage. With gaming PCs, the sheer number of different GPUs that can run any given game makes it a much larger challenge.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nTo simplify the process as much as possible, AMD, Intel, and Nvidia are providing the offline compilers for developers to use, and Microsoft has developed a set of APIs for digital storefronts to integrate into their installers. So when you fire up your newly downloaded game for the first time, it checks the database for the correct pre-compiled shaders to use.\n\nGames that handle shader compilation in the background might not benefit from Advanced Shader Delivery (Image credit: Sony Interactive Entertainment)\n\nWhether the entire PSDB (pre-compiled shader database) is part of the game's download or just a relevant subset isn't clear, but I suspect that the first stores and games to support Advanced Shader Delivery will probably go with the former. That means the size of the download will be larger, but for many PC gamers, that will be an acceptable trade-off for long loading times and stutters.\n\nAs things currently stand, the first store to host PSDBs for its games will be Microsoft's Xbox app, and even, only for the Asus ROG Xbox Ally and Xbox Ally X handhelds. That's just two hardware configurations, so it's not hard to see why the first iteration of the system is so limited.\n\nFor every other game store, we've got a long wait on our hands. Firstly, we need game developers to integrate the Advanced Shader Delivery system (which will be simple in some cases and a major hassle in others), then we need Valve, GOG, Epic, Ubisoft, et al to do the same.\n\nI suspect that we won't see it making an appearance until we're well into 2026, at the earliest, and even then, it will probably just be added to new releases or older ones that are still very popular (and would significantly benefit). Super-fast load times and a dearth of shader stutter are two advantages that consoles have over gaming PCs, so anything that can be done to even the playing field is a must-have, even if it takes a while to get here.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/graphics-cards/tired-of-shader-compilation-screens-microsoft-is-rolling-out-its-own-solution-but-we-wont-feel-the-benefits-immediately/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Bitsum ParkControl Pro 5.5.0.8",
      "content": "Description: ParkControl is Pro Windows app to adjust CPU core parking and heterogenous processor scheduling settings.\n\nPro Benefits\n\nBitsum Dynamic Boost\n\nAutomatically switch power plans when your PC enters and leaves the idle state\n\nPower Plan change Notifications\n\nNotifications of when and what process changed your active power plan (image)\n\nSupport Bitsum’s Independent Innovation\n\nYour support enables us to create new tools, and maintain our existing ones!\n\nIntroduction to CPU Core Parking\n\nCPU Parking is a low-power sleep state (C6) supported by most modern processors and operating systems. It dynamically disables CPU cores in an effort to conserve power when idle. Unfortunately, this power saving comes at a price: Latency when CPUs need unparked to execute code.\n\nInitially, core parking was controlled entirely by the operating system. The aggressive core parking of Windows led to a great deal of inefficiency during bursting CPU loads. Intel moved core parking control onto the chip in the Skylake generation, and AMD followed, but still the parameters of the Windows power plans are set to aggressively park CPU cores. Even the default ‘High Performance’ power plan is not immune. The new ‘Ultra Performance’ power plan copies what Bitsum did with our own ‘Bitsum Highest Performance’ power plan and finally disables core parking entirely.\n\nParkControl (and Process Lasso) not only let one more easily configure CPU core parking and frequency scaling, but also allow for dynamic entrance into a higher performance power plan. For instance, with Process Lasso, you can automatically enter ‘Bitsum Highest Performance’ will you start a game, then go back to ‘Balanced’ when you exit.\n\nParkControl has Dynamic Boost to allow you to set active and idle power plans. Process Lasso has a similar feature with its IdleSaver.\n\nEfficacy of Disabling Core Parking\n\nEmpirical evidence shows that disabling CPU core parking can make a tangible improvement in system performance. There are many factors that will determine precisely how effective it will be for a given situation. However, generally, Windows is too aggressive in its core parking, resulting in high latency during bursting CPU loads, stemming from the overhead of having to unpark CPU cores. Since bursting CPU loads are the most common type for many workloads, core parking can be a substantial drag on system performance and responsiveness.\n\nUsing ParkControl\n\nParkControl lets you easily set CPU core parking and frequency scaling parameters for both AC (plugged-in) and DC (battery) power states of your device.\n\nBoth CPU core parking and frequency scaling are power saving features of modern CPUs. CPU core parking is when cores are put into a sleep-like state when demand is low. Similarly, CPU frequency scaling allows the CPU base frequency to be lowered, again to conserve energy.\n\nEach power plan has its own settings, and can be selected via the power plan drop-down. When you select a power plan, the user interface will populate with that power plan’s settings. After making changes, click the ‘Apply’ button to save them. Use the ‘Make active’ button to switch the PC to that power plan.\n\nRelease Name: Bitsum ParkControl Pro 5.5.0.8\n\nSize: 3.6 MB\n\nLinks: HOMEPAGE – NFO – Torrent Search\n\nDownload: RAPiDGATOR",
      "source": "Rlsbb.to",
      "url": "https://post.rlsbb.to/bitsum-parkcontrol-pro-5-5-0-8/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "New Ryzen 7 H 255 performs almost identically to the 3-year old Ryzen 7 7840HS",
      "content": "The recently released Ryzen 7 H 255 may have the naming convention of a new Zen 5 CPU, but it's an old Zen 4 processor at heart with last generation performance and features.\n\n4 Reviews ← exclude selected types\n\nSystems shipping with the Ryzen 7 H 255 CPU like the GMK NucBox K12 are now becoming more widely available. After spending some time with a few of these systems, however, buyers may want to consider older and oftentimes cheaper Ryzen 7 7840HS, Ryzen 9 7940HS, or Ryzen 9 7940HS options instead. Performance is also similar to the Ryzen 9 8845HS as previously reported which is arguably far too many processor SKUs with few differentiating factors between them.\n\nOur benchmarks below show that the Ryzen 7 H 255 performs almost exactly the same as the aforementioned alternatives. All four processors share the same number of cores, threads, cache sizes, integrated Radeon 780M graphics, and even lack of an NPU. Indeed, the Ryzen 7 H 255 is really just a rebadged last generation Zen 4 processor despite it launching amongst a sea of faster and more efficient Zen 5 options.\n\nOverall performance is still very good for most HTPC or 4K streaming purposes especially when compared to outdated Iris Xe or Radeon RX Vega mini PCs. Users looking to save a bit of money will nonetheless find that the nearly 3-year old Ryzen 7 7840HS can offer better performance-per-dollar. The AMD CPU naming convention has changed since the days of the Ryzen 7 7840HS and so the Ryzen 7 H 255 isn't making it any easier for buyers who may be unaware of the recent changes.\n\nMore benchmarks and comparisons on the Ryzen 7 H 255 can be found on our review of the NucBox K12.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/New-Ryzen-7-H-255-performs-almost-identically-to-the-3-year-old-Ryzen-7-7840HS.1125386.0.html",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Kodiak Sciences (NASDAQ:KOD) Stock Rating Upgraded by Barclays",
      "content": "Kodiak Sciences (NASDAQ:KOD – Get Free Report) was upgraded by equities researchers at Barclays from an “underweight” rating to an “equal weight” rating in a report issued on Thursday, Marketbeat Ratings reports. The firm presently has a $17.00 price target on the stock, up from their previous price target of $7.00. Barclays‘s target price would indicate a potential upside of 7.59% from the company’s previous close.\n\nKOD has been the topic of a number of other research reports. HC Wainwright boosted their price target on shares of Kodiak Sciences from $3.00 to $5.00 and gave the company a “neutral” rating in a report on Monday, August 18th. JPMorgan Chase & Co. upgraded shares of Kodiak Sciences from an “underweight” rating to a “neutral” rating and set a $15.00 price target on the stock in a report on Thursday, August 14th. Finally, Jefferies Financial Group initiated coverage on shares of Kodiak Sciences in a research note on Monday, September 22nd. They issued a “buy” rating and a $15.00 price objective on the stock. One analyst has rated the stock with a Buy rating and three have assigned a Hold rating to the company. According to MarketBeat, Kodiak Sciences currently has a consensus rating of “Hold” and an average price target of $13.00.\n\nGet Kodiak Sciences alerts:\n\nGet Our Latest Analysis on Kodiak Sciences\n\nKodiak Sciences Price Performance\n\nKOD stock opened at $15.80 on Thursday. Kodiak Sciences has a 52-week low of $1.92 and a 52-week high of $19.39. The company’s 50 day simple moving average is $9.41 and its 200-day simple moving average is $5.60. The firm has a market capitalization of $834.56 million, a P/E ratio of -4.16 and a beta of 2.45.\n\nKodiak Sciences (NASDAQ:KOD – Get Free Report) last released its quarterly earnings results on Wednesday, August 13th. The company reported ($1.03) earnings per share (EPS) for the quarter, missing analysts’ consensus estimates of ($1.01) by ($0.02). Sell-side analysts predict that Kodiak Sciences will post -3.45 EPS for the current fiscal year.\n\nInstitutional Inflows and Outflows\n\nLarge investors have recently added to or reduced their stakes in the stock. Adage Capital Partners GP L.L.C. increased its stake in shares of Kodiak Sciences by 55.1% during the 2nd quarter. Adage Capital Partners GP L.L.C. now owns 2,055,707 shares of the company’s stock worth $7,668,000 after purchasing an additional 730,000 shares during the last quarter. Acadian Asset Management LLC increased its stake in shares of Kodiak Sciences by 27.0% during the 1st quarter. Acadian Asset Management LLC now owns 1,946,134 shares of the company’s stock worth $5,454,000 after purchasing an additional 413,821 shares during the last quarter. Jacobs Levy Equity Management Inc. increased its stake in shares of Kodiak Sciences by 90.1% during the 1st quarter. Jacobs Levy Equity Management Inc. now owns 685,198 shares of the company’s stock worth $1,922,000 after purchasing an additional 324,722 shares during the last quarter. Nantahala Capital Management LLC increased its stake in shares of Kodiak Sciences by 99.1% during the 1st quarter. Nantahala Capital Management LLC now owns 530,713 shares of the company’s stock worth $1,489,000 after purchasing an additional 264,100 shares during the last quarter. Finally, ICONIQ Capital LLC increased its stake in shares of Kodiak Sciences by 24.6% during the 1st quarter. ICONIQ Capital LLC now owns 1,266,563 shares of the company’s stock worth $3,559,000 after purchasing an additional 249,699 shares during the last quarter. Institutional investors and hedge funds own 89.06% of the company’s stock.\n\nKodiak Sciences Company Profile\n\n(Get Free Report)\n\nKodiak Sciences Inc, a clinical stage biopharmaceutical company, researches, develops, and commercializes therapeutics to treat retinal diseases. Its lead product candidate is tarcocimab tedromer (KSI-301), an anti-vascular endothelial growth factor antibody biopolymer that is in Phase IIb/III clinical study to treat wet age-related macular degeneration (AMD), as well as Phase III clinical study for the treatment of diabetic macular edema, naïve macular edema due to retinal vein occlusion, and non-proliferative diabetic retinopathy.\n\nFurther Reading\n\nReceive News & Ratings for Kodiak Sciences Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Kodiak Sciences and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/27/kodiak-sciences-nasdaqkod-stock-rating-upgraded-by-barclays/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Scalpers list ROG Xbox Ally X prices of $2500 after pre-orders for gaming handheld sell out",
      "content": "Some gamers scoff at the ROG Xbox Ally X price, but the Windows 11 handheld is selling out at retailers. The model with AMD Ryzen AI Z2 Extreme processor is out of stock on Asus and Microsoft stores. eBay scalpers are conducting ROG Xbox Ally X pre-orders with asking prices more than double MSRP.\n\n4 Reviews ← exclude selected types\n\nAfter endless speculation, ROG Xbox Ally and Xbox Ally X pre-orders have opened. Sadly for U.S. buyers, the costs of the gaming handhelds are higher than earlier reports had suggested. However, even with an ROG Xbox Ally X price of $999.99, retailers are struggling to fulfill orders. Scalpers are now taking advantage of the shortages, with eBay listings asking up to $2,500.\n\nROG Xbox Ally X availability varies across the world\n\nSo far, the ROG Xbox Ally X with AMD Ryzen AI Z2 Extreme processor is more popular than the $599.99 Xbox Ally. The official Xbox social media account posted a message on September 26th, notifying buyers that it was sold out on the Microsoft Store. Since then, the gaming handheld has also become unavailable on the Asus eShop. The bulk of the third-party supply may have gone to Best Buy, which is still taking pre-orders for the device.\n\nGlobal availability is more uneven, with the Windows 11 handheld sold out on the Asus UK store, but not in France. Gamers are debating whether demand is truly high or if low supplies are leading to the depleted stock levels. The excitement over the Lenovo Legion Go 2, which includes an AMD Ryzen Z2 Extreme variation, has led the manufacturer to cancel some pre-orders.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Scalpers-list-ROG-Xbox-Ally-X-prices-of-2500-after-pre-orders-for-gaming-handheld-sell-out.1126037.0.html",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Kodiak Sciences (NASDAQ:KOD) Upgraded by Wall Street Zen to “Hold” Rating",
      "content": "Wall Street Zen upgraded shares of Kodiak Sciences (NASDAQ:KOD – Free Report) from a sell rating to a hold rating in a research note released on Friday.\n\nOther research analysts also recently issued research reports about the company. Jefferies Financial Group started coverage on Kodiak Sciences in a research note on Monday, September 22nd. They issued a “buy” rating and a $15.00 price objective for the company. HC Wainwright upped their price objective on Kodiak Sciences from $3.00 to $5.00 and gave the company a “neutral” rating in a research note on Monday, August 18th. Barclays upgraded Kodiak Sciences from an “underweight” rating to an “equal weight” rating and upped their price objective for the company from $7.00 to $17.00 in a research note on Thursday. Finally, JPMorgan Chase & Co. upgraded Kodiak Sciences from an “underweight” rating to a “neutral” rating and set a $15.00 price objective for the company in a research note on Thursday, August 14th. One investment analyst has rated the stock with a Buy rating and three have given a Hold rating to the company. According to MarketBeat.com, the company presently has a consensus rating of “Hold” and an average target price of $13.00.\n\nGet Kodiak Sciences alerts:\n\nGet Our Latest Report on KOD\n\nKodiak Sciences Trading Up 0.8%\n\nNASDAQ KOD opened at $15.80 on Friday. The firm has a market capitalization of $834.56 million, a P/E ratio of -4.16 and a beta of 2.45. The business has a fifty day simple moving average of $9.41 and a 200 day simple moving average of $5.60. Kodiak Sciences has a 12 month low of $1.92 and a 12 month high of $19.39.\n\nKodiak Sciences (NASDAQ:KOD – Get Free Report) last released its quarterly earnings results on Wednesday, August 13th. The company reported ($1.03) EPS for the quarter, missing analysts’ consensus estimates of ($1.01) by ($0.02). As a group, sell-side analysts predict that Kodiak Sciences will post -3.45 EPS for the current fiscal year.\n\nInstitutional Inflows and Outflows\n\nSeveral large investors have recently added to or reduced their stakes in KOD. Ameriprise Financial Inc. boosted its stake in Kodiak Sciences by 26.1% in the 4th quarter. Ameriprise Financial Inc. now owns 38,624 shares of the company’s stock worth $384,000 after purchasing an additional 7,996 shares during the period. Millennium Management LLC boosted its stake in Kodiak Sciences by 148.7% in the 4th quarter. Millennium Management LLC now owns 81,991 shares of the company’s stock worth $816,000 after purchasing an additional 49,019 shares during the period. Two Sigma Investments LP boosted its stake in Kodiak Sciences by 25.2% in the 4th quarter. Two Sigma Investments LP now owns 49,406 shares of the company’s stock worth $492,000 after purchasing an additional 9,941 shares during the period. Public Employees Retirement System of Ohio boosted its stake in Kodiak Sciences by 183.9% in the 4th quarter. Public Employees Retirement System of Ohio now owns 14,759 shares of the company’s stock worth $147,000 after purchasing an additional 9,560 shares during the period. Finally, Aries Wealth Management bought a new position in Kodiak Sciences in the 1st quarter worth about $70,000. Institutional investors own 89.06% of the company’s stock.\n\nKodiak Sciences Company Profile\n\n(Get Free Report)\n\nKodiak Sciences Inc, a clinical stage biopharmaceutical company, researches, develops, and commercializes therapeutics to treat retinal diseases. Its lead product candidate is tarcocimab tedromer (KSI-301), an anti-vascular endothelial growth factor antibody biopolymer that is in Phase IIb/III clinical study to treat wet age-related macular degeneration (AMD), as well as Phase III clinical study for the treatment of diabetic macular edema, naïve macular edema due to retinal vein occlusion, and non-proliferative diabetic retinopathy.\n\nFeatured Stories\n\nReceive News & Ratings for Kodiak Sciences Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Kodiak Sciences and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/27/kodiak-sciences-nasdaqkod-upgraded-by-wall-street-zen-to-hold-rating/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Inside the Snapdragon X2 Elite: 20 Questions for Qualcomm’s Computing Chief",
      "content": "Table of Contents Market Successes for Snapdragon X So Far About Snapdragon Guardian Some SoC Particulars Market Positioning for the New X2 Chips Battery Life, and Why a Bigger NPU? Snapdragon X, Looking to 2029...\n\nDon't miss out on our latest stories. Add PCMag as a preferred source on Google.\n\nLAHAINA, MAUI—The highlight of this year's Snapdragon Summit is the unveiling of Qualcomm's second-generation Snapdragon X2 Arm laptop processors, including a new \"Extreme\" tier of chips that looks poised to take on AMD's, Intel's, and Apple's best. PCs with the new X2 Elite and X2 Elite Extreme processors won't appear until the first half of 2026, but Qualcomm is setting some great expectations: 18-core and 12-core processors with serious multicore CPU muscle, a field-leading TOPS count on its neural processor (an 80 TOPS NPU), and a redesigned graphics core.\n\nWith Intel on the ropes but now poised to work more closely than ever with Nvidia on co-designed \"RTX\" SoCs, with AMD benefitting from the power vacuum left by Intel, and with Apple Silicon going strong, it's the wildest time ever to cover laptop processors. PCMag's John Burek and Wired's Luke Larsen were given the opportunity to sit down with one of the company’s senior executives to chat about the new Snapdragon X2 Elite family. We quizzed Kedar Kondap, SVP and GM of Qualcomm's Compute division, on various aspects of the new X2 chips: their makeup, the new Snapdragon Guardian tech designed to appeal to enterprise, and how to cool these fierce-looking chips. The interview has been slightly edited and shortened for clarity.\n\nMarket Successes for Snapdragon X So Far\n\nPCMAG: We've seen various numbers from different sources—adoption numbers relative to the rest of the market—for the initial Snapdragon X Elite. Do you have anything that you can, want, or are able to share in terms of market percentages, numbers in terms of units sold, things of that sort?\n\nKONDAP: I can get you the right numbers that we've shared publicly, but we announced that at earnings. When you look at categories where we were focused—which is devices that are thin-and-light, $600 and above, with integrated GPU—in certain markets I think we've done really well...\n\nSo, approximately 9% of Windows laptops above $600 in the US and the top five European countries. These are the regions we focused on primarily in the first launch. We wanted to make sure that we were focused in how we delivered X Elite into the market. And it was staggered, right? We launched X Elite in June 2024; we launched X Plus devices in September at IFA last year; and then the X came in January. We announced in January, and devices came a little bit after that.\n\nWIRED: I'm curious—you probably don't have the numbers for this—about consumer purchases. Obviously, with some of the stuff announced, you are trying to push into enterprise more, which is where the big numbers are. Can you talk about how you are doing for consumers, people buying directly from stores and online?\n\nKONDAP: Yeah. The market, as you put it, is segmented between consumer and commercial. We focused the first launches on consumer. We've done a lot of pilots and enterprise trials. Those are in progress. We're a lead partner, in IT, ourselves. We've deployed more than 16,000 laptops at Qualcomm, so we're obviously leading the wave here. From a consumer standpoint, your question was more around, how did we approach the consumer segment?\n\nWIRED: I'm just wondering if you guys are doing better in that specific target [market] than enterprise?\n\nKONDAP: So our first focus was that we targeted consumer. Look at the investments and the strategy that we had. Products were very consumer-focused. We partnered with retailers, consumer retailers, globally. We had 50-plus retailers that we partnered with to have devices available. We focused on OEM dotcom channels. So, like, all of the OEM channels had devices. We announced more than 9,300 stores, and some of them even had a Snapdragon-branded kiosk. And the reason for us to do that is to build a relationship with the consumer. We wanted the consumer to understand: One, to understand the brand, but second, also to understand these experiences. The AI stuff is new, and there's not one specific app, or one use case, that's going to fit everybody....\n\nBut in parallel, we have started enterprise trials. Like I said, Qualcomm has led the way, but we have other partners like SAP and many others that have already deployed or are testing actively. We know that takes a little bit longer. Part of why we introduced Snapdragon Guardian today is to showcase more benefits to enterprises and what we can offer.\n\nAbout Snapdragon Guardian\n\nWIRED: I assume Guardian will be offered in all laptops, not just those sold directly into commercial?\n\nKONDAP: The use cases—obviously, it depends. For example, an OEM wants to sell it into the consumer space and add a capability with Guardian. You have the ability to track a PC, manage a PC. I'll give you a good use case.\n\nKids, for example, right? Many schools allow for kids to carry laptops, but they don't allow them to carry phones. So great use case: You know, today, on phones, people have Life360, or one of these apps that you can track where your kids are. You can geofence stuff. Think of it as something very similar. You have the ability to geofence where your kids are, have it on a laptop, and be able to manage it remotely. You can access what they're doing. So we want to give that control to consumers. So it's both a consumer and a commercial thing—but obviously it benefits largely commercial enterprises.\n\nWIRED: Will it be that when people buy those laptops, will they experience that? As in, are OEMs going to use that technology, then rebrand it? Or are we going to see it directly, like a feature in every laptop?\n\nKONDAP: I don't think we're ready to talk about that yet. But we wanted to showcase the technology and what we built because we have added the Guardian technology as a separate subsystem in our platform. So we've taken the steps to make sure that it is a secure subsystem within our SoC, and it provides the ability for our OEM partners to build on top of that. They can choose to offer it either in consumer or commercial. We're providing the foundation, if you will.\n\nPCMAG: About the Guardian stuff, I heard a mention in the presentation that it would be available even if the system was powered off. I was trying to figure out how that works. Are you able to talk on that?\n\nKONDAP: It is a separate subsystem within the SoC, and it connects to a cellular modem. The whole system stays in a low-power island. You can wake the modem up, which will wake up the subsystem. Now, as you know, that can go through multiple scenarios—like, for example, if it's a dead-battery situation, then obviously you can't do anything about it. But then, at the same time, our intent is offering this to enterprise or IT administrators. We want to give them the control to manage devices better, and the risk of a malicious attack is low if you're in a dead-battery situation. So as long as the user plugs in the laptop and brings it up to a certain threshold of battery, you have the ability to wake it up and just push a patch, or be able to do any activities...\n\nPCMAG: Disable it, or whatever the case.\n\nKONDAP: It's totally up to the IT administrators.\n\nSome SoC Particulars\n\nPCMAG: Question on the SoC. I was looking at the specs we were given and noticed that there were different memory allocations for the three different X2 SKUs announced so far. The first, the Elite Extreme, is at 48GB. The others were listed as \"device-dependent.\" And I was just wondering why the 48GB ceiling was landed upon. Any particular reason?\n\nKONDAP: I think the X2 Elite Extreme devices you saw, that we were running, had 48GB of memory. Honestly, we just picked the 48GB because that is still a pretty sweet spot. There's no science behind it. The X2 Elite can address up to 128GB. 48GB is already big for most users. So there's no science behind why we picked that.\n\n(Credit: John Burek)\n\nPCMAG: Is there anything you can speak to in terms of the Adreno GPU? The efficiency gains that were claimed on stage today are pretty impressive. And any insight into how you got to that point versus the first gen?\n\nKONDAP: It's a completely new Adreno GPU, designed ground up for this stuff. It has a new architecture, better shader pipelines. The entire GPU is new. It's not iterative. It is a new generation. And of course, if you're able to attend the sessions after this, we will go into a lot more technical details on exactly how it is done. But yes, it's a completely new architecture, and that's how we're able to get the performance gains as well as the power efficiency.\n\nPCMAG: One other thing that came up when I was talking with some of the folks in the benchmarking session that we had yesterday. The two reference desktops shown—I understand that they're being cooled with AirJet—Frore Systems' AirJet cooling—one of the reps told me?\n\nKONDAP: We have the option to do both. I should say, technically, you have the option to do three things. One, you can have the option to enable this with a fanless design. You can get close to at least 12 watts TDP, if not a little bit more. Or, you can use a regular fan. Or, you can use AirJet. And so, right now, we have two of the SKUs, I believe, that we're showing here. One of the designs is fanless, and the other one has AirJet, which gives you close to 25 watts TDP.\n\nIt's just an option that we want to showcase—that in the same X2 Elite or the X2 Elite Extreme, you can utilize the entire benefit and choose your design points, no different than laptops. And you can tell when you look at the form factors, the difference is insignificant in terms of what you can do, but you can still get 25 watts of performance at very low power.\n\nPCMAG: Thoughts on using AirJet outside of these desktops, in things like laptops? There's no reason you couldn't do that?\n\nKONDAP: No restriction. We just showcased this technology in the small form factors.\n\nMarket Positioning for the New X2 Chips\n\nWIRED: Can you talk about who the X2 Elite Extreme is for, and the thought behind offering that as a separate configuration?\n\nKONDAP: There's swim lanes, right? You have certain price points in certain swim lanes. The X1 Elite was in the price band, or I'll say the sweet spot, of $1,000 device SPs. Think of the X2 Elite as something very similar to that. The Extreme version with the 18-core CPU, with the much higher graphics core, will address a higher tier of experiences. That's part of why we focus so much on talking about gaming and creator use cases. We want to start showcasing the performance, and that's where you get the true benefit of running stuff.\n\n(Credit: John Burek)\n\nEverybody's in search of this one AI app that is going to transform. But we believe the workloads are going to get to agentic. And as you start looking at the whole scenario, all these different agents running on the device, we believe that it's going to run across all the different cores (obviously, on the NPU for low power), and it's going to run hybrid as necessary....Same reason why, for example, we added an 80 TOPS NPU. We believe that we're capping out in terms of many of the use cases that we're running, even at 45 TOPS. So we're enhancing leadership in each of those areas.\n\nWIRED: The 80 TOPS will be across the lineup, right? In the same way that 50 TOPS is across the [current Snapdragon X] lineup?\n\nKONDAP: We're keeping it constant. But the memory is different. In the X2 Elite and the X2 Elite Extreme, the memory configurations are different. DDR—the available bandwidth is different.\n\nFor example, you can address close to about 150, 152, gigabits per second in the X2 Elite. The Extreme gives you about 225, so think of it as an eight-channel DDR and a 12-channel DDR. That's the difference. In technical terms, it gives you more DDR bandwidth. And the reason to do that, obviously, is because many of the AI use cases are DDR-centric.\n\nEverybody's in search of this one AI app that is going to transform. But we believe the workloads are going to get to agentic.\n\nPCMAG: This might be a marketing question. I was looking at the initial three SKUs, and I noticed that the first SKU, the X2 Elite Extreme SKU, is 18-core, with everything else maxed out. The second one is also 18 cores, but not called Extreme. And then the other Elite is a 12-core, right? I was wondering what the marketing logic was of not making the first two 18-core chips both \"Extreme\"?\n\nKONDAP: So the difference is that with the Extreme version, because it's the higher DDR, and it is literally for \"extreme\" use cases, with AI and all of these things. The big difference between the three...all three SKUs support 80 TOPS, but the middle one and the lower one are both eight-channel. So addressability for memory is around 150 gigabits per second, and the Extreme version is the one with 225.\n\nPCMAG: Is the higher GPU performance also tied to the higher memory bandwidth?\n\nKONDAP: No...to be fair, obviously DDR also drives the GPU, drives a lot of the pipeline, drives a lot in terms of the SoC. But that's not why it is. Technically, yes, you are correct that games, or video, or those use cases, will scale because the bandwidth scales. But we've kept the graphics constant. You won't necessarily get to the same output. We just want to have the option available for everybody in case they want to use the 18-core without the extra DDR.\n\nPCMAG: About the Guardian hardware. It was said on stage that there is an SoC element that is part of the Guardian hardware. Is there any way of describing what that is?\n\nKONDAP: It's a dedicated processor within the SoC that's isolated from the rest of the other cores. It has its own BIOS. You can manage the subsystem independently without having to access the rest. So it's a more secure way of how we're able to access an independent processor within the entire SoC.\n\nBattery Life, and Why a Bigger NPU?\n\nWIRED: I noticed there was very little talk about battery life, as opposed to in the first generation—that was, you know, the thing! Anything to say about how different the battery life we're looking at [will be]? Or a kind of parity with the previous generation?\n\nKONDAP: No, it'll be better. We didn't talk in terms of specifics; then, the challenge becomes, what use cases, what do you want to run? With the first generation, we had to showcase stuff because we hadn't launched yet! [Laughter] Now, people have, like the [HP] OmniBook 5, tested out, and the claims that are made with 34 hours of battery life, they're tested. So there are third-party reports that have attested to this incredible battery life. But I showed some of the claims, as you heard; it's depending on which platform you look at: 30%, 40%, 50% better performance in the Extreme at 60% lower power. You will see improvements and gains in battery life, not just in terms of performance. But again, as you know, it's tied to use cases, how people are running it. But we will continue our leadership in performance per watt. We're going to lead the way.\n\nPCMAG: Question on the NPU. We are familiar with how things develop in CPU and GPU, but with NPU development, you're going from one number to a much larger number. How does that happen? What are the factors in chip development that enable an NPU to go from that to that in a generation? Just not being familiar with NPU architecture works.\n\nKONDAP: More details to come on Architecture Day for all of these, but look—AI, and that's why we had Steven [Bathiche] from Microsoft talk about it more technically, because there are things that are moving at such a rapid pace. It's funny, because when we talked about 45 TOPS, and were the first to introduce that in market, everybody said, 45 TOPS? Why do you need 45 TOPS?\n\nI don't know if you guys have had a chance to go through our demo area, but now you have use cases there that are utilizing 100% of our 45 TOPS, right? For example, there's an app called Collov, which basically helps you stage your home. There's no one app that's going to meet everybody's needs, but there are apps that are going to meet every different use case. What's happening is we're seeing this huge demand for NPU workloads.\n\nAt the same time, the models that we've seen have been optimized significantly. For example, when we launched, we talked about a 13-billion-parameter model back then, running on our 45 TOPS NPU with the eight-channel DDR at 130 gigabits per second. Now fast-forward. What has happened in two years is that models have shrunk. What was back then an INT8 model is now an INT4 model, sometimes an INT2 model. The accuracy is still very good. That's what Steven also addressed. We're also able to address bigger models now on the same device. Today, we're able to, in our X1 platform, in many cases, fit like a 27-billion-parameter model.\n\nSo what's happening is we looked at a macro level, at how the industry is shaping with the AI workloads and the models. Then we looked at what we believe is the future, looking at all of these agentic workloads. Let me give you an example. Think of a use case where you're going to tell your PC: Look at my calendar, try to see if I can go to Snapdragon Summit. Am I available that week? And please help me schedule with these five folks, and help me do ABCDE, and give me flight options.\n\nThat use case has multiple agents running on the device. Each agent is different. There's an agent that's looking at your calendar; there's an agent that's looking at the conflicts that somebody else might have. There's an agent that's going to look at your travel preferences and all of that. There's also a hybrid approach to this, because if your preference is Southwest, Alaska, Delta Airlines, whatever, it's going to go in and access the web to see that. OK, John would like to fly on September 20, and it says, \"Well, looks like you can make it. You're supposed to go meet Luke at so-and-so place, but it looks like we can find another option.\"\n\nWhat has happened in two years is that models have shrunk. What was back then an INT8 model is now an INT4 model, sometimes an INT2 model. The accuracy is still very good.\n\nSo those agents—I'm giving you a very rudimentary example—but think of that as workloads where we're building up workloads internally to start modeling. And that, in partnership with Microsoft as well, and looking at partnering with all the model vendors, that's how we sized up the NPU.\n\nThere's more to it. I'm still talking very rudimentary. Now, you think about LVMs [large vision models] and multi-modalities with images and creating videos. Like: I type a text prompt, I want to write a little story, and I want to get it converted into a video. How does that happen? What parts of it run on-device? That's how we start sizing up the NPU and start looking at how we want to architect this. But also the reason why, bringing it back to the higher DDR bandwidth is that we're seeing that use case there. That's why we wanted to have that option available for anybody who needs it.\n\nPCMAG: Is it also a [factor] that multiple AI demands are being made at the same time? So, having a larger NPU enables not only multiple agents, but multiple processes that may be happening in the system at the same time? Being unsure how an NPU works, can it juggle [like a CPU]?\n\nKONDAP: Yeah, it is able to in the same way. And you still have a very powerful CPU and a very powerful GPU, and you have an NPU. So the better part is now if you're offloading all of these tasks, like the agentic stuff, to your NPU, you still have a lot of CPU and GPU headroom left for you to do other tasks, right? You're still going to do your email, you're still going to do other tasks that you want to do that you've offloaded to these other pipelines, including the video and audio and all of that.\n\nWe talked about adding this NPU even to our audio blocks. That's where we look at echo cancellation, background, and all of that stuff. We're going to start running it more on these smaller NPUs. Overall, like I said, that's how we model our use cases right now.\n\n(Credit: John Burek)\n\nWIRED: [With NPU], are we still in a sort of \"build it and they will come\" situation? I know that initially, that's what it was, right? You had to get these into these computers before people could start developing. Where are we at right now?\n\nKONDAP: There are more ISVs than we can keep up with right now, the number of ISVs that are wanting to port all their stuff. And you see why specifically these creator workloads—like Ableton Live and with big voice-model stuff—these are very intense things that really do take up a lot of the NPU. And so everybody is moving toward the same thing, like enterprises are moving to agents.\n\nWe have a large customer right now that has moved a lot of their workforce in many areas...all onto agents. Like, they've moved their entire payroll to an agentic AI. There is no more payroll for them. They have, like, one person in payroll. They shrunk it from 11 down to one person. And then making sure that the agents can run payroll, they've linked it up in the back end. There are all these different use cases....I don't have to sit across the table and convince somebody that the future is AI. Those days are past us now.\n\nWIRED: Specifically on-device, right?\n\nKONDAP: It's moving on-device....The example I gave you of writing a little story and then building a video: It costs a lot of money to build that story and build a video from that story if you run it 100% in the cloud. And there's no reason to. But we're not necessarily saying everything's going to run on-device. We're just saying that's the optionality. You have the option to run a hybrid model, where you can run stuff on-device, and other parts in the cloud. That's the beauty of how this industry is going to move.\n\nPCMAG: Is there any world in which applications, AI applications, are load-balancing between the NPU and other parts of the CPU/SoC? Is that currently done today?\n\nKONDAP: Yes, it's done today. OK, but it's more power, right? The reason for the NPU is that it's a lot more power-efficient. Running anything on your NPU helps you with battery life significantly.\n\nPCMAG: And these days, what's managing the traffic around which part of the chip you're using? Is that something that's built into the app, is that something system-level? Who's arbitrating that?\n\nKONDAP: So the OS already has it. Like, we can go to your Task Manager today and see your NPU utilization relative to your CPU and GPU. So you can actually run something and see where it's being run—just the way you could run it earlier on the CPU and GPU, now you can see it on the NPU. From an orchestration standpoint, Microsoft provided—if you guys saw the announcement—Windows ML, so it makes it easier now for developers to have a cross-referenced framework that they can use.\n\nFor Qualcomm, we have our own orchestration framework. So, for example, when an ISV comes in and balances a particular use case, we have the governance in terms of what runs on the CPU, the GPU, or the NPU, or within the NPU, how do we want to run all the models. That governance we already have. We provide the orchestration ourselves.\n\nSnapdragon X, Looking to 2029...\n\nWIRED: Do you have a goal in mind for market share? What would you consider to be a success in this next generation?\n\nKONDAP: We've said our North Star. We said at our investor day, that's $4 billion in 2029.\n\nPCMAG: $4 million by 2029?\n\nKONDAP: $4 billion.\n\nPCMAG: That's a big number. [Laughter.]\n\n(Credit: Qualcomm)\n\nKONDAP: But we're also talking about a different way of how people are going to look at the PC. It's not the same as what we all see today. It will change. The interaction will change. You heard Cristiano [Amon, Qualcomm CEO] saying, \"AI will be the new UI.\" We're seeing it. I can't stress it enough.\n\n(Note: PCMag is attending Qualcomm's Snapdragon Summit by invitation, but in keeping with our ethics policy, we have assumed all costs for travel and lodging for the conference.)",
      "source": "PCMag.com",
      "url": "https://me.pcmag.com/en/processors/32492/inside-the-snapdragon-x2-elite-20-questions-for-qualcomms-computing-chief",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Scalpers sell ROG Xbox Ally X preorders for as much as $2,500 even though they are still in stock — stay away from eBay and buy from retailers",
      "content": "If you're looking at picking up one of the new ASUS ROG Xbox Ally X machines — and we wouldn't blame you, because they do look pretty sweet — we have some advice: namely, don't buy one off eBay. Yes, scalpers are already trying to move pre-orders for the system, and they're pushing them for as much as 2.5 times the manufacturer's suggested retail price of $999 USD. No, we're not kidding; see for yourself.\n\nSeriously, don't buy this. If you really want a ROG Xbox Ally X, head right on over to Best Buy, where you can still pre-order the thing ahead of its October 16 release date for the standard price of $999—a price that's already a little contentious given that performance is likely to be only slightly ahead of the extant $899 ROG Ally X despite that machine being based on the previous-generation Z1 Extreme processor.\n\nDon't mistake us; the ROG Xbox Ally X has a few upgrades over the previous model, like ergonomic handgrips, faster 8-Gbps LPDDR5X memory, and Xbox Series-style Impulse Triggers with haptic feedback. Still, the star of the show is undoubtedly that it debuts the top-end chip in the AMD Ryzen Z2 series, the Ryzen AI Z2 Extreme. This is fundamentally the same processor as the Ryzen Z2 Extreme, but where that chip disables Strix Point's NPU, the version coming in the Microsoft-branded machine retains its NPU functionality for AI features coming in 2026.\n\nCheck out the one \"marked down\" from $3570. (Image credit: eBay)\n\nWe haven't tested the Ryzen Z2 Extreme ourselves yet, but benchmarks out of China for MSI's Claw A8 with the chip put it slightly ahead of Intel's Core Ultra 7 258V in the MSI Claw 8 AI+, although the gap was vanishingly small. Considering that Lunar Lake is often not far ahead of the original Ryzen Z1 Extreme, this mirrors what we've seen in laptops, where the Ryzen AI 300 series' integrated GPU rarely puts much space between itself and the Ryzen AI 200 series, formerly known as the Ryzen 8040 series, codenamed Hawk Point. The Ryzen Z1 Extreme is also Hawk Point.\n\nIf you're really keen for a significant uplift in handheld performance versus the wave of Hawk Point-based machines, like the original ASUS ROG Ally, the Lenovo Legion Go, the Ayaneo Kun, the GPD Win 4, and many others, then what you're going to be looking for is a system based on the AMD Ryzen AI Max 300 family. These chips are fundamentally much larger, featuring desktop-class CPU cores, significantly wider GPUs, and a double-wide memory bus to prevent bandwidth bottlenecks.\n\nRyzen AI Max processors are not cheap, and as it happens, many of the systems sporting these SoCs seem to be coming in right around the prices asked by the ROG Xbox Ally X scalpers. If you've got $2,500 to drop on a handheld, maybe check out the GPD Win 5, Ayaneo's Next 2, and the just-announced OneXFly Apex, all of which are based on this chip, codenamed Strix Halo. They're going to offer you real premium features that you won't find on the ROG Xbox Ally X, including OLED screens, detachable batteries, and legitimate console-like performance. Of course, there's the question of whether you should spend $2500 on a machine with console-like performance, but that's your judgment call to make, not ours.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/video-games/handheld-gaming/scalpers-sell-rog-xbox-ally-x-preorders-for-as-much-as-usd2-500-even-though-they-are-still-in-stock-stay-away-from-ebay-and-buy-from-retailers",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "AMD's memory patent outlining a 'new, improved RAM' made from DDR5 memory isn't a new development — HB-DIMMs already superseded, probably won't come to market",
      "content": "A recent AMD patent, US19/201,497 titled \"High-bandwidth memory module architecture,\" is making the rounds again, with posts like this one on Reddit prompting all kinds of speculation about the \"new\" HB-DIMM memory technology that AMD is preparing. However, AMD is probably not preparing anything new; Instead, the new patent is actually a continuation of an older one that dates to 2022. The technology the company outlines has already been superseded by the new MRDIMM tech that's already shipping and supported by AMD.\n\nThe original patent, known as US12300346B2 and also titled \"High-bandwidth memory module architecture,\" was superseded in 2023 by US20230178121A1, which is the specific document extended by the \"new\" filing that was actually published back in July. In other words, by no means is this a novel technology, and AMD's recent activity with these patents is almost assuredly a form of \"bureaucratic housekeeping\" — paper shuffling intended to help protect AMD's intellectual property.\n\nSo, what are these patents actually about? HB-DIMMs, a new type of memory module that performs multiplexed accesses over \"two or more independently addressable pseudo-channels\" within a single memory module. These pseudo-channels are not necessarily analogous to memory ranks, but instead separate divisions within the module, and they can be within a single rank or across ranks.\n\nBy doing this, you can double the effective transfer rate of standard DDR5 DRAM, although you will need new modules with extra components, including additional data buffers and an RCD, or Register Clock Driver. This means, in essence, that HB-DIMMs would essentially supersede both standard RDIMMs and CUDIMMs.\n\nMultiple companies independently developed this idea; SK hynix pursued it in collaboration with Intel and Renesas, presenting a proposal called MCR-DIMM in late 2022. That was after AMD had already filed its patent on HB-DIMM, although the filing wasn't public at that time. It wouldn't do to have two competing, incompatible standards, so JEDEC got together with the two to standardize what we now have as MRDIMMs, or Multiplexed-Rank Dual Inline Memory Modules. MRDIMMs consolidate the ideas of MCR-DIMM and HB-DIMM into one standard form.\n\nIntel's Sierra Forest, Granite Rapids, and a Gaudi 3 accelerator, launched last year. (Image credit: Intel)\n\nMRDIMMs aren't a hypothetical future technology. They've already been available on the market for upwards of a year now, as they're supported in Intel's Xeon 6 family of server CPUs (formerly Granite Rapids). Phoronix recently tested the performance gains against standard DDR5 RDIMMs at 6400 Mbps, and while the overall gains were small, certain memory-intensive workloads like the High Performance Conjugate Gradient (HPCG) found significant gains, while memory latency actually saw a tiny, margin-of-error improvement.\n\nDoes this recent patent filing indicate that AMD will still pursue HB-DIMM? Probably not. Fundamentally, the technologies are very similar, and AMD has already voiced its intent to support JEDEC's MRDIMM open standard. The company's Zen 6-based EPYC 'Venice' processors are expected to use MRDIMMs — potentially second-generation MRDIMMs — to reach the lofty 1.6 TB/second per-socket memory bandwidth spec that Dr. Lisa Su teased at AMD's Advancing AI event in June.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nIf that was indeed meant to be a single-socket bandwidth number, then with the rumored sixteen-channel (1024-bit) memory interface of 'Venice', a transfer rate of 12,800 Mbps would get you directly to 1.6 TB/second. That happens to be exactly the transfer rate that JEDEC promised for second-generation MRDIMMs, so there's the source for our speculation.\n\nMRDIMMs are currently quite expensive, at least at retail (Image credit: Server Supply)\n\nThose hot-clocked DDR5 modules won't come cheap, though. Existing MRDIMMs are already extremely expensive, with a cost-per-gigabyte that is between 28% and 114% higher than standard, slower-clocked DDR5 RDIMMs, depending on the specific comparison being made. We're looking at retail pricing, which usually isn't what server operators pay, but the point is, you're looking at easily $100 to $150 extra per module, which is brutal when you need to fill eight, ten, twelve, or sixteen memory channels in a single server. The second-gen 12,800 Mbps stuff will likely be even more.\n\nSo, in summary: No, AMD (probably) isn't about to whip out some new high-speed memory technology. This stuff has been talked about for a few years already, and in fact, we actually covered HB-DIMM and MRDIMMs right here on this very website in the past. Here's hoping this technology could filter down to consumer systems, particularly if those rumors about AMD's new chiplet APUs are true.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/ram/amds-memory-patent-outlining-a-new-improved-ram-made-from-ddr5-memory-isnt-a-new-development-hb-dimms-already-superseded-probably-wont-come-to-market",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Inside the Snapdragon X2 Elite: 20 Questions for Qualcomm’s Computing Chief",
      "content": "Table of Contents Market Successes for Snapdragon X So Far About Snapdragon Guardian Some SoC Particulars Market Positioning for the New X2 Chips Battery Life, and Why a Bigger NPU? Snapdragon X, Looking to 2029...\n\nDon't miss out on our latest stories. Add PCMag as a preferred source on Google.\n\nLAHAINA, MAUI—The highlight of this year's Snapdragon Summit is the unveiling of Qualcomm's second-generation Snapdragon X2 Arm laptop processors, including a new \"Extreme\" tier of chips that looks poised to take on AMD's, Intel's, and Apple's best. PCs with the new X2 Elite and X2 Elite Extreme processors won't appear until the first half of 2026, but Qualcomm is setting some great expectations: 18-core and 12-core processors with serious multicore CPU muscle, a field-leading TOPS count on its neural processor (an 80 TOPS NPU), and a redesigned graphics core.\n\nWith Intel on the ropes but now poised to work more closely than ever with Nvidia on co-designed \"RTX\" SoCs, with AMD benefitting from the power vacuum left by Intel, and with Apple Silicon going strong, it's the wildest time ever to cover laptop processors. PCMag's John Burek and Wired's Luke Larsen were given the opportunity to sit down with one of the company’s senior executives to chat about the new Snapdragon X2 Elite family. We quizzed Kedar Kondap, SVP and GM of Qualcomm's Compute division, on various aspects of the new X2 chips: their makeup, the new Snapdragon Guardian tech designed to appeal to enterprise, and how to cool these fierce-looking chips. The interview has been slightly edited and shortened for clarity.\n\nMarket Successes for Snapdragon X So Far\n\nPCMAG: We've seen various numbers from different sources—adoption numbers relative to the rest of the market—for the initial Snapdragon X Elite. Do you have anything that you can, want, or are able to share in terms of market percentages, numbers in terms of units sold, things of that sort?\n\nKONDAP: I can get you the right numbers that we've shared publicly, but we announced that at earnings. When you look at categories where we were focused—which is devices that are thin-and-light, $600 and above, with integrated GPU—in certain markets I think we've done really well...\n\nSo, approximately 9% of Windows laptops above $600 in the US and the top five European countries. These are the regions we focused on primarily in the first launch. We wanted to make sure that we were focused in how we delivered X Elite into the market. And it was staggered, right? We launched X Elite in June 2024; we launched X Plus devices in September at IFA last year; and then the X came in January. We announced in January, and devices came a little bit after that.\n\nWIRED: I'm curious—you probably don't have the numbers for this—about consumer purchases. Obviously, with some of the stuff announced, you are trying to push into enterprise more, which is where the big numbers are. Can you talk about how you are doing for consumers, people buying directly from stores and online?\n\nKONDAP: Yeah. The market, as you put it, is segmented between consumer and commercial. We focused the first launches on consumer. We've done a lot of pilots and enterprise trials. Those are in progress. We're a lead partner, in IT, ourselves. We've deployed more than 16,000 laptops at Qualcomm, so we're obviously leading the wave here. From a consumer standpoint, your question was more around, how did we approach the consumer segment?\n\nWIRED: I'm just wondering if you guys are doing better in that specific target [market] than enterprise?\n\nKONDAP: So our first focus was that we targeted consumer. Look at the investments and the strategy that we had. Products were very consumer-focused. We partnered with retailers, consumer retailers, globally. We had 50-plus retailers that we partnered with to have devices available. We focused on OEM dotcom channels. So, like, all of the OEM channels had devices. We announced more than 9,300 stores, and some of them even had a Snapdragon-branded kiosk. And the reason for us to do that is to build a relationship with the consumer. We wanted the consumer to understand: One, to understand the brand, but second, also to understand these experiences. The AI stuff is new, and there's not one specific app, or one use case, that's going to fit everybody....\n\nBut in parallel, we have started enterprise trials. Like I said, Qualcomm has led the way, but we have other partners like SAP and many others that have already deployed or are testing actively. We know that takes a little bit longer. Part of why we introduced Snapdragon Guardian today is to showcase more benefits to enterprises and what we can offer.\n\nAbout Snapdragon Guardian\n\nWIRED: I assume Guardian will be offered in all laptops, not just those sold directly into commercial?\n\nKONDAP: The use cases—obviously, it depends. For example, an OEM wants to sell it into the consumer space and add a capability with Guardian. You have the ability to track a PC, manage a PC. I'll give you a good use case.\n\nKids, for example, right? Many schools allow for kids to carry laptops, but they don't allow them to carry phones. So great use case: You know, today, on phones, people have Life360, or one of these apps that you can track where your kids are. You can geofence stuff. Think of it as something very similar. You have the ability to geofence where your kids are, have it on a laptop, and be able to manage it remotely. You can access what they're doing. So we want to give that control to consumers. So it's both a consumer and a commercial thing—but obviously it benefits largely commercial enterprises.\n\nWIRED: Will it be that when people buy those laptops, will they experience that? As in, are OEMs going to use that technology, then rebrand it? Or are we going to see it directly, like a feature in every laptop?\n\nKONDAP: I don't think we're ready to talk about that yet. But we wanted to showcase the technology and what we built because we have added the Guardian technology as a separate subsystem in our platform. So we've taken the steps to make sure that it is a secure subsystem within our SoC, and it provides the ability for our OEM partners to build on top of that. They can choose to offer it either in consumer or commercial. We're providing the foundation, if you will.\n\nPCMAG: About the Guardian stuff, I heard a mention in the presentation that it would be available even if the system was powered off. I was trying to figure out how that works. Are you able to talk on that?\n\nKONDAP: It is a separate subsystem within the SoC, and it connects to a cellular modem. The whole system stays in a low-power island. You can wake the modem up, which will wake up the subsystem. Now, as you know, that can go through multiple scenarios—like, for example, if it's a dead-battery situation, then obviously you can't do anything about it. But then, at the same time, our intent is offering this to enterprise or IT administrators. We want to give them the control to manage devices better, and the risk of a malicious attack is low if you're in a dead-battery situation. So as long as the user plugs in the laptop and brings it up to a certain threshold of battery, you have the ability to wake it up and just push a patch, or be able to do any activities...\n\nPCMAG: Disable it, or whatever the case.\n\nKONDAP: It's totally up to the IT administrators.\n\nSome SoC Particulars\n\nPCMAG: Question on the SoC. I was looking at the specs we were given and noticed that there were different memory allocations for the three different X2 SKUs announced so far. The first, the Elite Extreme, is at 48GB. The others were listed as \"device-dependent.\" And I was just wondering why the 48GB ceiling was landed upon. Any particular reason?\n\nKONDAP: I think the X2 Elite Extreme devices you saw, that we were running, had 48GB of memory. Honestly, we just picked the 48GB because that is still a pretty sweet spot. There's no science behind it. The X2 Elite can address up to 128GB. 48GB is already big for most users. So there's no science behind why we picked that.\n\n(Credit: John Burek)\n\nPCMAG: Is there anything you can speak to in terms of the Adreno GPU? The efficiency gains that were claimed on stage today are pretty impressive. And any insight into how you got to that point versus the first gen?\n\nKONDAP: It's a completely new Adreno GPU, designed ground up for this stuff. It has a new architecture, better shader pipelines. The entire GPU is new. It's not iterative. It is a new generation. And of course, if you're able to attend the sessions after this, we will go into a lot more technical details on exactly how it is done. But yes, it's a completely new architecture, and that's how we're able to get the performance gains as well as the power efficiency.\n\nPCMAG: One other thing that came up when I was talking with some of the folks in the benchmarking session that we had yesterday. The two reference desktops shown—I understand that they're being cooled with AirJet—Frore Systems' AirJet cooling—one of the reps told me?\n\nKONDAP: We have the option to do both. I should say, technically, you have the option to do three things. One, you can have the option to enable this with a fanless design. You can get close to at least 12 watts TDP, if not a little bit more. Or, you can use a regular fan. Or, you can use AirJet. And so, right now, we have two of the SKUs, I believe, that we're showing here. One of the designs is fanless, and the other one has AirJet, which gives you close to 25 watts TDP.\n\nIt's just an option that we want to showcase—that in the same X2 Elite or the X2 Elite Extreme, you can utilize the entire benefit and choose your design points, no different than laptops. And you can tell when you look at the form factors, the difference is insignificant in terms of what you can do, but you can still get 25 watts of performance at very low power.\n\nPCMAG: Thoughts on using AirJet outside of these desktops, in things like laptops? There's no reason you couldn't do that?\n\nKONDAP: No restriction. We just showcased this technology in the small form factors.\n\nMarket Positioning for the New X2 Chips\n\nWIRED: Can you talk about who the X2 Elite Extreme is for, and the thought behind offering that as a separate configuration?\n\nKONDAP: There's swim lanes, right? You have certain price points in certain swim lanes. The X1 Elite was in the price band, or I'll say the sweet spot, of $1,000 device SPs. Think of the X2 Elite as something very similar to that. The Extreme version with the 18-core CPU, with the much higher graphics core, will address a higher tier of experiences. That's part of why we focus so much on talking about gaming and creator use cases. We want to start showcasing the performance, and that's where you get the true benefit of running stuff.\n\n(Credit: John Burek)\n\nEverybody's in search of this one AI app that is going to transform. But we believe the workloads are going to get to agentic. And as you start looking at the whole scenario, all these different agents running on the device, we believe that it's going to run across all the different cores (obviously, on the NPU for low power), and it's going to run hybrid as necessary....Same reason why, for example, we added an 80 TOPS NPU. We believe that we're capping out in terms of many of the use cases that we're running, even at 45 TOPS. So we're enhancing leadership in each of those areas.\n\nWIRED: The 80 TOPS will be across the lineup, right? In the same way that 50 TOPS is across the [current Snapdragon X] lineup?\n\nKONDAP: We're keeping it constant. But the memory is different. In the X2 Elite and the X2 Elite Extreme, the memory configurations are different. DDR—the available bandwidth is different.\n\nFor example, you can address close to about 150, 152, gigabits per second in the X2 Elite. The Extreme gives you about 225, so think of it as an eight-channel DDR and a 12-channel DDR. That's the difference. In technical terms, it gives you more DDR bandwidth. And the reason to do that, obviously, is because many of the AI use cases are DDR-centric.\n\nEverybody's in search of this one AI app that is going to transform. But we believe the workloads are going to get to agentic.\n\nPCMAG: This might be a marketing question. I was looking at the initial three SKUs, and I noticed that the first SKU, the X2 Elite Extreme SKU, is 18-core, with everything else maxed out. The second one is also 18 cores, but not called Extreme. And then the other Elite is a 12-core, right? I was wondering what the marketing logic was of not making the first two 18-core chips both \"Extreme\"?\n\nKONDAP: So the difference is that with the Extreme version, because it's the higher DDR, and it is literally for \"extreme\" use cases, with AI and all of these things. The big difference between the three...all three SKUs support 80 TOPS, but the middle one and the lower one are both eight-channel. So addressability for memory is around 150 gigabits per second, and the Extreme version is the one with 225.\n\nPCMAG: Is the higher GPU performance also tied to the higher memory bandwidth?\n\nKONDAP: No...to be fair, obviously DDR also drives the GPU, drives a lot of the pipeline, drives a lot in terms of the SoC. But that's not why it is. Technically, yes, you are correct that games, or video, or those use cases, will scale because the bandwidth scales. But we've kept the graphics constant. You won't necessarily get to the same output. We just want to have the option available for everybody in case they want to use the 18-core without the extra DDR.\n\nPCMAG: About the Guardian hardware. It was said on stage that there is an SoC element that is part of the Guardian hardware. Is there any way of describing what that is?\n\nKONDAP: It's a dedicated processor within the SoC that's isolated from the rest of the other cores. It has its own BIOS. You can manage the subsystem independently without having to access the rest. So it's a more secure way of how we're able to access an independent processor within the entire SoC.\n\nBattery Life, and Why a Bigger NPU?\n\nWIRED: I noticed there was very little talk about battery life, as opposed to in the first generation—that was, you know, the thing! Anything to say about how different the battery life we're looking at [will be]? Or a kind of parity with the previous generation?\n\nKONDAP: No, it'll be better. We didn't talk in terms of specifics; then, the challenge becomes, what use cases, what do you want to run? With the first generation, we had to showcase stuff because we hadn't launched yet! [Laughter] Now, people have, like the [HP] OmniBook 5, tested out, and the claims that are made with 34 hours of battery life, they're tested. So there are third-party reports that have attested to this incredible battery life. But I showed some of the claims, as you heard; it's depending on which platform you look at: 30%, 40%, 50% better performance in the Extreme at 60% lower power. You will see improvements and gains in battery life, not just in terms of performance. But again, as you know, it's tied to use cases, how people are running it. But we will continue our leadership in performance per watt. We're going to lead the way.\n\nPCMAG: Question on the NPU. We are familiar with how things develop in CPU and GPU, but with NPU development, you're going from one number to a much larger number. How does that happen? What are the factors in chip development that enable an NPU to go from that to that in a generation? Just not being familiar with NPU architecture works.\n\nKONDAP: More details to come on Architecture Day for all of these, but look—AI, and that's why we had Steven [Bathiche] from Microsoft talk about it more technically, because there are things that are moving at such a rapid pace. It's funny, because when we talked about 45 TOPS, and were the first to introduce that in market, everybody said, 45 TOPS? Why do you need 45 TOPS?\n\nI don't know if you guys have had a chance to go through our demo area, but now you have use cases there that are utilizing 100% of our 45 TOPS, right? For example, there's an app called Collov, which basically helps you stage your home. There's no one app that's going to meet everybody's needs, but there are apps that are going to meet every different use case. What's happening is we're seeing this huge demand for NPU workloads.\n\nAt the same time, the models that we've seen have been optimized significantly. For example, when we launched, we talked about a 13-billion-parameter model back then, running on our 45 TOPS NPU with the eight-channel DDR at 130 gigabits per second. Now fast-forward. What has happened in two years is that models have shrunk. What was back then an INT8 model is now an INT4 model, sometimes an INT2 model. The accuracy is still very good. That's what Steven also addressed. We're also able to address bigger models now on the same device. Today, we're able to, in our X1 platform, in many cases, fit like a 27-billion-parameter model.\n\nSo what's happening is we looked at a macro level, at how the industry is shaping with the AI workloads and the models. Then we looked at what we believe is the future, looking at all of these agentic workloads. Let me give you an example. Think of a use case where you're going to tell your PC: Look at my calendar, try to see if I can go to Snapdragon Summit. Am I available that week? And please help me schedule with these five folks, and help me do ABCDE, and give me flight options.\n\nThat use case has multiple agents running on the device. Each agent is different. There's an agent that's looking at your calendar; there's an agent that's looking at the conflicts that somebody else might have. There's an agent that's going to look at your travel preferences and all of that. There's also a hybrid approach to this, because if your preference is Southwest, Alaska, Delta Airlines, whatever, it's going to go in and access the web to see that. OK, John would like to fly on September 20, and it says, \"Well, looks like you can make it. You're supposed to go meet Luke at so-and-so place, but it looks like we can find another option.\"\n\nWhat has happened in two years is that models have shrunk. What was back then an INT8 model is now an INT4 model, sometimes an INT2 model. The accuracy is still very good.\n\nSo those agents—I'm giving you a very rudimentary example—but think of that as workloads where we're building up workloads internally to start modeling. And that, in partnership with Microsoft as well, and looking at partnering with all the model vendors, that's how we sized up the NPU.\n\nThere's more to it. I'm still talking very rudimentary. Now, you think about LVMs [large vision models] and multi-modalities with images and creating videos. Like: I type a text prompt, I want to write a little story, and I want to get it converted into a video. How does that happen? What parts of it run on-device? That's how we start sizing up the NPU and start looking at how we want to architect this. But also the reason why, bringing it back to the higher DDR bandwidth is that we're seeing that use case there. That's why we wanted to have that option available for anybody who needs it.\n\nPCMAG: Is it also a [factor] that multiple AI demands are being made at the same time? So, having a larger NPU enables not only multiple agents, but multiple processes that may be happening in the system at the same time? Being unsure how an NPU works, can it juggle [like a CPU]?\n\nKONDAP: Yeah, it is able to in the same way. And you still have a very powerful CPU and a very powerful GPU, and you have an NPU. So the better part is now if you're offloading all of these tasks, like the agentic stuff, to your NPU, you still have a lot of CPU and GPU headroom left for you to do other tasks, right? You're still going to do your email, you're still going to do other tasks that you want to do that you've offloaded to these other pipelines, including the video and audio and all of that.\n\nWe talked about adding this NPU even to our audio blocks. That's where we look at echo cancellation, background, and all of that stuff. We're going to start running it more on these smaller NPUs. Overall, like I said, that's how we model our use cases right now.\n\n(Credit: John Burek)\n\nWIRED: [With NPU], are we still in a sort of \"build it and they will come\" situation? I know that initially, that's what it was, right? You had to get these into these computers before people could start developing. Where are we at right now?\n\nKONDAP: There are more ISVs than we can keep up with right now, the number of ISVs that are wanting to port all their stuff. And you see why specifically these creator workloads—like Ableton Live and with big voice-model stuff—these are very intense things that really do take up a lot of the NPU. And so everybody is moving toward the same thing, like enterprises are moving to agents.\n\nWe have a large customer right now that has moved a lot of their workforce in many areas...all onto agents. Like, they've moved their entire payroll to an agentic AI. There is no more payroll for them. They have, like, one person in payroll. They shrunk it from 11 down to one person. And then making sure that the agents can run payroll, they've linked it up in the back end. There are all these different use cases....I don't have to sit across the table and convince somebody that the future is AI. Those days are past us now.\n\nWIRED: Specifically on-device, right?\n\nKONDAP: It's moving on-device....The example I gave you of writing a little story and then building a video: It costs a lot of money to build that story and build a video from that story if you run it 100% in the cloud. And there's no reason to. But we're not necessarily saying everything's going to run on-device. We're just saying that's the optionality. You have the option to run a hybrid model, where you can run stuff on-device, and other parts in the cloud. That's the beauty of how this industry is going to move.\n\nPCMAG: Is there any world in which applications, AI applications, are load-balancing between the NPU and other parts of the CPU/SoC? Is that currently done today?\n\nKONDAP: Yes, it's done today. OK, but it's more power, right? The reason for the NPU is that it's a lot more power-efficient. Running anything on your NPU helps you with battery life significantly.\n\nPCMAG: And these days, what's managing the traffic around which part of the chip you're using? Is that something that's built into the app, is that something system-level? Who's arbitrating that?\n\nKONDAP: So the OS already has it. Like, we can go to your Task Manager today and see your NPU utilization relative to your CPU and GPU. So you can actually run something and see where it's being run—just the way you could run it earlier on the CPU and GPU, now you can see it on the NPU. From an orchestration standpoint, Microsoft provided—if you guys saw the announcement—Windows ML, so it makes it easier now for developers to have a cross-referenced framework that they can use.\n\nFor Qualcomm, we have our own orchestration framework. So, for example, when an ISV comes in and balances a particular use case, we have the governance in terms of what runs on the CPU, the GPU, or the NPU, or within the NPU, how do we want to run all the models. That governance we already have. We provide the orchestration ourselves.\n\nSnapdragon X, Looking to 2029...\n\nWIRED: Do you have a goal in mind for market share? What would you consider to be a success in this next generation?\n\nKONDAP: We've said our North Star. We said at our investor day, that's $4 billion in 2029.\n\nPCMAG: $4 million by 2029?\n\nKONDAP: $4 billion.\n\nPCMAG: That's a big number. [Laughter.]\n\n(Credit: Qualcomm)\n\nKONDAP: But we're also talking about a different way of how people are going to look at the PC. It's not the same as what we all see today. It will change. The interaction will change. You heard Cristiano [Amon, Qualcomm CEO] saying, \"AI will be the new UI.\" We're seeing it. I can't stress it enough.\n\n(Note: PCMag is attending Qualcomm's Snapdragon Summit by invitation, but in keeping with our ethics policy, we have assumed all costs for travel and lodging for the conference.)",
      "source": "PCMag.com",
      "url": "https://uk.pcmag.com/processors/160308/inside-the-snapdragon-x2-elite-20-questions-for-qualcomms-computing-chief",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Nvidia CEO bets $100 billion on OpenAI becoming a multi-trillion-dollar company — Jensen outlines his view on OpenAI's path to becoming one of the biggest companies in the world",
      "content": "Nvidia CEO Jensen Huang believes OpenAI is on track to become a multi-trillion-dollar company, citing explosive growth and scale as the foundation for what could be the fastest rise to that valuation in the industry’s history. Speaking on the BG2 podcast, Huang said that OpenAI “is likely going to be the next multi-trillion-dollar hyperscaler company.”\n\nHis comments come on the heels of a high-stakes infrastructure pact between Nvidia and OpenAI. Earlier this week, the companies announced a letter of intent for up to 10 GW of GPU-powered data centers to be deployed through OpenAI’s preferred cloud partners. Nvidia, in turn, agreed to invest as much as $100 billion in those systems as capacity comes online, making it one of the largest vendor-led bets on AI infrastructure to date.\n\nIn doing so, Nvidia is effectively underwriting the next generation of AI growth by ensuring its silicon roadmap stays in sync with OpenAI’s compute ambitions. The deal anchors future demand for Nvidia’s Rubin-class platforms and next-gen networking hardware, while also giving OpenAI early access to systems that may not reach general availability for years.\n\nIt also helps to bolster Nvidia’s dominance in the AI supply chain. Major cloud providers, such as Microsoft, Amazon, and Google, have an insatiable appetite for GPU capacity, and Nvidia’s partnership strategy effectively pulls demand forward, locking hyperscalers like them into multi-year commitments while competitors like AMD and Intel are still playing catch-up. Expand the tweet below to see Jensen's explanation of OpenAI's path to a multi-trillion-dollar valuation.\n\n📁 Jensen Huang believes OpenAI is the next trillion-dollar company, and that’s why he’s investing. pic.twitter.com/bwI3ELEa4tSeptember 26, 2025\n\nAt 10 GW, OpenAI’s planned footprint and its associated capital expenditure have already pushed the plans into high-risk, high-reward territory. OpenAI recently struck a $6.5 billion expansion deal with CoreWeave, one of Nvidia’s key hosting partners, to help finance the rollout.\n\nNvidia also holds a stake in CoreWeave, and critics have raised concerns about the concentration of capital, hardware, and access among a small number of companies. However, that doesn’t seem to matter to Huang, who apparently believes that AI’s future will be defined by those who can scale infrastructure the fastest. OpenAI is outpacing even the most aggressive growth curves seen during the rise of cloud computing.\n\nNvidia’s ability to pre-sell entire generations of high-end GPUs into AI deployments will also have knock-on effects on the wider industry, including gaming card availability and workstation pricing. If OpenAI consumes a significant portion of future Rubin or Rubin Ultra supply, it could widen the gap between data center and consumer release cycles, making it even harder for consumers to obtain timely access to Nvidia’s latest hardware.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFor now, though, Huang seems unconcerned. He’s betting $100 billion that OpenAI’s growth definitely isn’t part of a wider AI bubble.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/jensen-huang-says-open-ai-will-be-a-multi-trillion-dollar-company",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Superintelligence is Beyond Reach",
      "content": "Superintelligence is Beyond Reach\n\nWhat’s the latest breakthrough in artificial intelligence (AI)? The answer may surprise you.\n\nWe’re all aware of the boom in AI-related stocks, AI technology and unrelenting news coverage about AI. You can’t open your browser without reading about AI and you can’t glance at your stock ticker without noticing the extent to which stock prices have been driven by AI company valuations. That boom may be a bubble but it need not change soon. Stock bubbles have a life of their own and don’t crash just because investors know it’s a bubble.\n\nThat said, there’s no doubt about the power of AI. It’s ubiquitous. It’s on the dashboard of your car, in your home appliances and in the palm of your hand in the form of AI apps. Every internet service provider has one from Microsoft, to Google, Facebook, Apple and OpenAI. When you open your refrigerator and a sign tells you to change your water filter, that’s AI at work.\n\nOf course, AI has been around since the 1950s. AI imitates the human brain by setting up neural networks. These networks have nodes that are connected to each other by what are called edges. The nodes contain mathematical formulas that process incoming data. The processed data then forms the output, which goes to another node.\n\nThe edges can be assigned weights with some inputs being more powerful than others. Nodal output can be arranged in tiers so that lower tier output goes upstream to higher tiers where more input/output processing takes place. Today, these neural networks can be unimaginably complex with billions of nodes processing hundreds of billions of inputs.\n\nAI Advances\n\nAI science hit a dead-end in the early 1980s due to limitations on processing power and the relatively primitive channels through which the processing was done. The 1980s were known as the “AI winter.” This lack of progress in AI science prevailed through the 1990s and early 2000s.\n\nBeginning around 2005, three major advances occurred that enabled the AI revolution we see today. The first was a dramatic increase in processing power. Faster semiconductor chips from NVIDIA and AMD designed for gaming were adapted to AI processing with great success.\n\nThe second was the invention of large language models (LLMs). These are algorithms that allow AI systems to scan billions of pages of content (including the entire internet), tokenize words, phrases and images and look for clusters of words and images that typically go together. These word and image combinations are assigned values and assembled into clouds that allow systems to fetch them as needed for grammatical writing and composite image creation.\n\nThe third breakthrough was the invention of generative pre-trained transformers (GPT) that allow processors to work in parallel rather than sequentially. The parallel threads converge at the end of the process, but the convergence contains much more refined data due to the transformer method. GPT also acts as a kind of turbocharger on the high-speed chips so that the combined leap in processing speed is exponential.\n\nIt was in November 2022 with the release of Chat GPT-4 by OpenAI (which gained 100 million users in less than 30 days) that the advances described above came together and launched the stock frenzy and the tech advances we’re still seeing.\n\nSuperintelligence Is Beyond Reach\n\nThe difficulty today is that all these advances and the AI boom in general have been extrapolated beyond the ability of the technology to perform. Talk of superintelligence or advanced general intelligence under which humans would be to computers what apes are to humans in terms of cognitive skills is nonsense. Computers may get faster and robots more common, but we won’t see true superintelligence perhaps ever.\n\nThe reason has to do with the difference between inductive and deductive reasoning on the one hand, which computers can do within limits, and abductive logic and semiotics, which are important human skills that computers cannot do at all. These skills are non-programmable and mark one of the key distinctions between human brain functions and computer processing.\n\nOther constraints involve functions of the law of diminishing marginal returns under which massive increases in energy inputs and processing power result in only minor increases in output. Major tech companies (Microsoft, Meta, Google, OpenAI, Apple, Oracle and a few others) have spent over $400 billion for data centers and other AI infrastructure in the past year with higher expenditures planned. This can be considered money spent on hardware.\n\nSoftware development costs and costs of information input are additional expenditures. Increased processing capacity has not been met with increased output. Profits remain elusive. In fact, new applications such as GPT-5 from OpenAI have been major disappointments. This phenomenon of diminishing returns is well-known to engineers in other fields but may come as a shock to AI investors driven by FOMO (Fear of Missing Out).\n\nAnother constraint that is little understood is the Law of Conservation of Information in Search Processes. This law has been rigorously demonstrated mathematically by my collaborator William A. Dembski in a recently published paper. The law posits that any search process (including the most sophisticated version of AI) with the fastest processors and LLMs cannot find new information. They can only find existing information.\n\nAI may produce faster and more extensive searches and may find correlations that human efforts could not identify in a lifetime, but that’s all still existing information. In short, AI has no creative capacity. It cannot “think” of anything new, unlike humans who create new formulas and works of art routinely. AI is not “intelligent” or creative. It’s just fast.\n\nIn a recent experiment, a supercomputer and a group of first grade children were given a ruler, a teapot and a stove and asked to draw a circle. The computer “knew” that the ruler was a draftsman’s tool not unlike a compass and promptly tried to draw a circle with a ruler. It failed. The children glanced at the teapot, saw that the bottom was round and used it to trace perfect circles.\n\nThis is an example of abductive logic (also called intuition or common sense) at work, which children have, and computers do not. The idea of children outperforming a supercomputer might cause investors to ask just what they are getting for their $400 billion (and counting).\n\nIn sum, AI will never be superintelligent, expenditures have hit the wall of diminishing returns, AI offers no creativity at all (just fast searches), and children can outperform the fastest machines when the task calls for intuition. Is the AI frenzy about to hit the wall?\n\nScaling Down The Data\n\nThere are some encouraging solutions that may allow AI to add value beyond robotics and fast processing. One of these is the use of small language models (SLMs) instead of LLMs.\n\nUnlike LLMs, which troll the entire internet or large subsets, SLMs contain far less data and are curated by subject matter experts to be tailored to specific tasks. What is the point of including billions of pages of text in a training set if most of those pages have nothing to do with the problem the AI application is trying to solve? As the IBM head of AI research David Cox recently said, “Your HR chatbot doesn’t need to know advanced physics.”\n\nOne difference between SLMs and LLMs is the number of parameters that the model is trained on. LLMs use hundreds of billions of parameters while SLMs might need only 40 billion or fewer parameters. Some SLMs use as few as 1 billion. This means the SLMs can run faster on far less energy. They can also be scaled more easily for smart phones and other applications like self-driving cars and household appliances.\n\nSLMs also have fewer “hallucinations” than LLMs (this refers to the tendency of AI to invent data from whole cloth in order to reply to a prompt or complete an otherwise unfinished narrative). SLMs are less likely to train on the output from LLMs that pollutes the training set. Research shows, as LLMs increasingly train on data sets that include prior output of LLMs, the training set becomes diluted with bad output, and the output quickly crashes into absurd results. SLMs are more resistant to this because their training sets are more technically rigorous.\n\nSLMs also run on less expensive chips, which may have negative implications for monster chip makers like NVIDIA. SLMs running on smaller cloud systems may make the massive server farms now being constructed, either redundant or obsolete.\n\nSLMs are good news for developers and users but may be very bad news for investors who have bet on the firms building massive data centers using super-fast chips and LLMs. All stock bubbles burst eventually. The countdown for the AI tech bubble collapse may have begun.",
      "source": "Dailyreckoning.com",
      "url": "https://dailyreckoning.com/superintelligence-is-beyond-reach/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Your cameras have been delivered!",
      "content": "AI: enough! Topic: technology, general, opinion Link here\n\nSunday's detailed investigation of generative artificial intelligence should have been enough, but it occurred to me that there was one thing I hadn't tried: graphics. OK, draw me a caricature of Greg Lehey.\n\nGoogle Gemini came up with this:\n\nOf course I don't need to like the results, but this shows very little understanding: no mention of BSD, just Linux (or even “Linix”). Yvonne tells me that it looks nothing like me. Compared to the text results, quite disappointing.\n\nAnd that was all. My other bots all couldn't do it. But their attempts were worth mentioning:\n\nChatAI\n\nI'm unable to draw images directly, but I can help you imagine a caricature of Greg Lehey! Picture a gentleman with a thoughtful expression, perhaps with glasses perched on his nose, and a hint of a smile suggesting a keen sense of humor. His hair might be slightly tousled, giving him a scholarly yet approachable look. You could exaggerate his features, like giving him a larger forehead to symbolize his intellect or a prominent chin to represent determination. Add a background filled with books and computers to reflect his interests in technology and writing\n\nI suppose that's acceptable for as far as it goes.\n\nClaude\n\nClaude did the best with the diary entry, but it failed completely with the caricature:\n\nClaude: I'd be happy to help you create a caricature, but I'll need a bit more information! There are likely multiple people named Greg Lehey, and I want to make sure I'm drawing the right person..\n\nClaude, you know who I am. There are “likely” multiple people named Greg Lehey? That wasn't a problem on Sunday. And as it happens, there is nobody else that I can find with the same name as mine. But OK, draw me a caricature of Greg Lehey, the FreeBSD person.\n\nI can't create visual caricatures or drawings as I'm a text-based AI. However, I'd be happy to help you in other ways: Written description: I could write a humorous written \"caricature\" or character sketch of Greg Lehman (assuming you meant Greg Lehman, a notable FreeBSD contributor) that captures his programming style, contributions to FreeBSD, or personality traits in an exaggerated, caricature-like way.\n\nWhat a cop-out! Now it says that it can't draw. And it comes up with a fictive Greg Lehman. That's completely useless.\n\nDeepSeek\n\nAs before, DeepSeek is inventive:\n\nWhile I can't physically draw for you, I can create a detailed \"blueprint\" for a caricature of the legendary BSD developer Greg \"Groggy\" Lehey. An artist could follow this description to create the perfect caricature. Here is a description designed for an artist to illustrate. Caricature of Greg \"Groggy\" Lehey Concept: The caricature should capture his iconic, jovial, and slightly mischievous personality, deeply intertwined with his life's work: BSD and Unix. Key Features to Exaggerate: The Beard and Hair: This is the #1 feature. Exaggerate his magnificent, full, and sprawling white beard. Make it vast and wizard-like, almost as if it's its own entity. It should be big enough to have a Daemon (the BSD logo) peeking out from within the whiskers, as if it lives there. His hair (what's visible under his hat) should be similarly wild and unkempt. The Headwear: He is almost never seen without a hat. Draw a slightly battered, well-loved flat cap or a beret perched on his head at a jaunty angle. Where did it get the hat from? I am almost never seen with a hat. The Expression: A wide, knowing, and cheerful grin. His eyes should be crinkled with laughter and wisdom, suggesting he's both a kind mentor and someone who knows where all the bugs in the code are hidden. The Props & Surroundings: In his hand: Instead of a coffee mug, he should be holding a massive, steaming beer stein. This is a nod to his famous \"Buy me a beer\" link on his website and his good-humored nature. Steaming beer? I can't even imagine that. And instead of referring to my brewing activities, it refers to a fictive “buy me a beer” link, which may be related to Poul-Henning Kamp. Under his arm: A well-worn copy of his magnum opus, \"The Complete FreeBSD\" book. Background Element: Have a Tux (the Linux penguin) peeking from around a corner, looking slightly nervous or annoyed, while Groggy pays it no mind. This playfully hints at the good-natured rivalry between BSD and Linux. Code: Faint lines of C code ( #include <beard.h> , printf(\"Cheers!\n\n\"); ) can be subtly woven into the texture of his shirt or the background. Overall Vibe: The image should feel warm, intelligent, and full of character. He is the friendly, brilliant, and slightly eccentric \"Unix Beard\" wizard, a beloved figure in the open-source community. Color Palette: Warm tones. Earthy browns for the hat, a rich color for the shirt (green or blue), the brilliant white of the beard, and the gold of the beer.\n\nStill, I suppose that could produce something useful. But where are all the image generators? Do I want to look? I've spent enough time on this already.\n\nWhy don't people read any more? Topic: language, general, technology, opinion Link here\n\nRecently I saw (but didn't read) a newspaper article, possibly from the New York Times, asking why people don't read books any more. The answer appears simple: information overload. When I was a lad I read lots of books, but it has been some time since I finished reading any, and then the relatively thin “Brave New World”.\n\nBut then we watched A Town Like Alice, and Yvonne borrowed the book. I have always liked Nevil Shute, and I have a number of his books, so I read it when she finished. It took me two weeks. While reading I was continually following up on details mentioned in the book—that's what the web is for, after all. In general, I ended up with a much broader view than I would have had if I had just read the book.\n\nAnd how did I like it? Not much. Clearly it's two different stories stuck together: the ordeals in Malaya at the hand of the Japanese occupation and the transformation of a tiny bush village in Queensland into a small town. The latter, in particular, seems very improbable.\n\nThe geographical details are what interested me most. Particularly in Malay(si)a I knew most of the real places. But I'm puzzled about why Shute spends a lot of time in the area Maran and Jerantut in the Jengka Triangle, places that must have been almost completely unknown at the time, but puts the women in a place called Kuala Telang “about half-way between Kuantan and Kota Bahru”. There is a town in that position, but it's called Kuala Terengganu, and it's a big town (capital of the state of Terengganu), not a small village. My guess is that Shute had never heard of it.\n\nSpelling is also strange. In the first half of the book, Kota Bharu was spelt “Kota Bahru”, and in the second half “Khota Bahru”. Tennant Creek became “Tennants Creek”. These spellings are the same both in the online book and the physical book that I read. And there are a couple of irritating US Americanisms that I don't understand: the animals central to the theme are called alligators, not crocodiles. The stockmen use lariats.\n\nThen there's the question of racial attitudes. The local aborigines (or aboriginals, to use the modern politically correct term) are called “boongs” or “abos”. Both are offensive nowadays. And there was talk of racial segregation, a separate milk bar for the boongs. This would have been about 1948, the time of my birth. Did such segregation really exist then?\n\nMy favourite one, though, is when the main characters (Jean and Joe) fall in love, and she decides not to sleep with him until after they are married. Given that Joe had been crucified in the first half of the story, I was half guessing that he might have been castrated at the same time, and Jean would not have found out until too late.\n\nIn summary: reading books has become much more of an exercise than it used to be. For light entertainment we have TV. I don't think I'll read another novel for some time to come.\n\nPredicting the past Topic: general, technology, opinion Link here\n\nI keep a close eye on the weather forecasts from the Bureau of Meteorology, both of them. There's one on the web and another for mobile phones. They don't often agree with each other, and of course they're both frequently wrong.\n\nToday, though, the mobile phone app excelled itself. We finally have rain, 6 mm over the last 24 hours. Or, as the app put it,\n\nPart of the app is a rainfall map showing precipitation. That showed that there was much more rain. How can that happen?\n\nWhatsApp: bug after bug? Topic: technology, opinion Link here\n\nI've been trying for a week now to set up video telephony on fossil, Yvonne's mobile phone. Somehow the “modern” approach to user interfaces shows itself at its worst here. But I had come to the conclusion that if I can work beyond WhatsApps bizarre interface, and explain it to Yvonne so that she doesn't have a panic attack every time she uses it, we might have something useful, especially since WhatsApp can communicate by an Internet link, which could be much cheaper.\n\nOK, try out on hirse first. It doesn't have a SIM card, so any communication has to go by the Internet. Migrate my main number to hirse. No problem. Make a call. Some message like “need to use the phone network”. Oh.\n\nTry calling in. The problem: hirse has the phone number associated with a SIM card in albo, which has a different WhatsApp number. Which does WhatsApp call? albo! Somehow there's more to this than meets the eye.\n\nWhen Yvonne got back from shopping, I changed her WhatsApp number to the number of second SIM on her phone. All sorts of things didn't work, and it couldn't call the number on hirse. hirse claimed that she wasn't registered, though I had set the “notify contacts” during the migration. In the end I moved the number back to the old one. And things still didn't work correctly! In particular, I could call the number, but WhatsApp didn't respond in any way, not even registering a missed call. Went through the settings and set tones for all notifications. Still no response. Restart the app. No response.\n\nNothing for it, the Microsoft solution: reboot. And yes, now it responds. Clearly some kind of bug. And it repeats the call tone for every notification, including messages. Oh, my bad. Get rid of the tone. Sorry, there's no provision for that. Select something at random, since it's too polite to play the tone when you're selecting it. I still get the ring tone for messages! I can't see any explanation except that it's another bug. It was getting late, so I turned off sounds to wait until tomorrow.\n\nAll this is made worse by the horrible user interface. So far I haven't found a way to display the associated phone number in the contact details. At one point I made the mistake of using the same name (mine) for both my phones, so there was no way at all to find out what “number” it had called.\n\nI hate WhatsApp! Topic: technology, general, opinion Link here\n\nMore fun with WhatsApp today. The first question, which decides whether it's even worthwhile: can I make a call over the Internet? Yesterday's experiments were overshadowed by other bugs. Today I tried making a call from fossil (Yvonne's phone) to hirse, the one without a SIM card. I have set it up with the main number of albo, so a normal call to that number should go to albo, and a WhatsApp call should go to hirse. Does it?\n\nYes! So yesterday's issues were probably due to other bugs.\n\nAnd the incorrect notification tones? Gone since the last reboot, Yvonne says. But later she changed her mind: once again the wrong tone when all notification tones were turned off.\n\nDammit, begone, WhatsApp! Removed it. Reinstalled it. And how about that, setup was almost completely without problem. She lost her image (“Avatar”, “The manifestation of a god in bodily form on earth” according to the OED). We can live with that. And somehow now everything Just Works—until the next unpleasant surprise.\n\nApart from that and the horrible user interface, established that you can change an audio call into a video call simply by pressing the button with the box with a loudspeaker on the right:\n\nInterestingly, it only works in one direction. To go in the other direction requires that the person at the other end do the same.\n\nVirtualBox again Topic: technology, photography, opinion Link here\n\nDxO PhotoLab 9 is out, and it looks worth trying. Time to reinstate one of my Microsoft virtual machines, which run under VirtualBox.\n\nI stopped using VirtualBox on hydra a year ago, though it was the main reason that I had so much memory (192 GB): I ran into network problems that I couldn't fix.\n\nNow FreeBSD has a port of VirtualBox 7. Time to try again? Tried first on dereel, with only 24 GB of memory. Where's my HOWTO? All fine, but it doesn't tell me how to add an existing VM. It must be in this diary somewhere, but where? I really should keep these HOWTOs up to date.\n\nStarting up the GUI was different from before, of course. And it wanted to set things up in the root file system. To go elsewhere I had to do this horrible tree walking. Finally I got to where I wanted (/src/VirtualBox/echuca). Tried to create a new VM. “Can't overwrite machine folder...\". What does that mean? They should know better than to call a directory a folder, but what's a “machine folder”? Lots of experimentation, continually being returned to the /root directory and having to climb my way out again. What does “help” say? Nothing. I wonder if the port forgot to install something important. After a while I discovered that it really wanted the parent directory /src/VirtualBox, but then I ran into other issues.\n\nAfter some time decided to create a new VM with the old virtual disk. Link? Yes, but VirtualBox detected the UUID and used the old name.\n\nYes, there are other possibilities. But I think that the best is to go through my diary and extract the information that I need to do things sanely. And maybe I should use the commands rather than the GUI, which seems to be getting more stupid as time goes on.\n\nWhatsApp an Avatar? Topic: technology, general, opinion Link here\n\nYesterday I established that an Avatar is a earthly manifestation of a Hindu god, but WhatsApp apparently wants to elevate Yvonne and me to deities. Until then, only initials appear to identify us on calls.\n\nOK, how do we do that? Settings, of course, “make your own avatar”, “Create from selfie”. OK. Take a suitably horrified photo of myself. Briefly it showed “There was an error with the avatar gen...”, so briefly that I didn't see it the first three times. What does that mean? Why can't it finish its sentences? So instead it presented me with a manual generation.\n\nWhy? What does the half message mean? It's repeatable on two different phones. And there seems to be no way to just add a normal photo. What a mess!\n\nVirtualBox progress Topic: technology, opinion Link here\n\nSo what's wrong with my VirtualBox installation? My current situation was exactly what I had a year ago: most VMs worked, but Microsoft VMs had networking problems. They could send data, but they didn't see the replies, so they hung in ARP. I attributed that to the version of VirtualBox (6.1.50 r161033), so I waited until version 7 came out. And then I discovered that I had exactly the same problem.\n\nThat didn't help just getting things running. After some searching, discovered that VirtualBox stores a configuration in the home directory, ~/.config/VirtualBox/ with a number of files, including log files that have no business there, but importantly VirtualBox.xml. OK, make a copy of that on dereel, and how about that, VirtualBox came up with all the VMs I knew.\n\nStart disaster, the only VM that would fit in dereel's memory.\n\nVT-x is disabled in the BIOS for all CPU modes (VERR_VMX_MSR_ALL_VMX_DISABLED).\n\n\n\nOh. There was something there, but can the twins help? Yes, specifically for a ThinkCentre:\n\nOnce in the BIOS, use the arrow keys to navigate to the Advanced tab. From the Advanced menu, select CPU Setup and press Enter. Look for an option labeled Intel(R) Virtualization Technology and select it. Using the arrow keys, change the setting from Disabled to Enabled.\n\nAfter that and rebooting, and with a change of network adapter name, it still didn't start. I got this message:\n\nX86_CPUID_AMD_FEATURE_EDX_AXMMX is not supported by the host but has already exposed to the guest [ver=19 pass=final] (VERR_SSM_LOAD_CPUID_MISMATCH).\n\nMore help from the twins. The saved state includes information from an AMD processor (hydra), but this is Intel. Discard saved state and start again.\n\nAfter that, and with a change of network adapter name, it started. I got this message, which I haven't seen before, but which seems harmless:\n\nerror: XDG_RUNTIME_DIR is invalid or not set in the environment.\n\nThat variable isn't set on hydra either.\n\nWe're still not done. Trying to start an xterm from current gave me the message\n\nThe Virtual Machine reports that the guest OS does not support mouse pointer integration\n\nWhat's that? Gemini tells me:\n\nThe message \"The Virtual Machine reports that the guest OS does not support mouse pointer integration...\" in a FreeBSD virtual machine is common and means you need to install and configure the necessary guest additions for the mouse to work seamlessly. FreeBSD does not include these drivers out of the box, so you must install them yourself.\n\nThat sounds like the Ports Collection. But there is no additions package for VirtualBox 7.1, only for 6.50 and 5.2. Mañana.\n\nOn with disaster. So: ARP issue? While messing around on disaster, found the help message for ARP. It uses Unix-style option delimiters, and -s sets a permanent MAC address. OK, if this is an ARP issue, we can fix that:\n\nOh: Microsoft has a different format for MAC addresses. Try again:\n\nAnd that as Administrator . Time to ask the twins.\n\nQ: What does \"The ARP entry addition failed: Access is denied\" when running CMD as administrator under \"windows\" 10? A: The \"ARP entry addition failed: Access is denied\" error in Windows 10, even when running Command Prompt as an administrator, typically happens when trying to add a static Address Resolution Protocol (ARP) entry for a reason other than a permission issue.\n\nInteresting. “Access is denied” is not a permission issue? Something's wrong here, either Gemini or Microsoft. My money is on Microsoft.\n\nAnd that's what Gemini suggests too:\n\nUse netsh instead: In some cases, especially on newer versions of Windows, the arp command may have issues with Access is denied errors even when the user has administrator privileges.\n\nSo I ended up with this simple invocation:\n\nAnd how about that, it worked. Well, at least it put the address in the ARP table, and I was able to ping out, so disaster knew the address. But it still didn't hear any reply.\n\nYet another question to Gemini:\n\nWhat could cause a Microsoft guest under VirtualBox to send network data but not receive it, when other guests have no problem with the same configuration?\n\nThe obvious answer: firewall. Check to be on the safe side. No, no firewall enabled. How about an Ethernet adapter issue?\n\nIf you are using an Intel PRO/1000, try switching to a different type, such as the AMD PCnet-FAST III.\n\nOK, try that. No improvement. Next idea: this video\n\nOK, try anything once. Follow the instructions step by step, none of which showed any obvious issues. Change the interface back to (specifically) Intel PRO/1000 MT Deskop (8254EM). Not much hope there: that's what I had.\n\nBut it worked! My final configuration looks identical to the start configuration. What changed? There's something lurking under the surface that I don't understand. Can I now get it to run on hydra?\n\nMore VirtualBox pain Topic: technology, opinion Link here\n\nYesterday I finally got networking working using VirtualBox 7.1 and Microsoft “Windows” 10. Time to refine a few things. First, start the windows on hydra:0.0, a 1920×1080 display, rather than on hydra:0.1, which has 3840×2160, giving windows that are too small.\n\nBut it didn't work! I could start on hydra:0.1, but on hydra:0.0 nothing happened. Is there some kind of built-in memory in the configuration file?\n\nSo, time to upgrade current.lemis.com, another VM running FreeBSD-CURRENT. It was a year out of date.\n\nStart a make buildworld , not for the first time. But nothing happened!\n\nFurther investigation showed that I had a network hang. And disaster was also hanging! Shut down disaster and current regained network access—for a while. Then it hung again.\n\nThis seems worse than my experience on hydra with VirtualBox 6.5. Tried it there and it worked.\n\nWhat a pain! What does Google Gemini say?\n\nQ: Are there known networking issues with VirtualBox under FreeBSD? A: Yes, there are known networking issues and quirks with VirtualBox when used as a host on a FreeBSD system. While VirtualBox works, it is not an officially \"supported\" host platform by Oracle, which means users often have to rely on the community and package maintainers to troubleshoot and resolve issues. (much irrelevant information omitted) Users sometimes experience slow network speeds, particularly with upload speeds, when using bridged adapters. This can be more pronounced on specific emulated network card types. While VirtualBox can function as a host on FreeBSD, it is not a \"fire-and-forget\" solution... If you encounter speed or reliability issues, experimenting with different emulated network adapter types can often resolve the problem.\n\nThat's not encouraging, though it doesn't directly relate to my problems. But what else can it be? Two different versions of FreeBSD, two different machines, two different versions of VirtualBox. Does it work better on Linux? That would be a real let-down, but possibly I should try it. How much pain would that be?\n\nTesting RSS feeds Topic: technology Link here\n\nI write all my web markup myself, with the aid of a number of PHP scripts. The result is that the RSS feed looks nothing much like my sources. So when something goes wrong with the markup, it's hard to find where, not helped by things like the W3.org validator, which typically points to where the error is detected, not where it occurred, and which at the moment caches input, so even after fixing the problem it reports the old problem.\n\nCallum Gibson is the main user of RSS feeds whom I know of. He pointed me to this validator. It also points to where the error was found, but at least I can try things and repeat them. That fixed an issue I had with earlier this month, where the error was over 100 lines from where it was detected.\n\nChasing the VirtualBox bug Topic: technology Link here\n\nSo why was VirtualBox version 7.1 on dereel even worse than version 6.50 on hydra? One possibility might be that the VMs themselves were NFS mounted. OK, find a 1 TB disk and copy them there. Put it in in place of the DVD drive, and was amazed to find that it came up as /dev/ada0, relegating the system disk to /dev/ada1 and requiring manual intervention (/etc/fstab) to continue. How could that happen?\n\nThen copying the VMs from hydra. That took a few hours, of course, so I'll continue tomorrow.\n\nWhile looking for the disks also found one marked “MS “Windows” 10 disgust”, dated 10.XII.2020. Comparing with my diary, that proves to be the disk that came with the machine I'm working on. So I should be able to just put it in and run it. That's the next thing to do if I still can't get VirtualBox to run reliably.\n\nDxO PhotoLab 9: worth the trouble? Topic: photography, technology, opinion Link here\n\nI've spent a lot of time looking at the new features of DxO PhotoLab 9. Even better noise reduction, of course, but the big new thing is what appears to be excellent object recognition (“masking”). But that's only part of the story. Can I remove objects? Replace them with something else? It seems that the answer is “no”.\n\nSomewhere I also thought I saw a way to merge HDR images, but that seems to be a misunderstanding. Instead they have improved file handling, including collapsing related image groups and automatic file naming. None of them seem to be anywhere near as flexible as the method I worked out 13 years ago, so it's of no use to me.\n\nSo: what will the future bring? The masking is good, but is it enough to spend US $240 on? There's a very good chance that they'll come up with a version 10 in the not-too-distant future and want $120 for an upgrade. Maybe I should just wait.\n\nVicRoads: still in the 20th century Topic: general, technology, opinion Link here\n\nAfter scrapping my Hyundai Elantra at the end of July I was due a refund for the registration.\n\nAnd they sent me a cheque! I thought they went out of fashion well over a year ago. And yes, the bank refused to accept it.\n\nBut why? I really don't understand. They should have transferred it to my bank account, like any sane company. But no, I had to call their customer service line (1300 555 165, which looks suspiciously like a fake US phone number) and go through their silly authentication process (including a form of 2FA, sending a PIN to my phone. That would have helped a lot if I had been calling from that phone). But yes, relatively quickly they took the details and told me that the transfer would occur in the next 2 to 3 weeks. Receipt number HD1155831.\n\n2 to 3 weeks? Why? Ah, we need human intervention. Why? Nowadays we have computers. With only marginally good programming the money could have been in my bank account before the end of the call. But clearly they don't have that.\n\nMore VirtualBox insights Topic: technology, opinion Link here\n\nSo what's wrong with VirtualBox networking? Google Gemini had suggested that it might depend on the emulated network adapter, so spent some time trying different adapters, with no improvement. About the only thing that was clear was the ping time: from guest to host the expected 0.15 ms, but in the other direction much longer, and with wildly different times:\n\nround-trip min/avg/max/stddev = 29.752/61.679/175.892/36.953 ms\n\nGave that up and looked at some bug reports, which showed surprisingly few network issues. But one, by Ivan Rozhuk, was interesting:\n\nTry to disable HW offloads on NIC:\n\nifconfig igb0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n\n\nAnd how about that, that worked. So why is this not better known? There's also a wiki with surprisingly little of use.\n\nLater I discovered that my guest current.lemis.com had 8 CPUs, while the host dereel only has four. That's quite impressive that it worked at all. Reducing the number of CPUs on current got rid of the slow ping times.\n\nSo: are we done? I don't think so. I still need to find whether the Microsoft guests work reliably.\n\nBruce Evans' C compiler Topic: technology, opinion Link here\n\nMail in the TUHS mailing list today:\n\nSubject: [TUHS] Bruce Evans 386 Minix patches & compiler source\n\n\n\nIt's been quite a while since I was messing with Minix386 back in the days\n\nwhen Bruce Evans released a set of patches to bring 386 support.\n\nI'm pretty sure over on oldlinux.org the patch set exists, but I can only\n\nfind the one set of binaries of his 386 toolchain.\n\nI know it eventually evolved into the bin86 toolchain that Linus would go on\n\nto use to create real mode boot code, but I don't know if any of the source\n\ncode to his 1991/1992 386 toolchain ever got published?\n\n\n\nIs it somewhere on the disk images that Peter Jeremy saved? I haven't looked at them for over three years, and I only had the smaller ones that I could download. Sent off a message to the other people who have access, Warren Toomey (who also coincidentally runs TUHS) and Warner Losh, and only got a brief response from the first.\n\nBack to look at what I have: three files, /src/bde/ad1.img, /src/bde/ad2.img and /src/bde/ad3.img. I had only looked at /ad0.img, requiring gnop to access the individual partitions. There was a good reason: I had renamed ad2.img.xz to ad2.img without uncompressing it. Did that now and ended up with 60 GB of data.\n\nAnd the contents?\n\n=== root@dereel (/dev/pts/1) /bde 13 -> mdconfig -a -t vnode -f /src/bde/besplex/ad2.img\n\nmd0\n\n=== root@dereel (/dev/pts/1) /bde 14 -> l /dev/md0\n\nmd0 md0s1 md0s2 md0s2a md0s2b md0s2d md0s2e md0s2f md0s2g md0s2h\n\n\n\nAll the BSD partitions there! So I can just mount them:\n\n=== root@dereel (/dev/pts/1) /bde 15 -> mkdir a b d e f g h\n\n=== root@dereel (/dev/pts/1) /bde 16 -> l\n\ntotal 1\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 a\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 b\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 d\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 e\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 f\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 g\n\ndrwxr-xr-x 2 root wheel 512 10 Sep 13:28 h\n\n=== root@dereel (/dev/pts/1) /bde 35 -> for i in `echo a b d e f g h`; do mount -o ro /dev/md0s2$i $i; done\n\nmount: /dev/md0s2a: No such file or directory\n\n=== root@dereel (/dev/pts/1) /bde 36 -> df\n\nFilesystem 1048576-blocks Used Avail Capacity Mounted on\n\n...\n\n/dev/md0s2b 3,952 3,542 93 97% /bde/b\n\n/dev/md0s2d 3,952 2,971 664 82% /bde/d\n\n/dev/md0s2e 3,952 3,658 -21 101% /bde/e\n\n/dev/md0s2f 3,952 3,514 121 97% /bde/f\n\n/dev/md0s2g 11,754 8,842 1,972 82% /bde/g\n\n/dev/md0s2h 29,525 14,599 14,926 49% /bde/h\n\n=== root@dereel (/dev/pts/1) /bde 37 ->\n\n\n\nAnd in one of the partitions I found a file /bde/e/besplex/home/bde/dist/minix.tar.gz, which may be just what Jason is looking for. That was much easier than I thought. Is it correct? That would be too easy.\n\nMore fun with VirtualBox and bde Topic: technology, opinion Link here\n\nMore playing around with VirtualBox today, with no breakthrough. I had paused dereel with zzz, and when I restarted it the networking had gone to hell again. Here a repeat of what I had done yesterday:\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 1 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500 options=4e524bb<RXCSUM,TXCSUM,VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,LRO,WOL_MAGIC,VLAN_HWFILTER,VLAN_HWTSO,RXCSUM_IPV6,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 2 -> ifconfig em0 -rxcsum -txcsum -vlanhwtso -lro -tso4 -tso6 down up\n\n=== root@dereel (/dev/pts/3) /eureka/home/grog 3 -> ifconfig\n\nem0: flags=1008943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST,LOWER_UP> metric 0 mtu 1500\n\noptions=4c120b8<VLAN_MTU,VLAN_HWTAGGING,JUMBO_MTU,VLAN_HWCSUM,WOL_MAGIC,VLAN_HWFILTER,TXCSUM_IPV6,HWSTATS,MEXTPG>\n\n\n\nAfter that it worked normally again, but the Microsoft boxen still didn't want to know. Do I have to cold start them every time?\n\nAnd Bruce Evans' C compiler? I posted what I had and got no answer. I'm not convinced that I have the right files, though the name usr/src/mx386/bcc (from the archive e/bde/dist/minix.tar.gz) does raise some hope.\n\nPower fail! Topic: general, technology, opinion Link here\n\nAt 11:04, while preparing breakfast, we had a grid power failure. Not a problem: we have a PV system. But the power dropped totally! Almost before we knew it, it was back again. The inverter log shows less than a minute.\n\nThat's not the first time. It happens far too often, most recently two months ago. And today, as then, my main machines eureka and hydra lost power, because I still hadn't got round to getting a UPS installed. Today I made up for that: I have a ten-year-old 1000 VA 650 W UPS just lying around. It is still functional? In contrast to the CyberPower UPS that I bought 2½ years ago, it seems still to work. While the power was down, took the opportunity to tidy up the mess to the left of my desk top, removing this display card from eureka and making a cut in my fingertip in the process:\n\nThat once drove three of the four monitors then connected to eureka, but that was years ago, as the dust suggests.\n\nWhat caused the outage? Hard to say. The inverter logs show no sign of overvoltage before the outage, though afterwards the voltage hung over 250 V for over an hour. I suppose it's time to brave the potential issues and update the firmware.\n\nPowercor had a different view. An hour later I received a message:\n\nAnd then\n\nOn checking, I found that I also had similar messages from the day before, where there was no outage at all. Still, rather phantom outages than real ones.\n\nhydra upgrade Topic: technology, opinion Link here\n\nI've had hydra for nearly 2 years, and I still haven't got round to configuring it quite the way I want; much is in the X menus. But of course the system is now down-rev. What better time then after a power failure to bring it up to date?\n\nMy real concern after an update is that the ports will no longer work the way I want. Building a new world is relatively simple, and it took just shy of 1000 seconds to build the world and new kernel. And rebooting went relatively smoothly, though it no longer found the Ethernet card on the motherboard. I had suspected issues in that area (it's a 2.5 Gb/s Realtek card) and installed a second, which showed up as re0 , so all I needed to do was to change where I plugged in the network cable.\n\nAs I feared, the ports were a different matter. They were worse then ever before, taking 3 iterations to delete 100—no, 101—no, 103 ports, including chromium curl, emacs of course, enblend, exiv2, feh, ffmpeg, firefox, fusefs-curlftpfs, gdb, git, gnupg, groff, hugin, mplayer, mpv, mutt, rdesktop, rsync, rtorrent, vigra, virtualbox-ose, xpdf and xv. And even then I missed ImageMagick, which further annoys me with a change of name. Yes, convert is a subcommand of ImageMagic, but now they have decided that the name is too invasive, so I'll have to change all invocations to magick convert. I suppose that one's fair enough.\n\nAnd firefox has new messages, which it spews by the hundred where it presumably suspects nobody is looking, on the home terminal:\n\nconsole.warn: services.settings: Could not determine network status. Message: TypeError: can't access prop \"isLinkUp\", lazy.gNetworkLinkService is undefined\n\nGradually the issues became clear: I can no longer connect to eureka with ssh, nor at all to hydra. I was expecting issues with eureka, but not with hydra. Was it because it came up before the network was ready? I had to restart syslogd to get it to write to eureka, and to change the permissions on wake for normal users to use it.\n\nWhat am I left with? I can no longer use erc, the Emacs IRC command:\n\nerc: missing symbol (.at)\n\n⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.⛔ Warning (erc): Required module ‘networks’ not loaded. If this was unexpected, please add it to ‘erc-modules’.\n\n\n\nWhat does that mean? I'll find out some time. Fortunately it still works on eureka, so there's no hurry.\n\nAnd independently of all that I need to pay more attention to my X configuration. I still don't get my mice set up correctly at startup. But that's fun for another day.\n\nCompleting the upgrade Topic: technology, general, photography, opinion Link here\n\nInto the office this morning as usual. No mail from hydra. What happened there? /var/log/maillog showed a number of:\n\nSep 20 03:03:54 hydra postfix/cleanup[70392]: B1BC41AB5: message-id=<202509191703.58JH3sRP070451@hydra.lemis.com>\n\nSep 20 03:03:54 hydra sendmail[70451]: 58JH3sRP070451: to=root, ctladdr=root (0/0), delay=00:00:00, xdelay=00:00:00, mailer=relay, pri=33687, relay=[127.0.0.1] [127.0.0.1], dsn=2.0.0, stat=Sent (Ok: queued as B1BC41AB5)\n\nSep 20 03:03:54 hydra postfix/qmgr[1845]: B1BC41AB5: from=<root@hydra.lemis.com>, size=4303, nrcpt=1 (queue active)\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: unexpected attribute smtputf8 from local socket (expecting: sendopts)\n\nSep 20 03:03:54 hydra postfix/smtpd[70368]: disconnect from localhost[127.0.0.1] ehlo=1 mail=1 rcpt=1 data=1 quit=1 commands=5\n\nSep 20 03:03:54 hydra postfix/local[70440]: warning: deliver_request_get: error receiving common attributes\n\n\n\nWhat's smtputf8 ? Checking /usr/local/etc/postfix/ showed that a number of files, which should have been symlinks to the same directory on eureka, were missing. Forgot to mount a NFS file system. After mounting and restarting postfix, all was well. But what does the strange message mean? It seems that it's a default.\n\nAnd then there was Hugin. I had expected some issues, but not what I got: when I tried to start the “fast panorama preview” I got\n\nerror installing GLEW\n\nFast preview window can not be opened\n\nWhat does that mean? I have a package installed, which pkg reports as\n\nglew-2.2.0_3 OpenGL Extension Wrangler Library\n\nAnd there doesn't seem to be anything else that was there before. But when I retried the attempt, it worked. Where is the bug? Hugin or FreeBSD? In addition, irritatingly it resized the windows on every start. I thought I had got rid of that with some script magic, but it seems to be gone.\n\nAnd then there's the mouse. That's simple enough: instead of searching for the index for the mouse, it's easy enough to write\n\nxinput set-button-map \"Telink 2.4G Mouse\" 1 2 3 4 5 6 7 2 2 10\n\nOne of the messages I received was completely misleading:\n\n=== grog@hydra (/dev/pts/16) ~/Photos/20250920 47 -> (EE) event4 - Telink 2.4G Mouse, class 0/0, rev 1.10/1.00, addr 4: client bug: event processing lagging behind by 32ms, your system is too slow\n\n(EE) client bug: timer event4 debounce: scheduled expiry is in the past (-48ms), your system is too slow\n\n(EE) client bug: timer event4 debounce short: scheduled expiry is in the past (-61ms), your system is too slow\n\n\n\nThat's not hydra at all, despite the prompt. I started X on teevee from hydra, and this appears to be its way of saying “the cat got on my mouse”.\n\nAccessing systems with ssh from eureka Topic: technology Link here\n\neureka is now running a nearly 10 year old system, but I don't want to update it: it works.\n\nBut some issues remain. One was that I couldn't automatically log on with ssh: I had to enter a password, which is irritating in scripts. Once again Google Gemini to my aid. Add this to /etc/ssh/sshd_config:\n\nPubkeyAcceptedKeyTypes=ssh-ed25519,ssh-rsa,rsa-sha2-512,rsa-sha2-256\n\nNow I just need to see why I can't access eureka from hydra without a password.\n\nFinally the birding photos Topic: photography, animals, technology, opinion Link here\n\nIt's been 4 days since the latest OM System birding “workshop”, and I've only just got round to processing the best photos. Are these the best?\n\nIt's a lot of work making up my mind out of over 250 photos. Yvonne did it for me, and those were the ones she liked.\n\nMore ssh strangeness Topic: technology, opinion Link here\n\nI've already established issues with ssh sessions from hydra to eureka, but not from other systems. Once again Google Gemini to my aid, this time less useful. It tells me to allow ssh-rsa in /etc/ssh/sshd_config by adding this line:\n\nPubkeyAcceptedKeyTypes=+ssh-rsa\n\nWe've seen that before on the other side. But that's a non-starter: sshd doesn't want to know:\n\n=== root@eureka (/dev/pts/1) /etc/ssh 28 -> service sshd restart\n\nPerforming sanity check on sshd configuration.\n\n/etc/ssh/sshd_config: line 54: Bad configuration option: PubkeyAcceptedKeyTypes\n\n/etc/ssh/sshd_config: terminating, 1 bad configuration options\n\nOK, what about the alternative of using a key?\n\n=== root@eureka (/dev/pts/1) /etc/ssh 32 -> service sshd restart; date\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStopping sshd.\n\nWaiting for PIDS: 22656.\n\nPerforming sanity check on sshd configuration.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\nStarting sshd.\n\nCould not load host key: /etc/ssh/ssh_host_ed25519_key\n\n\n\nWhy? It doesn't seem to affect other key forms. And comparing hydra and tiwi gives me on hydra:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: send_pubkey_test: no mutual signature algorithm\n\n\n\nBut on tiwi it works as expected:\n\ndebug1: Offering public key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\ndebug1: Server accepts key: /home/grog/.ssh/id_rsa RSA SHA256:S7sZHLcY4dgw53/rF70vrScdPuGef3enHdJzuYA1WDo agent\n\nAuthenticated to eureka.lemis.com ([192.109.197.137]:22) using \"publickey\".\n\n\n\nWhat's the difference?\n\nMutt problems Topic: technology, opinion Link here\n\nFirst thing I do in the morning is to read the overnight mail, typically a couple of hundred messages. But this morning I tried to delete the messages I had read, I received the message “unable to write mailbox” or something similar. Why? Normally I see a message like that when I'm out of disk space, but this wasn't the case. Return, painfully delete the messages again, and it worked. Is that an NFS issue? It has happened before. Was that also overnight? I'll have to look more carefully next time.\n\nMore ssh pain Topic: technology, general, opinion Link here\n\nInto the office this morning to find eureka maxed out with at least 35 ssh-add processes, all looping at 100% CPU time.\n\nWhy? This is not a new program:\n\n3054180 -r-xr-xr-x 1 root wheel 17576 25 Nov 2015 /usr/bin/ssh-add\n\nOnce again Google Gemini to my aid, coming with the suggestion that it could be that ssh-add was running already, and that I should put in code like\n\nssh-add -l >/dev/null || ssh-add\n\nThat worked up to a point, but it doesn't explain why it is only happening now, after nearly 10 years. It's much more likely that it's related to the playing around I have been doing lately, though it didn't affect ssh-add, and I had backed out the changes anyway. And in the course of the day I found another instance in my weather software, but that found further breakage: the external view of my weather stopped in early June when I got the new weather station. More to fix when the current problems are over.\n\nssh-add: A clue Topic: technology, opinion Link here\n\nI haven't done much to investigate the ssh-add problem for the moment. It seems that I call ssh-add in a number of places, all of which need fixing. But while playing around I found:\n\n=== grog@eureka (/dev/pts/3) ~/public_html 32 -> ssh-add < /dev/null\n\nEnter passphrase for /home/grog/.ssh/id_rsa:\n\nCould it be that the looping is the incorrect handling of a prompt? It doesn't help much in fixing it, but it could help understand.\n\nThe advantages of upgrades Topic: technology, opinion Link here\n\nAs expected, upgrading hydra caused a number of problems, most of which I have described. And this time it was Chromium, which has forgotten all its editing keys, or at least the ones I want. More searching required.\n\nOn the other hand, one bug has gone away: xv can now display PNG again. Not exactly a big improvement, but at least a fixed bug.\n\nThe daily Android bug Topic: technology, opinion Link here\n\nSomehow the Android operating system seems to be the least reliable I know. I'm gradually coming to terms with it, but today there was another one: trying to download files to a Real Computer, albo didn't respond, though it claimed to be working. Disable Wi-Fi, reeenable, and it worked. No change of connection.\n\nWhat a mess Android is!\n\nAnother web server overload Topic: technology, opinion Link here\n\nIt's been well over 4 months since I set up a new external web server, fra.lemis.com, to address the really heavy load, with load averages up to 170. And so, of course, it dropped back to under 1.\n\nBut now it's increasing again, both servers now well over 200. Why? I had thought it was related to the imagesizes parameter, but that doesn't seem to be the case. Let's see how long the overload lasts this time.\n\nFast postal service Topic: general, technology, opinion Link here\n\nI've bought a couple of cameras in the United Kingdom. The usual tracking information, with a twist:\n\nIt's in Leeds, but it'll be here tomorrow! Now that's a lot faster than Australia Post. Or just plain stupid.\n\nYour cameras have been delivered! Topic: technology, photography, general, opinion Link here\n\nYesterday's claim of fast delivery was amusing enough, but they haven't given up:\n\nThey have been delivered! How did we do?\n\nI'm amazed. Clearly the cameras are still in the United Kingdom. My best guess is that Royal Mail have delivered the cameras to the people who are currently in the process of sending them half way round the world, or at least they have received documentation from them. So from their limited viewpoint they have been delivered. No concept of them only having travelled a fraction of the distance.\n\nWeb server load: dropping Topic: technology Link here\n\nYesterday's web server overload didn't last long. It's back to round 1 again. I suppose that's what we're going to have to live with for the foreseeable future. It's interesting that even at this extreme overload people claimed that response was satisfactory. That's significantly different from last time, where some sites got timeouts.\n\nArtificially intelligent breakfast Topic: food and drink, technology, opinion Link here\n\nFor some reason we bought a quarter cabbage recently. I forget why, but it was intended for breakfast. All right, Google Gemini, give me some east asian recipes with fried cabbage.\n\nAnd the twins obliged: 手撕包菜 - Shǒu Sī Bāo Cài, “hand shredded cabbage\", which didn't look too bad, modulo these horrible cups measurements. I can't even blame the twins for that: so many recipes use it. But it's the biggest hindrance I can find for trying out recipes. OK, Gemini, give me a Chinese recipe with fried cabbage and noodles using metric units. OK, how about 包菜炒粉/麵, which Google Translate translates as “cabbage fried rice noodles”? A completely different recipe! The best I can guess from the two recipes is that 4 cups of cabbage weigh about 300 g.\n\nSpent some time—probably more than cooking—writing a sane version of the second recipe.\n\nSoftware upgrades: the sting in the tail Topic: technology, photography, opinion Link here\n\nHouse photos again today, the second time since I upgraded hydra to FreeBSD 14.3 last week. And once again I had pain.\n\nFirstly, creating HDR didn't work well. It took me a while to discover that it was an unrelated bug in one of my scripts: I managed to mix images from the OM System OM-1 Mark II with the correct images from the Olympus OM-D E-M1 Mark II. I had already expected problems like that, and /Photos/Tools/housephtos.awk contained appropriate comments. Here the fix:\n\n-# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n+# $Id: diary-sep2025.php,v 1.35 2025/10/01 05:22:39 grog Exp $\n\n# Create a makejpeg file from housephoto.notes file.\n\nBEGIN {\n\ni = 0;\n\n-# XXX Only look at photos from E-M1 Mark II.\n\n+# Only look at photos from E-M1 Mark II.\n\n# Is this safe?\n\n-# Was: 4*.ORF, E-M1 /2 only\n\n- while (\"ls -rt *.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n+# It's better than the alternative.\n\n+ while (\"ls -rt 4*.ORF | sed 's:embedded\\.::; s:\\.JPG::; s:\\.jpg::; s:\\.ORF::'\" | getline > 0)\n\n\n\nThe problem was that I didn't limit the choice to photos from the E-M1 Mark II. Not an upgrade problem at all.\n\nThe other, though, seems to be related to the upgrade of Hugin, now version 2024.0.1. The screens appear in the wrong place and at the wrong (tiny) size, and the directories are wrong. That's almost certainly related to the scripts that I wrote over 16 years ago which frob the ~/.hugin file to get rid of this horrible directory name retention. But that's all they do, and somehow it doesn't seem to work. A small detail, but irritating. Will I get round to it by next week?\n\nRevisiting old photos Topic: photography, technology, opinion Link here\n\nLooking back through old photos, found some of my first panoramas:\n\nIt dates from 11 April 2009 with the Olympus E-510, so old that I don't even have Exif data for it. I had already attempted to improve it 8 years later:\n\nBut that was still with the Ashampoo Photo Optimizer, which I have stopped using. Another attempt with “Perfectly Clear” gave me further improvements. Here are the three together (run the cursor over an image to compare it with its neighbour):\n\nIn particular the highlights and shadows are greatly improved.\n\nfra rebooted! Topic: technology, general, opinion Link here\n\nThe vultures have rebooted fra! Yes, they warned they would do so because of some unspecific bug in Linux, so they rebooted my FreeBSD box as well. The good news is that it came back without any intervention on my part, but of course the up time has gone to hell.\n\nAnother bloody power fail Topic: technology, general, opinion Link here\n\nIn the evening, another grid power failure. And another directly behind it. Both were sub-second, but once again eureka and hydra failed. So much for the UPS.\n\nWhy? Yes, it's an old UPS, but it claims to have plenty of charge, and the failures were so short that most clocks in the kitchen kept going. Can it be that it was a power surge, and that this UPS didn't handle it? The UPSs for lagune, teevee and tiwi had no problems.\n\nAnd the fallout? I got things running relatively quickly, but firefox didn't recover its many tabs. I had to start a different profile to get anything. And of course X on teevee failed, because I had started it from hydra.\n\nSo what do I do now? Buy more of UPSs of the kind that power the other machines?\n\nTuesday, 30 September 2025 Dereel Top of page previous day\n\nMore firefox pain Topic: technology, general, opinion Link here\n\nSo what's wrong with firefox? My standard profile just hangs. Why? How do I debug such a mess?\n\nI tried setting up a different profile, losing a number of tabs in the process, but nothing I could do could get the font sizes right. Get them right for my diary (without any trickery) and they're far too small for things like Wikipedia and friends. Migrate from hydra:0.2 (3840×2160) to hydra:0.0 (1920×1080)? Yes, that works, but why did it happen?\n\nThen it occured to me: yes, the standard profile still hangs. But I can check the settings. And it seems that the big thing is the Zoom setting, which was at 150%. After setting that, things were OK. But why the difference between my diary and Wikipedia and Co.? And why are font sizes such an issue with firefox?",
      "source": "Lemis.com",
      "url": "http://www.lemis.com/grog/diary-sep2025.php?topics=c#D-20250927-023856",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "ASUS VivoBook S14: 14\" FHD+ OLED, Ryzen AI 9 HX 370, 32GB LPDDR5, 1TB SSD $999.99 (0 replies)",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired Dr.W posted Item 1 of 2 Item 1 of 2 expired Dr.W posted ASUS VivoBook S14: 14\" FHD+ OLED, Ryzen AI 9 HX 370, 32GB LPDDR5, 1TB SSD $999.99 $1,000 $1,200 16% off Newegg 7 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 3,747 Views Visit Newegg Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details SPECS: 14\", WUXGA (1920 x 1200) 16:10, 60Hz, 600-nits HDR, 100% DCI-P3, VESA CERTIFIED ,PANTONE Validated, Glossy, OLED Display\n\nAMD Ryzen AI 9 HX 370 Processor 2.0GHz (36MB Cache, up to 5.1GHz, 12 cores, 24 Threads); AMD XDNA NPU up to 50TOPS\n\n32GB LPDDR5X on board\n\n1TB M.2 NVMe PCIe 4.0 SSD\n\nAMD Radeon 890M Graphics\n\nWi-Fi 6E(802.11ax) (Dual band) 2*2 + BT 5.3\n\nFHD camera with IR function to support Windows Hello w/ privacy shutter\n\nBacklit Chiclet Keyboard 1-Zone RGB without Num-key, 1.7mm Key-travel, Touchpad, With Copilot key\n\n75WHrs, 4S1P, 4-cell Li-ion Battery\n\n1.30 kg (2.87 lbs.)\n\nModel: M5406WA-BS99\n\nPorts: 1x USB 3.2 Gen 1 Type-C with support for display / power delivery 1x USB 4.0 Gen 3 Type-C with support for display / power delivery 2x USB 3.2 Gen 1 Type-A 1x HDMI 2.1 TMDS 1x 3.5mm Combo Audio Jack Micro SD card reader\n\n\n\nhttps://www.newegg.com/asus-vivob...7db37c6 678 Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster Dr.W Follow Give Rep Message 8,032 Deal Posts 11,542 Comments Posts 16,996 Reputation Points 10,806 Votes Submitted Deal Details Community Notes About the Poster SPECS: 14\", WUXGA (1920 x 1200) 16:10, 60Hz, 600-nits HDR, 100% DCI-P3, VESA CERTIFIED ,PANTONE Validated, Glossy, OLED Display\n\nAMD Ryzen AI 9 HX 370 Processor 2.0GHz (36MB Cache, up to 5.1GHz, 12 cores, 24 Threads); AMD XDNA NPU up to 50TOPS\n\n32GB LPDDR5X on board\n\n1TB M.2 NVMe PCIe 4.0 SSD\n\nAMD Radeon 890M Graphics\n\nWi-Fi 6E(802.11ax) (Dual band) 2*2 + BT 5.3\n\nFHD camera with IR function to support Windows Hello w/ privacy shutter\n\nBacklit Chiclet Keyboard 1-Zone RGB without Num-key, 1.7mm Key-travel, Touchpad, With Copilot key\n\n75WHrs, 4S1P, 4-cell Li-ion Battery\n\n1.30 kg (2.87 lbs.)\n\nModel: M5406WA-BS99\n\nPorts: 1x USB 3.2 Gen 1 Type-C with support for display / power delivery 1x USB 4.0 Gen 3 Type-C with support for display / power delivery 2x USB 3.2 Gen 1 Type-A 1x HDMI 2.1 TMDS 1x 3.5mm Combo Audio Jack Micro SD card reader\n\n\n\nhttps://www.newegg.com/asus-vivob...7db37c6 678",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18638728-asus-vivobook-s14-14-fhd-oled-ryzen-ai-9-hx-370-32gb-lpddr5-1tb-ssd-999-99",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Ubuntu 24.10 failing to load login and desktop following monitor change",
      "content": "This question is off-topic , as it is specific to an unsupported release of Ubuntu. It is not currently accepting answers. This question is specific to a release of Ubuntu which is beyond either its end of standard support or end of life date, and is not related to asking how to upgrade to a supported release. It should be closed as off-topic, and only reopened if it relates to asking for help upgrading to a supported release. Closed 2 days ago. Improve this question\n\nI have brought a new MSI monitor and to give it full name it is - MSI PRO MP341CQ 34\" Curved Monitor, 1500R, UWQHD (3440 x 1440), 21:9, 100Hz, VA, 4ms, HDMI, VGA\n\nIt comes with a HDMI port, but after plugging and ensuring it is pointing to the right port I get nothing apart from no signal message.\n\nSo using a hdmi cable converter to VGA port, I will see a bios screen, Ubuntu splash screen but no login or desktop. Now, I can drop to recovery mode and this loads, but I can't get it to boot normally. For now I am using my old Samsung S24D300. The graphics card is a Advanced Micro Devices, Inc [AMD/ATI] Hawaii PRO [Radeon R9 290/390] (rev 80).\n\nHas anyone seen this before? If so, what is the fix?",
      "source": "Askubuntu.com",
      "url": "https://askubuntu.com/questions/1556647/ubuntu-24-10-failing-to-load-login-and-desktop-following-monitor-change",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Kodiak Sciences (NASDAQ:KOD) Shares Gap Up Following Analyst Upgrade",
      "content": "Kodiak Sciences Inc. (NASDAQ:KOD – Get Free Report)’s share price gapped up before the market opened on Thursday after Wall Street Zen upgraded the stock from a sell rating to a hold rating. The stock had previously closed at $15.49, but opened at $16.34. Kodiak Sciences shares last traded at $18.10, with a volume of 375,073 shares.\n\nSeveral other analysts have also recently commented on the stock. HC Wainwright increased their price target on shares of Kodiak Sciences from $3.00 to $5.00 and gave the company a “neutral” rating in a research note on Monday, August 18th. Jefferies Financial Group assumed coverage on shares of Kodiak Sciences in a report on Monday, September 22nd. They issued a “buy” rating and a $15.00 price objective on the stock. JPMorgan Chase & Co. upgraded shares of Kodiak Sciences from an “underweight” rating to a “neutral” rating and set a $15.00 price objective on the stock in a report on Thursday, August 14th. Finally, Barclays upgraded shares of Kodiak Sciences from an “underweight” rating to an “equal weight” rating and increased their price objective for the company from $7.00 to $17.00 in a report on Thursday. One research analyst has rated the stock with a Buy rating and three have issued a Hold rating to the stock. According to MarketBeat, the stock has an average rating of “Hold” and a consensus target price of $13.00.\n\nGet Kodiak Sciences alerts:\n\nCheck Out Our Latest Analysis on Kodiak Sciences\n\nHedge Funds Weigh In On Kodiak Sciences\n\nKodiak Sciences Stock Performance\n\nHedge funds and other institutional investors have recently made changes to their positions in the company. US Bancorp DE increased its position in shares of Kodiak Sciences by 131.7% in the 1st quarter. US Bancorp DE now owns 9,282 shares of the company’s stock valued at $26,000 after buying an additional 5,276 shares in the last quarter. Vontobel Holding Ltd. bought a new stake in shares of Kodiak Sciences in the 1st quarter valued at $28,000. Headlands Technologies LLC increased its position in shares of Kodiak Sciences by 256.4% in the 2nd quarter. Headlands Technologies LLC now owns 8,083 shares of the company’s stock valued at $30,000 after buying an additional 5,815 shares in the last quarter. Walleye Capital LLC bought a new stake in shares of Kodiak Sciences in the 1st quarter valued at $49,000. Finally, Vanguard Personalized Indexing Management LLC increased its position in shares of Kodiak Sciences by 21.7% in the 2nd quarter. Vanguard Personalized Indexing Management LLC now owns 15,070 shares of the company’s stock valued at $56,000 after buying an additional 2,691 shares in the last quarter. 89.06% of the stock is owned by institutional investors.\n\nThe stock’s 50-day moving average is $9.41 and its 200 day moving average is $5.60. The firm has a market cap of $834.56 million, a P/E ratio of -4.16 and a beta of 2.45.\n\nKodiak Sciences (NASDAQ:KOD – Get Free Report) last released its quarterly earnings data on Wednesday, August 13th. The company reported ($1.03) EPS for the quarter, missing analysts’ consensus estimates of ($1.01) by ($0.02). On average, research analysts anticipate that Kodiak Sciences Inc. will post -3.45 EPS for the current year.\n\nAbout Kodiak Sciences\n\n(Get Free Report)\n\nKodiak Sciences Inc, a clinical stage biopharmaceutical company, researches, develops, and commercializes therapeutics to treat retinal diseases. Its lead product candidate is tarcocimab tedromer (KSI-301), an anti-vascular endothelial growth factor antibody biopolymer that is in Phase IIb/III clinical study to treat wet age-related macular degeneration (AMD), as well as Phase III clinical study for the treatment of diabetic macular edema, naïve macular edema due to retinal vein occlusion, and non-proliferative diabetic retinopathy.\n\nRecommended Stories\n\nReceive News & Ratings for Kodiak Sciences Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Kodiak Sciences and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/27/kodiak-sciences-nasdaqkod-shares-gap-up-following-analyst-upgrade/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Colorful Preps Several OC-Ready AM5 Motherboards For AMD Ryzen CPUs: B850M ARK With BCLK Generator & X870E Vulcan With Dual DIMM Design",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/colorful-oc-ready-am5-motherboards-amd-ryzen-b850m-ark-bclk-generator-x870e-vulcan-with-dual-dimm/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Zacks Research Expects Lower Earnings for Kodiak Sciences",
      "content": "Kodiak Sciences Inc. (NASDAQ:KOD – Free Report) – Zacks Research reduced their Q3 2025 earnings per share estimates for shares of Kodiak Sciences in a report released on Wednesday, September 24th. Zacks Research analyst Team now anticipates that the company will earn ($1.06) per share for the quarter, down from their previous estimate of ($1.03). The consensus estimate for Kodiak Sciences’ current full-year earnings is ($3.45) per share. Zacks Research also issued estimates for Kodiak Sciences’ Q4 2025 earnings at ($1.10) EPS, FY2025 earnings at ($4.28) EPS, Q1 2026 earnings at ($0.90) EPS, Q3 2026 earnings at ($1.07) EPS, Q4 2026 earnings at ($1.17) EPS, FY2026 earnings at ($4.09) EPS, Q1 2027 earnings at ($0.85) EPS, Q2 2027 earnings at ($0.92) EPS and FY2027 earnings at ($3.98) EPS.\n\nGet Kodiak Sciences alerts:\n\nKodiak Sciences (NASDAQ:KOD – Get Free Report) last announced its quarterly earnings data on Wednesday, August 13th. The company reported ($1.03) earnings per share (EPS) for the quarter, missing the consensus estimate of ($1.01) by ($0.02).\n\nSeveral other brokerages have also recently issued reports on KOD. HC Wainwright raised their price objective on Kodiak Sciences from $3.00 to $5.00 and gave the stock a “neutral” rating in a research note on Monday, August 18th. JPMorgan Chase & Co. upgraded Kodiak Sciences from an “underweight” rating to a “neutral” rating and set a $15.00 price objective on the stock in a research note on Thursday, August 14th. Wall Street Zen upgraded Kodiak Sciences from a “sell” rating to a “hold” rating in a research note on Friday. Jefferies Financial Group initiated coverage on Kodiak Sciences in a research note on Monday, September 22nd. They set a “buy” rating and a $15.00 price objective on the stock. Finally, Barclays upgraded Kodiak Sciences from an “underweight” rating to an “equal weight” rating and raised their price objective for the stock from $7.00 to $17.00 in a research note on Thursday. One equities research analyst has rated the stock with a Buy rating and three have issued a Hold rating to the company’s stock. According to data from MarketBeat.com, Kodiak Sciences currently has a consensus rating of “Hold” and an average price target of $13.00.\n\nView Our Latest Analysis on Kodiak Sciences\n\nKodiak Sciences Price Performance\n\nShares of KOD opened at $15.80 on Friday. The business’s fifty day moving average price is $9.41 and its 200 day moving average price is $5.61. Kodiak Sciences has a 12-month low of $1.92 and a 12-month high of $19.39. The stock has a market capitalization of $834.56 million, a PE ratio of -4.16 and a beta of 2.45.\n\nInstitutional Investors Weigh In On Kodiak Sciences\n\nLarge investors have recently added to or reduced their stakes in the stock. Headlands Technologies LLC increased its position in Kodiak Sciences by 256.4% in the second quarter. Headlands Technologies LLC now owns 8,083 shares of the company’s stock worth $30,000 after buying an additional 5,815 shares during the period. US Bancorp DE increased its holdings in shares of Kodiak Sciences by 131.7% during the first quarter. US Bancorp DE now owns 9,282 shares of the company’s stock valued at $26,000 after purchasing an additional 5,276 shares during the period. Vontobel Holding Ltd. acquired a new position in shares of Kodiak Sciences during the first quarter valued at $28,000. Public Employees Retirement System of Ohio increased its holdings in shares of Kodiak Sciences by 183.9% during the fourth quarter. Public Employees Retirement System of Ohio now owns 14,759 shares of the company’s stock valued at $147,000 after purchasing an additional 9,560 shares during the period. Finally, Vanguard Personalized Indexing Management LLC increased its holdings in shares of Kodiak Sciences by 21.7% during the second quarter. Vanguard Personalized Indexing Management LLC now owns 15,070 shares of the company’s stock valued at $56,000 after purchasing an additional 2,691 shares during the period. 89.06% of the stock is owned by institutional investors and hedge funds.\n\nKodiak Sciences Company Profile\n\n(Get Free Report)\n\nKodiak Sciences Inc, a clinical stage biopharmaceutical company, researches, develops, and commercializes therapeutics to treat retinal diseases. Its lead product candidate is tarcocimab tedromer (KSI-301), an anti-vascular endothelial growth factor antibody biopolymer that is in Phase IIb/III clinical study to treat wet age-related macular degeneration (AMD), as well as Phase III clinical study for the treatment of diabetic macular edema, naïve macular edema due to retinal vein occlusion, and non-proliferative diabetic retinopathy.\n\nFeatured Stories\n\nReceive News & Ratings for Kodiak Sciences Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Kodiak Sciences and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/28/zacks-research-expects-lower-earnings-for-kodiak-sciences/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Intel’s Panther Lake CPUs Will Be The Firm’s First ‘Gamble’ With The Highly-Anticipated 18A Node – Here’s Everything We Know",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/roundup/intel-panther-lake/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "VMScape and why Xen dodged it",
      "content": "ETH Zürich’s new VMScape attack hit KVM and VMware, but Xen’s microkernel-like design kept it out of reach.\n\nIt’s been less than two weeks since the security team at ETH Zürich published their research on a new microarchitectural attack they call VMScape:\n\nIt’s a neat piece of work, and it shows once again how CPUs, with all their clever tricks for performance, can sometimes open the door to data leaks across virtual machines.\n\nWhat is VMScape?\n\nThe short version: modern CPUs use a branch predictor to guess where code will go next. It makes things faster, but the predictor also “remembers” past patterns. If you can manipulate that memory, you can mislead the CPU and peek at things you shouldn’t. That’s the basic idea behind Spectre-style attacks.\n\nAccording to the ETH team:\n\n“We find that branch predictor state is not fully flushed across VMs, enabling cross-VM Branch Target Injection (vBTI) primitives. We demonstrate the practical impact of vBTI with VMScape, a cross-VM attack capable of leaking QEMU userspace secrets from a malicious guest VM on AMD Zen 4 and Zen 5 CPUs.”\n\nIn other words, a malicious VM can target the hypervisor’s userspace components and start leaking data. For KVM, that means QEMU, which is heavily exposed. VMware is in the same situation.\n\nWhy Xen wasn’t affected\n\nThe researchers also note that Xen is not vulnerable. That’s not because Xen has no bugs (it does, like every hypervisor), but because of its architecture.\n\nFrom day one, Xen was designed to keep the hypervisor core small and move everything else out. Device emulation, storage drivers, network stacks — they all live in Dom0, which is itself just another virtual machine. Dom0 has more privileges than a normal guest, but it’s still not the hypervisor.\n\nThat architectural choice makes Xen closer to a microkernel than a traditional monolithic hypervisor. The core stays minimal, with a narrow set of responsibilities, and anything that doesn’t absolutely need to run at the highest privilege level gets pushed out. That’s not just elegant — it’s a big deal for security.\n\nSize matters (in a good way)\n\nBecause the hypervisor itself is small, it’s easier to audit, reason about, and even certify. That’s why you’ll find Xen at the heart of a lot of embedded and safety-critical projects, where formal verification and certification are required. Try doing that with a massive, monolithic kernel and you’ll quickly run into a wall. With Xen, it’s actually feasible (and being done as we speak).\n\nVMScape highlights the benefits of that design: QEMU is simply not sitting next to the hypervisor. Even if you leak information from it, you’re still only talking about a process in Dom0, not the privileged heart of the system.\n\nWhy this matters\n\nArchitectural choices made twenty years ago are paying off today. By separating responsibilities, Xen reduced its attack surface and avoided a whole class of problems. That doesn’t make it invincible (Xen has had and will have its share of vulnerabilities) but it does mean that by design, certain attacks don’t land as hard.\n\nAs the ETH Zürich team points out, mitigations for KVM involve adding new predictor flushes, which Linux developers have already started to implement. VMware will need similar patches. Xen doesn’t need those same emergency measures, because the architecture already put a buffer in place.\n\nDefense in depth\n\nIt’s tempting to say “Xen wins” and stop there. But that’s not the whole story. Security is never just about one design decision. CPUs will keep evolving, new side channels will keep appearing, and no hypervisor can afford to be complacent.\n\nStill, VMScape is a good reminder that defense in depth starts at the architecture level. A small, microkernel-like core, privilege separation, isolation of device emulation — all of that adds resilience. It won’t stop every possible attack, but it does add another layer of safety, and in security, layers are what make the difference.",
      "source": "Virtualize.sh",
      "url": "https://virtualize.sh/blog/vmscape-and-why-xen-dodged-it/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Bitsum ParkControl Pro 5.5.0.8",
      "content": "Description: ParkControl is Pro Windows app to adjust CPU core parking and heterogenous processor scheduling settings.\n\nPro Benefits\n\nBitsum Dynamic Boost\n\nAutomatically switch power plans when your PC enters and leaves the idle state\n\nPower Plan change Notifications\n\nNotifications of when and what process changed your active power plan (image)\n\nSupport Bitsum’s Independent Innovation\n\nYour support enables us to create new tools, and maintain our existing ones!\n\nIntroduction to CPU Core Parking\n\nCPU Parking is a low-power sleep state (C6) supported by most modern processors and operating systems. It dynamically disables CPU cores in an effort to conserve power when idle. Unfortunately, this power saving comes at a price: Latency when CPUs need unparked to execute code.\n\nInitially, core parking was controlled entirely by the operating system. The aggressive core parking of Windows led to a great deal of inefficiency during bursting CPU loads. Intel moved core parking control onto the chip in the Skylake generation, and AMD followed, but still the parameters of the Windows power plans are set to aggressively park CPU cores. Even the default ‘High Performance’ power plan is not immune. The new ‘Ultra Performance’ power plan copies what Bitsum did with our own ‘Bitsum Highest Performance’ power plan and finally disables core parking entirely.\n\nParkControl (and Process Lasso) not only let one more easily configure CPU core parking and frequency scaling, but also allow for dynamic entrance into a higher performance power plan. For instance, with Process Lasso, you can automatically enter ‘Bitsum Highest Performance’ will you start a game, then go back to ‘Balanced’ when you exit.\n\nParkControl has Dynamic Boost to allow you to set active and idle power plans. Process Lasso has a similar feature with its IdleSaver.\n\nEfficacy of Disabling Core Parking\n\nEmpirical evidence shows that disabling CPU core parking can make a tangible improvement in system performance. There are many factors that will determine precisely how effective it will be for a given situation. However, generally, Windows is too aggressive in its core parking, resulting in high latency during bursting CPU loads, stemming from the overhead of having to unpark CPU cores. Since bursting CPU loads are the most common type for many workloads, core parking can be a substantial drag on system performance and responsiveness.\n\nUsing ParkControl\n\nParkControl lets you easily set CPU core parking and frequency scaling parameters for both AC (plugged-in) and DC (battery) power states of your device.\n\nBoth CPU core parking and frequency scaling are power saving features of modern CPUs. CPU core parking is when cores are put into a sleep-like state when demand is low. Similarly, CPU frequency scaling allows the CPU base frequency to be lowered, again to conserve energy.\n\nEach power plan has its own settings, and can be selected via the power plan drop-down. When you select a power plan, the user interface will populate with that power plan’s settings. After making changes, click the ‘Apply’ button to save them. Use the ‘Make active’ button to switch the PC to that power plan.\n\nRelease Name: Bitsum ParkControl Pro 5.5.0.8\n\nSize: 3.6 MB\n\nLinks: HOMEPAGE – NFO – Torrent Search\n\nDownload: RAPiDGATOR",
      "source": "Rlsbb.to",
      "url": "https://post.rlsbb.to/bitsum-parkcontrol-pro-5-5-0-8-2/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "AMD’s Instinct MI450X Has Reportedly ‘Forced’ NVIDIA to Make Changes With the Rubin AI Chip, Including Higher TGPs & Memory Bandwidth",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/amd-instinct-mi450x-has-forced-nvidia-to-make-changes-with-the-rubin-ai-chip/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Qualcomm’s Snapdragon X2 Elite Extreme Isn’t the Fastest Laptop SoC, as Apple’s M4 Max Beats It in Single-Core & Multi-Core Performance",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/qualcomm-snapdragon-x2-elite-extreme-isnt-the-fastest-laptop-soc-out-there/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "AMD to Pivot from SERDES to a “Sea-of-Wires” D2D Interconnect in Next-Gen Zen 6 CPUs, Bringing Major Power-Efficiency and Latency Gains",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/amd-to-pivot-from-serdes-to-a-sea-of-wires-d2d-interconnect-with-zen-6-cpus/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Advanced Micro Devices (NASDAQ:AMD) Trading Down 1.1% After Insider Selling",
      "content": "Advanced Micro Devices, Inc. (NASDAQ:AMD – Get Free Report)’s stock price was down 1.1% during mid-day trading on Friday following insider selling activity. The stock traded as low as $157.05 and last traded at $159.46. Approximately 30,202,717 shares traded hands during mid-day trading, a decline of 35% from the average daily volume of 46,521,398 shares. The stock had previously closed at $161.27.\n\nSpecifically, EVP Forrest Eugene Norrod sold 2,250 shares of the stock in a transaction dated Wednesday, September 24th. The stock was sold at an average price of $165.01, for a total value of $371,272.50. Following the completion of the transaction, the executive vice president directly owned 311,598 shares in the company, valued at approximately $51,416,785.98. This trade represents a 0.72% decrease in their ownership of the stock. The transaction was disclosed in a document filed with the Securities & Exchange Commission, which can be accessed through this link.\n\nGet Advanced Micro Devices alerts:\n\nAnalyst Upgrades and Downgrades\n\nSeveral equities analysts have commented on AMD shares. Susquehanna increased their target price on Advanced Micro Devices from $135.00 to $210.00 and gave the company a “positive” rating in a research report on Wednesday, July 30th. Wedbush reiterated a “cautious” rating on shares of Advanced Micro Devices in a research report on Saturday, August 9th. HSBC dropped their target price on Advanced Micro Devices from $200.00 to $185.00 and set a “buy” rating for the company in a research report on Tuesday, September 9th. Rosenblatt Securities reiterated a “buy” rating and issued a $200.00 target price on shares of Advanced Micro Devices in a research report on Friday, June 13th. Finally, Seaport Res Ptn downgraded Advanced Micro Devices from a “strong-buy” rating to a “hold” rating in a research report on Thursday, September 4th. Three equities research analysts have rated the stock with a Strong Buy rating, twenty-one have assigned a Buy rating, thirteen have issued a Hold rating and one has assigned a Sell rating to the stock. Based on data from MarketBeat, the stock currently has a consensus rating of “Moderate Buy” and an average price target of $180.88.\n\nAdvanced Micro Devices Stock Down 1.1%\n\nThe firm has a 50 day moving average of $165.48 and a 200 day moving average of $131.48. The firm has a market cap of $258.78 billion, a price-to-earnings ratio of 91.64, a PEG ratio of 1.88 and a beta of 1.92. The company has a quick ratio of 1.81, a current ratio of 2.49 and a debt-to-equity ratio of 0.05.\n\nAdvanced Micro Devices (NASDAQ:AMD – Get Free Report) last released its earnings results on Tuesday, August 5th. The semiconductor manufacturer reported $0.48 EPS for the quarter, missing the consensus estimate of $0.54 by ($0.06). Advanced Micro Devices had a return on equity of 7.54% and a net margin of 9.57%.The business had revenue of $7.69 billion for the quarter, compared to analyst estimates of $7.41 billion. During the same period in the prior year, the business earned $0.69 EPS. The company’s revenue for the quarter was up 31.7% on a year-over-year basis. Advanced Micro Devices has set its Q3 2025 guidance at EPS. As a group, sell-side analysts predict that Advanced Micro Devices, Inc. will post 3.87 earnings per share for the current year.\n\nInstitutional Investors Weigh In On Advanced Micro Devices\n\nHedge funds have recently added to or reduced their stakes in the company. Pinney & Scofield Inc. grew its stake in Advanced Micro Devices by 81.0% in the second quarter. Pinney & Scofield Inc. now owns 190 shares of the semiconductor manufacturer’s stock valued at $27,000 after acquiring an additional 85 shares during the period. Dogwood Wealth Management LLC grew its stake in Advanced Micro Devices by 2,311.1% in the second quarter. Dogwood Wealth Management LLC now owns 217 shares of the semiconductor manufacturer’s stock valued at $30,000 after acquiring an additional 208 shares during the period. Avion Wealth grew its stake in Advanced Micro Devices by 49.3% in the second quarter. Avion Wealth now owns 218 shares of the semiconductor manufacturer’s stock valued at $30,000 after acquiring an additional 72 shares during the period. West Branch Capital LLC grew its stake in Advanced Micro Devices by 3,057.1% in the second quarter. West Branch Capital LLC now owns 221 shares of the semiconductor manufacturer’s stock valued at $31,000 after acquiring an additional 214 shares during the period. Finally, Evolution Wealth Management Inc. bought a new position in shares of Advanced Micro Devices in the second quarter valued at approximately $34,000. Institutional investors and hedge funds own 71.34% of the company’s stock.\n\nAdvanced Micro Devices Company Profile\n\n(Get Free Report)\n\nAdvanced Micro Devices, Inc operates as a semiconductor company worldwide. It operates through Data Center, Client, Gaming, and Embedded segments. The company offers x86 microprocessors and graphics processing units (GPUs) as an accelerated processing unit, chipsets, data center, and professional GPUs; and embedded processors, and semi-custom system-on-chip (SoC) products, microprocessor and SoC development services and technology, data processing unites, field programmable gate arrays (FPGA), and adaptive SoC products.\n\nSee Also\n\nReceive News & Ratings for Advanced Micro Devices Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Advanced Micro Devices and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/28/advanced-micro-devices-nasdaqamd-trading-down-1-1-after-insider-selling/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Intel’s Top Granite Rapids Xeon Workstation CPU Leaked: 86 Cores & 172 Threads On The W890 Platform",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/intel-granite-rapids-xeon-workstation-cpu-leak-86-cores-172-threads-w890-platform/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Meta’s Infrastructure Evolution and the Advent of AI",
      "content": "Over the past 21 years, Meta has grown exponentially from a small social network connecting a few thousand people in a handful of universities in the U.S. into several apps and novel hardware products that serve over 3.4 billion people throughout the world.\n\nOur infrastructure has evolved significantly over the years, growing from a handful of software systems on a small fleet of servers in a few co-location facilities to a massive, globally networked operation. We faced numerous challenges along the way and developed innovative solutions to overcome them.\n\nThe advent of AI has changed all of our assumptions on how to scale our infrastructure. Building infrastructure for AI requires innovation at every layer of the stack, from hardware and software, to our networks, to our data centers themselves.\n\nFacebook was built on the open source Linux, Apache, MySQL, and PhP (LAMP) stack. True to our roots, much of our work has been openly shared with the engineering community in the form of research papers or open source hardware and software systems. We remain committed to this open source vision and describe how we are committed to an open standards approach to silicon and hardware systems as we push the frontiers of computer science.\n\nScaling Our Infrastructure Stack (2004 – 2010)\n\nIn our earliest years, we focused our engineering work on scaling our software stack. As Facebook expanded from Harvard to other universities, each university got its own database. Students logging on to Facebook would connect to a set of common web servers that would in turn connect each student to their university’s database. We quickly realized that students wished to connect with their friends who attended other universities — this was the birth of our social graph that interconnected everyone on the social network.\n\nAs Facebook expanded beyond universities to high schools and then the general public, there was a dramatic increase in the number of people on our platform. We managed database load by scaling our Memcache deployments and then building entirely new software systems such as the TAO social graph, and a whole host of new caching and data management systems. We also developed a new ranking service for News Feed and a photo service for sharing photos and videos.\n\nSoon, we were expanding beyond the US to Europe. Scaling our software systems was critical, but no longer sufficient. We needed to find other ways to scale. So we moved one layer below software and started scaling our physical infrastructure. We expanded beyond small co-location facilities in the Bay Area to a co-lo in Ashburn, Va. In parallel, we built out our first data centers in Prineville, Ore. and Forest City, N.C.\n\nAs our physical infrastructure scaled to multiple data centers, we ran into two new problems. First, we needed to connect our user base distributed across the US and Europe to our data centers. We tackled this problem by aggressively building out our edge infrastructure where we obtained some compute capacity beside every local internet service provider (ISP) and bought into the peering network that connected the ISP to our data centers. Second, we needed to replicate our entire software stack to each data center so that people would have the same experience irrespective of which actual physical location they connected to. This required us to build a high bandwidth, multipath backbone network that interconnected our data centers. Initially, this entailed building out our terrestrial fiber network to connect the various co-location facilities in California and Virginia to our new data centers in Oregon and North Carolina.\n\nAs our user base grew globally, we scaled beyond single data center buildings and into data center regions consisting of multiple buildings. We also aggressively built out our edge presence, where we now operate hundreds of points-of-presence (POPs) across the world.\n\nThe Challenges of Scaling (2010 – 2020)\n\nBuilding out a global infrastructure also brought along all of the complex corner cases of computer science.\n\nCache Consistency\n\nFirst, we needed to solve for cache consistency. We saw issues where people would receive notifications about being tagged in a photo, but couldn’t see the photo. Or people in a chat thread would receive messages out-of-order. These problems manifested because we were serving a fraction of our user base out of each data center region. People served out of the same region would receive notifications and see the right data, while people in a different region would experience a lag as the data update was replicated across our distributed fleet. This lag directly led to an inconsistent user experience. We solved these problems by building novel software systems that delivered cache invalidations, eventually building a consistency API for distributed systems.\n\nFleet management\n\nAs we added new data center regions and grew our machine fleet, we also had to develop new abstractions to manage them. This included systems and associated components like:\n\nTwine : a cluster management system that scales to manage millions of machines in a data center region.\n\nTectonic : a data center scale distributed file system.\n\nZippyDB : a strongly consistent distributed key value store.\n\nShard Manager : a global system to manage tens of millions of shards of data, hosted on hundreds of thousands of servers for hundreds of applications.\n\nDelos : a new control plane for our global infrastructure.\n\nService Router : to manage our global service mesh.\n\nWe developed the above systems, and many others, so we could operate a global fleet of millions of machines, while also providing excellent performance.\n\nMasking hardware failure\n\nMore machines also implies a higher likelihood of failure. To address this, we worked to ensure that we could mask failures from users and provide a highly available and accessible service. We accomplished this by building new systems like:\n\nKraken : which leverages live traffic load tests to identify and resolve resource utilization bottlenecks.\n\nTaiji : to manage user traffic load balancing.\n\nMaelstrom : which handled data center-scale disasters safely and efficiently while minimizing user impact.\n\nWe continue to invest heavily in reliability and fault tolerance as stability is critical for all the people who use our services to connect with their friends, family, and the businesses that serve them.\n\nEnter AI Workloads (2020)\n\nWhile we were navigating the challenges of scaling, we were also seeing glimpses of how AI workloads would impact our infrastructure.\n\nThe Emergence of GPUs\n\nOur first encounter with AI-induced infrastructure challenges actually started in the late 2010s when short-form videos were becoming very popular. The people who consumed this type of content wanted personalized recommendations – this differed dramatically from our format of ranking content to date.\n\nMeta’s apps were built on the premise that people are part of communities with shared interests. Thus, Facebook surfaced content based on what the community liked rather than having a direct understanding of the individual and their interests. In contrast, if you want to give people an entertaining stream of short form videos, you have to be able to understand all videos uploaded to the platform and pick videos that are interesting to every single person.\n\nThis is a significantly different problem. In the first case, all we’re ranking is content that someone’s friends (typically just a few hundred people) have interacted with. In this new model, we have to rank all content that has been uploaded, which is orders of magnitude larger than the number of friends each person has. And we need to produce this ranking not just once, but a custom ranking for each person for each piece of content.\n\nThis is where GPUs and other AI accelerators enter the picture. In contrast to a CPU which is primarily a load-store machine, a GPU is a vector and matrix processing machine which can perform orders of magnitude more computation than a CPU.\n\nWhen given an extremely large corpus of data, for example, a video library, we can build an embedding, which is a mathematical representation of each video as a vector of numbers. This vector captures the context of the video in a lower-dimensional space so that semantically similar content is positioned close to each other. We can now build a model that tracks the sequence of clicks a user makes as they navigate through a library of videos and predict future videos that they might be interested in. Thus, AI combines the mathematical notion of similarity in content, with the computational power of a GPU to provide personalized recommendations.\n\nInternet services scaled throughout the 2000s and 2010s by buying CPUs/memory/hard drives that were extremely cost efficient but unreliable, and then built software systems to mask failures. In contrast, an AI cluster is a high performance computational system consisting of hundreds or even thousands of extremely powerful GPUs with ample memory interconnected with a high bandwidth, a low latency network, and a custom software stack optimized to squeeze the maximum performance out of the system.\n\nOur initial AI clusters interconnected 4k GPUs that were used to train our ranking and recommendation models.\n\nThe Rise of Large Language Models (2022)\n\nThis remained the case until large language models (LLMs) started to take off in 2022. At the time, while our AI clusters were 4k in size, each of our training jobs tended to run on 128 GPUs.\n\nWhen we started to train LLMs, this quickly changed.\n\nLLMs required dramatically more compute capacity, and the more compute you were able to throw at the pretraining job, the better the model you were able to produce. In a few weeks, we had to scale our training job sizes from 128 GPUs to 2k and then 4k GPUs.\n\nFor the first time, we were regularly dealing with training jobs where we needed thousands of GPUs to run synchronously. Any single straggling GPU would hold up the performance of the entire cluster.\n\nWe quickly learned that scaling training jobs came with all kinds of challenges. GPUs can fail, memory can have errors, the network can experience jitter… And, as with traditional web workloads, the more machines you have, the more likely you are to experience failure. Except this time, it was not so easy to avoid the failures because, unlike the case of serving web requests — where you can simply retry your request on a different machine — in the case of AI training workloads, your entire training cluster is running one job, and any single failure can bring that job to a halt. If jobs fail too frequently, we stop making progress because of how long it takes to checkpoint and restart jobs. Through collaboration with the industry and our partners, we were able to drive the interruption rate down by ~50x (based on normalized interruption/reliability metrics).As we built larger clusters, we also invested in fundamental research and development across our AI Infrastructure. LLMs influenced how we developed our ranking and recommendation models. For instance, Hierarchical Sequential Transduction Units (HSTU) accelerated training and inference by 10-1000x for Generative Recommenders.\n\nAccelerating Our GPU Scale and AI Infrastructure (2023)\n\nAs we were working to get our 4k jobs to run well, we also realized we needed to figure out how to build even larger clusters. Taking advantage of what was available to us, we designed a cluster to use all the power available in a data center building, which is typically low 10s of megawatts. This led to us to build two clusters of 24k H100s each in late 2023, one using Infiniband and the other using RoCE. This allowed us to explore different network technologies while providing our AI teams with the capacity they needed to train increasingly larger LLM models such as Llama 3.\n\nWhile our two 24k clusters were amongst the largest in the world in 2023, our AI researchers were finding that the more computational power we dedicated to pre-training, the higher quality and more performant the LLM models became. Thus, our infrastructure engineers were tasked with scaling our AI cluster up by another order of magnitude.\n\nTo accomplish this, we did something we had never done in Meta’s history: As we mentioned, Meta’s data centers are usually deployed as regions of five or more identical buildings in a single location. By emptying out five production data centers we were able to build a single AI cluster with 129k H100 GPUs – all in a matter of months!\n\nThe final challenge that we are tackling is one of efficiency: What hardware and software solutions can most efficiently support the workloads we care about and maximize utilization of our data center capacity?\n\nUnfortunately, our AI workloads are not homogenous. The ranking and recommendation models that deliver personalized user experiences on our apps have different needs than LLMs. And LLMs themselves are rapidly evolving. We are quickly moving beyond the pre-training era to one where reinforcement learning, supervised fine tuning, test time inference, and reasoning are all increasing in importance and require custom hardware and software support.\n\nGiven the size of Meta’s AI ambitions, we need to work with different vendors to encourage market diversity. We believe that having multiple options leads to a healthier ecosystem and better solutions in the long run.\n\nTo build out our AI infrastructure, we’ve leveraged solutions from partners like AMD and NVIDIA as well as our own custom silicon. The image below shows a pod consisting of six racks. The middle two racks house 72 NVIDIA Blackwell GPUs that consume ~140kW of power! We do not have facility liquid cooling in our traditional data centers, so we had to deploy four air assisted liquid cooling (AALC) racks so the heat wouldn’t melt the machines!\n\nThis pod, together, produces 360 PFLOPS of FP16 compute capacity. To put things in perspective, this pod consumes more than 800x the power a typical CPU consumes, and produces hundreds of thousand times the compute capacity! We are also starting to work with the next system, GB300, which is an improvement in many ways over GB200.\n\nWe have invested in other AI accelerators such as AMD’s MI300, which serves a variety of workloads at Meta. We have also invested heavily in the software layer to abstract away hardware differences from our developers as much as possible. Here is where open source software stacks such as PyTorch and Triton have really paid off for us.\n\nMeta Training & Inference Accelerator (MTIA)\n\nWe have also invested heavily in developing our own silicon. The Meta Training and Inference Accelerator (MTIA) is optimized for our ranking and recommendation inference workloads. This chip is now deployed at scale in our data centers, primarily serving our ads workloads, and has given us massive benefits in efficiency over vendor silicon.\n\nThis is only the beginning of our silicon program. Our training chip for ranking and recommendations is also starting to ramp up production. And we have multiple chips in various stages of development that we expect to deploy in the next couple of years.\n\nAs we’ve been diving further into designing our own silicon we’ve encountered some scaling challenges.\n\nThe Need for Advanced Packaging Techniques\n\nTransistors aren’t scaling at the same pace as the need for performance. Right now, reticle size is limited to 830 mm², which means that if anyone needs more performance than a single die can enable, their only option is to invest in more dies.\n\nWorking with LLMs we’ve found that the need to scale is so innate that it forces us into this exact scenario to keep up with the performance needs of each new model generation. The challenge is only compounded by the fact that these dies can only be placed adjacently through advanced 2.5D and 3D packaging, which limits the size of the arrays we can build and creates concerns around energy efficiency and cooling as well.\n\nWe suspect that, along with advanced cooling solutions, advanced packaging techniques can help overcome these challenges by integrating multiple chiplets, or diverse capabilities (compute, memory, I/O).\n\nInvesting in Solutions for Memory Disaggregation\n\nThe rise of reasoning models, test-time inference, and reinforcement learning are all adding additional pressure to memory subsystems. We are starting to stack high-bandwidth memory (HBM) adjacent to the compute chiplets to maximize I/O bandwidth. But we only have so much silicon beachfront, so we have to make hard tradeoffs between the computational capability of the chip, versus memory size, versus network bandwidth. Not to mention that adding several HBMs creates more cooling concerns.\n\nInvesting in higher performance networks instead and locating high bandwidth memory off-chip, or even off machines, might mitigate these issues.\n\nThe Case for Silicon Photonics\n\nAs we have been planning our silicon roadmap, we’ve found that the minimum power budget for each rack has grown dramatically. We’re building larger and larger interconnected chips, and that comes with increasing power demands.\n\nSilicon photonics, which offer a range of benefits, such as allowing for faster signaling over larger distances, could significantly reduce the rack’s overall power consumption.\n\nAdvanced optical solutions like these are also the only viable path to increasing shoreline beyond 3.2T and moving beyond the constraints of backplanes required to connect more endpoints.\n\nThese solutions would come with challenges of their own, such as higher power consumption and less reliability compared to electrical signaling. Ultimately, future solutions will have to be interoperable between different technologies and vendors, more reliable than electrical signaling, and capable of being manufactured at a high volume.\n\nWe are actively engaging in research to tackle these difficult hardware challenges and collaborating with the industry ecosystem to evolve the field and develop higher performance hardware.\n\nThe Role of Open Standards in Scaling AI\n\nWhile the proliferation of hardware provides options and allows us to handle workload heterogeneity by matching customized solutions that optimize for each need, they also create management challenges for hyperscalers, cloud operators, and hardware and software developers.\n\nFrom an operator point of view, it is difficult for Meta to deal with 5-6 different SKUs of hardware deployed every year. Heterogeneity of the fleet makes it difficult to move workloads around, leading to underutilized hardware. It is difficult for software engineers to think about building and optimizing workloads for different types of hardware. If new hardware necessitates the rewriting of libraries, kernels, and applications, then there will be strong resistance to adoption of new hardware. In fact, the current state of affairs is making it hard for hardware companies to design products because it is difficult to know what data center, rack, or power specifications to build for.\n\nWhat is needed here are open standards, open weight models, and open source software.\n\nOpen source software like PyTorch and Triton can help by providing a consistent programming interface for machine learning developers and researchers. Open weight models give application developers cost efficient access to high quality LLMs, and at the same time, give infrastructure and hardware engineers a standard workload to optimize for.\n\nFrom the very beginning, we’ve been strong supporters of open hardware for data center infrastructure. We were a founding member of the Open Compute Project and continue to be a leading contributor of technical content and IP into it. Since its inception, Meta has made 187 contributions (approximately 25% of all tech contributions) to OCP. Working with the OCP community has benefited us operationally by improving consistency in our fleet, financially through economies of scale, and technologically by enabling companies to come together and debate solutions. While we’ve seen this produce great results in our general purpose compute fleet, the benefits will only be amplified in the era of AI.\n\nLast year at the annual OCP Global Summit, for example, we unveiled Catalina, our open-design, high-powered rack for AI workloads, and a new version of Grand Teton, our AI hardware platform that features a single monolithic system design with fully integrated power, control, compute, and fabric interfaces.\n\nBut we have a long way to go in continuing to push open standards. We need standardization of systems, racks and power as rack power density continues to increase. These common abstractions help us continue to innovate quickly and deploy at scale as we build out the next generation of data centers and power grids. An example of this standardization is the recent push to adapt the Open Compute rack standards to accommodate AI needs.\n\nWe need standardization of the scale up and scale out network that these AI clusters use so that customers can mix/match different GPUs and accelerators to always use the latest and more cost effective hardware. We need software innovation and standards to allow us to run jobs across heterogeneous hardware types that may be spread in different geographic locations. These open standards need to exist all the way through the stack, and there are massive opportunities to eliminate friction that is slowing down the build out of AI infrastructure.\n\nThe Next Stage (2026 and Beyond)\n\nNo one can say for certain how the AI field will continue to evolve. Yet, what we do know is that computational capability is key to building higher quality models.\n\nAt Meta, our goal is to build models that will deliver the best, most engaging experiences, and act as personal assistants to each one of the billions of people that use our products every day.\n\nBuilding the infrastructure for models this sophisticated means actively addressing challenges throughout our data centers – everything from advanced packaging, thermal management, power delivery, to memory disaggregation, while enabling scalable networks through optics.\n\nOur next AI cluster, Prometheus, will be a 1-gigawatt cluster spanning across multiple data center buildings. Constructing Prometheus has been a monumental engineering feat, with infrastructure spanning five or more data center buildings in a single data center region. While a region is large, it is a small fraction of a gigawatt facility. Thus, we needed to find innovative ways to scale: We accomplished this by building this cluster across several of our traditional data center buildings as well as several weatherproof tents, and adjacent colocation facilities. We are also evolving our software stack, including Twine and MAST, to support long-distance training across a geographically distributed set of data centers.\n\nWe also have an even larger cluster, Hyperion, expected to come online beginning in 2028. Once finished, the Hyperion cluster will have the ability to scale up to a capacity of 5 gigawatts.\n\nWe are still early in the evolution and adoption of AI workloads. The last few years have been busy, but the next few years are going to move at an even faster pace. The demands AI will push on hardware show no signs of slowing down.",
      "source": "Fb.com",
      "url": "https://engineering.fb.com/2025/09/29/data-infrastructure/metas-infrastructure-evolution-and-the-advent-of-ai/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "China's factory activity likely slows again amid weak demand, trade tensions: Reuters poll",
      "content": "BEIJING (Reuters) -China's factory activity probably shrank for a sixth straight month in September, keeping alive calls for more stimulus in the world's second-largest economy to fend off a sharp slowdown as a U.S. trade deal remains distant.\n\nThe survey of 32 economists forecast the official purchasing managers' index (PMI) would edge up to 49.6 from August's 49.4, remaining below the 50-point threshold that separates growth from contraction. The data is due on Tuesday.\n\nThe prolonged slump underlines the twin pressures on China's economy: domestic demand has failed to mount a durable recovery in the years since the pandemic while U.S. President Donald Trump's tariffs have squeezed Chinese factories as well as overseas firms that buy components for finished goods.\n\nMalaysia's Maybank Investment Bank returned the highest poll reading of 50.0, indicating no change, while Pantheon Macroeconomics gave the lowest forecast of 49.0.\n\nPolicymakers rolled out a series of consumer loan subsidies in mid-August, a decision vindicated by separate factory output and retail sales data for the month, which saw their weakest growth in 12 months.\n\nPan Gongsheng, the governor of the People's Bank of China, said last week a range of monetary policy tools to support the economy remained available, but refrained from following the U.S. Federal Reserve with a rate cut, as some economists speculated the central bank might.\n\nDespite signs the $19 trillion economy is losing momentum, authorities appear in no hurry to roll out major stimulus measures, given resilient exports and a stock market rally, market watchers say.\n\nChina's exports to regional rival India hit an all-time high in August, customs data showed, while shipments to Africa and Southeast Asia are on track for annual records.\n\nBut no other country comes close to the consumption power of the U.S., where Chinese producers sell more than $400 billion worth of goods annually, accounting for around 14% of total exports.\n\nChinese leader Xi Jinping phoned Trump on September 19 for the first time in three months, and while the call appeared to ease tensions, it remains unclear whether it yielded the expected agreement on popular short-video app TikTok, which analysts see as key to a broader trade deal.\n\nDisagreements on technical details appeared to be weighing on negotiations, as Chinese and U.S. trade officials met again last Thursday to revisit issues discussed in talks before this month's Madrid summit, where a framework TikTok deal was reached.\n\nAnalysts polled by Reuters forecast the private sector RatingDog PMI to come in at 50.2, down from 50.5 a month prior. The data will also be released on September 30.\n\n(Reporting by Joe Cash; Polling by Vijayalakshmi Srinivasan and Devayani Sathyan in Bengaluru and Jing Wang in Shanghai; Editing by Sam Holmes amd Kate Mayberry)",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/chinas-factory-activity-likely-slows-055117188.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Microsoft Photos will use AI to auto-categorize your photos",
      "content": null,
      "source": "Ghacks Technology News",
      "url": "https://www.ghacks.net/2025/09/29/microsoft-photos-will-use-ai-to-auto-categorize-your-photos/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "S&P 500, Nasdaq Inches Higher As AI Stocks Recover From Last Week's Selloff",
      "content": "This article first appeared on GuruFocus.\n\nSep 29 - The S&P 500 edged slightly higher on Monday, adding 0.2%, while the Nasdaq Composite climbed 0.5% and the Dow Jones Industrial Average hovered near flat levels.\n\nInvestors looked to regain momentum after a tough week for the artificial intelligence trade.\n\nNvidia (NASDAQ:NVDA) gained 2% as sentiment around AI spending steadied following recent doubts about infrastructure capacity and energy demands tied to its partnership with OpenAI. Advanced Micro Devices (AMD) and Micron Technology (MU) also moved higher, rising 2% and 3% respectively.\n\nVideo game publisher Electronic Arts (EA) jumped 4% after announcing a $55 billion take-private deal. According to Goldman Sachs, U.S. merger activity has already topped $1 trillion this year, up 29% compared to last year.\n\nDespite last week's pullback, analysts remain optimistic. Barclays strategist Venu Krishna noted that capital expenditures tied to AI infrastructure remain strong and continue to support broader markets, though he cautioned about the risks of market concentration.\n\nMarkets are also keeping a close eye on the potential U.S. government shutdown, which could delay key economic data releases and complicate the Federal Reserve's policy outlook.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/p-500-nasdaq-inches-higher-231049428.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "AMD D2D Interconnect in “Zen 6” Gets Sea-of-Wires Upgrade",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/amd-d2d-interconnect-in-zen-6-gets-sea-of-wires-upgrade/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "AMD’s Newest Patent Brings a Gigantic Boost to Memory Performance By a Multi-Chip DRAM Approach; Immensely Benefitting APUs As Well - Wccftech",
      "content": "Want to read Slashdot from your mobile device? Point it at m.slashdot.org and keep reading!",
      "source": "Slashdot.org",
      "url": "https://slashdot.org/firehose.pl?op=view&amp;id=179577340",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Show HN: Katakate – Self-hosted safe VMs for AI compute",
      "content": null,
      "source": "Github.com",
      "url": "https://github.com/Katakate/k7",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Outlook Therapeutics Provides Update on Type A Meeting with FDA",
      "content": "ISELIN, N.J., Sept. 29, 2025 (GLOBE NEWSWIRE) -- Outlook Therapeutics, Inc. (Nasdaq: OTLK), a biopharmaceutical company focused on optimizing the standard of care for bevacizumab for the treatment of retina diseases, today announced that it has completed the Type A Meeting with the U.S. Food and Drug Administration (FDA) to discuss the complete response letter (CRL) dated August 27, 2025 regarding the biologics license application (BLA) resubmission for ONS-5010, an investigational ophthalmic formulation of bevacizumab under development to treat wet AMD. Based on the discussion with the FDA, Outlook Therapeutics expects to resubmit its BLA before the end of calendar year 2025, after reviewing the agency’s feedback and meeting minutes.\n\n“We had a productive discussion with the FDA. Based on our meeting, and pending receipt of the agency’s written minutes, we plan to resubmit the BLA later this year. We remain committed to providing patients, physicians and payors in the U.S. with a safe and effective ophthalmic bevacizumab for the treatment of wet AMD,” commented Bob Jahr, Chief Executive Officer of Outlook Therapeutics.\n\nAbout ONS-5010/LYTENAVA™ (bevacizumab-vikg, bevacizumab gamma)\n\nONS-5010/LYTENAVA™ is an ophthalmic formulation of bevacizumab for the treatment of wet AMD. LYTENAVA™ (bevacizumab gamma) is the subject of a centralized Marketing Authorization granted by the European Commission in the EU and Marketing Authorization granted by the Medicines and Healthcare products Regulatory Agency (MHRA) in the UK for the treatment of wet AMD.\n\nIn the United States, ONS-5010/LYTENAVA™ (bevacizumab-vikg) is investigational. In certain European Union Member States ONS-5010/LYTENAVA™ must receive pricing and reimbursement approval before it can be sold.\n\nBevacizumab-vikg (bevacizumab gamma in the EU and UK) is a recombinant humanized monoclonal antibody (mAb) that selectively binds with high affinity to all isoforms of human vascular endothelial growth factor (VEGF) and neutralizes VEGF’s biologic activity through a steric blocking of the binding of VEGF to its receptors Flt-1 (VEGFR-1) and KDR (VEGFR-2) on the surface of endothelial cells. Following intravitreal injection, the binding of bevacizumab to VEGF prevents the interaction of VEGF with its receptors on the surface of endothelial cells, reducing endothelial cell proliferation, vascular leakage, and new blood vessel formation in the retina.\n\nAbout Outlook Therapeutics, Inc.\n\nOutlook Therapeutics is a biopharmaceutical company focused on the development and commercialization of ONS-5010/LYTENAVA™ (bevacizumab-vikg, bevacizumab gamma) to optimize the standard of care for bevacizumab for the treatment of retina diseases. LYTENAVA™ (bevacizumab gamma) is the first ophthalmic formulation of bevacizumab to receive European Commission and MHRA Marketing Authorization for the treatment of wet AMD. Outlook Therapeutics commenced commercial launch of LYTENAVA™ (bevacizumab gamma) in Germany and the UK as a treatment for wet AMD.\n\nIn the United States, ONS-5010/LYTENAVA™ (bevacizumab-vikg) is investigational. If approved in the United States, ONS-5010/LYTENAVA™, would be the first approved ophthalmic formulation of bevacizumab for use in retinal indications, including wet AMD.\n\nForward-Looking Statements\n\nThis press release contains forward-looking statements. All statements other than statements of historical facts are “forward-looking statements,” including those relating to future events. In some cases, you can identify forward-looking statements by terminology such as “anticipate,” “believe,” “continue,” “expect,” “intend,” “may,” “on track,” “plan,” “potential,” “seek,” “target,” “will,” or “would” the negative of terms like these or other comparable terminology, and other words or terms of similar meaning. These include, among others, plans to resubmit the BLA for ONS-5010 and the expected timing thereof, Outlook Therapeutics’ ability to provide the additional clarity required by the FDA’ and to address the deficiency identified in the CRL, the potential to obtain FDA approval for ONS-5010, the potential of ONS-5010/LYTENAVA™ as a treatment for wet AMD, and other statements that are not historical fact. Although Outlook Therapeutics believes that it has a reasonable basis for the forward-looking statements contained herein, they are based on current expectations about future events affecting Outlook Therapeutics and are subject to risks, uncertainties and factors relating to its operations and business environment, all of which are difficult to predict and many of which are beyond its control. These risk factors include those risks associated with developing and commercializing pharmaceutical product candidates, risks of conducting clinical trials and risks in obtaining necessary regulatory approvals, including the risk that the Outlook Therapeutics is unable to address the issues identified in the CRL and ultimately obtain FDA approval, the content and timing of decisions by regulatory bodies, the sufficiency of Outlook Therapeutics’ resources, as well as those risks detailed in Outlook Therapeutics’ filings with the Securities and Exchange Commission (the SEC), including the Annual Report on Form 10-K for the fiscal year ended September 30, 2024, filed with the SEC on December 27, 2024, as supplemented by the Quarterly Report on Form 10-Q for the fiscal quarter ended June 30, 2025 and future reports Outlook Therapeutics files with the SEC, which include uncertainty of market conditions and future impacts related to macroeconomic factors, including as a result of the ongoing overseas conflicts, tariffs and trade tensions, fluctuations in interest rates and inflation and potential future bank failures on the global business environment. These risks may cause actual results to differ materially from those expressed or implied by forward-looking statements in this press release. All forward-looking statements included in this press release are expressly qualified in their entirety by the foregoing cautionary statements. You are cautioned not to place undue reliance on these forward-looking statements, which speak only as of the date hereof. Outlook Therapeutics does not undertake any obligation to update, amend or clarify these forward-looking statements whether as a result of new information, future events or otherwise, except as may be required under applicable securities law.\n\nInvestor Inquiries:\n\nJenene Thomas\n\nChief Executive Officer\n\nJTC Team, LLC\n\nT: 908.824.0775\n\nOTLK@jtcir.com",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/29/3157742/0/en/Outlook-Therapeutics-Provides-Update-on-Type-A-Meeting-with-FDA.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "This MacBook Pro-esque laptop has the world's largest battery and is built by the same company that brought you the smartphone with the biggest battery ever",
      "content": "EnergyBook Pro Ultra packs a 192Wh battery, the largest ever fitted into a laptop\n\nAvenir Telecom claims up to 28 hours of use and a week on standby\n\nAt 192Wh, the laptop unfortunately exceeds aviation limits for carry-on batteries\n\nEnergizer, better known for batteries and smartphones, is launching a new laptop that puts endurance ahead of all else.\n\nThe EnergyBook Pro Ultra comes with a 192Wh lithium-polymer monobloc, which the company says is the largest battery ever built into a laptop.\n\nAvenir Telecom, the French company which designs and manufactures Energizer-branded hardware, claims the new laptop can last for up to 28 hours of regular office work, or around 11 hours of gaming and graphics-heavy tasks. In standby mode, it can reportedly go a whole week without needing to be charged.\n\nThat just won't fly\n\n“With the EnergyBook Pro Ultra, we’re pushing the boundaries of what laptops look like. It’s packed with power, battery life, and durability - true to Energizer’s DNA,” noted Julien Galou, head of marketing at Avenir Telecom.\n\nThe company has form when it comes to packing large batteries into devices - in 2024, it rolled out the Hard Case P28K rugged smartphone with a huge 28,000mAh battery, promising a talk time of 122 hours (roughly five days) and a standby time of 2,253 hours or a little over three months.\n\nBattery aside, the specifications for the EnergyBook Pro Ultra laptop are otherwise decidedly mid-range.\n\nThe system features an AMD Ryzen 5 processor, 16GB of RAM, a 512GB NVMe SSD and an 18-inch Full HD+ display.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nConnectivity includes USB-C, HDMI, USB 3.0, SD card slot and a headphone jack.\n\nThe laptop will sell for €449 ($523) before tax. No word on when or where it will be available though.\n\nOne detail may limit its audience, however. Aviation safety rules restrict lithium-ion batteries on flights to 100Wh in carry-on luggage, with some airlines allowing up to 160Wh with special approval.\n\nAt 192Wh, the EnergyBook Pro Ultra exceeds both limits, making it unlikely to be permitted on most commercial flights (some airlines may not check, but it’s worth being aware).\n\nThe EnergyBook Pro Ultra is part of a wider line, which also includes 15- and 18-inch models with smaller batteries.\n\nWith the Ultra’s record-breaking size, Energizer has created a laptop that could struggle to live up to its promise of mobility.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/this-macbook-pro-esque-laptop-has-the-worlds-largest-battery-and-is-built-by-the-same-company-that-brought-you-the-smartphone-with-the-biggest-battery-ever",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "I replaced my ThinkPad with a 5G Windows laptop, and it's changed my workflow for good",
      "content": "HP EliteBook 6 G1q ZDNET's key takeaways The EliteBook 6 G1q is currently available for $1,382 at B&H Photo-Video.\n\nIt's a sleek and battery-efficient laptop with lots of ports and 5G connectivity.\n\nIt occupies that middle ground where a few hundred dollars more could get you a substantially more premium laptop. $1,382.95 at B&H Photo-Video\n\nFollow ZDNET: Add us as a preferred source on Google.\n\nHP's EliteBook 6 G1q is an affordable model from its productivity-minded lineup. It features extensive connectivity and a marathon battery in a thin and lightweight form factor.\n\nPreviously known as HP's 600 series, the EliteBook 6 G1 lineup is available in multiple RAM and memory configurations, a lightweight form factor, and either an AMD, Intel, or Qualcomm processor; a highly customizable laptop for a wide range of users.\n\nAlso: Why this portable hotspot may be my favorite travel gadget of the year\n\nI went hands-on with the EliteBook G1q (q for Qualcomm), which has the Snapdragon X Plus chip, 32GB of RAM, and a 512GB PCIe NVMe SSD. I found it to be a capable device with great battery life and a very comfortable keyboard. I'd recommend it as a lightweight work laptop, but there are a few concerns.\n\nThe entry-level machine with 16GB of memory and a 256GB SSD looks to be aimed at users who live in the cloud and value longevity over raw power, while higher-end hardware opens up the device for more diverse productivity uses.\n\nThe middle-of-the-road configuration I tested displays the performance you'd expect from a thin and light Snapdragon device. It boots up instantaneously, is highly responsive for everyday tasks, and has an efficient battery for all-day use.\n\nOn the surface, the EliteBook 6 G1q is nondescript and commercial, with HP's typical silver aluminum build, a gray keyboard, and a utilitarian display. But it also has an extensive selection of customizability, up to 64GB of RAM, a 1TB SSD, and numerous display options, including an 800-nit WUXGA (1920 x 1200) IPS screen at the top end.\n\nAlso: I tested Acer's $299 smart monitor, and it's a tariff-smart option I can get behind\n\nThe model I tested came with a WUXGA (1920x1200) IPS display with 300 nits of brightness and a 60Hz refresh rate. It's not quite what I'd call premium, but it gets the job done for work-related tasks, especially with the matte finish that mitigates glare well.\n\nAt 3.17 pounds, it's right around where it should be in terms of portability. It easily slides into a backpack or bag and lives up to its intended use case as a device for remote and hybrid workers.\n\nA touchscreen option is available, as are higher resolutions and refresh rates with a few hundred bucks added onto the price, but the upgrades add up quickly, approaching price points you'd get for more premium EliteBook models.\n\nThe right side of the laptop features a lock slot, ethernet port, USB-A, and nano SIM slot. Kyle Kucharski/ZDNET\n\nOne of the notable available features is the Snapdragon X72 5G card, which grants the laptop 5G connectivity, a solid option for users who need always-on connectivity in the field or away from Wi-Fi.\n\nThe feature is enabled with a service called HP Go, which uses an eSIM with multi-carrier 5G connectivity for $19 a month. It works by using infrastructure from the top three US carrier networks, whichever has the strongest available connection in the area.\n\nThis type of service can be critical for users who need a reliable connection in locations with unavailable or spotty Wi-Fi, but it is more geared toward the enterprise use case. That said, for anyone who travels and ends up having to pay for hotel Wi-Fi or struggling with terrible, unsecure connections, the $19 a month could be worth it.\n\nAlso: Is this the most promising Chromebook yet? This Acer has specs that almost rival my MacBook\n\nSpeaking of enterprise connectivity, this laptop has some pretty robust I/O, including an HDMI port, two USB-Cs, a 3.5mm headphone jack, a USB-A, a Kensington lock slot, a microSD, and even an Ethernet port. Thus, it's a highly compatible device that enterprise teams will appreciate.\n\nIt's also an enjoyable laptop to work on, as the keyboard is particularly nice. I found the large, sticky keys with nice key travel to be responsive and well-designed, except the Page Up and Page Down buttons near the arrow keys is a key placement choice I'm not a fan of.\n\nKyle Kucharski/ZDNET\n\nIn terms of performance, the EliteBook 6 G1q feels a lot like its Copilot+ PC peers with similar hardware. I had no issues with daily tasks during my week with this laptop, and I appreciate its snappy boot times and strong ability to multitask.\n\nThe EliteBook 6 G1q has the same 45 TOPS NPU as its X Elite counterpart, qualifying it as an official Copilot+ PC. Local AI tasks should run smoothly for everyday tasks, like HP's Poly camera pro feature, which is one of the better AI-powered videoconferencing suites to come pre-loaded.\n\nThe AI works with multiple cameras to create overlays and AI-generated backgrounds, but for most users, it just means it will automatically adjust to lighting conditions to improve your presence on camera.\n\nOur benchmarking numbers place it right around its competitors, earning scores in balanced mode that place it where it theoretically should be in comparison to higher-end EliteBook models, like the G1 series I tested earlier this year.\n\nUsers have the option to customize the battery on this laptop, with a 48Whr or 56Whr 3-cell unit, both with HP's fast charge. Either way, you'll get great battery longevity here. HP says you'll get over 24 hours of battery life in video playback in balanced mode. In my experience, I made it through two full workdays of intermittent sustained/idle usage on one charge.\n\nAlso: How to upgrade your 'incompatible' Windows 10 PC to Windows 11 - for free today\n\nOne thing of note with this laptop is the heat generation, which I was a little surprised to experience with the Snapdragon X Plus processor. This also applies to the ports: the left side of the laptop (where the USB-C ports are located) gets palpably warm when both are in use, but not so much that it's significantly uncomfortable.\n\nZDNET's buying advice\n\nThe high degree of customization, commercial build, extensive I/O, and 5G connectivity make the EliteBook 6 G1q a quintessential enterprise PC. The hardware on board is expressly geared toward productivity tasks, and the battery-efficient Snapdragon X rounds out the user experience.\n\nThe display is fine, but nothing overly premium. Although the build is nondescript and corporate, it's sleek and lightweight, with a comfortable keyboard and trackpad. If you're looking for a more premium productivity laptop from HP, however, check out the EliteBook G1a at the top of the lineup.\n\nAlso: This HP EliteBook I tested is one of the most versatile work laptops of 2025 - and it's on sale\n\nIf you're looking for something similar in terms of performance, form factor, and battery life, check out the OmniBook X with the Snapdragon X Elite chip, which doesn't have 5G connectivity, but is less than half the price.",
      "source": "ZDNet",
      "url": "https://www.zdnet.com/article/i-replaced-my-thinkpad-with-a-5g-windows-laptop-and-its-changed-my-workflow-for-good/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "AMD D2D Interconnect in \"Zen 6\" Gets Sea-of-Wires Upgrade",
      "content": "Jtuck9 Interesting to see how they perform in the handheld space. I thought they seemed more tailored toward workstations with emphasis on AI?!\n\nWell, by the looks of it, AT4 should be able to rival a PS5 at very low power, and AT3 able to rival a PS5pro at very low power (or PS5 at VERY VERY low power). I think many people will find that compelling.Then ofc there are (more-or-less) configs of AT2 that would appear to find themselves into the next-gen consoles.Then we have AT0 essentially built for AI. If those will be connected in such a config idk, but it's certainly possible.I know this goes outside the realm of this article (as I doubt anything beyond AT2 would be bonded to another in this fashion), but I wonder if AMD is holding AT1 until after 32Gigabit/40gbps GDDR7 exists.I say this because Hynix 32Gigabit/10gbps HBM4e is coming in 2027,and I imagine GDDR7 will follow/be similar, as RAM generations are usually 18 months apart, pegging that at perhaps around the end of 2027.That said, if you start to think about AT2, which might be an amazing chip, perhaps rivaling 6080 (if not just being a better alternative to 6070ti/6070), it does appear another config edging the 'forever' GPU people want to upsell to the cut-down consumer AT0 most people don't really need.In my mind that would be 32GB (which would require 4GB chips on a 256-bit bus for a single-sided config) and exceeding 100TF...which should handle anything creators make for a very long while.Both AT2 and perhaps 6080 may target being below one or two of these metrics purposely; AMD perhaps with 18 and then 24GB configs, nVIDIA 24 then 32GB...but both perhaps targeting <100TF (or so; 4k60mins).It would require an absurdly high clock with AT2's config (even if AMD targets high clocks on N3P) and buffer may become an issue long-term, while nVIDIA may target power/area with lower clocks on their design(s)The nVIDIA design *could* potentially pull it out if they choose, but they've been known to edge people and push them toward an upsell of their Halo. AMD may or may not do the same (long-term).Enter such a chip, which could steal the show (especially considering 3nm will be a fairly old process by then). With (if nothing else) 40gbps available/cheaper...that's what I'm personally most excited about.Given AMD's choice to pair these chiplets, their targets, the ubiquity of their performance, and the tiers of performance the GPUs should offer, I am very optimistic across markets and performance levels.Both in the foreseeable and even slightly further future.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341445/amd-d2d-interconnect-in-zen-6-gets-sea-of-wires-upgrade",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "“Zen 6”はCCDとIODの接続が変わる―SERDESから“Sea-of-Wires”へ",
      "content": null,
      "source": "Fc2.com",
      "url": "https://northwood.blog.fc2.com/blog-entry-12859.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Intel aims at AMD's Threadripper with its new Granite Rapids-WS CPU — chip armed with core count approaching the flagship AMD Threadripper 9995WX, boasts a 4.8GHz boost clock",
      "content": "It looks like Intel is getting ready to launch a new branch of Granite Rapids processors designed to compete directly with AMD’s Ryzen 9000WX series parts based on Zen 5. Resident X poster Momomo_us found an openbenchmark.org listing featuring an 86-core CPU codenamed Granite Rapid-WS.\n\nThe only specs we have are the cores, threads, and clock speed, featuring the aforementioned 86 cores and 172 threads operating at up to 4.8GHz. But being based on the Granite Rapids architecture, it is very likely that this chip is a much higher clocking offshoot of the Xeon 6787P, which also boasts 86 cores across two compute tiles, but peaks at a 3.8GHz peak turbo clock speed.\n\nAt 86 cores, this new chip is approaching the core count of AMD’s current Threadripper flagship, the 9995WX with 96 Zen 5 cores. This SKU might not even be the flagship part since Granite Rapids can scale up to 128 cores. Only time will tell if this is the case — to reach 128 cores, Intel has to use three compute dies, whereas with its 86-core Granite Rapid SKUs, it only needs to use two. Limiting Granite Rapids-WS to 86 cores has the potential to reduce manufacturing costs for Intel.\n\nRumors have been circulating about a workstation-offshoot of Granite Rapids for months. In February, we covered a Granite Rapids-W leak, allegedly stating these new workstation parts will come with up to 128 PCIe 5.0 lanes, feature eight-channel DDR5 memory support, and support Intel’s outgoing W890 chipset.\n\nGranite Rapids is Intel’s latest generation server architecture, and one of its most competitive yet, featuring core count parity with AMD EYPC processors for the first time since 2017, when it launched in the Xeon 6900P series late last year. Similar to Arrow Lake-S, Granite Rapids is based on a tile-based architecture, featuring several I/O and compute tiles to reach previously untouchable core counts.\n\nIntel hasn’t had a serious CPU lineup that has been able to compete with AMD’s Threadripper WX-series parts over the past two generations. Its outgoing W-3500 Sapphire Rapids Refresh chips only scale up to 60 cores, while AMD has had 96-core trims since the Threadripper 7000WX series and 64-core chips dating all the way back to the Threadripper 3000 series. With Granite Rapids-WS, Intel has its first opportunity in years to approach or outpace AMD on core count in the HEDT/workstation segment, similar to the server market.\n\nFollow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/intel-aims-at-amds-threadripper-with-its-new-granite-rapids-ws-cpu-chip-armed-with-core-count-approaching-the-flagship-amd-threadripper-9995wx-boasts-a-4-8ghz-boost-clock",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "No, Dedicated AI Buttons on Laptops Are Not Going to Sell More PCs",
      "content": "We’ll be waiting until next year for the first round of PCs sporting Qualcomm’s new Snapdragon X2 Elite Extreme chip, plus whatever Intel and AMD have in store for lightweight laptops. As a hint of what to expect, in stepped a company nobody had ever heard of, offering a laptop few people wanted. Humain (no, not that AI wearable company that bricked its wonky AI Pin and sold itself to HP for peanuts), a Saudi Arabian company, debuted a laptop at Qualcomm’s Snapdragon Summit in Hawaii (full disclosure: travel and lodging were paid by Qualcomm, and Gizmodo did not guarantee any coverage as a condition of accepting the trip), that looks like every other clamshell notebook, save for one small detail. Instead of the Copilot key that’s become standardized on Windows machines, it features an “Humain” AI key.\n\nHumain’s laptop is a Windows machine at its heart, powered by the Snapdragon X2 Elite chip. But the AI key brings up an extra layer of UI called Humain One. Through the interface, you can call up an AI chatbot, an AI image generator, and a few more semi-interesting capabilities. There’s a special chatbot for homework help, document summaries, or a “Story Generator.” The AI will create a narrative using the average third-grade reading level.\n\nIt’s nothing we haven’t seen before, most obviously from Microsoft’s own Copilot AI, which is built into the company’s 365 apps and desktop. Humain usurped Copilot’s new laptop with the promise that at least some of the AI processes are being handled on-device. The notebook is otherwise packing solid-sounding specs, from an OLED display designed by Samsung, 32GB of RAM, and a 1TB SSD. No, the company didn’t have any word about how much the machine will cost, or when, or where it will be available. There’s no word if it will come to the U.S., either. The only question remaining is, would you want it to?\n\nApps still don’t make use of new laptops’ AI capabilities\n\nI spent all of Snapdragon Summit barely able to take in the epic sights of Maui through the haze of big tech AI hype. Qualcomm’s new slogan, “AI is the new UI,” ran like a river through every new announcement and demo. Qualcomm wanted to imply that on-device AI will be able to look into your fridge and suggest meals (Samsung’s fridges already do that). You can use an AI app called Collov AI to remodel rooms in your house with new furniture, though it currently doesn’t have any hookup to major furniture retailers to see how products you can actually buy might look in your abode. It’s nothing I haven’t seen before; only now these features are supposedly running on the device, versus in the cloud.\n\nQualcomm’s explanation for how this works suggests that the new Snapdragon X2 Elite chip for PCs has such strong AI processing capabilities, but if a laptop or mini-PC using it ever gets overwhelmed, it can bring in the big guns—the major datacenters with such massive cloud compute they could suck the power grid dry. On-device AI should be the goal for every company. AI models are getting better at being contained. The Snapdragon X2 Elite’s redesigned NPU—or neural processing engine built for low-key or background AI tasks—now sports 80 TOPS (trillions of operations per second) versus the 45 TOPS on the original Snapdragon X platform.\n\nWhat that translates to is still vague. Collov AI, the home decoration app, was tasking the NPU at just 10%. The GPU, or graphics processing unit, was taking the brunt of the rest of the AI image generation. There’s nothing necessarily wrong with that, though I have yet to see a demo that can truly tax the NPU.\n\nBetter chips are getting more expensive\n\nI ran multiple benchmark tests on Qualcomm’s Snapdragon X2 Elite Extreme platform, all done on non-commercial test machines with 48GB of RAM and 1TB SSD under the hood. I was standing in front of many Qualcomm reps ready to slap my hand if I tried jumping for any non-synthetic benchmark. From what I could see, the chip does have more power behind it than previous Intel, AMD, and Qualcomm chips. The problem is that when you try and benchmark for AI performance, even if the chip does well, it’s too difficult to determine what that translates to when you’re using the device as a daily driver.\n\nThe Snapdragon X2 Elite Extreme’s GPU was especially impressive. The laptops managed to hit a score of 5,648 and an average of 41 fps in 3DMark’s Steel Nomad Light test and 23,586 in the Solar Bay benchmark. It all suggests that laptops with the Snapdragon X2 Extreme chip will be great for graphics tasks, but the issue will be the number of apps and drivers that are compatible with Qualcomm’s ARM-based chip. Apps like Maxon’s ZBrush should have an ARM version by early 2026, but good luck trying to get any gaming done on these machines.\n\nThese tests can only offer a perspective of what users could potentially expect from actual products. I couldn’t possibly say how much the X2 Elite Extreme laptops will cost in this age of tariffs. Recent rumors suggested TSMC, which manufactures these chips, is going to pass tariff costs for 3nm process CPUs onto Qualcomm and fellow chipmaker MediaTek.\n\n“It’s [TSMC’s] choice to try to figure out what to do with the pricing structure,” said Alex Katouzian, Qualcomm’s head of compute and mobile. “What we constantly think about is, ‘How do I get the most efficient design, meaning performance per millimeter square?'”",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/no-dedicated-ai-buttons-on-laptops-are-not-going-to-sell-more-pcs-2000664709",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "I thought my CPU was maxed out until I tweaked these BIOS settings",
      "content": null,
      "source": "MakeUseOf",
      "url": "https://www.makeuseof.com/cpu-was-maxed-until-these-bios-settings/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Wall Street Says AMD Stock Could Gain 40% in a Year",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/35104377/wall-street-says-amd-stock-could-gain-40-in-a-year",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Zhaoxin Launches Its KH-50000 CPUs With Up To 96 Cores: First Die Shots Reveal 12 Compute Chiplet Accompanying A Massive IO Chiplet",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/zhaoxin-launches-kh-50000-cpus-up-to-96-cores-first-die-shots-12-compute-chiplet/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Intel subnotebook regains ground — Asus ZenBook 14 OLED UX3405CA review",
      "content": "Transparency\n\nThe selection of devices to be reviewed is made by our editorial team. The test sample was provided to the author as a loan by the manufacturer or retailer for the purpose of this review. The lender had no influence on this review, nor did the manufacturer receive a copy of this review before publication. There was no obligation to publish this review. As an independent media company, Notebookcheck is not subjected to the authority of manufacturers, retailers or publishers.\n\nThis is how Notebookcheck is testing\n\nEvery year, Notebookcheck independently reviews hundreds of laptops and smartphones using standardized procedures to ensure that all results are comparable. We have continuously developed our test methods for around 20 years and set industry standards in the process. In our test labs, high-quality measuring equipment is utilized by experienced technicians and editors. These tests involve a multi-stage validation process. Our complex rating system is based on hundreds of well-founded measurements and benchmarks, which maintains objectivity. Further information on our test methods can be found here.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/Intel-subnotebook-regains-ground-Asus-ZenBook-14-OLED-UX3405CA-review.1126966.0.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Data Center Servers Market Opportunities and Strategies to 2034 | Data Center Server Market Sees Modular, High-Density, and AI-Optimized Solutions Transform Infrastructure",
      "content": "Dublin, Sept. 29, 2025 (GLOBE NEWSWIRE) -- The \"Data Center Servers Market Opportunities and Strategies to 2034\" report has been added to ResearchAndMarkets.com's offering.\n\n\n\nThe global data center server market reached a value of nearly $56.89 billion in 2024, having grown at a compound annual growth rate (CAGR) of 5.28% since 2019. The market is expected to grow from $56.89 billion in 2024 to $82.33 billion in 2029 at a rate of 7.67%. The market is then expected to grow at a CAGR of 7.45% from 2029 and reach $117.92 billion in 2034.\n\n\n\nGrowth in the historic period resulted from increasing data traffic, growing adoption of cloud computing, growing smart city initiative and proliferation of big data and analytics. Factors that negatively affected growth in the historic period were the high initial investment and operational costs and rising restrictive regulations.\n\n\n\nGoing forward, the rise in 5G connectivity, shift towards digital transformation across industries, growing adoption of IoT devices and surge in AI applications support will drive growth. Factor that could hinder the growth of the data center server market in the future include were cybersecurity threats and high energy consumption.\n\n\n\n\n\nNorth America was the largest region in the data center server market, accounting for 37.25% or $21.19 billion of the total in 2024. It was followed by Asia-Pacific, Western Europe and then the other regions. Going forward, the fastest-growing regions in the data center server market will be Asia-Pacific and South America where growth will be at CAGRs of 8.79% and 8.53% respectively. These will be followed by Africa and Middle East where the markets are expected to grow at CAGRs of 8.01% and 7.96% respectively.\n\n\n\nThe global data center server markets are fairly fragmented, with a large number of small players operating in the market. The top 10 competitors in the market made up 16.10% of the total market in 2023. Dell Technologies Inc. was the largest competitor with a 2.59% share of the market, followed by Supermicro with 2.34%, Asus with 2.12%, Gigabyte Technology with 1.98%, Microsoft Corp. with 1.93%, Quanta Computer Incorporated (Quanta Cloud Technology) with 1.19%, International Business Machines Corporation (IBM) with 1.07%, Hewlett Packard Enterprise Company with 1-01%, Cisco Systems Inc. with 0.99% and NEC Corporation with 0.88%.\n\n\n\nThe top opportunities in the data center server market segmented by product will arise in the rack servers segment, which will gain $11.46 billion of global annual sales by 2029. The top opportunities in the data center server market segmented by application will arise in the commercial servers segment, which will gain $18.6 billion of global annual sales by 2029. The top opportunities in the data center server market segmented by verticals will arise in the IT and telecom segment, which will gain $11.29 billion of global annual sales by 2029. The data center server market size will gain the most in the USA at $7.82 billion.\n\n\n\nMarket-trend-based strategies for the data center server market include revolutionizing AI and data center development with modular server solutions, introduction on localized and scalable data center solutions to support AI and cloud infrastructure expansion, high-density computing servers for optimized data center resources, next-generation blade server delivers unmatched performance and scalability.\n\n\n\nPlayer-adopted strategies in the data center server market include focus on expanding its business capabilities through innovative product launch to expand its operational capabilities and manufacturing capabilities through strategic investment.\n\n\n\nTo take advantage of the opportunities, the analyst recommends the data center server focus on expanding modular server solutions for ai and data center growth, focus on expanding localized and sustainable infrastructure, focus on high-density, energy-efficient server development, focus on advancing blade server technology for enhanced scalability, focus on microservers for growth, expand in emerging markets, continue to focus on developed markets, focus on expanding distribution channels for data center servers, focus on optimizing pricing strategies for data center servers, focus on targeted digital marketing, focus on industry partnerships and webinars, focus on targeting it and telecom end-users.\n\n\n\nMajor Market Trends\n\nRevolutionizing AI and Data Center Development with Modular Server Solutions\n\nIntroduction on Localized and Scalable Data Center Solutions to Support AI and Cloud Infrastructure Expansion\n\nHigh-Density Computing Servers for Optimized Data Center Resources\n\nNext-Generation Blade Server Delivers Unmatched Performance and Scalability\n\nKey Mergers and Acquisitions\n\nAMD Acquired ZT Systems\n\nRedcentric Acquired 4D Data Centres\n\nBit Digital, Inc. Acquired Enovum Data Centers\n\nMicrosoft Corporation Acquired Fungible Inc.\n\nMarkets Covered:\n\nProduct: Rack Servers; Blade Servers; Microservers; Tower Servers\n\nApplication: Industrial Servers; Commercial Servers\n\nVerticals: BFSI (Banking, Financial Services and Insurance); IT and Telecom; Government; Defense; Other Verticals\n\nKey Attributes:\n\n\n\n\n\nReport Attribute Details No. of Pages 345 Forecast Period 2024 - 2034 Estimated Market Value (USD) in 2024 $56.89 Billion Forecasted Market Value (USD) by 2034 $82.33 Billion Compound Annual Growth Rate 3.8% Regions Covered Global\n\n\n\n\n\nKey Topics Covered:\n\n\n\nMarket Characteristics\n\nGeneral Market Definition\n\nSummary\n\nData Center Server Market Definition and Segmentations\n\nMarket Segmentation by Product Rack Servers Blade Servers Microservers Tower Servers\n\nMarket Segmentation by Application Industrial Servers Commercial Servers\n\nMarket Segmentation by Verticals BFSI (Banking, Financial Services and Insurance) IT and Telecom Government Defense Other Verticals\n\n\n\nGlobal Data Center Server\n\nGlobal: PESTEL Analysis\n\nAnalysis of End User B2B Market\n\nGlobal Data Center Server Market Growth Rate Analysis\n\nHistoric Market Growth, 2019-2024, Value ($ Million)\n\nForecast Market Growth, 2024-2029, 2034F Value ($ Million)\n\nForecast Growth Contributors/Factors\n\nGlobal Data Center Server Total Addressable Market (TAM)\n\nGlobal Data Center Server Market Segmentation\n\nGlobal Data Center Server Market, Segmentation by Product\n\nGlobal Data Center Server Market, Segmentation by Application\n\nGlobal Data Center Server Market, Segmentation by Verticals\n\nGlobal Data Center Server Market, Sub-Segmentation of Rack Servers\n\nGlobal Data Center Server Market, Sub-Segmentation of Blade Servers\n\nGlobal Data Center Server Market, Sub-Segmentation by Microservers\n\nGlobal Data Center Server Market, Sub-Segmentation by Tower Servers\n\nData Center Server Market, Regional and Country Analysis\n\n\n\nCompetitive Landscape and Company Profiles\n\nDell Technologies Inc.\n\nSuper Micro Computer, Inc.\n\nAsus\n\nGigabyte Technology\n\nMicrosoft Corp.\n\nOther Major and Innovative Companies\n\nQuanta Computer Incorporated (Quanta Cloud Technology)\n\nInternational Business Machines Corporation (IBM)\n\nHewlett Packard Enterprise Company\n\nCisco Systems Inc.\n\nNEC Corporation\n\nLenovo\n\nGoogle LLC\n\nAtos (Bull Atos Technologies)\n\nSamsung Electronics Co., Ltd.\n\nFoxconn (Hon Hai Technology Group)\n\nInspur Group\n\nHitachi Ltd.\n\nFujitsu\n\nOracle Corporation\n\nInfortrend Technology Inc.\n\nCompetitive Benchmarking\n\nRecent Developments in the Data Center Server Market\n\nHigh-Performance AI Server with Scalable GPU Support\n\nNext-Generation Servers with Enhanced Security and AI Insights\n\nNext-Gen Rack Servers Enhance Performance with Latest Processor Integration\n\nInnovative Servers for High-Performance Cloud and AI Workloads\n\nHigh-Performance Server Hardware for Cutting-Edge Cloud Applications\n\nFor more information about this report visit https://www.researchandmarkets.com/r/7atzr8\n\nAbout ResearchAndMarkets.com\n\nResearchAndMarkets.com is the world's leading source for international market research reports and market data. We provide you with the latest data on international and regional markets, key industries, the top companies, new products and the latest trends.\n\nAttachment",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/29/3157459/28124/en/Data-Center-Servers-Market-Opportunities-and-Strategies-to-2034-Data-Center-Server-Market-Sees-Modular-High-Density-and-AI-Optimized-Solutions-Transform-Infrastructure.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "34\" Samsung ViewFinity S50GC Ultra-WQHD 100Hz 1440p AMD FreeSync HDR10 Monitor $220 + Free Shipping",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18643501-34-samsung-viewfinity-s50gc-ultra-wqhd-100hz-1440p-amd-freesync-hdr10-monitor-220-free-shipping",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Maingear debuts new premium desktop PCs — Apex Rush, Force models start at $6,259, with top-end model featuring hardline tubing and dual 420mm radiators",
      "content": "Popular PC vendor Maingear has today debuted a brand new line-up of extremely potent performance PCs with an eye-watering price tag to match. New this week are the Apex Force and Apex Rush models, starting at a cool $7,469/$6,259 respectively.\n\nFirst up is the new Apex Force, a full-tower chassis housed inside the Phanteks NV9 case. Maingear touts a dual-loop hardline cooling system with offset tubing, upgradable RGB, and more. Support for dual 420mm radiators with three 140mm fans keeps everything cool, which is important given the components on offer.\n\nMaingear Apex Force specs\n\nChassis: Phanteks NV9 (Full-tower)\n\nPhanteks NV9 (Full-tower) Motherboard: Top-tier Z890 and X870E motherboards from Asrock and MSI\n\nTop-tier Z890 and X870E motherboards from Asrock and MSI CPU: AMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K\n\nAMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K GPU: NVIDIA GeForce RTX 5080 and 5090 GPUs\n\nNVIDIA GeForce RTX 5080 and 5090 GPUs RAM: Up to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz)\n\nUp to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz) Storage: Up to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs\n\nUp to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs Cooling: 2x 420mm x 60mm radiators, 6x 140mm x 30mm RGB fans, Custom APEX Integrated Cooling System, Separate GPU and CPU dual loop system, Easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance\n\n2x 420mm x 60mm radiators, 6x 140mm x 30mm RGB fans, Custom APEX Integrated Cooling System, Separate GPU and CPU dual loop system, Easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance Power: Up to 1650W 80+ Titanium PSU\n\nUp to 1650W 80+ Titanium PSU Aesthetics: Acrylic and metal hard tubing with 10-degree offset to match case design, premium metal fittings in various colors, dual coolant color options, multiple translucent coolant colors available, diffused RGB trim kit, motherboard and case RGB control with separate cooling loop zones.\n\nAll of that will set you back a cool $7,469, but that's just the starting price, with upgrade options for beefier processor, GPU, RAM, and storage likely to run you more.\n\nThe new Apex Rush is cheaper (relatively speaking), starting at just $6,259. The dual-chamber mid-tower has panoramic tempered glass, and customization for water cooling with options for hard and soft tubing. Cooling is less prolific at just dual 360mm radiators with six 120mm fans. There are also screwless panels for the cooling system to make draining and filling easier.\n\n(Image credit: Maingear)\n\nMaingear Apex Rush specs\n\nChassis: Lian-Li O11 EVO RGB (Mid-tower)\n\nLian-Li O11 EVO RGB (Mid-tower) Motherboard: Top-tier Z890 and X870E motherboards from Asrock and MSI\n\nTop-tier Z890 and X870E motherboards from Asrock and MSI CPU: AMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K\n\nAMD Ryzen 9700X to 9950X3D and Intel Core Ultra 265K and 285K GPU: NVIDIA GeForce RTX 5080 and 5090 GPUs\n\nNVIDIA GeForce RTX 5080 and 5090 GPUs RAM: Up to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz)\n\nUp to 64GB T-Force Extreme RGB DDR5 6000MHz (and up to 96GB at 6400MHz) Storage: Up to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs\n\nUp to 8TB Gen4 or 4TB Gen5 M.2 NVMe SSDs Cooling: 2x 360mm radiators, 7x 120mm RGB fans, Custom APEX Integrated Cooling System, easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance\n\n2x 360mm radiators, 7x 120mm RGB fans, Custom APEX Integrated Cooling System, easily accessible drain and fill ports, serviceable pump, quick disconnects on drain ports for easy maintenance Power: Up to 1650W 80+ Titanium PSU\n\nUp to 1650W 80+ Titanium PSU Aesthetics: Soft vinyl or Neoprene tubing with optional braided sleeving or Acrylic and Metal hard tubing, Premium metal fittings in various colors, multiple translucent coolant color options, braided cable sleeving, motherboard and case RGB control with diffused lighting\n\nLike the rest of the lineup, the new Apex Force and Apex Rush PCs come with a one-year warranty, extendable to three years, with financing options also available. Maingear's latest PCs can be found on its website.\n\nFollow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/desktops/gaming-pcs/maingear-debuts-new-premium-desktop-pcs-apex-rush-force-models-start-at-usd6-259-with-top-of-the-line-nvidia-intel-and-amd-in-tow",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Nvidia (NVDA) Stock Trades Up, Here Is Why",
      "content": "What Happened?\n\nShares of leading designer of graphics chips Nvidia (NASDAQ:NVDA) jumped 2.3% in the afternoon session after several Wall Street firms raised their price targets on the stock and reports surfaced of a major deal involving its advanced AI systems.\n\nThe positive sentiment was fueled by a reported deal where cloud provider CoreWeave agreed to supply Meta Platforms with up to $14.2 billion in AI computing power using Nvidia's latest GB300 systems. This agreement highlighted the immense and sustained demand for AI infrastructure from major tech companies. Further boosting investor confidence, several financial firms, including KeyBanc, Barclays, and Citi, increased their price targets for Nvidia. Analysts pointed to an improving supply of key components and strong, continued spending in the AI sector as the primary reasons for their optimistic outlook, which helped push the stock to a record high.\n\nAfter the initial pop the shares cooled down to $186.21, up 2.4% from previous close.\n\nIs now the time to buy Nvidia? Access our full analysis report here, it’s free.\n\nWhat Is The Market Telling Us\n\nNvidia’s shares are quite volatile and have had 18 moves greater than 5% over the last year. In that context, today’s move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.\n\nThe previous big move we wrote about was 8 days ago when the stock gained 4.1% on the news that the company announced a partnership with OpenAI that included plans for a potential investment of up to $100 billion.\n\nThe deal aimed to supply OpenAI with advanced AI hardware for its next generation of AI models and the buildout of massive data centers. According to the announcement, the partnership involved deploying at least 10 gigawatts of Nvidia's systems for OpenAI's AI infrastructure. This news solidified Nvidia's central role in the future of artificial intelligence.\n\nNvidia is up 34.6% since the beginning of the year, and at $186.21 per share, has set a new 52-week high. Investors who bought $1,000 worth of Nvidia’s shares 5 years ago would now be looking at an investment worth $13,762.\n\nUnless you’ve been living under a rock, it should be obvious by now that generative AI is going to have a huge impact on how large corporations do business. While Nvidia and AMD are trading close to all-time highs, we prefer a lesser-known (but still profitable) semiconductor stock benefiting from the rise of AI. Click here to access our free report on our favorite semiconductor growth story.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-nvda-stock-trades-why-185050056.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "$50 Battering RAM Attack Breaks Intel and AMD Cloud Security Protections",
      "content": "A group of academics from KU Leuven and the University of Birmingham has demonstrated a new vulnerability called Battering RAM to bypass the latest defenses on Intel and AMD cloud processors.\n\n\"We built a simple, $50 interposer that sits quietly in the memory path, behaving transparently during startup and passing all trust checks,\" researchers Jesse De Meulemeester, David Oswald, Ingrid Verbauwhede, and Jo Van Bulck said on a website publicizing the findings. \"Later, with just a flip of a switch, our interposer turns malicious and silently redirects protected addresses to attacker-controlled locations, allowing corruption or replay of encrypted memory.\"\n\nBattering RAM compromises Intel's Software Guard Extensions (SGX) and AMD's Secure Encrypted Virtualization with Secure Nested Paging (SEV-SNP) hardware security features, which ensure that customer data remains encrypted in memory and protected during use.\n\nIt affects all systems using DDR4 memory, specifically those relying on confidential computing workloads running in public cloud environments to secure data from the cloud service provider using hardware-level access control and memory encryption.\n\nThe attack, in a nutshell, involves leveraging a custom-built, low-cost DDR4 interposer hardware hack to stealthily redirect physical addresses and gain unauthorized access to protected memory regions. The interposer makes use of simple analog switches to actively manipulate signals between the processor and memory, and can be built for less than $50.\n\nOn Intel platforms, Battering RAM achieves arbitrary read access to victim plaintext or write plaintext into victim enclaves, whereas on AMD systems, the attack can be used to sidestep recent firmware mitigations against BadRAM, which was documented by the researchers back in December 2024, and introduce arbitrary backdoors into the virtual machine without raising any suspicion.\n\nSuccessful exploitation of the vulnerability can allow a rogue cloud infrastructure provider or insider with limited physical access to compromise remote attestation and enable the insertion of arbitrary backdoors into protected workloads.\n\nBattering RAM was reported to the vendors earlier this year, following which Intel, AMD, and Arm have responded that physical attacks are currently considered out of scope of their product's threat model. However, defending against Battering RAM would require a fundamental redesign of memory encryption itself, the researchers noted.\n\n\"Battering RAM exposes the fundamental limits of the scalable memory encryption designs currently used by Intel and AMD, which omit cryptographic freshness checks in favor of larger protected memory sizes,\" they added. \"Battering RAM [...] is capable of introducing memory aliases dynamically at runtime. As a result, Battering RAM can circumvent Intel's and AMD's boot-time alias checks.\"\n\nThe disclosure comes as AMD released mitigations for attacks dubbed Heracles and Relocate-Vote disclosed by the University of Toronto and ETH Zürich, respectively, that can leak sensitive data from cloud environments and confidential virtual machines that rely on AMD's SEV-SNP technology by means of a malicious hypervisor.\n\n\"The system lets the hypervisor move data around to manage memory efficiently,\" David Lie, director of the Schwartz Reisman Institute (SRI) at the University of Toronto, said. \"So when data is relocated, AMD's hardware decrypts it from the old location and re-encrypts it for the new location. But, what we found was that by doing this over and over again, a malicious hypervisor can learn recurring patterns from within the data, which could lead to privacy breaches.\"\n\nLast month, ETH Zürich researchers also demonstrated that a CPU optimization known as the stack engine can be abused as a side channel for attacks that lead to information leakage. A proof-of-concept (PoC) has been developed for AMD Zen 5 machines, although it's believed that all models have this \"abusable hardware feature.\"\n\nThe discovery of Battering RAM also follows a report from Vrije Universiteit Amsterdam researchers about a new, realistic attack technique referred to as L1TF Reloaded that combines L1 Terminal Fault (aka Foreshadow) and Half-Spectre gadgets (aka incomplete Spectre-like code patterns) to leak memory from virtual machines running on public cloud services.\n\n\"L1TF is a CPU vulnerability that allows an (attacker) VM to speculatively read any data residing in the (core-local) L1 data cache – including data the VM shouldn't have access to,\" VUSec researchers said. \"At a high level, L1TF Reloaded abuses this to obtain an arbitrary RAM read primitive.\"\n\nGoogle, which provided the researchers with a sole-tenant node in order to conduct the research safely without potentially affecting any other customers, awarded a $151,515 bug bounty and \"applied fixes to the affected assets.\" Amazon said the L1TF Reloaded vulnerability does not impact the guest data of AWS customers running on the AWS Nitro System or Nitro Hypervisor.\n\nSpectre, which first came to light in early 2018, continues to haunt modern CPUs, albeit in the form of different variants. As recently as two weeks ago, academics from ETH Zürich devised a new attack known as VMScape (CVE-2025-40300, CVSS score: 6.5) that breaks virtualization boundaries in AMD Zen CPUs and Intel Coffee Lake processors.\n\nDescribed as a Spectre branch target injection (Spectre-BTI) attack targeting the cloud, it exploits isolation gaps across host and guest in user and supervisor modes to leak arbitrary memory from an unmodified QEMU process. A software fix has been introduced in the Linux kernel to counter the cross-virtualization BTI (vBTI) attack primitive.\n\n\"VMScape can leak the memory of the QEMU process at the rate of 32 B/s on AMD Zen 4,\" the authors said in a study. \"We use VMScape to find the location of secret data and leak the secret data, all within 772 s, extracting the cryptographic key used for disk encryption/decryption as an example.\"",
      "source": "Internet",
      "url": "https://thehackernews.com/2025/10/50-battering-ram-attack-breaks-intel.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Programming AI Accelerators with Triton",
      "content": "Introduction Sure, computing Deep Neural Networks (DNNs) is a computationally expensive endeavour. Luckily, their computation can be parallelized on Graphics Processing Units (GPUs), which excel at performing numerous small tasks concurrently. To enable programmability of this hardware, several frameworks have been released for General Purpose (GPGPU) computing such as CUDA – but remain complex for easy adoption and implementation. This is irksome for researchers and deep learning practitioners who need to iterate through algorithms quickly to achieve optimal performance. Domain Specific Languages (DSLs) and compilers like Triton are excellent for enhancing productivity when writing GPU kernels to accelerate training and inference for AI workloads. Note that this article is covering the Triton DSL and not the Triton Inference Server.\n\nKey Takeaways Triton is a python DSL and compiler initially designed for GPU kernels but has been expanding to support other hardware, including CPUs and AI accelerators.\n\ninitially designed for GPU kernels but has been expanding to support other hardware, including CPUs and AI accelerators. Before Triton, developers primarily used high-level frameworks (like PyTorch) or low-level languages (like CUDA). Triton provides an abstraction layer that simplifies GPU programming compared to low-level languages, while offering more control than high-level frameworks.\n\nThe triton.jit decorator ( @triton.jit ) decorator defines Triton kernels.\n\n) decorator defines Triton kernels. Pointer arithmetic is used for computing memory locations, ensuring that memory accesses are fast.\n\nWhy was Triton Developed? Before Triton, developers had two main options for programming machine learning tasks on different hardware: (1) High-Level Frameworks (like PyTorch) and (2) Low-Level Languages (like CUDA or PTX). The philosophy behind Triton is to let the compiler do the work you don’t want to do, while still giving you control over critical aspects like algorithms and tuning parameters. You still define your algorithm, data types, and precision, but you don’t have to worry about complex tasks such as shared memory management, using tensor cores, and load coalescing and optimizing memory access patterns. The Triton compiler handles all of this automatically, saving the developer significant effort.\n\nThe above diagram and the table below was presented in a talk by Thomas Raoux from OpenAI at the PyTorch 2023 conference :“Triton tries to find an abstraction sweet spot between what you want to expose to users and what you want the compiler to do… Compilers are productivity tools…the goal of Triton is to have the compiler do the work you don’t want to do … but still leaves control on things like algorithms and any knob you want to use to be able to do tuning.” CUDA Triton Torch Op Algorithm User User Compiler Shared memory User Compiler Compiler Barriers User Compiler Compiler Distribution to blocks User User Compiler Grid size User User Compiler Distribution to Warps/threads User Compiler Compiler Tensor Core usage User Compiler Compiler Coalescing User Compiler Compiler Intermediate data layout User Compiler Compiler Workgroup size User User Compiler In this tutorial, we’re going to implement matrix multiplication with Triton. There are a number of other tutorials available in the official documentation including vector addition, fused softmax, low-memory dropout, layer normalization, fused attention (FlashAttention v2), invoking a custom function from an external library, group GEMM, persistent matmul, block scaled matrix multiplication.\n\nAnatomy of a Triton Kernel\n\nThe above figure was presented in the Triton 2024 conference in the Tools for Triton talk by Keren Zhou. It may also be worthwhile to familiarize yourself with the triton.language page in the Triton documentation.\n\nKernel decorator: A @triton.jit decorator defines a triton kernel.\n\nPointers: These are passed into the function and specify the memory location where the elements of value are stored.\n\nProgram IDs: tl.program_id() is used to specify the current program instance\n\nMemory Operations: tl.load and tl.store handle moving tensor values between global memory and Triton’s registers\n\nPrimer on Matrix Multiplication Matrix A with shape (M, K)\n\nMatrix B with shape (K, N)\n\nResulting matrix C has shape (M, N) When implementing matrix multiplication, we want to break it down into smaller chunks – often referred to as tiles or blocks. If we look at the code, we have a doubly nested for loop where one loop is placed inside another. We would use this structure to iterate over two-dimensional data, like a grid, matrix, or table. The outer loops parallelize the work across blocks while the inner loops accumulate the dot products for each tile. A Triton program instance is performing each iteration of the doubly-nested for-loop. for m in range ( 0 , M , BLOCK_SIZE_M ) : for n in range ( 0 , N , BLOCK_SIZE_N ) : acc = zeros ( ( BLOCK_SIZE_M , BLOCK_SIZE_N ) , dtype = float32 ) for k in range ( 0 , K , BLOCK_SIZE_K ) : a = A [ m : m + BLOCK_SIZE_M , k : k + BLOCK_SIZE_K ] b = B [ k : k + BLOCK_SIZE_K , n : n + BLOCK_SIZE_N ] acc += dot ( a , b ) C [ m : m + BLOCK_SIZE_M , n : n + BLOCK_SIZE_N ] = acc For more context on the code:\n\nThe line below extracts a horizontal tile of matrix A with dimensions BLOCK_SIZE_M by BLOCK_SIZE_K. a = A [ m : m + BLOCK_SIZE_M , k : k + BLOCK_SIZE_K ] A : The full matrix\n\nm: m+BLOCK_SIZE_M : This is the row slice. Here, we select a block of rows starting at index m and ending index m+BLOCK_SIZE_M . The outer for loop, for m in range(0,M,BLOCK_SIZE_M): , increments in m steps of BLOCK_SIZE_M, moving the starting point for each new row block. k : k+BLOCK_SIZE_K : This is the column size. Here, we are selecting a block of column that begin with index k and ends at k+BLOCK_SIZE_K. This is addressed by the inner inner for loop, for k in range(0, K, BLOCK_SIZE_K), which iterates through the columns of matrix A in blocks of BLOCK_SIZE_K. The line below extracts a vertical tile of matrix B with dimensions BLOCK_SIZE_K by BLOCK_SIZE_N. b = B [ k : k + BLOCK_SIZE_K , n : n + BLOCK_SIZE_N ] B: The second full matrix\n\nk : k+BLOCK_SIZE_K : In matrix B , this is the row slice. A block of rows is selected from matrix B starting at k and ending at k+BLOCK_SIZE_K .\n\nn : n+BLOCK_SIZE_N : This is the column size. Here, we are selecting a block of columns in matrix B that begin with index n and ends at n+BLOCK_SIZE_N. This is addressed by the inner for loop, for n in range(0, N, BLOCK_SIZE_N), which iterates through the columns of matrix B in blocks of BLOCK_SIZE_N. The core idea here is that by taking slices of our matrices, we can perform calculations – in this case the dot product – on smaller manageable chunks of data that can be loaded on to faster GPU memory leading to better GPU performance.\n\nGetting Started with Triton on DigitalOcean DigitalOcean has AI accelerators and Virtual Machines available as GPU Droplets and Droplets respectively. With respect to GPUs, we offer many solutions including NVIDIA H100 and H200 as well as AMD MI300 and MI325.Create a GPU Droplet and in the web console: git clone https : // github . com / triton - lang / triton . git cd triton pip install - r python / requirements . txt pip install - e . If LLVM isn’t installed on your system, the setup.py script will automatically fetch the official LLVM static libraries and use those for linking. To build using your own LLVM version, check the “Building with a custom LLVM” section on GitHub. After installation, you can verify everything works by running the test suite. make dev - install make test make test - nogpu\n\nConclusion In this tutorial, we covered the motivation behind and the fundamentals of Triton. Additionally, we walked you through a Triton matrix multiplication implementation and benchmarking. Be sure to check out the links scattered throughout the article and the references section for supplementary content.\n\nFinal Thoughts Triton strikes a balance by allowing its users to define and manipulate tensors in SRAM and modify them with the use of torch-like operators, making it possible to write efficient GPU code without extensive CUDA experience. There’s a lot we’re curious about. Particularly, how software and hardware co-evolves. How do open-source languages like Triton affect the CUDA moat? How does Triton compare to CuTe-DSL, Nvidia’s python DSL for kernel programming? What languages does the developer community and industry gravitate toward? And critically, how do these choices shape what gets built: do accessible abstractions democratize AI development, or do they introduce performance ceilings that matter at scale?",
      "source": "Digitalocean.com",
      "url": "https://www.digitalocean.com/community/tutorials/introduction-to-triton-programming",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "William Shatner amd Tom Bergeron Team Up for Holiday Drama Series FAMILY TREE",
      "content": "William Shatner and Tom Bergeron are joining forces for a new holiday dramedy titled Family Tree, which is currently in pre-production and gearing up to begin filming in 2026. The project is being produced by Pathway Pictures.\n\nThe series was created by Shatner and Bergeron, with both set to star and executive-produce alongside Nat Bernstein. The script comes from Katie Amanda Keane and Marla Sokoloff, with Sokoloff also stepping behind the camera to direct.\n\nFamily Tree tells the story of three estranged siblings who reunite during Christmas to sell their rundown childhood home, only to realize that restoring the house could also help mend their broken relationships. Shatner will play Frank, while Bergeron will take on the role of Jeff.\n\nSokoloff, who fans will recognize from her roles in The Practice and Fuller House, shared her excitement about the project, saying:\n\n“Family Tree is about the kind of healing that only happens when you’re stuck together with the people who know you best, and challenge you the most. It’s a story with grief, growth, and humor, wrapped in holiday warmth.\n\n“Katie Amanda Keane and I have always wanted to collaborate on a holiday movie that is rooted in family reality with a touch of holiday magic, and I think we accomplished that with this script.”\n\nShatner also spoke about the project, adding: “I am so pleased to be involved in this magical mysterious Christmas show that celebrates love!”\n\nWith a heartfelt story, a mix of comedy and drama, and Shatner and Bergeron leading the charge, Family Tree looks like it’s shaping up to be a charming addition to the holiday season lineup when it eventually arrives.\n\nSource: Deadline",
      "source": "GeekTyrant",
      "url": "https://geektyrant.com/news/william-shatner-amd-tom-bergeron-team-up-for-holiday-drama-series-family-tree",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Intel's original 64bit extensions for x86",
      "content": "Intel’s original 64bit extensions for x86\n\nIntroduction\n\nIn the late 1900s, Intel was fully invested in Itanium (IA-64) being their future 64bit architecture.\n\nAt that time (allegedly around 1997-1998), some Intel engineers – who were more cautious than their management – built a 64bit extension for their x86 processors as a backstop. It never shipped:\n\nIntel’s Pentium 4 had our own internal version of x86–64. But you could not use it: we were forced to “fuse it off”, meaning that even though the functionality was in there, it could not be exercised by a user.\n\nThis was a marketing decision by Intel — they believed, probably rightly, that bringing out a new 64-bit feature in the x86 would be perceived as betting against their own native-64-bit Itanium, and might well severely damage Itanium’s chances.\n\n– Bob Colwell\n\nAMD announced AMD64, their own 64bit extension to x86, in 1999 (and shipped it in 2003), condemning both Itanium and Intel’s own x86 extension to obscurity.\n\nIntel implemented AMD’s design in Project Yamhill and shipped its first processors with AMD64 in 2004.\n\nHow did Intel’s design look like?\n\nWhile AMD’s 64bit extension design that repurposed inc/dec instructions as the REX prefix is well-documented, there is very little known about Intel’s own 64bit extension design.\n\nHere is what can be reconstructed from Intel’s patent applications from 2000 and 2003:\n\nAn instruction having [a] format […] — where the mode field is 01B , the R/M field is 100B , the index field is 100B — has addressing mode information that is currently unsupported in the IA-32 architecture regardless of the value of the scale field.\n\nAn instruction of [that] format […] thereby includes heretofore unused bit fields (e.g., the two bits of scale field, bits of displacement, etc.), that can support an expanded logical register set for existing instructions formats and legacy operands.\n\nMaterial from the Bristol Community College also mentions this specific combination of bits:\n\nNote that this addressing mode does not allow the use of the ESP register as an index register.\n\nPresumably, Intel left this particular mode undefined to provide the ability to extend the addressing modes in a future version of the CPU.\n\nDifferences from AMD64\n\nAMD’s REX prefix introduced 1 bit R to extend the 3-bit register to 4 bits, allowing access to 16 registers.\n\nThe prefix also added 1 bit W to extend operand size, 1 bit X to extend SIB byte’s index and 1 bit B to extend SIB byte’s base.\n\nIntel’s approach would have added 2 additional bits to the existing 3-bit register encoding, and introduced a second, additional 5-bit register encoding.\n\nIt appears this encoding would have provided a future expansion possibility to 32 registers, even if the implementation may have been limited to 16 registers at first.\n\nIt is unclear what the equivalent of (or the alternative to) AMD64’s W , X and B bits would have been under Intel’s design.\n\nConclusion\n\nSadly, there is no definitive information on how close the patents were to what was shipped (fused-off) in Intel processors of that specific time period.",
      "source": "Soc.me",
      "url": "https://soc.me/interfaces/intels-original-64bit-extensions-for-x86.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "AMD Dense Geometry Format (DGF) Aims to Increase Visual Detail with Future GPUs",
      "content": "Visible Noise Nine months after Nvidia ships a feature, AMD produces a paper about their equivalent, and btw it doesn’t work with any of their existing products. Looks like 90XX is a dead end product.\n\nVisible Noise Why are people so surprised and angry at Nvidia’s success?\n\nVisible Noise They literally have no competition. Nvidia is still delivering features years ahead of AMD.\n\nHecate91 As usual Nvidia fans whine that AMD cards don't have a proprietary to Nvidia feature, then whine anyways when AMD develops something similar because they've never bought an AMD and never have any intention to do anything but mindlessly bash the brand.\n\nAnyway unless the feature does something groundbreaking then it's just another optional feature, I wouldn't expect this to make RDNA4 cards obsolete, and perhaps it could be processed at a driver level or on existing hardware.\n\nNvidia shipped Ray Tracing, it wasn't supported on GTX cards. They shipped MFG, it's not supported on cards prior to RTX50. You don't consider GeForce a dead end lineup, do you ?Because Nvidia is using their success to push their agenda of making the entire planet dependent on their dogshit AI tech that nobody neither wants nor needs.100% AI generated raster ? Miss me with that shit.The latest AMD has been on an Nvidia feature is Ray Reconstruction/Redstone and they barely have a full year of latency on this.Also, I'd like to point out that if you read the article a little bit closer, AMD's tech seems to be better since hitting broader, not just RT perf.And since if could run on raster, it would be hardware agnostic instead of vendor locked.I noticed that so far, when AMD follows, they might be later on delivery, but they follow with better.I'm curious about that \"potential performance hit\" mentioned on the article, how much of a hit are we talking about ? How much variance in outcome can we expect ? How is it behaving at different resolutions and different tiers of details complexity ? Is it hardware agnostic ? How would it run on other brands of cards ?I gotta say, I'm looking forward to this, even if if looks to be hardware dependent to get the intended performance, it kinda sounds like a new \"FSR moment\" to me when they make something that just works for everyone and improves X or Y factor.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341494/amd-dense-geometry-format-dgf-aims-to-increase-visual-detail-with-future-gpus",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Nvidia Stock Edges Up. Can It Keep Its Lead Over AMD?",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/3117c25ef592c136",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "China's 96-core x86 CPU taps chiplet design to rival AMD EPYC and Intel Xeon — 13 chiplets per processor provide up to 384 cores on a single motherboard, but no word on power consumption",
      "content": "Zhaoxin may not produce the best CPUs for gaming, but the leading Chinese fabless semiconductor enterprise is undoubtedly preparing to unleash a highly impressive server chip. Zhaoxin has unveiled its next-generation Kaisheng KH-50000 processors, which the company describes in its press release as \"presenting a 'technological gift' on the eve of the 76th anniversary of the founding of the People's Republic of China.\"\n\nThe KH-50000 utilizes Zhaoxin's latest Century Avenue architecture, named after a famous road in Shanghai. The company is fond of naming its architectures after famous locations within Shanghai because, after all, Zhaoxin is a joint venture between VIA Technologies and the Shanghai government. Century Avenue is the current architecture used by the company for its mainstream KaiXian KX-7000 processors; consequently, it is logical for Zhaoxin to align its latest server processors accordingly. Although Century Avenue is an internally developed architecture by Zhaoxin, many speculate that Century Avenue derives from Centaur Technology's CNS core, prior to the company's split from VIA Technologies in 2021.\n\nZhaoxin utilizes a chiplet design for the KH-50000, similar to AMD's Ryzen and EPYC processors, with a greater emphasis on the latter, given the high number of cores. A chiplet design would enable Zhaoxin to push the core boundary on the KH-50000, effectively matching AMD's EPYC 9004 (codenamed Genoa) series that tops out at 96 cores. Zhaoxin has planned two variants of the KH-50000: the flagship 96-core SKU and a more affordable 72-core SKU, both of which lack simultaneous multithreading (SMT). The KH-50000 represents a monumental leap forward for Zhaoxin, as it provides 3X more cores than the company's existing KH-40000.\n\nZhaoxin's photograph of the KH-50000 reveals that the chipset layout exhibits minor differences from that of AMD; the core design remains consistent, however. The gargantuan I/O die is centrally positioned on the processor, encircled by four clusters of compute dies. Each cluster contains three compute dies, totaling twelve. Each die incorporates eight cores and 32MB of L3 cache. When assembled, the resulting processor comprises a 96-core configuration with 384MB of L3 cache.\n\nZhaoxin Kaisheng KH-50000 Specifications\n\nSwipe to scroll horizontally Processor Architecture Cores / Threads Base / Boost Clock (GHz) L3 Cache (MB) Memory Support PCIe Lanes SATA 3.2 Ports USB Ports Socket Package Size (mm) KH-50000 Century Avenue 96 / 96 2.2 / 3.0 384 12 Channel DDR5-5200 128 PCIe 5.0 + 16 PCIe 4.0 12 4 x USB 3.2 Gen 2 LGA 72 x 76 KH-50000 Century Avenue 72 / 72 2.6 / 3.0 384 12 Channel DDR5-5200 128 PCIe 5.0 + 16 PCIe 4.0 12 4 x USB 3.2 Gen 2 LGA 72 x 76 KH-40000/32 Yongfeng 32 / 32 2.5 / N/A 64 8 Channel DDR4-3200 128 PCIe 3.0 16 8 x USB 3.2 Gen 1 LGA 77.5 x 56.5\n\nThe clock speeds on the KH-50000 aren't too shabby and fall in line with what you'd expect from a server chip. The 96-core variant has a 2.2 GHz base clock and 3.0 GHz boost clock. Since the 72-core chip has fewer cores, Zhaoxin could push the base clock to 2.6 GHz but maintained the same boost clock.\n\nAlthough the company has taken the wraps off the KH-50000, it didn't reveal the TDP or other power metrics for the upcoming server chip. The thing with a chiplet design is that Zhaoxin can effectively utilize older process nodes for the KH-50000. Sanctions don't hurt as much if you don't care about power consumption.\n\nFor comparison, AMD has historically kept its top EPYC chips around the 300-350W range, and that's with SMT. Nonetheless, the chipmaker has recently pushed the power envelope up to 500W, which is understandable when its EPYC processors are maxing out at 192 cores.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nIn addition to core count, the KH-50000 advances the development of Chinese server processors. It now supports up to 12 channels of DDR5-5200 RAM, allowing for a maximum of 3TB of memory, in contrast to the 2TB supported by DDR4-3200 on the KH-40000. Zhaoxin has added Compute Express Link (CXL) interconnect support. Furthermore, the expansion capabilities of the KH-50000 have enjoyed an upgrade to include 128 PCIe 5.0 lanes and 16 PCIe 4.0 lanes, compared to the 128 PCIe 3.0 lanes available on the KH-40000.\n\nThe SATA and USB ports experienced a slight decrease in numbers when comparing the KH-50000 to the KH-40000. However, Zhaoxin has upgraded the latter to support the latest USB 3.2 Gen 2 specification.\n\n(Image credit: Zhaoxin)\n\nThe KH-50000 supports x86 32-bit and 64-bit instructions, including SSE4.2, AVX, and AVX2. Support for virtualization is also present. To adhere to China's security guidelines, the KH-5000 supports the country's proprietary SM2, SM3, and SM4 encryption standards. Notably, Zhaoxin has integrated National Technology's fourth-generation trusted computing chip (likely the NS350) beneath the KH-50000, where the contacts are situated. This chip meets the security requirements of China's GM/T 0012-2020 cryptographic module standard and complies with the international TPM 2.0 (SPEC 1.59) standard.\n\nThe footprint of the KH-50000 measures 72 x 76 mm, which is considerably larger than that of the KH-40000. Notably, it shares dimensions with AMD's Genoa and Bergamo processors, which measure 72 x 75.4 mm and are compatible with the socket SP5. Therefore, the size of the KH-50000 is precisely the same as that of AMD's more recent EPYC chips.\n\nThe KH-50000 slots into a socket with a Land Grid Array (LGA) design, meaning the pins are located on the motherboard rather than on the processor. Zhaoxin's latest server chips are scalable, similar to AMD's EPYC and Intel's Xeon chips. The KH-50000 embraces 2S and 4S systems, where you can accumulate up to 384 cores on the latter. Zhaoxin built its own ZPI (Zhaoxin Processor Interconnect) 5.0 for inter-chip communication.\n\nContrary to AI GPUs, companies in China can still acquire server chips without significant difficulty, albeit potentially at increased costs. Nonetheless, Zhaoxin continues to make considerable progress in the domestic market, and with Chinese authorities firmly committed to utilizing domestically produced technology, the company could achieve success even if the KH-50000 does not rival AMD or Intel's latest server chips.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/chinas-96-core-cpu-taps-chiplet-design-to-rival-amds-epyc-up-to-384-cores-on-a-single-motherboard-but-no-word-yet-on-tdp",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Trump Has Created an ‘Unusual Bull Case’ for Intel Stock. Should You Buy INTC Now?",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/35138552/trump-has-created-an-unusual-bull-case-for-intel-stock-should-you-buy-intc-now",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Intel Linux Setbacks, Linux Kernel Drama & Other Q3 Highlights",
      "content": "So far on this last day of Q3'2025 we are at just over 800 original Linux news articles for the quarter on Linux hardware and open-source software. Here is a look back at what proved to be most popular for the quarter.There was a lot of interesting developments for the Linux kernel this quarter both of technical merit as well as Linux kernel mailing list (LKML) drama. The ongoing Intel layoffs/restructurings have also led to a number of unfortunate setbacks in their Linux/open-source support. Plus a wide array of other interesting Linux/FLOSS developments.Before getting to the Q3'2025 news highlight list (see yesterday's Q3 review / featured article highlights as well)... As one last reminder, if you enjoy all of the daily original content on Phoronix over the past 21 years, today is the last day of the Phoronix.com autumn deal to help with the site by enjoying a discounted rate on Phoronix Premium . Thank you for your support consideration amid these ongoing difficult times for the web/ad industry and rampant ad-block usage and other issues continuing to hamper operations.With that said, here's a look at the most popular Q3'2025 news on Phoronix:Linus Torvalds has grown frustrated enough with seeing \"Link: \" tags within Git commits/patches that often times they are of no value and he's had enough of it. For Linux kernel activity moving forward he's going to be more strict over \"useless\" link tags in Git commit messages.The most depressing news of the week: Intel is ending their performance-optimized Clear Linux distribution. Over the past decade the Clear Linux operating system has shown what's possible with out-of-the-box performance on x86_64 hardware... Not just for Intel platforms but even showing extremely great performance results on AMD x86_64 too. But with the cost-cutting going on at Intel, Clear Linux is now being sunset.Linus Torvalds has used his authority to reject the RISC-V architecture changes for the Linux 6.17 kernel. The RISC-V updates won't land this cycle and will need to try again for v6.18 later in the year. Linus refers to at least some of the proposed RISC-V code as garbage along with being submitted rather late during the merge window.XTX Markets as one of the largest algorithmic trading firms that handles $250 billion in daily traded volume and relies on around 650+ petabytes of storage for its price forecasts and other algorithmic trading data has open-sourced its Linux file-system. XTX developed TernFS for distributed storage after they outgrew their original NFS usage and other file-system alternatives.Amid the ongoing discussion over what will happen too Bcachefs in the mainline Linux kernel, an interesting anecdote around Btrfs was mentioned.Code was open-sourced this week and posted to the Linux kernel mailing list as a \"request for comments\" (RFC) for a multi-kernel architecture. This proposal could allow for multiple independent kernel instances to co-exist on a single physical machine. Each kernel could run on dedicated CPU Cores while sharing underlying hardware resources. This could also allow for some complex use-cases such as real-time (RT) kernels running on select CPU cores.Linus Torvalds has finally come to a decision following his plans to part ways with the Bcachefs file-system and then not merging any Bcachefs updates for Linux 6.17.The newest hardware offering from Raspberry Pi announced today is... a 1TB SSD.Developers behind the Git distributed revision control system are debating whether to make Rust programming language support mandatory.Well, it's an unpleasant afternoon in Linux land with more signs of the ongoing impact from Intel's corporate-wide restructuring. Just after writing about Intel's CPU temperature monitoring driver now left unmaintained/orphaned, more patches hit the public Linux kernel mailing list to mark additional Intel drivers as orphaned and removing maintainer entries for Linux developers no longer at Intel.Ubuntu 25.10's transition to using Rust Coreutils in place of GNU Coreutils has uncovered a few performance issues so far with the Rust version being slower than the C-based GNU Coreutils. Fortunately there still are a few weeks to go until Ubuntu 25.10 releases as stable and upstream developers are working to address these performance gaps.KDE Plasma 6.5 is introducing a change that has been \"years in the wanting\" and that is rounded bottom corners for windows.The Debian release team today shared their final release plans for Debian 13 \"Trixie\" that aims to be out as stable in less than one month's time.The upcoming FFmpeg 8.0 multimedia library release continues to get more exciting almost by the day. The newest feature being squeezed into this next release is a Whisper audio filter for making use of OpenAI's Whisper model for providing automatic speech recognition / transcription capabilities.Several years ago Google engineers began exploring address space isolation for the Linux kernel and ultimately proposing Linux ASI for better dealing with CPU speculative execution attacks. While the hope was it would better cope with the ever growing list of CPU speculative execution vulnerabilities, the effort was thwarted initially by I/O throughput seeing a 70% performance hit. That level of performance cost was unsustainable. But now that I/O overhead has been reduced to just 13%.Amid Intel's ongoing financial difficulties and multiple rounds of layoffs some Linux engineers at Intel left last year and there's been at least one prominent departure this week amid the latest round of challenges at the company.There is yet more apparent fallout from Intel's recent layoffs/restructurings as it impacts the Linux kernel... The coretemp driver that provides CPU core temperature monitoring support for all Intel processors going back many years is now set to an orphaned state with the former driver maintainer no longer at Intel and no one immediately available to serve as its new maintainer.Josef Bacik who is a long-time Btrfs developer and active co-maintainer alongside David Sterba is leaving Meta. Additionally, he's also stepping back from Linux kernel development as his primary job.Just over one year after the Amarok 3.0 release after a six year hiatus that brought it to Qt5 and KDE Frameworks 5, Amarok 3.3 is out today as the first version taking it to Qt6 and KDE Frameworks 6.The latest round of cost-cutting at Intel seems to be having a larger impact on their software engineering efforts than some of their previous rounds of layoffs. In addition to a prominent Linux kernel developer veteran leaving Intel last week where he worked for the past 14 years and responsible for many great upstream improvements, other Intel software engineers working on their Linux/open-source affairs have also been departing. In just the latest instance, one of the upstream Intel Linux kernel drivers is now \"orphaned\" due to the developer departing and no one experienced left to maintain the code.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Q3-2025-Linux-News",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "We tested Hisense's latest flagship QLED TV, and it offers unrivaled brightness at a pretty unbeatable value",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nHisense continues to step up its game with the release of the U8QG, its latest flagship QLED 4K TV. The display boasts one of the brightest pictures on the market while costing less than dimmer models from brands like Samsung and Sony.\n\nBut Hisense didn't stop at just making a bright TV. The U8QG also boasts excellent backlight control, which produces impressive black levels for a TV of this type, along with sparkling specular highlights.\n\nIts color performance is better than last year's U8N, too, but there are some inaccuracies here and there. And though the TV's gaming capabilities are stacked with features like a 165Hz refresh rate, it's a bit disappointing that there are only three HDMI ports. Likewise, the U8QG has some tough competition from the TCL QM8K, which offers similar performance.\n\nChoosing between the Hisense U8QG and the TCL QM8K is challenging, as both have their strengths and weaknesses. However, the Hisense U8QG is often on sale for less, and the incredible brightness it achieves is hard to ignore. This is easily one of the best-performing QLED 4K TVs of the year.\n\nHisense 65-inch U8QG QLED 4K TV The Hisense U8QG impresses with one of the brightest pictures on the market, and pairs that searing luminance with excellent contrast for a dynamic, punchy picture. Check price at Amazon Check price at Walmart Check price at Best Buy What we like Check mark icon A check mark. It indicates a confirmation of your intended interaction. Blazingly bright\n\nCheck mark icon A check mark. It indicates a confirmation of your intended interaction. Excellent contrast for a QLED\n\nCheck mark icon A check mark. It indicates a confirmation of your intended interaction. Includes great gaming features What we don’t like con icon Two crossed lines that form an 'X'. Some color inaccuracies in reds\n\ncon icon Two crossed lines that form an 'X'. Only three HDMI ports\n\ncon icon Two crossed lines that form an 'X'. USB-C DisplayPort doesn’t support HDR or VRR Specifics Resolution: 4K Ultra HD (3840 x 2160)\n\n4K Ultra HD (3840 x 2160) Panel type: QLED, 165Hz with PC\n\nQLED, 165Hz with PC Backlight: Mini LED with local dimming\n\nMini LED with local dimming HDR formats: HDR10, HDR10+, Dolby Vision, HLG\n\nHDR10, HDR10+, Dolby Vision, HLG Smart TV OS: Google TV\n\nGoogle TV HDMI ports: Three HDMI 2.1\n\nThe U8QG has a solid design, but its connection options are a mixed bag\n\nThe U8QG comes with a sturdy pedestal stand. John Higgins/Business Insider\n\nThe Hisense U8QG is available in five sizes: 55, 65, 75, 85, and 100 inches. Hisense provided a 65-inch model for this review. According to reports, the 65- and 85-inch models use a VA panel, while the other three sizes use an ADS Pro panel. VA panels tend to have better contrast, while ADS panels have better viewing angles. This means that the 55-, 75-, and 100-inch models likely offer worse black-level performance than the 65- and 85-inch editions. All sizes have a native 165Hz panel and use the new Hisense Hi-View AI Engine Pro processor.\n\nThe TV comes with a pedestal stand featuring a metal base (the 100-inch size includes left and right feet instead). It supports the TV well and can be attached in two positions, with the higher one offering a little over three inches of clearance to place a soundbar in front. A back panel on the stand covers a cable management channel to keep cords nice and tidy.\n\nIn comparison to other TVs released this year, the U8QG looks rather chunky. The panel measures 1.75 inches thick, and while that is technically less than the thickest point of its predecessor, the previous model got thinner in certain areas. There isn't a central electronics housing that protrudes, so the U8QG's thickness is uniform.\n\nThis chunkier build does allow room for an integrated 4.1.2 sound system, featuring side-firing and up-firing speakers. Although beefier than most tiny TV speakers, the sound still lacks oomph (particularly in the bass), and dialogue clarity suffers as the volume increases. I still recommend pairing the TV with a soundbar for an improved sonic experience.\n\nThe TV has three HDMI ports, instead of the typical four found on most displays in this class. John Higgins/Business Insider\n\nAlso housed on the side of the panel is a USB-C DisplayPort input, a unique inclusion not commonly found on many TVs. This connection is designed for PCs and, at first glance, appears to be geared toward gamers. However, this input doesn't support HDR or VRR (variable refresh rate). I also don't love its position, since a connected cable will be visible protruding from the side of the TV. Not a slick look. For a cleaner appearance and expanded gaming capabilities, the TV's three HDMI 2.1 inputs, located on the back of the panel, remain your best option.\n\nYou'll notice I said three HDMI ports instead of the four found on most TVs in this class. Unfortunately, it seems that including the USB-C input resulted in the removal of one of the HDMI ports. While having three HDMI 2.1 ports with 165Hz VRR is nice, it still limits the maximum number of sources that can be connected to the U8QG.\n\nIf you're using a soundbar connected to the eARC port and have three other sources to connect — perhaps an Xbox, PlayStation, and Apple TV — then you'll have to choose your favorites or play musical inputs when you want to use whichever source is left out. Admittedly, this won't affect the majority of people, but for those it will, it's important to note.\n\nThe remote is the same one Hisense introduced last year. It has a long, silver metallic design with backlit keys. It includes direct buttons for input selection and settings, a feature not offered by every manufacturer, and fits relatively well in the hand (those with smaller hands will need to slide it around in their palm to easily reach all the buttons).\n\nThe U8QG is incredibly bright, but it has some color issues\n\nThe U8QG's QLED panel and Mini LED backlight enable high brightness, creating a vibrant and bold image. John Higgins/Business Insider\n\nHisense is known for underselling its TVs' brightness performance. For years, it's basically been a guarantee that its TVs would measure at least a few hundred nits higher than advertised. But with such a strong push across the industry to increase brightness, I wondered how long its TVs would be able to keep overperforming on their promises. Well, they haven't stopped yet.\n\nAccording to its specifications, the U8QG has a brightness of up to 5,000 nits across all sizes, except for the 55-inch model, which tops out at 3,000 nits. In my measurements — using a Portrait Displays C6 HDR5000, Murideo Seven-G 8K pattern generator, and Calman calibration software — the TV blasted past that number. In HDR Filmmaker mode, it achieved 5,759 nits from a 5% window. Even a 10% window was impressively bright, with a reading of 4,094 nits.\n\nThose are the brightest measurements I've seen on those windows from any TV this year. In comparison, the TCL QM8K, another exceptionally bright TV, came in at 4,999 nits from a 5% window and 3,648 nits from a 10% window. With the default Filmmaker setting in SDR (which has brightness at 45), the U8QG measured 1,512 nits on a 10% window. Increasing the brightness to 100 results in a measurement of 3,297 nits.\n\nWith such a bright image, ambient light is of no consequence. Even if you have large windows in your living room, as I do, the image easily holds up to the sunlight. To a certain extent, the TV is even able to handle reflective light from lamps, as I found it to be less distracting on the U8QG than on other TVs with glossy panels.\n\nThe TV's luminance can be a bit overwhelming in certain settings, but you can adjust it to your preference. John Higgins/Business Insider\n\nThe question is, how much brightness do you actually need? It's true that there are some HDR movies on 4K Blu-ray and streaming that are mastered for 4,000 nits or more — \"The Meg\" and \"Alpha\" are two that us reviewers have been using for a few years to check high-brightness performance. For those kinds of movies, the U8QG's brightness is a boon.\n\nIn \"Alpha,\" one of the final scenes includes a vista with a blazing sun. On lesser TVs, the sun lacks definition, and its yellow blends into the oranges of the evening sky. But on the Hisense U8QG, you can clearly see the circular shape of the sun as it illuminates the sky with rich yellows and oranges.\n\nIn a dark room, however, those bright moments can feel a bit oppressive, and some might prefer to dial down the TV's luminance. Thankfully, the Hisense U8QG affords you the possibility. Although the TV can surpass 5,000 nits, you can also adjust settings to reduce the brightness to a level that's comfortable for you. If you find the luminance too much, I suggest changing the TV's Peak Brightness mode to medium or low.\n\nIn addition to the high brightness, the U8QG has excellent black levels when its local dimming mode is set to high. Blooming (halos around bright objects) is well controlled by the dimming zones, which keep dark sections of the screen inky black while coming close to rivaling the performance of an OLED. The U8QG's blooming performance doesn't quite match that of the TCL QM8K, particularly when viewing subtitles or credits on a dark screen, but in other situations, the difference is negligible.\n\nThat said, the TV does have a tendency to crush black levels in some scenes. \"Blade Runner 2049\" frequently utilizes shadow detail to establish its tone. The walls and corners of Sapper Morton's small home are enshrouded in shadow, but they should still have some definition — the wall by the piano and the corner of the kitchen counter, in particular. On the U8QG, the home appears appropriately dark, but there's some detail missing in the shadows.\n\nA dedicated gaming bar is available for quick adjustments, and the TV features a high 165Hz refresh rate for PCs. John Higgins/Business Insider\n\nThe U8QG's color performance is vibrant with decent accuracy, and the QLED panel covers nearly all of the P3 color gamut. However, there are some issues with oversaturation, particularly in reds. The explosions in \"Mad Max: Fury Road\" appear spectacularly bright and vibrant, but the reds are a bit too intense, causing them to look slightly artificial. The yellow and orange tones of the desert scenes are less affected by the oversaturated reds, and skin tones appear natural without the sunburned look that oversaturation can sometimes cause. But as the TV's grayscale gets closer to white, it leans toward a red tint.\n\nThe U8QG offers a range of gaming features, including AMD FreeSync Premium Pro VRR with a refresh rate of up to 165Hz for PCs and 120Hz for consoles, low input lag, Dolby Vision gaming support, and good motion handling. I noticed some minor smearing while using VRR, but it was nothing excessive that distracted me. My time gaming on the U8QG was enjoyable.\n\nQLED TVs, such as the U8QG, often struggle with viewing angles, particularly those with VA panels, like my review sample. The U8QG does indeed start to lose color vibrancy and veer toward a slightly washed-out appearance when viewed at an angle of approximately 30 degrees. That's similar to the performance I saw on the TCL QM8K. A family sitting on the couch for a movie night won't notice much of a difference, but if a large group is over watching the game, those on the sides will see the loss in quality.\n\nIt's also important to reiterate that my experience with the 65-inch model may not be representative of other sizes, as the U8 series uses different panel types for certain sizes. Sizes with an ADS panel will likely perform better off-angle at the expense of overall contrast.\n\nGoogle TV OS continues to be a great interface\n\nThe Google TV OS is one of our favorites, thanks to its straightforward layout and seamless integration with Google accounts. John Higgins/Business Insider\n\nThe U8QG utilizes the Google TV OS, which works great, offering smooth operation and easy integration with an existing Google account. There are, of course, ads within the Google interface, but they're not too obtrusive, and navigation is fast.\n\nThe Google Store offers thousands of apps for download, including ones you'd expect, such as HBO Max, Disney Plus, and Prime Video, as well as more niche options that aren't available on all built-in streaming OS platforms. F1 fans will be able to follow the season with F1 TV, and comedy fans can revel in the world of Dropout.\n\nGoogle Assistant voice control is supported with the included remote or through hands-free commands via the TV's built-in microphones. Later this year, the U8QG is also set to receive an update to enable support for Gemini, Google's AI chatbot. Compared to Google Assistant, Gemini offers more conversational search functions and provides more extensive information across a wider range of topics.\n\nShould you buy the Hisense U8QG?\n\nThe Hisense U8QG has a few drawbacks, but it's a great fit for buyers who crave a high-brightness TV. John Higgins/Business Insider\n\nThe Hisense U8QG is as good or better than its predecessor, the U8N, in every way. It's brighter, has better HDR color accuracy, excellent contrast — especially for a Mini LED display — and has strong gaming support. Its impressive performance for the price puts it in the mix as one of the top 4K QLED TVs of the year.\n\nBut not everything about the U8QG is perfect. There are some issues with oversaturated color that can make things look off, and the grayscale tracks a bit warm. The decision to replace one of the HDMI inputs with a USB-C DisplayPort is only beneficial to a select few, and the input's placement on the edge of the TV's frame detracts from a sleek, clean installation.\n\nThe U8QG's main competitor is the TCL QM8K, another fantastic, and (not quite as) bright flagship QLED 4K TV. The QM8K has slightly better color and grayscale accuracy, and thanks to TCL's Halo Control System, it's even better at reducing blooming than the Hisense. The QM8K also has four HDMI inputs, but only two of them are version 2.1. You can learn more in our TCL QM8K QLED 4K TV review.\n\nHowever, the Hisense is often discounted for less than the QM8K, and it's available in an additional 55-inch size. If prices were all equal, I'd lean toward the TCL, but if you want to save a bit of money, the Hisense U8QG offers a slightly brighter picture while still maintaining a colorful and punchy image.\n\nFor more display recommendations, be sure to check out our complete guide to the best TVs.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/guides/tech/hisense-u8qg-4k-tv-review",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Can't upgrade your Windows 10 PC? You have 2 weeks to act - and 5 options",
      "content": "DimaSobko/iStock/Getty Images Plus\n\nFollow ZDNET: Add us as a preferred source on Google.\n\nZDNET's key takeaways\n\nWindows 10 support ends on Oct. 14, 2025.\n\nYou have free and paid options for extended updates.\n\nDoing nothing is not a safe option.\n\nHave you decided what to do with your old Windows 10 PCs when they reach their official end-of-support date in two weeks?\n\nThe official deadline is October 14, 2025. Microsoft is not going to back down at the last minute and offer an extension. The hardware requirements aren't going to change, either. So, if you have a laptop or desktop PC that doesn't pass the compatibility checks, Microsoft will block you from upgrading through Windows Update, and they will encourage you to buy a new PC instead.\n\nBut you have other alternatives, including some new ways to continue getting security updates for an extra year at no cost. Don't procrastinate, though -- if you're responsible for one or more Windows 10 PCs that fail Microsoft's Windows 11 compatibility tests, you need to choose one of these five options soon.\n\nAlso: How to get free Windows 10 security updates through Oct. 2026\n\nEven if you and your business aren't affected by this deadline, it's likely that you have friends and family members who own older PCs that are still perfectly functional but can't be upgraded to Windows 11. They've probably been ignoring warning messages for a few months now, but those messages are going to get more insistent as the deadline approaches. You can help them out by sending them a link to this article.\n\n1. Sign up for extended security updates\n\nMicrosoft will continue developing security updates for Windows 10, but they won't be free for everyone. Extended Security Updates (ESUs) for Windows 10 will be available on a subscription basis for up to three years.\n\nAlso: Consumer Reports calls Microsoft 'hypocritical' for stranding millions of Windows 10 PCs\n\nHow much are these paid-for updates going to cost? That depends.\n\nConsumers have the option to receive security updates for one additional year after the end-of-support date, with the deadline pushing out to October 2026. The list price for that subscription is $30 a year, but you can cut the cost to zero by using Microsoft Rewards points earned by using the Bing search engine or the Windows Backup tool. (For details, see How to get Windows 10 extended security updates for free.) That's the obvious choice if you simply want to postpone the decision. Just be aware that the consumer ESU subscription is only good for one year. At the end of that year, you'll have an unsupported PC once again, so make sure you use that time to figure out your exit strategy for October 2026.\n\nAlso: I replaced my Microsoft account password with a passkey - and you should, too\n\nIf you're an administrator at an educational institution with a deployment of Windows 10 Education edition, you're in luck. You can purchase extended updates for up to three years, and the cost will bea mere pittance: $1 per machine for the first year, $2 for the second year, and $4 for the third and final year, taking you all the way to October 2028.\n\nIT pros who manage a fleet of business PCs aren't so lucky and will need to pay dearly to stick with Windows 10. A license for the Extended Security Updates program is sold as a per-device subscription. For the first year, the cost is $61 per PC. For year two, the price doubles, and it doubles again for year three. Do the math, and the cost is staggering: a three-year ESU subscription will cost $61 + $122 + $244, for a total of $427.\n\n2. Buy a new PC (or rent a virtual PC)\n\nMicrosoft and its partners would like you to replace that unsupported hardware with a new PC. You might even be tempted by one of the shiny new Copilot+ PCs, with their dedicated neural processing units, or maybe a powerful gaming PC. But throwing away a perfectly good computer seems wasteful, and it's not an option if you're hanging on to Windows 10 because you have mission-critical software or an expensive hardware device that's incompatible with Windows 11.\n\nAlso: I never pay full price for PCs or Macs, thanks to these 7 money-saving tricks\n\nYou also have the option to rent a new virtual PC by signing up for Windows 365, which allows you to connect remotely to your own Windows 11-powered virtual PC in Microsoft's cloud. A Windows 365 subscription works on Windows 10 and includes extended security updates for the host PC for up to three years. Windows 365 isn't cheap (plans start at $28 a month), but that option probably costs less than a new PC.\n\nFor businesses, replacing a PC that is more than six years old is absolutely the correct option. Ask your CPA about depreciation deductions.\n\n3. Upgrade your 'incompatible' hardware to Windows 11\n\nThat pesky compatibility checker might insist that you can't upgrade your Windows 10 PC to Windows 11, but there are indeed documented ways to bypass those restrictions. You just have to jump through a few technical hoops. Frankly, if you have a PC that is less than 10 years old, this is the easiest, cheapest, and most reliable option.\n\nAlso: The 10 apps I can't live or work without - on Windows, Mac, and mobile\n\nYou can find all the details in this article: How to upgrade your 'incompatible' Windows 10 PC to Windows 11. Here's the short version:\n\nFor PCs originally designed for Windows 10 (basically anything designed in 2016 or later), you need to make one small registry edit and then ensure that your PC is configured to use Secure Boot with the Trusted Platform Module (TPM) enabled. Even an old TPM 1.2 chip will do. As many readers have confirmed via email, this process works seamlessly as long as you've got those configuration details set properly. This option will work even with PCs that are 10 years old.\n\nFor older PCs originally designed for Windows 7 or Windows 8.1, you might need to use a third-party tool called Rufus to bypass installation challenges. That's especially true on PCs that use a legacy BIOS instead of UEFI firmware and for those that don't have access to a TPM. Make sure you have the most recent version of Rufus (version 4.9 or later) to keep up with Microsoft's latest compatibility checks.\n\nThose upgrade options can't save a device whose CPU lacks support for two specific instruction sets -- POPCNT and SSE 4.2. Most PCs built using Intel CPUs from 2009 or later will pass this test; AMD CPUs from 2015 or later should also be OK. As I note in this article, there is no workaround if you own one of those very old PCs that fail this test.\n\nAlso: How to upgrade from Windows 11 Home to Pro - without overpaying\n\nIf you do use one of these upgrade hacks, don't be alarmed by the threatening message you might see when trying to do an unsupported upgrade: \"If you proceed with installing Windows 11, your PC will no longer be supported and won't be entitled to receive updates. Damages to your PC due to lack of compatibility aren't covered under the manufacturer warranty.\"\n\nThat's deliberately misleading language from Microsoft. As I've noted before, that warning doesn't really say that Microsoft is going to cut off your access to updates; it simply says your PC is no longer supported, and you're no longer \"entitled\" to those updates. That bit of legalese is a tell on Microsoft's part, disclaiming corporate responsibility without actually saying what it will do.\n\nIf you don't want to mess with the registry and you're willing to do a clean install on a system that has a TPM but fails the CPU check, just use Rufus to create a bootable Windows 11 installation drive, which bypasses the compatibility checker completely. You'll need to restore your data files from a backup or from the cloud, and you'll also need to install your software from scratch, but that's no more difficult than setting up a new PC.\n\n4. Ditch Windows completely\n\nYou could keep your old hardware and replace Windows 10 with the flavor of Linux you prefer. If you've got the technical know-how and experience to manage the transition, that option is worth considering. Thanks to Google Workspace, Microsoft 365, and a million or so web-based services, you can do just about all your basic work in a web browser these days. You might not even notice what operating system is running that browser.\n\nAlso: Yes, you can run Windows apps on Linux - here are my top 5 ways\n\nSwitching to Google's free ChromeOS Flex might also be possible, although the compatibility requirements for that alternative are just as likely to get in your way. I wrote about my experience here: Installing ChromeOS Flex? 5 things you need to do first to avoid headaches. As I pointed out, \"If you've got an old PC or Mac and you're thinking of installing ChromeOS Flex on it, don't do anything until you check Google's official ChromeOS Flex certified models list.\"\n\nPay special attention to the end-of-support date for the PC you're thinking of upgrading. It doesn't make much sense to replace Windows 10 with a release of ChromeOS Flex that's also set to end support in the next year.\n\nAlso: 7 most Windows-like Linux distros - if you're ready to ditch Microsoft\n\nSwitching to Linux or some derivative of Linux might be a good way to repurpose an old PC. For consumers and businesses with existing investments in Windows software, it might not be a realistic alternative, but it's worth considering.\n\n5. Ignore the end-of-support deadline completely\n\nYou could do nothing at all -- just continue running your unsupported operating system and hope for the best. That's a bad idea that exposes you to the very real possibility that you'll fall prey to a security exploit. Unfortunately, a lot of people are going to do just that. Some percentage of them will end up regretting their decision.\n\nI've heard from some folks who believe that being extra careful and using third-party antivirus software will protect them from harm. I wouldn't bet my business on that strategy.\n\nAlso: Stop paying for antivirus software. Here's why you don't need it\n\nIf you're intent on doing so, consider installing the third-party 0patch agent to deal with any security issues that aren't addressed by Microsoft. The free 0patch personal plan includes patches for known 0-day vulnerabilities, but if you want all Windows 10 patches, or if the PC is used for business or enterprise tasks, you'll need to pay for a 0patch Pro plan at a per-PC rate of €24.95 per year -- for customers in the US, at current exchange rates, that equates to less than $2.50 a month.\n\nI wouldn't recommend that for a PC that you use for business, but if you have a device you use for casual tasks at home, you might be willing to take the risk.\n\nWhat does 'end of support' mean?\n\nFor nearly a quarter-century, Microsoft has had a formal policy of supporting each major operating system release for 10 years. Windows 10 was released in 2015, so its 10 years are up, as expected, in 2025.\n\nThe end date is right there on the Microsoft Support document that lists products retiring or reaching the end of support in 2025. Every retail edition of Windows, as well as the Enterprise and Education editions, is slated for retirement.\n\nIf you have a Windows 10 PC, it faces mandatory retirement in 2025 Screenshot by Ed Bott/ZDNET\n\nThat schedule is defined by Microsoft's Modern Lifecycle Policy, which is documented on the Microsoft Lifecycle page: \"Windows 10 will reach end of support on Oct. 14, 2025. The current version, 22H2, will be the final version of Windows 10, and all editions will remain in support with monthly security update releases through that date.\" In a separate support article, Microsoft reiterates that as of Oct. 14, 2025, it will no longer provide technical support or security and reliability fixes for PCs running Windows 10.\n\nAlso: How to upgrade your 'incompatible' Windows 10 PC to Windows 11 - for free\n\nWhen a Windows version reaches its end-of-support date, the software keeps working, but Windows Update stops delivering security and reliability fixes:\n\n[There] will be no new security updates, non-security updates, or assisted support. Customers are encouraged to migrate to the latest version of the product or service. Paid programs may be available for applicable products.\n\nThat part in the middle sounds encouraging, doesn't it? \"Customers are encouraged to migrate to the latest version of the product or service.\" Unfortunately, that's not a supported option for customers running Windows 10 on hardware that doesn't meet the stringent hardware compatibility requirements of Windows 11. If you try to upgrade one of those PCs to Windows 11, you'll encounter an error message.\n\nAnd then you'll have to choose one of the five options above.",
      "source": "ZDNet",
      "url": "https://www.zdnet.com/article/cant-upgrade-your-windows-10-pc-you-have-2-weeks-to-act-and-5-options/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Nvidia: The story behind the world’s most valuable company - Generate Wealth Weekly",
      "content": "At the heart of Nvidia’s success is its co-founder and CEO, Jensen Huang. Born in Taiwan and raised in the United States, Huang washed dishes and cleaned bathrooms at Denny’s as a teenager, eventually earning a master’s degree in electrical engineering from Stanford.\n\nUnder his guidance, Nvidia has transformed from a graphics company into a global leader in parallel computing and AI. When most saw the GPU as a tool with limited applications, Huang continued to invest huge amounts into R&D while many analysts and investors queried whether or not there would ever be an acceptable return on investment.\n\nNvidia’s leadership was propelled even further through the release of CUDA (Compute Unified Device Architecture) – a programming platform that helps users write software algorithms on top of Nvidia’s GPUs. Launched in 2006, CUDA opened the GPU’s raw computing power to researchers and developers beyond the world of graphics. Suddenly, scientists in fields ranging from genomics to astrophysics could run complex simulations hundreds of times faster than before. But the true inflection point came when AI researchers discovered that Nvidia GPUs could dramatically improve the process of training deep neural networks, enabling breakthroughs in computer vision, natural language processing, and autonomous systems.\n\nToday, Nvidia is the undisputed king of AI hardware. Its GPUs power everything from data centres and high-performance computers to self-driving cars and personal devices. The company’s hardware is the engine behind OpenAI’s Chat GPT models, Google’s vast AI infrastructure, and the world’s most advanced robotics. In addition, Nvidia’s software has become the dominant platform for AI development.\n\nBecause of the market’s insatiable demand for its GPUs the company has seen its market capitalisation soar, recently surpassing the US$4 trillion-dollar mark and becoming the most valuable company in the world. This rise in value has been staggering as it only surpassed the US$1 trillion mark in May of 2023, equating to a 4x increase in value in a little over two years.\n\nIn the process Nvidia has made thousands of its employees millionaires – a recent survey found that a third of Nvidia’s staff have a net wealth in excess of US$20 million. This is easy to understand when you consider that only 10 years ago Nvidia’s shares were trading at less than US$0.60 per share versus the current price of US$175.\n\nBut Nvidia’s rise is not unchallenged. Competition is fierce, with rivals like AMD and Broadcom racing to catch up. And as AI becomes more powerful, there are ethical dilemmas about privacy, job displacement, and the potential misuse of autonomous systems.\n\nIn an age when AI is everywhere, Nvidia is the company quietly making it all possible. From its humble origins as a graphics chip startup, it’s become the backbone of the world’s AI revolution.\n\nGenerate is a New Zealand-owned KiwiSaver and Managed Fund provider managing over $8 billion on behalf of more than 175,000 New Zealanders.\n\nThis article is intended for general information only and should not be considered financial advice. The views expressed are those of the author. All investments carry risk, and past performance is not indicative of future results.\n\nTo see Generate’s Financial Advice Provider Disclosure Statement or Product Disclosure Statement, go to www.generatewealth.co.nz/advertising-disclosures/. The issuer is Generate Investment Management Limited. Past performance is not indicative of future performance.\n\nSign up to Herald Premium Editor’s Picks, delivered straight to your inbox every Friday. Editor-in-Chief Murray Kirkness picks the week’s best features, interviews and investigations. Sign up for Herald Premium here.",
      "source": "New Zealand Herald",
      "url": "https://www.nzherald.co.nz/business/personal-finance/investment/nvidia-the-story-behind-the-worlds-most-valuable-company-generate-wealth-weekly/P4YKZCFDJFDLHERP7UAPHPPIPM/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "China's Zhaoxin breaks into healthcare: 6,000+ hospital PCs run x86 chips against Intel, AMD",
      "content": "China's Zhaoxin breaks into healthcare: 6,000+ hospital PCs run x86 chips against Intel, AMD\n\nShanghai Zhaoxin Semiconductor has scored a breakthrough in China's healthcare sector. On September 23, the x86 chipmaker announced that over 6,000 of its processor-powered desktops won a major hospital procurement bid, an important step for Chinese x86 CPUs in mission-critical medical deployments.\n\nChina's healthcare system is in the midst of rapid digital transformation, with ambitious goals to modernize core hospital information systems by 2025. The transition requires computing platforms that are both powerful and easy to deploy, critical traits in an industry long burdened by fragmented IT ecosystems.\n\nChina's healthcare IT fragmentation\n\nFragmentation remains one of healthcare IT's biggest challenges. Core systems such as hospital information systems (HIS), laboratory information systems (LIS), and picture archiving and communication systems (PACS) still depend on foreign databases like Oracle and SQL Server, which command over 80% market share. Domestic databases account for less than 15%, and migrating decades of records is complicated by format incompatibility and strict real-time demands.\n\nAt one leading provincial hospital, 40% of legacy HIS systems still run on outdated VB6 architecture, with upgrades costing up to CNY800,000 (approx. US$112,500) per system. Provinces are now piloting phased adaptation, rushing \"emergency fixes\" for critical platforms like PACS, while allowing a three-year transition for non-core systems such as office software. The dual-track approach underscores the clash between policy mandates and technical realities.\n\nSmaller hospitals face even sharper challenges: nearly 30% of their systems are too old to run domestic operating systems or new applications, leaving them stuck between costly legacy reuse and risky data migration.\n\nZhaoxin's processor ecosystem strategy\n\nZhaoxin is tackling these pain points with processors that combine compatibility and performance. The firm has independently developed six generations of high-performance CPUs, including the KaiXian desktop and KaiSheng server lines, with products spanning AI PCs, desktops, notebooks, all-in-ones, servers, and embedded platforms.\n\nThe chips support both domestic operating systems: UnionTech Software UOS, NeoKylin, Zhongkefangde Software, and Microsoft Windows. They are compatible with mainstream applications, cloud platforms, databases, development tools, and AI models, while keeping software migration costs low.\n\nFor healthcare, Zhaoxin has introduced \"seamless migration\" and \"one-stop support\" solutions. It has also set up medical application innovation centers with partners, offering hospitals end-to-end guidance from chips to operating systems and applications.\n\nToday, Zhaoxin works with nearly 4,000 partners across systems integration, software, and hardware. Together with domestic OS vendors, it has completed more than 200,000 software-hardware adaptation projects, building a full-stack ecosystem from processors to databases and applications.\n\nFrom 2022 to 2024, Zhaoxin recorded revenues of CNY340 million, CNY555 million, and CNY889 million, respectively, with a compound annual growth rate of 61.71%.\n\nRivaling Intel and AMD in hospitals\n\nBeating out Intel and AMD in a high-profile bid highlights Zhaoxin's progress in performance, compatibility, and cost efficiency. Its processors are built to handle demanding healthcare workloads — from electronic medical records to telemedicine platforms — while maintaining stable operations.\n\nWith integrated security, Zhaoxin CPUs protect patient data across its lifecycle: collection, transmission, storage, and use. This meets China's strict compliance standards, as hospitals lean on secure, high-performance platforms for data-heavy applications.\n\nAs digitalization accelerates, medical data will expand from text records and lab reports to imaging archives and real-time vital signs. Zhaoxin's processors can manage these workloads, minimizing downtime and enabling use cases such as AI diagnostics and cross-regional data sharing.\n\nChina's x86 chips gain traction\n\nThe hospital bid underscores the rising role of Chinese x86 chips in public welfare sectors. By offering strong performance and ecosystem compatibility, Zhaoxin is gaining ground in healthcare digitalization, an arena once dominated by foreign technology.\n\nIf sustained, these gains could speed the localization of hospital IT infrastructure, supporting China's drive for tech independence while laying the groundwork for smarter, more secure healthcare systems.\n\nArticle edited by Jack Wu",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250924VL209/x86-chips-smart-healthcare-shanghai.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Ambitious Wee Beastie Project Aims To Put Desktop NVIDIA RTX 4070 GPU Into 4.75 L Chassis",
      "content": "A rift appears to be forming in the desktop PC market, with full-size desktops on one side and mini PCs on the other side. Of course, there is small, but dedicated community that has sprung up around SFF PCs, but those are often limited, with many calling for flex PSUs and other compromises. The Wee Beastie, a new project on Kickstarter , is a small form-factor PC that hopes to cut back on the compromises, claiming to offer a powerful gaming and LLM-oriented system with an upgradeable dGPU in just 4.75 L volume—this is just 0.25 L more than the Framework Desktop PC , which uses an AMD Ryzen AI+ 395 Max with an iGPU. That said, even the pre-release Kickstarter marketing leaves some questions.The Wee Beastie Super Mini Fishtank, as it is called, is a mini PC with up to an Intel Core Ultra 7 255H CPU and NVIDIA GeForce RTX 4070 12 GB GPU. It will also be available with up to 128 GB of DDR5 RAM and a 16 TB SSD, and it boasts Wi-Fi 7 and room for up to 13 case fans. It will also contain an internal PSU capable of 400 W, which technically falls well below the 550 W we recommend for a desktop RTX 4070. Although the GPU shown on the Kickstarter page has the \" AD104-251-A1\" associated with the desktop variants of the RTX 4070 , the PSU output suggests that there will be some power throttling or down-tuning at play, so RTX 4070 Mobile performance might be what's to be expected here. Often, the most challenging part of projects like these, as was the case with the custom expansion modules on the Framework Laptop 16 until recently, is supporting the MXM standard for future hardware revisions. Although MXM modules are technically an open standard, like ATX, it is not commonly used due to limited demand and size constraints. Currently, the Kickstarter has completed funding, having reached $53,763 of its $2,570 goal, and the SFF PC looks to be going into production as soon as 2026.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341473/ambitious-wee-beastie-project-aims-to-put-desktop-nvidia-rtx-4070-gpu-into-4-75-l-chassis",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Merge tag 'x86_cache_for_v6.18_rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip",
      "content": "\n\nindex 6607dbb1be441f..bf1e6ca6aeb82f 100644\n\n--- a/\n\n+++ b/ diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txtindex 6607dbb1be441f..bf1e6ca6aeb82f 100644--- a/ Documentation/admin-guide/kernel-parameters.txt +++ b/ Documentation/admin-guide/kernel-parameters.txt @@ -6163,7 +6163,7 @@ rdt= [HW,X86,RDT] Turn on/off individual RDT features. List is: cmt, mbmtotal, mbmlocal, l3cat, l3cdp, l2cat, l2cdp, - mba, smba, bmec. + mba, smba, bmec, abmc. E.g. to turn on cmt and turn off mba use: rdt=cmt,!mba\n\nindex c7949dd44f2f3a..006d23af66e19f 100644\n\n--- a/\n\n+++ b/ diff --git a/Documentation/filesystems/resctrl.rst b/Documentation/filesystems/resctrl.rstindex c7949dd44f2f3a..006d23af66e19f 100644--- a/ Documentation/filesystems/resctrl.rst +++ b/ Documentation/filesystems/resctrl.rst @@ -26,6 +26,7 @@ MBM (Memory Bandwidth Monitoring) \"cqm_mbm_total\", \"cqm_mbm_local\" MBA (Memory Bandwidth Allocation) \"mba\" SMBA (Slow Memory Bandwidth Allocation) \"\" BMEC (Bandwidth Monitoring Event Configuration) \"\" +ABMC (Assignable Bandwidth Monitoring Counters) \"\" =============================================== ================================ Historically, new features were made visible by default in /proc/cpuinfo. This @@ -256,6 +257,144 @@ with the following files: # cat /sys/fs/resctrl/info/L3_MON/mbm_local_bytes_config 0=0x30;1=0x30;3=0x15;4=0x15 +\"mbm_assign_mode\": + The supported counter assignment modes. The enclosed brackets indicate which mode + is enabled. The MBM events associated with counters may reset when \"mbm_assign_mode\" + is changed. + :: + + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + [mbm_event] + default + + \"mbm_event\": + + mbm_event mode allows users to assign a hardware counter to an RMID, event + pair and monitor the bandwidth usage as long as it is assigned. The hardware + continues to track the assigned counter until it is explicitly unassigned by + the user. Each event within a resctrl group can be assigned independently. + + In this mode, a monitoring event can only accumulate data while it is backed + by a hardware counter. Use \"mbm_L3_assignments\" found in each CTRL_MON and MON + group to specify which of the events should have a counter assigned. The number + of counters available is described in the \"num_mbm_cntrs\" file. Changing the + mode may cause all counters on the resource to reset. + + Moving to mbm_event counter assignment mode requires users to assign the counters + to the events. Otherwise, the MBM event counters will return 'Unassigned' when read. + + The mode is beneficial for AMD platforms that support more CTRL_MON + and MON groups than available hardware counters. By default, this + feature is enabled on AMD platforms with the ABMC (Assignable Bandwidth + Monitoring Counters) capability, ensuring counters remain assigned even + when the corresponding RMID is not actively used by any processor. + + \"default\": + + In default mode, resctrl assumes there is a hardware counter for each + event within every CTRL_MON and MON group. On AMD platforms, it is + recommended to use the mbm_event mode, if supported, to prevent reset of MBM + events between reads resulting from hardware re-allocating counters. This can + result in misleading values or display \"Unavailable\" if no counter is assigned + to the event. + + * To enable \"mbm_event\" counter assignment mode: + :: + + # echo \"mbm_event\" > /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + + * To enable \"default\" monitoring mode: + :: + + # echo \"default\" > /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + +\"num_mbm_cntrs\": + The maximum number of counters (total of available and assigned counters) in + each domain when the system supports mbm_event mode. + + For example, on a system with maximum of 32 memory bandwidth monitoring + counters in each of its L3 domains: + :: + + # cat /sys/fs/resctrl/info/L3_MON/num_mbm_cntrs + 0=32;1=32 + +\"available_mbm_cntrs\": + The number of counters available for assignment in each domain when mbm_event + mode is enabled on the system. + + For example, on a system with 30 available [hardware] assignable counters + in each of its L3 domains: + :: + + # cat /sys/fs/resctrl/info/L3_MON/available_mbm_cntrs + 0=30;1=30 + +\"event_configs\": + Directory that exists when \"mbm_event\" counter assignment mode is supported. + Contains a sub-directory for each MBM event that can be assigned to a counter. + + Two MBM events are supported by default: mbm_local_bytes and mbm_total_bytes. + Each MBM event's sub-directory contains a file named \"event_filter\" that is + used to view and modify which memory transactions the MBM event is configured + with. The file is accessible only when \"mbm_event\" counter assignment mode is + enabled. + + List of memory transaction types supported: + + ========================== ======================================================== + Name Description + ========================== ======================================================== + dirty_victim_writes_all Dirty Victims from the QOS domain to all types of memory + remote_reads_slow_memory Reads to slow memory in the non-local NUMA domain + local_reads_slow_memory Reads to slow memory in the local NUMA domain + remote_non_temporal_writes Non-temporal writes to non-local NUMA domain + local_non_temporal_writes Non-temporal writes to local NUMA domain + remote_reads Reads to memory in the non-local NUMA domain + local_reads Reads to memory in the local NUMA domain + ========================== ======================================================== + + For example:: + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + local_reads,remote_reads,local_non_temporal_writes,remote_non_temporal_writes, + local_reads_slow_memory,remote_reads_slow_memory,dirty_victim_writes_all + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + local_reads,local_non_temporal_writes,local_reads_slow_memory + + Modify the event configuration by writing to the \"event_filter\" file within + the \"event_configs\" directory. The read/write \"event_filter\" file contains the + configuration of the event that reflects which memory transactions are counted by it. + + For example:: + + # echo \"local_reads, local_non_temporal_writes\" > + /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + local_reads,local_non_temporal_writes + +\"mbm_assign_on_mkdir\": + Exists when \"mbm_event\" counter assignment mode is supported. Accessible + only when \"mbm_event\" counter assignment mode is enabled. + + Determines if a counter will automatically be assigned to an RMID, MBM event + pair when its associated monitor group is created via mkdir. Enabled by default + on boot, also when switched from \"default\" mode to \"mbm_event\" counter assignment + mode. Users can disable this capability by writing to the interface. + + \"0\": + Auto assignment is disabled. + \"1\": + Auto assignment is enabled. + + Example:: + + # echo 0 > /sys/fs/resctrl/info/L3_MON/mbm_assign_on_mkdir + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_on_mkdir + 0 + \"max_threshold_occupancy\": Read/write file provides the largest value (in bytes) at which a previously used LLC_occupancy @@ -380,10 +519,77 @@ When monitoring is enabled all MON groups will also contain: for the L3 cache they occupy). These are named \"mon_sub_L3_YY\" where \"YY\" is the node number. + When the 'mbm_event' counter assignment mode is enabled, reading + an MBM event of a MON group returns 'Unassigned' if no hardware + counter is assigned to it. For CTRL_MON groups, 'Unassigned' is + returned if the MBM event does not have an assigned counter in the + CTRL_MON group nor in any of its associated MON groups. + \"mon_hw_id\": Available only with debug option. The identifier used by hardware for the monitor group. On x86 this is the RMID. +When monitoring is enabled all MON groups may also contain: + +\"mbm_L3_assignments\": + Exists when \"mbm_event\" counter assignment mode is supported and lists the + counter assignment states of the group. + + The assignment list is displayed in the following format: + + <Event>:<Domain ID>=<Assignment state>;<Domain ID>=<Assignment state> + + Event: A valid MBM event in the + /sys/fs/resctrl/info/L3_MON/event_configs directory. + + Domain ID: A valid domain ID. When writing, '*' applies the changes + to all the domains. + + Assignment states: + + _ : No counter assigned. + + e : Counter assigned exclusively. + + Example: + + To display the counter assignment states for the default group. + :: + + # cd /sys/fs/resctrl + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + + Assignments can be modified by writing to the interface. + + Examples: + + To unassign the counter associated with the mbm_total_bytes event on domain 0: + :: + + # echo \"mbm_total_bytes:0=_\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=_;1=e + mbm_local_bytes:0=e;1=e + + To unassign the counter associated with the mbm_total_bytes event on all the domains: + :: + + # echo \"mbm_total_bytes:*=_\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=_;1=_ + mbm_local_bytes:0=e;1=e + + To assign a counter associated with the mbm_total_bytes event on all domains in + exclusive mode: + :: + + # echo \"mbm_total_bytes:*=e\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + When the \"mba_MBps\" mount option is used all CTRL_MON groups will also contain: \"mba_MBps_event\": @@ -1429,6 +1635,125 @@ View the llc occupancy snapshot:: # cat /sys/fs/resctrl/p1/mon_data/mon_L3_00/llc_occupancy 11234000 + +Examples on working with mbm_assign_mode +======================================== + +a. Check if MBM counter assignment mode is supported. +:: + + # mount -t resctrl resctrl /sys/fs/resctrl/ + + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + [mbm_event] + default + +The \"mbm_event\" mode is detected and enabled. + +b. Check how many assignable counters are supported. +:: + + # cat /sys/fs/resctrl/info/L3_MON/num_mbm_cntrs + 0=32;1=32 + +c. Check how many assignable counters are available for assignment in each domain. +:: + + # cat /sys/fs/resctrl/info/L3_MON/available_mbm_cntrs + 0=30;1=30 + +d. To list the default group's assign states. +:: + + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + +e. To unassign the counter associated with the mbm_total_bytes event on domain 0. +:: + + # echo \"mbm_total_bytes:0=_\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=_;1=e + mbm_local_bytes:0=e;1=e + +f. To unassign the counter associated with the mbm_total_bytes event on all domains. +:: + + # echo \"mbm_total_bytes:*=_\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignment + mbm_total_bytes:0=_;1=_ + mbm_local_bytes:0=e;1=e + +g. To assign a counter associated with the mbm_total_bytes event on all domains in +exclusive mode. +:: + + # echo \"mbm_total_bytes:*=e\" > /sys/fs/resctrl/mbm_L3_assignments + # cat /sys/fs/resctrl/mbm_L3_assignments + mbm_total_bytes:0=e;1=e + mbm_local_bytes:0=e;1=e + +h. Read the events mbm_total_bytes and mbm_local_bytes of the default group. There is +no change in reading the events with the assignment. +:: + + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_total_bytes + 779247936 + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_total_bytes + 562324232 + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_local_bytes + 212122123 + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_local_bytes + 121212144 + +i. Check the event configurations. +:: + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_total_bytes/event_filter + local_reads,remote_reads,local_non_temporal_writes,remote_non_temporal_writes, + local_reads_slow_memory,remote_reads_slow_memory,dirty_victim_writes_all + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + local_reads,local_non_temporal_writes,local_reads_slow_memory + +j. Change the event configuration for mbm_local_bytes. +:: + + # echo \"local_reads, local_non_temporal_writes, local_reads_slow_memory, remote_reads\" > + /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + + # cat /sys/fs/resctrl/info/L3_MON/event_configs/mbm_local_bytes/event_filter + local_reads,local_non_temporal_writes,local_reads_slow_memory,remote_reads + +k. Now read the local events again. The first read may come back with \"Unavailable\" +status. The subsequent read of mbm_local_bytes will display the current value. +:: + + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_local_bytes + Unavailable + # cat /sys/fs/resctrl/mon_data/mon_L3_00/mbm_local_bytes + 2252323 + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_local_bytes + Unavailable + # cat /sys/fs/resctrl/mon_data/mon_L3_01/mbm_local_bytes + 1566565 + +l. Users have the option to go back to 'default' mbm_assign_mode if required. This can be +done using the following command. Note that switching the mbm_assign_mode may reset all +the MBM counters (and thus all MBM events) of all the resctrl groups. +:: + + # echo \"default\" > /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + # cat /sys/fs/resctrl/info/L3_MON/mbm_assign_mode + mbm_event + [default] + +m. Unmount the resctrl filesystem. +:: + + # umount /sys/fs/resctrl/ + Intel RDT Errata ================\n\nindex a80cca9aa6ff2b..62d16c20a888eb 100644\n\n--- a/\n\n+++ b/ diff --git a/MAINTAINERS b/MAINTAINERSindex a80cca9aa6ff2b..62d16c20a888eb 100644--- a/ MAINTAINERS +++ b/ MAINTAINERS @@ -21186,6 +21186,7 @@ M: Tony Luck <tony.luck@intel.com> M: Reinette Chatre <reinette.chatre@intel.com> R: Dave Martin <Dave.Martin@arm.com> R: James Morse <james.morse@arm.com> +R: Babu Moger <babu.moger@amd.com> L: linux-kernel@vger.kernel.org S: Supported F: Documentation/filesystems/resctrl.rst\n\nindex 751ca35386b0ef..b2a562217d3ffc 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/include/asm/cpufeatures.h b/arch/x86/include/asm/cpufeatures.hindex 751ca35386b0ef..b2a562217d3ffc 100644--- a/ arch/x86/include/asm/cpufeatures.h +++ b/ arch/x86/include/asm/cpufeatures.h @@ -496,6 +496,7 @@ #define X86_FEATURE_TSA_L1_NO (21*32+12) /* AMD CPU not vulnerable to TSA-L1 */ #define X86_FEATURE_CLEAR_CPU_BUF_VM (21*32+13) /* Clear CPU buffers using VERW before VMRUN */ #define X86_FEATURE_IBPB_EXIT_TO_USER (21*32+14) /* Use IBPB on exit-to-userspace, see VMSCAPE bug */ +#define X86_FEATURE_ABMC (21*32+15) /* Assignable Bandwidth Monitoring Counters */ /* * BUG word(s)\n\nindex b60d3711a7089e..73393a66d3ab05 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.hindex b60d3711a7089e..73393a66d3ab05 100644--- a/ arch/x86/include/asm/msr-index.h +++ b/ arch/x86/include/asm/msr-index.h @@ -1230,6 +1230,8 @@ /* - AMD: */ #define MSR_IA32_MBA_BW_BASE 0xc0000200 #define MSR_IA32_SMBA_BW_BASE 0xc0000280 +#define MSR_IA32_L3_QOS_ABMC_CFG 0xc00003fd +#define MSR_IA32_L3_QOS_EXT_CFG 0xc00003ff #define MSR_IA32_EVT_CFG_BASE 0xc0000400 /* AMD-V MSRs */\n\nindex feb93b50e990ac..575f8408a9e7c6 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/include/asm/resctrl.h b/arch/x86/include/asm/resctrl.hindex feb93b50e990ac..575f8408a9e7c6 100644--- a/ arch/x86/include/asm/resctrl.h +++ b/ arch/x86/include/asm/resctrl.h @@ -44,7 +44,6 @@ DECLARE_PER_CPU(struct resctrl_pqr_state, pqr_state); extern bool rdt_alloc_capable; extern bool rdt_mon_capable; -extern unsigned int rdt_mon_features; DECLARE_STATIC_KEY_FALSE(rdt_enable_key); DECLARE_STATIC_KEY_FALSE(rdt_alloc_enable_key); @@ -84,21 +83,6 @@ static inline void resctrl_arch_disable_mon(void) static_branch_dec_cpuslocked(&rdt_enable_key); } -static inline bool resctrl_arch_is_llc_occupancy_enabled(void) -{ - return (rdt_mon_features & (1 << QOS_L3_OCCUP_EVENT_ID)); -} - -static inline bool resctrl_arch_is_mbm_total_enabled(void) -{ - return (rdt_mon_features & (1 << QOS_L3_MBM_TOTAL_EVENT_ID)); -} - -static inline bool resctrl_arch_is_mbm_local_enabled(void) -{ - return (rdt_mon_features & (1 << QOS_L3_MBM_LOCAL_EVENT_ID)); -} - /* * __resctrl_sched_in() - Writes the task's CLOSid/RMID to IA32_PQR_MSR *\n\nindex 187d527ef73b6e..06ca5a30140c2f 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/kernel/cpu/resctrl/core.c b/arch/x86/kernel/cpu/resctrl/core.cindex 187d527ef73b6e..06ca5a30140c2f 100644--- a/ arch/x86/kernel/cpu/resctrl/core.c +++ b/ arch/x86/kernel/cpu/resctrl/core.c @@ -107,7 +107,7 @@ u32 resctrl_arch_system_num_rmid_idx(void) struct rdt_resource *r = &rdt_resources_all[RDT_RESOURCE_L3].r_resctrl; /* RMID are independent numbers for x86. num_rmid_idx == num_rmid */ - return r->num_rmid; + return r->mon.num_rmid; } struct rdt_resource *resctrl_arch_get_resource(enum resctrl_res_level l) @@ -365,8 +365,10 @@ static void ctrl_domain_free(struct rdt_hw_ctrl_domain *hw_dom) static void mon_domain_free(struct rdt_hw_mon_domain *hw_dom) { - kfree(hw_dom->arch_mbm_total); - kfree(hw_dom->arch_mbm_local); + int idx; + + for_each_mbm_idx(idx) + kfree(hw_dom->arch_mbm_states[idx]); kfree(hw_dom); } @@ -400,25 +402,27 @@ static int domain_setup_ctrlval(struct rdt_resource *r, struct rdt_ctrl_domain * */ static int arch_domain_mbm_alloc(u32 num_rmid, struct rdt_hw_mon_domain *hw_dom) { - size_t tsize; - - if (resctrl_arch_is_mbm_total_enabled()) { - tsize = sizeof(*hw_dom->arch_mbm_total); - hw_dom->arch_mbm_total = kcalloc(num_rmid, tsize, GFP_KERNEL); - if (!hw_dom->arch_mbm_total) - return -ENOMEM; - } - if (resctrl_arch_is_mbm_local_enabled()) { - tsize = sizeof(*hw_dom->arch_mbm_local); - hw_dom->arch_mbm_local = kcalloc(num_rmid, tsize, GFP_KERNEL); - if (!hw_dom->arch_mbm_local) { - kfree(hw_dom->arch_mbm_total); - hw_dom->arch_mbm_total = NULL; - return -ENOMEM; - } + size_t tsize = sizeof(*hw_dom->arch_mbm_states[0]); + enum resctrl_event_id eventid; + int idx; + + for_each_mbm_event_id(eventid) { + if (!resctrl_is_mon_event_enabled(eventid)) + continue; + idx = MBM_STATE_IDX(eventid); + hw_dom->arch_mbm_states[idx] = kcalloc(num_rmid, tsize, GFP_KERNEL); + if (!hw_dom->arch_mbm_states[idx]) + goto cleanup; } return 0; +cleanup: + for_each_mbm_idx(idx) { + kfree(hw_dom->arch_mbm_states[idx]); + hw_dom->arch_mbm_states[idx] = NULL; + } + + return -ENOMEM; } static int get_domain_id_from_scope(int cpu, enum resctrl_scope scope) @@ -516,6 +520,9 @@ static void domain_add_cpu_mon(int cpu, struct rdt_resource *r) d = container_of(hdr, struct rdt_mon_domain, hdr); cpumask_set_cpu(cpu, &d->hdr.cpu_mask); + /* Update the mbm_assign_mode state for the CPU if supported */ + if (r->mon.mbm_cntr_assignable) + resctrl_arch_mbm_cntr_assign_set_one(r); return; } @@ -535,9 +542,13 @@ static void domain_add_cpu_mon(int cpu, struct rdt_resource *r) d->ci_id = ci->id; cpumask_set_cpu(cpu, &d->hdr.cpu_mask); + /* Update the mbm_assign_mode state for the CPU if supported */ + if (r->mon.mbm_cntr_assignable) + resctrl_arch_mbm_cntr_assign_set_one(r); + arch_mon_domain_online(r, d); - if (arch_domain_mbm_alloc(r->num_rmid, hw_dom)) { + if (arch_domain_mbm_alloc(r->mon.num_rmid, hw_dom)) { mon_domain_free(hw_dom); return; } @@ -707,6 +718,7 @@ enum { RDT_FLAG_MBA, RDT_FLAG_SMBA, RDT_FLAG_BMEC, + RDT_FLAG_ABMC, }; #define RDT_OPT(idx, n, f) \\ @@ -732,6 +744,7 @@ static struct rdt_options rdt_options[] __ro_after_init = { RDT_OPT(RDT_FLAG_MBA, \"mba\", X86_FEATURE_MBA), RDT_OPT(RDT_FLAG_SMBA, \"smba\", X86_FEATURE_SMBA), RDT_OPT(RDT_FLAG_BMEC, \"bmec\", X86_FEATURE_BMEC), + RDT_OPT(RDT_FLAG_ABMC, \"abmc\", X86_FEATURE_ABMC), }; #define NUM_RDT_OPTIONS ARRAY_SIZE(rdt_options) @@ -863,15 +876,24 @@ static __init bool get_rdt_alloc_resources(void) static __init bool get_rdt_mon_resources(void) { struct rdt_resource *r = &rdt_resources_all[RDT_RESOURCE_L3].r_resctrl; + bool ret = false; - if (rdt_cpu_has(X86_FEATURE_CQM_OCCUP_LLC)) - rdt_mon_features |= (1 << QOS_L3_OCCUP_EVENT_ID); - if (rdt_cpu_has(X86_FEATURE_CQM_MBM_TOTAL)) - rdt_mon_features |= (1 << QOS_L3_MBM_TOTAL_EVENT_ID); - if (rdt_cpu_has(X86_FEATURE_CQM_MBM_LOCAL)) - rdt_mon_features |= (1 << QOS_L3_MBM_LOCAL_EVENT_ID); + if (rdt_cpu_has(X86_FEATURE_CQM_OCCUP_LLC)) { + resctrl_enable_mon_event(QOS_L3_OCCUP_EVENT_ID); + ret = true; + } + if (rdt_cpu_has(X86_FEATURE_CQM_MBM_TOTAL)) { + resctrl_enable_mon_event(QOS_L3_MBM_TOTAL_EVENT_ID); + ret = true; + } + if (rdt_cpu_has(X86_FEATURE_CQM_MBM_LOCAL)) { + resctrl_enable_mon_event(QOS_L3_MBM_LOCAL_EVENT_ID); + ret = true; + } + if (rdt_cpu_has(X86_FEATURE_ABMC)) + ret = true; - if (!rdt_mon_features) + if (!ret) return false; return !rdt_get_mon_l3_config(r); @@ -965,7 +987,7 @@ static enum cpuhp_state rdt_online; /* Runs once on the BSP during boot. */ void resctrl_cpu_detect(struct cpuinfo_x86 *c) { - if (!cpu_has(c, X86_FEATURE_CQM_LLC)) { + if (!cpu_has(c, X86_FEATURE_CQM_LLC) && !cpu_has(c, X86_FEATURE_ABMC)) { c->x86_cache_max_rmid = -1; c->x86_cache_occ_scale = -1; c->x86_cache_mbm_width_offset = -1; @@ -977,7 +999,8 @@ void resctrl_cpu_detect(struct cpuinfo_x86 *c) if (cpu_has(c, X86_FEATURE_CQM_OCCUP_LLC) || cpu_has(c, X86_FEATURE_CQM_MBM_TOTAL) || - cpu_has(c, X86_FEATURE_CQM_MBM_LOCAL)) { + cpu_has(c, X86_FEATURE_CQM_MBM_LOCAL) || + cpu_has(c, X86_FEATURE_ABMC)) { u32 eax, ebx, ecx, edx; /* QoS sub-leaf, EAX=0Fh, ECX=1 */\n\nindex 5e3c41b3643737..9f4c2f0aaf5c80 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/kernel/cpu/resctrl/internal.h b/arch/x86/kernel/cpu/resctrl/internal.hindex 5e3c41b3643737..9f4c2f0aaf5c80 100644--- a/ arch/x86/kernel/cpu/resctrl/internal.h +++ b/ arch/x86/kernel/cpu/resctrl/internal.h @@ -37,6 +37,15 @@ struct arch_mbm_state { u64 prev_msr; }; +/* Setting bit 0 in L3_QOS_EXT_CFG enables the ABMC feature. */ +#define ABMC_ENABLE_BIT 0 + +/* + * Qos Event Identifiers. + */ +#define ABMC_EXTENDED_EVT_ID BIT(31) +#define ABMC_EVT_ID BIT(0) + /** * struct rdt_hw_ctrl_domain - Arch private attributes of a set of CPUs that share * a resource for a control function @@ -54,15 +63,15 @@ struct rdt_hw_ctrl_domain { * struct rdt_hw_mon_domain - Arch private attributes of a set of CPUs that share * a resource for a monitor function * @d_resctrl: Properties exposed to the resctrl file system - * @arch_mbm_total: arch private state for MBM total bandwidth - * @arch_mbm_local: arch private state for MBM local bandwidth + * @arch_mbm_states: Per-event pointer to the MBM event's saved state. + * An MBM event's state is an array of struct arch_mbm_state + * indexed by RMID on x86. * * Members of this structure are accessed via helpers that provide abstraction. */ struct rdt_hw_mon_domain { struct rdt_mon_domain d_resctrl; - struct arch_mbm_state *arch_mbm_total; - struct arch_mbm_state *arch_mbm_local; + struct arch_mbm_state *arch_mbm_states[QOS_NUM_L3_MBM_EVENTS]; }; static inline struct rdt_hw_ctrl_domain *resctrl_to_arch_ctrl_dom(struct rdt_ctrl_domain *r) @@ -102,6 +111,7 @@ struct msr_param { * @mon_scale: cqm counter * mon_scale = occupancy in bytes * @mbm_width: Monitor width, to detect and correct for overflow. * @cdp_enabled: CDP state of this resource + * @mbm_cntr_assign_enabled: ABMC feature is enabled * * Members of this structure are either private to the architecture * e.g. mbm_width, or accessed via helpers that provide abstraction. e.g. @@ -115,6 +125,7 @@ struct rdt_hw_resource { unsigned int mon_scale; unsigned int mbm_width; bool cdp_enabled; + bool mbm_cntr_assign_enabled; }; static inline struct rdt_hw_resource *resctrl_to_arch_res(struct rdt_resource *r) @@ -159,6 +170,42 @@ union cpuid_0x10_x_edx { unsigned int full; }; +/* + * ABMC counters are configured by writing to MSR_IA32_L3_QOS_ABMC_CFG. + * + * @bw_type : Event configuration that represents the memory + * transactions being tracked by the @cntr_id. + * @bw_src : Bandwidth source (RMID or CLOSID). + * @reserved1 : Reserved. + * @is_clos : @bw_src field is a CLOSID (not an RMID). + * @cntr_id : Counter identifier. + * @reserved : Reserved. + * @cntr_en : Counting enable bit. + * @cfg_en : Configuration enable bit. + * + * Configuration and counting: + * Counter can be configured across multiple writes to MSR. Configuration + * is applied only when @cfg_en = 1. Counter @cntr_id is reset when the + * configuration is applied. + * @cfg_en = 1, @cntr_en = 0 : Apply @cntr_id configuration but do not + * count events. + * @cfg_en = 1, @cntr_en = 1 : Apply @cntr_id configuration and start + * counting events. + */ +union l3_qos_abmc_cfg { + struct { + unsigned long bw_type :32, + bw_src :12, + reserved1: 3, + is_clos : 1, + cntr_id : 5, + reserved : 9, + cntr_en : 1, + cfg_en : 1; + } split; + unsigned long full; +}; + void rdt_ctrl_update(void *arg); int rdt_get_mon_l3_config(struct rdt_resource *r); @@ -168,5 +215,6 @@ bool rdt_cpu_has(int flag); void __init intel_rdt_mbm_apply_quirk(void); void rdt_domain_reconfigure_cdp(struct rdt_resource *r); +void resctrl_arch_mbm_cntr_assign_set_one(struct rdt_resource *r); #endif /* _ASM_X86_RESCTRL_INTERNAL_H */\n\nindex c261558276cdd4..c8945610d45550 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/kernel/cpu/resctrl/monitor.c b/arch/x86/kernel/cpu/resctrl/monitor.cindex c261558276cdd4..c8945610d45550 100644--- a/ arch/x86/kernel/cpu/resctrl/monitor.c +++ b/ arch/x86/kernel/cpu/resctrl/monitor.c @@ -31,11 +31,6 @@ */ bool rdt_mon_capable; -/* - * Global to indicate which monitoring events are enabled. - */ -unsigned int rdt_mon_features; - #define CF(cf) ((unsigned long)(1048576 * (cf) + 0.5)) static int snc_nodes_per_l3_cache = 1; @@ -135,7 +130,7 @@ static int logical_rmid_to_physical_rmid(int cpu, int lrmid) if (snc_nodes_per_l3_cache == 1) return lrmid; - return lrmid + (cpu_to_node(cpu) % snc_nodes_per_l3_cache) * r->num_rmid; + return lrmid + (cpu_to_node(cpu) % snc_nodes_per_l3_cache) * r->mon.num_rmid; } static int __rmid_read_phys(u32 prmid, enum resctrl_event_id eventid, u64 *val) @@ -166,18 +161,14 @@ static struct arch_mbm_state *get_arch_mbm_state(struct rdt_hw_mon_domain *hw_do u32 rmid, enum resctrl_event_id eventid) { - switch (eventid) { - case QOS_L3_OCCUP_EVENT_ID: - return NULL; - case QOS_L3_MBM_TOTAL_EVENT_ID: - return &hw_dom->arch_mbm_total[rmid]; - case QOS_L3_MBM_LOCAL_EVENT_ID: - return &hw_dom->arch_mbm_local[rmid]; - default: - /* Never expect to get here */ - WARN_ON_ONCE(1); + struct arch_mbm_state *state; + + if (!resctrl_is_mbm_event(eventid)) return NULL; - } + + state = hw_dom->arch_mbm_states[MBM_STATE_IDX(eventid)]; + + return state ? &state[rmid] : NULL; } void resctrl_arch_reset_rmid(struct rdt_resource *r, struct rdt_mon_domain *d, @@ -206,14 +197,16 @@ void resctrl_arch_reset_rmid(struct rdt_resource *r, struct rdt_mon_domain *d, void resctrl_arch_reset_rmid_all(struct rdt_resource *r, struct rdt_mon_domain *d) { struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); - - if (resctrl_arch_is_mbm_total_enabled()) - memset(hw_dom->arch_mbm_total, 0, - sizeof(*hw_dom->arch_mbm_total) * r->num_rmid); - - if (resctrl_arch_is_mbm_local_enabled()) - memset(hw_dom->arch_mbm_local, 0, - sizeof(*hw_dom->arch_mbm_local) * r->num_rmid); + enum resctrl_event_id eventid; + int idx; + + for_each_mbm_event_id(eventid) { + if (!resctrl_is_mon_event_enabled(eventid)) + continue; + idx = MBM_STATE_IDX(eventid); + memset(hw_dom->arch_mbm_states[idx], 0, + sizeof(*hw_dom->arch_mbm_states[0]) * r->mon.num_rmid); + } } static u64 mbm_overflow_count(u64 prev_msr, u64 cur_msr, unsigned int width) @@ -224,15 +217,33 @@ static u64 mbm_overflow_count(u64 prev_msr, u64 cur_msr, unsigned int width) return chunks >> shift; } +static u64 get_corrected_val(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 rmid, enum resctrl_event_id eventid, u64 msr_val) +{ + struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); + struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); + struct arch_mbm_state *am; + u64 chunks; + + am = get_arch_mbm_state(hw_dom, rmid, eventid); + if (am) { + am->chunks += mbm_overflow_count(am->prev_msr, msr_val, + hw_res->mbm_width); + chunks = get_corrected_mbm_count(rmid, am->chunks); + am->prev_msr = msr_val; + } else { + chunks = msr_val; + } + + return chunks * hw_res->mon_scale; +} + int resctrl_arch_rmid_read(struct rdt_resource *r, struct rdt_mon_domain *d, u32 unused, u32 rmid, enum resctrl_event_id eventid, u64 *val, void *ignored) { - struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); - struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); int cpu = cpumask_any(&d->hdr.cpu_mask); - struct arch_mbm_state *am; - u64 msr_val, chunks; + u64 msr_val; u32 prmid; int ret; @@ -243,17 +254,76 @@ int resctrl_arch_rmid_read(struct rdt_resource *r, struct rdt_mon_domain *d, if (ret) return ret; + *val = get_corrected_val(r, d, rmid, eventid, msr_val); + + return 0; +} + +static int __cntr_id_read(u32 cntr_id, u64 *val) +{ + u64 msr_val; + + /* + * QM_EVTSEL Register definition: + * ======================================================= + * Bits Mnemonic Description + * ======================================================= + * 63:44 -- Reserved + * 43:32 RMID RMID or counter ID in ABMC mode + * when reading an MBM event + * 31 ExtendedEvtID Extended Event Identifier + * 30:8 -- Reserved + * 7:0 EvtID Event Identifier + * ======================================================= + * The contents of a specific counter can be read by setting the + * following fields in QM_EVTSEL.ExtendedEvtID(=1) and + * QM_EVTSEL.EvtID = L3CacheABMC (=1) and setting QM_EVTSEL.RMID + * to the desired counter ID. Reading the QM_CTR then returns the + * contents of the specified counter. The RMID_VAL_ERROR bit is set + * if the counter configuration is invalid, or if an invalid counter + * ID is set in the QM_EVTSEL.RMID field. The RMID_VAL_UNAVAIL bit + * is set if the counter data is unavailable. + */ + wrmsr(MSR_IA32_QM_EVTSEL, ABMC_EXTENDED_EVT_ID | ABMC_EVT_ID, cntr_id); + rdmsrl(MSR_IA32_QM_CTR, msr_val); + + if (msr_val & RMID_VAL_ERROR) + return -EIO; + if (msr_val & RMID_VAL_UNAVAIL) + return -EINVAL; + + *val = msr_val; + return 0; +} + +void resctrl_arch_reset_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 unused, u32 rmid, int cntr_id, + enum resctrl_event_id eventid) +{ + struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); + struct arch_mbm_state *am; + am = get_arch_mbm_state(hw_dom, rmid, eventid); if (am) { - am->chunks += mbm_overflow_count(am->prev_msr, msr_val, - hw_res->mbm_width); - chunks = get_corrected_mbm_count(rmid, am->chunks); - am->prev_msr = msr_val; - } else { - chunks = msr_val; + memset(am, 0, sizeof(*am)); + + /* Record any initial, non-zero count value. */ + __cntr_id_read(cntr_id, &am->prev_msr); } +} + +int resctrl_arch_cntr_read(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 unused, u32 rmid, int cntr_id, + enum resctrl_event_id eventid, u64 *val) +{ + u64 msr_val; + int ret; + + ret = __cntr_id_read(cntr_id, &msr_val); + if (ret) + return ret; - *val = chunks * hw_res->mon_scale; + *val = get_corrected_val(r, d, rmid, eventid, msr_val); return 0; } @@ -346,12 +416,13 @@ int __init rdt_get_mon_l3_config(struct rdt_resource *r) unsigned int mbm_offset = boot_cpu_data.x86_cache_mbm_width_offset; struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); unsigned int threshold; + u32 eax, ebx, ecx, edx; snc_nodes_per_l3_cache = snc_get_config(); resctrl_rmid_realloc_limit = boot_cpu_data.x86_cache_size * 1024; hw_res->mon_scale = boot_cpu_data.x86_cache_occ_scale / snc_nodes_per_l3_cache; - r->num_rmid = (boot_cpu_data.x86_cache_max_rmid + 1) / snc_nodes_per_l3_cache; + r->mon.num_rmid = (boot_cpu_data.x86_cache_max_rmid + 1) / snc_nodes_per_l3_cache; hw_res->mbm_width = MBM_CNTR_WIDTH_BASE; if (mbm_offset > 0 && mbm_offset <= MBM_CNTR_WIDTH_OFFSET_MAX) @@ -366,7 +437,7 @@ int __init rdt_get_mon_l3_config(struct rdt_resource *r) * * For a 35MB LLC and 56 RMIDs, this is ~1.8% of the LLC. */ - threshold = resctrl_rmid_realloc_limit / r->num_rmid; + threshold = resctrl_rmid_realloc_limit / r->mon.num_rmid; /* * Because num_rmid may not be a power of two, round the value @@ -375,12 +446,17 @@ int __init rdt_get_mon_l3_config(struct rdt_resource *r) */ resctrl_rmid_realloc_threshold = resctrl_arch_round_mon_val(threshold); - if (rdt_cpu_has(X86_FEATURE_BMEC)) { - u32 eax, ebx, ecx, edx; - + if (rdt_cpu_has(X86_FEATURE_BMEC) || rdt_cpu_has(X86_FEATURE_ABMC)) { /* Detect list of bandwidth sources that can be tracked */ cpuid_count(0x80000020, 3, &eax, &ebx, &ecx, &edx); - r->mbm_cfg_mask = ecx & MAX_EVT_CONFIG_BITS; + r->mon.mbm_cfg_mask = ecx & MAX_EVT_CONFIG_BITS; + } + + if (rdt_cpu_has(X86_FEATURE_ABMC)) { + r->mon.mbm_cntr_assignable = true; + cpuid_count(0x80000020, 5, &eax, &ebx, &ecx, &edx); + r->mon.num_mbm_cntrs = (ebx & GENMASK(15, 0)) + 1; + hw_res->mbm_cntr_assign_enabled = true; } r->mon_capable = true; @@ -401,3 +477,91 @@ void __init intel_rdt_mbm_apply_quirk(void) mbm_cf_rmidthreshold = mbm_cf_table[cf_index].rmidthreshold; mbm_cf = mbm_cf_table[cf_index].cf; } + +static void resctrl_abmc_set_one_amd(void *arg) +{ + bool *enable = arg; + + if (*enable) + msr_set_bit(MSR_IA32_L3_QOS_EXT_CFG, ABMC_ENABLE_BIT); + else + msr_clear_bit(MSR_IA32_L3_QOS_EXT_CFG, ABMC_ENABLE_BIT); +} + +/* + * ABMC enable/disable requires update of L3_QOS_EXT_CFG MSR on all the CPUs + * associated with all monitor domains. + */ +static void _resctrl_abmc_enable(struct rdt_resource *r, bool enable) +{ + struct rdt_mon_domain *d; + + lockdep_assert_cpus_held(); + + list_for_each_entry(d, &r->mon_domains, hdr.list) { + on_each_cpu_mask(&d->hdr.cpu_mask, resctrl_abmc_set_one_amd, + &enable, 1); + resctrl_arch_reset_rmid_all(r, d); + } +} + +int resctrl_arch_mbm_cntr_assign_set(struct rdt_resource *r, bool enable) +{ + struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); + + if (r->mon.mbm_cntr_assignable && + hw_res->mbm_cntr_assign_enabled != enable) { + _resctrl_abmc_enable(r, enable); + hw_res->mbm_cntr_assign_enabled = enable; + } + + return 0; +} + +bool resctrl_arch_mbm_cntr_assign_enabled(struct rdt_resource *r) +{ + return resctrl_to_arch_res(r)->mbm_cntr_assign_enabled; +} + +static void resctrl_abmc_config_one_amd(void *info) +{ + union l3_qos_abmc_cfg *abmc_cfg = info; + + wrmsrl(MSR_IA32_L3_QOS_ABMC_CFG, abmc_cfg->full); +} + +/* + * Send an IPI to the domain to assign the counter to RMID, event pair. + */ +void resctrl_arch_config_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + enum resctrl_event_id evtid, u32 rmid, u32 closid, + u32 cntr_id, bool assign) +{ + struct rdt_hw_mon_domain *hw_dom = resctrl_to_arch_mon_dom(d); + union l3_qos_abmc_cfg abmc_cfg = { 0 }; + struct arch_mbm_state *am; + + abmc_cfg.split.cfg_en = 1; + abmc_cfg.split.cntr_en = assign ? 1 : 0; + abmc_cfg.split.cntr_id = cntr_id; + abmc_cfg.split.bw_src = rmid; + if (assign) + abmc_cfg.split.bw_type = resctrl_get_mon_evt_cfg(evtid); + + smp_call_function_any(&d->hdr.cpu_mask, resctrl_abmc_config_one_amd, &abmc_cfg, 1); + + /* + * The hardware counter is reset (because cfg_en == 1) so there is no + * need to record initial non-zero counts. + */ + am = get_arch_mbm_state(hw_dom, rmid, evtid); + if (am) + memset(am, 0, sizeof(*am)); +} + +void resctrl_arch_mbm_cntr_assign_set_one(struct rdt_resource *r) +{ + struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r); + + resctrl_abmc_set_one_amd(&hw_res->mbm_cntr_assign_enabled); +}\n\nindex 6b868afb26c319..4cee6213d66738 100644\n\n--- a/\n\n+++ b/ diff --git a/arch/x86/kernel/cpu/scattered.c b/arch/x86/kernel/cpu/scattered.cindex 6b868afb26c319..4cee6213d66738 100644--- a/ arch/x86/kernel/cpu/scattered.c +++ b/ arch/x86/kernel/cpu/scattered.c @@ -51,6 +51,7 @@ static const struct cpuid_bit cpuid_bits[] = { { X86_FEATURE_COHERENCY_SFW_NO, CPUID_EBX, 31, 0x8000001f, 0 }, { X86_FEATURE_SMBA, CPUID_EBX, 2, 0x80000020, 0 }, { X86_FEATURE_BMEC, CPUID_EBX, 3, 0x80000020, 0 }, + { X86_FEATURE_ABMC, CPUID_EBX, 5, 0x80000020, 0 }, { X86_FEATURE_TSA_SQ_NO, CPUID_ECX, 1, 0x80000021, 0 }, { X86_FEATURE_TSA_L1_NO, CPUID_ECX, 2, 0x80000021, 0 }, { X86_FEATURE_AMD_WORKLOAD_CLASS, CPUID_EAX, 22, 0x80000021, 0 },\n\nindex 3c39cfacb25183..0d0ef54fc4de1f 100644\n\n--- a/\n\n+++ b/ diff --git a/fs/resctrl/ctrlmondata.c b/fs/resctrl/ctrlmondata.cindex 3c39cfacb25183..0d0ef54fc4de1f 100644--- a/ fs/resctrl/ctrlmondata.c +++ b/ fs/resctrl/ctrlmondata.c @@ -473,12 +473,12 @@ ssize_t rdtgroup_mba_mbps_event_write(struct kernfs_open_file *of, rdt_last_cmd_clear(); if (!strcmp(buf, \"mbm_local_bytes\")) { - if (resctrl_arch_is_mbm_local_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) rdtgrp->mba_mbps_event = QOS_L3_MBM_LOCAL_EVENT_ID; else ret = -EINVAL; } else if (!strcmp(buf, \"mbm_total_bytes\")) { - if (resctrl_arch_is_mbm_total_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) rdtgrp->mba_mbps_event = QOS_L3_MBM_TOTAL_EVENT_ID; else ret = -EINVAL; @@ -563,10 +563,15 @@ void mon_event_read(struct rmid_read *rr, struct rdt_resource *r, rr->r = r; rr->d = d; rr->first = first; - rr->arch_mon_ctx = resctrl_arch_mon_ctx_alloc(r, evtid); - if (IS_ERR(rr->arch_mon_ctx)) { - rr->err = -EINVAL; - return; + if (resctrl_arch_mbm_cntr_assign_enabled(r) && + resctrl_is_mbm_event(evtid)) { + rr->is_mbm_cntr = true; + } else { + rr->arch_mon_ctx = resctrl_arch_mon_ctx_alloc(r, evtid); + if (IS_ERR(rr->arch_mon_ctx)) { + rr->err = -EINVAL; + return; + } } cpu = cpumask_any_housekeeping(cpumask, RESCTRL_PICK_ANY_CPU); @@ -582,7 +587,8 @@ void mon_event_read(struct rmid_read *rr, struct rdt_resource *r, else smp_call_on_cpu(cpu, smp_mon_event_count, rr, false); - resctrl_arch_mon_ctx_free(r, evtid, rr->arch_mon_ctx); + if (rr->arch_mon_ctx) + resctrl_arch_mon_ctx_free(r, evtid, rr->arch_mon_ctx); } int rdtgroup_mondata_show(struct seq_file *m, void *arg) @@ -653,10 +659,16 @@ int rdtgroup_mondata_show(struct seq_file *m, void *arg) checkresult: + /* + * -ENOENT is a special case, set only when \"mbm_event\" counter assignment + * mode is enabled and no counter has been assigned. + */ if (rr.err == -EIO) seq_puts(m, \"Error\n\n\"); else if (rr.err == -EINVAL) seq_puts(m, \"Unavailable\n\n\"); + else if (rr.err == -ENOENT) + seq_puts(m, \"Unassigned\n\n\"); else seq_printf(m, \"%llu\n\n\", rr.val);\n\nindex 9a8cf6f11151d9..cf1fd82dc5a99e 100644\n\n--- a/\n\n+++ b/ diff --git a/fs/resctrl/internal.h b/fs/resctrl/internal.hindex 9a8cf6f11151d9..cf1fd82dc5a99e 100644--- a/ fs/resctrl/internal.h +++ b/ fs/resctrl/internal.h @@ -52,19 +52,31 @@ static inline struct rdt_fs_context *rdt_fc2context(struct fs_context *fc) } /** - * struct mon_evt - Entry in the event list of a resource + * struct mon_evt - Properties of a monitor event * @evtid: event id + * @rid: resource id for this event * @name: name of the event + * @evt_cfg: Event configuration value that represents the + * memory transactions (e.g., READS_TO_LOCAL_MEM, + * READS_TO_REMOTE_MEM) being tracked by @evtid. + * Only valid if @evtid is an MBM event. * @configurable: true if the event is configurable - * @list: entry in &rdt_resource->evt_list + * @enabled: true if the event is enabled */ struct mon_evt { enum resctrl_event_id evtid; + enum resctrl_res_level rid; char *name; + u32 evt_cfg; bool configurable; - struct list_head list; + bool enabled; }; +extern struct mon_evt mon_event_all[QOS_NUM_EVENTS]; + +#define for_each_mon_event(mevt) for (mevt = &mon_event_all[QOS_FIRST_EVENT]; \\ + mevt < &mon_event_all[QOS_NUM_EVENTS]; mevt++) + /** * struct mon_data - Monitoring details for each event file. * @list: Member of the global @mon_data_kn_priv_list list. @@ -99,6 +111,8 @@ struct mon_data { * @evtid: Which monitor event to read. * @first: Initialize MBM counter when true. * @ci: Cacheinfo for L3. Only set when @d is NULL. Used when summing domains. + * @is_mbm_cntr: true if \"mbm_event\" counter assignment mode is enabled and it + * is an MBM event. * @err: Error encountered when reading counter. * @val: Returned value of event counter. If @rgrp is a parent resource group, * @val includes the sum of event counts from its child resource groups. @@ -113,6 +127,7 @@ struct rmid_read { enum resctrl_event_id evtid; bool first; struct cacheinfo *ci; + bool is_mbm_cntr; int err; u64 val; void *arch_mon_ctx; @@ -226,6 +241,8 @@ struct rdtgroup { #define RFTYPE_DEBUG BIT(10) +#define RFTYPE_ASSIGN_CONFIG BIT(11) + #define RFTYPE_CTRL_INFO (RFTYPE_INFO | RFTYPE_CTRL) #define RFTYPE_MON_INFO (RFTYPE_INFO | RFTYPE_MON) @@ -375,6 +392,41 @@ bool closid_allocated(unsigned int closid); int resctrl_find_cleanest_closid(void); +void *rdt_kn_parent_priv(struct kernfs_node *kn); + +int resctrl_mbm_assign_mode_show(struct kernfs_open_file *of, struct seq_file *s, void *v); + +ssize_t resctrl_mbm_assign_mode_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off); + +void resctrl_bmec_files_show(struct rdt_resource *r, struct kernfs_node *l3_mon_kn, + bool show); + +int resctrl_num_mbm_cntrs_show(struct kernfs_open_file *of, struct seq_file *s, void *v); + +int resctrl_available_mbm_cntrs_show(struct kernfs_open_file *of, struct seq_file *s, + void *v); + +void rdtgroup_assign_cntrs(struct rdtgroup *rdtgrp); + +void rdtgroup_unassign_cntrs(struct rdtgroup *rdtgrp); + +int event_filter_show(struct kernfs_open_file *of, struct seq_file *seq, void *v); + +ssize_t event_filter_write(struct kernfs_open_file *of, char *buf, size_t nbytes, + loff_t off); + +int resctrl_mbm_assign_on_mkdir_show(struct kernfs_open_file *of, + struct seq_file *s, void *v); + +ssize_t resctrl_mbm_assign_on_mkdir_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off); + +int mbm_L3_assignments_show(struct kernfs_open_file *of, struct seq_file *s, void *v); + +ssize_t mbm_L3_assignments_write(struct kernfs_open_file *of, char *buf, size_t nbytes, + loff_t off); + #ifdef CONFIG_RESCTRL_FS_PSEUDO_LOCK int rdtgroup_locksetup_enter(struct rdtgroup *rdtgrp);\n\nindex 7326c28a7908f3..4076336fbba6db 100644\n\n--- a/\n\n+++ b/ diff --git a/fs/resctrl/monitor.c b/fs/resctrl/monitor.cindex 7326c28a7908f3..4076336fbba6db 100644--- a/ fs/resctrl/monitor.c +++ b/ fs/resctrl/monitor.c @@ -336,7 +336,7 @@ void free_rmid(u32 closid, u32 rmid) entry = __rmid_entry(idx); - if (resctrl_arch_is_llc_occupancy_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) add_rmid_to_limbo(entry); else list_add_tail(&entry->list, &rmid_free_lru); @@ -346,27 +346,97 @@ static struct mbm_state *get_mbm_state(struct rdt_mon_domain *d, u32 closid, u32 rmid, enum resctrl_event_id evtid) { u32 idx = resctrl_arch_rmid_idx_encode(closid, rmid); + struct mbm_state *state; - switch (evtid) { - case QOS_L3_MBM_TOTAL_EVENT_ID: - return &d->mbm_total[idx]; - case QOS_L3_MBM_LOCAL_EVENT_ID: - return &d->mbm_local[idx]; - default: + if (!resctrl_is_mbm_event(evtid)) return NULL; + + state = d->mbm_states[MBM_STATE_IDX(evtid)]; + + return state ? &state[idx] : NULL; +} + +/* + * mbm_cntr_get() - Return the counter ID for the matching @evtid and @rdtgrp. + * + * Return: + * Valid counter ID on success, or -ENOENT on failure. + */ +static int mbm_cntr_get(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, enum resctrl_event_id evtid) +{ + int cntr_id; + + if (!r->mon.mbm_cntr_assignable) + return -ENOENT; + + if (!resctrl_is_mbm_event(evtid)) + return -ENOENT; + + for (cntr_id = 0; cntr_id < r->mon.num_mbm_cntrs; cntr_id++) { + if (d->cntr_cfg[cntr_id].rdtgrp == rdtgrp && + d->cntr_cfg[cntr_id].evtid == evtid) + return cntr_id; + } + + return -ENOENT; +} + +/* + * mbm_cntr_alloc() - Initialize and return a new counter ID in the domain @d. + * Caller must ensure that the specified event is not assigned already. + * + * Return: + * Valid counter ID on success, or -ENOSPC on failure. + */ +static int mbm_cntr_alloc(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, enum resctrl_event_id evtid) +{ + int cntr_id; + + for (cntr_id = 0; cntr_id < r->mon.num_mbm_cntrs; cntr_id++) { + if (!d->cntr_cfg[cntr_id].rdtgrp) { + d->cntr_cfg[cntr_id].rdtgrp = rdtgrp; + d->cntr_cfg[cntr_id].evtid = evtid; + return cntr_id; + } } + + return -ENOSPC; } -static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) +/* + * mbm_cntr_free() - Clear the counter ID configuration details in the domain @d. + */ +static void mbm_cntr_free(struct rdt_mon_domain *d, int cntr_id) +{ + memset(&d->cntr_cfg[cntr_id], 0, sizeof(*d->cntr_cfg)); +} + +static int __mon_event_count(struct rdtgroup *rdtgrp, struct rmid_read *rr) { int cpu = smp_processor_id(); + u32 closid = rdtgrp->closid; + u32 rmid = rdtgrp->mon.rmid; struct rdt_mon_domain *d; + int cntr_id = -ENOENT; struct mbm_state *m; int err, ret; u64 tval = 0; + if (rr->is_mbm_cntr) { + cntr_id = mbm_cntr_get(rr->r, rr->d, rdtgrp, rr->evtid); + if (cntr_id < 0) { + rr->err = -ENOENT; + return -EINVAL; + } + } + if (rr->first) { - resctrl_arch_reset_rmid(rr->r, rr->d, closid, rmid, rr->evtid); + if (rr->is_mbm_cntr) + resctrl_arch_reset_cntr(rr->r, rr->d, closid, rmid, cntr_id, rr->evtid); + else + resctrl_arch_reset_rmid(rr->r, rr->d, closid, rmid, rr->evtid); m = get_mbm_state(rr->d, closid, rmid, rr->evtid); if (m) memset(m, 0, sizeof(struct mbm_state)); @@ -377,8 +447,12 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) /* Reading a single domain, must be on a CPU in that domain. */ if (!cpumask_test_cpu(cpu, &rr->d->hdr.cpu_mask)) return -EINVAL; - rr->err = resctrl_arch_rmid_read(rr->r, rr->d, closid, rmid, - rr->evtid, &tval, rr->arch_mon_ctx); + if (rr->is_mbm_cntr) + rr->err = resctrl_arch_cntr_read(rr->r, rr->d, closid, rmid, cntr_id, + rr->evtid, &tval); + else + rr->err = resctrl_arch_rmid_read(rr->r, rr->d, closid, rmid, + rr->evtid, &tval, rr->arch_mon_ctx); if (rr->err) return rr->err; @@ -402,8 +476,12 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) list_for_each_entry(d, &rr->r->mon_domains, hdr.list) { if (d->ci_id != rr->ci->id) continue; - err = resctrl_arch_rmid_read(rr->r, d, closid, rmid, - rr->evtid, &tval, rr->arch_mon_ctx); + if (rr->is_mbm_cntr) + err = resctrl_arch_cntr_read(rr->r, d, closid, rmid, cntr_id, + rr->evtid, &tval); + else + err = resctrl_arch_rmid_read(rr->r, d, closid, rmid, + rr->evtid, &tval, rr->arch_mon_ctx); if (!err) { rr->val += tval; ret = 0; @@ -419,8 +497,8 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) /* * mbm_bw_count() - Update bw count from values previously read by * __mon_event_count(). - * @closid: The closid used to identify the cached mbm_state. - * @rmid: The rmid used to identify the cached mbm_state. + * @rdtgrp: resctrl group associated with the CLOSID and RMID to identify + * the cached mbm_state. * @rr: The struct rmid_read populated by __mon_event_count(). * * Supporting function to calculate the memory bandwidth @@ -428,9 +506,11 @@ static int __mon_event_count(u32 closid, u32 rmid, struct rmid_read *rr) * __mon_event_count() is compared with the chunks value from the previous * invocation. This must be called once per second to maintain values in MBps. */ -static void mbm_bw_count(u32 closid, u32 rmid, struct rmid_read *rr) +static void mbm_bw_count(struct rdtgroup *rdtgrp, struct rmid_read *rr) { u64 cur_bw, bytes, cur_bytes; + u32 closid = rdtgrp->closid; + u32 rmid = rdtgrp->mon.rmid; struct mbm_state *m; m = get_mbm_state(rr->d, closid, rmid, rr->evtid); @@ -459,7 +539,7 @@ void mon_event_count(void *info) rdtgrp = rr->rgrp; - ret = __mon_event_count(rdtgrp->closid, rdtgrp->mon.rmid, rr); + ret = __mon_event_count(rdtgrp, rr); /* * For Ctrl groups read data from child monitor groups and @@ -470,8 +550,7 @@ void mon_event_count(void *info) if (rdtgrp->type == RDTCTRL_GROUP) { list_for_each_entry(entry, head, mon.crdtgrp_list) { - if (__mon_event_count(entry->closid, entry->mon.rmid, - rr) == 0) + if (__mon_event_count(entry, rr) == 0) ret = 0; } } @@ -602,44 +681,49 @@ static void update_mba_bw(struct rdtgroup *rgrp, struct rdt_mon_domain *dom_mbm) } static void mbm_update_one_event(struct rdt_resource *r, struct rdt_mon_domain *d, - u32 closid, u32 rmid, enum resctrl_event_id evtid) + struct rdtgroup *rdtgrp, enum resctrl_event_id evtid) { struct rmid_read rr = {0}; rr.r = r; rr.d = d; rr.evtid = evtid; - rr.arch_mon_ctx = resctrl_arch_mon_ctx_alloc(rr.r, rr.evtid); - if (IS_ERR(rr.arch_mon_ctx)) { - pr_warn_ratelimited(\"Failed to allocate monitor context: %ld\", - PTR_ERR(rr.arch_mon_ctx)); - return; + if (resctrl_arch_mbm_cntr_assign_enabled(r)) { + rr.is_mbm_cntr = true; + } else { + rr.arch_mon_ctx = resctrl_arch_mon_ctx_alloc(rr.r, rr.evtid); + if (IS_ERR(rr.arch_mon_ctx)) { + pr_warn_ratelimited(\"Failed to allocate monitor context: %ld\", + PTR_ERR(rr.arch_mon_ctx)); + return; + } } - __mon_event_count(closid, rmid, &rr); + __mon_event_count(rdtgrp, &rr); /* * If the software controller is enabled, compute the * bandwidth for this event id. */ if (is_mba_sc(NULL)) - mbm_bw_count(closid, rmid, &rr); + mbm_bw_count(rdtgrp, &rr); - resctrl_arch_mon_ctx_free(rr.r, rr.evtid, rr.arch_mon_ctx); + if (rr.arch_mon_ctx) + resctrl_arch_mon_ctx_free(rr.r, rr.evtid, rr.arch_mon_ctx); } static void mbm_update(struct rdt_resource *r, struct rdt_mon_domain *d, - u32 closid, u32 rmid) + struct rdtgroup *rdtgrp) { /* * This is protected from concurrent reads from user as both * the user and overflow handler hold the global mutex. */ - if (resctrl_arch_is_mbm_total_enabled()) - mbm_update_one_event(r, d, closid, rmid, QOS_L3_MBM_TOTAL_EVENT_ID); + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + mbm_update_one_event(r, d, rdtgrp, QOS_L3_MBM_TOTAL_EVENT_ID); - if (resctrl_arch_is_mbm_local_enabled()) - mbm_update_one_event(r, d, closid, rmid, QOS_L3_MBM_LOCAL_EVENT_ID); + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + mbm_update_one_event(r, d, rdtgrp, QOS_L3_MBM_LOCAL_EVENT_ID); } /* @@ -712,11 +796,11 @@ void mbm_handle_overflow(struct work_struct *work) d = container_of(work, struct rdt_mon_domain, mbm_over.work); list_for_each_entry(prgrp, &rdt_all_groups, rdtgroup_list) { - mbm_update(r, d, prgrp->closid, prgrp->mon.rmid); + mbm_update(r, d, prgrp); head = &prgrp->mon.crdtgrp_list; list_for_each_entry(crgrp, head, mon.crdtgrp_list) - mbm_update(r, d, crgrp->closid, crgrp->mon.rmid); + mbm_update(r, d, crgrp); if (is_mba_sc(NULL)) update_mba_bw(prgrp, d); @@ -842,38 +926,819 @@ out_unlock: mutex_unlock(&rdtgroup_mutex); } -static struct mon_evt llc_occupancy_event = { - .name = \"llc_occupancy\", - .evtid = QOS_L3_OCCUP_EVENT_ID, +/* + * All available events. Architecture code marks the ones that + * are supported by a system using resctrl_enable_mon_event() + * to set .enabled. + */ +struct mon_evt mon_event_all[QOS_NUM_EVENTS] = { + [QOS_L3_OCCUP_EVENT_ID] = { + .name = \"llc_occupancy\", + .evtid = QOS_L3_OCCUP_EVENT_ID, + .rid = RDT_RESOURCE_L3, + }, + [QOS_L3_MBM_TOTAL_EVENT_ID] = { + .name = \"mbm_total_bytes\", + .evtid = QOS_L3_MBM_TOTAL_EVENT_ID, + .rid = RDT_RESOURCE_L3, + }, + [QOS_L3_MBM_LOCAL_EVENT_ID] = { + .name = \"mbm_local_bytes\", + .evtid = QOS_L3_MBM_LOCAL_EVENT_ID, + .rid = RDT_RESOURCE_L3, + }, }; -static struct mon_evt mbm_total_event = { - .name = \"mbm_total_bytes\", - .evtid = QOS_L3_MBM_TOTAL_EVENT_ID, +void resctrl_enable_mon_event(enum resctrl_event_id eventid) +{ + if (WARN_ON_ONCE(eventid < QOS_FIRST_EVENT || eventid >= QOS_NUM_EVENTS)) + return; + if (mon_event_all[eventid].enabled) { + pr_warn(\"Duplicate enable for event %d\n\n\", eventid); + return; + } + + mon_event_all[eventid].enabled = true; +} + +bool resctrl_is_mon_event_enabled(enum resctrl_event_id eventid) +{ + return eventid >= QOS_FIRST_EVENT && eventid < QOS_NUM_EVENTS && + mon_event_all[eventid].enabled; +} + +u32 resctrl_get_mon_evt_cfg(enum resctrl_event_id evtid) +{ + return mon_event_all[evtid].evt_cfg; +} + +/** + * struct mbm_transaction - Memory transaction an MBM event can be configured with. + * @name: Name of memory transaction (read, write ...). + * @val: The bit (eg. READS_TO_LOCAL_MEM or READS_TO_REMOTE_MEM) used to + * represent the memory transaction within an event's configuration. + */ +struct mbm_transaction { + char name[32]; + u32 val; }; -static struct mon_evt mbm_local_event = { - .name = \"mbm_local_bytes\", - .evtid = QOS_L3_MBM_LOCAL_EVENT_ID, +/* Decoded values for each type of memory transaction. */ +static struct mbm_transaction mbm_transactions[NUM_MBM_TRANSACTIONS] = { + {\"local_reads\", READS_TO_LOCAL_MEM}, + {\"remote_reads\", READS_TO_REMOTE_MEM}, + {\"local_non_temporal_writes\", NON_TEMP_WRITE_TO_LOCAL_MEM}, + {\"remote_non_temporal_writes\", NON_TEMP_WRITE_TO_REMOTE_MEM}, + {\"local_reads_slow_memory\", READS_TO_LOCAL_S_MEM}, + {\"remote_reads_slow_memory\", READS_TO_REMOTE_S_MEM}, + {\"dirty_victim_writes_all\", DIRTY_VICTIMS_TO_ALL_MEM}, }; +int event_filter_show(struct kernfs_open_file *of, struct seq_file *seq, void *v) +{ + struct mon_evt *mevt = rdt_kn_parent_priv(of->kn); + struct rdt_resource *r; + bool sep = false; + int ret = 0, i; + + mutex_lock(&rdtgroup_mutex); + rdt_last_cmd_clear(); + + r = resctrl_arch_get_resource(mevt->rid); + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + for (i = 0; i < NUM_MBM_TRANSACTIONS; i++) { + if (mevt->evt_cfg & mbm_transactions[i].val) { + if (sep) + seq_putc(seq, ','); + seq_printf(seq, \"%s\", mbm_transactions[i].name); + sep = true; + } + } + seq_putc(seq, '\n\n'); + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + + return ret; +} + +int resctrl_mbm_assign_on_mkdir_show(struct kernfs_open_file *of, struct seq_file *s, + void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + int ret = 0; + + mutex_lock(&rdtgroup_mutex); + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + seq_printf(s, \"%u\n\n\", r->mon.mbm_assign_on_mkdir); + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + + return ret; +} + +ssize_t resctrl_mbm_assign_on_mkdir_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + bool value; + int ret; + + ret = kstrtobool(buf, &value); + if (ret) + return ret; + + mutex_lock(&rdtgroup_mutex); + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + r->mon.mbm_assign_on_mkdir = value; + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + + return ret ?: nbytes; +} + +/* + * mbm_cntr_free_all() - Clear all the counter ID configuration details in the + * domain @d. Called when mbm_assign_mode is changed. + */ +static void mbm_cntr_free_all(struct rdt_resource *r, struct rdt_mon_domain *d) +{ + memset(d->cntr_cfg, 0, sizeof(*d->cntr_cfg) * r->mon.num_mbm_cntrs); +} + +/* + * resctrl_reset_rmid_all() - Reset all non-architecture states for all the + * supported RMIDs. + */ +static void resctrl_reset_rmid_all(struct rdt_resource *r, struct rdt_mon_domain *d) +{ + u32 idx_limit = resctrl_arch_system_num_rmid_idx(); + enum resctrl_event_id evt; + int idx; + + for_each_mbm_event_id(evt) { + if (!resctrl_is_mon_event_enabled(evt)) + continue; + idx = MBM_STATE_IDX(evt); + memset(d->mbm_states[idx], 0, sizeof(*d->mbm_states[0]) * idx_limit); + } +} + +/* + * rdtgroup_assign_cntr() - Assign/unassign the counter ID for the event, RMID + * pair in the domain. + * + * Assign the counter if @assign is true else unassign the counter. Reset the + * associated non-architectural state. + */ +static void rdtgroup_assign_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + enum resctrl_event_id evtid, u32 rmid, u32 closid, + u32 cntr_id, bool assign) +{ + struct mbm_state *m; + + resctrl_arch_config_cntr(r, d, evtid, rmid, closid, cntr_id, assign); + + m = get_mbm_state(d, closid, rmid, evtid); + if (m) + memset(m, 0, sizeof(*m)); +} + +/* + * rdtgroup_alloc_assign_cntr() - Allocate a counter ID and assign it to the event + * pointed to by @mevt and the resctrl group @rdtgrp within the domain @d. + * + * Return: + * 0 on success, < 0 on failure. + */ +static int rdtgroup_alloc_assign_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, struct mon_evt *mevt) +{ + int cntr_id; + + /* No action required if the counter is assigned already. */ + cntr_id = mbm_cntr_get(r, d, rdtgrp, mevt->evtid); + if (cntr_id >= 0) + return 0; + + cntr_id = mbm_cntr_alloc(r, d, rdtgrp, mevt->evtid); + if (cntr_id < 0) { + rdt_last_cmd_printf(\"Failed to allocate counter for %s in domain %d\n\n\", + mevt->name, d->hdr.id); + return cntr_id; + } + + rdtgroup_assign_cntr(r, d, mevt->evtid, rdtgrp->mon.rmid, rdtgrp->closid, cntr_id, true); + + return 0; +} + /* - * Initialize the event list for the resource. + * rdtgroup_assign_cntr_event() - Assign a hardware counter for the event in + * @mevt to the resctrl group @rdtgrp. Assign counters to all domains if @d is + * NULL; otherwise, assign the counter to the specified domain @d. + * + * If all counters in a domain are already in use, rdtgroup_alloc_assign_cntr() + * will fail. The assignment process will abort at the first failure encountered + * during domain traversal, which may result in the event being only partially + * assigned. * - * Note that MBM events are also part of RDT_RESOURCE_L3 resource - * because as per the SDM the total and local memory bandwidth - * are enumerated as part of L3 monitoring. + * Return: + * 0 on success, < 0 on failure. + */ +static int rdtgroup_assign_cntr_event(struct rdt_mon_domain *d, struct rdtgroup *rdtgrp, + struct mon_evt *mevt) +{ + struct rdt_resource *r = resctrl_arch_get_resource(mevt->rid); + int ret = 0; + + if (!d) { + list_for_each_entry(d, &r->mon_domains, hdr.list) { + ret = rdtgroup_alloc_assign_cntr(r, d, rdtgrp, mevt); + if (ret) + return ret; + } + } else { + ret = rdtgroup_alloc_assign_cntr(r, d, rdtgrp, mevt); + } + + return ret; +} + +/* + * rdtgroup_assign_cntrs() - Assign counters to MBM events. Called when + * a new group is created. + * + * Each group can accommodate two counters per domain: one for the total + * event and one for the local event. Assignments may fail due to the limited + * number of counters. However, it is not necessary to fail the group creation + * and thus no failure is returned. Users have the option to modify the + * counter assignments after the group has been created. + */ +void rdtgroup_assign_cntrs(struct rdtgroup *rdtgrp) +{ + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); + + if (!r->mon_capable || !resctrl_arch_mbm_cntr_assign_enabled(r) || + !r->mon.mbm_assign_on_mkdir) + return; + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + rdtgroup_assign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID]); + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + rdtgroup_assign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID]); +} + +/* + * rdtgroup_free_unassign_cntr() - Unassign and reset the counter ID configuration + * for the event pointed to by @mevt within the domain @d and resctrl group @rdtgrp. + */ +static void rdtgroup_free_unassign_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, struct mon_evt *mevt) +{ + int cntr_id; + + cntr_id = mbm_cntr_get(r, d, rdtgrp, mevt->evtid); + + /* If there is no cntr_id assigned, nothing to do */ + if (cntr_id < 0) + return; + + rdtgroup_assign_cntr(r, d, mevt->evtid, rdtgrp->mon.rmid, rdtgrp->closid, cntr_id, false); + + mbm_cntr_free(d, cntr_id); +} + +/* + * rdtgroup_unassign_cntr_event() - Unassign a hardware counter associated with + * the event structure @mevt from the domain @d and the group @rdtgrp. Unassign + * the counters from all the domains if @d is NULL else unassign from @d. + */ +static void rdtgroup_unassign_cntr_event(struct rdt_mon_domain *d, struct rdtgroup *rdtgrp, + struct mon_evt *mevt) +{ + struct rdt_resource *r = resctrl_arch_get_resource(mevt->rid); + + if (!d) { + list_for_each_entry(d, &r->mon_domains, hdr.list) + rdtgroup_free_unassign_cntr(r, d, rdtgrp, mevt); + } else { + rdtgroup_free_unassign_cntr(r, d, rdtgrp, mevt); + } +} + +/* + * rdtgroup_unassign_cntrs() - Unassign the counters associated with MBM events. + * Called when a group is deleted. */ -static void l3_mon_evt_init(struct rdt_resource *r) +void rdtgroup_unassign_cntrs(struct rdtgroup *rdtgrp) { - INIT_LIST_HEAD(&r->evt_list); + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); - if (resctrl_arch_is_llc_occupancy_enabled()) - list_add_tail(&llc_occupancy_event.list, &r->evt_list); - if (resctrl_arch_is_mbm_total_enabled()) - list_add_tail(&mbm_total_event.list, &r->evt_list); - if (resctrl_arch_is_mbm_local_enabled()) - list_add_tail(&mbm_local_event.list, &r->evt_list); + if (!r->mon_capable || !resctrl_arch_mbm_cntr_assign_enabled(r)) + return; + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + rdtgroup_unassign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID]); + + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + rdtgroup_unassign_cntr_event(NULL, rdtgrp, + &mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID]); +} + +static int resctrl_parse_mem_transactions(char *tok, u32 *val) +{ + u32 temp_val = 0; + char *evt_str; + bool found; + int i; + +next_config: + if (!tok || tok[0] == '\\0') { + *val = temp_val; + return 0; + } + + /* Start processing the strings for each memory transaction type */ + evt_str = strim(strsep(&tok, \",\")); + found = false; + for (i = 0; i < NUM_MBM_TRANSACTIONS; i++) { + if (!strcmp(mbm_transactions[i].name, evt_str)) { + temp_val |= mbm_transactions[i].val; + found = true; + break; + } + } + + if (!found) { + rdt_last_cmd_printf(\"Invalid memory transaction type %s\n\n\", evt_str); + return -EINVAL; + } + + goto next_config; +} + +/* + * rdtgroup_update_cntr_event - Update the counter assignments for the event + * in a group. + * @r: Resource to which update needs to be done. + * @rdtgrp: Resctrl group. + * @evtid: MBM monitor event. + */ +static void rdtgroup_update_cntr_event(struct rdt_resource *r, struct rdtgroup *rdtgrp, + enum resctrl_event_id evtid) +{ + struct rdt_mon_domain *d; + int cntr_id; + + list_for_each_entry(d, &r->mon_domains, hdr.list) { + cntr_id = mbm_cntr_get(r, d, rdtgrp, evtid); + if (cntr_id >= 0) + rdtgroup_assign_cntr(r, d, evtid, rdtgrp->mon.rmid, + rdtgrp->closid, cntr_id, true); + } +} + +/* + * resctrl_update_cntr_allrdtgrp - Update the counter assignments for the event + * for all the groups. + * @mevt MBM Monitor event. + */ +static void resctrl_update_cntr_allrdtgrp(struct mon_evt *mevt) +{ + struct rdt_resource *r = resctrl_arch_get_resource(mevt->rid); + struct rdtgroup *prgrp, *crgrp; + + /* + * Find all the groups where the event is assigned and update the + * configuration of existing assignments. + */ + list_for_each_entry(prgrp, &rdt_all_groups, rdtgroup_list) { + rdtgroup_update_cntr_event(r, prgrp, mevt->evtid); + + list_for_each_entry(crgrp, &prgrp->mon.crdtgrp_list, mon.crdtgrp_list) + rdtgroup_update_cntr_event(r, crgrp, mevt->evtid); + } +} + +ssize_t event_filter_write(struct kernfs_open_file *of, char *buf, size_t nbytes, + loff_t off) +{ + struct mon_evt *mevt = rdt_kn_parent_priv(of->kn); + struct rdt_resource *r; + u32 evt_cfg = 0; + int ret = 0; + + /* Valid input requires a trailing newline */ + if (nbytes == 0 || buf[nbytes - 1] != '\n\n') + return -EINVAL; + + buf[nbytes - 1] = '\\0'; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + rdt_last_cmd_clear(); + + r = resctrl_arch_get_resource(mevt->rid); + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + ret = resctrl_parse_mem_transactions(buf, &evt_cfg); + if (!ret && mevt->evt_cfg != evt_cfg) { + mevt->evt_cfg = evt_cfg; + resctrl_update_cntr_allrdtgrp(mevt); + } + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + + return ret ?: nbytes; +} + +int resctrl_mbm_assign_mode_show(struct kernfs_open_file *of, + struct seq_file *s, void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + bool enabled; + + mutex_lock(&rdtgroup_mutex); + enabled = resctrl_arch_mbm_cntr_assign_enabled(r); + + if (r->mon.mbm_cntr_assignable) { + if (enabled) + seq_puts(s, \"[mbm_event]\n\n\"); + else + seq_puts(s, \"[default]\n\n\"); + + if (!IS_ENABLED(CONFIG_RESCTRL_ASSIGN_FIXED)) { + if (enabled) + seq_puts(s, \"default\n\n\"); + else + seq_puts(s, \"mbm_event\n\n\"); + } + } else { + seq_puts(s, \"[default]\n\n\"); + } + + mutex_unlock(&rdtgroup_mutex); + + return 0; +} + +ssize_t resctrl_mbm_assign_mode_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + struct rdt_mon_domain *d; + int ret = 0; + bool enable; + + /* Valid input requires a trailing newline */ + if (nbytes == 0 || buf[nbytes - 1] != '\n\n') + return -EINVAL; + + buf[nbytes - 1] = '\\0'; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + rdt_last_cmd_clear(); + + if (!strcmp(buf, \"default\")) { + enable = 0; + } else if (!strcmp(buf, \"mbm_event\")) { + if (r->mon.mbm_cntr_assignable) { + enable = 1; + } else { + ret = -EINVAL; + rdt_last_cmd_puts(\"mbm_event mode is not supported\n\n\"); + goto out_unlock; + } + } else { + ret = -EINVAL; + rdt_last_cmd_puts(\"Unsupported assign mode\n\n\"); + goto out_unlock; + } + + if (enable != resctrl_arch_mbm_cntr_assign_enabled(r)) { + ret = resctrl_arch_mbm_cntr_assign_set(r, enable); + if (ret) + goto out_unlock; + + /* Update the visibility of BMEC related files */ + resctrl_bmec_files_show(r, NULL, !enable); + + /* + * Initialize the default memory transaction values for + * total and local events. + */ + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask; + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask & + (READS_TO_LOCAL_MEM | + READS_TO_LOCAL_S_MEM | + NON_TEMP_WRITE_TO_LOCAL_MEM); + /* Enable auto assignment when switching to \"mbm_event\" mode */ + if (enable) + r->mon.mbm_assign_on_mkdir = true; + /* + * Reset all the non-achitectural RMID state and assignable counters. + */ + list_for_each_entry(d, &r->mon_domains, hdr.list) { + mbm_cntr_free_all(r, d); + resctrl_reset_rmid_all(r, d); + } + } + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + + return ret ?: nbytes; +} + +int resctrl_num_mbm_cntrs_show(struct kernfs_open_file *of, + struct seq_file *s, void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + struct rdt_mon_domain *dom; + bool sep = false; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + list_for_each_entry(dom, &r->mon_domains, hdr.list) { + if (sep) + seq_putc(s, ';'); + + seq_printf(s, \"%d=%d\", dom->hdr.id, r->mon.num_mbm_cntrs); + sep = true; + } + seq_putc(s, '\n\n'); + + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + return 0; +} + +int resctrl_available_mbm_cntrs_show(struct kernfs_open_file *of, + struct seq_file *s, void *v) +{ + struct rdt_resource *r = rdt_kn_parent_priv(of->kn); + struct rdt_mon_domain *dom; + bool sep = false; + u32 cntrs, i; + int ret = 0; + + cpus_read_lock(); + mutex_lock(&rdtgroup_mutex); + + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + list_for_each_entry(dom, &r->mon_domains, hdr.list) { + if (sep) + seq_putc(s, ';'); + + cntrs = 0; + for (i = 0; i < r->mon.num_mbm_cntrs; i++) { + if (!dom->cntr_cfg[i].rdtgrp) + cntrs++; + } + + seq_printf(s, \"%d=%u\", dom->hdr.id, cntrs); + sep = true; + } + seq_putc(s, '\n\n'); + +out_unlock: + mutex_unlock(&rdtgroup_mutex); + cpus_read_unlock(); + + return ret; +} + +int mbm_L3_assignments_show(struct kernfs_open_file *of, struct seq_file *s, void *v) +{ + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); + struct rdt_mon_domain *d; + struct rdtgroup *rdtgrp; + struct mon_evt *mevt; + int ret = 0; + bool sep; + + rdtgrp = rdtgroup_kn_lock_live(of->kn); + if (!rdtgrp) { + ret = -ENOENT; + goto out_unlock; + } + + rdt_last_cmd_clear(); + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event counter assignment mode is not enabled\n\n\"); + ret = -EINVAL; + goto out_unlock; + } + + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled || !resctrl_is_mbm_event(mevt->evtid)) + continue; + + sep = false; + seq_printf(s, \"%s:\", mevt->name); + list_for_each_entry(d, &r->mon_domains, hdr.list) { + if (sep) + seq_putc(s, ';'); + + if (mbm_cntr_get(r, d, rdtgrp, mevt->evtid) < 0) + seq_printf(s, \"%d=_\", d->hdr.id); + else + seq_printf(s, \"%d=e\", d->hdr.id); + + sep = true; + } + seq_putc(s, '\n\n'); + } + +out_unlock: + rdtgroup_kn_unlock(of->kn); + + return ret; +} + +/* + * mbm_get_mon_event_by_name() - Return the mon_evt entry for the matching + * event name. + */ +static struct mon_evt *mbm_get_mon_event_by_name(struct rdt_resource *r, char *name) +{ + struct mon_evt *mevt; + + for_each_mon_event(mevt) { + if (mevt->rid == r->rid && mevt->enabled && + resctrl_is_mbm_event(mevt->evtid) && + !strcmp(mevt->name, name)) + return mevt; + } + + return NULL; +} + +static int rdtgroup_modify_assign_state(char *assign, struct rdt_mon_domain *d, + struct rdtgroup *rdtgrp, struct mon_evt *mevt) +{ + int ret = 0; + + if (!assign || strlen(assign) != 1) + return -EINVAL; + + switch (*assign) { + case 'e': + ret = rdtgroup_assign_cntr_event(d, rdtgrp, mevt); + break; + case '_': + rdtgroup_unassign_cntr_event(d, rdtgrp, mevt); + break; + default: + ret = -EINVAL; + break; + } + + return ret; +} + +static int resctrl_parse_mbm_assignment(struct rdt_resource *r, struct rdtgroup *rdtgrp, + char *event, char *tok) +{ + struct rdt_mon_domain *d; + unsigned long dom_id = 0; + char *dom_str, *id_str; + struct mon_evt *mevt; + int ret; + + mevt = mbm_get_mon_event_by_name(r, event); + if (!mevt) { + rdt_last_cmd_printf(\"Invalid event %s\n\n\", event); + return -ENOENT; + } + +next: + if (!tok || tok[0] == '\\0') + return 0; + + /* Start processing the strings for each domain */ + dom_str = strim(strsep(&tok, \";\")); + + id_str = strsep(&dom_str, \"=\"); + + /* Check for domain id '*' which means all domains */ + if (id_str && *id_str == '*') { + ret = rdtgroup_modify_assign_state(dom_str, NULL, rdtgrp, mevt); + if (ret) + rdt_last_cmd_printf(\"Assign operation '%s:*=%s' failed\n\n\", + event, dom_str); + return ret; + } else if (!id_str || kstrtoul(id_str, 10, &dom_id)) { + rdt_last_cmd_puts(\"Missing domain id\n\n\"); + return -EINVAL; + } + + /* Verify if the dom_id is valid */ + list_for_each_entry(d, &r->mon_domains, hdr.list) { + if (d->hdr.id == dom_id) { + ret = rdtgroup_modify_assign_state(dom_str, d, rdtgrp, mevt); + if (ret) { + rdt_last_cmd_printf(\"Assign operation '%s:%ld=%s' failed\n\n\", + event, dom_id, dom_str); + return ret; + } + goto next; + } + } + + rdt_last_cmd_printf(\"Invalid domain id %ld\n\n\", dom_id); + return -EINVAL; +} + +ssize_t mbm_L3_assignments_write(struct kernfs_open_file *of, char *buf, + size_t nbytes, loff_t off) +{ + struct rdt_resource *r = resctrl_arch_get_resource(RDT_RESOURCE_L3); + struct rdtgroup *rdtgrp; + char *token, *event; + int ret = 0; + + /* Valid input requires a trailing newline */ + if (nbytes == 0 || buf[nbytes - 1] != '\n\n') + return -EINVAL; + + buf[nbytes - 1] = '\\0'; + + rdtgrp = rdtgroup_kn_lock_live(of->kn); + if (!rdtgrp) { + rdtgroup_kn_unlock(of->kn); + return -ENOENT; + } + rdt_last_cmd_clear(); + + if (!resctrl_arch_mbm_cntr_assign_enabled(r)) { + rdt_last_cmd_puts(\"mbm_event mode is not enabled\n\n\"); + rdtgroup_kn_unlock(of->kn); + return -EINVAL; + } + + while ((token = strsep(&buf, \"\n\n\")) != NULL) { + /* + * The write command follows the following format: + * \"<Event>:<Domain ID>=<Assignment state>\" + * Extract the event name first. + */ + event = strsep(&token, \":\"); + + ret = resctrl_parse_mbm_assignment(r, rdtgrp, event, token); + if (ret) + break; + } + + rdtgroup_kn_unlock(of->kn); + + return ret ?: nbytes; } /** @@ -900,24 +1765,43 @@ int resctrl_mon_resource_init(void) if (ret) return ret; - l3_mon_evt_init(r); - if (resctrl_arch_is_evt_configurable(QOS_L3_MBM_TOTAL_EVENT_ID)) { - mbm_total_event.configurable = true; + mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID].configurable = true; resctrl_file_fflags_init(\"mbm_total_bytes_config\", RFTYPE_MON_INFO | RFTYPE_RES_CACHE); } if (resctrl_arch_is_evt_configurable(QOS_L3_MBM_LOCAL_EVENT_ID)) { - mbm_local_event.configurable = true; + mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID].configurable = true; resctrl_file_fflags_init(\"mbm_local_bytes_config\", RFTYPE_MON_INFO | RFTYPE_RES_CACHE); } - if (resctrl_arch_is_mbm_local_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) mba_mbps_default_event = QOS_L3_MBM_LOCAL_EVENT_ID; - else if (resctrl_arch_is_mbm_total_enabled()) + else if (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) mba_mbps_default_event = QOS_L3_MBM_TOTAL_EVENT_ID; + if (r->mon.mbm_cntr_assignable) { + if (!resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID)) + resctrl_enable_mon_event(QOS_L3_MBM_TOTAL_EVENT_ID); + if (!resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)) + resctrl_enable_mon_event(QOS_L3_MBM_LOCAL_EVENT_ID); + mon_event_all[QOS_L3_MBM_TOTAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask; + mon_event_all[QOS_L3_MBM_LOCAL_EVENT_ID].evt_cfg = r->mon.mbm_cfg_mask & + (READS_TO_LOCAL_MEM | + READS_TO_LOCAL_S_MEM | + NON_TEMP_WRITE_TO_LOCAL_MEM); + r->mon.mbm_assign_on_mkdir = true; + resctrl_file_fflags_init(\"num_mbm_cntrs\", + RFTYPE_MON_INFO | RFTYPE_RES_CACHE); + resctrl_file_fflags_init(\"available_mbm_cntrs\", + RFTYPE_MON_INFO | RFTYPE_RES_CACHE); + resctrl_file_fflags_init(\"event_filter\", RFTYPE_ASSIGN_CONFIG); + resctrl_file_fflags_init(\"mbm_assign_on_mkdir\", RFTYPE_MON_INFO | + RFTYPE_RES_CACHE); + resctrl_file_fflags_init(\"mbm_L3_assignments\", RFTYPE_MON_BASE); + } + return 0; }\n\nindex 77d08229d85502..0320360cd7a6eb 100644\n\n--- a/\n\n+++ b/ diff --git a/fs/resctrl/rdtgroup.c b/fs/resctrl/rdtgroup.cindex 77d08229d85502..0320360cd7a6eb 100644--- a/ fs/resctrl/rdtgroup.c +++ b/ fs/resctrl/rdtgroup.c @@ -123,14 +123,8 @@ void rdt_staged_configs_clear(void) static bool resctrl_is_mbm_enabled(void) { - return (resctrl_arch_is_mbm_total_enabled() || - resctrl_arch_is_mbm_local_enabled()); -} - -static bool resctrl_is_mbm_event(int e) -{ - return (e >= QOS_L3_MBM_TOTAL_EVENT_ID && - e <= QOS_L3_MBM_LOCAL_EVENT_ID); + return (resctrl_is_mon_event_enabled(QOS_L3_MBM_TOTAL_EVENT_ID) || + resctrl_is_mon_event_enabled(QOS_L3_MBM_LOCAL_EVENT_ID)); } /* @@ -196,7 +190,7 @@ static int closid_alloc(void) lockdep_assert_held(&rdtgroup_mutex); if (IS_ENABLED(CONFIG_RESCTRL_RMID_DEPENDS_ON_CLOSID) && - resctrl_arch_is_llc_occupancy_enabled()) { + resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) { cleanest_closid = resctrl_find_cleanest_closid(); if (cleanest_closid < 0) return cleanest_closid; @@ -981,7 +975,7 @@ static int rdt_last_cmd_status_show(struct kernfs_open_file *of, return 0; } -static void *rdt_kn_parent_priv(struct kernfs_node *kn) +void *rdt_kn_parent_priv(struct kernfs_node *kn) { /* * The parent pointer is only valid within RCU section since it can be @@ -1141,7 +1135,7 @@ static int rdt_num_rmids_show(struct kernfs_open_file *of, { struct rdt_resource *r = rdt_kn_parent_priv(of->kn); - seq_printf(seq, \"%d\n\n\", r->num_rmid); + seq_printf(seq, \"%d\n\n\", r->mon.num_rmid); return 0; } @@ -1152,9 +1146,12 @@ static int rdt_mon_features_show(struct kernfs_open_file *of, struct rdt_resource *r = rdt_kn_parent_priv(of->kn); struct mon_evt *mevt; - list_for_each_entry(mevt, &r->evt_list, list) { + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled) + continue; seq_printf(seq, \"%s\n\n\", mevt->name); - if (mevt->configurable) + if (mevt->configurable && + !resctrl_arch_mbm_cntr_assign_enabled(r)) seq_printf(seq, \"%s_config\n\n\", mevt->name); } @@ -1735,9 +1732,9 @@ next: } /* Value from user cannot be more than the supported set of events */ - if ((val & r->mbm_cfg_mask) != val) { + if ((val & r->mon.mbm_cfg_mask) != val) { rdt_last_cmd_printf(\"Invalid event configuration: max valid mask is 0x%02x\n\n\", - r->mbm_cfg_mask); + r->mon.mbm_cfg_mask); return -EINVAL; } @@ -1803,6 +1800,44 @@ static ssize_t mbm_local_bytes_config_write(struct kernfs_open_file *of, return ret ?: nbytes; } +/* + * resctrl_bmec_files_show() — Controls the visibility of BMEC-related resctrl + * files. When @show is true, the files are displayed; when false, the files + * are hidden. + * Don't treat kernfs_find_and_get failure as an error, since this function may + * be called regardless of whether BMEC is supported or the event is enabled. + */ +void resctrl_bmec_files_show(struct rdt_resource *r, struct kernfs_node *l3_mon_kn, + bool show) +{ + struct kernfs_node *kn_config, *mon_kn = NULL; + char name[32]; + + if (!l3_mon_kn) { + sprintf(name, \"%s_MON\", r->name); + mon_kn = kernfs_find_and_get(kn_info, name); + if (!mon_kn) + return; + l3_mon_kn = mon_kn; + } + + kn_config = kernfs_find_and_get(l3_mon_kn, \"mbm_total_bytes_config\"); + if (kn_config) { + kernfs_show(kn_config, show); + kernfs_put(kn_config); + } + + kn_config = kernfs_find_and_get(l3_mon_kn, \"mbm_local_bytes_config\"); + if (kn_config) { + kernfs_show(kn_config, show); + kernfs_put(kn_config); + } + + /* Release the reference only if it was acquired */ + if (mon_kn) + kernfs_put(mon_kn); +} + /* rdtgroup information files for one cache resource. */ static struct rftype res_common_files[] = { { @@ -1813,6 +1848,13 @@ static struct rftype res_common_files[] = { .fflags = RFTYPE_TOP_INFO, }, { + .name = \"mbm_assign_on_mkdir\", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_mbm_assign_on_mkdir_show, + .write = resctrl_mbm_assign_on_mkdir_write, + }, + { .name = \"num_closids\", .mode = 0444, .kf_ops = &rdtgroup_kf_single_ops, @@ -1827,6 +1869,12 @@ static struct rftype res_common_files[] = { .fflags = RFTYPE_MON_INFO, }, { + .name = \"available_mbm_cntrs\", + .mode = 0444, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_available_mbm_cntrs_show, + }, + { .name = \"num_rmids\", .mode = 0444, .kf_ops = &rdtgroup_kf_single_ops, @@ -1841,6 +1889,12 @@ static struct rftype res_common_files[] = { .fflags = RFTYPE_CTRL_INFO | RFTYPE_RES_CACHE, }, { + .name = \"num_mbm_cntrs\", + .mode = 0444, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_num_mbm_cntrs_show, + }, + { .name = \"min_cbm_bits\", .mode = 0444, .kf_ops = &rdtgroup_kf_single_ops, @@ -1916,6 +1970,28 @@ static struct rftype res_common_files[] = { .write = mbm_local_bytes_config_write, }, { + .name = \"event_filter\", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = event_filter_show, + .write = event_filter_write, + }, + { + .name = \"mbm_L3_assignments\", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = mbm_L3_assignments_show, + .write = mbm_L3_assignments_write, + }, + { + .name = \"mbm_assign_mode\", + .mode = 0644, + .kf_ops = &rdtgroup_kf_single_ops, + .seq_show = resctrl_mbm_assign_mode_show, + .write = resctrl_mbm_assign_mode_write, + .fflags = RFTYPE_MON_INFO | RFTYPE_RES_CACHE, + }, + { .name = \"cpus\", .mode = 0644, .kf_ops = &rdtgroup_kf_single_ops, @@ -2168,10 +2244,48 @@ int rdtgroup_kn_mode_restore(struct rdtgroup *r, const char *name, return ret; } +static int resctrl_mkdir_event_configs(struct rdt_resource *r, struct kernfs_node *l3_mon_kn) +{ + struct kernfs_node *kn_subdir, *kn_subdir2; + struct mon_evt *mevt; + int ret; + + kn_subdir = kernfs_create_dir(l3_mon_kn, \"event_configs\", l3_mon_kn->mode, NULL); + if (IS_ERR(kn_subdir)) + return PTR_ERR(kn_subdir); + + ret = rdtgroup_kn_set_ugid(kn_subdir); + if (ret) + return ret; + + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled || !resctrl_is_mbm_event(mevt->evtid)) + continue; + + kn_subdir2 = kernfs_create_dir(kn_subdir, mevt->name, kn_subdir->mode, mevt); + if (IS_ERR(kn_subdir2)) { + ret = PTR_ERR(kn_subdir2); + goto out; + } + + ret = rdtgroup_kn_set_ugid(kn_subdir2); + if (ret) + goto out; + + ret = rdtgroup_add_files(kn_subdir2, RFTYPE_ASSIGN_CONFIG); + if (ret) + break; + } + +out: + return ret; +} + static int rdtgroup_mkdir_info_resdir(void *priv, char *name, unsigned long fflags) { struct kernfs_node *kn_subdir; + struct rdt_resource *r; int ret; kn_subdir = kernfs_create_dir(kn_info, name, @@ -2184,8 +2298,25 @@ static int rdtgroup_mkdir_info_resdir(void *priv, char *name, return ret; ret = rdtgroup_add_files(kn_subdir, fflags); - if (!ret) - kernfs_activate(kn_subdir); + if (ret) + return ret; + + if ((fflags & RFTYPE_MON_INFO) == RFTYPE_MON_INFO) { + r = priv; + if (r->mon.mbm_cntr_assignable) { + ret = resctrl_mkdir_event_configs(r, kn_subdir); + if (ret) + return ret; + /* + * Hide BMEC related files if mbm_event mode + * is enabled. + */ + if (resctrl_arch_mbm_cntr_assign_enabled(r)) + resctrl_bmec_files_show(r, kn_subdir, false); + } + } + + kernfs_activate(kn_subdir); return ret; } @@ -2608,10 +2739,8 @@ static int rdt_get_tree(struct fs_context *fc) goto out_root; ret = schemata_list_create(); - if (ret) { - schemata_list_destroy(); - goto out_ctx; - } + if (ret) + goto out_schemata_free; ret = closid_init(); if (ret) @@ -2637,6 +2766,8 @@ static int rdt_get_tree(struct fs_context *fc) if (ret < 0) goto out_info; + rdtgroup_assign_cntrs(&rdtgroup_default); + ret = mkdir_mondata_all(rdtgroup_default.kn, &rdtgroup_default, &kn_mondata); if (ret < 0) @@ -2675,15 +2806,16 @@ out_mondata: if (resctrl_arch_mon_capable()) kernfs_remove(kn_mondata); out_mongrp: - if (resctrl_arch_mon_capable()) + if (resctrl_arch_mon_capable()) { + rdtgroup_unassign_cntrs(&rdtgroup_default); kernfs_remove(kn_mongrp); + } out_info: kernfs_remove(kn_info); out_closid_exit: closid_exit(); out_schemata_free: schemata_list_destroy(); -out_ctx: rdt_disable_ctx(); out_root: rdtgroup_destroy_root(); @@ -2822,6 +2954,7 @@ static void free_all_child_rdtgrp(struct rdtgroup *rdtgrp) head = &rdtgrp->mon.crdtgrp_list; list_for_each_entry_safe(sentry, stmp, head, mon.crdtgrp_list) { + rdtgroup_unassign_cntrs(sentry); free_rmid(sentry->closid, sentry->mon.rmid); list_del(&sentry->mon.crdtgrp_list); @@ -2862,6 +2995,8 @@ static void rmdir_all_sub(void) cpumask_or(&rdtgroup_default.cpu_mask, &rdtgroup_default.cpu_mask, &rdtgrp->cpu_mask); + rdtgroup_unassign_cntrs(rdtgrp); + free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); kernfs_remove(rdtgrp->kn); @@ -2946,6 +3081,7 @@ static void resctrl_fs_teardown(void) return; rmdir_all_sub(); + rdtgroup_unassign_cntrs(&rdtgroup_default); mon_put_kn_priv(); rdt_pseudo_lock_release(); rdtgroup_default.mode = RDT_MODE_SHAREABLE; @@ -3057,10 +3193,9 @@ static int mon_add_all_files(struct kernfs_node *kn, struct rdt_mon_domain *d, struct mon_evt *mevt; int ret, domid; - if (WARN_ON(list_empty(&r->evt_list))) - return -EPERM; - - list_for_each_entry(mevt, &r->evt_list, list) { + for_each_mon_event(mevt) { + if (mevt->rid != r->rid || !mevt->enabled) + continue; domid = do_sum ? d->ci_id : d->hdr.id; priv = mon_get_kn_priv(r->rid, domid, mevt, do_sum); if (WARN_ON_ONCE(!priv)) @@ -3427,9 +3562,12 @@ static int mkdir_rdt_prepare_rmid_alloc(struct rdtgroup *rdtgrp) } rdtgrp->mon.rmid = ret; + rdtgroup_assign_cntrs(rdtgrp); + ret = mkdir_mondata_all(rdtgrp->kn, rdtgrp, &rdtgrp->mon.mon_data_kn); if (ret) { rdt_last_cmd_puts(\"kernfs subdir error\n\n\"); + rdtgroup_unassign_cntrs(rdtgrp); free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); return ret; } @@ -3439,8 +3577,10 @@ static int mkdir_rdt_prepare_rmid_alloc(struct rdtgroup *rdtgrp) static void mkdir_rdt_prepare_rmid_free(struct rdtgroup *rgrp) { - if (resctrl_arch_mon_capable()) + if (resctrl_arch_mon_capable()) { + rdtgroup_unassign_cntrs(rgrp); free_rmid(rgrp->closid, rgrp->mon.rmid); + } } /* @@ -3716,6 +3856,9 @@ static int rdtgroup_rmdir_mon(struct rdtgroup *rdtgrp, cpumask_var_t tmpmask) update_closid_rmid(tmpmask, NULL); rdtgrp->flags = RDT_DELETED; + + rdtgroup_unassign_cntrs(rdtgrp); + free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); /* @@ -3763,6 +3906,8 @@ static int rdtgroup_rmdir_ctrl(struct rdtgroup *rdtgrp, cpumask_var_t tmpmask) cpumask_or(tmpmask, tmpmask, &rdtgrp->cpu_mask); update_closid_rmid(tmpmask, NULL); + rdtgroup_unassign_cntrs(rdtgrp); + free_rmid(rdtgrp->closid, rdtgrp->mon.rmid); closid_free(rdtgrp->closid); @@ -4022,9 +4167,14 @@ static void rdtgroup_setup_default(void) static void domain_destroy_mon_state(struct rdt_mon_domain *d) { + int idx; + + kfree(d->cntr_cfg); bitmap_free(d->rmid_busy_llc); - kfree(d->mbm_total); - kfree(d->mbm_local); + for_each_mbm_idx(idx) { + kfree(d->mbm_states[idx]); + d->mbm_states[idx] = NULL; + } } void resctrl_offline_ctrl_domain(struct rdt_resource *r, struct rdt_ctrl_domain *d) @@ -4050,7 +4200,7 @@ void resctrl_offline_mon_domain(struct rdt_resource *r, struct rdt_mon_domain *d if (resctrl_is_mbm_enabled()) cancel_delayed_work(&d->mbm_over); - if (resctrl_arch_is_llc_occupancy_enabled() && has_busy_rmid(d)) { + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID) && has_busy_rmid(d)) { /* * When a package is going down, forcefully * decrement rmid->ebusy. There is no way to know @@ -4084,32 +4234,41 @@ void resctrl_offline_mon_domain(struct rdt_resource *r, struct rdt_mon_domain *d static int domain_setup_mon_state(struct rdt_resource *r, struct rdt_mon_domain *d) { u32 idx_limit = resctrl_arch_system_num_rmid_idx(); - size_t tsize; + size_t tsize = sizeof(*d->mbm_states[0]); + enum resctrl_event_id eventid; + int idx; - if (resctrl_arch_is_llc_occupancy_enabled()) { + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) { d->rmid_busy_llc = bitmap_zalloc(idx_limit, GFP_KERNEL); if (!d->rmid_busy_llc) return -ENOMEM; } - if (resctrl_arch_is_mbm_total_enabled()) { - tsize = sizeof(*d->mbm_total); - d->mbm_total = kcalloc(idx_limit, tsize, GFP_KERNEL); - if (!d->mbm_total) { - bitmap_free(d->rmid_busy_llc); - return -ENOMEM; - } + + for_each_mbm_event_id(eventid) { + if (!resctrl_is_mon_event_enabled(eventid)) + continue; + idx = MBM_STATE_IDX(eventid); + d->mbm_states[idx] = kcalloc(idx_limit, tsize, GFP_KERNEL); + if (!d->mbm_states[idx]) + goto cleanup; } - if (resctrl_arch_is_mbm_local_enabled()) { - tsize = sizeof(*d->mbm_local); - d->mbm_local = kcalloc(idx_limit, tsize, GFP_KERNEL); - if (!d->mbm_local) { - bitmap_free(d->rmid_busy_llc); - kfree(d->mbm_total); - return -ENOMEM; - } + + if (resctrl_is_mbm_enabled() && r->mon.mbm_cntr_assignable) { + tsize = sizeof(*d->cntr_cfg); + d->cntr_cfg = kcalloc(r->mon.num_mbm_cntrs, tsize, GFP_KERNEL); + if (!d->cntr_cfg) + goto cleanup; } return 0; +cleanup: + bitmap_free(d->rmid_busy_llc); + for_each_mbm_idx(idx) { + kfree(d->mbm_states[idx]); + d->mbm_states[idx] = NULL; + } + + return -ENOMEM; } int resctrl_online_ctrl_domain(struct rdt_resource *r, struct rdt_ctrl_domain *d) @@ -4144,7 +4303,7 @@ int resctrl_online_mon_domain(struct rdt_resource *r, struct rdt_mon_domain *d) RESCTRL_PICK_ANY_CPU); } - if (resctrl_arch_is_llc_occupancy_enabled()) + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID)) INIT_DELAYED_WORK(&d->cqm_limbo, cqm_handle_limbo); /* @@ -4219,7 +4378,7 @@ void resctrl_offline_cpu(unsigned int cpu) cancel_delayed_work(&d->mbm_over); mbm_setup_overflow_handler(d, 0, cpu); } - if (resctrl_arch_is_llc_occupancy_enabled() && + if (resctrl_is_mon_event_enabled(QOS_L3_OCCUP_EVENT_ID) && cpu == d->cqm_work_cpu && has_busy_rmid(d)) { cancel_delayed_work(&d->cqm_limbo); cqm_setup_limbo_handler(d, 0, cpu);\n\nindex 6fb4894b8cfd1f..a7d92718b653f5 100644\n\n--- a/\n\n+++ b/ diff --git a/include/linux/resctrl.h b/include/linux/resctrl.hindex 6fb4894b8cfd1f..a7d92718b653f5 100644--- a/ include/linux/resctrl.h +++ b/ include/linux/resctrl.h @@ -157,27 +157,42 @@ struct rdt_ctrl_domain { }; /** + * struct mbm_cntr_cfg - Assignable counter configuration. + * @evtid: MBM event to which the counter is assigned. Only valid + * if @rdtgroup is not NULL. + * @rdtgrp: resctrl group assigned to the counter. NULL if the + * counter is free. + */ +struct mbm_cntr_cfg { + enum resctrl_event_id evtid; + struct rdtgroup *rdtgrp; +}; + +/** * struct rdt_mon_domain - group of CPUs sharing a resctrl monitor resource * @hdr: common header for different domain types * @ci_id: cache info id for this domain * @rmid_busy_llc: bitmap of which limbo RMIDs are above threshold - * @mbm_total: saved state for MBM total bandwidth - * @mbm_local: saved state for MBM local bandwidth + * @mbm_states: Per-event pointer to the MBM event's saved state. + * An MBM event's state is an array of struct mbm_state + * indexed by RMID on x86 or combined CLOSID, RMID on Arm. * @mbm_over: worker to periodically read MBM h/w counters * @cqm_limbo: worker to periodically read CQM h/w counters * @mbm_work_cpu: worker CPU for MBM h/w counters * @cqm_work_cpu: worker CPU for CQM h/w counters + * @cntr_cfg: array of assignable counters' configuration (indexed + * by counter ID) */ struct rdt_mon_domain { struct rdt_domain_hdr hdr; unsigned int ci_id; unsigned long *rmid_busy_llc; - struct mbm_state *mbm_total; - struct mbm_state *mbm_local; + struct mbm_state *mbm_states[QOS_NUM_L3_MBM_EVENTS]; struct delayed_work mbm_over; struct delayed_work cqm_limbo; int mbm_work_cpu; int cqm_work_cpu; + struct mbm_cntr_cfg *cntr_cfg; }; /** @@ -256,39 +271,52 @@ enum resctrl_schema_fmt { }; /** + * struct resctrl_mon - Monitoring related data of a resctrl resource. + * @num_rmid: Number of RMIDs available. + * @mbm_cfg_mask: Memory transactions that can be tracked when bandwidth + * monitoring events can be configured. + * @num_mbm_cntrs: Number of assignable counters. + * @mbm_cntr_assignable:Is system capable of supporting counter assignment? + * @mbm_assign_on_mkdir:True if counters should automatically be assigned to MBM + * events of monitor groups created via mkdir. + */ +struct resctrl_mon { + int num_rmid; + unsigned int mbm_cfg_mask; + int num_mbm_cntrs; + bool mbm_cntr_assignable; + bool mbm_assign_on_mkdir; +}; + +/** * struct rdt_resource - attributes of a resctrl resource * @rid: The index of the resource * @alloc_capable: Is allocation available on this machine * @mon_capable: Is monitor feature available on this machine - * @num_rmid: Number of RMIDs available * @ctrl_scope: Scope of this resource for control functions * @mon_scope: Scope of this resource for monitor functions * @cache: Cache allocation related data * @membw: If the component has bandwidth controls, their properties. + * @mon: Monitoring related data. * @ctrl_domains: RCU list of all control domains for this resource * @mon_domains: RCU list of all monitor domains for this resource * @name: Name to use in \"schemata\" file. * @schema_fmt: Which format string and parser is used for this schema. - * @evt_list: List of monitoring events - * @mbm_cfg_mask: Bandwidth sources that can be tracked when bandwidth - * monitoring events can be configured. * @cdp_capable: Is the CDP feature available on this resource */ struct rdt_resource { int rid; bool alloc_capable; bool mon_capable; - int num_rmid; enum resctrl_scope ctrl_scope; enum resctrl_scope mon_scope; struct resctrl_cache cache; struct resctrl_membw membw; + struct resctrl_mon mon; struct list_head ctrl_domains; struct list_head mon_domains; char *name; enum resctrl_schema_fmt schema_fmt; - struct list_head evt_list; - unsigned int mbm_cfg_mask; bool cdp_capable; }; @@ -372,8 +400,29 @@ u32 resctrl_arch_get_num_closid(struct rdt_resource *r); u32 resctrl_arch_system_num_rmid_idx(void); int resctrl_arch_update_domains(struct rdt_resource *r, u32 closid); +void resctrl_enable_mon_event(enum resctrl_event_id eventid); + +bool resctrl_is_mon_event_enabled(enum resctrl_event_id eventid); + bool resctrl_arch_is_evt_configurable(enum resctrl_event_id evt); +static inline bool resctrl_is_mbm_event(enum resctrl_event_id eventid) +{ + return (eventid >= QOS_L3_MBM_TOTAL_EVENT_ID && + eventid <= QOS_L3_MBM_LOCAL_EVENT_ID); +} + +u32 resctrl_get_mon_evt_cfg(enum resctrl_event_id eventid); + +/* Iterate over all memory bandwidth events */ +#define for_each_mbm_event_id(eventid) \\ + for (eventid = QOS_L3_MBM_TOTAL_EVENT_ID; \\ + eventid <= QOS_L3_MBM_LOCAL_EVENT_ID; eventid++) + +/* Iterate over memory bandwidth arrays in domain structures */ +#define for_each_mbm_idx(idx) \\ + for (idx = 0; idx < QOS_NUM_L3_MBM_EVENTS; idx++) + /** * resctrl_arch_mon_event_config_write() - Write the config for an event. * @config_info: struct resctrl_mon_config_info describing the resource, domain @@ -416,6 +465,26 @@ static inline u32 resctrl_get_config_index(u32 closid, bool resctrl_arch_get_cdp_enabled(enum resctrl_res_level l); int resctrl_arch_set_cdp_enabled(enum resctrl_res_level l, bool enable); +/** + * resctrl_arch_mbm_cntr_assign_enabled() - Check if MBM counter assignment + * mode is enabled. + * @r: Pointer to the resource structure. + * + * Return: + * true if the assignment mode is enabled, false otherwise. + */ +bool resctrl_arch_mbm_cntr_assign_enabled(struct rdt_resource *r); + +/** + * resctrl_arch_mbm_cntr_assign_set() - Configure the MBM counter assignment mode. + * @r: Pointer to the resource structure. + * @enable: Set to true to enable, false to disable the assignment mode. + * + * Return: + * 0 on success, < 0 on error. + */ +int resctrl_arch_mbm_cntr_assign_set(struct rdt_resource *r, bool enable); + /* * Update the ctrl_val and apply this config right now. * Must be called on one of the domain's CPUs. @@ -528,6 +597,63 @@ void resctrl_arch_reset_rmid_all(struct rdt_resource *r, struct rdt_mon_domain * */ void resctrl_arch_reset_all_ctrls(struct rdt_resource *r); +/** + * resctrl_arch_config_cntr() - Configure the counter with its new RMID + * and event details. + * @r: Resource structure. + * @d: The domain in which counter with ID @cntr_id should be configured. + * @evtid: Monitoring event type (e.g., QOS_L3_MBM_TOTAL_EVENT_ID + * or QOS_L3_MBM_LOCAL_EVENT_ID). + * @rmid: RMID. + * @closid: CLOSID. + * @cntr_id: Counter ID to configure. + * @assign: True to assign the counter or update an existing assignment, + * false to unassign the counter. + * + * This can be called from any CPU. + */ +void resctrl_arch_config_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + enum resctrl_event_id evtid, u32 rmid, u32 closid, + u32 cntr_id, bool assign); + +/** + * resctrl_arch_cntr_read() - Read the event data corresponding to the counter ID + * assigned to the RMID, event pair for this resource + * and domain. + * @r: Resource that the counter should be read from. + * @d: Domain that the counter should be read from. + * @closid: CLOSID that matches the RMID. + * @rmid: The RMID to which @cntr_id is assigned. + * @cntr_id: The counter to read. + * @eventid: The MBM event to which @cntr_id is assigned. + * @val: Result of the counter read in bytes. + * + * Called on a CPU that belongs to domain @d when \"mbm_event\" mode is enabled. + * Called from a non-migrateable process context via smp_call_on_cpu() unless all + * CPUs are nohz_full, in which case it is called via IPI (smp_call_function_any()). + * + * Return: + * 0 on success, or -EIO, -EINVAL etc on error. + */ +int resctrl_arch_cntr_read(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 closid, u32 rmid, int cntr_id, + enum resctrl_event_id eventid, u64 *val); + +/** + * resctrl_arch_reset_cntr() - Reset any private state associated with counter ID. + * @r: The domain's resource. + * @d: The counter ID's domain. + * @closid: CLOSID that matches the RMID. + * @rmid: The RMID to which @cntr_id is assigned. + * @cntr_id: The counter to reset. + * @eventid: The MBM event to which @cntr_id is assigned. + * + * This can be called from any CPU. + */ +void resctrl_arch_reset_cntr(struct rdt_resource *r, struct rdt_mon_domain *d, + u32 closid, u32 rmid, int cntr_id, + enum resctrl_event_id eventid); + extern unsigned int resctrl_rmid_realloc_threshold; extern unsigned int resctrl_rmid_realloc_limit;\n\nindex a25fb9c4070d3c..acfe07860b346c 100644\n\n--- a/\n\n+++ b/ diff --git a/include/linux/resctrl_types.h b/include/linux/resctrl_types.hindex a25fb9c4070d3c..acfe07860b346c 100644--- a/ include/linux/resctrl_types.h +++ b/ include/linux/resctrl_types.h @@ -34,11 +34,18 @@ /* Max event bits supported */ #define MAX_EVT_CONFIG_BITS GENMASK(6, 0) -/* - * Event IDs, the values match those used to program IA32_QM_EVTSEL before - * reading IA32_QM_CTR on RDT systems. - */ +/* Number of memory transactions that an MBM event can be configured with */ +#define NUM_MBM_TRANSACTIONS 7 + +/* Event IDs */ enum resctrl_event_id { + /* Must match value of first event below */ + QOS_FIRST_EVENT = 0x01, + + /* + * These values match those used to program IA32_QM_EVTSEL before + * reading IA32_QM_CTR on RDT systems. + */ QOS_L3_OCCUP_EVENT_ID = 0x01, QOS_L3_MBM_TOTAL_EVENT_ID = 0x02, QOS_L3_MBM_LOCAL_EVENT_ID = 0x03, @@ -47,4 +54,7 @@ enum resctrl_event_id { QOS_NUM_EVENTS, }; +#define QOS_NUM_L3_MBM_EVENTS (QOS_L3_MBM_LOCAL_EVENT_ID - QOS_L3_MBM_TOTAL_EVENT_ID + 1) +#define MBM_STATE_IDX(evt) ((evt) - QOS_L3_MBM_TOTAL_EVENT_ID) + #endif /* __LINUX_RESCTRL_TYPES_H */",
      "source": "Kernel.org",
      "url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=2cb8eeaf00efc037988910de17ffe592b23941a6",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "中古パソコン販売のPCバル『Windows11乗り換え応援フェア』に限定商品続々登場! 人気の富士通LIFEBOOK Aシリーズ・Win11搭載15.6インチノートPCが19,800円で限定15台!!",
      "content": "株式会社バルテック（本社：東京都新宿区）のグループ会社、株式会社バルテックフィールドサービス（本社：東京都新宿区）が運営する中古パソコンの販売サイト「PCバル」（https://www.smaphodock24.jp/used/）では、2025年10月14日に控えたWindows10サポート終了を踏まえ、パソコンの乗り換えが必要なユーザー様に向け開催中の『Windows11乗り換え応援フェア』、好評のフェア限定商品に第３弾として、税込19,800円の富士通LIFEBOOK Aシリーズを15台追加!!\n\n限定15台・税込19,800円 富士通LIFEBOOK Aシリーズはこちら\n\n１． 全台システム要件適合・1,000台以上のWindows11搭載PC\n\nコスパ重視の第8世代からハイスペックの第12・第13世代まで幅広いラインナップのWindows11搭載中古パソコンをご用意!\n\nもちろんパソコン修理店が母体のPCバルならでは、独自の検査基準・項目に基づき状態をチェック後入念に整備しているので、安心してお使いいただけます!\n\nWindows11搭載中古ノートパソコン\n\nWindows11搭載中古デスクトップパソコン\n\n2． 乗り換えフェア限定・特別価格Windows11搭載中古パソコン\n\nさらに! 期間中はPCバルが特選した中古パソコンをフェア限定商品としてサプライズ価格で続々とご提供! PCバルは価格でも皆様のWindows11乗り換えを応援します!!\n\nWindow11乗り換え応援フェア限定商品はこちら\n\n新たに登場したフェア限定商品第3弾・ワンプライス19,800円でお届けする人気の富士通Aシリーズを限定15台!!\n\n新着・税込19,800円 富士通LIFEBOOK Aシリーズ 15.6インチはこちら\n\n☆第8世代Core i5＋8GBメモリで快適動作、実用性の高さが魅力の15.6インチPC\n\n大好評であっという間に売れたワンプライス18,150円のマウス製ノートPC・まだ少々在庫がありますので、こちらも要チェックで!\n\n残り僅か・税込18,150円 MOUSE MPro-NB391H-SSD 13.3インチ/MPro-NB510H 15.6インチ\n\n☆第8世代Core i5＋Mem8GB(1台だけ16GBモデルあり)＋SSD 240GB~1TB\n\n他にも多彩なフェア限定商品をご用意していますのでお見逃しなく! !\n\n税込22,222円 Lenovo ThinkPad X390 LTE 13.3 Intel Core i5-8265U 8GB\n\n☆コスパ最重視でWin11搭載PCを選ぶなら! 第8世代CPUで軽作業なら楽々♪\n\n税込54,321円 HP ELITE DRAGONFLY G2 Intel Core i5-1135G7 13.3 8GB\n\n☆第11世代CPU搭載、スタイリッシュなブルーが印象的な人気機種\n\n税込67,890円 DELL Inspiron 5415 14 AMD Ryzen 7-5700U 8GB\n\n☆高いマルチコア性能でクリエイティブワークの強い味方・RYZEN 7搭載！\n\n第8世代X1カーボンや第10世代LIFEBOOK Uシリーズなど他にも人気機種をサプライズ価格でご用意しておりますが、いずれも数に限りがありますので、ぜひお早めに!\n\n3． 選べる2つの特典で乗り換え応援!\n\n期間中にフェア限定商品をご成約の方には、MS Officeと高い互換性なのにリーズナブルな価格で人気のキングソフト製定番オフィスソフト『WPS Office 2 Standard Edition』をもれなくプレゼント!\n\nさらに、PCバル各店とWEBSHOPでそれぞれ特典をご用意!\n\n【PCバル各店店頭でのご購入】\n\nPCバル各店店頭でフェア限定商品をご購入のお客様には、今お使いのパソコンからデータのお引越し(データ移行)を、通常の50%OFFでご提供!\n\n大事なデータがあるからパソコンを換えるのは抵抗が…という心配はご無用です。\n\nご希望のお客様は店頭ご購入時に店頭でお申し付けください。\n\n【PCバルWEBSHOPでのご購入】\n\nPCバルWEBSHOP でフェア限定商品をご購入のお客様には、WPS Office 2に加え、ウイルス＆フィッシング対策・システムメンテナンスを1つでこなす『セキュリティPro』(キングソフト製)をプレゼント!\n\n■「PCバル」3つの安心\n\n（https://www.smaphodock24.jp/used/）\n\n１．専門店ならではのこだわり\n\n取扱商品は仕入れ後にパソコン整備士の資格を持ったスタッフが、独自の検査基準・項目に基づき状態をチェック後入念に整備。長く使える・故障の少ない状態でお届けできるようメンテナンスした上で販売しています。安定性と体感速度に影響するコンポーネンツはSSD＋RAMメモリ8GB以上を標準構成※とし、プロが手掛けたリフレッシュPCとして高度化・高速化するパソコンの使用環境に対応しお客様満足度の向上を目指しています。\n\n※一部標準構成外の商品もございます。\n\n２．お客様に寄り添った情報掲載・商品説明\n\n写真と説明だけで選ぶネットの商品でも安心してお選びいただけるよう、スペック情報だけでなく「動作には問題ないものの、細かなキズや使用感がある部分など…」といった状態も丁寧にご案内しています。\n\n店頭展示品についても、スタッフが実物をご案内しながら、納得いただけるようわかりやすくご説明しています。\n\n３．安心保証&充実サポート\n\n購入時から最大6ヶ月間の保証※が中古PCに付いてくる！パソコン修理専門店を10年以上全国に展開するPCバルならではの修理技術が可能にする手厚いサポートです。保証期間内中の修理ではお客様の費用負担はゼロ(適用条件あり)！ 保証期間終了後に故障が発生した場合でも、症状状態ご予算に応じ当社の技術スタッフが最善のご提案を致します。\n\n※中古PCの保証適用条件はWEB保証書へのアクセスまたは(紙)保証書でご確認ください。\n\n※商品により保証期間が異なります。詳しくは各商品ページをご確認ください。\n\n◆会社概要\n\n□株式会社バルテック\n\n事業内容：ICT機器及びソフトウェアの開発・製造・管理\n\n設立： 1993年3月23日\n\n所在地：〒163-1103 東京都新宿区西新宿6-22-1 新宿スクエアタワー3階\n\nURL：https://www.webjapan.co.jp/\n\n□株式会社バルテックフィールドサービス\n\n事業内容：ICT機器及びソフトウェアの施工、保守、修理\n\nパソコン修理サービス店のフランチャイズ展開\n\nURL：https://www.smaphodock24.jp/",
      "source": "Prtimes.jp",
      "url": "https://prtimes.jp/main/html/rd/p/000000787.000008585.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Dell Ryzen 7 Laptop Bundle Crashes to 64% Off, Loaded With Freebies and Likely Gone Before October Prime Day",
      "content": "If you happen to be on the hunt for a new laptop, whether that’s because you’re a student in need of something to complete assignments, a small business owner looking to handle your business needs, or just some guy looking to watch YouTube and draw pictures, come check out the Dell Inspiron 15. This laptop has a touchscreen and is bundled with some bonus accessories. The Amazon listing has the full price set at $2,200, but the limited time deal indicates its been marked down by 64% to just $800. Some quick napkin math will tell you that’s a $1,400 discount.\n\nYou might be thinking that’s absolutely ridiculous. How can this laptop be on sale for that much off? Well, you’re right to be suspicious. When we look at this bundle’s price history, we can see it has only existed on Amazon for about a month. After first being listed, it immediately dropped in price and it’s mostly been at that $800 amount since.\n\nSee at Amazon\n\nLots of sellers on Amazon will artificially inflate the list price so that when they mark it down, the sale looks enormous. Even if we go to Dell’s website, we’ll find versions of this model laptop going for about the same as you find it here. All that said, this is a pretty good value.\n\nWhat you’re getting is a 15.6-inch touchscreen laptop that’s powered by the AMD Ryzen 7 7730U. With that we also have an integrated graphics card, 32GB of memory, and a full 1TB of internal storage on its SSD. This laptop is designed to be able to take on school, work, entertainment, and any other sort of everyday task an average user might encounter — and it’s got the specs to support that.\n\nThe screen’s touch controls allow you to operate the laptop as if it’s a tablet, choosing to use pinch, zoom, and swipe gestures like you would on a mobile device. It has a resolution of 1080p and uses an anti-glare coating to help minimize reflections, making for more comfortable viewing in bright settings.\n\nBonus Gifts Included\n\nAlong with the laptop, you also get a number of free accessories. This Dell Inspiron 15 comes with a stylus pen to be used on the touchscreen, a cleaning clothe, a laptop sleeve for traveling, a USB flash drive with 128GB on it, as well as some port covers and webcam covers. Plus, the laptop comes pre-installed with Windows 11 Pro.\n\nRight now, you can get the Dell Inspiron 15 and all these goodies for just $800.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/dell-ryzen-7-laptop-bundle-crashes-to-64-off-loaded-with-freebies-and-likely-gone-before-october-prime-day-2000629976",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "IREN (IREN) Doubles GPU Fleet to 23,000, Raises Revenue Target",
      "content": "IREN Limited (NASDAQ:IREN) is one of the best performing ASX stocks in 2025. On September 22, the company said it had doubled its GPU fleet to 23,000 units after acquiring 12,400 more GPUs for about $674 million. The expanded fleet now includes a mix of NVIDIA H100s & H200s (1,900), NVIDIA B200s & B300s (19,100), NVIDIA GB300s (1,200), and AMD MI350Xs (1,100).\n\nIREN (IREN) Doubles GPU Fleet to 23,000, Raises Revenue Target\n\nIREN raised its annualized run-rate revenue (ARR) target for its AI Cloud segment to more than $500 million by the end of Q1 2026. The company previously targeted 10,900 GPUs by year-end, but strong market demand led to a larger fleet and a higher ARR goal. It now plans to support up to 60,000 GPUs, especially at its British Columbia sites.\n\nThe management expects that the GPU investments will bolster long-term revenue and improve operational efficiency. It is particularly banking on the Blackwell architecture, which offers improvements in AI performance and energy efficiency. Deliveries and deployment will occur at the Prince George campus and other facilities in British Columbia.\n\nIREN Limited (NASDAQ:IREN) is a sustainable Bitcoin mining and AI infrastructure company. It develops and operates large-scale data centers powered by renewable energy, with major facilities in Texas and British Columbia. Its main products are mined bitcoin and high-performance AI cloud services.\n\nWhile we acknowledge the potential of IREN as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: Conservative Stock Portfolio: 11 Best Stocks to Buy Now and 10 Best Performing Penny Stocks to Buy Now.\n\nDisclosure: None. This article is originally published at Insider Monkey.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/iren-iren-doubles-gpu-fleet-190126547.html",
      "timestamp": "2025-09-30"
    }
  ],
  "Intel": [
    {
      "headline": "I used a business laptop for gaming for a week, and now it’s my 1-stop device for travel",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/i-used-a-business-laptop-for-gaming-for-a-week/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "What are your CPU's PL1, PL2, and other power limits?",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/understading-cpu-pl1-pl2-power-limits/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Trump’s tariff‑shaped stick can’t beat reality on US chip fabbing",
      "content": "Comment Ending America's reliance on foreign chip fabs remains a high priority for Uncle Sam, but the Trump administration's \"my way or the highway\" approach to the issue threatens to do more harm than good.\n\nWhere the Biden administration sought to use federal subsidies and tax breaks as a carrot to encourage investment in domestic chip production, the current administration's philosophy can best be described as a stick wielded by a capricious bully, unconcerned whether or not his demands can be met, only that concessions are made.\n\nIn some respects, it reflects a modern economic take on Roosevelt's Big Stick ideology, only Trump seems to have ignored the speaking softly bit and jumped straight to swinging his stick like every problem is a piñata with candy inside. Trump need not even swing his stick – all he has to do is make a threat, and those in its path scramble to appease him. And whether you agree with this approach, as life-alteringly disruptive as they might be, he has been effective at getting US companies to bend to his will.\n\nLast month, the US claimed a 10 percent stake in Intel. The $8.9 billion equity deal drew on previously awarded but unpaid CHIPS Act funds, along with the Secure Enclave program. The congressionally-approved funds had already been awarded to the x86 giant, but only a fraction of them had been distributed when Trump took office.\n\nIn March, the threat of massive chip tariffs drove Taiwan Semiconductor Manufacturing Co. (TSMC) to bolster its investment in US manufacturing to the tune of $165 billion. Many months later, the White House still hasn't pulled the trigger on said tariffs.\n\nHowever, as the Wall Street Journal reported on Friday, that could soon change. The Commerce Department is reportedly weighing whether to require US tech companies to manufacture one chip in the US for every chip imported, or pay a tariff. That tariff, Trump warned last month, could be as much as 100%.\n\nCommerce Secretary Howard Lutnick is said to have discussed the idea with industry executives, arguing the measures may be necessary to maintain the US' economic security.\n\nBy some estimates, 90 percent of leading-edge silicon is manufactured by TSMC. The vast majority of that comes from fabs in Taiwan, an island whose sovereignty is a controversial subject for its neighbor 80 miles to the west. US government officials have warned for years that China could exploit the world's continued reliance on Taiwan.\n\nHowever, achieving a 1:1 ratio of chip production to imports may be harder than the White House might think.\n\nTSMC's US build out won't change the calculus much — at least not before Trump's second term expires. Building a leading-edge wafer fab takes years. TSMC's first Arizona foundry site was announced amid the 2020 election, and only this year began ramping up production.\n\nIt's estimated that, when all is said and done, about 30 percent of TSMC's 2nm and smaller fab capacity will eventually be centered in the US, but it'll be years before that happens.\n\nIntel could pick up some of the slack in the meantime. Its new Arizona fabs are already in production, with its first generation of chips based on Intel 18A, a 2nm-class process node. It certainly wouldn't be surprising to see the White House drive potential foundry customers into Intel's arms now that it's a stakeholder in the company's success.\n\nThe problem is it takes years and hundreds of millions of dollars to tape out a chip on a new process node. Companies already evaluating 18A or Intel's forthcoming 14A process tech may be able to move a bit faster, but there are still a lot of ifs. Intel needs to have the capacity to take on new customers, and its fabs will need to achieve high enough yields, or a move could end up costing fab customers more than simply paying the tariffs.\n\nIntel is currently in the process of clawing back products previously outsourced to TSMC, and as such it stands to benefit the most, or perhaps suffer the least, from the reported policy change.\n\nApple, Nvidia, and AMD have insulated themselves to some degree, announcing plans to manufacture chips at TSMC's Fab 21 wafer plant in Arizona. To what extent, however, they haven't said.\n\nFor everyone else who hasn't already signed large-scale commitments with TSMC for domestic fab capacity, avoiding the semi-tariffs will be nearly impossible for the remainder of Trump's second term. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/28/trump_1_1_chip_rule_too_late/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Linux Kernel 6.17 Released, This is What’s New",
      "content": "EXT4 filesystem boosts – and changes to help SSDs last longer\n\nLinus Torvalds has announced the release of Linux kernel 6.17, an update that brings improved hardware support and a number of core system improvements.\n\nThe new kernel provides graphic drivers for the latest Intel ‘Panther Lake’ laptops, better power management features for devices with AMD hybrid GPUs, resolves a software bug that’s been knocking around since 1993, and helps SSDs last longer.\n\nAnnouncing the release on the Linux Kernel Mailing List (LKML), Linus Torvalds says: “No huge surprises this past week, so here we are, with kernel 6.17 pushed out and ready to go.”\n\nUbuntu 25.10 ships wit the new kernel, including in the beta build that was released last week. Users on the current long-term support release, Ubuntu 24.04 LTS, will receive kernel 6.17 as part of the next hardware enablement (HWE) update in early 2026.\n\nIs this kernel a solid upgrade? You know it is! For a whip through the new features in Linux 6.17 which caught my eye, read on.\n\nLinux 6.17: What’s New?\n\nGraphics & Gaming\n\nAlienware’s ‘boost’ key (top row) gets a standardised keycode\n\nThe first Core Ultra Series 3 laptops powered by Intel ‘Panther Lake’ chips are due to go on sale soon, so it’s timely that Intel Xe3 integrated graphics are enabled by default in Linux 6.17. This ensures anyone bagging a new model and installing Ubuntu 25.10 gets solid graphics performance off the bat.\n\nSmartMux in 6.17 will switch between integrated and discrete graphics on AMD laptops\n\nFor those using laptops equipped with Core Ultra Series 2 (‘Lunar Lake’) chips, the Intel IPU7 driver has proper web camera support. Ideal for online meetings, social chats and accidental jump-scares when launching the camera app by accident.\n\nAMD hybrid GPU laptops gain SmartMux support with Linux 6.17. This auto-switches between integrated and discrete graphics based on workload to (obviously) save power or deliver maximum performance if needed.\n\nLenovo WMI Gaming Series Drivers add support for both Legion Go and the SteamOS-powered Legion Go S handheld, which will be especially handy for those looking to run other kinds of Linux-based operating systems on the AMD-powered handheld.\n\nThe kernel also standardises the keycode used by the (mysterious) “performance boost” key on newer Dell and Alienware laptops, and the (rather frutiger aero-looking) Flydigi Apex 5 game controller now has proper support on Linux — nice!\n\nOn a tangentially gaming-related note, the networking stack adds DualPI2 congestion control support. This helps to reduce network queue latency, which should prove beneficial for online gaming, streaming, video calls, and other real-time applications.\n\nFilesystem changes\n\nKernel write changes may help SSDs last longer\n\nThere are many filesystems improvements in 6.17 that will be directly appreciable by those of us running a desktop Linux distribution (not just the one this site is named after, either).\n\nUbuntu’s default file system is EXT4, and Linux 6.17 sees major performance boosts\n\nPerhaps most significant: the kernel can now write zeroes efficiently without actual I/O operations on NVMe SSDs that support the DEAC bit, and SCSI SSDs which support the UMMAP bit (a ‘bit’ is a kind of indicator of a feature state).\n\nThe FALLOC_FL_WRITE_ZEROES option for fallocate() will mark storage regions as zero-filled internally on modern SSDs. This will improve performance and reduce wear (SSDs theoretically have finite read/write lifespans, so fewer writes = lasts longer).\n\nUbuntu’s default filesystem EXT4 improves block allocation scalability. Per benchmarks, this provides noticeable performance benefits under I/O heavy tasks like querying databases or copying large numbers of files.\n\nBtrfs adds experimental large-folio support, which reduces memory management overhead when handling large files. This, combined with compression control during defragmentation, makes Btrfs better suited to performance-sensitive workloads.\n\nEROFS supports metadata compression and faster directory reading, which should prove especially handy on systems with read-only root filesystems or in container-heavy workloads. There’s no Bcachefs in the 6.17 merge reports…\n\nLaptop Support\n\nMacBook Pro touchbar becoming ever-more-functional in Linux\n\nLinux support on M1 and M2 Macs continues to improve in Linux 6.17, with the Apple Silicon SMC driver enabling ‘proper’ rebooting of M1 and M2 Macs. With work to run Linux on M3 and M4 Macs in limbo, it’s nice earlier gens are improving their mainline support.\n\nThe Touch Bar on Intel-based MacBook Pros see further improvements in Linux 6.17 with patches to enable touch screen input, albeit with a few lingering quirks. Apple ends support for Intel-based Macs after macOS 26, so Linux will give those devices a new lease of life.\n\nElsewhere, Linux 6.17 brings mainline support for ASUS Zenbook A14 Snapdragon X1 Plus/Elite laptops, allowing more Linux distributions to run on these ARM-based Windows devices. There’s also mainline support for Raspberry Pi 5’s RP1 I/O chip.\n\nGot a keyboard with F13-F24 keys? Those are now properly mapped in Linux 6.17\n\nSupport for Corsair HX1200i PSU monitoring (2025 model) is present; wake-on-touch support added to the Intel Touch Host Controller (along with overlay objects support, great for tablet and 2-in-1 users); and kernel mapping for F13 – F24 keys on PS/2 keyboards.\n\nYes, keyboards with an addition 12 function keys actually exist!\n\nHD Audio support is extended to cover the Framework Laptop 13 with AMD Ryzen AI 300, commercial ASUS laptops using CS35L41 HDA, and HP EliteBook models. USB audio offloading (a feature in Linux 6.xx) covers more mobile devices, including Fairphone 4.\n\nCore kernel changes\n\nNew Attack Vector Controls have been integrated to simplify security handling for known CPU vulnerabilities, such as Spectre and Meltdown. Previously, each mitigation had its own kernel command-line option. In 6.17, there’s a unified option.\n\nMaking it easier for Linux server admins (and others) to disable unneeded protections may help them claw back performance dips certain mitigations require as well make it easier to manage the growing number of hardware vulnerability bandaids.\n\nSupport for uniprocessor configuration has been removed from the kernel scheduler. Every machine, even those which run on a single-core processor will now ‘unconditionally’ run a kernel designed for multicore systems.\n\nThis shouldn’t lead to any detrimental impact on single-core systems (not that many folks likely run one full-time in 2025), but adopting a unified scheduling approach across all CPUs should reduce code and make kernel behaviour more reliable.\n\nSpeed Boosts?\n\nLinux 6.17 picks up initial proxy execution support. This new kernel feature may speed up apps by preventing slowdowns when a high-priority application is waiting for a resource, the system temporarily gives the resource holder a boost, causing it to finish and release the resource faster.\n\nA new kernel feature could speed up apps by preventing slowdowns when high-priority tasks are waiting for a resource\n\nOr to word it the way kernel devs would, this resolves “priority-inversion problems” by enabling “high-priority tasks waiting for locks to donate execution context to lock holders”, which reduces latency spikes — slowdowns — in desktop apps.\n\nMemory management sees various optimisations across the kernel subsystems, notable with improved futex performance for heavily threaded applications (and more reliable crash kernel handling for debugging when things go wrong).\n\nAMD’s Hardware Feedback Interface (HFI) was added. Modern processors mix two types of cores: performance and efficiency. On AMD, HFI gives the kernel info to help it decide which core is better suited to which tasks, improving performance and power management.\n\nWeird Stuff\n\nLinux 6.17 removes the Pktcdvd packet-writing optical driver. It was deprecated in 2016, survived a removal attempt in 2023, but now, in 2025 optical packet-writing is definitively done and dusted! A loss for those who liked it, but a curio for those who’d never heard of it…\n\nThere’s also a bug fix for a kernel limitation dating back to 1993. It’s related to ELF program header handling that causes some applications in certain conditions to bug out. After 30 years, someone has finally bothered to fix it properly.\n\nOther Changes:\n\nBeyond the highlights above, some other notable changes in Linux 6.17:\n\nBPF subsystem adds standard string operations\n\nBPF programs have output and error streams for userspace communication\n\nExtended attributes support for pidfds\n\nNew DAMON_STAT kernel module for simplified memory activity monitoring\n\nTCP stack now enforces receive window limits more strictly\n\nASoC adds AMD ACP7.2 platform support\n\nKernel live patch support on 64-bit ARM\n\nTurbostat utility gains L3 cache topology display\n\nFor more detail on the release as whole read through the comprehensive merge report recaps (first half & second half) put out by the folks at LWN, or sift through the thousands of kernel commits on GitHub (grab a coffee before doing that, eh).\n\nUpgrade to Linux 6.17\n\nLinux 6.17 is available for download from kernel.org as source, but you will need to compile that source code by hand to make use of it — not for the faint of heart!\n\nUbuntu 25.10 includes Linux 6.17 by default, and the release will be back-ported to Ubuntu 24.04 LTS users in early 2026.\n\nIt will not be packaged for and uploaded to Ubuntu repositories for other supported releases officially, but it is possible to make use of Canonical Mainline DEBs or third-party PPAs unofficially — not without caveats, however.\n\nInstalling newer Linux kernels on Ubuntu from outside of the main repos comes with no guarantees and no support. They may lack Ubuntu-specific patches and drivers, not work in with some hardware or lack feature integrations.",
      "source": "Omgubuntu.co.uk",
      "url": "https://www.omgubuntu.co.uk/2025/09/linux-kernel-6-17-new-features",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Linux 6.17 Released: Intel Panther Lake Xe3 Graphics Ready, New Optimizations",
      "content": "As expected, Linus Torvalds just released the Linux 6.17 kernel on-schedule as the kernel version powering Ubuntu 25.10, Fedora 43, and other upcoming Linux distribution releases and rolling releases. Linux 6.17 delivers many exciting improvements including Attack Vector Controls, Intel Panther Lake Xe3 graphics declared stable, various Intel graphics driver improvements for Project Battlematrix, mainline Raspberry Pi RP1 support, the Intel IPU7 driver, EXT4 scalability improvements, various other performance optimizations, and much more\n\nLinux 6.17 is running very well in my testing thus far. It's a solid release and showing some nice performance improvements Linux 6.17 stable can be downloaded at kernel.org . Now onward to the Linux 6.18 merge window with many features expected for Linux 6.18",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.17-Released",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Multiple Injured in Michigan LDS Church Shooting",
      "content": "Play video content Broadcastify.com\n\n11:06 AM PT -- Police have revealed some details about the deadly attack on a Mormon church in Michigan ... claiming a 40-year-old suspect drove his vehicle through the front door of the church before firing shots from an assault rifle at hundreds of people attending a service. As of the most recent press conference, 1 person is confirmed dead, 9 others were injured.\n\nGrand Blanc Township Police Chief William Renye also said they believe this suspect started the fire at the church ... though the motive for this is unknown.\n\nChief Reyne says authorities think it's possible people near the fire were unable to escape the blaze -- and, they expect to find additional victims as the day goes on.\n\nMultiple people have been killed and injured in an active shooting at the Church of Jesus Christ of Latter-day Saints in Michigan on Sunday.\n\nNEW: Mormon church in Michigan is on fire following an active shooter incident, leaving multiple victims.\n\n\n\nThe incident happened at the Church of Jesus Christ of Latter-day Saints in Grand Blanc.\n\n\n\nThe shooter is reportedly down.pic.twitter.com/lmKdUIoeIv — Collin Rugg (@CollinRugg) September 28, 2025 @CollinRugg\n\nThe shooter is down, and the church is on fire, the Grand Blanc Township Police Department confirmed. Police have asked the public avoid the area and has established reunification sites. There is no further threat at this time.\n\nAt least two person has been confirmed dead after the shooting, according to authorities.\n\nDispatchers can be heard ordering a water supply to the building in audio obtained by TMZ as they rush to save the structure.\n\nBREAKING: Video shows church on fire as officials respond to active shooter with multiple victims at The Church of Jesus Christ of Latter-day Saints in Grand Blanc, Michigan. pic.twitter.com/pQDd0UZPEu — AZ Intel (@AZ_Intel_) September 28, 2025 @AZ_Intel_\n\nAt one point, an individual can be heard warning about \"heavy fire\" as other crews are confirmed to be assisting with the blaze.",
      "source": "TMZ",
      "url": "https://www.tmz.com/2025/09/28/michigan-lds-church-shooting-fire/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Nvidia’s $100 billion OpenAI investment raises eyebrows and a key question: How much of the AI boom is just Nvidia’s cash being recycled?",
      "content": "Two of the most prominent examples of Nvidia’s web of circuitous investments are OpenAI and Coreweave. In addition to the latest investment in OpenAI, Nvidia had previously participated in a $6.6 billion investment round in the fast-growing AI company in October 2024. Nvidia also has invested in CoreWeave, which supplies data center capacity to OpenAI and is also an Nvidia customer. As of the end of June, Nvidia owned about 7% of Coreweave, a stake worth about $3 billion currently. The benefits that companies get from a Nvidia investment extend beyond the cash itself. Nvidia’s equity stakes in companies such as OpenAI and Coreweave enable these companies to access debt financing for data center projects at potentially significantly lower interest rates than they would be able to access without such backing. Jay Goldberg, an analyst with Seaport Global Securities, compares such deals to someone asking their parents to be a co-signer on their mortgage. It gives lenders some assurance that they may actually get their money back.\n\nIn addition, there are so many interlocking rings of circularity—where Nvidia has invested in a company, such as OpenAI, that in turn purchases services from a cloud service provider that Nvidia has also invested in, which then also buys or leases GPUs from Nvidia—that disentangling what money is flowing where is far from easy.\n\nThe extent to which the entire AI boom is backstopped by Nvidia’s cash isn’t easy to answer precisely, which is also one of the unsettling things about it. The company has struck a number of investment and financing deals, many of which are too small individually for the company to consider “material” and report in its financial filings, even though collectively they may be significant.\n\nIn past technology bubbles, revenue “roundtripping” and tech companies financing their own customers have exacerbated the damage when those bubbles eventually popped. While the share of Nvidia’s revenues that are currently being driven by such financing appears to be relatively small, the company’s dominance as the world’s most valuable publicly-traded company means that its stock is “priced for perfection” and that even minor missteps could have outsized impact on its valuation—and on financial markets and perhaps even the wider economy.\n\nWhile Nvidia’s latest announcement is by far the largest example, the AI chipmaker has engaged in a series of “circular” deals in which it invests in, or lends money to, its own customers. Vendor financing exists to some degree in many industries, but in this case, circular transactions may give investors an inflated perception of the true demand for AI.\n\nNvidia’s announcement earlier this week that it is investing $100 billion into OpenAI to help fund its massive data center build out has added to a growing sense of unease among investors that there is a dangerous financial bubble around AI, and that the revenues and earnings math underpinning the valuations of both public and private companies in the sector just doesn’t add up.\n\n繼續閱讀\n\nStartups financing data centers have often had to borrow money at rates as high as 15%, compared to 6% to 9% that a large, established corporation such as Microsoft might have to pay. With Nvidia’s backing, OpenAI and Coreweave have been able to borrow at rates closer to what Microsoft or Google might pay.\n\n\n\nNvidia has also signed a $6.3 billion deal to purchase any cloud capacity that CoreWeave can’t sell to others. The chipmaker had previously agreed to spend $1.3 billion over four years on cloud computing with CoreWeave. Coreweave, meanwhile, has purchased at least 250,000 Nvidia GPUs so far—the majority of which it says are H100 Hopper models, which cost about $30,000 each—which means Coreweave has spent about $7.5 billion buying these chips from Nvidia. So in essence, all of the money Nvidia has invested in Coreweave has come back to it in the form of revenue.\n\n\n\nNvidia has struck similar cloud computing deals with other so-called “neo-cloud” companies. According to a story in The Information, Nvidia agreed this summer to spend $1.3 billion over four years renting some 10,000 of its own AI chips from Lambda, which like Coreweave runs data centers, as well as a separate $200 million deal to rent some 8,000 more over an unspecified time period.\n\nFor those who believe there’s an AI bubble, the Lambda deal is clear evidence of froth. Those Nvidia chips Lambda is renting time on back to Nvidia? It bought them with borrowed money collateralized by the value of the GPUs themselves.\n\n\n\nBesides its large investments in OpenAI and Coreweave, AI chipmaker also holds multi-million dollar stakes in several other publicly-traded companies that either purchase its GPUs or work on related chip technology. These include chip design firm Arm, high-performance computing company Applied Digital, cloud services company Nebius Group, and biotech company Recursion Pharmaceuticals. (Nvidia also recently purchased a 4% stake in Intel for $5 billion. Like Arm, Intel makes chips that in some cases are alternatives to Nvidia’s GPUs, but which for the most part are complementary to them.)\n\nEarlier this month, Nvidia also pledged to invest £2 billion ($2.7 billion) in U.K. AI startups, including at least £500 million in Nscale, a U.K.-based data center operator that will, presumably, be using some of that money to purchase Nvidia GPUs to provision the data centers it is building. Nvidia also said it would invest in a number of British startups, both directly and through local venture capital firms, and some of that money too, will likely come back to OpenAI in the form of computing purchases, either directly, or through cloud service providers, who in turn will need to buy Nvidia GPUs.\n\n\n\nIn 2024, Nvidia invested about $1 billion in AI startups globally either directly or through its corporate venture capital arm NVentures, according to data from Dealroom and The Financial Times. This amount was up significantly from what Nvidia invested in 2022, the year the generative AI boom kicked off with OpenAI’s debut of ChatGPT.\n\n\n\nHow much of this money winds up coming right back to Nvidia in the form of sales is again, difficult to determine. Wall Street research firm NewStreet Research has estimated that for every $10 billion Nvidia invests in OpenAI, it will see $35 billion worth of GPU purchases or GPU lease payments, an amount equal to about 27% of its annual revenues last fiscal year.\n\nEchoes of the dotcom era\n\nThat kind of return would certainly make this sort of customer financing worthwhile. But it does raise concerns among analysts about a bubble in AI valuations. These kinds of circular deals have been a hallmark of previous technology bubbles and have often come back to haunt investors.\n\nIn this case, the lease arrangements that Nvidia is entering into with OpenAI as part of its latest investment could prove problematic. By leasing GPUs to OpenAI, rather than requiring them to buy the chips outright, Nvidia is sparing OpenAI from having to take an accounting charge for the high depreciation rates on the chips, which will ultimately help OpenAI’s bottom line. But it means that instead Nvidia will have to bear this depreciation costs. What’s more, Nvidia will also take on the risk of being stuck with an inventory of GPUs no one wants if demand for AI workloads don’t match Nvidia CEO Jensen Huang’s rosy predictions.\n\n\n\nTo some market watchers, Nvidia’s latest deals feel all-too-similar to the excesses of past technology booms. During the dot com bubble at the turn of the 21st Century, telecom equipment makers such as Nortel, Lucent, and Cisco lent money to startups and telecom companies to purchase their equipment. Just before the bubble burst in 2001, the amount of financing Cisco and Nortel had extended to their customers exceeded 10% of annual revenues, and the amount of financing the top five telecom equipment makers had provided to customers exceeded 123% of their combined earnings.\n\n\n\nUltimately, the amount of fiber-optic cabling and switching equipment installed far exceeded demand, and when the bubble burst and many of those customers went bust, the telecom equipment makers were left holding the bad debt on their balance sheets. This contributed to a greater loss of value when the bubble burst than would have otherwise been the case, with networking equipment businesses losing more than 90% of their value over the ensuing decade.\n\n\n\nWorse yet were companies such as fiber-optic giant Global Crossing that engaged in direct “revenue roundtripping.” These companies cut deals—often at the end of a quarter in order to hit topline forecasts—in which they paid money to another company for services, and then that company agreed to purchase equipment of exactly equal value. When the bubble burst, Global Crossing went bankrupt, and its executives ultimately paid large legal settlements related to revenue roundtripping.\n\n\n\nIt is memories of these kinds of transactions that have caused analysts to at least raise an eyebrow at some of Nvidia’s circular investments. Goldberg, the Seaport Global analyst, said the deals had a whiff of circular financing and were emblematic of “bubble-like behavior.”\n\n“The action will clearly fuel ‘circular’ concerns,” Stacy Rasgon, an analyst with Bernstein Research, wrote in an investor note following Nvidia’s announcement of its blockbuster investment in OpenAI. It’s a long way from a concern to a crisis, of course, but as AI company valuations get higher, that distance is starting to close.\n\nThis story was originally featured on Fortune.com",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/nvidia-100-billion-openai-investment-110000256.html",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Actual ports and NVIDIA GPUs make this laptop the practical Dell XPS and MacBook Pro alternative",
      "content": "The Lenovo Yoga Pro 9i is the premium, feature-packed 16-inch powerhouse for those who need to work, create, and even game on the go. It's an excellent, incredibly practical laptop that feels like the more reasonable alternative to the divisive Dell 16 Premium (previously the Dell XPS 16). I only wish battery life was better, but I can't say I'm shocked it's not.\n\nWhy you can trust Windows Central Our expert reviewers spend hours testing and comparing products and services so you can choose the best for you. Find out more about how we test.\n\nCreators, engineers, and other professionals the world over rely on powerful 16-inch laptops to keep them working smoothly, even while staying mobile. The Dell XPS 16 (now the Dell 16 Premium), the Apple MacBook Pro 16, the Razer Blade 16 — these are all great choices, but there's another excellent alternative on the block.\n\nThis is the Lenovo Yoga Pro 9i 16 (Gen 10) Aura Edition... which is a ridiculously long name for an incredibly capable laptop with a practical design, potent performance, and an impressive set of features that make it well-suited to almost any task.\n\nIt's also well priced compared to the aforementioned competition, making it one of the easiest to recommend. While other laptops often focus on sleek and minimalist designs (often at the expense of features or practicality), the Yoga Pro 9i doesn't cut any corners — or ports.\n\nDisclaimer This review was made possible thanks to a review sample provided by Lenovo. Lenovo had no input nor saw the contents of this review prior to publication.\n\nMy Yoga Pro 9i 16 (Gen 10) review\n\nImage 1 of 4 The clean Lenovo logo and \"communications bar\" are in full display with this laptop. (Image credit: Windows Central | Zachary Boddy) Most people would be content with just the ports on one side. (Image credit: Windows Central | Zachary Boddy) I'd prefer swapping one of those Type-A ports for a Thunderbolt 4 port on the other side, but this is a great I/O selection either way. (Image credit: Windows Central | Zachary Boddy) These aren't the slimmest bezels on the block, but the Yoga Pro 9i still feels plenty premium. (Image credit: Windows Central | Zachary Boddy)\n\nDesign ⭐⭐⭐⭐½\n\nWhere the Dell 16 Premium (2025) we recently reviewed boasts a controversial, futuristic, and minimalist design, the Lenovo Yoga Pro 9i absolutely prioritizes function over form.\n\nIt's a familiar two-tier Lenovo design with a rounded base and squared-off lid, creating a unique profile entirely constructed of high-quality aluminum. The Yoga Pro 9i isn't the most refined high-end laptop I've held in my hand and doesn't feature the slimmest display bezel, but it absolutely looks and feels like a premium product.\n\nYou can immediately tell the Yoga Pro 9i is a truly premium laptop, even if it's not the most futuristic design.\n\nAt around 17.9mm thick and 1.93kg heavy, there are certainly beefier 16-inch workstations, but the Yoga Pro 9i's design does make it seem chunkier than it actually is.\n\nAt least you get a ton of ports. There's the 170W DC power port, an HDMI 2.1 port, two full-featured Thunderbolt 4 ports with Power Delivery and DisplayPort functions, a 3.5mm audio jack, two USB Type-A (5GBps) ports, a side-mounted power button, a webcam privacy shutter, and even a full-sized SD card slot. The only things missing are an Ethernet port (Lenovo would've had to make this laptop a fair bit thicker for that) and a Kensington Nano Security Slot, which may actually disappoint some professional users.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nI really wish Lenovo had sent me a model with the Tandem OLED panel, but this is still an excellent display. (Image credit: Windows Central | Zachary Boddy)\n\nDisplay ⭐⭐⭐⭐½\n\nLenovo actually offers two OLED, touchscreen PureSight Pro display options for the Yoga Pro 9i. Both panels boast a 120Hz refresh rate, excellent color accuracy across standard and cinematic gamuts, Dolby Vision HDR and VESA DisplayHDR True Black 1000 support, and the trifecta of TÜV Rheindland Low Blue Light, TÜV Rheinland Flicker-Free, and Eyesafe certifications.\n\nFor an extra $150, though, you can upgrade to a Tandem OLED display with a higher 3.2K resolution (up from 2.8K), even greater color accuracy (especially in the AdobeRGB gamut), twice the display brightness at up to 1,000 nits (compared to 500 nits, and that's not even with HDR enabled), and greater efficiency to boot. Sadly, Lenovo didn't send me that configuration to test, so I can't tell you just how much better that panel is.\n\nThe entry-level screen is still fantastic, though. It's bright, vibrant, and responsive whether I was working, editing photos, gaming, or watching videos. If the Tandem OLED display is even better, it'll be one of the best panels you'll find on a laptop right now.\n\nPerformance ⭐⭐⭐⭐½\n\nThe Yoga Pro 9i is powered by an Intel Core Ultra 9 285H, a 16-core CPU with fantastic overall performance and solid efficiency. That's backed by up to an NVIDIA GeForce RTX 5070 (8GB) GPU, but Lenovo sent me the entry-level configuration with an RTX 5050 inside — and it seriously impressed me.\n\nThis laptop is a strong performer in general, backed by Intel Evo guarantees for responsiveness and bolstered by excellent thermal management. The Yoga Pro 9i never got too warm, never suffered from abnormal throttling, and kept quiet enough even under load.\n\nThe Yoga Pro 9i was practically guaranteed to deliver great performance, but it still managed to surprise me.\n\nAs I mentioned, though, it's the RTX 5050 that surprised me. Lenovo actually offers a GPU overclocking option, and when enabled the Yoga Pro 9i's RTX 5050 performed well beyond the level I expected, coming within a stone's throw of the far more expensive Dell 16 Premium's RTX 5070 without becoming thermally restrained.\n\nI was able to play Forza Horizon 5 with Extreme settings without any issues, either, never dipping below a stable 60 FPS.\n\nImage 1 of 3 I really like this keyboard, but I'm still not a fan of Lenovo's next key coating. (Image credit: Windows Central | Zachary Boddy) There's a lot of power packed into this chassis, but you don't feel it most of the time. (Image credit: Windows Central | Zachary Boddy) Intel Evo, NVIDIA Studio — this laptop has all the ingredients it needs to tackle any workflow or task. (Image credit: Windows Central | Zachary Boddy)\n\nBattery life ⭐⭐⭐½\n\nWith an 84Whr battery stashed away inside, the Yoga Pro 9i certainly has plenty of juice... but it's not enough to translate to true all-day battery life. In my testing, the Yoga Pro 9i can deliver around 5 hours of real-time usage — slightly better than the Dell 16 Premium and its larger 99Whr battery, but nothing too impressive.\n\nYou can use up to 100W USB Type-C chargers whenever you're in a pinch, at least. Performance when off the charger is throttled, but is still absolutely what I'd consider \"flagship\" level — especially the graphical oomph.\n\nThis laptop can't claim to boast the greatest endurance, but it's no worse than much of the competition.\n\nKeyboard & touchpad ⭐⭐⭐⭐\n\nI've historically been a huge fan of Lenovo's keyboards, and that still mostly holds true with the Yoga Pro 9i. The layout, key travel, and consistency are all top-notch, and the keyboard doesn't feel too cramped despite having a compact tenkey number pad off to one side (a feature some will love, and others will hate).\n\nAs I noted in my Lenovo Yoga Slim 7i (Gen 9) Aura Edition review, though, the new coating Lenovo puts on its keys isn't my favorite. This is a good keyboard, it's just slippery.\n\nThe touchpad is spacious and responsive with Microsoft Precision drivers, so I have little to complain about there... but I do wish Lenovo would finally embrace haptic touchpads on its premium consumer laptops.\n\nLenovo's \"Aura Edition\" branding doesn't mean anything to 99% of people... this laptop still delivers a great software experience, though. (Image credit: Windows Central | Zachary Boddy)\n\nSoftware & AI ⭐⭐⭐⭐½\n\nIt should come as no surprise that the Lenovo Yoga Pro 9i runs Windows 11, and it does so without issue. Drivers are stable and Lenovo hasn't injected an absurd amount of bloatware onto the device.\n\nLenovo didn't pour every feature imaginable into the Yoga Pro 9i, it just focused on delivering a capable, high-quality laptop.\n\nYou also get some extra features courtesy of Lenovo's \"Aura Edition\" branding, such as multi-device syncing for photos and files, \"smart\" performance and settings profiles, and Lenovo's \"AI Now\" companion, but the Yoga Pro 9i is not a Copilot+ PC thanks to the weaker NPU of its processor, so it doesn't boast all the latest and greatest artificial intelligence features in Windows.\n\nThat won't make a difference to most people, but it's worth noting this laptop technically isn't on the cutting edge for software.\n\nEverything else ⭐⭐⭐⭐½\n\nThe display isn't the only reason the Yoga Pro 9i is a monster for entertainment, as it also packs a capable six-speaker system (dual 2W tweeters and quad 2W woofers) with Dolby Atmos support.\n\nI won't go as far as claiming these are the best-sounding speakers in a laptop I've heard, but the Yoga Pro 9i does sound full, loud, and clear. You also get a quad microphone array flanking the great 5MP front-facing camera, which is supported by an IR sensor for Windows Hello facial recognition.\n\nI never had any issues with the Wi-Fi 7 or Bluetooth 5.4 connectivity, either. The Yoga Pro 9i doesn't rock any additional features like Human Presence Detection (HPD) or ambient light sensors, or a fingerprint reader, but the basics are covered and they're covered well.\n\nYoga Pro 9i (Gen 10) review: My final thoughts\n\nThe Lenovo Yoga Pro 9i isn't one of the most exciting laptops of 2025, but it is one of my favorites. (Image credit: Windows Central | Zachary Boddy)\n\n✅You should buy this if ...\n\nYou need a powerful, feature-packed 16-inch laptop for work and creation.\n\nYou also want that laptop to be good for PC gaming, too.\n\nYou want a laptop with a top-notch OLED display and speaker system.\n\n❌You should not buy this if ...\n\nYou actually care about Windows 11's Copilot+ PC-exclusive features.\n\nYou need a laptop with consistent, easy all-day battery life.\n\nThe Lenovo Yoga Pro 9i 16 (Gen 10) Aura Edition may have a slightly ridiculous name, but it's hands-down one of the greatest laptops in the category of \"powerful and premium 16-inch workstations.\"\n\nWhile Apple commits to minimalism and Dell pushes even more aggressively in that direction, Lenovo is delivering an equally capable laptop packed with features and ports — all while undercutting the competition on price. It's a shockingly practical laptop for productivity, creation, entertainment, and gaming.\n\nWhile I do wish the battery could withstand a full day's worth of work without compromise, that doesn't stop this from being one of the best Windows laptops I've tested this year. You can customize your own Lenovo Yoga Pro 9i 16 (Gen 10) Aura Edition from $1,869.99 at Lenovo.com, or pull the trigger on the configuration I most recommend for $2,149.99 at Lenovo.com, which upgrades you to that sweet Tandem OLED display and a more powerful RTX 5060 GPU.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/lenovo/lenovo-yoga-pro-9i-16-gen-10-aura-edition-review",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "White House may give Intel a huge gift",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/technology/white-house-may-give-intel-a-huge-gift-",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Qualcomm's most powerful CPU ever will target AMD's Ryzen AI+ 395 with 128GB onboard LPDDR5X memory - while Intel has only 32GB integrated memory to contend with",
      "content": "Qualcomm's new X2 Elite Extreme has 18 cores, 5.0GHz boost and 128GB LPDDR5X RAM\n\nX2 Elite has 12 cores, 4.7GHz boost and the same memory at lower bandwidth\n\nBoth chips add Adreno GPUs with ray tracing, and multi display support\n\nQualcomm has taken the wraps off its latest processors for Windows notebooks and PCs.\n\nThe Snapdragon X2 Elite and the Snapdragon X2 Elite Extreme are set to compete with AMD's Ryzen AI+ 395 and offer a significant boost over previous generation chips.\n\nThe X2 Elite Extreme is the flagship version, with higher core counts, faster clock speeds and stronger AI performance than the standard Elite model.\n\nBoost to 5.0GHz\n\nThe chip features up to 18 Oryon CPU cores, with 12 prime and 6 performance cores built on TSMC’s 3nm process.\n\nTwo of the prime cores can boost to 5.0GHz, making it the first Arm-based consumer processor to hit that speed.\n\nThe chip supports up to 128GB of LPDDR5X-9523 memory with 228GB/s bandwidth and 53MB of cache.\n\nIn comparison, the standard X2 Elite has up to 12 cores on TSMC’s 4nm process.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nIt supports the same 128GB memory capacity but at lower bandwidth, and its peak boost is 4.7GHz on one core. Cache is reduced to 34MB.\n\nAI processing is another area of difference. The Extreme’s NPU delivers up to 80 TOPS, nearly double the 45 TOPS of the X2 Elite.\n\nQualcomm says this level of acceleration is designed for Copilot+ PCs, allowing multiple AI workloads to run on-device at the same time.\n\nGraphics performance also gets an upgrade. The Extreme has the Adreno X2-90 GPU, while it's Adreno X2-85 for the Elite.\n\nBoth add hardware-based ray tracing for the first time and support for DirectX 12.2 Ultimate, Vulkan and OpenCL 3.0.\n\nThe chips can drive up to three 4K external displays at 144Hz or two 5K monitors at 60Hz, and connectivity includes Wi-Fi 7 via FastConnect 7800 and optional 5G with the Snapdragon X75 modem, with I/O packing PCIe 5.0 on the Extreme, PCIe 4.0 on the Elite, plus NVMe SSDs, UFS 4.0 and multiple USB4 ports.\n\nThe first notebooks featuring Qualcomm’s new X2 Elite and Elite Extreme chips are set to arrive in the first half of 2026 - and the first benchmarks for the new chips are expected soon.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/qualcomms-most-powerful-cpu-ever-will-target-amds-ryzen-ai-395-with-128gb-onboard-lpddr5x-memory-while-intel-has-only-32gb-integrated-memory-to-contend-with",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Cryptography Performance Improvements Coming For Linux 6.18",
      "content": "Adding to the list of pull requests submitted early in advance of the Linux 6.18 merge window opening are several cryptography-related improvements. In particular, some nice performance optimizations once again for the Linux kernel.Google engineer Eric Biggers continues leading some very nice performance improvements in the cryptography space for the Linux kernel.First up is a pull request adding interleaved SHA-256 hashing support . This 2-way interleaved SHA-256 hashing is immediately used by the FS-VERITY module for faster file data verification. In turn it's been observed that FS-VERITY performance improves nicely across many Intel/AMD x86_64 and AArch64 processors. Eric Biggers reported in the patch that it's roughly 35% faster performance.\n\nAlso sent in was the FSCRYPT pull request for Linux 6.18. The focus there is on using HMAC-SHA512 library functions rather than going through crypto_shash. In turn FSCRYPT should enjoy this simpler and faster and more reliable code path.Lastly there was a pull request sent out on Saturday for crypto library updates . This pull brings RISC-V optimized code for Poly1305, simplifies other code, and always enabling architecture-optimized BLAKE2s code.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-Faster-Crypto",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Cathie Wood sells $22.3 million of popular tech stock",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/investing/cathie-wood-sells-22-3-million-of-popular-tech-stock",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Weekly Market Wrap: Apple up, Electronic Arts soars, and Intel resurfaces",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/investing/weekly-market-wrap-apple-up-electronic-arts-soars-and-intel-resurfaces",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Rick and Morty EP: Network Didn't Want Rick Too Messy in \"Vindicators\"",
      "content": null,
      "source": "Bleeding Cool News",
      "url": "https://bleedingcool.com/tv/rick-and-morty-ep-network-didnt-want-rick-too-messy-in-vindicators/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "RUMOR: SPIDER-MAN: BRAND NEW DAY Will See The Punisher In Direct Conflict With The Villainous [SPOILER]",
      "content": "Spider-Man: Brand New Day is going to see Peter Parker face perhaps his greatest challenge yet. No longer an Avenger, the street-level superhero will have to contend with fellow \"hero\" The Punisher's war on crime, and new threats in The Scorpion and Tombstone.\n\nThe Hulk is also expected to enter the fray, while recent rumours have pointed to the supernatural Shathra being the movie's big bad.\n\nMinor plot details have come our way in dribs and drabs in recent weeks, with the latest shared by scooper Daniel Richtman. He claims that, in Spider-Man: Brand New Day, \"[The] Punisher and Tombstone will be in direct conflict.\"\n\nIf The Punisher has set his sights on him, then this points to Tombstone being a major threat in the movie. Assuming Mayor Wilson Fisk is defeated and imprisoned in Daredevil: Born Again season 2, then it's likely that the power vacuum in New York will lead to a Gang War that Spider-Man and Frank Castle attempt to put an end to.\n\nThis may also go some way in explaining what leads Frank to seemingly go to war with Ma Gnucci in the upcoming Punisher Special Presentation.\n\nRecent set photos have confirmed that the Department of Damage Control will appear in Spider-Man: Brand New Day, following appearances in Spider-Man: No Way Home and Ms. Marvel.\n\nHowever, before this movie is released, insider @MyTimeToShineH says we'll see the government organisation play a \"huge role\" in December's Wonder Man TV series.\n\nWe're not shocked to learn there's a connection between that and Spider-Man: Brand New Day because filmmaker Destin Daniel Cretton has obviously worked on both projects.\n\nRecently, Marvel's Head of Streaming, Television, and Animation, Brad Winderbaum, said, \"Wonder Man is eight episodes. It's a very new flavor for Marvel. It's straight from the minds of Destin Daniel Cretton and Andrew Guest. Honestly, it is one of my favorite things ever.\"\n\n\"I think it's the best show no one's ever seen, and I’m very excited to see the audience reaction to it,\" the executive teased. \"I think it's a love letter to what we do as filmmakers. It's a love letter to acting as a profession, and it's a very sincere, beautiful show.\"\n\nAs always, let us know your thoughts on these MCU rumours down in the comments section.\n\nSpider-Man: Brand New Day shares a title with a divisive era of storytelling, which, thanks to a deal with Mephisto, saw the wall-crawler get a fresh start when his marriage to Mary Jane Watson ended and his identity became secret again. He faced many new sinister foes during that time and was surrounded by an overhauled supporting cast, including Mister Negative, Jackpot, Menace, and Carlie Cooper.\n\nInstead, all signs point to Spidey teaming up with (and at some point fighting) The Punisher to take on a Savage Hulk, with The Scorpion thrown in for good measure.\n\nSeveral other villains are reportedly set to appear in the movie, including Tombstone, Tarantula, Boomerang, and Ramrod. There's been some chatter online about the Venom Symbiote factoring into the story, potentially setting the stage for Mac Gargan to eventually don the alien costume.\n\nShang-Chi and the Legend of the Ten Rings helmer Destin Daniel Cretton directs Spider-Man: Brand New Day from a script by Chris McKenna and Erik Sommers. Tom Holland leads a cast that also includes Jon Bernthal, Mark Ruffalo, Zendaya, Sadie Sink, Michael Mando, Tramell Tillman, Marvin Jones III, and Liza Colón-Zayas. Thunderbolts* star Florence Pugh has also joined the cast.\n\nSpider-Man: Brand New Day will be released in theaters on July 31, 2026.",
      "source": "CBM (Comic Book Movie)",
      "url": "https://comicbookmovie.com/spider_man/spider_man-brand-new-day/rumor-spider-man-brand-new-day-will-see-the-punisher-in-direct-conflict-with-the-villainous-spoiler-a224032",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Apple, TSMC weigh potential investment in Intel",
      "content": "Intel is in early talks with Apple and TSMC on potential investment and cooperation, according to sources familiar with the matter. The discussions follow Intel’s recent funding wins, including $2 billion from SoftBank, $8.9 billion in US government subsidies, and $5 billion from NVIDIA. If Apple and TSMC join as investors, the move could provide a crucial boost to Intel’s revival plan. Apple is seen as a potential customer for Intel’s advanced packaging technology, while TSMC may strengthen production at Intel’s US plants through a possible joint venture. Talks remain preliminary, and it is unclear whether an agreement will be reached. [Reuters]\n\nRelated",
      "source": "TechNode",
      "url": "http://technode.com/2025/09/28/apple-tsmc-weigh-potential-investment-in-intel/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "NEC V20: The Original PC Processor Upgrade",
      "content": "In the early 1980s, there was the IBM PC, with its 4.77 MHz Intel 8088 processor. It was an unexpected hit for the company, and within a few years there were a host of competitors. Every self-respecting technology corporation wanted a piece of the action including processor manufacturers, and among those was NEC with their V20 chip and its V30 sibling. From the outside they were faster pin-compatible 8088 and 8086 clones, but internally they could also run both 8080 and 80186 code. [The Silicon Underground] has a look back at the V20, with some technical details, history, and its place as a PC upgrade.\n\nFor such a capable part it’s always been a surprise here that it didn’t take the world by storm, and the article sheds some light on this in the form of an Intel lawsuit that denied it a critical early market access. By the time it was available in quantity the PC world had moved on from the 8088, so we saw it in relatively few machines. It was a popular upgrade for those in the know back in the day though as it remains in 2025, and aside from its immediate speed boost there are a few tricks it lends to a classic PC clone. The version of DOS that underpinned Windows 95 won’t run on an 8086 or 8088 because it contains 8016 instructions, but a V20 can run it resulting in a much faster DOS experience. One to remember, if an early PC or clone cones your way.\n\nHungry for the good old days of DOS? You don’t need to find 80s hardware for that.",
      "source": "Hackaday",
      "url": "https://hackaday.com/2025/09/27/nec-v20-the-original-pc-processor-upgrade/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "The truth lies — test your Call of Duty: Black Ops knowledge with this quiz ahead of COD Next",
      "content": "Test your knowledge of Call of Duty: Black Ops before the beta.\n\nWith Call of Duty NEXT and the Black Ops 7 beta right around the corner, I figured now would be a good time for me to take over the Windows Central quiz and see just how much our community knows about the Black Ops franchise.\n\nMore quizzes! (Image credit: Xbox Game Studios / Windows Central) The list of Windows Central quizzes continues to grow. You might know your stuff when it comes to Call of Duty: Black Ops, but how will you fare against our other tests?\n\nBlack Ops is a series that has introduced drastic changes to the Call of Duty franchise over the years. In an era when many shooters embraced the brown and gray aesthetic, Black Ops dared to be a little brighter, featuring maps with bolder color palettes that are still among some of the best playgrounds even today.\n\nFrom the Siege of Stalingrad to Project Blackout, Black Ops’ history has taken us on mind-bending adventures across the annals of history that forge a twisted path to a future beyond imagination. And yet, Treyarch leadership says that Black Ops 7 will not bring the series to a close.\n\n“It can’t be [the end] for us because we have so much love for our other games,” answered Yale Miller, Treyarch’s director of production, “Like Black Ops 3 is canon, right? There are still things that are there [to explore].”\n\nWhile Black Ops’ deep lore and extensive campaigns provide plenty of fodder for future titles, so does its much-loved Zombies mode. Effectively a game-within-a-game, Zombies has grown into a beast of its own with its own canon story lines, unique cast, and nightmarish undead foes.\n\nTake our quiz below and test your Call of Duty: Black Ops knowledge:\n\nCall of Duty: Black Ops 7 is set to launch on Xbox, PC, and PlayStation on November 14. The next mainline title in the 20+ year old franchise is expected to be stacked with an all-new cooperative campaign and endgame. You can also look forward to classic multiplayer with a slightly more futuristic twist, and the next chapter in the Dark Aether storyline for its famed Zombies mode.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nBlack Ops 7 is the first Call of Duty title to fall under the Xbox Play Anywhere initiative, offering cross-entitlement to players on PC, Xbox, and Xbox Cloud Gaming with one purchase. The game will also launch day one on Xbox Game Pass Ultimate and PC Game Pass.\n\nFor more intel on Call of Duty: Black Ops 7, stay tuned for Call of Duty NEXT 2025 on September 30.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/gaming/call-of-duty/call-of-duty-black-ops-quiz",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "This alarming intel shows how TACO Trump will drag us into World War III",
      "content": null,
      "source": "Raw Story",
      "url": "https://www.rawstory.com/raw-investigates/world-war-iii/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "NVIDIA Expands AI Presence with Intel Partnership and £2 Billion UK Investment",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_ca5bb8e3-ac8f-4472-a5c7-09f7602816e6",
      "timestamp": "2025-09-27"
    },
    {
      "source": "Stratechery.com",
      "headline": "Nvidia and Intel, Tan’s Earnings Call Negotiation, Deal Specifics",
      "url": "https://stratechery.com/2025/nvidia-and-intel-tans-earnings-call-negotiation-deal-specifics/",
      "timestamp": "2025-09-22",
      "content": "Intel and Nvidia have made a historic deal; it's good for Intel (and Nvidia), but doesn't solve their — and the U.S.'s — fundamental problems."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Super Micro (SMCI) Stock Trades Up, Here Is Why",
      "url": "https://finance.yahoo.com/news/super-micro-smci-stock-trades-204708134.html",
      "timestamp": "2025-09-22",
      "content": "Shares of server solutions provider Super Micro (NASDAQ:SMCI) jumped 3% in the afternoon session after the company unveiled a new lineup of AI-optimized..."
    },
    {
      "source": "Business Insider",
      "headline": "Ukraine claims first-ever kills of Russian Be-12 seaplanes. These aircraft are said to hunt naval drones.",
      "url": "https://www.businessinsider.com/ukraine-said-destroyed-russian-aircraft-type-first-time-history-2025-9",
      "timestamp": "2025-09-22",
      "content": "Ukraine said it destroyed two Russian Be-12 aircraft, calling it the first time in history that the aircraft type had been destroyed in combat."
    },
    {
      "source": "PCWorld",
      "headline": "Nvidia and Intel’s collaborative PC chips might not happen for years",
      "url": "https://www.pcworld.com/article/2915876/nvidia-and-intels-collaborative-pc-chips-might-not-happen-for-years.html",
      "timestamp": "2025-09-22",
      "content": "Neither Intel nor Nvidia have said exactly when the first fruits of its co-designed integrated CPUs will ship. But the thinking right now seems to be that it might a take a few years.\r\n\n\n\n\nNvidia announced a $5 billion investment into Intel last week, where I…"
    },
    {
      "source": "Phoronix",
      "headline": "Linux 6.18 Adding A New Power Savings Option For The Intel Graphics Driver",
      "url": "https://www.phoronix.com/news/Linux-6.18-SLPC-Power-Profile",
      "timestamp": "2025-09-22",
      "content": "Queued up into DRM-Next is a last batch of Intel Xe kernel graphics driver improvements ahead of the Linux 6.18 merge window that is expected to begin next week. With this last minute Intel Xe driver activity is also a new power management knob for those want…"
    },
    {
      "source": "Windows Central",
      "headline": "Microsoft's official Windows 11 version 25H2 RTM ISO media is now available — Download all 38 languages here for x64 or Arm64",
      "url": "https://www.windowscentral.com/microsoft/windows-11/microsofts-official-windows-11-version-25h2-rtm-iso-media-is-now-available-download-all-28-languages-here-for-x64-or-arm64",
      "timestamp": "2025-09-22",
      "content": "Tired of waiting for Microsoft to release Windows 11 version 25H2 via Windows Update? The official RTM ISO media is now online and can be downloaded straight from Microsoft."
    },
    {
      "source": "TechRadar",
      "headline": "Nvidia and Intel’s partnership could introduce the huge performance upgrade for handheld gaming PCs I’ve been hoping for",
      "url": "https://www.techradar.com/computing/cpu/nvidia-and-intels-partnership-could-introduce-the-huge-performance-upgrade-for-handheld-gaming-pcs-ive-been-hoping-for",
      "timestamp": "2025-09-22",
      "content": "AMD is arguably running away with the crown in the handheld gaming PC space, with its most powerful SoC challenging an Nvidia RTX GPU, but it might be in trouble after Nvidia and Intel's partnership."
    },
    {
      "source": "Biztoc.com",
      "headline": "TikTok deal won't include 'golden share' or equity for U.S., Trump administration says",
      "url": "https://biztoc.com/x/8cfe23fecf490f84",
      "timestamp": "2025-09-22",
      "content": "President Donald Trump has secured a golden share in U.S. Steel and taken an equity stake in Intel."
    },
    {
      "source": "Biztoc.com",
      "headline": "A $5 Billion Reason To Buy Intel Stock Here",
      "url": "https://biztoc.com/x/05b67cadcad4cc01",
      "timestamp": "2025-09-22",
      "content": "Join Barchart Premier to attend LIVE \"Market on Close\" program each Friday with John Rowland.\nFREE 30 Day Trial\n- Market Pulse\n- VolatilityVolume & Open InterestHorizontal StrategiesButterfly Strategies\n-\n- Market PulseResourcesEuropean FuturesEuropean Groupi…"
    },
    {
      "source": "Al Jazeera English",
      "headline": "Nvidia to invest billions in OpenAI as AI race heats up",
      "url": "https://www.aljazeera.com/economy/2025/9/22/nvidia-to-invest-billions-in-openai-as-ai-race-heats-up",
      "timestamp": "2025-09-22",
      "content": "The company will also provide chips for OpenAI’s data centres."
    },
    {
      "source": "Theregister.com",
      "headline": "Huawei used its own silicon to re-educate DeepSeek so its output won’t bother Beijing",
      "url": "https://www.theregister.com/2025/09/22/asia_tech_news_roundup/",
      "timestamp": "2025-09-22",
      "content": "PLUS: India ponders tax breaks for datacenters; Samsung plans hiring spree; Taliban bans fiber internet; and more\nAsia In Brief Huawei last week revealed that China’s Zhejiang University used its Ascend 1000 accelerators to create a version of DeepSeek’s R1 m…"
    },
    {
      "source": "Scientific American",
      "headline": "Announcing the #SciAmInTheWild Photography Contest Short List",
      "url": "https://www.scientificamerican.com/article/announcing-the-sciaminthewild-photography-contest-short-list/",
      "timestamp": "2025-09-22",
      "content": "To celebrate Scientific American’s 180th anniversary, we invited readers to place our magazine covers in the wild. See our staff’s favorite submissions"
    },
    {
      "source": "Biztoc.com",
      "headline": "Stock Market Today: Dow, S&P 500, Nasdaq Set to Open Down; Nvidia, Tesla, Intel, More Movers",
      "url": "https://biztoc.com/x/0d5aeefbd21c93ee",
      "timestamp": "2025-09-22",
      "content": "LIVE\nDow Set to Open Down as the Market Struggles to Find Catalysts\nThe S&P 500 and Nasdaq are also falling in premarket trading.\nLast Updated:\nSep. 22, 2025 at 3:54 AM ET\nKey Events\nLatest Updates\nStocks looked set to slide on Monday, as investors tried to f…"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Bank of America shocks with AMD stock verdict post Nvidia-Intel deal",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_90d22509-969b-469e-8e89-32a72176fc0c",
      "timestamp": "2025-09-21",
      "content": null
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "A $5 Billion Reason to Buy Intel Stock Here",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_7955d53c-7f2d-4f0c-b7e1-b7026e11d9c2",
      "timestamp": "2025-09-21",
      "content": null
    },
    {
      "source": "XDA Developers",
      "headline": "I tried using a FreeBSD distro that's meant to be run off a flash drive",
      "url": "https://www.xda-developers.com/i-tried-using-a-freebsd-distro-thats-meant-be-run-off-a-flash-drive/",
      "timestamp": "2025-09-21",
      "content": "NomadBSD exceeded all my expectations"
    },
    {
      "source": "Biztoc.com",
      "headline": "US Steel changes course and will keep processing raw steel at Granite City plant in Illinois",
      "url": "https://biztoc.com/x/cd4d6da022535782",
      "timestamp": "2025-09-21",
      "content": ""
    },
    {
      "source": "Biztoc.com",
      "headline": "A profile of Noah Urban, who was a key member of the Scattered Spider group because of his social engineering skills and is serving a 10-year prison sentence",
      "url": "https://biztoc.com/x/0e4a790dbb4cf532",
      "timestamp": "2025-09-21",
      "content": ""
    },
    {
      "source": "Digitimes",
      "headline": "Nvidia's US$5B Intel stake sparks foundry jitters for TSMC, Samsung",
      "url": "https://www.digitimes.com/news/a20250919PD219/nvidia-intel-investment-samsung-tsmc-government.html",
      "timestamp": "2025-09-21",
      "content": "Nvidia's US$5 billion stake in Intel has shaken the global semiconductor landscape, sparking debate over future foundry competition and supply chain realignment. While the deal excludes wafer foundry cooperation, it has put TSMC and Samsung Electronics on ale…"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Dow, S&P 500, Nasdaq futures pull back from records as gold powers to fresh all-time high",
      "url": "https://finance.yahoo.com/news/live/dow-sp-500-nasdaq-futures-pull-back-from-records-as-gold-powers-to-fresh-all-time-high-234423591.html",
      "timestamp": "2025-09-21",
      "content": "A parade of Fed speakers and a key inflation print are in focus for clues to further rate cuts."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Stock market today: Dow, S&P 500, Nasdaq futures pull back from records as gold powers to fresh high",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-dow-sp-500-nasdaq-futures-pull-back-from-records-as-gold-powers-to-fresh-high-234423457.html",
      "timestamp": "2025-09-21",
      "content": "A parade of Fed speakers and a key inflation print are in focus for clues to further rate cuts."
    },
    {
      "source": "SiliconANGLE News",
      "headline": "Intel-Nvidia: The baton passes to the CUDA era",
      "url": "https://siliconangle.com/2025/09/20/intel-nvidia-baton-passes-cuda-era/",
      "timestamp": "2025-09-21",
      "content": "In our view, the Intel–Nvidia pact further accentuates Nvidia Corp.’s dominant market position and represents a milestone in the transition to the next era of computing. Just as Intel Corp. had a lock on the market in the ’80s and ’90s, Nvidia has now extende…"
    },
    {
      "source": "Medium",
      "headline": "The Russians Keep Parking Helicopters On the Same Undefended Tarmac In Crimea.",
      "url": "https://medium.com/war-is-boring/the-russians-keep-parking-helicopters-on-the-same-undefended-tarmac-in-crimea-940b8a3e017f",
      "timestamp": "2025-09-21",
      "content": "Ukrainian drones and missiles range freely across Crimea."
    },
    {
      "source": "Wnd.com",
      "headline": "Intel chief Gabbard sparks controversy after revoking 37 security clearances without White House approval",
      "url": "https://www.wnd.com/2025/09/intel-chief-gabbard-sparks-controversy-after-revoking-37/",
      "timestamp": "2025-09-21",
      "content": "... Read more"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Stock market today: Dow, S&P 500, Nasdaq turn higher as Nvidia surges on OpenAI deal",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-dow-sp-500-nasdaq-turn-higher-as-nvidia-surges-on-openai-deal-234423447.html",
      "timestamp": "2025-09-21",
      "content": "A parade of Fed speakers and a key inflation print are in focus for clues to further rate cuts."
    },
    {
      "source": "Biztoc.com",
      "headline": "‘Time to Sell,’ Warns Top Citi Analyst on Intel Stock after Nvidia-Fueled Rally",
      "url": "https://biztoc.com/x/7a383d5d95a9bf6f",
      "timestamp": "2025-09-20",
      "content": "Top Citi analyst Christopher Danely downgraded Intel (INTC) to Sell from Neutral, even as he raised his price target to $29 from $24. The downgrade came after Intel surged nearly 23% on news that Nvidia (NVDA) will invest $5 billion for a 4% stake and partner…"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "I’m the VC researcher who helped uncover Intel’s close ties to China. Its nationalization just exposes a corporate governance crisis",
      "url": "https://finance.yahoo.com/news/m-vc-researcher-helped-uncover-113000708.html",
      "timestamp": "2025-09-20",
      "content": "It wasn’t my plan to find myself embroiled in international intrigue involving semiconductors. I'm a VC who used to be the general counsel for a hockey team."
    },
    {
      "source": "Fc2.com",
      "headline": "NVIDIAとの協業後もArc GPUの開発は継続される",
      "url": "https://northwood.blog.fc2.com/blog-entry-12853.html",
      "timestamp": "2025-09-20",
      "content": "Intel Arc GPUs Remain in Development, NVIDIA RTX iGPUs Are Complementary（TechPowerUp）Intel says blockbuster Nvidia deal doesn’t change its own roadmap（PC World）先日、IntelとNVIDIAの協業が発表され、“x86 RTX SoC”の開発が行われることなどが明らかにされたが、Intelによるとこの協業はあくまでも補完的なものであり、Intel自身のGPU…"
    },
    {
      "source": "Codingconfessions.com",
      "headline": "What Makes System Calls Expensive: A Linux Internals Deep Dive",
      "url": "https://blog.codingconfessions.com/p/what-makes-system-calls-expensive",
      "timestamp": "2025-09-20",
      "content": "An explanation of how Linux handles system calls on x86-64 and why they show up as expensive operations in performance profiles"
    },
    {
      "source": "TheStreet",
      "headline": "Analysts revamp Nvidia stock outlook on its investment in Intel",
      "url": "https://www.thestreet.com/technology/analysts-revamp-nvidia-stock-outlook-on-its-investment-in-intel-",
      "timestamp": "2025-09-20",
      "content": "Analysts provided their opinion on Nvidia stock, following the company's $5 billion investment into Intel."
    },
    {
      "source": "XDA Developers",
      "headline": "6 operating system luxuries Windows users have never known about Linux",
      "url": "https://www.xda-developers.com/operating-system-luxuries-windows-users-have-never-known-about-linux/",
      "timestamp": "2025-09-20",
      "content": "Windows may seem easier, but Linux has a lot of advantages over it. You might not even know these features exist, but they're fantastic."
    },
    {
      "source": "Digitimes",
      "headline": "Intel-Nvidia's twin strategy faces speed test, but PC path leads, says DIGITIMES analyst",
      "url": "https://www.digitimes.com/news/a20250919VL203/nvidia-intel-gpu-cpu-packaging.html",
      "timestamp": "2025-09-20",
      "content": "Nvidia and Intel on Thursday detailed a sweeping product roadmap that links their CPU and GPU platforms, while underscoring continued collaboration with Taiwan Semiconductor Manufacturing Company (TSMC) and pointing to Intel's advanced packaging as an enabler."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Investing.com’s stocks of the week",
      "url": "https://finance.yahoo.com/news/investing-com-stocks-week-083010242.html",
      "timestamp": "2025-09-20",
      "content": "Investing.com -- U.S. stocks rose on Friday and are on track for weekly gains following the Federal Reserve rate cut on Wednesday."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Wedbush: Nvidia–Intel (INTC) Deal Is a “Game Changer” for Struggling Chipmaker",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_8621872a-de20-4848-acaa-aa69eb9c79d6",
      "timestamp": "2025-09-20",
      "content": null
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "BofA Sees Stronger Demand for ASML’s Chipmaking Tools Amid AI Boom",
      "url": "https://finance.yahoo.com/news/bofa-sees-stronger-demand-asml-223915890.html",
      "timestamp": "2025-09-20",
      "content": "ASML Holding N.V. (NASDAQ:ASML) is one of the AI Stocks Analysts Are Tracking Closely. On September 18, BofA Securities analyst Didier Scemama raised the..."
    },
    {
      "source": "Fortune",
      "headline": "I’m the VC researcher who helped uncover Intel’s close ties to China. Its nationalization just exposes a corporate governance crisis",
      "url": "https://fortune.com/2025/09/20/i-helped-expose-intel-china-corporate-governance-crisis/",
      "timestamp": "2025-09-20",
      "content": "It wasn’t my plan to find myself embroiled in international intrigue involving semiconductors. I'm a VC who used to be the general counsel for a hockey team."
    },
    {
      "source": "Raw Story",
      "headline": "GOP lawmaker accuses fellow Republican of 'greatly exaggerating his military service'",
      "url": "https://www.rawstory.com/mace-mills-military-service/",
      "timestamp": "2025-09-20",
      "content": "Rep. Nancy Mace (R-SC) on Saturday accused fellow Republican lawmaker, Rep. Cory Mills (R-FL), of \"greatly exaggerating his military service.\"Mace recently lashed out at Mills and accused him of privately threatening her, following the failure of her resoluti…"
    },
    {
      "source": "Slashdot.org",
      "headline": "Intel Says Blockbuster Nvidia Deal Doesn't Change Its Own Roadmap",
      "url": "https://slashdot.org/story/25/09/19/019243/intel-says-blockbuster-nvidia-deal-doesnt-change-its-own-roadmap",
      "timestamp": "2025-09-19",
      "content": "If you're wondering what effect Intel's blockbuster deal with Nvidia will have on its existing product roadmaps, Intel has one message for you: it won't. PCWorld: \"We're not discussing specific roadmaps at this time, but the collaboration is complementary to …"
    },
    {
      "source": "Hackaday",
      "headline": "Imagining the CPS-1: An Early 70s 4-bit Microcomputer from Canada",
      "url": "https://hackaday.com/2025/09/19/imagining-the-cps-1-an-early-70s-4-bit-microcomputer-from-canada/",
      "timestamp": "2025-09-19",
      "content": "[Michael Gardi] wrote in to let us know about his project: CPS-1: Imagining An Early 70s 4-bit Microcomputer. The CPS-1 was the first Canadian microprocessor-based computer. It was built by …read more"
    },
    {
      "source": "XDA Developers",
      "headline": "Dangerous PC hardware myths for novice PC builders",
      "url": "https://www.xda-developers.com/most-dangerous-pc-hardware-myths-for-new-pc-builders/",
      "timestamp": "2025-09-19",
      "content": "Don't take every piece of PC building advice seriously"
    },
    {
      "source": "TechRadar",
      "headline": "Nvidia gained $150 billion on Intel announcement, more than Intel market capitalization - netting a 30x return on its investment in 24 hours with just $5 billion",
      "url": "https://www.techradar.com/pro/nvidia-gained-usd150-billion-on-intel-announcement-more-than-intel-market-capitalization-netting-a-30x-return-on-its-investment-in-24-hours-with-just-usd5-billion",
      "timestamp": "2025-09-19",
      "content": "Nvidia gained $150 billion in market value after shock Intel partnership announcement, rising to $4.28 trillion cap."
    },
    {
      "source": "Forbes",
      "headline": "Markets Hit New Highs As Intel Surges, Government Spending Looms",
      "url": "https://www.forbes.com/sites/jjkinahan/2025/09/19/markets-hit-new-highs-as-intel-surges-government-spending-looms/",
      "timestamp": "2025-09-19",
      "content": "Stocks hit new highs as Intel soared on Nvidia’s $5B stake. Government spending plans, FedEx earnings, and TikTok talks added to a volatile, policy-driven market backdrop."
    },
    {
      "source": "Forbes",
      "headline": "Forbes Daily: Intel Shares Spike After Deal With Rival Nvidia",
      "url": "https://www.forbes.com/sites/daniellechemtob/2025/09/19/forbes-daily-intel-shares-spike-after-deal-with-rival-nvidia/",
      "timestamp": "2025-09-19",
      "content": "Today’s Forbes Daily newsletter covers the fallout from Kimmel's removal, the FTC sues Ticketmaster and Live Nation, Congress alarmed over TikTok deal and more."
    },
    {
      "source": "Biztoc.com",
      "headline": "Intel Got $5 Billion, but Nvidia Could Be the Big Winner. Here’s Why",
      "url": "https://biztoc.com/x/0fc46dddd53f043f",
      "timestamp": "2025-09-19",
      "content": "With the Intel deal, Nvidia may have just secured its computing dominance."
    },
    {
      "source": "Forbes",
      "headline": "Novice Investor’s Digest For Friday, September 19",
      "url": "https://www.forbes.com/sites/catherinebrock/2025/09/19/novice-investors-digest-for-friday-september-19/",
      "timestamp": "2025-09-19",
      "content": "Stock prices hit new record highs after interest rates decline and Nvidia announces Intel investment. Also: all-at-once rebalancing or gradual?"
    },
    {
      "source": "The Verge",
      "headline": "Nvidia invests $5 billion into Intel to jointly develop PC and data center chips",
      "url": "https://www.theverge.com/news/780792/nvidia-intel-investment-pc-chips-data-center",
      "timestamp": "2025-09-18",
      "content": "Nvidia is throwing Intel a $5 billion life raft, just weeks after similar stakes from the US government and SoftBank. Nvidia is investing $5 billion in Intel common stock in a collaboration that will see the pair “jointly develop multiple generations of custo…"
    },
    {
      "source": "Gizmodo.com",
      "headline": "Nvidia Appeals to Trump With a $5 Billion Intel Stake",
      "url": "https://gizmodo.com/nvidia-appeals-to-trump-with-a-5-billion-intel-stake-2000660647",
      "timestamp": "2025-09-18",
      "content": "The two competitors will collaborate to develop PC chips and data centers."
    },
    {
      "source": "Business Insider",
      "headline": "Nvidia CEO explains why he's making a $5 billion bet on struggling chip giant Intel",
      "url": "https://www.businessinsider.com/intel-investment-nvidia-jensen-huang-stock-ai-chip-plans-2025-9",
      "timestamp": "2025-09-18",
      "content": "\"Having Jensen's blessing is priceless,\" wrote Bernstein senior analyst  Stacy Rasgon about Nvidia's $5 billion investment in Intel."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Ives Says Pop the Champagne for Intel After Nvidia Investment",
      "url": "https://finance.yahoo.com/video/ives-says-pop-champagne-intel-143208222.html",
      "timestamp": "2025-09-18",
      "content": "Dan Ives of Wedbush Securities talks about Nvidia agreeing to invest $5 billion in Intel. The companies will co-develop chips for PCs and data centers. The..."
    },
    {
      "source": "Wired",
      "headline": "China Turns Legacy Chips Into a Trade Weapon",
      "url": "https://www.wired.com/story/china-probe-us-chip-makers-tiktok-deal/",
      "timestamp": "2025-09-18",
      "content": "As Washington pushes for a TikTok deal, Beijing is countering with probes into American chipmakers."
    },
    {
      "source": "Barchart.com",
      "headline": "Nvidia CEO Jensen Huang Says 'You Can’t Overstate the Magic' That is Taiwan Semiconductor, But is TSM Stock a Buy at New Highs?",
      "url": "https://www.barchart.com/story/news/34900133/nvidia-ceo-jensen-huang-says-you-cant-overstate-the-magic-that-is-taiwan-semiconductor-but-is-tsm-stock-a-buy-at-new-highs",
      "timestamp": "2025-09-18",
      "content": "Foundry giant Taiwan Semiconductor will play a key role in the new partnership between Nvidia and Intel, according to CEOs Jensen Huang and Lip-Bu Tan."
    },
    {
      "source": "Kotaku",
      "headline": "Treyarch Co-Founder Sentenced To Federal Prison After Flying Drone Into Firefighting Aircraft In January",
      "url": "https://kotaku.com/treyarch-co-founder-game-dev-drone-firefighting-plane-jail-time-federal-court-2000626833",
      "timestamp": "2025-09-18",
      "content": "Also: Nvidia and Intel strike up partnership, Microsoft Flight Sim might be coming to PS5, a new Yakuza game has leaked, and be careful while playing classic Doom\nThe post Treyarch Co-Founder Sentenced To Federal Prison After Flying Drone Into Firefighting Ai…"
    },
    {
      "source": "Windows Central",
      "headline": "Intel and NVIDIA announce partnership that will see \"jointly developed x86 Intel CPUs fused with RTX GPUs\" in shocking move",
      "url": "https://www.windowscentral.com/hardware/intel/intel-and-nvidia-announce-partnership-that-will-see-jointly-developed-x86-intel-cpus-fused-with-rtx-gpus-in-shocking-move",
      "timestamp": "2025-09-18",
      "content": "NVIDIA is partnering up with Intel to product new chips that fuse x86 Intel CPUs with RTX GPUs in an attempt to compete with AMD APUs, along with helping Intel stay afloat in its fight with TSMC."
    },
    {
      "source": "Kotaku",
      "headline": "Dell Tower PC Desktop Is Cheaper Than Ever, Probably to Clear Shelves Before Amazon Prime Big Deal Days",
      "url": "https://kotaku.com/dell-tower-pc-desktop-is-cheaper-than-ever-probably-to-clear-shelves-before-amazon-prime-big-deal-days-2000626589",
      "timestamp": "2025-09-18",
      "content": "Save 33% on the Dell Vostro 3030 PC tower for a limited time at Amazon.\nThe post Dell Tower PC Desktop Is Cheaper Than Ever, Probably to Clear Shelves Before Amazon Prime Big Deal Days appeared first on Kotaku."
    },
    {
      "source": "Theregister.com",
      "headline": "Intel and Nvidia sitting in a tree, NVLink-I-N-G",
      "url": "https://www.theregister.com/2025/09/18/nvidia_intel_deal_nvlink/",
      "timestamp": "2025-09-18",
      "content": "But still no hero customer for Chipzilla's Foundry biz\nNvidia is set to become one of Intel's largest shareholders after the GPU giant announced on Thursday it would invest $5 billion in the struggling chipmaker under a co-development agreement targeting PCs …"
    },
    {
      "source": "Windows Central",
      "headline": "Should Microsoft make its own wearable AI hardware with Copilot?",
      "url": "https://www.windowscentral.com/microsoft/windows-11/should-microsoft-make-its-own-wearable-ai-hardware-with-copilot",
      "timestamp": "2025-09-18",
      "content": "Dan & Zac discuss the latest on Windows 11, and whether or not Microsoft should consider making AI wearable hardware powered by Copilot to compete with devices like the newly announced Meta Ray Ban Displays."
    },
    {
      "source": "Al Jazeera English",
      "headline": "Nvidia to become one of Intel’s biggest shareholders with new investment",
      "url": "https://www.aljazeera.com/economy/2025/9/18/nvidia-to-become-one-of-intels-biggest-shareholders-with-new-investment",
      "timestamp": "2025-09-18",
      "content": "The White House denies any involvement with the deal which came after Nvidia’s CEO met US President Donald Trump."
    },
    {
      "source": "GSMArena.com",
      "headline": "Nvidia invests $5 billion in Intel, x86 APUs with Nvidia RTX GPU chiplets incoming",
      "url": "https://www.gsmarena.com/nvidia_invests_5_billion_in_intel_x86_apus_with_nvidia_rtx_gpu_chiplets_incoming-news-69570.php",
      "timestamp": "2025-09-18",
      "content": "Did you feel that? There was a tectonic shift in the PC market just now – Nvidia announced that it is buying $5 billion worth of Intel’s common stock and, more importantly, the two companies will jointly build products for PC and servers.\n\nHere’s the most exc…"
    },
    {
      "source": "Gizmodo.com",
      "headline": "I Watched Every Jimmy Kimmel Monologue Since Charlie Kirk Was Killed and All I Got Was This Sinking Feeling",
      "url": "https://gizmodo.com/why-jimmy-kimmel-was-canceled-2000660731",
      "timestamp": "2025-09-18",
      "content": "Most critics aren't even playing the clip of what Kimmel said."
    },
    {
      "source": "PCWorld",
      "headline": "Intel says blockbuster Nvidia deal doesn’t change its own roadmap",
      "url": "https://www.pcworld.com/article/2913872/intel-nvidia-deal-doesnt-change-its-roadmap.html",
      "timestamp": "2025-09-18",
      "content": "If you’re wondering what effect Intel’s blockbuster deal with Nvidia will have on its existing product roadmaps, Intel has one message for you: it won’t.\r\n\n\n\n\n“We’re not discussing specific roadmaps at this time, but the collaboration is complementary to Inte…"
    },
    {
      "source": "PCWorld",
      "headline": "Intel Arc graphics face a murky future after Nvidia’s $5B RTX mashup",
      "url": "https://www.pcworld.com/article/2913669/intel-arc-graphics-face-a-murky-future-after-nvidias-5b-rtx-mashup.html",
      "timestamp": "2025-09-18",
      "content": "Surprise! We woke up this morning to a blockbuster mashup between Intel and Nvidia. Team Green invested a cool $5 billion into Intel, and in exchange, the two companies will be co-creating consumer and data center x86 processors interwoven with Nvidia’s RTX g…"
    },
    {
      "source": "Kotaku",
      "headline": "Apple Seems to Be Clearing Out the 2025 M4 MacBook Air at an All-Time Low Before Amazon Prime Big Deal Days",
      "url": "https://kotaku.com/apple-seems-to-be-clearing-out-the-2025-m4-macbook-air-at-an-all-time-low-before-amazon-prime-big-deal-days-2000626103",
      "timestamp": "2025-09-17",
      "content": "If Apple is clearing the decks for an early 2026 release of a new model, now's the time to grab the super-fast M4 model at a great price.\nThe post Apple Seems to Be Clearing Out the 2025 M4 MacBook Air at an All-Time Low Before Amazon Prime Big Deal Days appe…"
    },
    {
      "source": "Cheezburger.com",
      "headline": "Employee quits stable job for better position elsewhere, then gets fired on day four with no justified explanation: '[They] told me I wasn't the right fit!'",
      "url": "https://cheezburger.com/42430981/employee-quits-stable-job-for-better-position-elsewhere-then-gets-fired-on-day-four-with-no",
      "timestamp": "2025-09-17",
      "content": "Every time an employee begins work at a new company, it's a gamble. There is only so much research one can do in advance, and there is only so much intel one can obtain during the application and interview processes. At the end of the day, you rarely know for…"
    },
    {
      "source": "PC Gamer",
      "headline": "Researchers argue that 'at least 40%' of the bloated x86 ISA could be removed and emulated to improve CPU efficiency",
      "url": "https://www.pcgamer.com/hardware/processors/researchers-argue-that-at-least-40-percent-of-the-bloated-x86-isa-could-be-removed-and-emulated-to-improve-cpu-efficiency/",
      "timestamp": "2025-09-17",
      "content": "They propose a big SHRINK."
    },
    {
      "source": "Windows Central",
      "headline": "\"A painful reset\" — Fiverr lays off 30% of its employees in a sweeping AI-first overhaul",
      "url": "https://www.windowscentral.com/artificial-intelligence/fiverr-announces-layoffs-ai-restructuring",
      "timestamp": "2025-09-17",
      "content": "Fiverr's CEO recently announced that the company is cutting about 30% of its staff to focus on AI restructuring. Here's why this sort of news is no longer surprising."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Stock market today: Nasdaq, Dow, S&P 500 rise after Fed signals more cuts, Nvidia bets on Intel",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-nasdaq-dow-sp-500-rise-after-fed-signals-more-cuts-nvidia-bets-on-intel-231448487.html",
      "timestamp": "2025-09-17",
      "content": "Markets are shaking off initial hesitation prompted by Powell's warning that there's no 'risk-free path' for policy."
    },
    {
      "source": "Osnews.com",
      "headline": "Haiku vastly improves git status performance",
      "url": "https://www.osnews.com/story/143365/haiku-vastly-improves-git-status-performance/",
      "timestamp": "2025-09-17",
      "content": "Another month, another summary of changes in Haiku, the BeOS-inspired operating system. The main focus this past month has been improving the performance of git status, which has been measurably worse on Haiku than on Linux running on similar hardware. This w…"
    },
    {
      "source": "Project Syndicate",
      "headline": "Lawless State Capitalism Is No Answer to China’s Rise",
      "url": "https://www.project-syndicate.org/commentary/trump-state-capitalism-lawless-and-no-answer-to-china-rivalry-by-curtis-j-milhaupt-and-angela-huyue-zhang-2025-09",
      "timestamp": "2025-09-17",
      "content": "Invoking national security and the economic rivalry with China, the Trump administration is pursuing legally dubious interventions and control of private industry, with potentially high costs for US dynamism. Like the panic over Japan's rise in the 1980s, the…"
    },
    {
      "source": "Kotaku",
      "headline": "New Splinter Cell Show Trailer Seems To Pick A Canon Ending For Chaos Theory",
      "url": "https://kotaku.com/new-splinter-cell-trailer-netflix-deathwatch-chaos-theory-ending-john-wick-2000626077",
      "timestamp": "2025-09-16",
      "content": "I still miss Michael Ironside, but Sam Fisher sounds perfectly old, grumpy, and deadly in the upcoming animated series\nThe post New Splinter Cell Show Trailer Seems To Pick A Canon Ending For Chaos Theory appeared first on Kotaku."
    },
    {
      "source": "Business Insider",
      "headline": "Ukraine says Russia's new jet-powered attack drone is full of foreign parts and immune to electronic warfare",
      "url": "https://www.businessinsider.com/russia-jet-powered-drone-immune-electronic-warfare-ukraine-says-2025-9",
      "timestamp": "2025-09-16",
      "content": "The Geran-3, modeled after the Iranian-made Shahed-238, is faster and more advanced than its predecessor."
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Intel Core Ultra 3 205 delivers impressive results in early review — reportedly surpasses previous-gen Core i3-14100 and Core i5-14400",
      "url": "https://www.tomshardware.com/pc-components/cpus/intel-core-ultra-3-205-delivers-impressive-results-in-early-review-reportedly-surpasses-previous-gen-core-i3-14100-and-core-i5-14400",
      "timestamp": "2025-09-16",
      "content": "Intel's Core Ultra 3 205 has impressed in early testing, with decent performance scores surpassing previous Intel budget picks."
    },
    {
      "source": "Forbes",
      "headline": "AVGO Stock vs. NVDA & INTC",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/16/avgo-stock-vs-nvda--intc/",
      "timestamp": "2025-09-16",
      "content": "The key question is: How does AVGO stock now compare to its peers, such as NVIDIA, Qualcomm, Intel, and Cisco, in terms of size, valuation, growth, and margins?"
    },
    {
      "source": "Biztoc.com",
      "headline": "What Is Going On With Intel Stock On Tuesday?",
      "url": "https://biztoc.com/x/a6deb868479fe7b3",
      "timestamp": "2025-09-16",
      "content": "President Donald Trump's administration plans to take a stake in Intel Corp (NASDAQ:INTC) to help the key U.S. chipmaker unlock value. The administration aims to replicate the public-private model that fueled Taiwan Semiconductor Manufacturing Co's (NYSE:TSM)…"
    },
    {
      "source": "Theregister.com",
      "headline": "Microsoft blocks bait for ‘fastest-growing’ 365 phish kit, seizes 338 domains",
      "url": "https://www.theregister.com/2025/09/16/microsoft_cloudflare_shut_down_raccoono365/",
      "timestamp": "2025-09-16",
      "content": "Redmond names alleged ringleader, claims 5K+ creds stolen and $100k pocketed\nMicrosoft has seized 338 websites associated with RaccoonO365 and identified the leader of the phishing service - Joshua Ogundipe - as part of a larger effort to disrupt what Redmond…"
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "MGX co-invests with Silver Lake in Altera acquisition",
      "url": "https://finance.yahoo.com/news/mgx-co-invests-silver-lake-142459477.html",
      "timestamp": "2025-09-16",
      "content": "DUBAI (Reuters) -MGX, an Abu Dhabi artificial intelligence investment firm and partner of Silver Lake, said on Tuesday it has joined the buyout group in..."
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Nvidia tipped to be TSMC's first 16A customer, ahead of Apple — Feynman GPUs could make full use of GAA transistors and backside power",
      "url": "https://www.tomshardware.com/tech-industry/semiconductors/nvidia-dethrones-apple-to-debut-tsmc-a16",
      "timestamp": "2025-09-16",
      "content": "Nvidia will be the first customer to use TSMC’s A16, a 1.6nm-class process that marries gate-all-around (GAA) transistors with backside power delivery."
    },
    {
      "source": "Forbes",
      "headline": "The Nvidia Deal And Taxing Exports: The Constitutionality Of It All",
      "url": "https://www.forbes.com/sites/taxnotes/2025/09/16/the-nvidia-deal-and-taxing-exports-the-constitutionality-of-it-all/",
      "timestamp": "2025-09-16",
      "content": "In this episode of Tax Notes Talk, Tax Notes contributing editors Robert Goulder and Joseph Thorndike discuss the recent Nvidia deal to export chips to China, and they question its constitutionality and implications."
    },
    {
      "source": "Digitimes",
      "headline": "Intel China chairmanship changes hands: Wang Rui retires, Wang Zhicong takes over",
      "url": "https://www.digitimes.com/news/a20250916VL205/intel-chairman-growth.html",
      "timestamp": "2025-09-16",
      "content": "Intel announced on September 16, 2025, that Dr. Wang Rui, chair of Intel China with more than 30 years at the company, will retire this month. The leadership transition has been underway since February 2025, when Wang Zhicong was named vice chairman to prepar…"
    },
    {
      "source": "Cybersecuritydive.com",
      "headline": "How the retail sector teams up to defend against cybercrime",
      "url": "https://www.cybersecuritydive.com/news/retail-isac-lessons-learned-scattered-spider/758504/",
      "timestamp": "2025-09-16",
      "content": "The cyberthreat intel-sharing and collaboration group RH-ISAC is helping companies confront cyberattacks. But the challenge is delivering timely intelligence in a dynamic threat environment."
    },
    {
      "headline": "20 tech giants that could be hit hardest by President Donald Trump's $100,000 H-1B visa fees",
      "content": "lighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nAn executive order signed by President Donald Trump late Friday, hiking H-1B visa application fees to $100,000, sent Silicon Valley into a tailspin.\n\nH-1B visas have become a mainstay of the tech industry, allowing companies to hire highly-skilled workers from abroad, including engineers.\n\nAffected tech workers and corporate lawyers initially scrambled to decipher the new policies, with companies like Amazon, Microsoft, and Meta telling employees on H-1B visas to either stay in the US or return from abroad within 24 hours.\n\nThe Trump administration subsequently clarified that the fees would only apply to new applicants, not renewals or current H-1B holders.\n\nThe Trump administration said it implemented the changes to prevent system \"abuses\" and to encourage companies to train American workers.\n\nSome applauded the new policy, including Netflix cofounder Reed Hastings, who said it could mean the end of the lottery system, given H-1Bs are capped at 85,000 workers annually. Others worried cash-strapped startups would be most severely affected, or that the executive order could counterintuitively push more jobs out of the country.\n\nBusiness Insider examined publicly available data from the Department of Labor and US Citizenship and Immigration Services (USCIS) to track which tech companies had the most H-1B visa approvals in 2025.\n\nBloomberg, Intel, and Nvidia declined to comment. The rest of the companies on this list did not respond to requests for comment from Business Insider.\n\nDo you have experience with the H-1B visa program? Business Insider wants to hear from you. Please fill out this quick form.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/h1b-visa-fee-hike-tech-giants-hit-hardest-donald-trump-2025-9",
      "timestamp": ""
    },
    {
      "headline": "Reviving a Scrapped Sound Blaster 2.0 ISA Soundcard",
      "content": "What do you do when you find a ISA Sound Blaster 2.0 card in a pile of scrap? Try to repair the damage on it to give it a second shot at life, of course. This is what [Adrian Black] did with one hapless victim, with the card in question being mostly in good condition minus an IC that had been rather rudely removed. The core Creative CT1336A and Yamaha YM3812 ICs were still in place, so the task was to figure out what IC was missing, find a replacement and install it.\n\nThe CT1350 is the final revision of the original 8-bit ISA Sound Blaster card, with a number of upgrades that makes this actually quite a desirable soundcard. The CT1350B revision featured here on a card from 1994 was the last to retain compatibility with the C/MS chips featured on the original SB card. After consulting with [Alex] from the Bits und Bolts YT channel, it was found that not only is the missing IC merely an Intel 8051-based Atmel MCU, but replacements are readily available. After [Alex] sent him a few replacements with two versions of the firmware preflashed, all [Adrian] had to do was install one.\n\nBefore installation, [Adrian] tested the card to see whether the expected remaining functionality like the basic OPL2 soundchip worked, which was the case. Installing the new MCU got somewhat hairy as multiple damaged pads and traces were discovered, probably because the old chip was violently removed. Along the way of figuring out how important these damaged pads are, a reverse-engineered schematic of the card was discovered, which was super helpful.\n\nSome awkward soldering later, the card’s Sound Blaster functionality sprung back to life, after nudging the volume dial on the card up from zero. Clearly the missing MCU was the only major issue with the card, along with the missing IO bracket, for which a replacement was printed after the video was recorded.",
      "source": "Hackaday",
      "url": "https://hackaday.com/2025/09/22/reviving-a-scrapped-sound-blaster-2-0-isa-soundcard/",
      "timestamp": ""
    },
    {
      "headline": "Lax Space: Designing With Duct Tape and Everyday Chaos",
      "content": "Want to build websites but don’t know where to start? Scrimba's Frontend Developer Career Path is the perfect beginner-friendly course to kickstart your journey! Created with Mozilla MDN, it teaches you modern web development skills step by step. Codrops readers get 20% off Pro plans!",
      "source": "Tympanus.net",
      "url": "https://tympanus.net/codrops/2025/09/23/lax-space-designing-with-duct-tape-and-everyday-chaos/",
      "timestamp": ""
    },
    {
      "headline": "Maya Man and Isabella Lalonde's 'The twentynine Experience' Proved Glitches Hit Harder Than Perfection",
      "content": "A conversation with Hypeart editor Erin Ikeuchi dug into the duo’s process: how imperfections became the point, how humor and distortion can undercut impossible beauty ideals, and why AI is a collaborator rather than a replacement. “Many of humanity’s most significant inventions have come from mistakes,” she noted. “That’s why I’m curious to see how AI will evolve through the unexpected, even beautiful errors it produces.”\n\n\n\nTwo takeaways defined the night. Maya Man framed AI as a tool of confrontation—not a shortcut—training on her own face and embracing distortions to expose bias and the pressure of self-image. “Because of how they’re trained, generative AI models act like a distorted reflection of the world as it already is,” she said. “For me, it was compelling to use that technology to recreate a style of imagery I’ve been surrounded by my whole life: advertising.”",
      "source": "HYPEBEAST",
      "url": "https://hypebeast.com/2025/9/maya-man-beepybella-twentynine-experience-event-recap",
      "timestamp": ""
    },
    {
      "source": "XDA Developers",
      "headline": "Arm is the future of desktop computing, and the writing is on the wall for x86",
      "url": "https://www.xda-developers.com/arm-future-desktop-computing-writing-wall-x86/",
      "timestamp": "2025-09-23",
      "content": "Arm has been slowly picking up pace in the last two decades, but the momentum is only growing stronger."
    },
    {
      "source": "Theregister.com",
      "headline": "SonicWall releases rootkit-busting firmware update following wave of attacks",
      "url": "https://www.theregister.com/2025/09/23/sonicwall_rootkitbooting_firmware_update/",
      "timestamp": "2025-09-23",
      "content": "Security vendor's no good, very bad week year\nSonicWall on Monday released a firmware update that the security vendor says will remove rootkit malware deployed in recent attacks targeting Secure Mobile Access (SMA) 100 appliances.…"
    },
    {
      "source": "Theregister.com",
      "headline": "Third time's the charm? SolarWinds (again) patches critical Web Help Desk RCE",
      "url": "https://www.theregister.com/2025/09/23/solarwinds_patches_rce/",
      "timestamp": "2025-09-23",
      "content": "Or maybe 3 strikes, you're out?\nSolarWinds on Tuesday released a hotfix - again - for a critical, 9.8-severity flaw in its Web Help Desk IT ticketing software that could allow a remote, unauthenticated attacker to run commands on a host machine. …"
    },
    {
      "source": "Windows Central",
      "headline": "How to watch Call of Duty Next 2025 — Reveals for multiplayer, Zombies, and Warzone content for Black Ops 7",
      "url": "https://www.windowscentral.com/gaming/call-of-duty/when-and-how-to-watch-call-of-duty-next-2025",
      "timestamp": "2025-09-23",
      "content": "Here's where to watch CoD NEXT so you can be informed on all of the upcoming Call of Duty content headed our way."
    },
    {
      "source": "PCWorld",
      "headline": "Finally! Windows 11 24H2 won’t break your webcam or Bluetooth anymore",
      "url": "https://www.pcworld.com/article/2918065/finally-windows-11-24h2-wont-break-your-webcam-or-bluetooth-anymore.html",
      "timestamp": "2025-09-23",
      "content": "Ever since version 24H2 of Windows 11 was rolled out to the public last autumn, there have been persistent problems with some webcams, which, among other things, made it difficult to use facial recognition to log in with Windows Hello.\r\n\n\n\n\nTo protect users, …"
    },
    {
      "source": "PC Gamer",
      "headline": "It's Alchemist, Battlemage or nothing: Intel driver support for every other GPU from the past four years moves into legacy mode",
      "url": "https://www.pcgamer.com/hardware/graphics-cards/its-alchemist-battlemage-or-nothing-intel-driver-support-for-every-other-gpu-from-the-past-four-years-moves-into-legacy-mode/",
      "timestamp": "2025-09-23",
      "content": "No game-related fixes or tweaks, just quarterly security updates."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Dean of Valuation Aswath Damodaran Says He’d Rather Have His Money in Intel Than NVIDIA (NVDA)",
      "url": "https://finance.yahoo.com/news/dean-valuation-aswath-damodaran-says-133245375.html",
      "timestamp": "2025-09-23",
      "content": "We recently published These 10 Stocks are Buzzing After Important Analyst Calls. NVIDIA Corp (NASDAQ:NVDA) is one of the stocks analysts were recently..."
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "Intel (INTC) in Focus: Citi Downgrades Shares Despite Nvidia Partnership",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_2349cb92-6ad4-4678-96d0-3a6879f10851",
      "timestamp": "2025-09-23",
      "content": null
    },
    {
      "source": "Yahoo Entertainment",
      "headline": "INTC: Intel, Nvidia Partnership Buys Time, Not A Near-Term Turnaround",
      "url": "https://finance.yahoo.com/news/intc-intel-nvidia-partnership-buys-124032570.html",
      "timestamp": "2025-09-23",
      "content": "Partnership With Nvidia Extends Intel's Runway, Not Its Results"
    },
    {
      "source": "Questdb.com",
      "headline": "From Rust to Reality: The Hidden Journey of Fetch_max",
      "url": "https://questdb.com/blog/rust-fetch-max-compiler-journey/",
      "timestamp": "2025-09-23",
      "content": "A compiler deep-dive tracing Rust’s AtomicU64::fetch_max from macro expansion and rustc intrinsics through LLVM’s atomicrmw umax and AtomicExpandPass to the final x86-64 CAS loop"
    },
    {
      "source": "PCWorld",
      "headline": "HP EliteBook 8 G1a review: AMD’s hardware shines",
      "url": "https://www.pcworld.com/article/2916785/hp-elitebook-8-g1a-review.html",
      "timestamp": "2025-09-23",
      "content": "At a glance\r\nExpert's Rating\r\n\n\nPros\r\n\n<ul>\n<li>Great combination of CPU performance and battery life</li>\n\n\n\n<li>Premium build quality</li>\n\n\n\n<li>Runs Copilot+ PC features with full x86 app compatibility</li>\n\n\n\n<li>Nice keyboard</li>\n</ul>\n\r\n\n\n\n\nCons\r\n\n<ul…"
    },
    {
      "source": "Sputnikglobe.com",
      "headline": "Europe Preparing to Occupy Moldova - Russian Intel",
      "url": "https://sputnikglobe.com/20250923/europe-preparing-to-occupy-moldova---russian-intel-1122838566.html",
      "timestamp": "2025-09-23",
      "content": "Western provocations to send forces into Moldova are possible during the elections to the Supreme Council of Transnistria on November 30, according to Russia’s Foreign Intelligence Service (SVR)."
    },
    {
      "source": "Tom's Hardware UK",
      "headline": "Intel drops day zero game driver support for chips released last year — last-gen iGPUs on 14th-gen Core and older CPUs already put on the backburner of legacy software support",
      "url": "https://www.tomshardware.com/pc-components/gpu-drivers/intel-drops-day-zero-game-driver-support-for-chips-released-last-year-last-gen-igpus-on-14th-gen-core-and-older-cpus-already-put-on-the-backburner-of-legacy-software-support",
      "timestamp": "2025-09-23",
      "content": "Intel announced that it will transition the integrated graphics on 11th- to 14th-generation processors to a legacy software support model, relegating its last-generation chips to the back burner. The company says that it will no longer release new features for these chips and will only provide software support for critical fixes and security vulnerabilities. It also reduces the update release cadence for the iGPUs from monthly to quarterly, and they will also lose Day 0 Game support.\n\nThis announcement affects both desktops and laptop chips. The 11th to 14th-generation Intel CPUs are still relatively new — the 14th-generation Raptor Lake Refresh CPUs first arrived in 2023, with new models released just last year, while the 11th-generation Tiger Lake processors launched in 2020. In effect, Intel is saying that your one-year-old Intel Core i5-14400 is already on the back burner.\n\nWhile an unwelcome move, the company is likely making this change to conserve resources and focus on its newer Arc graphics architecture. After all, Intel has cut 4,000 positions in the U.S. alone so far this year, with thousands of technicians and engineers being let go as the company fights hard for its survival.\n\nStill, many customers might feel betrayed; after all, if you bought a new processor, you expect it to be supported for at least five to seven years. This announcement will not brick your PC, and you still get critical and security updates quarterly. But you’re also not getting new features, and you might have issues with (or possibly not even be able to play) the latest games at launch.\n\nNevertheless, many users will likely not feel this. After all, gamers who typically download, install, and play a AAA game at launch most often have a discrete GPU installed on their system. In fact, even the most hardware-friendly titles, such as the upcoming Battlefield 6, require a modest graphics card like the Nvidia RTX 2060, AMD Radeon RX 5600 XT, or Intel Arc A380.\n\nEven though it makes sense for Intel to focus on its newer Core and Core Ultra chips, the fact that Intel is moving such a relatively new CPU line-up to legacy support could leave a bad taste in the mouths of some users.\n\nFollow Tom's Hardware on Google News , or add us as a preferred source , to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!"
    },
    {
      "headline": "Meet Lisa Su: CEO and president of Advanced Micro Devices, the main competitor to Nvidia",
      "content": "Lisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion.\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nLisa Su is widely credited for accomplishing one of the most dramatic turnarounds in the tech industry, bringing AMD from a struggling company to an industry leader with a market cap of more than $270 billion. REUTERS/Steve Marcus\n\nlighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nLisa Su is the engineer behind one of the most dramatic corporate turnarounds in the tech industry.\n\nThe Taiwanese American CEO is widely credited with transforming AMD from a struggling semiconductor firm on the brink of collapse into a global powerhouse competing head-to-head with Intel and Nvidia.\n\nWhen Su joined AMD in 2012, the company's market value was under $2 billion. Within a decade of her leadership, AMD's innovations in high-performance computing and graphics, especially the Ryzen CPUs and EPYC server processors, catapulted the company's value to roughly $270 billion as of October 2025.\n\nBut Su's leadership has not been without challenges. AMD's two largest competitors, Nvidia and Intel, are now working together in a strategic collaboration. Under the second Trump administration, export regulations related to China, one of AMD's largest markets, are also constantly changing.\n\nHere's a look at the timeline of Su's career, from her early life in New York City to her role as one of the most influential women in tech and innovation:",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/meet-lisa-su-ceo-and-president-of-advanced-micro-device",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "If you just need a laptop for the basics, this one at $349 is an absolute steal",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/asus-vivobook-15-gets-a-serious-discount/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Intel: What Next For The Chip Fabrication Giant?",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/digital-assets/2025/10/05/intel-what-next-for-the-chip-fabrication-giant/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Linux 6.18 DRM Pull Includes New Tyr & Rocket Drivers, More AMD & Intel GPU Enhancements",
      "content": "The Direct Rendering Manager \"DRM\" pull request ended up leading to Linus Torvalds complaining over text and Rust code formatting but in the end he pulled all of these kernel graphics driver updates and also the associated \"accel\" accelerator subsystem drivers too.With the Linux 6.18 DRM pull there is a lot of kernel graphics driver improvements across the board, including the new drivers of Tyr and the Rocket accelerator driver. For enhancing existing driver support, the AMD and Intel graphics drivers continue seeing a bulk of the activity. Plus ongoing Rust code work in the DRM subsystem and more.\n\nBelow is a look at the DRM kernel driver changes for Linux 6.18.- The \"Rocket\" accelerator driver is finally mainlined for enabling the NPU found on newer Rockchip SoCs. This is the open-source driver reverse-engineered and started by Tomeu Vizoso. The Rocket accel driver works with new user-space code in Mesa 25.3 for Rockchip NPUs.- The AMDGPU and AMDKFD Checkpoint and Resture \"CRIU\" support for GEM memory objects.- Expanded AMDGPU Video Core Next \"VCN\" engine reset support.- More AMD Cyan Skillfish updates.- The AMDXDNA accelerator driver now supports user-space allocated buffers, improved error reporting, and other enhancements.- A new Intel Xe driver interface for querying VMA count and memory attributes. The intel Intel SLPC \"power_profile\" sysfs interface for the Xe driver for power management tuning.- Intel Xe driver SR-IOV support for CCS surfaces on Xe2+. The SR-IOV PF mode is also now enabled by default on supported platforms. Intel has returned to working on the upstream Habana Labs accelerator driver . There still is no Gaudi 3 support but at least they are back to working on this code under a new set of maintainers.- Intel Xe driver support for madvise in GPU SVM (Shared Virtual Memory).- The Arm Mali Panthor DRM driver added support for Mali G710, G510, G310, Gx15, Gx20, Gx25 GPUs.- Continued work on Nova as the next-generation open-source NVIDIA Linux kernel driver written in Rust.- The initial code around Tyr as a new Rust driver for Arm Mali GPUs . It's not yet usable by end-users, similar to the Nova driver.- Various new Rust abstractions and other work toward making Rust DRM drivers more practical.See this pull for the full list of DRM feature patches this cycle.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-DRM",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "AMD Versal TRNG Driver Upstreamed To Linux 6.18, Intel Adds New Telemetry For QAT Gen6",
      "content": "All of the crypto subsystem changes have been merged for the in-development Linux 6.18 kernel.A new driver in the cryptographic subsystem is the AMD Versal TRNG driver . This provides true random number generator support with the AMD Versal Adaptive SoCs.\n\nThis driver was contributed by AMD directly for upstreaming to the mainline Linux kernel. This also joins other new Versal support in Linux 6.18 like the new Versal NET DDR EDAC driver Meanwhile the AMD Crypto Co-Processor \"CCP\" driver has added a new API for dealing with SEV-SNP virtualization around cipher text hiding.Over on the Intel side, earlier this year they introduced QAT Gen6 support . For QuickAssist/QAT Gen6 with the Linux 6.18 kernel they are adding ring buffer idle and command queue telemetry support.The crypto pull for Linux 6.18 also includes improvements to the HiSilicon crypto driver, a new TI driver with ECB/CBC AES support, and other changes. See the crypto pull for the full list of crypto changes that were merged to mainline yesterday.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-Crypto",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "I cloned my voice with AI and it was unsettlingly good",
      "content": null,
      "source": "MakeUseOf",
      "url": "https://www.makeuseof.com/ai-voice-clone-chatterbox/",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Haptic Touchpad Support Makes It Into Linux 6.18",
      "content": "The HID changes have been merged for Linux 6.18 and are headlined by initial support in the mainline kernel for haptic touchpad handling.As written about last month, haptic touchpad support is ready for the Linux kernel. Haptic touchpads contain force sensors and haptic actuators in place of a traditional button. Haptic touchpads can eliminate mechanical parts and provide a nice clicking effect across the entire touchpad.\n\nFor Linux 6.18, Google engineers were focused on the Elan 2703 haptic touchpad as their initial support target. Google has been leading the work on haptic touchpads for Linux in motivated by their own Chrome OS needs.In addition to the haptic touchpad support, another Linux 6.18 HID addition worth noting is the Sony DualSense controller audio jack handling work.Some of the other HID changes include HID-BPF to be able to re-bind a driver to hid-multitouch, making hidraw ioctls safer, PIDFF improvements, and better configuration of Intel QuickI2C via ACPI.More details on these HID feature updates for Linux 6.18 via this merge",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-HID",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Weekly Market Wrap: Intel, Nvidia and Electronic Arts made major news",
      "content": null,
      "source": "TheStreet",
      "url": "https://www.thestreet.com/markets/weekly-market-wrap-intel-nvidia-and-electronic-arts-made-the-most-news",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Microsoft's new Photos app update is so good that it could well become my favorite photo organizing tool - but you will need a Copilot+ PC to experience it",
      "content": "The app sorts receipts, screenshots, and handwritten notes automatically\n\nCopilot+ PCs are required for Microsoft’s newest Photos app functions\n\nAutomatic classification works even across different languages and scripts\n\nMicrosoft has released a new version of its Photos app, now presented as a more advanced tool for organizing and enhancing digital images.\n\nThe update, now live in the Microsoft Store, relies heavily on local artificial intelligence computation, with new functions tied specifically to Copilot+ PCs.\n\nThe app is not a dedicated photo editor, so it cannot be an Adobe Photoshop alternative. It instead focuses on sorting pictures, tagging documents, and upscaling low-resolution images with AI.\n\nAI-powered photo organization\n\nThe update brings automatic classification using an onboard neural processing unit to scan a library of pictures and sort them into categories such as screenshots, receipts, documents, and handwritten notes.\n\nThis system is meant to reduce the time spent scrolling through unstructured folders.\n\nMicrosoft also says the classification works across languages, so a receipt or document in another script should be tagged correctly.\n\nA “keyword” search option now allows users to quickly filter results, a function that might appeal to those who already store years of digital clutter inside their image folders.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAlongside organizational features, the update introduces a “super resolution” feature that can upscale low-resolution images without relying on external servers.\n\nThe work happens locally on the device, restoring detail that would normally disappear during enlargement.\n\nMicrosoft presents this as a way to bring older or compressed photographs closer to modern display standards.\n\nOn the downside, these AI functions are only available on Copilot+ PCs powered by Intel, AMD, or Qualcomm chips with NPU units.\n\nThat requirement places the most publicized upgrades out of reach for most current Windows users.\n\nIt also frames the Photos app as more of a showcase for Microsoft’s new hardware strategy than a universal solution for managing digital images.\n\nWhile the company promotes the update as a leap in convenience, the limitations suggest that many users will keep relying on existing tools.\n\nSome may stick with a free photo editor already familiar to them, while others will continue returning to established professional packages.\n\nFollow TechRadar on Google News and add us as a preferred source to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!\n\nAnd of course you can also follow TechRadar on TikTok for news, reviews, unboxings in video form, and get regular updates from us on WhatsApp too.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/microsofts-new-photos-app-update-is-so-good-that-it-could-well-become-my-favorite-photo-organizing-tool-but-you-will-need-a-copilot-pc-to-experience-it",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "The age of silicon and software began 75 years ago with the patenting of the transistor",
      "content": "75 years ago, the three Bell Labs scientists behind the invention of the transistor would, at last, have the U.S. Patent in their hands. This insignificant-looking semiconductor device with three electrodes sparked the third industrial revolution. Moreover, it ushered in the age of silicon and software, which still dominates business and human society to this day.\n\nThe first working transistor was demonstrated in 1947, but it wasn’t until October 3, 1950, that the patent was secured by John Bardeen, Walter Brattain, and William Shockley. The patent was issued for a “three-electrode circuit element utilizing semiconductor materials.” It would take several more years before the significant impacts transistors would have on business and society were realized.\n\nTransistors replaced the bulky, fragile and power-hungry valves, that stubbornly remain present in some guitar amplifiers, audiophile sound systems, studio gear, where their ‘organic’ sound profile is sometime preferred. We also still see valves in some military, scientific, and microwave/RF applications, where transistors might be susceptible to radiation or other interference. There are other niche use cases.\n\nBeyond miniaturization, transistors would deliver dramatic boosts in - computational speed, energy efficiency, and reliability. Moreover, they became the foundation for integrated circuits and processors, where billions of transistors could operate reliably in a much smaller footprint than taken up by a single valve. Processors featuring a trillion transistors are now on the horizon.\n\n1947: invention, 1950: patent, 1965: Moore’s Law, 2025: billions of transistors per chip.\n\nFor PC enthusiasts, probably the best known piece of transistor lore comes from Intel co-founder Gordon Moore. Of course, we are talking about Moore’s Law, which was an observation by the pioneering American engineer. Moore’s most famous prediction was that “the number of transistors on an integrated circuit will double every two years with minimal rise in cost.” (Law was revised from one to two years in 1975).\n\nImage 1 of 3 (Image credit: Intel) (Image credit: Intel) (Image credit: Intel)\n\nObviously, prior to 1965, when Moore’s Law was set out, the startling advance in transistor technology indicated that such an extrapolation would be reasonable. Even, now, certain semiconductor companies, engineers, and commentators reckon that Moore’s Law is still alive and well. You can see Intel's position in the slides, above.\n\nWhatever the case, it can’t be denied that since the patenting of the transistor, we have seen incredible miniaturization and advances in computing and software, expanding the possibilities of minds and machines. The current tech universe is actually buzzing with firms that reckon they can make machines with minds - artificial intelligence.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/semiconductors/the-age-of-silicon-and-software-began-75-years-ago-with-the-patenting-of-the-transistor",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Lenovo Legion Go 2 Review: A Handheld Made For Big, Meaty Claws",
      "content": "You buy Lenovo’s new Legion Go 2 handheld for the screen. The performance is secondary to how beautiful recent 2D titles look on the 8.8-inch, 1200p OLED display. The Legion Go 2 is otherwise a big, meaty handheld for gamers with big, meaty claws. You’ll struggle to hold it above your head lying in bed unless you’re a professional power lifter; the controls won’t be your favorite; it’s as wonky as its predecessor. And it’s hard to argue anybody should spend well over $1,000 on a gaming handheld rather than just buying a full gaming laptop.\n\nDespite all that, I can’t help but enjoy the hell out of it. My initial hours spent rolling my eyes at everything Lenovo failed to fix from its first iteration slowly morphed into the kind of appreciation that can only occur when a device starts to feel personal. It’s what happened when I downloaded Hollow Knight: Silksong and Hades II to the device and had to hold back a gasp on a crowded plane for how gorgeous both games looked on Lenovo’s big, expensive, beautiful display.\n\nLegion Go 2 It's thick, heavy, and so damn pretty. It's a shame it costs as much as it does. 4 See at Best Buy Pros Beautiful OLED display\n\n144Hz refresh rate with VRR\n\nNew ergonomics\n\nLow-wattage performance uplift Cons Annoying removable controls\n\nFPS mode is pointless\n\nReflective display\n\nVery expensive at $1,350\n\nIt’s the same feeling I get from Valve’s $550 Steam Deck OLED, which uses the same organic light-emitting diode screen technology to present deeper contrast and rich colors. Valve’s handheld maxes out at 800p on an older, custom AMD chipset. Even when you factor in performance and display size, the Steam Deck OLED is still a much, much better deal. My review unit version of the Legion Go 2 with the AMD Ryzen Z2 Extreme processor, 32GB of RAM, and 1TB of storage, costs $1,350. I could literally buy two Steam Decks for this price (more if I opted for the LCD model). For Lenovo’s inflated price, I could run out and buy three $450 Nintendo Switch 2 handhelds. You could nab a version of the Legion Go 2 that starts at $1,100 for a version with a AMD Ryzen Z2, but judging by my tests that chip will land closer in power to handhelds that are three years old and cost much less.\n\nIt’s a ridiculous scenario that consumers are taking the brunt of Donald Trump’s obsession with import taxes, aka tariffs. And in that way, consumers are screwed no matter what. The upcoming Asus ROG Xbox Ally X, which is set to launch on Oct. 16 with the same Ryzen Z2 Extreme chip, will set you back $1,000. The original Legion Go asked for $700 in 2023. The Asus ROG Ally X demanded $800 at launch last year. Both now retail at a higher price, likely due to tariffs. I would tell you to wait and buy a new handheld, but there’s no way to tell if prices might increase in coming months.\n\nReally? You kept FPS mode?\n\nWhat drives me mad using the Legion Go 2 is how Lenovo held back from improving over the 2023 handheld. The revised version is far more ergonomic than the two-year-old device with its sharp corners. Both handhelds let you remove each controller and play with the screen separated, like the Nintendo Switch. The Switch 2 did away with rails and went for magnetic connections for each Joy-Con 2, which makes attaching and detaching the controllers a little easier. Lenovo’s old and new system still use a series of exposed pins you jam into a cavity on each side of the screen. You need two hands and a strong pitching arm to remove each controller with a down and out motion. Reattaching them can be just as annoying.\n\nSee Lenovo Legion Go 2 at Best Buy\n\nThe controller uses Hall effect sticks that are much better at surviving stick drift, though they still feel a little too thin on my fingers compared to other handhelds I’ve used. The Legion Go 2 has slightly redesigned bumper buttons that make it easier to press and the same, large triggers. The $650 Legion Go S had a switch to enable instant triggers with less travel—better for first-person shooter games, but because of the removable controllers you’ll have to stick with the full range of motion.\n\nThe Switch 2’s big standout feature is its new mouse mode enabled just by putting the controller down on a table or your pant’s leg. Lenovo did it first on the Legion Go with its FPS mode. So is it any better now? No, absolutely not. You still need to remove the right controller and flick the “FPS” switch to turn on an optical mouse sensor. You then need to slot it into a base to hold it like an old-school flight stick, where the two side buttons act as the left and right mouse click. The DPI is still low enough you’ll struggle to get it working on anything but a desk. Even when you do, using a joystick and the FPS controller together necessitates changing the in-game controls. I tried it in both Cyberpunk 2077 and Borderlands 4, and it caused such havoc with both titles I was loathe to use the FPS mode again.\n\nAs for I/O, the Legion Go 2 has both a bottom and top USB-4 port. In theory, this could allow you to hook it up to an eGPU. More likely, it’s sole purpose is for charging or hooking up to a dock for HDMI passthrough. As much as Lenovo implies you’ll create a full “battle station” out of your device for instantaneous PC, you don’t want to hook it up to anything larger than a 1440p monitor, and only then for playing games most systems can run anyway.\n\nStrangely enough, one of the best improvements over the last generation handheld is the Legion Go 2’s new soft carrying case. The old case was very protective, but it was also enormous. The new version is smaller and more squat than the default Steam Deck case, which makes lugging around the 8.8-inch handheld onto planes surprisingly easy. There’s two little hidey-holes for the FPS mode stand, but since you’ll never use it, you can stick anything else in there. Just don’t tell me what.\n\nThe Legion Go 2 is so damn pretty\n\nAll the new ergonomics make it easier to hold, but not enough that it won’t feel heavy in your hands. You’ll find you’ll need a table or lap to rest your elbows on, or else you’ll use the built-in kickstand to prop it up on your desk. Either way you hold it, you’ll end up enjoying this handheld mostly for the display. As I said earlier, the 8.8-inch OLED display is sublime. It doesn’t have any higher screen resolution than the Legion Go’s 1,920 x 1,200, but it’s enough to make games pop.\n\nFor my hands, the Legion Go 2 is just large enough where I can grip it and access all the controls. Other users who are smaller in stature may not be so lucky. Ignore all those 11-inch handhelds out there. Near-9-inch devices are more than enough. The screen also sports a 144Hz refresh rate with VRR, or variable refresh rate. All those games that can hit above 100 fps (which, let’s be honest, will mostly be older or 2D titles), will look their peak on the Legion Go 2.\n\nThe screen feels bright enough indoors, but while Lenovo promises you’ll get 1,100 nits of HDR brightness, the screen is not great for using outdoors. It’s blinded by direct sunlight, and even sitting near a window you’ll see most details disappear. The screen is also very reflective. A matte coating would have dulled the display quality, but it’s at the risk of catching a glimpse of your girlfriend walking up behind you.\n\nRyzen Z2 Extreme isn’t a huge leap\n\nThe AMD Ryzen Z2 Extreme APU is purely iterative. If you’ve been watching like a hawk, hoping to devour the latest and fastest handheld chip, this isn’t it. The performance difference generation to generation is minimal. In some games, you could get 5 to 10 fps more at the highest TDP, or thermal design power, People who focus too hard on benchmarks will come away disappointed. If you care more about whether the system can play the latest AAA games, know that you’ll be able to achieve playable frame rates at the max 1200p resolution though only by dropping any hope of ray tracing for more-realistic lighting effects.\n\nSee Lenovo Legion Go 2 at Best Buy\n\nI’m fundamentally a gamer who refuses to drop the resolution of games for the sake of performance. I will lower graphics settings in a desperate attempt to eek out the minimum 30 fps. The Legion Go 2 can manage to take some AAA games into playable states at the max 35W of TDP (thermal design power) once the handheld’s engines are firing on all cylinders. TDP determines how much power is being sent to the processor, which will dictate overall performance. Borderlands 4 is one of those games notorious for running poorly on PC and consoles alike (you won’t find the game on Switch 2 in the coming days, either). I was able to get a stable sub-40 fps on the lowest possible graphics settings. I could achieve a little better frame rates in Indiana Jones and the Great Circle. Even at lower graphics settings, the game still looks and sounds great on the small screen.\n\nOlder games fare better. Control could average 40 to 49 fps at low settings with the handheld plugged in. The Shadow of the Tomb Raider benchmark at 1200p and medium settings preset with AMD’s FSR upscaling saw an average of 44 fps, while at 1080p with the same settings it could hit 48 fps. In Baldur’s Gate III, I could average above 60 fps in the open areas of Act 1 and get between 45 and 55 fps in the city environments of Act III.\n\nIn 3DMark benchmarks, the Legion Go 2 hit a score of 3,305 and 24.48 average fps in Steel Nomad Lite tests. That’s 1,000 points better than the Legion Go S with its Ryzen Z2 Go chip running on Windows, but it’s only a little more than 300 points better than the Z1 Extreme on the Asus ROG Ally X from 2024. The new device hit 3,897 points in Time Spy tests, which again is barely more than 300 points better than an Ally X. It’s not much better than an MSI Claw 8 AI+, which uses a full Intel laptop chip. Simply put, the Legion Go 2 isn’t a huge step over the previous gen at the max wattage.\n\nHowever, the device’s secret sauce is in how well it performs at lower wattages. Tests with multiple games at wattages as low as 34 fps still enabled relatively stable frame rates in games like Shadow of the Tomb Raider. While in Cyberpunk 2077 at full resolution and Steam Deck settings, the device gets 44 fps in benchmarks, at 15W it still managed to eek out nearly 30 fps. I don’t expect anybody will run high-end games on lower power. Instead, the best experience comes from games that are far less intensive. I could net well over 160 fps in Hades II on the “Balanced” performance setting. Hollow Knight: Silksong seems like it was built with the Legion Go 2 in mind with automatic settings to stay around 144Hz. These games play so gloriously on this handheld, I don’t want to play them on anything else. It’s a shame you have to spend $350 more than an Xbox Ally X jut for that pretty screen and higher refresh rate.\n\nWindows still sucks for handhelds, but it could get better\n\nOn balanced power settings, I could game for around 2 hours and 40 minutes before the device was literally begging me to plug it in. In other tests where I was gaming at the full resolution and wattage playing Indiana Jones, it lasted closer to 2 hours. The Legion Go 2 sports a 74Wh battery, which is slightly worse than the ROG Ally X’s 80Wh. The larger OLED display and higher max resolution will inevitably drag the battery life down.\n\nAt this point, players should not expect a handheld that will last very long. The ROG Ally X still has one of the best battery life at full power when it gets closer to 3 hours of runtime. In real life, the difference is negligible. At this point in my life, having a max two hours of playtime is strangely beneficial. If I’m clearing room after room in Hades II late at night, the battery timer is essentially my alarm. If it’s close to 12 a.m. and I’m about to run out of power, it’s a sign I should get some rest.\n\nDepending on the game you’re playing, the device’s fans can get relatively loud. Even at max speed I wouldn’t call them jet engine noise. It’s enough to remind you to be mindful when sitting next to strangers on a plane. The device kept very cool in my time using it. I never felt any heat around the controls, and the area around the fans also didn’t feel steamy when playing a game at max wattage.\n\nI can’t excuse the price, but I had such a good time with the Legion Go 2 it felt like a personal companion after traveling for more than a week and a half away from home. But there’s an elephant in the room shaped like a big “X” we need to address. The Xbox Ally and Xbox Ally X are supposed to launch with a new version of Windows, dubbed the “Full Screen Experience” (FSE) built exclusively for gaming handhelds. While this may fix the lingering usability issues of Windows 11 on a 7- or 8-inch screen, the upgrade should also eliminate background tasks and—hopefully—boost performance by 20%. The issue is that Microsoft has said you may need to wait until next spring to get it on handhelds like the Legion Go 2.\n\nWindows is terrible on handhelds. It gets in the way when trying to put the device to sleep while still in-game. It bombards you with popups for OneDrive that you need to use the touchscreen to excise. It saps power and makes the device run worse than it would if it was running SteamOS, the same Linux-based operating system running on the Steam Deck. In our tests, the Legion Go S with SteamOS outperforms its Windows counterpart by 20 to 30%. Unless you’re dead set on keeping your Xbox Game Pass games handy, I would suggest looking into installing Valve’s software on the Legion Go 2. I have not confirmed whether you can install SteamOS on the new handheld, though if its not compatible at launch, I assume an update may be around the corner. Without the FSE or SteamOS, this can’t be my handheld of choice. With a new operating system, the Legion Go 2 would become the bell of the ball for modern PC handhelds.\n\nSee Lenovo Legion Go 2 at Best Buy",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/lenovo-legion-go-2-review-a-handheld-made-for-big-meaty-claws-2000666394",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Intel's \"Panther Lake\" Microarchitecture Deep Dive Set for October, Full Launch in 2026",
      "content": "The story of Intel's first 18A product, \"Panther Lake,\" remains shrouded in mystery, at least for a few more days. According to earlier reports, Intel was expected to start shipping the first PTL-U and PTL-H SKUs by the end of 2025, with additional SKUs to follow in 2026. However, that situation could be subject to change, according to Golden Pig Upgrade. The rumored October 9 launch date is reserved only for the microarchitecture deep dive, and the launch and final specifications of specific models will occur at CES 2026. Being Intel's first big bet with the 18A node, Panther Lake is a product of years of Intel's manufacturing innovation, which needs to demonstrate that the investment in advanced manufacturing was worthwhile. Reportedly, Intel started limited shipments of its 18A nodes to U.S. customers in Q3, with these wafers already in production and initial output of its own CPUs expected in Q4.Given that Panther Lake is the first 18A node product, we could expect that to be a large part of those shipped wafers, most likely going to OEMs for testing before integration. As a reminder, the low-power PTL-U models are designed for a 15 W TDP and are expected to come in 6-core and 8-core versions. Some SKUs will feature four high-performance P-cores paired with four LPE-cores, while others will have only two LPE-cores complementing four P-cores. Both families will utilize Xe3-based integrated graphics, with entry models featuring four GPU cores. The more powerful PTL-H line will scale up to around 16 CPU cores, comprising four P-Cores, eight E-cores, and four LPE-cores. Some H-series parts might include up to 12 GPU Xe3 cores for integrated graphics, but the final configurations will be revealed when Intel officially launches the Panther Lake product family.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341614/intels-panther-lake-microarchitecture-deep-dive-set-for-october-full-launch-in-2026",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "I went to a day trading meetup and spoke to people with dreams of getting good enough to quit their 9-to-5",
      "content": "Some traders at TraderDaddy's 2-hour class said they aspired to become full-timers.\n\nSome traders at TraderDaddy's 2-hour class said they aspired to become full-timers. Jutharat Pinyodoonyachet for BI\n\nSome traders at TraderDaddy's 2-hour class said they aspired to become full-timers. Jutharat Pinyodoonyachet for BI\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nThe day trader persona on social media looks something like this: A man with a sporty vibe and the swagger of a finance bro says he hit it big in the stock market — and you can too.\n\nYou probably don't envision a room of tired 9-5 workers, poring over candlestick charts and quietly looking for their next big trade. Yet, that's what I found in midtown Manhattan last week when I shadowed an in-person trading course hosted by TraderDaddy, a trading education and mentoring company that says it's been successful at turning some amateurs into profitable traders.\n\nThere are no guarantees, Daniel Alhanti, the CEO and head instructor at TraderDaddy, told the room. Much of a trader's success depends on how hard they're willing to work to understand the market, he said.\n\nThe well-known difficulty of day trading hasn't stopped many Americans who quietly dream of quitting the 9-to-5 lifestyle from trying to make a living in the market. Many, too, have dropped serious cash on courses, coaching, and other kinds of mentorship to boost their chance of success.\n\nThese services have been around for a long time, but they've become more sought after in the years since the pandemic retail-trading boom. According to the Google Trends analytic tool Glimpse, global search interest for \"day trading class\" is up 700% the past quarter and hit an all-time high this summer. Search interest in \"trading coach\" is up 325% over the same timeframe, while interest in \"day trading group\" is up 572%.\n\nOn Coursera, enrollment in online trading courses soared 213% from 2019 to 2024, according to data the online course provider shared with Business Insider. The online trading platform Webull also says it's seen the number of users on its learning platform grow 37% over the last three years.\n\nTraderDaddy's Alhanti, who worked as a financial advisor before becoming a trading instructor, said he witnessed firsthand the surge in interest in trading courses and groups, such as the one he runs.\n\n\"And a lot of it is the same story,\" he said of the wave of newcomers in recent years. \"'I was watching trading on social media, saw people doing it, and I tried to teach myself on YouTube. I couldn't really find anyone else that was doing it, and I was just looking for someone to help me.'\"\n\nAlhanti, who worked as a financial advisor before becoming a trading instructor, says he can identify a successful trader when he sees one. Jutharat Pinyodoonyachet for BI\n\nThe class I attended took place in the evening and had about 30 people in it, with men making up about three-quarters of the class. People trickled into the coworking space a little before 7 p.m. and began to whip out their notebooks, giving it a college lecture vibe.\n\nHere's everything I took away from the night.\n\nThere were a lot of beginners eager to get started\n\n\"Who here is an absolute beginner?\" Alhanti said, gauging the sprinkling of hands that popped into the air. \"Who here has invested in crypto? Option contracts?\"\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nI was surprised at how many in the group appeared to be new to this. Later, when Alhanti asked traders to list the top market-moving events of 2024, the class seemed stumped before someone brought up the presidential election, tariffs, and the Fed rate-cutting cycle.\n\nTraderDaddy says it has noticed an explosion of interest in day trading groups in recent years. Jutharat Pinyodoonyachet for BI\n\nAttendees were passionate about markets\n\nThere seemed to be high enthusiasm for the market. In a side discussion, a few traders spoke heatedly about option contracts for Palantir and whether a particular trade had been profitable.\n\n\"I think they just want to make money more than anything,\" Gerardo Arevalo, a trader at the event, told me, speaking about the work ethic of the group.\n\nAlhanti says he can tell when a trader will be successful. \"You can see it in their eyes when they focus,\" he told me after the class.\n\nBecoming a successful trader is notoriously hard. A 2020 study found that 97% of investors who traded for more than 300 days lost money, and less than 1% earned $54 or more a day.\n\nTechnical analysis and independent thinking were emphasized\n\nFor two hours, Alhanti walked the group through candlestick charts and technical analysis for trades he said his students were most interested in, which included Apple, Tesla, Intel, and the broader S&P 500. The goal was to identify a price breakout—such as when a stock suddenly trades above its 200-day moving average—and of course, buy at the right time.\n\nAlhanti said he wanted to see traders become confident and skilled enough to make their own decisions when trading, as opposed to relying on him to tell them when to buy and sell.\n\nSometimes, when traders in the group make a profit, they text Alhanti in a panic, asking him what to do next, he said.\n\n\"Do not just blindly follow me,\" he said to the class.\n\nMany desire to quit their jobs\n\nA strong desire for financial freedom was a common sentiment among the aspiring traders.\n\nJoshua Villas, a 23-year-old trader who sat in the back, told me he'd spent more than $900 on trading courses. He said he became interested in trading after a conversation with a friend not long after graduating from high school. The gist of the conversation was that day-trading was a ticket to financial freedom.\n\n\"Just hearing that and knowing that someone told you and actually seeing it's real — You kind of just keep going and trying,\" Villas said.\n\nVillas, who was recently laid off from his job as a stylist, added: \"I'd say the end goal is just not to have to worry about survival. I would be happy if I was just able to make enough to keep living.\"\n\nAlhanti says he frequently comes across aspiring traders who say they feel lost or stuck in their careers. Jutharat Pinyodoonyachet for BI\n\nThat's a common story among many traders Alhanti works with. In recent years, he says he's met more younger people who are aspiring traders, people who are unsure of how to start their careers but want income and are seeking mentorship.\n\n\"They don't really know what type of career they want, or where to go, or what to do, but they know that they want to have multiple incomes in their life, trading being one of them,\" Alhanti said.\n\nYacoub Rahman, a 21-year-old college student who trades on the side, said his goal is also to one day become a full-time trader. That endpoint is appealing, largely because trading \"full-time\" isn't anything like working a full-time job, he said.\n\n\"I don't think it would take a long time. Two or three hours, I guess that's enough,\" he predicted about the amount of work required each day.\n\nRahman said he spent around three hours a day studying the market after completing his schoolwork. He added that he aspired to one day have plenty of free time to travel.\n\nArevalo, a 50-year-old trader and computer programmer, said he had effectively entered early retirement and was looking to trade for a living.\n\nBefore trading, Arevalo said he job-hopped, as he was past his prime as a coder and felt expendable to companies he worked for. He now spends six to eight hours a day trading.\n\nAlhanti says he feels bad for many of the traders who come to him feeling lost in their careers, particularly younger people. He himself was caught in the 2008 recession, when the job market for young adults was brutal.\n\n\"They just generally feel behind, and they don't really know what their next steps are,\" he said of younger traders. \"I think a lot of them are really trying to find something that is going to really put them ahead.\"",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/day-trading-course-learn-to-trade-stock-market-quitting-job-2025-9",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "TechCrunch Mobility: Toyota makes a $1.5B bet on the startup ecosystem",
      "content": "Welcome back to TechCrunch Mobility, your hub for all things “future of transportation.” To get this in your inbox, sign up here for free — just click TechCrunch Mobility!\n\nMore than a month ago, I asked you, dear reader, how you thought EV sales would play out once the $7,500 federal tax credit expired on September 30. The majority of those who responded to the poll predicted that EV sales would fall off a cliff.\n\nNow, it’s too early to tell yet; we are just a few days past the end of the quarter. But the expiring tax credit did give many automakers a bit of a sales bump as consumers raced to buy EVs before the deadline.\n\nTesla, which has seen sales growth diminish, just registered its best quarter of deliveries ever at 497,099 vehicles. That’s a massive 29% jump from the second quarter, about a 7% increase over the same period last year, and more than it has ever delivered in a single quarter.\n\nFord Motor, General Motors, and Hyundai also reported record quarterly sales of EVs. Rivian saw deliveries jump to 13,201 vehicles, up from 10,661 and 8,640 in the second and first quarters, respectively.\n\nThe looming question is how will automakers navigate a possible slowdown in EV sales in this post-tax credit era? Rivian has already adjusted its guidance down for 2025. Others may follow.\n\nThe crux for automakers is how to get rid of inventory as the new 2026 models come in without reducing or eliminating profit margins (and in some cases deepening the losses)?\n\nA little bird\n\nImage Credits:Bryce Durbin\n\nThe Department of Energy canceled 321 clean energy projects but wasn’t sharing the details with TechCrunch or the public. Luckily, a little bird shared the complete list of awards the Trump administration had canceled, and the results were revealing.\n\nAltogether, the canceled awards totaled $7.56 billion, with California bearing the brunt, losing $2.2 billion worth of grants, including a $630 million grid-modernization program that could have become a template for the nation. Colorado, Illinois, Massachusetts, Minnesota, New York, and Oregon rounded out the top eight, losing between $300 million and $600 million each.\n\nIt wasn’t until farther down the list that a red state popped up. Indeed, the majority of projects were sited in states that had voted for Kamala Harris in the last presidential election, something many media outlets reported after Office of Management and Budget chief Russell Vought tweeted as much.\n\nBut even in blue states, some awards stuck, possibly due to political connections with the Trump administration or aligned interests. Whatever the case, the move by the DOE suggests the government might be a less reliable partner for businesses, especially small startups.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/techcrunch-mobility-toyota-makes-1-160300263.html",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Legion 5i Gen 10: 15.1\" QHD+ 165Hz OLED, Intel Ultra 7 255HX, RTX 5070, 16GB DDR5, 1TB SSD $1262.24",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18662788-legion-5i-gen-10-15-1-qhd-165hz-oled-intel-ultra-7-255hx-rtx-5070-16gb-ddr5-1tb-ssd-1262-24",
      "timestamp": "2025-10-05"
    },
    {
      "headline": "Many Debian/Ubuntu Packages For Intel Accelerators & Other Intel Software Have Been Orphaned",
      "content": "In addition to some Intel Linux kernel drivers being \"orphaned\" following the corporate restructuring at Intel between developers being laid off and others deciding to pursue opportunities elsewhere, these changes have also led to a number of Intel-related software packages within Debian being orphaned. In turn these Intel packages are also relied on by Ubuntu and other downstream Debian Linux distributions.Around one dozen Intel packages within the Debian archive were recently orphaned, a.k.a. now being unmaintained following developer departures from Intel with no one currently taking up the new responsibility, with also needing to be a Debian Developer or Debian Maintainer to contribute.\n\nAmong the Intel-related packages within Debian to recently be marked as orphaned include:- The package for configuring the Intel Data Streaming Accelerators \"DSA\" IP on recent Xeon processors. This is needed for properly configuring the DSA accelerators from user-space for interfacing with the kernel drivers.- Intel QuickAssist Technology OpenSSL engine support.- The QuickAssist Technology library for making use of that hardware acceleration for offloading security, authentication, and compression services.- The Zip library utilizing QAT.- The cache monitoring and configuration of Intel Cache Monitoring Technology, Memory Bandwidth Monitoring, and Cache Allocation Technology.- The Intel Low Power Model Daemon for optimizing active idle power on Intel systems.- The Intel Cryptography Primitives Library.- Intel Multi-Buffer Crypto for IPSec.- Intel's NumaTOP observation tool.- Intel's Power Stress and Shaping Tool (PSST).- The Intel Thermal Daemon.- Thunderbolt / USB4 debugging tools.These packages were all orphaned last month and haven't seen anyone stepping up to maintain them for Debian either from Intel Corp or other interested Debian developers from the community or other organizations. This follows some Intel drivers in the upstream Linux kernel being orphaned like the Intel CPU temperature monitoring driver and Intel also having recently ended open-source projects like the x86-simd-sort library and the sad demise of Clear Linux With the user-space accelerator packages like QAT and DSA being impacted as well as various other Intel libraries and even NumaTOP and other utilities, this could pose a problem if no one steps up to maintain these packages long-term. Again, not only Debian itself being affected but also Ubuntu and other downstream Debian-based Linux distributions. This is a set-back for a nice out-of-the-box experience for Intel hardware on Debian/Debian-derived operating systems and could make it more difficult to leverage Intel accelerators moving forward if having to either run the outdated packages, build your own code from source, or relying on generic packages from Intel.com where available. Hopefully this lack of Intel maintainership to these Debian packages can be rectified soon.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Intel-Debian-Packages-Orphaned",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "These co-CEOs can't imagine running things on their own",
      "content": "Connor Diemand-Yauman and Rebecca Taber Staehelin are co-CEOs of the nonprofit Merit America. The times they've disagreed on strategy tested their thinking in ways that were \"exponentially beneficial,\" she said.\n\nConnor Diemand-Yauman and Rebecca Taber Staehelin are co-CEOs of the nonprofit Merit America. The times they've disagreed on strategy tested their thinking in ways that were \"exponentially beneficial,\" she said. Courtesy Merit America\n\nConnor Diemand-Yauman and Rebecca Taber Staehelin are co-CEOs of the nonprofit Merit America. The times they've disagreed on strategy tested their thinking in ways that were \"exponentially beneficial,\" she said. Courtesy Merit America\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nWhen Connor Diemand-Yauman popped the question to Rebecca Taber Staehelin, he got down on a knee and handed her a rose.\n\nHis gesture drew the attention of others at the Italian food hotspot in San Francisco, where the colleagues were discussing how to structure their work partnership.\n\n\"Everyone in the restaurant started applauding because they thought we were getting married,\" Diemand-Yauman told Business Insider.\n\nWhat he was actually asking Taber Staehelin to formalize in 2019 was their decision to serve as co-CEOs of Merit America, a nonprofit they had founded the year before to help low-wage workers build skills and reach the middle class.\n\nDiemand-Yauman and Taber Staehelin's business arrangement is fairly unusual. There are fewer than 40 public companies in the US that operate with dual CEOs, according to the analytics firm Boardroom Alpha. Yet the setup is having a moment: In little more than a week, Spotify, Comcast, and Oracle have recently announced that they will have co-CEOs lead their organizations.\n\nInstead of getting bogged down by the potential risks of partnerships — uneven power splits, fuzzy accountability, or strategic clashes — some companies are embracing the idea that, in a period when many CEOs' remits are broader than ever, more can be more.\n\n\"It really has allowed us to specialize in the things that we're respectively passionate about and great at,\" Mike Sobel, co-CEO of fintech company Trumid, said of the division of labor he has with his counterpart, Ronnie Mateo.\n\nKnowing who does what\n\nSobel joined Trumid in 2014, when the startup was about five months old. For years after, he and a growing number of colleagues — mostly bond traders and salespeople with experience from across Wall Street — worked alongside Mateo to build a fixed-income platform. In the early days, there were few job titles or defined responsibilities, Sobel told Business Insider.\n\n\"It was just like, 'Everyone grab a shovel,'\" he said.\n\nTrumid co-CEOs Ronnie Mateo and Mike Sobel sometimes \"disagree vehemently,\" but because it's in service of the right answer, it's productive, Sobel said. Courtesy Trumid\n\nAs the company grew, especially during the boom years of the pandemic, so did the need to draw sharper contours around who did what. That clarity was necessary, Sobel said, both for new clients and for employees who joined the New York firm when lockdowns meant people weren't coming to the office. When it had been a smaller group in one place, knowing where to go wasn't as much of a challenge, he said.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nTrumid now has 200 employees and saw its average daily trading volume increase by 62% in 2024, reaching $1.4 trillion for the year.\n\n\"It's very important that titles reflect the reality of responsibilities, and who is accountable for what,\" Sobel said. So, in 2021, Trumid elevated him to co-CEO so that he could run the day-to-day, while Mateo, who founded the company, could be the indefatigable \"locker-room leader,\" chief sales guy, and face of the company, Sobel said.\n\n\"Ronnie is the visionary and the star player,\" he said.\n\nSobel said that internally, in particular, staffers understand who runs what and know that they \"can get a final answer from either one of us.\"\n\nAmong the company's half dozen top execs, there's also a clear sense of who is the specialist in each area, he said.\n\nWhen it comes to decision-making, Sobel said, he understands when it's a call he can make on his own versus one that's consequential enough to merit consulting with Mateo or others on the executive team. In some cases, Sobel might simply want a gut check.\n\n\"I should — and want to — talk to my partner about this, because it's really important,\" he said.\n\nAnother key factor, Sobel said, is the faith he and Mateo have in each other and the rest of their team.\n\n\"I trust in terms of motives, and also trust in terms of excellence,\" he said.\n\nWhen disagreements arise\n\nSobel said he and Mateo tend to be the opposite when it comes to their instincts, which can lead to \"heated debates.\"\n\nYet, because both of them are clear on the shared goal, \"you could disagree vehemently, but it's in the service of the right answer,\" he said. \"It is a productive exercise.\"\n\nSobel said the firm subscribes to the \"disagree and commit\" mantra popularized by Jeff Bezos at Amazon, as well as by former Intel CEO Andy Grove. When leaders at Trumid make a decision, the team gets on board and, regardless of how it turns out, \"there is no keeping score,\" Sobel said.\n\nDiemand-Yauman and Taber Staehelin see it similarly. Early on, Taber Staehelin said, before they became \"a hive mind,\" most disagreement emerged over annual budgeting. She said she tended to be more conservative, while Diemand-Yauman sought to be more ambitious in his approach to investing in growth.\n\nTo resolve disputes, Taber Staehelin said, the pair would step back to refocus on what they were trying to accomplish.\n\n\"It really tested the rigor of the thinking in a way that was exponentially beneficial,\" she said.\n\nTaber Staehelin still has the rose that Diemand-Yauman gave her at a restaurant when they decided to become co-CEOs. Courtesy Merit America\n\nThat's why Diemand-Yauman sees value in having a human copilot. \"When you do it right, it is far better than a single CEO, and when you do it wrong, it's far worse.\"\n\nHe said he wouldn't want to be a solo CEO again, as he was at a prior nonprofit he founded.\n\n\"I can't imagine starting or leading something without a partner,\" Diemand-Yauman said. In part, he said, that's because being a sole CEO can be isolating and because it's often hard to get a straight answer from other teammates.\n\nTaber Staehelin still has the rose that Diemand-Yauman gave her, which she keeps in a shoe box. It's a reminder of what each of them, both of whom are married, has invested in their work spouse.\n\n\"You are with someone who is in the trenches with you and can empathize with what you're going through, who will always honor confidentiality and create a safe space for you to vent and problem-solve,\" Diemand-Yauman said.\n\nTaber Staehelin agreed: \"He's Taylor; I'm Travis.\"",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/co-ceos-on-benefits-having-shared-responsibilities-2025-10",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Cramming for Week 5: Five fantasy sleepers, three predictions, three trends and an intriguing bet",
      "content": "Open Extended Reactions\n\nWeek 5 of the 2025 NFL season is here, and our NFL analysts have you covered in the eleventh hour. Don't miss our last-minute prep for a loaded slate.\n\nHere's what we have: First, analytics writer Seth Walder breaks down three stat trends that could be pivotal this weekend. Then fantasy football writer Eric Moody runs through five players who are rostered in under 50% of ESPN fantasy football leagues as of Saturday and could be started in a jam. That's followed by NFL analyst Matt Bowen predicting three potentially big surprises and sports betting analyst Pamela Maldonado giving her favorite bet for Week 5.\n\nWill the Giants' offense roll against the Saints? Can Lions defensive end Aidan Hutchinson get multiple sacks against the Bengals? Will Browns CB Denzel Ward snag an interception for the second straight game? Which two QBs have sneaky fantasy value this week? And could we see a bunch of points in the Raiders-Colts game? Let's dive in.\n\nJump to:\n\nStat trends | Fantasy sleepers\n\nPotential surprises | Best bet\n\nWalder: Three key stat trends that could determine Week 5 winners\n\nCan Giants receivers Wan'Dale Robinson and Darius Slayton step up against the Saints?\n\nThe numbers suggest they can. New Orleans has one of the most pass-inducing defenses in the NFL, ranking second highest in pass rate over expectation allowed (plus-2%), per NFL Next Gen Stats. It's easy to see why. While the Saints' defense allows minus-0.10 EPA per designed carry (ninth best), it allows 0.25 EPA per dropback (fourth worst).\n\nTwenty-one percent of passes against New Orleans are thrown to receivers in the slot, which ought to specifically help Robinson, who has lined up in the slot 69% of the time. It doesn't end there, as the Saints have allowed 8.6 air yards per attempt this season (fourth most), which should play right into the hands of Slayton, a deep threat who is averaging 12.7 air yards per target.\n\nIs Lions edge rusher Aidan Hutchinson headed for another multi-sack day against the Bengals?\n\nI'm a little surprised to see the Lions leading the entire league in defensive sack rate (10.6%), but Hutchinson is hot since returning from leg surgery. He has a sack in three straight games, including two last Sunday against the Browns. He also ranked in the top five in pass rush win rate at edge that week. Now he and the Lions get to face a Bengals team that is struggling mightily in pass protection.\n\nAs a team, the Bengals rank dead last in pass block win rate (44.6%). Against the Broncos last week, both tackles Amarius Mims and Orlando Brown Jr. ranked in the bottom five in pass block win rate at their position. Add in that backup QB Jake Browning has been sacked 8% of the time (higher-than-average rate), and that the Bengals should have to pass plenty as underdogs. So Hutchinson (and perhaps Al-Quadin Muhammad) should be in for a productive pass rushing day.\n\nCan RB Woody Marks and the Texans have rushing success against the Ravens?\n\nMarks, a fourth-round rookie, burst onto the scene against the Titans with 17 carries for 69 yards and a rushing touchdown; he also had 50 more yards and a touchdown in the receiving game. And there's reason to believe that success could continue this week, thanks to a schematic change this season.\n\nUnder new offensive coordinator Nick Caley, the Texans have shifted from a heavy outside zone team to a heavy duo team, a downhill scheme that uses double-team blocks. Since the start of last season, the Ravens have allowed 3.4 yards per carry to outside zone but 5.0 to duo. The Lions, most notably, gashed Baltimore with duo plays (9.5 yards per carry!) in Week 3.\n\nMoody: Five fantasy sleepers you need to pick up -- and can start this week\n\nRico Dowdle, RB, Carolina Panthers (39.6% rostered)\n\nChuba Hubbard has been ruled out of Sunday's game against the Dolphins with a calf injury, putting Dowdle in line for a heavy workload. He should find success against a Miami defensive front that ranks 28th in run stop win rate and has allowed the seventh-most fantasy points per game to running backs this season. Last season with the Cowboys, Dowdle averaged 12.3 fantasy points in games where he saw 15 or more touches.\n\nJaxson Dart, QB, New York Giants (36.6% rostered)\n\nDart hit the ground running against the Chargers in his first career start, not only leading the Giants to a win but also delivering 19.8 fantasy points. He generates production with both his arm and his legs, and as Seth mentioned above, he has capable targets in Robinson, Slayton and Theo Johnson. The rookie draws a favorable matchup against a Saints defense that has allowed the fifth-most fantasy points per game to quarterbacks.\n\nplay 1:21 Warner: You could feel the spark Jaxson Dart gave the Giants Kurt Warner joins \"The Rich Eisen Show\" to recap Jaxson Dart's performance vs. the Chargers.\n\nElic Ayomanor, WR, Tennessee Titans (35.5% rostered)\n\nAyomanor is the lone bright spot in a Titans offense that ranks 31st in total yards per game (210.5) and 32nd in points per game (12.8). He leads Tennessee in targets (25), receiving yards (151) and touchdowns (2), averaging 9.8 fantasy points per game. That's a solid floor, but his ceiling could be even higher against a Cardinals defense that has allowed the third-most receptions per game to wide receivers.\n\nBrenton Strange, TE, Jacksonville Jaguars (35.1% rostered)\n\nStrange has posted at least 10 fantasy points and seven targets in two straight games. He also leads the Jaguars in receptions (19) and receiving yards (182). He offers fantasy managers a high floor, with at least four catches and 45 yards in three games this season. Strange hasn't found the end zone yet, but that could change against the Chiefs, who might prioritize stopping the Jaguars' prolific running game in the red zone.\n\nBryce Young, QB, Carolina Panthers (15.2% rostered)\n\nYoung is off to a poor start for the second straight season, and a strong performance against Miami could be crucial to getting back on track. He is averaging just 12.9 fantasy points per game, but the Dolphins' defense has allowed the second-most fantasy points per game to opposing quarterbacks. Carolina would be wise to lean on its run game behind an offensive line that ranks seventh in run block win rate, and then build off that with play-action passes against a subpar Miami pass rush.\n\nBowen: Don't be surprised if ...\n\nGiants RB Cam Skattebo scores a touchdown against the Saints\n\nWith Skattebo taking over the lead role in New York, his volume and scoring opportunities are up in Brian Daboll's offense. Skattebo scored a touchdown in two of the past three games and had seven goal-to-goal carries. Plus, with his pass-catching ability (12 receptions), Skattebo could find the end zone on an underneath throw from quarterback Jaxson Dart. The Saints has allowed nine touchdowns through the air this season, which is tied for third worst in the league.\n\nAll of ESPN. All in one place. Watch your favorite events in the newly enhanced ESPN App. Learn more about what plan is right for you. Sign Up Now\n\nBrowns CB Denzel Ward gets another interception versus Vikings\n\nMinnesota quarterback Carson Wentz threw two interceptions last week against the Steelers, and his 38.7 QBR was third worst out of all quarterbacks who started the past two weeks. Behind a Browns defensive front that has generated a pressure rate of 37.8%, the fifth highest in the league, Ward will have opportunities to make plays on the ball, especially when Wentz's decision-making declines late in the down. Ward notched his first interception of the season versus the Lions in Week 4.\n\nLions WR Jameson Williams catches a pass over 25 yards against the Bengals\n\nThe Bengals' defense has allowed six completions of 25 or more yards this season, and I like Williams to create an explosive play. He has seen seven targets of 25 or more air yards through four games, including four against the Browns (only one resulted in a reception). Look for the Lions to set up Jared Goff on a deep shot here, with Williams stretching the defense at the third level.\n\nMaldonado: My favorite bet for Week 5\n\nOVER 47.5 points in Las Vegas Raiders at Indianapolis Colts\n\nThe Colts move the ball better than almost anyone, leading the league in success rate (52.8%) and averaging over 7.0 yards on first down. The Raiders' defense has struggled to get stops, especially in the red zone, where opponents are scoring touchdowns nearly 89% of the time. Indianapolis QB Daniel Jones should also thrive against Las Vegas' heavy Cover 3 looks.\n\nWhile the Raiders' offense is inconsistent, Indy's defense isn't exactly shutting anyone down either, ranking near the bottom in success rate and red zone efficiency. Both teams should finish drives, and if the Raiders are chasing points late, that only helps this matchup to hit the over.",
      "source": "ESPN",
      "url": "https://www.espn.com/nfl/story/_/id/46449711/2025-nfl-week-5-predictions-fantasy-sleepers-upsets-bets-stats-matchups",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Hell freezes over: AMD may team up with Intel to produce chips - but I don't expect Intel foundries to push out Ryzen CPUs anytime soon",
      "content": "Intel in talks to produce AMD chips despite major technology hurdles\n\nAMD may shift limited production to Intel while protecting flagship processors\n\nWashington favors US chipmaking as Intel woos investors and potential customers\n\nBack in February 2025, well before everyone suddenly got interested in throwing money at Intel, I wrote that the iconic but beleaguered chip maker could be about to merge with GlobalFoundries - a rumor made all the more salacious as GloFlo is AMD’s former foundry.\n\nThe headline I gave it started with “Hell freezes, pigs fly” because frankly it seemed like an unlikely situation.\n\nFast forward to now, and Semafor is reporting that Intel is in early talks to add AMD as a foundry customer, which isn’t as unlikely as it would have been a few months ago, but still…\n\nNot flagship chips though\n\nIntel has been on something of a charm offensive lately, seeking customers and investors to back its push to establish itself as a contract chipmaker.\n\nIn recent weeks it has lined up financial support from the White House, Nvidia, and SoftBank, been in talks with Apple and TSMC, and no doubt had a few behind closed door conversations with other members of the so-called Magnificent 7.\n\nFor AMD, any foundry deal with Intel would be more than a little complicated. Its most advanced processors are built on TSMC’s leading-edge nodes, which Intel can’t yet match.\n\nThis makes it unlikely AMD would hand over production of its flagship products to its long-time rival.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAt best, the resurgent chip maker might win some lower-margin or less complex chips, which would still help diversify AMD’s supply chain and earn goodwill in Washington.\n\nAs a commenter on Tom’s Hardware suggested, “I am wondering if AMD will make the embedded (low power APUs) and networking (Pensando) stuff in Intel's fabs. That would make the most sense to me, due to supply distances. Makes little to no sense to do chips in the USA, send them to Taiwan/Malaysia and then back to the USA.”\n\nIt's not yet clear how far discussions have gone, or whether they would involve AMD taking a direct stake in Intel’s foundry arm, as other partners have done.\n\nSemafor says both companies have so far declined to comment on the matter.\n\nFollow TechRadar on Google News and add us as a preferred source to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!\n\nAnd of course you can also follow TechRadar on TikTok for news, reviews, unboxings in video form, and get regular updates from us on WhatsApp too.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/hell-freezes-over-amd-may-team-up-with-intel-to-produce-chips-but-i-dont-expect-intel-foundries-to-push-out-ryzen-cpus-anytime-soon",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "Ultra-rare unreleased Pentium 4 with 4.0 GHz clock speed discovered — CPU-Z confirms it is an Intel Pentium Extreme Edition 980",
      "content": "A rare Intel engineering sample from the twilight of the Pentium 4 era has surfaced on social media. We’ve never seen this 4.0 GHz chip before. On Reddit, the current owner of the purported Intel Pentium Extreme Edition 980 processor, diegunguyman, has shared photos of the chip, both front and back, along with a CPU-Z screenshot for some deeper technical details. Due to quirks with the CPU-Z app/online database, this CPU won’t validate correctly.\n\nDiegunguyman reached out on various Subreddits to try and glean more insight into his find. The basic backstory was that “The only text on the CPU itself was written in Sharpie, just the model number and clock speed, 4 GHz.” With no official documentation to reference, the Redditor turned to experts on Subreddits like r/pcmasterrace and r/Intel to seek answers.\n\nA rare breed\n\nThis particular dual-core Hyperthreaded ‘Presler’ P4 is a very interesting sample for a number of reasons. Firstly, the collective wisdom of the flock of attentive Redditors interested in this story indicates that the sample now owned by diegunguyman was likely a loaner chip given to an employee.\n\nThese Employee Loaner Chips are rarer than typical Engineering Samples (ES). Their rarity is probably bolstered by the strict terms of the loan. However, a purported Intel ‘insider’ on Reddit indicates that due to the extensive layoffs at the firm, policing of the loaner system has evaporated.\n\nAnother interesting aspect of this CPU is the reasons that the public never saw with the pinnacle of NetBurst. It is now a matter for the history books, but the processor line already had a poor reputation for its thermals and performance, which played a part.\n\nPivot: Plan B becomes Plan A\n\nWhat likely sealed this ‘ghost’ processor’s fate was Intel’s strategic pivot. Management was already shifting focus to the legendary Core 2 lineup, built on the mobile-first Core microarchitecture. Then we saw Intel’s marketing shift to focusing on the entirely reasonable performance-per-watt metric, and the NetBurst design was quickly relegated to history, with budget / entry-level chips being the primary beneficiaries.\n\nIt is probably fair to say Intel’s Haifa design team and its mobile-first Core microarchitecture were Intel’s saviors. From mid-2006, the new performance-per-watt tuned chips managed to effectively stall the momentum of AMD’s contemporaneous CPUs like the Athlon 64 and X2 designs on the desktop.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/ultra-rare-unreleased-pentium-4-with-4-0-ghz-clock-speed-discovered-cpu-z-confirms-it-is-an-intel-pentium-extreme-edition-980",
      "timestamp": "2025-10-04"
    },
    {
      "headline": "US Tech Companies Enabled the Surveillance and Detention of Hundreds of Thousands in China",
      "content": "An Associated Press investigation based on tens of thousands of leaked documents revealed Tuesday that American technology companies designed and built core components of China's surveillance apparatus over the past 25 years, selling billions of dollars in equipment to Chinese police and government agencies despite warnings about human rights abuses.IBM partnered with Chinese defense contractor Huadi in 2009 to develop predictive policing systems for the \"Golden Shield\" project, AP reports, citing classified government blueprints. The technology enabled mass detentions in Xinjiang, where administrators assigned 100-point risk scores to Uyghurs with deductions for growing beards or being aged 15-55. Dell promoted a laptop with \"all-race recognition\" capabilities on its WeChat account in 2019. Thermo Fisher Scientific marketed DNA kits as \"designed\" for ethnic minorities including Uyghurs and Tibetans until August 2024.Oracle, Microsoft, HP, Cisco, Intel, NVIDIA, and VMware sold geographic mapping software, facial recognition systems, and cloud infrastructure to Chinese police through the 2010s. The surveillance network tracks \"key persons\" whose movements are restricted and monitored, with one estimate suggesting 55,000 to 110,000 people were placed under residential surveillance in the past decade. China now has more surveillance cameras than the rest of the world combined.",
      "source": "Slashdot.org",
      "url": "https://news.slashdot.org/story/25/09/09/1124247/us-tech-companies-enabled-the-surveillance-and-detention-of-hundreds-of-thousands-in-china",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel's crown as the best choice for gamers may be slipping as pros complain about its performance vs. AMD",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/intels-crown-slipping-pros-complain-performance-vs-amd/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Exit, rebuild, repeat — Intel’s new era begins without Holthaus",
      "content": "The Intel logo is displayed during the 2018 CeBIT technology trade fair\n\nIntel has announced major leadership changes as CEO Lip-Bu Tan pushes ahead with efforts to transform the struggling chipmaker. The most notable departure is Michelle Johnston Holthaus, whose career at Intel has spanned more than 30 years.\n\nThe shake-up comes just as Intel admitted its Arrow Lake processors failed to live up to expectations. All eyes are now on the upcoming Nova Lake architecture, which it hopes will restore competitiveness against AMD. This rivalry continues to gain ground with users and across the industry.\n\nHolthaus’s departure after 30 years at Intel\n\nHolthaus joined Intel in 1996, a year before I was even born, which makes me feel old. Anyway, starting as a program manager in the OEM Platform Solutions Division. Holthaus went from there, and she moved steadily through leadership roles in sales, marketing, and product development.\n\nBetween 2013 and 2017, she managed Intel’s partnership with Microsoft, coordinating sales, product roadmaps, and technical support. This role kept Intel’s CPUs and Microsoft’s platforms closely aligned across Windows, Surface, Xbox, and cloud services.\n\nIn late 2024, Holthaus stepped into the spotlight as interim co-CEO alongside CFO David Zinsner following Pat Gelsinger’s departure. She was later appointed CEO of Intel Products but held the position for only 9 months before resigning. Intel said the decision was due to “a material reduction in her duties, responsibilities, salary, and target annual bonus,” which matched the “Good Reason” clause in her contract.\n\nThanks to this clause, Holthaus will receive full severance benefits and remain with Intel in a non-executive advisory role until March 1, 2026.\n\nNew leadership team takes shape\n\nKevork Kechichian has joined Intel from Arm as Executive Vice President and General Manager of the Data Center Group. He brings more than 30 years of semiconductor experience and previously managed Snapdragon SoC teams at Qualcomm.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAnother addition is Jim Johnson, a 40-year Intel veteran, who has been confirmed as Senior Vice President and General Manager of the Client Computing Group. Over his long career, Johnson has worked across Intel’s Technology and Manufacturing Group, Networking and Communications, and global operations.\n\nIntel has also formed a new division in 2025, the Central Engineering Group, which will be led by Srinivasan “Srini” Iyengar. This team will focus on custom silicon design for external customers. Iyengar, who spent over 25 years at Cadence Design Systems, brings deep expertise in silicon engineering and design automation.\n\nLastly, Dr. Naga Chandrasekaran’s responsibilities have been expanded to include Foundry Services, alongside his existing role as Executive Vice President and Chief Technology and Operations Officer of Intel Foundry. Before joining Intel, he spent 16 years at Micron, where he led advanced memory technology development.\n\nTogether, these appointments show Tan’s push to blend long-time Intel leaders with external expertise from companies like Arm, Cadence, and Micron. It may take time before the results are clear, but the changes highlight Intel’s willingness to act boldly as it struggles to compete.\n\nTan’s strategy and vision for Intel’s future\n\nLip-Bu Tan, chief executive officer of Intel Corp (Image credit: Getty Images | Bloomberg)\n\nTan is aiming to cut back on bureaucracy by eliminating redundant management layers and creating a flatter, more focused structure. The goal is to speed up decision-making and bring more direct accountability. A clear example is that Holthaus’s position will not be replaced, with key groups now reporting directly to Lip-Bu Tan.\n\nHe is also pivoting Intel toward custom silicon and foundry services, areas where the company hopes to become a leader. The newly formed Central Engineering Group is central to this effort, with a focus on building chips for external customers instead of just Intel’s own products.\n\nOf course, no turnaround story in 2025 would be complete without AI, and Tan’s plans touch on that too. Still, the real test will be whether this strategy helps Intel compete with rivals like AMD. Rebuilding trust with users and partners will take time, but Nova Lake may give us the first glimpse of what Tan’s reshaped Intel can deliver.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/intel/exit-rebuild-repeat-intels-new-era-begins-without-holthaus",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "TikTok's parent company ByteDance is valuing itself at $330 billion. One big investor thinks it's worth even more.",
      "content": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nByteDance believes it is worth more than Chevron, General Electric, and Coca-Cola. One of the world's biggest investors thinks it's even more valuable than that.\n\nFidelity, which invested in TikTok's parent company in 2020 through its massive Contrafund, valued the company at more than $385 billion at the end of July, filings show. That is nearly 17% more than ByteDance's self-valuation of $330 billion.\n\nAccording to reports in late August, ByteDance is offering a share buyback program for employees looking for liquidity and valued itself at more than $330 billion, a 5.5% increase from earlier this year, when the company marked itself at $315 billion.\n\nIt's a lofty valuation for a company that struggles to make profits despite tens of billions of dollars in quarterly revenues. But for $6.4 trillion Fidelity, the Chinese company's valuation of itself is low. Fidelity's valuation of the company considers ByteDance more valuable than public companies such as defense tech firm Palantir and Wall Street staple Bank of America.\n\nFidelity declined to comment. ByteDance did not immediately respond to a request for comment.\n\nThere are plenty of reasons why the company might depress its valuation when offering buybacks to employees, primarily to accumulate its own equity at a discount in case it is needed for fundraising down the line.\n\nThe company has a looming deadline that would materially change its standing. President Donald Trump's June executive order postponed the date by which ByteDance would need to sell its US TikTok operations to September 17, though he has hinted at that deadline being extended.\n\nThe app briefly went dark in the US in January to comply with the original divest-or-sell deadline before Trump directed his Attorney General not to enforce the law, which was passed by the Senate. The White House made its own TikTok account last month, when Trump said he was a fan of the app.\n\nHe floated the government taking a 50% stake in TikTok, similar to the deal the government struck to take 10% of Intel, though he did not give additional details on what the joint venture would look like.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/fidelity-valuation-tiktok-parent-bytedance-2025-9",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Weird CPU architectures, the MOV only CPU (2020)",
      "content": "I like CPU architectures, especially weird, interesting and unusual ones. For example, the Intel iAPX 432 is still something I would love to play around with. Recently, I realized that a working CPU can be made with just a simple Move instruction. For this to work, everything needs to be memory mapped. The ALU, program counter, everything.\n\nOf course, this idea is nothing new and this idea is called the Transport Triggered Architecture. I decided to have a look into this, how it works and make a simple TTA CPU.\n\nHow does a TTA CPU work\n\nBefore I can make a CPU, let’s look into what is so different in a TTA CPU. In most CPU’s, calculations are done using registers and some arithmetic logic unit. For example, to add 2 numbers, the assembly code could be:\n\nLOAD VARIABLE1, REGISTER0 LOAD VARIABLE2, REGISTER1 ADD REGISTER0, REGISTER1, REGISTER2 STORE REGISTER2, VARIABLE3\n\nIn a TTA CPU, there is no ALU or registers in the CPU itself. Instead, they exist somewhere in memory. In order to add 2 numbers, they are moved from memory or registers, to the ALU. The ALU result is then moved back to memory/registers. Or in code:\n\nMOVE VARIABLE1, ALU_A MOVE VARIABLE2, ALU_B MOVE ALU_ADD_RESULT, VARIABLE3\n\nIn the simplest form, the CPU in a TTA CPU only needs to move data from one memory address to another. All calculations are done as a result of data being moved around. If you think, how would you jump to a different section of code, it’s easy. If the program counter is also in memory, a jump is as simple as moving a new address to the program counter.\n\nA few TTA computers have been made, and even commercially sold. But in general, it’s a niche architecture that never has gotten popular. So let’s build one :D\n\nBuilding a simple TTA computer\n\nI decided to build the computer in Digital, a simulator for digital logic that is based on Logisim but much improved. Just the name is a bit too common when googling :)\n\nIn order to make a simple TTA computer, a few things are needed.\n\nA CPU capable of moving data A program counter An ALU A branch block\n\nI want the CPU to be a von Neumann type of CPU, meaning that there is one memory bus with code to execute and RAM. To have a useable amount of memory, a 16 bit address, in order to address 64KB of RAM, is probably nice. Let’s just make it a 16 bit CPU when we are busy.\n\nAs there is just a single instruction, MOVE data from A to B, every instruction is 32 bits. First 16 bits with the address A, then 16 bits with the address B.\n\nThe CPU\n\nThe CPU can be surprisingly easy, after some consideration I came to the realization it just has to 4 things:\n\nFetch the first 16 bits of the instruction for the source address Fetch the second 16 bits of the instruction for the destination address Read the data from the source address Write that data to the destination address\n\nTo build the entire CPU, a block to turn one clock signal into 4 is needed for the 4 steps. This means 1 instruction takes 4 clocks, but that is not too uncommon for a simple CPU.\n\nThe program counter is needed to select the right instruction, and a few latches or registers to store the addresses and data.\n\nOne simple CPU\n\nTo simplify things, I created a 16 bit bus driver, 16 bit latch and 16 bit register building block. The 1 to 4 CLK modules is made using a 74_161 counter and a 74_139 2 to 4 decoder.\n\nThe program counter only sees a clock when fetching the instruction, when the CPU reads and writes to the fetched addresses, the program counter is not incremented.\n\nThe program counter\n\nWithout the program counter, the CPU won’t do much. To make a 16 bit program counter, a total of 4 of the 74_161 counters are needed. The program counter is, of course, memory mapped. In order to change it, a write to a specific address is used. This means a comparator is required to check if the address is correct. The output of the comparator AND the read/write signal are connected to the Load pins of the 74_161 in order to load a new value.\n\nAll in all, a fairly simple program counter.\n\nThe ALU\n\nWith the CPU done, let’s hook up some things to it, like the ALU\n\nTo keep part count down, a common option is to use the 74_181 4 bit ALU. With 4 of those, a 16 bit ALU can be made. Additionally, 2 registers are needed for the 2 inputs, and a bus driver in order to only output a value when needed.\n\nSome logic is also required for address decoding. The lowest 5 bits select the instruction, as the 74_181 has 32 possible instructions. The 6th bit selects in which register to store the data for the input.\n\nThe full schematic is as follows\n\nEach alu_slice just contains a 74_181, but connected in a way that I can work with busses. And even then it’s a bit of a messy schematic.\n\nThe flow control block\n\nBy lack of better name, the flow control block. Some form of program flow control is needed in order to implement something like an if() statement. In this case, a block with 4 registers and one output. 2 registers contain addresses, 2 contain variables. When read, if the variables are equal, address 1 will be returned, else address 2. And just like that, a simple flow control is implemented\n\nA comparator, 2 to 4 decoder, some registers and addressing logic and that’s all. By now one downside of this type of CPU slowly pops up, having registers in all memory mapped peripherals like the ALU and flow control slowly make a small CPU fairly big.\n\nWith that all in order, the complete CPU looks like this:\n\nI added a GPIO block that just stores the value written to it to make debugging easier.\n\nLet’s calculate some Fibonacci numbers\n\nWhat to do with a simple CPU that does show it functions as a CPU? Calculate some Fibonacci numbers seems like a good idea. It’s simple, but does show some flow control and calculation abilities.\n\nLet’s start with the code needed in C, or at least, pseudo-C, to calculate the first 10 Fibonacci numbers\n\nint T1 = 0; int T2 = 1; int nextTerm = 0; for(int i = 0; i < 10; ++i) { nextTerm = T1 + T2; T1 = T2; T2 = nextterm; }\n\nNow, let’s translate that to a bunch of MOV instuctions. A big bunch of them. First, a memory map.\n\n0x0000 to 0x7FFF is the instruction memory\n\n0x8000 to 0xBFFF is the RAM\n\n0xC000 to 0xC03F is the ALU\n\n0xC100 to 0xC103 is the flow control block\n\n0xFE00 is the GPIO block\n\n0xFFFF is the program counter\n\n//one time setup MOV 0x64 0xC102 MOV 10, compareB MOV 0x65 0xC101 MOV addrdone, Compare_addr2 MOV 0x66 0xC100 MOV 6, Compare_addr1 MOV 0x67 0x8001 MOV 1, T2 //Fibonacci calculation MOV 0x8000 0xc000 MOV T1, ALU1 MOV 0x8001 0xc020 MOV T2, ALU2 MOV 0x8001 0x8000 MOV T2, T1 MOV 0xC012 0x8001 MOV ALU_O, T2 MOV 0x8001 0xfe00 MOV T2, GPIO //handling the for loop MOV 0x8002 0xC000 MOV CNT, ALU1 MOV 0x0067 0xC020 MOV 1, ALU2 MOV 0xC012 0x8002 MOV ALU_O, CNT MOV 0x8002 0xC103 MOV CNT, CompareA MOV 0xC100 0xFFFF MOV Compare_O, PC MOV 0x0065 0xFFFF MOV addrdone, PC //just a loop\n\nWow, that’s a lot of code. Let’s try and unwrap that a bit. As the CPU can only move data, numbers have to be stored in memory. This means that the “int T2 = 1” C instruction is done by moving the value 1 stored in flash (in address 0x67) to variable T2 in RAM (address 0x8002)\n\nThe Fibonacci calculation itself is fairly easy, move T1 and T2 to the ALU, replace T1’s value with T2, move the result from the ALU back to T2. T2 is moved to the GPIO for a nice indication.\n\nThe for loop is handled by increasing a variable by 1 and comparing it to a set value, 10 (stored in address 0x64) for 10 loops. If they are not equal, the PC is set to the start of the Fibonacci calculation, else it’s set to an address containing an infinite loop.\n\nConclusion\n\nAnd with all of that, it calculates.\n\nFibonacci result in the top right under GPIO\n\nThere is a small bug caused by the RAM being infinite fast and asynchronous, sometimes a value is written to address 0x8012, caused by the 0xC012 address of the ALU. Apart from that, the CPU happily runs along.\n\nThis was an interesting way of making a CPU, but it’s not the most efficient or fast CPU. It can be made pretty small however. All in all, a fun exercise in a quirky and niche CPU architecture.\n\nAll the source files can be found here, and if you enjoyed this post, you can buy me a coffee.",
      "source": "Justanotherelectronicsblog.com",
      "url": "https://justanotherelectronicsblog.com/?p=771",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "How Republicans Plan to Use AI for 2026 (Even If It’s Too Woke)",
      "content": "Conservatives in California descended on Orange County over the weekend for the Republican Party’s Fall 2025 Convention and Leadership Summit. Some of the sessions at the three-day event focused on artificial intelligence, providing a peek at how the party of Donald Trump plans to use AI in the 2026 midterm elections and beyond.\n\nBrent Lowder, the California director of a right-wing nonprofit called the Leadership Institute, gave well-attended talks at the convention about how Republicans should use AI in a rapidly evolving environment. Lowder’s talks emphasized the need for conservatives to embrace new technology as quickly as possible or risk getting walloped by Democratic opponents who use AI.\n\n“AI’s just this kind of new technology, and I don’t wanna see conservatives be slow to adopt it, like we’ve done so much before. That’s why it’s so important for us,” Lowder told the audience.\n\nIn 2008, presidential hopeful Barack Obama promised to announce his VP candidate (Joe Biden) via text, which allowed his campaign to collect a massive number of phone numbers from people who wanted to be the first to know. And in 2012, President Obama’s campaign embraced social media in ways that his competitor, Mitt Romney, did not.\n\nThe 51-year-old Lowder, who previously ran a political action committee that helped elect Trump to his first term in 2016, understands Republicans can’t get caught flat-footed technologically.\n\nThat kind of fear about missing out seemed to drive much of the discussion. But Lowder also touted the increased efficiency he saw in using AI. Lowder told the audience to think of AI as “super interns.” He said that AI makes mistakes, and it’s important not to just use whatever the AI produces as a final product. And he repeatedly reminded the audience that AI will just make things up and produce errors. It was a tool, he told the crowds. And it was interesting to hear him downplay the capabilities while remaining optimistic, a contrast to the hype of AI CEOs who insist tools like ChatGPT are like having PhD experts in any field.\n\nLowder also stressed that you could really get some interesting ideas by prompting tools like ChatGPT to pretend as though it were a conservative operative, using that exact kind of wording when asking for an analysis of poll results.\n\nLowder played videos of Steve Jobs giving a speech at Leeds University in 1985 that seem incredibly prescient 40 years later. Jobs predicted that one day, people might be able to have a conversation with Aristotle. The audience was audibly impressed by the late Apple co-founder’s predictions, instantly making the connection to tools like OpenAI’s ChatGPT.\n\nLowder told the audience about different kinds of AI tools they could use beyond ChatGPT, including Grok, which he noted was run by Elon Musk, “so it’s a little bit crazy and wild-eyed, and also a lot of fun.” He told the audience that his favorite tools were Perplexity, because of how it cited sources, and NotebookLM, because of the customization options.\n\nHe also recommended that anyone who needed to use sensitive documents download something like Jan.ai to run a model locally. Privacy can obviously be a major concern for political campaigns, and even the most green convention attendees seemed to understand that.\n\nOne man from the audience asked if he could ask ChatGPT about any secret information that may have been uploaded by Democrats. Lowder told him that wasn’t going to work, but noted that Republicans shouldn’t upload anything sensitive.\n\nLowder said that AI could make people nervous because they consider it creepy, especially given how it’s now being portrayed in popular media. And while he understood where that unease was coming from, it was vital for the conservative movement to embrace it if they wanted to win elections.\n\nLowder had AI write some social media posts, generating bullet points about innovation and the free market. One of the examples that came back was, “Let’s keep those incentives flowing to watch innovation as it transforms our world.” Lowder then showed how he asked the bot to punch up the language to make it “shorter” and more “edgy” but it spit out something that was too over the top: “We’re here to dominate, innovate, and conquer in the free market. In the free market jungle.”\n\n“So I was like, ‘Eh, I don’t know if I want my candidate to say we’re here to dominate that.’ You know, Trump can say that, but maybe not everybody, right?” Lowder said, to a laugh from the audience.\n\nEven though Lowder is clearly all-in on Trump and Trumpism, it was interesting to hear him talk in what might be considered more old-school Republican language. When Lowder was asked about the biases that may be present in the major AI chatbots, he talked about the notorious example when Google’s Gemini generated images of American founding fathers as Black in early 2024. But Lowder was quick to note that all of the big tech companies just want to make a product that works as they seek to dominate the space.\n\nThe problem with so many AI chatbots, as Lowder sees it, is that they’re trained on the internet, which apparently has a liberal bias. “I would guess it probably leans left. The reality is all these models were trained basically on the internet, right? And the internet leans left,” Lowder said. But he insisted that the free market would sort it all out. That’s not quite how Trump sees the world these days, as he gobbles up 10% of Intel.\n\nLowder also showed off how AI image tools could be used to clean up campaign photographs, using a failed local politician, former Republican Rep. Michelle Steel, as an example in his slides. Lowder said that if you took a photo for a campaign and wanted to remove a tattoo, that was something AI could help you with, showing the audience before and after photos of the “unwanted tattoo.”\n\nDuring the 2024 race, Steel lost to her opponent, Democrat Derek Tran, by an extremely close margin in Orange County. How close? Just 653 votes. Steel had compared Tran to Mao Zedong and used hammer and sickle imagery in mailers. Tran is the son of Vietnamese refugees who fled the Communist country, making her attack particularly weird. But it’s unclear if she actually used AI to remove any tattoos from her own campaign mailers. That may have just been a hypothetical on Lowder’s part, who insisted he didn’t actually have anything against tattoos.\n\nLowder came across as knowledgeable and reasonable when it came to the possibilities and limits of AI, but he did show the limits of his knowledge at times, including when he suggested that he could tell when something was written by AI just because it used an em dash. Or, as he called it, a long hyphen.\n\n“We all laugh at each other when we can see somebody send us an email or a leftist candidate puts a quote in that we can tell is generated by GPT,” Lowder told the audience. “You know how you can tell it’s GPT? GPT loves really big hyphens. So if you see really big hyphens, and they use them a lot, it’s definitely a GPT thing, I guarantee you.”\n\nAgain, they’re called em dashes. And the reason that AI chatbots like to use em dashes is because 30- and 40-somethings love to use em dashes. People jokingly refer to them on social media as “millennial em dashes” for a reason. In fact, President Donald Trump sometimes uses em dashes in his Truth Social posts. But that’s not because Trump is using AI. It’s almost certainly because Trump often dictates his posts to a person, and during the 2024 presidential campaign, that person was Natalie Harp, his 34-year-old assistant. Is it possible that Trump uses AI? Sure. But the more likely explanation is that his millennial assistant is just showing her love for millennial em dashes.\n\nLowder clearly believes that AI is a powerful tool. And any Republican who resists embracing platforms like Perplexity, ChatGPT, and NotebookLM is bound to be left in the dust.\n\n“The bottom line is we have to get over that nervousness and we have to engage with the technology because if we don’t, there’s gonna be consequences, right?” Lowder said. “It’s not going anywhere.”\n\nAnd however you feel about AI personally, Lowder’s perspective is one shared by just about every political operative across the spectrum right now. You may like AI, you may hate it. But even if the AI bubble were to burst tomorrow, it really feels like a technology that will be around in some form for many years to come. The question is just how Lowder and his opponents decide to get with it.",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/republican-plan-to-use-ai-in-2026-2000655153",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Why I stopped overclocking my CPU after years of enthusiasm",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/cpu-overclocking-is-mostly-dead/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "macOS Tahoe RC Now Available With New Features For Mac Users",
      "content": "After the iPhone 17 event, Apple made the Release Candidate version of macOS Tahoe available. With that, the company is days away from launching one of the biggest macOS releases since Big Sur. At that time, the company was about to unveil the first M1 Macs. Now, it's preparing to stop supporting Intel computers, as the focus will shift completely to Macs with its own processors.\n\nHowever, more than just offering a final glimpse of the future of macOS to Intel Mac users, Apple designed software that's more integrated with iOS and iPadOS than ever before. After all, macOS Tahoe features the new Liquid Glass design, which is also available on the other operating systems. Additionally, Apple is adding new apps to the Mac, including Phone, Journal, and Preview.\n\nThat said, not only is Apple making the transition between hardware more seamless, but also better integrated. For example, iPhone Mirroring expands Live Activities to the Mac, so you can see when an Instagram post has been uploaded, when your Uber driver is arriving, or how your team is performing in a big game, all from your Mac's display.",
      "source": "BGR",
      "url": "https://www.bgr.com/1963608/macos-tahoe-rc-download-now-available/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "This Dell Inspiron laptop with Intel Core 7 is a steal for only $600",
      "content": "Finding an everyday laptop that’s good enough to get you through your days without costing a fortune can be tough—unless you let us do the hard work for you. I just found this Dell Inspiron 14 laptop that’s perfect as a daily driver, and it’s extremely affordable right now with this sale: Dell is selling it for $599.99 via its online shop (was $899.99).\n\nThis isn’t some weak configuration either. You’re looking at a more-than-decent 2024-era Intel Core 7 150U processor with 10 cores, plus 16GB of speedy DDR5 RAM, plus a spacious 1TB SSD that’s plenty for all your apps, files, photos, and even videos. This config will comfortably run Windows 11 Home (which comes pre-installed) without choking or slowing to a crawl, making sure it doesn’t impact your productivity.\n\nIt’s relatively compact for a laptop, with a 14-inch IPS screen at a crisp 2.2K resolution (that’s 2240×1400), a reasonable weight of 3.44 pounds, and an okay thickness of 0.74 inches. You should be able to lug this around without breaking a sweat, and that display should be adequate (though not great) with 300 nits of brightness.\n\nThis laptop lacks a dedicated graphics card so don’t expect to game much on it. It’s also rather light on connectivity, with just two USB-A ports and a USB-C video port with power delivery, plus an HDMI 1.4 port (only goes up to 1080p@60Hz) and a 3.5mm headset jack.\n\nIt’s far from the greatest machine ever, but it’s a darn good value now that it’s $300 off. Grab it for just $599.99 before this deal expires!\n\nSave $300 on this Dell Inspiron laptop with Intel Core 7 processor",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2903058/this-dell-inspiron-laptop-with-intel-core-7-is-a-steal-for-only-600.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "New Intel executive reshuffle sees products chief Holthaus leave after 30 years",
      "content": "Intel’s Michelle Johnston Holthaus leaves the company after 30+ years\n\nFurther leadership roles appointed, including a new hire\n\nCEO Lip-Bu Tan wants to flatten company leadership\n\nSenior Intel exec Michelle Johnston Holthaus will be departing the company after more than three decades, including a short stint as interim co-CEO with David Zinsner after ex-CEO Pat Gelsinger’s departure.\n\nHolthaus’ most recent role as Chief Exec of Products comes to a close after 10 months, and the company will not be rehiring for this role.\n\nAcknowledging Holthaus’ transformational impacts, new CEO Lip-Bu Tan noted: “She has made a lasting impact on our company and inspired so many of us with her leadership.”\n\nIntel announces major leadership shakeups\n\nThe company also announced the appointment of Kevork Kechichian as EVP & GM of Data Center Group, bringing more than 30 years’ chip industry experience from Arm, NXP Semiconductor, Qualcomm and more.\n\nJim Johnson becomes SVP & GM of Client Computing Group after around four decades at Intel, Srinivasan Iyengar becomes the head of a new Central Engineering Group, and Naga Chandrasekaran steps up at EVP & CTO of Intel Foundry to oversee development, manufacturing and go-to-market.\n\nThe changes come amid Intel’s ongoing efforts to flatten its hierarchical structure, resulting in more leaders reporting directly to Tan. By streamlining operations, cutting jobs and rebuilding its engineering culture, Tan hopes Intel can reposition itself to succeed going forward.\n\nThe news comes a couple of weeks after Intel reached an agreement with President Trump, whereby the US Government would invest $8.9 billion in Intel to help strengthen its position and bolster domestic American manufacturing.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nA move that has drawn its fair share of public scrutiny, including remarks made by Intel itself about the potential implications of having such political backing.\n\nIntel shares are up 21% this year to date, but the company’s market cap ($113.87 billion) falls far behind that of Nvidia ($4.097 trillion), now ranked as the world’s most valuable company.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/new-intel-executive-reshuffle-sees-products-chief-holthaus-leave-after-30-years",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel ousts CEO of Products as part of the latest executive shake-up, ending 30-year career — company also establishes new custom chip design unit",
      "content": "Intel has removed its chief executive officer of products, Michelle Johnston Holthaus, as part of a major shake-up of the executive branch of the embattled chip firm, according to Reuters. This is part of new CEO Lip-Bu Tan's plan to reshape the company under his leadership, flattening the leadership structure so he makes more of the important decisions about day-to-day operation.\n\nSince joining Intel in March this year, CEO Lip-Bu Tan has been a controversial figure. He's presided over mass firings and had to walk a fine line with shareholders, executives, and the U.S. administration, after his ties to Chinese businesses came to light. But in his short time at Intel he's made sweeping changes, laying off hundreds of engineers and chip designers, killing Intel's automotive division, and cutting middle management in chip fabrication teams.\n\nHolthaus is the latest high-profile figure at Intel to get the axe, ending a 30-year career at Intel, but a mere 10 months in her CEO of products role, and a temporary position as co-CEO after the previous CEO, Pat Gelsinger, suddenly left in 2024.\n\n\"Throughout her incredible career, Michelle has transformed major businesses, built high-performing teams and worked to delight our customers,\" Tan said in a statement. \"She has made a lasting impact on our company and inspired so many of us with her leadership. We are grateful for all Michelle has given Intel and wish her the best.\"\n\nIntel has said Holthaus will remain with the company in an advisory role, but her position will not be filled by anyone else.\n\nWhat Intel is doing, though, is bringing in executives from elsewhere, including one who worked at Tan's previous endeavour, Cadence. Srinivasan Iyengar joined the company in June and will take on the role of head of a new central engineering division.\n\nThis group will focus on developing a new custom silicon business for external customers. Although Intel's fabrication business has been one of its worst-performing in recent years, and there are still talks of it selling large portions of it, it's found a new lease of life following U.S. government investment and Bu Tan's leadership.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nWith Iyengar's new role, though, it's possible we'll see Intel designing chips for customers, rather than merely producing them. That could see it compete against the likes of Broadcom and Marvell. With Tan pushing for a faster, leaner business overall, Iyengar will report directly to him in his new role.\n\nIntel also announced that it had acquired the services of former executive vice president of solutions engineering at Arm, Kevork Kechichian. He'll begin heading Intel's datacenter group, and brings years of experience at ARM, NXP Semiconductor, and Qualcomm.\n\nAll of this comes at a both turbulent and rather bizarre time for the company. It has recently secured swifter funding as part of the CHIPS Act under the Trump administration's restructuring of how that fund works. But to get it, Intel had to agree to give the government a 10% stake in the company.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/intel-ousts-ceo-of-products-as-part-of-the-latest-executive-shake-up-ending-30-year-career-company-also-establishes-new-custom-chip-design-unit",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Acer unveils superlight Travelmate X4 14 AI laptop with an OLED display and Wi-Fi 7 connectivity",
      "content": "Acer TravelMate X4 14 AI unveiled at IFA 2025 with Intel Core Ultra processors\n\nWeighs 1.27kg, offers up to 32GB memory, 1TB storage, and OLED display option\n\nFeatures Wi-Fi 7, Thunderbolt 4 ports, and 65Wh battery rated 12 hours\n\nAcer has taken the wraps off a number of new products at IFA 2025, including the TravelMate X4 14 AI, lightweight Windows 11 Pro laptop aimed at small and medium businesses.\n\nThe Copilot+ PC (model TMX414-51) is powered by Intel’s Core Ultra Series 2 processors, with options ranging up to the Core Ultra 7 258V, and can reach up to 115 TOPS of overall performance.\n\nGraphics come from integrated Intel Arc, with configurations including Arc 130V and Arc 140V.\n\nAdvanced hardware and modern processors\n\n“As AI is becoming increasingly important in modern business workflows, small and medium businesses need devices that integrate intelligent tools, robust security, and mobility,” said James Lin, General Manager, Notebooks, Acer.\n\n“The TravelMate X14 AI was designed to deliver just that, powered by the latest Intel Core Ultra processors and Copilot+ PC experiences, offering professionals a lightweight yet durable solution crafted to accelerate productivity and collaboration from anywhere.”\n\nThe business laptop weighs 1.27kg and measures 15.9mm thick. It meets MIL-STD 810H testing standards covering vibration, humidity, and temperature extremes.\n\nThe system is available with up to 32GB of LPDDR5X memory and up to 1TB of PCIe Gen4 SSD storage.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe 14-inch screen is available in two versions. Buyers can choose an IPS WUXGA display with 120Hz refresh and 100% sRGB coverage, or an OLED WUXGA display with 120Hz refresh, 500 nits peak brightness, 100% DCI-P3 color, and VESA DisplayHDR True Black 500 certification.\n\nBoth panels use a 16:10 aspect ratio. An FHD webcam with IR support is included, paired with a built-in shutter for privacy.\n\nAcer has also included UserSensing 2.0, which dims and locks the screen when the user steps away. Other security features include a discrete TPM, Acer ProShield Plus, and support for a Kensington Nano lock. The laptop also carries TCO and EPEAT compliance.\n\nMark Linton, Vice President, Windows + Devices at Microsoft, said, “The Acer TravelMate X14 AI demonstrates what’s possible when advanced hardware and modern processors come together. With powerful performance, enhanced security, and unique AI experiences, it’s an ideal choice for today’s professionals looking to upgrade to a PC that prioritizes portability and performance.”\n\nConnectivity includes Wi-Fi 7, Bluetooth 5.4, two Thunderbolt 4 ports, two USB-A ports, HDMI 2.1, an audio jack, and a Gigabit Ethernet jack.\n\nThe 65Wh battery supports fast charging and is rated at up to 12 hours of use under MobileMark 2025 testing.\n\nThe laptop also integrates Acer PurifiedView 2.0 for improved video calls, along with PurifiedVoice 2.0, DTS:X Ultra Audio speakers, and a triple microphone array.\n\nThere's no word on pricing or availability yet - but we should know more soon.\n\nAcer TravelMate X4 14 AI | Boost SMB with AI Performance | Acer - YouTube Watch On",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/acer-unveils-superlight-travelmate-x4-14-ai-laptop-with-an-oled-display-and-wi-fi-7-connectivity",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel reshuffle puts engineering and 'a new custom silicon business' in the spotlight but also ends a 30-year career at Intel for Product CEO Michelle Johnston Holthaus",
      "content": "Things are, once again, all shake-up at Intel. After a new CEO, tons of layoffs, an increased focus on the Foundry side of the business, and other changes, Intel is sticking on-brand and making even more changes, this time to executive leadership. And while the biggest news for many might be that Intel Products CEO Michelle Johnston Holthaus is leaving, what's particularly interesting is the company is starting a new group that will focus on a new custom silicon business.\n\nIn addition to these two things, Intel also announced that Jim Johnson will lead the Client Computing Group (CCG), Kevork Kechichian from Arm will join to lead Intel's Data Center Group (DCG), and Intel Foundry CTOO Naga Chandrasekaran will also cover Foundry Services.\n\nThe custom silicon business that's perhaps of most interest is to be headed up by senior VP and Fellow Srini Iyengar. Iyengar joined Intel earlier in the year after being a Fellow at Cadence Design Systems, which is of note because Intel CEO Lip-Bu Tan was previously CEO of Cadence until 2021.\n\nThe new group will apparently be looking towards serving external customers: \"Intel is also establishing a new Central Engineering Group led by Srinivasan (Srini) Iyengar, a senior vice president and Fellow. In his expanded role, Iyengar will lead horizontal engineering functions and build a new custom silicon business to serve a broad range of external customers.\"\n\nIf it pans it, this could certainly be a good move for Intel. Hearing the words \"custom silicon\" for \"external customers\" in 2025 triggers obvious thoughts of AI, as well as chasing down TSMC's foundry dollar. Data centres are increasingly gobbling up AI workloads and thus far Nvidia has been the company to reap the bulk of the rewards from that.\n\nIntel CEO Lip-Bu Tan conducting a keynote address. (Image credit: Intel)\n\nFrom his very first earnings call, Tan made it clear that Intel is going to look to cement itself in the AI market, although there's been no definite word over what exactly that means. Now, there's some reason to suppose that will mean custom AI silicon for data centers. Intel Foundry could certainly do with something of the sort to stake a bold new claim to after the past few years and especially months of troubled waters. But it really needs customers onboard.\n\nNo doubt extra incentive to push into Intel Foundry comes from the recent 10% buy-in from the US government, which is under the stipulation that Intel must own at least 51% of its Foundry for five years. In other words, there can be no back-up plan to scarper and sell.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nAs far as we're concerned as PC gamers, it could be good news, too. Emphasis on \"could\" there, but a push into AI accelerators, for instance, would presumably give Intel a lot of R&D as well as actual GPU silicon to trickle down into its gaming division. Just like Nvidia with Blackwell and the RTX 50-series. Though I suppose that analogy should show us such a development might not necessarily spell any improvements for GPU prices. At any rate, changes are afoot.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/graphics-cards/intel-reshuffle-puts-engineering-and-a-new-custom-silicon-business-in-the-spotlight-but-also-ends-a-30-year-career-at-intel-for-product-ceo-michelle-johnston-holthaus/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Qualcomm Snapdragon X Elite Linux Performance Improving But Short Of AMD Ryzen & Intel Core Ultra",
      "content": "Back in May we provided an initial look at the Qualcomm Snapdragon X Elite laptop performance on Ubuntu Linux with the upstream support for the Qualcomm Snapdragon X1E maturing, more laptops becoming supported, and the Ubuntu X1E \"Concept\" ISOs enhancing the end-user experience. The performance was okay but short of expectations. Months later we are revisiting the Qualcomm Snapdragon X Elite Linux performance on the newest Ubuntu Concept ISOs and newer firmware that is providing a much better experience albeit still not as competitive as the newest AMD Ryzen AI 300 series and Intel Core Ultra laptops under Linux.\n\nSince the May testing, the Qualcomm Snapdragon X Elite Linux testing was experiencing a hiatus... Newer Ubuntu X1E Concept ISOs were failing to properly work on the Acer Swift AI 14 laptop that I had purchased to carry out these Linux tests. Repeatedly the new refreshed media for several months failed to boot properly on the laptop due to Device Tree issues and/or other problems over time. Fortunately, the newest Ubuntu X1E Concept ISOs from late August fixed those problems. So I have been able to carry out clean, working installs of Ubuntu again on this Acer Swift 14 AI laptop powered by an X1 Elite SoC.\n\nThe \"plucky-desktop-arm64+x1e-20250827.iso\" as the newest as of testing now has everything in place so the laptop I have been using for testing works out. Though caveats still apply like you will want to keep around the Microsoft Windows 11 on ARM installation in order to run qcom-firmware-extract for extracting the necessary firmware from the Windows partitions. Most Snapdragon X laptops still do not have any firmware permitted for redistribution in upstream linux-firmware.git and thus the workaround of needing to fetch it from a Windows partition is needed for getting features like GPU acceleration and other functionality working.\n\nKeeping the Windows 11 installation is also important for easily applying system firmware updates to the device itself. While working through these Ubuntu Linux woes on the Acer Swift 14 AI, a system firmware update came down and was applied that ended up being very important for multi-core performance as I'll be showing in this article.\n\nIt's far from a pleasant out-of-the-box experience but at least an easier route than the likes of Apple Silicon on Linux.\n\nFor today's benchmarking is a look at how the Qualcomm Snapdragon X Elite performance has evolved since the tests earlier this year and then followed by a comparison of the Acer Swift 14 AI up against an assortment of other Intel Core and AMD Ryzen laptops tested over the summer, all on Ubuntu 25.04 and tested within the Phoronix lab.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/review/snapdragon-x1e-september",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Repost: Make your development environment portable and reproducible",
      "content": "Getting Genetics Done, and kindly contributed to Want to share your content on R-bloggers? [This article was first published on, and kindly contributed to R-bloggers ]. (You can report issue about the content on this page here Want to share your content on R-bloggers? click here if you have a blog, or here if you don't.\n\nReposted from the original at https://blog.stephenturner.us/p/development-environment-portable-reproducible.\n\nYou upgrade your old Intel Macbook Pro for a new M4 MBP. You’re setting up a new cloud VM on AWS after migrating away from GCP. You get an account on your institution’s new HPC. You have everything just so in your development environment, and now you have to remember how to set everything up again.\n\nI just started a new position, and I’m doing this right now.\n\nSetting up a reproducible and portable development environment that works seamlessly across different machines and cloud platforms can save you time and headaches. These are a few of the strategies I use to quickly reproduce my development environment across machines.\n\nDotfiles in a GitHub repo New VM setup script in a GitHub repo R “verse” package on GitHub Dev containers in VS Code\n\nKeep your dotfiles in a private GitHub repo\n\nDotfiles are the hidden configuration files in your home directory. Examples include .vimrc for Vim, .tmux.conf for tmux, or .bashrc for your shell environment. I have a long list of aliases and little bash functions in a .aliases.sh file that my .bashrc sources. I also have a .dircolors , global .gitignore , a .gitconfig , and a minimal .Rprofile .\n\nKeeping these files in a GitHub repository makes it easy to quickly reproduce your development environment on another machine. If you search GitHub for “dotfiles” or look at the awesome-dotfiles repo, you’ll see many people keep their dotfiles in a public repo. I use a private repo, because I’m too scared I might accidentally commit secrets, such as API tokens in my .Renviron or PyPI credentials in .pypirc .\n\nWhenever you get a new machine or VM, getting things set up is easy:\n\n# Your private dotfiles repo git clone https://github.com/<yourusername>/dotfiles cd ~/dotfiles # A script to symlink things to your home ./install.sh\n\nKeep a fresh cloud VM setup script\n\nI started playing with computers in the 1990s. I’ve experienced enough hard drive failures, random BSODs, and other critical failures, that I treat my computer as if it could spontaneously combust at any moment and I could immediately lose all of my unsaved, un-backed-up work at any moment. I treat my cloud VMs the same way, as if they’re disposable (many times they are disposable, by design).\n\nImagine you launch a new cloud VM starting from a clean Ubuntu image. Now you need all the tools you use every day on this machine – vim, tmux, RStudio, conda, Docker, gcloud/gsutil, etc. Additionally, while I use conda to create virtual environments for installing tools for specific tasks, there are some domain-specific tools I use so often every day for exploratory analysis that I actually prefer having a local installation on the machine — things like bedtools, seqtk, samtools, bcftools, fastp, Nextflow, and a few others — instead of having to load a conda environment or use Docker every time I want to do something simple.\n\nI keep a script on GitHub that will install all the software I need on a fresh VM. Here’s an example setup script I use as a GitHub gist.\n\nI know this isn’t completely Reproducible™ in the sense that a Docker container might be, because I’m not controlling the version of every tool and library I’m installing, but it’s good enough to get me up and running for development and interactive data analysis and exploration.\n\nR: Custom “verse” package on GitHub\n\nThe tidyverse is probably the best known meta-package that installs lots of other packages for data science. Take a look at the tidyverse package DESCRIPTION file. When you run install.packages(\"tidyverse\") , it will install all the packages listed in the Imports field, including dplyr, tidyr, purrr, ggplot2, and others.\n\nYou can use this pattern to create your own “verse” package that installs all your favorite packages. This is helpful for setting up a new machine, or re-installing all the R packages you use whenever you upgrade to a new major version of R.\n\nTake a look at my Tverse package on GitHub at github.com/stephenturner/Tverse, specifically at the DESCRIPTION file. In the Imports field I include all the packages I know I’ll use routinely. Note that this also includes several Bioconductor packages (which requires including the biocViews: directive in the DESCRIPTION), as well as one of my favorite packages, breakerofchains, that is only available from GitHub (requiring the Remotes: entry).\n\nOnce this package is pushed to GitHub I can easily install all those packages and their dependencies:\n\ndevtools::install(\"stephenturner/Tverse\")\n\nDev containers in VS Code\n\nDevelopment containers (dev containers) allow you to create and use consistent development environments using Docker containers. It allows you to open any folder inside (or mounted into) a container and take advantage of Visual Studio Code’s full feature set. This is particularly useful when working with teams or switching between projects with different dependencies.\n\nThe dev container docs and tutorial are both good places to start. You’ll need to have Docker running, and install the Dev Containers VS Code extension.\n\nFrom Microsoft’s documentation:\n\nWorkspace files are mounted from the local file system or copied or cloned into the container. Extensions are installed and run inside the container, where they have full access to the tools, platform, and file system. This means that you can seamlessly switch your entire development environment just by connecting to a different container.\n\nFrom Microsoft’s dev containers documentation .\n\nUsing a dev container template\n\nYou can use any pre-built dev container templates available on registries like Docker Hub or Microsoft’s container registry. Here’s an example using Rocker with R version 4.4.1, and adds a few extensions to VS Code running in the container. You could also create your own container for development, put that on Docker Hub, then use that image.\n\n{ \"image\": \"rocker/r-ver:4.4.1\", \"customizations\": { \"vscode\": { \"extensions\": [ \"REditorSupport.r\", \"ms-vscode-remote.remote-containers\" ] } } }\n\nUsing a custom Dockerfile\n\nYou can use a custom Dockerfile to create your dev container. First, create a .devcontainer/ directory in your project with a Dockerfile and a devcontainer.json file. Define your development environment in the Dockerfile (base image, installed packages and configuration). In the JSON replace the image property with build and dockerfile properties:\n\n{ \"build\": { \"dockerfile\": \"Dockerfile\" } }\n\nStart VS Code running the container\n\nAfter you create your devcontainer.json file (either from a template or completely custom), open the folder in the container using the command palette:\n\nAnd prove to yourself that your VS Code environment is indeed using the container (I’m using rocker R 4.4.1 here). Running whoami shows I’m root inside the container (not my own username), and I’m indeed running R version 4.4.1.",
      "source": "R-bloggers.com",
      "url": "https://www.r-bloggers.com/2025/09/repost-make-your-development-environment-portable-and-reproducible/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Reorg Puts 40-Year Vet in Charge of PC Group",
      "content": "Intel announced a corporate reorganization that puts Jim Johnson, a 40-year veteran of the company, in charge of the Client Computing Group responsible for its x86-based chip designs for PCs. He was previously serving in this role in an interim basis.\n\n“Jim’s steady leadership and trusted relationships across the computing industry are driving continued progress in our client business as we prepare to launch a new generation of products,” Intel CEO Lip-Bu Tan said.\n\nThurrott.com readers may recognize Johnson as the face of “Lunar Lake,” the controversial—and, I would argue, unsuccessful—attempt to quickly scale Intel’s x86 silicon to battery compete with more efficient Arm-based designs. He anchored the Intel announcement event for Lunar Lake at last year’s IFA in Berlin, Germany. And then he appeared at the Lenovo Innovation World press conference at this year’s show, which was held last week.\n\nHis appearance at Lenovo Innovation World was, to put it mildly, awkward, though he gets an A for confidence and staying on-message.\n\n“With Core Ultra Series 2 [Lunar Lake], we re-engineered the CPU, the GPU, and the NPU and delivered faster compute, improved AI experience, and busted the myth that x86 can’t be power efficient,” Johnson said at the event, which is available for rewatching on YouTube. Here, he paused, presumably for applause.\n\nIt never came. As most in the audience understood, and as my unpredictable and mostly lackluster experiences with Lunar Lake-based PCs show, this isn’t the home run that Johnson promoted. Lunar Lake is more efficient than previous Intel chips, but it’s also incredibly unreliable and unpredictable. Indeed, Lunar Lake is such a disaster that Intel will never make a chip design like it again, and it loses money on every unit sold. Subsequent Core Ultra Series 2 designs have all used different architectures.\n\nTo be clear, this is no one person’s fault in the sense that a cascading series of strategic mistakes over a decade or more led to Intel’s problems today. The company was forced to rush Lunar Lake to market so it could have a Copilot+ PC-compatible chip to compete with more efficient designs from AMD and Qualcomm.\n\nAnd Johnson wasn’t in charge of Intel’s Client Computing Group at that time. Michelle Johnston Holthaus was. And as it turns out, she’s leaving Intel as Johnson is elevated into her former role. She had become CEO of Intel products briefly, after Pat Gelsinger, the previous Intel CEO, left the company.\n\n“Throughout her incredible career, Michelle has transformed major businesses, built high-performing teams, and worked to delight our customers,” Tan said. “She has made a lasting impact on our company and inspired so many of us with her leadership. We are grateful for all Michelle has given Intel and wish her the best.”\n\nAs part of the reorg, Intel also revealed that Naga Chandrasekaran, the executive vice president and chief technology and operations officer of Intel Foundry, will expand his role to include Foundry Services. He joined Intel last year after a stint at Micron.\n\nIntel is also creating a new Central Engineering Group that will “build a new custom silicon business to serve a broad range of external customers.” This will be led by Srini Iyengar, who joined Intel this past June. And former Arm executive Kevork Kechichian has joined Intel as executive vice president and general manager of the Data Center Group (DCG).\n\nChandrasekaran was already reporting directly to the Intel CEO, and now Johnson, Kechichian, and Iyengar will as well, Intel says.",
      "source": "Thurrott.com",
      "url": "https://www.thurrott.com/hardware/326233/intel-reorg-puts-40-year-vet-in-charge-of-pc-group",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "What I learned while optimizing my RAM timings for better PC performance",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/improve-your-ram-timings/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel CFO talks 14A production, says US stake removes CHIPS grant ‘handcuffs’",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_58f88a00-b09b-4ae4-84d0-2a0527c07026",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 \"Battlemage\" Nears Launch as Intel Prepares Packaging",
      "content": "Intel plans to complete its Arc \"Battlemage\" lineup with the highest-performing B770 SKU. Thanks to @Haze2K1 on X, we found shipping manifests dated June 11, 2025, which list BMG-G31 GPU dies packed in boxes with dimensions matching those used before the Arc B580 launch. Last time with B580, the launch happened 2.5 months after these shipping manifests appeared. The current rumor mill suggests that the card will utilize 32 Xe2 cores with 16 GB of memory on a 256-bit bus, providing it with a clear capacity edge over many 8 GB rivals from AMD and NVIDIA, like the RTX 5060 Ti and RX 9060. The BMG-G31 die is bigger than the BMG-G21 used in the B580, B570, and Arc Pro parts, which explains the larger crates. Extra silicon could enable higher clocks, stronger ray tracing, and a wider memory interface, though thermal management and power draw will matter. Early samples and firmware checks will set the final timing and availability soon.Timing will determine how much impact the Arc B770 can have, because AMD and NVIDIA already control much of the upper mid-range and high-end segments. NVIDIA \"SUPER\" refreshes of the current \"Blackwell\" only raise the pressure on Intel to be both performance competitive and well priced. Battlemage has already shifted pricing expectations in the market before, compelling rivals to rethink memory configurations and price points. Intel has also shown steady improvement in its driver updates and software support, which has narrowed historical gaps in user experience. Rumors pointing to a Q4 2025 debut would put the card into the usual holiday buying window, but to convert gamer's interest into real market share, Intel will need an aggressive pricing strategy and solid supply.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340802/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "QNAP’s new NAS hardware features Intel N150 or Core 3 N355 inside",
      "content": "QNAP may be one of the biggest names in the network-attached storage business, but many of the company’s consumer-grade products tend to ship with years-old processors that can hamper performance.\n\nSo it’s nice to see that QNAP has finally introduced new systems powered by Intel Alder Lake-N/Twin Lake processors. The new QNAP Qu405, Qu605, and Qu805 feature between four and 8 bays for hard drives and come with a choice of Intel N150 quad-core or Core 3 N355 octa-core processors.\n\nWhile these are technically new chips based on Intel Twin Lake architecture, there’s virtually no real difference between Twin Lake and Alder Lake-N, which means that even these processors are starting to show their age a bit – they’re basically 12th-gen Intel Core processors that were first released in early 2023 featuring four or more Efficiency cores and no Performance cores.\n\nBut they’re still a pretty good fit for network-attached storage devices that are meant for 24/7 stable operation thanks to a combination of low-power consumption and respectable performance. And they should bring pretty significant gains in CPU and graphics performance over the Intel Jasper Lake chips used in earlier models from QNAP.\n\nSo far QNAP has only introduced its new models with Twin Lake chips for the Chinese market, so it’s possible some specs or features could be different if and when these (or similar) systems become available in other regions.\n\nBut it looks like all of the new QNAP QuX05 series models announced in China will have a set of features that includes::\n\n1 x SODIMM slot for up to 16GB of DDR5 memory\n\n8GB of eMMC NAND flash storage\n\n4, 6 or 8 bays for 3.5 inch SATA HDDs (or 2.5″ drives with adapters)\n\n2 x M.2 2280 slots for PCIe Gen 3 SSDs (SSD cache acceleration is supported)\n\n2 x 2.5 Gb Ethernet ports\n\n1 x USB 3.2 Gen 2 Type-C port\n\n2 x USB 3.2 Gen 2 Type-A port\n\n1 x HDMI 2.1 port\n\nLike most NAS hardware, these new models typically ship without any hard drives or SSDs, but QNAP will at least four processor/memory configurations for each model:\n\nIntel N150 + 8GB\n\nIntel N150 + 16GB\n\nIntel Core 3 N355 + 8GB\n\nIntel Core 3 N355 + 16GB\n\nWithout knowing the global pricing for the new models, it’s hard to say how competitive they’ll be at a time when a growing number of companies are entering the NAS space with systems featuring decent hardware and affordable price tags. But it is nice to see an established brand like QNAP catching up in terms of hardware capabilities.\n\nvia TechPowerUp and NASCompares\n\nSupport Liliputing Liliputing's primary sources of revenue are advertising and affiliate links (if you click the \"Shop\" button at the top of the page and buy something on Amazon, for example, we'll get a small commission). But there are several ways you can support the site directly even if you're using an ad blocker* and hate online shopping. Contribute to our Patreon campaign or... Contribute via PayPal * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a guide that may help you disable it.",
      "source": "Liliputing",
      "url": "https://liliputing.com/qnaps-new-nas-hardware-features-intel-n150-or-core-3-n355-inside/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "(PR) Intel Announces Key Leadership Changes to Data Center and Client Computing Group",
      "content": "Intel Corporation today announced a series of senior leadership appointments that support the company's strategy to strengthen its core product business, build a trusted foundry, and foster a culture of engineering across the business.Kevork Kechichian has joined Intel as executive vice president and general manager of the Data Center Group (DCG). In this role, he will lead Intel's data center business across cloud and enterprise, including the Intel Xeon processor family.Kechichian brings more than 30 years of industry experience, and joins Intel from Arm, where he most recently served as executive vice president of engineering. At Arm, he led technology development with ecosystem partners and managed the company's transformation from IP licensing to delivering full-stack solutions. His previous leadership roles include senior engineering positions at NXP Semiconductors and Qualcomm.\"Kevork brings a powerful combination of strategic vision, technical depth, and operational rigor that will help us seize growth opportunities across the data center market,\" said Lip-Bu Tan, CEO of Intel.Jim Johnson has been appointed senior vice president and general manager of Intel's Client Computing Group (CCG), after successfully serving in the role on an interim basis. He will lead Intel's efforts to deliver innovative computing solutions and foster growth across the global PC and edge ecosystems.A 40-year Intel veteran, Johnson has held various engineering and leadership roles across the company, including in the Technology and Manufacturing Group, the Networking and Communications Group, and general manager of several global businesses and manufacturing plants.\"Jim's steady leadership and trusted relationships across the computing industry are driving continued progress in our client business as we prepare to launch a new generation of products,\" Tan said.Intel is also establishing a new Central Engineering Group led by Srinivasan (Srini) Iyengar, a senior vice president and Fellow. In his expanded role, Iyengar will lead horizontal engineering functions and build a new custom silicon business to serve a broad range of external customers.Iyengar joined Intel in June from Cadence Design Systems, where he led global silicon engineering. He brings deep technical expertise in custom silicon development and has worked closely with hyperscale data center customers to optimize solutions for key workloads.\"With Srini leading Central Engineering, we're aligning innovation and execution more tightly in service to customers,\" Tan said. \"We are laser-focused on delivering world-class products and empowering our engineering teams to move faster and execute with excellence. Kevork, Jim, and Srini are exceptional leaders whose deep technical acumen and industry relationships will be instrumental as we continue building a new Intel.\"Kechichian, Johnson, and Iyengar will report directly to CEO Lip-Bu Tan.Naga Chandrasekaran, executive vice president and chief technology and operations officer of Intel Foundry, will expand his role to include Foundry Services. This will create a more integrated structure spanning technology development, manufacturing and go-to-market to better serve customers. Intel consolidated technology development and manufacturing under Chandrasekaran's leadership earlier this year.Chandrasekaran joined Intel in 2024 from Micron, where he served as senior vice president for technology development. He brings decades of experience spanning the breadth of semiconductor manufacturing and R&D.\"Naga's strong leadership, combined with a more integrated foundry operating model, will help us enhance the quality of execution, collaboration and customer service across our foundry business,\" Tan said.Chandrasekaran will continue reporting to Tan. Kevin O'Buckley, continues as senior vice president and general manager of Foundry Services, reporting to Chandrasekaran.Additionally, Intel announced that Michelle Johnston Holthaus, chief executive of Intel Products, will depart after more than three decades with the company. Holthaus held numerous senior leadership roles, including interim co-CEO, executive vice president and general manager of CCG, and chief revenue officer. She will remain a strategic advisor over the coming months to ensure a seamless transition.\"Throughout her incredible career, Michelle has transformed major businesses, built high-performing teams and worked to delight our customers,\" Tan said. \"She has made a lasting impact on our company and inspired so many of us with her leadership. We are grateful for all Michelle has given Intel and wish her the best.\"",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340800/intel-announces-key-leadership-changes-to-data-center-and-client-computing-group",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Arc B770 “Battlemage” Nears Launch as Intel Prepares Packaging",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "ACEMAGIC Kron Mini K1 review – Quite a capable mini PC",
      "content": "MetryGrow 48W LED Plant Grow Light review – makes sure your indoor plants get what they need",
      "source": "The Gadgeteer",
      "url": "https://the-gadgeteer.com/2025/09/09/acemagic-kron-mini-k1-review-quite-a-capable-mini-pc/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel announces leadership changes to strengthen execution and accelerate innovation",
      "content": "Intel announces leadership changes to strengthen execution and accelerate innovation\n\nIntel has announced a series of senior leadership appointments aimed at advancing its core product business, scaling its foundry operations, and reinforcing engineering capabilities across the company. The moves, which include new hires and expanded responsibilities for key executives, come as Intel continues its efforts to improve execution and sharpen competitiveness in the semiconductor industry.\n\nAccording to a press release, Kevork Kechichian has been named executive vice president and general manager of the Data Center Group, overseeing Intel's data center business spanning cloud and enterprise solutions, including the Xeon processor line. Kechichian joins from Arm, where he was executive vice president of engineering and led the company's transition from IP licensing to full-stack solutions. He previously held leadership roles at NXP Semiconductors and Qualcomm. Intel CEO Lip-Bu Tan said Kechichian brings a blend of \"strategic vision, technical depth, and operational rigor\" to the role.\n\nIn the Client Computing Group, Jim Johnson has been confirmed as senior vice president and general manager, following an interim tenure. A 40-year Intel veteran, Johnson has held engineering and management positions across multiple business units. Tan credited him with providing \"steady leadership\" as Intel prepares to launch a new generation of client computing products.\n\nIntel is also creating a Central Engineering Group led by Srinivasan (Srini) Iyengar, who joined the company earlier this year from Cadence Design Systems. Iyengar will oversee horizontal engineering functions and establish a custom silicon business serving external customers, particularly in the hyperscale data center market.\n\nIn its foundry operations, Intel said Naga Chandrasekaran, executive vice president and chief technology and operations officer, will expand his role to include Foundry Services. The change consolidates technology development, manufacturing, and go-to-market functions under a single leadership structure. Chandrasekaran, who joined Intel in 2024 from Micron, will continue reporting to Tan, while Kevin O'Buckley remains senior vice president and general manager of Foundry Services, reporting to Chandrasekaran.\n\nAlongside these appointments, Intel announced that Michelle Johnston Holthaus, chief executive of Intel Products, will depart after more than 30 years at the company. Holthaus held several senior leadership roles, including interim co-CEO, General Manager of the Client Computing Group, and Chief Revenue Officer. She will serve as a strategic advisor during the transition period. Tan praised her for transforming key businesses and inspiring teams across the company.\n\nMajor corporate restructuring continues\n\nIn March 2025, Intel named Lip-Bu Tan as its new CEO. Under his leadership, the company has embarked on a significant restructuring aimed at accelerating decision-making and bolstering technological leadership.\n\nTan's restructuring efforts have resulted in a flattened organizational hierarchy. Key business units, such as the Data Center and AI Group and the Client Computing Group, now report directly to the CEO. This change is intended to streamline the company's decision-making processes, enabling a more agile response to market demands in the highly competitive semiconductor industry.\n\nAdditionally, Intel appointed Sachin Katti as Chief Technology and AI Officer. Katti's responsibilities include overseeing the company's AI strategy and product roadmap as well as managing operations within the networking and edge computing division. This appointment reflects Intel's emphasis on expanding its AI capabilities and integrating advanced technologies across multiple sectors.\n\nChanges to the company's board have also been implemented. Three board members retired, reducing the total board size to 11. To reinforce its industry expertise, Intel added Eric Meurice, formerly the CEO of ASML, and Steve Sanghi, interim CEO of Microchip Technology, to its board. Both new members bring extensive experience in the chip manufacturing sector, which Intel aims to leverage in its ongoing transformation.\n\nArticle edited by Jack Wu",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250909VL202/intel-management-personnel-business.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Watch The PC Gamer Streamer Showdown live today on Twitch",
      "content": "Are you ready?\n\nThe PC Gamer Streamer Showdown kicks off today, a three-day triathalon of gaming competition between eight talented streamers. Watch live on twitch.tv/pcgamer beginning at 12 noon ET / 9 AM PT / 5 PM BST or on the streams of any of our eight competitors.\n\nWins in these three games aren't the only thing that our streamers are fighting for, they're also vying for \"Cool Points\" that add to their overall tournament performance, earned by completing special challenges within matches like registering a perfect round in Street Fighter 6 or finding the Bugle of Friendship in Peak. For more details read here.\n\nHere's a breakdown of the match schedule for September 9, 10, and 12.\n\nThe weeklong schedule of competition. (Image credit: PC Gamer)\n\nThe lineup of competitors is a talented set of variety streamers:\n\nBarefootTasha twitch.tv/barefoottasha\n\nKingGothalion twitch.tv/kinggothalion\n\nAplFisher twitch.tv/aplfisher\n\nRIPMika twitch.tv/ripmika\n\nAsh IV twitch.tv/ashiv_\n\nElainaExe twitch.tv/elainaexe\n\nDish twitch.tv/dish\n\nunCAGEDgamez twitch.tv/uncagedgamez\n\nOur brave contestants. (Image credit: Future)\n\nThe PC Gamer Streamer Showdown is powered by OMEN. Watch all week long for a chance to win an OMEN Max 16 laptop, valued at more than $3000! On the final day of the tournament, a viewer of the winning streamer will be randomly selected to win.\n\nLaptop specs and features include:\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\n(Image credit: OMEN)",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/games/pc-gamer-streamer-showdown/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Delta Force Reveals New Operator Raptor Ahead Of Next Season",
      "content": null,
      "source": "Bleeding Cool News",
      "url": "https://bleedingcool.com/games/delta-force-reveals-new-operator-raptor-ahead-of-next-season/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "What to know about the Trump administration's Intel investment",
      "content": null,
      "source": "Quartz India",
      "url": "https://qz.com/federal-government-investing-semiconductor-business-intel",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Synopsys reports quarterly revenue below estimates, shares fall",
      "content": "(Reuters) -Chip design software provider Synopsys (SNPS) missed Wall Street estimates for third-quarter revenue on Tuesday, hurt by weakness in its Design IP business, sending shares down 20% in premarket trading on Wednesday.\n\nThe segment includes Synopsys' interface, security and embedded processor intellectual property, along with IP implementation services.\n\nThe underperformance in the segment was caused by deals that did not materialize, largely due to new export restrictions disrupting design starts in China and challenges at a major foundry customer, CEO Sassine Ghazi said on a post-earnings call.\n\nIn early July, the United States lifted restrictions on exports to China for chip design software developers, which had been imposed in late May.\n\nSynopsys had made significant investments in building out IP for the foundry customer, with expectations for returns in the second half of 2025, Ghazi said on the call. However, the customer pulled out due to market and client-related reasons.\n\nSynopsys, which counts companies such as Nvidia, Intel and Qualcomm among its partners, provides software and hardware used to design advanced processors.\n\nSunnyvale, California-based Synopsys completed its $35 billion cash-and-stock acquisition of engineering design firm Ansys in July, after receiving conditional approval from China's market regulator. The deal, announced early last year, faced intense antitrust scrutiny in markets including Britain.\n\nThe company reported revenue of $1.74 billion for the third quarter ended July 31, missing analysts' estimates of $1.77 billion, according to data compiled by LSEG.\n\nOn an adjusted basis, Synopsys reported a profit of $3.39 per share, also below estimates of $3.74 per share.\n\nSynopsys projected current-quarter revenue between $2.23 billion and $2.26 billion, while analysts expect $2.09 billion.\n\nRival Cadence Design Systems raised its annual sales and profit forecast in July.\n\n(Reporting by Juby Babu in Mexico City; Editing by Mohammed Safi Shamsi)",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/synopsys-reports-quarterly-revenue-below-233110633.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Shipped \"Panther Lake\" Processors to Samsung for Galaxy Book Laptops",
      "content": "According to the NBD shipment manifests, Intel has shipped its upcoming \"Panther Lake\" processor family to Samsung for its Galaxy Book laptops as early as May this year. This indicates that the final integration of Intel's latest design is complete and that Samsung has already incorporated these processors into its Galaxy Book line. The leaked shipping manifests show a BGA2540 processor, which corresponds to Panther Lake and is described as an integrated chip for a Samsung laptop. This confirms that the Galaxy Book is set to receive a Panther Lake update. However, the specific SKUs that will power the Samsung Galaxy Book laptops remain unknown for now.The low-power PTL-U models are designed for a 15 W TDP and are expected to come in 6-core and 8-core versions. Some SKUs will feature four high-performance P-cores paired with four LPE-cores, while others will have only two LPE-cores complementing four P-cores. Both families will utilize Xe3-based integrated graphics, with entry models featuring four GPU cores. The more powerful PTL-H line will scale up to around 16 CPU cores, comprising four P-Cores, eight E-cores, and four LPE-cores. Some H-series parts might include up to 12 GPU cores for integrated graphics, but the final configurations will be revealed when Intel officially launches the Panther Lake product family. At IFA 2025 in Berlin, Acer was the only OEM to showcase a Panther Lake-powered laptop, the Swift 16 AI . We will have to wait for Samsung's official announcement to learn more about the remaining specifications, such as SKU choices, screen, memory, and storage configurations.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340805/intel-shipped-panther-lake-processors-to-samsung-for-galaxy-book-laptops",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "QNAP Intros QuNAS Series with Intel Core 3 N355 Twin Lake CPUs",
      "content": "QNAP has unveiled its new QuNAS series of network-attached storage systems featuring Intel's latest Twin Lake architecture processors launched in January this year. The lineup centers around the Intel Core 3 N355 CPU , an 8-core, 8-thread processor with a 15 W TDP that can boost up to 3.9 GHz. The series flagship QNAP Qu805-N355 model measures 165 × 217 × 285 mm and can hold eight 3.5-inch SATA drives with hot-swap capability, supporting both 2.5-inch SATA SSDs. Memory configurations include 8 GB or 16 GB DDR5 SODIMM options, with 8 GB eMMC NAND flash for boot storage. Two M.2 2280 slots support NVMe PCIe Gen 3 x1 SSDs for additional storage expansion. Connectivity features dual 2.5 Gigabit Ethernet ports, three USB 3.2 Gen 2 ports including one Type-C connector, and HDMI 2.1 output capable of 4K resolution at 60 Hz. The system draws 102.78 W during typical operation from a 150 W external adapter.The series is complemented with six-bay (Qu605, 165 × 217 × 226 mm, 84.42 W) and four-bay (Qu405, 165 × 217 × 168 mm, 62.69 W) models. QNAP also offers Lite variants powered by the Intel N150 quad-core processor running at 3.6 GHz while maintaining similar feature sets. Exact pricing and availability are yet to be known since the series is currently listed only on the QNAP Chinese official website.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340809/qnap-intros-qunas-series-with-intel-core-3-n355-twin-lake-cpus",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Announces Key Leadership Changes to Data Center and Client Computing Group",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/intel-announces-key-leadership-changes-to-data-center-and-client-computing-group/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Steve Bannon Rages: Young Republicans Want Nationalized Health Care",
      "content": "Real America's Voice Steve Bannon was livid that young Republicans have so many liberal and socialist views when it comes to healthcare, wealth and industry.\n\nMedicare for all looks good, right young MAGA's?\n\nA new Rasmussen poll couldn't appease Bannon's annoyance with the reults\n\nRasmussen usually are the most pro-Trump polls in America\n\nMITCHELL: Well, here's a really good example. This is an 18 to 39 year old likely voter survey.\n\nI have to thank the folks at Stopping Socialism, Justin Haskins, the Heartland Institute for sponsoring this. It's free. People can go to RasmussenReports.com, download the cross tabs, because there's a lot of stuff in here.\n\nBut here's one example. This is a sample that we weighted to a Trump minus four recalled vote.\n\nThis is how it looked in November. Do you agree or disagree with this statement?\n\nMajor industries like healthcare, energy, and big tech should be nationalized to give more control and equity to the people.\n\nIf the Zoomers were really based, that number should be a pretty low number, but it's not. 76% of 18 to 39 year olds at least somewhat agree with that.\n\nAlmost 40% strongly agree, but here's the problem. It's not just the Democrats. 78% of self-ID'd Republican young people who want major industries like healthcare and tech nationalized.\n\nThat's absolutely insane.\n\nAnd it's a vast majority of Trump 2024 voters. So people did not vote for Trump because they're conservative. Yes, 79% of Trump 2024 voters want to nationalize major industries. We have 57% of Trump 2024 voters wanting excess wealth confiscation.\n\nThese people are not just going to be happy with, you know, let's cut a few regulations.\n\n--\n\nBANNON: If that's the way, and I keep telling, if that's the system you want, you're going to get Luigi on one end or you get Mondami on the other.\n\nOkay.\n\nYou've brought this on yourself.\n\nI don't know.\n\nI back these kids in that they don't know the details of change, but it has to change.\n\nDo we have to nationalize tech or big health?",
      "source": "Crooksandliars.com",
      "url": "https://crooksandliars.com/2025/09/steve-bannon-flips-young-republicans-healthcare",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Detailed findings from AP investigation into how US tech firms enabled China's digital police state",
      "content": "BEIJING (AP) — American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warningsfrom the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nThe AP investigation was based on tens of thousands of leaked emails and databases from a Chinese surveillance company; thousands of pages of confidential corporate and government documents; public Chinese language marketing material; and thousands of procurements, many provided by ChinaFile, a digital magazine published by the non-profit Asia Society. The AP also drew from dozens of open record requests and interviews with more than 100 current and former Chinese and American engineers, executives, experts, officials, administrators, and police officers.\n\nAmerican tech firms were by far the biggest suppliers, but German, Japanese, and Korean firms also had a role. Here are some examples:\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nMILITARY ACCESS: A Chinese military contractor worked with Armonk, New York-based IBM in 2009 to design national intelligence systems, including a counterterrorism system, according to classified Chinese government documents. These systems were used by China’s secret police, the Ministry of State Security, and the Chinese military. IBM referred to any such deals as “old, stale interactions”: “ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.”\n\nANTI-TERROR ANALYSIS: IBM agents in China sold IBM’s i2 policing analysis software to the Xinjiang police, China’s Ministry of State Security, and other Chinese police units throughout the 2010s, leaked emails show. i2 software was subsequently copied and deployed by one former IBM agent, Landasoft, as the basis for a predictive policing platform that tagged hundreds of thousands of people as potential terrorists during a brutal crackdown in China’s far west Xinjiang region. IBM says it ceased relations with Landasoft in 2014, prohibited sales to police in Xinjiang and Tibet since 2015, and has no record of any sales of i2 software to the Public Security Bureau in Xinjiang.\n\nETHNIC REPRESSION: Dell and then-subsidiary VMWare sold cloud software and storage devices to police and entities providing data to police in Tibet and Xinjiang, even as late as 2022 after ethnic repression there was widely known. Dell addressed race in its marketing: In 2019, Dell said on WeChat it had teamed up with surveillance firm Yitu to sell a “military-grade” AI-powered laptop for Chinese police with “all-race recognition.” Dell, based in Round Rock, Texas, told AP it conducts “rigorous due diligence” to ensure compliance with U.S. export controls. Chinese policing systems, including in Xinjiang, also used software from Oracle, based in Austin, Texas, and from Microsoft, based in Seattle, according to procurements and a leaked database obtained by AP.\n\nFINGERPRINT RECOGNITION: Chinese defense contractor Huadi worked with IBM to construct China’s national fingerprint database; IBM said it never sold “fingerprinting-specific” products to the Chinese government and that any possible misuse “for fingerprinting purposes” was done without its knowledge or assistance. HP and VMWare sold technology used for fingerprint comparison by Chinese police. Intel said in 2019 marketing material that it partnered with Hisign, a Chinese fingerprinting company that sold to Xinjiang police, to make their fingerprint readers more effective, and that the new reader was “fully tested in an actual application scenario” with a municipal police bureau. Hisign was still an Intel partner as of last year, according to Chinese media reports. California-based Intel said it has not had any technical engagement with Hisign since 2024, and told AP it would “act swiftly” if it became aware of any “credible misuse.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAI CAMERAS: IBM, Dell, Tokyo-based Hitachi, and VMWare promoted facial recognition for use by Chinese police. Japanese electronics giant Sony said on its official WeChat account that it wired a Chinese prison with “intelligent” cameras, saying it was widely trusted for “surveillance projects.” California chip giant Nvidia and Intel partnered with China’s three biggest surveillance companies to add AI capabilities to camera systems used for video surveillance across China, including in Xinjiang and Tibet, until sanctions were imposed. Relations with other Chinese surveillance companies continued more recently: Nvidia posted on its WeChat social media account in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk. Nvidia told AP those relationships no longer continue.\n\nSURVEILLANCE RESEARCH: Nvidia, IBM, and Hitachi staff collaborated with Chinese police researchers and companies on surveillance technology. Nvidia said in a post dating to 2013 or later that a Chinese police institute used its chips for surveillance technology research. Nvidia said it doesn’t currently work with Chinese police but did not address the past. And in 2021, an IBM and a U.S. Army researcher coauthored an AI video study with a Chinese police researcher working at a sanctioned company, according to a paper unearthed by IPVM, a surveillance research publication. The U.S. Army told AP the Chinese police researcher only worked on the paper after the Army researcher’s work had concluded.\n\nDNA: Chinese police DNA labs bought Dell and Microsoft software and equipment to save genetic data on police databases. In 2021, Hitachi advertised DNA sequencers to Chinese police, and police labs bought pipettes from German biotech firm Eppendorf last year. And until contacted by AP in August, Massachusetts-based biotech firm Thermo Fisher Scientific‘s website stated that its kits are made for China’s national DNA database and “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans,” and featured the work of a Chinese police researcher who discussed using Thermo Fisher kits to identify ethnic Uyghur and Manchu populations at a 2016 conference. Thermo Fisher stopped sales in Xinjiang in 2021 and in Tibet in 2024, but still promotes kits to police elsewhere in China, including at a police trade show earlier this year. In a statement to AP, Thermo Fisher said its kits “are designed to be effective across diverse global populations” but “do not have the capability to distinguish among specific ethnic groups.”\n\nINTERNET POLICE: In 2014, VMWare said internet police in cities across China used its software, and in 2016, Dell said on its WeChat account that its services assisted the Chinese internet police in “cracking down on rumormongers” — essentially promoting censorship. An undated IBM marketing presentation said that internet police in Shanghai and Guangzhou used its i2 software, with metadata suggesting it was from 2018. IBM held a conference in Beijing promoting i2 in 2018, according to its official WeChat account.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nENCRYPTION TECHNOLOGY: Leaked government blueprints show Illinois-based Motorola provided encrypted radio communications technology to the Chinese police for handling “sudden and mass events in Beijing.” Motorola did not respond to requests for comment.\n\nAI DRIVES: Californian hard disk giants Seagate and Western Digital and Tokyo-based Toshiba sell hard drives specialized for AI video systems for use by Chinese police. In 2022, Toshiba wrote about how its surveillance hard drives can help police monitor communities to “identify and control suspicious” or “blacklisted” individuals. “They’re optimized and adapted for security systems,” Toshiba sales director Feng Hao told AP. Last year, Western Digital touted its partnership with Chinese surveillance company Uniview at a policing trade expo, months before Uniview was sanctioned over complicity in rights abuses. And Seagate said on WeChat in 2022 that it sells hard drives “tailor made” for AI video systems in China for use by police to help them ”control key persons,” and promoted their drives to police at a security trade association in China this year.\n\nMAPPING SOFTWARE: Blueprints show that in 2009, IBM, Oracle, and Esri, the creator of ArcGIS based in California, sold hundreds of thousands of dollars’ worth of software to build China’s Police Geographic Information System, and in 2013, HP said it sold “digital fencing” solutions to Chinese police. Such systems alert Chinese police even today when Uyghurs, Tibetans or dissidents stray out of provinces, counties or even villages. The U.S. curbed exports of such mapping software to China in 2020. But the restrictions are narrow in scope, and Esri maintains a research center in Beijing that marketed to police and other Chinese clients. Esri denied involvement.\n\nPOLICE GEAR: Chinese police patrol the streets equipped with foreign technology. Officers stroll the streets of Beijing with Motorola walkie-talkies, for example, while Korean electronics giant Samsung sells microSD cards for police body cameras, advertising them at Chinese police trade shows in 2023 and 2024. And in WeChat posts, Chinese state-owned company Jinghua said it cooperated with German electronics giant Philips on China’s first ”AI-powered 5G” police body camera and advertised Philips-branded recorders and cameras to Chinese police. In a statement, Philips said it had no partnership with Jinghua, did not authorize sales of Philips-branded body cameras in China, and would be contacting Jinghua over the posts.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nIBM, Dell, California network seller Cisco, Seattle-based Amazon Web Services, Seagate, Intel, Thermo Fisher and Western Digital all said they adhere to relevant export controls, laws and regulations where they operate. Eppendorf, Sony, and Hitachi declined to describe their business relationships in China but said they respected human rights.\n\nOracle, Hewlett Packard Enterprise, and California tech conglomerate Broadcom, which acquired VMWare in 2023, did not comment on the record. HP, Motorola, Samsung, Toshiba, Huadi, and Landasoft did not respond. Microsoft said it did not knowingly provide software for updates to China’s main policing system.\n\nThe Xinjiang government said in a statement that it uses surveillance technologies to “prevent and combat terrorist and criminal activity” and does not target any particular ethnicity. The statement said Western countries also use such technology, calling the U.S. “a true surveillance state.” Other government agencies did not respond to a request for comment.\n\n__\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/detailed-findings-ap-investigation-us-043012321.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel 14A Node Expected to Cost More Than 18A, Driven by High-NA EUV",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/intel-14a-node-expected-to-cost-more-than-18a-driven-by-high-na-euv/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Belarusian spy network uncovered by Eurojust operation, Moldovan ex-intel chief arrested",
      "content": null,
      "source": "EURACTIV",
      "url": "https://www.euractiv.com/section/politics/news/belarusian-spy-network-uncovered-by-eurojust-operation-moldovan-ex-intel-chief-arrested/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "HP EliteBook 8 G1a 16 AI laptop review: Redesigned inside and out",
      "content": "The business-centric EliteBook 8 series directly replaces the outgoing EliteBook 800 series. The new naming convention makes it easier to identify the price category, generation, and type of processor. In this case, the EliteBook 8 G1a 16 in review is an entry-level (8) first generation (G1) model powered by an AMD (a) processor. Higher-end EliteBook models sport the \"X\" or \"Ultra\" name instead of the \"8\".\n\nOur test configuration is a costlier SKU with the Zen 5 Ryzen AI 7 PRO 350 CPU, 32 GB of RAM, and 1200p IPS display for approximately $1900 USD. Lower-end options start with the Zen 4 Ryzen 5 Pro 230 while the 1200p native resolution is fixed across the board.\n\nAlternatives to the 16-inch EliteBook 8 G1a include other entry-level to midrange business or office laptops like the Asus ExpertBook B5, Lenovo ThinkPad L16, or Dell Latitude 5000 to 7000 series. A 14-inch version of this model is also available called the EliteBook 8 G1a 14. For Intel fans, SKUs with Core Ultra CPUs are aptly named the EliteBook 8 G1i 16.\n\nMore HP reviews:",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/HP-EliteBook-8-G1a-16-AI-laptop-review-Redesigned-inside-and-out.1103659.0.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Appoints Jim Johnson As CCG Head, Kevork Kechichian As DCG Head & Naga Chandrasekaran As IFS Head, Michelle Johnston Departs After More Than 3 Decades",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/intel-appoints-jim-johnson-ccg-head-kevork-kechichian-dcg-head-naga-chandrasekaran-ifs-head-michelle-johnston-departs/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Nvidia Announces Rubin CPX GPU To Speed Long-Context AI",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/karlfreund/2025/09/09/nvidia-announces-rubin-cpx-gpu-to-speed-long-context-ai/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Apple、Liquid Glassデザインを採用した「macOS 26 Tahoe」や「iOS/iPadOS 26」、「watchOS 26」、「visionOS 26」、「tvOS 26」を日本時間9月16日にリリースすると発表。",
      "content": "AppleがLiquid Glassデザインを採用した「macOS 26 Tahoe」と「iOS 26」、「watchOS 26」「visionOS 26」を9月16日に正式リリースすると発表しています。詳細は以下から。\n\n\n\n\n\nAppleは日本時間2025年09月10日 午前2時より、スペシャルイベント「Awe dropping. (言葉にできない。)」を開催し、A19チップを搭載した「iPhone 17/Air/Pro」、「AirPods Pro 3」、「Apple Watch Series 11」などを発表しましたが、\n\n更新されたAppleのプレビューページによると、Appleは06月からBeta版を公開し開発を進めてきたLiquid Glassデザインシステム採用の「macOS 26 Tahoe」や「iOS/iPadOS 26」、「watchOS 26」、「visionOS 26」、「tvOS 26」を現地時間2025年09月15日、日本時間の16日に正式リリースすると発表しています。\n\nシステム要件\n\nmacOS 26 TahoeやiOS/iPadOS 26はガラス調のLiquid Glassデザインシステムが全Apple OSで採用される一方、Macでは最後のIntel Mac miniとなっている「Mac mini (2018)」や、Intelチップを搭載した最後のMacBook Air「MacBook Air (Retina, 13-inch, 2020)」、プロユーザー向けにIntel Xeonを搭載した「iMac Pro (2017)」、そして2018~2019年製造のMacBook Pro、iMacがmacOS 26 Tahoeのサポートから外されており、\n\niPhone/iPadでは、2018年に発売されたApple A12 Bionicチップ搭載の「iPhone XR/XS」シリーズ、2019年に発売されたA10 Fusionチップ搭載の「iPad (第7世代)」がシステム要件から外れるので、ユーザーの方は注意してください。\n\nmacOSのシステム要件\n\nmacOS 14\n\nSonoma macOS 15\n\nSequoia macOS 26\n\nTahoe MacBook Air 2018以降 2020以降 2020以降のApple Siliconモデルのみ MacBook Pro 2018以降 2020以降のApple Siliconモデル\n\nMacBook Pro (16‑inch, 2019)\n\nMacBook Pro (13‑inch, 2020, Four Thunderbolt 3 ports) Mac mini 2018以降 2020以降のApple Siliconモデル iMac 2019以降 2020以降 iMac Pro 2017以降 終了 Mac Studio 2022以降 Mac Pro 2019以降",
      "source": "Applech2.com",
      "url": "https://applech2.com/archives/20250910-macos-26-tahoe-and-ios-26-available-9-15.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Media Encoder 2025 v25.4.1",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-media-encoder-2025-v25-4-1-2/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Lenovo Legion Pro 7i: 16\" QHD+ 240Hz OLED, RTX 5090, Intel Ultra 9 275HX, 64GB DDR5, 2TB SSD $2999.99",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18593518-lenovo-legion-pro-7i-16-qhd-240hz-oled-rtx-5090-intel-ultra-9-275hx-64gb-ddr5-2tb-ssd-2999-99",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Dell 14 Plus: 14\" QHD+ 90Hz, Intel Ultra 9 288V, 32GB LPDDR5, 1TB SSD $899.99",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired Dr.W posted Item 1 of 2 Item 1 of 2 expired Dr.W posted Dell 14 Plus: 14\" QHD+ 90Hz, Intel Ultra 9 288V, 32GB LPDDR5, 1TB SSD $899.99 $900 $1,390 35% off Micro Center 9 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 5,929 Views Visit Micro Center Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details Lowest price ever and cheaper than the previous popular\n\n\n\nAvailable In-store Only; In stock at all stores (except for CA, TX) when posting.\n\n\n\nSPECS: 14\" 2.5K/QHD+ (2560x1600, WQXGA+) 16:10, 90Hz, 300-nits, 100% sRGB, Anti-Glare, WVA/IPS Display\n\nIntel Core Ultra 9 288V (48 TOPS NPU, 8 cores, up to 5.1 GHz)\n\n32GB, LPDDR5X, 8533MT/s, Memory on Package, onboard\n\n1TB M.2 PCIe NVMe Solid State Drive\n\nIntel Arc Graphics\n\nIntel Wi-Fi 7 BE201, 2x2, 802.11be, Bluetooth wireless card\n\n1080p at 30 fps FHD camera\n\nEnglish Backlit Copilot key keyboard, no numeric keypad\n\n4-Cell Battery, 64WHr (Integrated)\n\n4.42 lbs. (2.00 kg)\n\nExterior chassis materials: LCD Cover/Base: Aluminium Bezel/Palmrest: Plastic\n\nPorts: 1x USB 3.2 Gen 1 (5 Gbps) port 1x USB 3.2 Gen 2 (10 Gbps) Type-C port with DisplayPort 1.4 and Power Delivery 1x Thunderbolt 4 port with DisplayPort 2.1 and Power Delivery 1x HDMI 2.1 port 1x Universal Audio jack\n\n\n\n\n\nhttps://www.microcenter .com/produ...r-ice-blue and cheaper than the previous popular FP deal In stock at all stores (except for CA, TX) when posting. Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster Dr.W Follow Give Rep Message 8,032 Deal Posts 11,542 Comments Posts 16,996 Reputation Points 10,806 Votes Submitted Deal Details Community Notes About the Poster Lowest price ever and cheaper than the previous popular\n\n\n\nAvailable In-store Only; In stock at all stores (except for CA, TX) when posting.\n\n\n\nSPECS: 14\" 2.5K/QHD+ (2560x1600, WQXGA+) 16:10, 90Hz, 300-nits, 100% sRGB, Anti-Glare, WVA/IPS Display\n\nIntel Core Ultra 9 288V (48 TOPS NPU, 8 cores, up to 5.1 GHz)\n\n32GB, LPDDR5X, 8533MT/s, Memory on Package, onboard\n\n1TB M.2 PCIe NVMe Solid State Drive\n\nIntel Arc Graphics\n\nIntel Wi-Fi 7 BE201, 2x2, 802.11be, Bluetooth wireless card\n\n1080p at 30 fps FHD camera\n\nEnglish Backlit Copilot key keyboard, no numeric keypad\n\n4-Cell Battery, 64WHr (Integrated)\n\n4.42 lbs. (2.00 kg)\n\nExterior chassis materials: LCD Cover/Base: Aluminium Bezel/Palmrest: Plastic\n\nPorts: 1x USB 3.2 Gen 1 (5 Gbps) port 1x USB 3.2 Gen 2 (10 Gbps) Type-C port with DisplayPort 1.4 and Power Delivery 1x Thunderbolt 4 port with DisplayPort 2.1 and Power Delivery 1x HDMI 2.1 port 1x Universal Audio jack\n\n\n\n\n\nhttps://www.microcenter .com/produ...r-ice-blue and cheaper than the previous popular FP deal In stock at all stores (except for CA, TX) when posting.",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18593587-dell-14-plus-14-qhd-90hz-intel-ultra-9-288v-32gb-lpddr5-1tb-ssd-899-99",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Patch Tuesday Arrives with New Features for Windows 11",
      "content": "It’s Patch Tuesday, and those on Windows 11 can look forward to a long list of new features. You know, once Microsoft gets around to delivering them on your PC, as most of them are being rolled out gradually.\n\nCumulative update KB5065426 is available for PCs running Windows 11 version 23H2. And cumulative update KB5065426 is available now for PCs running Windows 11 version 24H2. Both builds include numerous new features that were first previewed two weeks ago.\n\nKey new features include:\n\nRecall improvements (Copilot+ PCs only). Recall provides a new homepage experience with shortcuts for your recent activity, most-used apps, and most-visited websites. There are new controls for filtering the apps and websites that Recall shouldn’t record, plus a new navigation bar on the left with links to Home, Timeline, Feedback, and Settings.\n\nClick to Do improvements (Copilot+ PCs only). Click to Do now provides an interactive tutorial when you first launch it, and you can access it later by navigating to More options (“…”) > Start tutorial.\n\nAgent in Settings (Copilot+ PCs only). Previously available on Snapdragon X-based Copilot+ PCs, the new Agent in Settings is now available to those with AMD- and Intel-based Copilot+ PCs too. But it’s still limited to English, which must be configured as your primary display language.\n\nSearch improvements. When you initiate Search from the Taskbar item, a new grid view is used for image results so you can more easily find what you’re looking for. The Search window will now display a status pane if Windows 11 is still indexing your search locations. And search results will clearly differentiate between local and cloud-stored files.\n\nLarger clock option in Notification center. As was the case in Windows 10, you can now enable a larger clock with settings in the Date and Calendar window that appears when you display the Notification center. (To do so, open Settings, navigate to Time & language > Date & time, and enable the option “Show time in the Notification Center.”)\n\nSystem dialog improvements. System dialogs now appear modally over the rest of the Desktop, which is dimmed to give emphasis to the dialog.\n\nLock screen widgets improvements. You can now add, remove, and rearrange Lock screen widgets. And these widgets now support a new small sizing option.\n\nFile Explorer improvements. Microsoft has made minor visual changes to the context menu that appears when you right-click in File Explorer.\n\nWindows Hello improvements. The Windows Hello user experience is completely redesigned with more modern visuals. It’s nicer looking but, truth be told, slower and more tedious to use now. But it does let you switch between available authentication options such as passkeys or connected devices.\n\nGenerative AI privacy and security settings. A new page in the Settings app, found at Privacy & security > Text and Image Generation, displays which third-party apps have recently used generative AI models built into Windows. You can also manage which apps can use these features, and then disable those you don’t want.\n\nWidgets improvements. You can now configure multiple dashboards in the Widgets board, and there’s a new navigation bar on the left for switching between the widget dashboards and other views like the Discover feed, which is “more organized, personalized, and engaging.”\n\nTask Manager improvements. Task Manager has been updated to more accurately display CPU usage across all views. The Details view now has an optional CPU Utility column, as per the Processes view.\n\nFixes. As you might imagine, these builds also deliver multiple security and bug fixes across ReFS, the Chinese (Simplified) Input Method Editor (IME), Arm64 performance, and more.\n\nYes, you will need to reboot as usual.",
      "source": "Thurrott.com",
      "url": "https://www.thurrott.com/windows/windows-11/326263/patch-tuesday-arrives-with-new-features-for-windows-11",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Takeaways from AP's investigation into how US tech companies enabled China's digital police state",
      "content": "BEIJING (AP) — Across China, tens of thousands of people tagged as troublemakers are trapped in a digital cage, barred from leaving their province and sometimes even their homes by the world’s largest digital surveillance apparatus. Most of this technology came from companies in a country that has long claimed to support freedoms worldwide: the United States.\n\nOver the past quarter century, American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warnings from the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nMost of the companies that responded said they fully complied with all laws, sanctions and U.S. export controls governing business in China, past and present. Here are key findings:\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAmerica brought ‘predicative policing’ to China\n\nU.S. companies introduced systems that mine a vast array of information — texts, calls, payments, flights, video, DNA swabs, mail deliveries, the internet, even water and power use — to unearth individuals deemed suspicious and predict their movements. But this technology also allows Chinese police to threaten friends and family and preemptively detain people for crimes they have not even committed. The AP found a Chinese defense contractor, Huadi, worked with IBM in 2009 to design the main policing system for Beijing to censor the internet and crack down on alleged terrorists, the Falun Gong religious sect, and even villagers deemed troublesome. IBM referred to any possible relationship it may have had with Chinese government agencies as “old, stale interactions”: “ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.” Huadi did not respond.\n\nUS tech enabled the Xinjiang crackdown\n\nAmerican surveillance technologies allowed a brutal mass detention campaign in the far west region of Xinjiang — targeting, tracking and grading virtually the entire native Uyghur population to forcibly assimilate and subdue them. IBM agents in China sold its i2 software to the Xinjiang police, China’s Ministry of State Security, and many other Chinese police units throughout the 2010s, leaked emails show. One agent, Landasoft, subsequently copied and deployed it as the basis for a predictive policing platform that tagged hundreds of thousands of people as potential terrorists. IBM said it has no record of its i2 software ever being sold to the Public Security Bureau in Xinjiang, was not aware of any interaction between Landasoft and that bureau and cut ties with Landasoft in 2014. Landasoft did not respond.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome tech companies even specifically addressed race in their marketing. Dell and a Chinese surveillance firm promoted a “military-grade” AI-powered laptop with “all-race recognition” on its official WeChat account in 2019. And until contacted by AP in August, biotech giant Thermo Fisher Scientific’s website marketed DNA kits to the Chinese police as “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans.” The Xinjiang government said that it uses surveillance technologies to prevent terrorism, and that Western countries also use such technology, calling the U.S. “a true surveillance state.”\n\nCompanies pitched tech to control citizens\n\nThough the companies often claim they aren’t responsible for how their products are used, some directly pitched their tech as tools for Chinese police to control citizens, marketing materials from IBM, Dell, Cisco, and Seagate show. Their sales pitches — made both publicly and privately — cited Communist Party catchphrases on crushing protest, including “stability maintenance,” “key persons,” and “abnormal gatherings,” and named programs that stifle dissent, such as “Internet Police,” “Sharp Eyes” and the “Golden Shield.” IBM, Dell, Cisco and Seagate said they adhere to all relevant laws.\n\nAmerican tech laid the foundation for Chinese surveillance\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nAmerican technology laid the foundation for China’s surveillance apparatus that Chinese companies have since built on and in some cases replaced. Intel and Nvidia helped China’s three biggest surveillance companies make their camera systems AI-powered. Contracts to maintain existing IBM, Dell, HP, Cisco, Oracle, and Microsoft software and gear remain ubiquitous, often with third parties. And to this day, concerns remain over where technology sold to China will end up, with former U.S. officials and national security experts criticizing a deal struck this summer for Nvidia to sell chips used in artificial intelligence to China, saying the technology would fall into the hands of the Chinese military and intelligence. Nvidia said in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk, but told the AP those relationships no longer continue. Nvidia said it does not make surveillance systems or software, does not work with police in China and has not designed the H20 chips for police surveillance, and the White House and Department of Commerce did not respond to requests for comment.\n\nBig loopholes in sanctions remain\n\nSome U.S. companies ended contracts in China over rights concerns and after sanctions. IBM said it has prohibited sales to Tibet and Xinjiang police since 2015, and suspended business relations with defense contractor Huadi in 2019. Nvidia and Intel also ended partnerships with China’s top two surveillance companies in 2019. However, sanctions experts noted that the laws have significant loopholes and often lag behind new developments. For example, a ban on military and policing gear to China after the 1989 Tiananmen massacre does not take into account newer technologies or general-use products that can be applied in policing. They also noted that the law around export controls is complicated.\n\nA cautionary tale\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nWhat started in China more than a decade ago could be seen as a cautionary tale for other countries at a time when the use of surveillance technology worldwide is rising sharply, including in the United States. Emboldened by the Trump administration, U.S. tech companies are more powerful than ever, and President Donald Trump has rolled back a Biden-era executive order meant to safeguard civil rights from new surveillance technologies. As the capacity and sophistication of such technologies has grown, so has their reach. Surveillance technologies now include AI systems that help track and detain migrants in the U.S. and identify people to kill in the Israel-Hamas war. China, in the meantime, has used what it learned from the U.S. to turn itself into a surveillance superpower, selling technologies to countries like Iran and Russia.\n\n“Because of this technology … we have no freedom at all,” said Yang Caiying, now in exile in Japan, whose family has been trapped in an increasingly tight noose of surveillance for the past 16 years. “At the moment, it’s us Chinese that are suffering the consequences, but sooner or later, Americans and others, too, will lose their freedoms.”\n\n__\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/takeaways-aps-investigation-us-tech-043117960.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Perfectly Clear WorkBench 4.8.0.2849",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/perfectly-clear-workbench-4-8-0-2849-2/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe After Effects 2025 v25.4.0",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-after-effects-2025-v25-4-0/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "US tech companies enabled the surveillance and detention of hundreds of thousands in China",
      "content": "BEIJING (AP) — The body camera hung from the top of the IV drip, recording the slightest twitch made by Yang Guoliang as he lay bloody and paralyzed in a hospital bed after a police beating with bricks.\n\nBy then, surveillance was nothing new for the Yang family in rural China, snared in an intricate network based on U.S. technology that spies on them and predicts what they’ll do.\n\nTheir train tickets, hotel bookings, purchases, text messages and phone calls are forwarded to the government. Their house is ringed with more than a dozen cameras. They’ve tried to go to Beijing 20 times in the past few years, but masked men show up and grab them, often before they depart. And last year, Yang’s wife and younger daughter were detained and now face trial for disrupting the work of the Chinese state — a crime carrying a sentence of up to a decade in prison.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nYet the Yangs say they are not criminals. They are simply farmers trying to beg Beijing to stop local officials from seizing their 1 1/2 acres of land in China’s eastern Jiangsu province.\n\n“Every move in my own home is monitored,” Yang said, sitting behind black curtains that block him from the glare of police lights trained straight at his house. “Their surveillance makes me feel unsafe all the time, everywhere.”\n\nAcross China, tens of thousands of people tagged as troublemakers like the Yangs are trapped in a digital cage, barred from leaving their province and sometimes even their homes by the world’s largest digital surveillance apparatus. Most of this technology came from companies in a country that has long claimed to support freedoms worldwide: the United States.\n\nOver the past quarter century, American tech companies to a large degree designed and built China’s surveillance state, playing a far greater role in enabling human rights abuses than previously known, an Associated Press investigation found. They sold billions of dollars of technology to the Chinese police, government and surveillance companies, despite repeated warningsfrom the U.S. Congress and in the media that such tools were being used to quash dissent, persecute religious sects and target minorities.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nCritically, American surveillance technologies allowed a brutal mass detention campaign in the far west region of Xinjiang — targeting, tracking and grading virtually the entire native Uyghur population to forcibly assimilate and subdue them.\n\nU.S. companies did this by bringing “predictive policing” to China — technology that sucks in and analyzes data to prevent crime, protests, or terror attacks before they happen. Such systems mine a vast array of information — texts, calls, payments, flights, video, DNA swabs, mail deliveries, the internet, even water and power use — to unearth individuals deemed suspicious and predict their behavior. But they also allow Chinese police to threaten friends and family and preemptively detain people for crimes they have not even committed.\n\nFor example, the AP found a Chinese defense contractor, Huadi, worked with IBM to design the main policing system known as the “Golden Shield” for Beijing to censor the internet and crack down on alleged terrorists, the Falun Gong religious sect, and even villagers deemed troublesome, according to thousands of pages of classified government blueprints taken out of China by a whistleblower, verified by AP and revealed here for the first time. IBM and other companies that responded said they fully complied with all laws, sanctions and U.S. export controls governing business in China, past and present.\n\nAcross China, surveillance systems track blacklisted “key persons,” whose movements are restricted and monitored. In Xinjiang, administrators logged people as high, medium, or low risk, often according to 100-point scores with deductions for factors like growing a beard, being 15 to 55 years old, or just being Uyghur.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome tech companies even specifically addressed race in their marketing. Dell and a Chinese surveillance firm promoted a “military-grade” AI-powered laptop with “all-race recognition” on Dell's official WeChat account in 2019. And until contacted by AP in August, biotech giant Thermo Fisher Scientific’s website marketed DNA kits to the Chinese police as “designed” for the Chinese population, including “ethnic minorities like Uyghurs and Tibetans.”\n\nWhile the flood of American technology slowed considerably starting in 2019 after outrage and sanctions over atrocities in Xinjiang, it laid the foundation for China’s surveillance apparatus that Chinese companies have since built on and in some cases replaced. To this day, concerns remain over where technology sold to China will end up.\n\nFor example, 20 former U.S. officials and national security experts wrote a letter in late July criticizing a deal for Nvidia to sell H20 chips used in artificial intelligence to China, with 15% of revenues going to the U.S. government. They said no matter who the chip is sold to, it will fall into the hands of Chinese military and intelligence services.\n\nNvidia said it does not make surveillance systems or software, does not work with police in China and has not designed the H20 for police surveillance. Nvidia posted on its WeChat social media account in 2022 that Chinese surveillance firms Watrix and GEOAI used its chips to train AI patrol drones and systems to identify people by their walk, but told the AP those relationships no longer continue. The White House and Department of Commerce did not respond to requests for comment.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nThermo Fisher and hard drive maker Seagate promoted their products to Chinese police at conferences and trade shows this year, according to online posts. Officers stroll the streets of Beijing with Motorola walkie talkies. Nvidia and Intel chips remain critical for Chinese policing systems, procurements show. And contracts to maintain existing IBM, Dell, HP, Cisco, Oracle, and Microsoft software and gear remain ubiquitous, often with third parties.\n\nWhat started in China more than a decade ago could be seen as a cautionary tale for other countries at a time when the use of surveillance technology worldwide is rising sharply, including in the United States. Emboldened by the Trump administration, U.S. tech companies are more powerful than ever, and President Donald Trump has rolled back a Biden-era executive order meant to safeguard civil rights from new surveillance technologies.\n\nAs the capacity and sophistication of such technologies has grown, so has their reach. Surveillance technologies now include AI systems that help track and detain migrants in the U.S. and identify people to kill in the Israel-Hamas war. China, in the meantime, has used what it learned from the U.S. to turn itself into a surveillance superpower, selling technologies to countries like Iran and Russia.\n\nThe AP investigation was based on tens of thousands of leaked emails and databases from a Chinese surveillance company; tens of thousands of pages of confidential corporate and government documents; public Chinese language marketing material; and thousands of procurements, many provided by ChinaFile, a digital magazine published by the non-profit Asia Society. The AP also drew from dozens of open record requests and interviews with more than 100 current and former Chinese and American engineers, executives, experts, officials, administrators, and police officers.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nThough the companies often claim they aren’t responsible for how their products are used, some directly pitched their tech as tools for Chinese police to control citizens, marketing material from IBM, Dell, Cisco, and Seagate show. Their sales pitches — made both publicly and privately — cited Communist Party catchphrases on crushing protest, including “stability maintenance,” “key persons,” and “abnormal gatherings,” and named programs that stifle dissent, such as “Internet Police,” “Sharp Eyes” and the “Golden Shield.”\n\nOther companies, like Intel, Nvidia, Oracle, Thermo Fisher, Motorola, Amazon Web Services, Microsoft, Western Digital, creator of mapping software ArcGIS Esri, and what was then Hewlett Packard, or HP, also sold technology or services knowingly to Chinese police or surveillance companies. Four practicing lawyers said sales like those uncovered by AP could potentially go against at least the spirit, if not the letter, of U.S. export laws at the time, which the companies denied.\n\nAmerican technology made up nearly every part of China’s surveillance apparatus, AP found:\n\nMILITARY AND POLICE: In 2009, Chinese defense contractor Huadi worked with IBM to build national intelligence systems, including a counterterrorism system, used by the Chinese military and China’s secret police, the Ministry of State Security. Chinese agents sold IBM’s i2 police surveillance analysis software to the same ministry and to Chinese police, including in Xinjiang, through the 2010s, leaked emails and marketing posts show. IBM said it has no record of its i2 software ever having been sold to the Public Security Bureau in Xinjiang.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSURVEILLANCE: Nvidia and Intel partnered with China’s three biggest surveillance companies to add AI capabilities to camera systems used for video surveillance across China, including Xinjiang and Tibet, until sanctions were imposed. Nvidia said in a post dating to 2013 or later that a Chinese police institute used its chips for surveillance technology research.\n\nETHNIC REPRESSION: IBM, Oracle, HP, and ArcGIS developer Esri sold hundreds of thousands of dollars’ worth of geographic and mapping software to Chinese police that allows officers to detect when blacklisted Uyghurs, Tibetans or dissidents stray out of provinces or villages. As late as 2019, with detentions in Xinjiang well underway, Dell hosted an industry summit in its capital. Dell and then-subsidiary VMWare sold cloud software and storage devices to police and entities providing data to police in Tibet and Xinjiang, even in 2022 after abuses there became widely known.\n\nIDENTIFICATION: Huadi worked with IBM to construct China’s national fingerprint database; IBM told AP it never sold “fingerprinting-specific product or technology” to the Chinese government “in violation of US law.” HP and VMWare sold technology used for fingerprint comparison by Chinese police, while Intel partnered with a Chinese fingerprinting company to make their devices more effective. IBM, Dell, and VMWare also promoted facial recognition to Chinese police. China’s police and police DNA labs bought Dell and Microsoft software and equipment to save genetic data on police databases.\n\nCENSORSHIP AND CONTROL: In 2016, Dell boasted on its WeChat account that its services assisted the Chinese internet police in “cracking down on rumormongers.” Seagate said on WeChat in 2022 that it sells hard drives “tailor made” for AI video systems in China for use by police to help them ”control key persons,” despite facing backlash for selling drives in Xinjiang.\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nFor extended findings, click here.\n\n“Everything was built on American tech,” said Valentin Weber, a researcher at the German Council on Foreign Relations who studied the use of U.S. tech by Chinese police. “China’s capability was close to zero.”\n\nIBM, Dell, Cisco, Intel, Thermo Fisher and Amazon Web Services all said they adhere to export control policies. Seagate and Western Digital said they adhere to all relevant laws and regulations where they operate.\n\nOracle, Hewlett Packard Enterprise, and tech conglomerate Broadcom, which acquired VMWare and cloud company Pivotal in 2023, did not comment on the record; HP, Motorola and Huadi did not respond, and Esri denied involvement but did not reply to examples. Microsoft told AP it found no evidence that it “knowingly sold technology to the military or police” as part of updates to the “Golden Shield.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nSome U.S. companies ended contracts in China over rights concerns and after sanctions. For example, IBM said it has prohibited sales to Tibet and Xinjiang police since 2015, and suspended business relations with defense contractor Huadi in 2019.\n\nHowever, sanctions experts noted that the laws have significant loopholes and often lag behind new developments. For example, a ban on military and policing gear to China after the 1989 Tiananmen massacre does not take into account newer technologies or general-use products that can be applied in policing.\n\nThey also noted that the law around export controls is complicated. Raj Bhala, an expert in international trade law at the University of Kansas, said the issues the AP described fell into “the kind of gray area that we put in exams.”\n\n“It would raise concerns about possible inconsistencies, possible violations,” said Bhala, who emphasized he was speaking generally and not about any specific company. “But I really stress ‘possible.’ We need to know more facts.”\n\nAdvertisement Advertisement\n\nAdvertisement Advertisement\n\nWhile German, Japanese and Korean firms also played a role, American tech firms were by far the biggest suppliers.\n\nThe Xinjiang government said in a statement that it uses surveillance technologies to “prevent and combat terrorist and criminal activity,” that it respects citizens’ privacy and legal rights and that it does not target any particular ethnicity. The statement said Western countries also use such technology, calling the U.S. “a true surveillance state.” Other government agencies did not respond to a request for comment, including China’s police and authorities in the Yangs’ province.\n\nThis technology still powers the police database that controls the Yangs and other ordinary people. An estimate based on Chinese government statistics found at least 55,000 to 110,000 were put under residential surveillance in the past decade, and vast numbers are restricted from travel in Xinjiang and Tibet. China’s cities, roads and villages are now studded with more cameras than the rest of the world combined, analysts say — one for every two people.\n\n“Because of this technology … we have no freedom at all,” said Yang Guoliang’s elder daughter, Yang Caiying, now in exile in Japan. “At the moment, it’s us Chinese that are suffering the consequences, but sooner or later, Americans and others, too, will lose their freedoms.”\n\nSelling surveillance superpowers\n\nBack when China was emerging from the chaotic violence of the Cultural Revolution in 1976, three in four Chinese were farmers, including the Yangs. They lived in a three-room home of tiles and pounded earth nestled among the lush, humid fields of the Yangtze River delta.\n\nAfter Chairman Mao Zedong’s death that year, Beijing’s new leaders opened China to the world, and American tech firms like HP and IBM rushed in. But there were hard limits on how much change the government would accept. In 1989, the Tiananmen pro-democracy protests rattled Beijing, which sent tanks and troops to shoot students.\n\nSoon after, Beijing began planning the “Golden Shield,” aimed at digitizing China’s police force.\n\nIn 2001, the 9/11 al-Qaida attacks turbocharged interest in surveillance technology. One researcher claimed authorities could have foiled the attack by unearthing connections between hijackers through public information in databases.\n\nAmerican companies cashed in, selling the U.S. billions of dollars in surveillance technologies they said could prevent crime and terror attacks.\n\nThey spotted the same sales opportunity in China. Researchers warned surveillance technologies would be “instruments of repression” in the hands of authoritarian states. Yet IBM, Cisco, Oracle, and other American companies clinched orders to supply Beijing’s “Golden Shield.”\n\n“China didn’t have this kind of thing before,” said Wang, a former Chinese police official in Xinjiang who asked to be identified only by last name for fear of retaliation. “These concepts all came from the West.”\n\nSoon, disturbing stories emerged. Chinese police blocked sensitive news, pinpointing dissidents with unnerving precision. They stalked adherents of the Falun Gong sect banned by authorities. Congress demanded explanations from tech companies.\n\nIn 2008, documents leaked to the press showed Cisco saw the “Golden Shield” as a sales opportunity, quoting a Chinese official calling the Falun Gong an “evil cult.” A Cisco presentation reviewed by AP from the same year said its products could identify over 90% of Falun Gong material on the web. Followers sued Cisco, which is now petitioning the U.S. Supreme Court to throw out the lower court ruling that allowed the lawsuit.\n\nAt a human rights conference in February, then-Cisco lawyer Katie Shay said companies had a responsibility to understand how customers might misuse their technology for “surveillance and censorship.”\n\n“A lot of people have suffered at the hands of their government, and I want to acknowledge that pain,” said Shay, who left Cisco in June. “I also will say that Cisco disputes the allegations of Cisco’s involvement.”\n\nCisco told the AP it is committed to human rights, but the court allegations may “open the floodgates for suits against U.S. corporations merely for legal exports of off-the-shelf goods and services.”\n\nAs Cisco was summoned before Congress, IBM partnered with a Chinese defense contractor on Phase Two of China’s “Golden Shield.”\n\nClassified government blueprints obtained by AP show that in 2009, IBM worked with Huadi, the state-owned subsidiary of China’s biggest missile military contractor spun off from China’s Ministry of Defense, to build out predictive policing.\n\n“Consolidate Communist Party rule,” read the Huadi blueprint, which showed the databases would track hundreds of thousands of people online.\n\nIn response to AP’s questions, IBM referred to any possible relationship it may have had with Chinese government agencies as “old, stale interactions”:\n\n“ ... If older systems are being abused today — and IBM has no knowledge that they are — the misuse is entirely outside of IBM’s control, was not contemplated by IBM decades ago, and in no way reflects on IBM today.”\n\nBack in 2009, Beijing needed the technology urgently to quash critics bonding online. Among them were the Yangs.\n\nIn April that year, local authorities ordered the Yangs and more than 300 other families in their village off their land. Developers coveted their prime lakefront property for “Western-style” apartments and villas, with fountains, football fields and shopping centers.\n\nThe Yangs had no idea police were installing systems that could target families like theirs. They just knew their land was being seized — in return for just a unit in a five-floor walk-up, too many stairs for their elderly mother to climb.\n\nThe Yangs and other farmers across China filed complaints.\n\n“I discovered the way the government took our land was illegal,” Yang Caiying said. “They cheated us.”\n\nPredict and prevent\n\nIn July 2009, three months after the Yang land was seized, riots erupted on the other side of the country in Xinjiang. Gory images of a Uyghur lynched at a toy factory spread online, angry Uyghurs took to the streets, and hundreds were killed.\n\nOnce again, American firms pitched their technology as the solution.\n\nThe government sent troops and cut Xinjiang’s phone and internet connections. In secret meetings, officials concluded that police had failed to spot the danger signs because they couldn’t identify Uyghurs deemed separatists, terrorists, and religious extremists, three engineers then working for the Xinjiang government told AP.\n\nAt the time, Xinjiang police and data systems were already running on American technology including IBM, Cisco, Oracle, and Microsoft, the engineers said, which AP verified by reviewing government contracts. But the databases were unconnected.\n\nSo Xinjiang launched an ambitious initiative to fuse data from all available sources, including banks, railways, and phone companies, into a central database. Officials demanded complete information on all suspicious individuals and their relatives going back three generations, according to the engineers, who described specific meetings in which they participated. Two asked to remain anonymous, fearing for their family in China; the third, Nureli Abliz, is now in Germany.\n\nSoon, lucrative contracts went up for bidding. Among those seeking to profit was IBM.\n\n“Prevent problems before they happen,” IBM promised Chinese officials. In an August 2009 pamphlet, IBM cited the Xinjiang riots and said its technology could help the government “ensure urban safety and stability.”\n\nIBM executives fanned out across the country to court Chinese officials. In December 2009, they set up a new “IBM Institute for Electronic Governance Innovation” in Beijing. In 2011, IBM acquired i2, a software program designed to prevent “terrorist threats.” IBM touted i2’s ability to analyze Chinese social media and licensed a Shanghai-based firm called Landasoft to sell it to China’s police, corporate records show.\n\nChinese police purchased tens of millions of dollars’ worth of products from companies like IBM, Cisco, Oracle, and Microsoft to upgrade the “Golden Shield” policing systems, a leaked accounting ledger acquired by AP from a whistleblower shows.\n\nIn the confrontation between the Chinese state and its critics, American technology tipped the scales of power.\n\nIn 2011, thieves ransacked the Yangs’ house, hunting for their property deed. They didn’t find it.\n\nTwo years later, bald men with tattoos and gold chains smashed down their door, shattered windows and flipped furniture to bully them out of their home anyway. Yang’s mother dropped to the floor in terror. Doctors diagnosed a heart attack, but the Yangs didn’t have money for a pacemaker.\n\nFurious, the Yangs sued local police. In June 2015, a judge ruled their land had been seized illegally. The Yangs celebrated.\n\nBut just weeks after the ruling, officers identified human rights lawyers through the “Golden Shield” technology, cuffed hundreds of them and pressed them into police vans across China. One lawyer later recalled how police monitored his messages on human rights in WeChat before they grabbed him, shackled him to a chair, and tortured him.\n\nOvernight, China’s budding rights-defense movement was dealt a fatal blow — and with it, the Yangs’ case. The Yangs were called in and curtly told the judgment was being overturned, their lawsuit dismissed without trial.\n\n“We really had too much faith in the law, you know?” Yang Guoliang said, his hands clenched in fists. “It turned out to be worthless.”\n\nTechnologies of terror\n\nIn the meantime, Beijing was transforming Xinjiang into the most heavily surveilled place on earth, sweeping around a million people into camps and prisons.\n\nWhen bombs tore through a train station in Xinjiang’s capital hours after a visit by leader Xi Jinping in 2014, Xi demanded a crackdown.\n\n“He was super angry,” said Abliz, one of the engineers with the Xinjiang government. “They concluded they weren’t surveilling Uyghurs closely enough.”\n\nThe next year, in April 2015, Abliz attended a closed-door exposition in Xinjiang. A booth ran by Landasoft, the former IBM partner, caught his eye.\n\nAfter years as a vendor of IBM’s i2 police surveillance analysis software to Xinjiang police, Landasoft had struck out on its own, touting i2-like software it said could detain extremists before they caused trouble. The similarity was no coincidence: Landasoft’s software was copied from i2, according to leaked emails and records.\n\n“The platform is developed based on i2,” a Landasoft project manager wrote in an email.\n\nIt used a proprietary data visualization system developed by i2. The software powered what was called the Integrated Joint Operations Platform, or IJOP, with the authority to trigger arrests.\n\nAbliz went numb.\n\n“I thought then that this was the end of humanity,” he said.\n\nLandasoft did not respond to repeated requests for comment. IBM said it cut ties with Landasoft in 2014 and was not aware of any interaction between Landasoft and the Public Security Bureau in Xinjiang.\n\nIn the autumn of 2015, months after the Xinjiang expo, Landasoft signed contracts with Xinjiang police, emails show. Workers installed millions of cameras and wired over 7,000 police outposts, often built just hundreds of meters apart. Nearly 100,000 officers were recruited to pound on doors and collect names, addresses, fingerprints and face-scans.\n\nThough Chinese hardware was favored, foreign software was irreplaceable for its performance and compatibility with China’s American-built systems, engineers told AP. That included server and database software from Oracle and Microsoft and cloud software from VMWare, which Dell acquired in 2016.\n\nIn late 2016, the crackdown began. Internal documents, a leaked copy of the Landasoft software and interviews with 16 former Xinjiang police officers, officials and engineers reveal how the system worked.\n\nLandasoft’s software combined data fed into a central police database to compile a dossier on vast swaths of Xinjiang’s population, tagging them with categories like “went on pilgrimage” or “studied abroad.” Administrators then questioned them, computed risk scores and decided who to detain.\n\nHundreds of thousands of people were tagged “untrustworthy”, leaked messages show. Leaked documents show the IJOP flagged 24,412 people as “suspicious” in just one week in 2017, leading to most being detained.\n\n“They thought it better to grab thousands of innocents than let a single criminal slip free,” Abliz said.\n\nThe technology was crude and flawed. Landasoft emails show engineers frantically fixing a software bug to release hundreds of people categorized as high-risk. And surveillance cameras often misidentified people, a former Xinjiang police officer found when he checked their ID cards.\n\nYet officers were told “computers cannot lie” and that the IJOP’s listed targets were “absolutely correct,” Abliz said. The software’s orders were often obeyed fearfully, unquestioningly.\n\n“The tech companies told the government their software is perfect,” Abliz said. “It’s all a myth.”\n\nMinority report\n\nThe all-encompassing surveillance forced total compliance: Officers arrested colleagues, neighbors informed on each other.\n\nIn May 2017, Kalbinur Sidik, a teacher now in the Netherlands, was summoned to her district government office in a yellow brick apartment building in Xinjiang’s capital. A young Uyghur woman, fresh from college, rose and introduced herself as a local official. Sidik, the woman explained, was being appointed as the head of her building, responsible for collecting information on neighbors.\n\n“What’s this data going to be used for?” Sidik asked.\n\nThe woman looked at a computer, with a Landasoft program running and lists of names and tags: “Goes out at night,” “Overseas phone,” “unemployed.” One button stood out: “Push Alert.”\n\nThe woman clicked it, and the screen filled with names. These people, the woman explained, would be detained and interrogated for suspected ties to terrorism. Sidik’s eyes widened.\n\n“I hated her for what she was doing,” Sidik said. “I knew those people would disappear.”\n\nXinjiang officials issued arrest quotas, Sidik and five other former officers and administrators said. Sidik watched with horror as the number of people who attended her compound’s weekly mandatory flag-raising ceremony shrank, from 400 to just over 100, as residents were arrested.\n\nAt the district office, she observed the logos popping up on screens: Oracle, Microsoft, Intel. The AP found evidence of products from all three companies used in Xinjiang’s policing and data systems during the crackdown, along with Esri, Seagate, Western Digital, Nvidia, Thermo Fisher, and VMWare, then owned by Dell, which advertised cooperation with Xinjiang authorities on its website.\n\nSidik asked her neighborhood official where it all came from.\n\n“We’ve spent a lot of money to import foreign technology,” she recalls the official telling her.\n\nAmong those caught in the digital dragnet was Parida Qabylqai, an ethnic Kazakh pharmacist at a military hospital in Xinjiang.\n\nIn February 2018, Qabylqai was flagged by the IJOP for visiting her parents in Kazakhstan. At first, her boss thought it was a mistake.\n\n“You’re a good person, you shouldn’t be listed,” she recalled him saying. Then he checked the IJOP and spotted her name.\n\n“It’s really serious! You’re going to end up in the camps,” he blurted out in shock.\n\nAn officer pressed a confession into her hands.\n\n“What did I do wrong?” Qabylqai asked.\n\n“Just sign!” the officer shouted.\n\nQabylqai was cuffed, hooded, and whisked to a camp, where cameras watched her day and night, even peering at her naked body in the toilet. Guards barking over speakers ordered her not to speak or even to move.\n\n“They did things to us that no human being should ever have to experience,” she said. “But they said my name was listed by the IJOP, so they didn’t need to explain anything.”\n\nEven enforcers of the system weren’t spared.\n\nIn 2018, Liu Yuliang, a civil servant in Xinjiang, was ordered to the home of a young police officer in his village. He and dozens of others stood, silent, as the officer embraced his sobbing, pregnant wife.\n\nThe officer had forced many people into the camps. Then he himself was flagged for detention.\n\nToo fearful to resist, Liu went along with the arrest, just as the young officer had done before him.\n\nLandasoft software alerted police when flagged people did anything labeled suspicious, like going out at night or logging on the internet repeatedly. Liu was sent to knock on doors, questioning residents whose “eyes filled with fear.”\n\nAs police swept Xinjiang, Landasoft purchased software from Pivotal, a cloud company later acquired by Broadcom, emails show. And Landasoft registered accounts on both Amazon Web Services and Microsoft Azure in 2018, seeking to expand cloud offerings to police clients, emails show.\n\nAWS said Landasoft “consumed very limited cloud services for a brief period” and not for software in the Xinjiang crackdown. Microsoft said Landasoft used Azure services through a self-service portal retired in 2021, and that any Landasoft data was deleted.\n\nThe Xinjiang government told the AP: “There is absolutely no such thing as ‘large-scale human rights violations.’”\n\nLiu eventually resigned and returned to his hometown in eastern China, trying to forget what he had seen and done. But he noted with unease the new cameras and checkpoints being installed around his home.\n\nFour days later, state security called and summoned him for questioning. The all-seeing surveillance apparatus had followed him home.\n\n“The Xinjiang model is being copied everywhere, in every city in China,” Liu said.\n\nIn 2024, Liu left China, ignoring an airport officer who warned that wherever he went, he would be watched.\n\n“This technology has no emotions,” Liu said. “But in the hands of a government that doesn’t respect the law, it becomes a tool for evil.”\n\nAutomated autocracy\n\nThe Yangs are still trapped by U.S. technology. IBM, Dell, HP, Cisco, and Seagate servers, switches and drives power police systems targeting them, maintenance contracts dating to this year show. Intel and Nvidia chips process data. Oracle and VMWare software run the database.\n\nBut the harder the Yangs push, the harder the system pushes back.\n\nIn February 2023, they went to the National Public Complaints Administration in Beijing with a letter. Two days later, police grabbed them from their hotel and drove them home.\n\nThe Yangs persisted, trying to plead their case to Beijing. In the following months, they were seized at bus and train stations, beaten at a hospital and abducted by ambulance.\n\nLast July, Yang’s mother tried again. She carried a letter for Chinese leader Xi Jinping:\n\n“They’re using violence and kidnapping to bar me from petitioning and seeking medical treatment ... We beg you, General Secretary, to save us.”\n\nOutside Beijing’s leadership compound, burly men in black tackled Yang’s mother to the ground. She was jailed for over a month, questioned, strip-searched, force-fed medication and deprived of food and water. In October, she and Yang’s sister disappeared.\n\nThe Yangs’ house is now the last left standing. The father lives alone.\n\nHis relatives have cut contact, unnerved by the flock of police that tail him. Thousands of pages of documents stashed in drawers, stuffed in bags, and piled in boxes in a bathtub chronicle every step of their 16-year quest for justice.\n\nIn April, Yang was sent criminal charges showing how much police had spent to stop the family’s “abnormal petitioning.”\n\nThe cost: About $37,000.\n\n__\n\nYael Grauer is an independent investigative tech reporter. AP journalists Garance Burke in San Francisco, Larry Fenn in New York and Byron Tau in Washington contributed to this report, along with Myf Ma, an independent investigative journalist, researcher and programmer in New York covering China.\n\n__\n\nContact AP’s global investigative team at Investigative@ap.org or https://www.ap.org/tips/",
      "source": "Yahoo Entertainment",
      "url": "https://www.yahoo.com/news/articles/us-tech-companies-enabled-surveillance-040441040.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel’s chief executive of products departs among other leadership changes",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/dee0bcafc675be2b",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel and Dell announce key leadership exits",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/12b96d116a22c7f3",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Bridge 2025 v15.1.1",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-bridge-2025-v15-1-1/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Lightroom Classic 2025 v14.5.1",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-lightroom-classic-2025-v14-5-1-3/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Core Ultra 3 205 Reportedly Delivers Up To 48% Higher Multi-Core Performance Vs Core i3 14100",
      "content": null,
      "source": "Wccftech",
      "url": "https://wccftech.com/intel-core-ultra-3-205-reportedly-delivers-up-to-48-higher-multi-core-performance-vs-core-i3-14100/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "High Potential Cast on What You Need to Know Heading Into Season 2",
      "content": null,
      "source": "Bleeding Cool News",
      "url": "https://bleedingcool.com/tv/high-potential-cast-on-what-you-need-to-know-heading-into-season-2/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Blue City Mayor Tells CNN Just How Far He’s Gone To Interfere With ICE",
      "content": "Democratic Mayor Daniel Biss of Evanston, Illinois, told CNN host Erin Burnett on Monday that his city turned off certain public safety tools in an effort to thwart United States Immigration and Customs Enforcement (ICE).\n\nPresident Donald Trump hinted at stepped-up federal enforcement efforts in Chicago in an Aug. 25 post on Truth Social, following it up with a meme based on a famous character from the “Apocalypse Now” posted Saturday, which included a reference to the quote “I love the smell of napalm in the morning” from the Francis Ford Coppola-directed film. Biss, a Democratic candidate for Congress, told Burnett that he’d ordered license-plate cameras to be turned off. (RELATED: Dems Are Losing Their Minds Over Trump’s ‘Smell Of Deportations In The Morning’ Post)\n\n“The reason that we communicated with our residents this morning is that I got information from a senior state official last night indicating that they had good intel, that they thought it was likely that ICE would be coming to Evanston today and in the coming days, and we just felt that we had a responsibility to let our residents know so they could work to protect themselves,” Biss claimed.\n\nWATCH:\n\n\n\n“We’ve been doing everything we can to protect our residents from before Donald Trump took office, passing strong sanctuary laws to make sure our police are not cooperating with federal civil immigration enforcement,” Biss continued. “Protecting our data, switching off our license plate cameras when we learned that that data was being shared. But we also need to make sure our residents know as much as possible so they can take the steps they need to protect themselves.”\n\nLicense-plate cameras help police with parking enforcement, monitoring traffic flow and to combat auto theft, according to SecurityCameraKing.com. Biss also announced his intention to emulate a stunt pulled by Democratic Mayor Karen Bass of Los Angeles.\n\n“I got trained in rapid response,” Biss told Burnett later in the interview. “So now when ICE comes to town, I get a text. I’m able to go immediately to the location, share rights that individuals have with them, and inform them of their rights. Videotape, bear witness, hold ICE officials accountable.”\n\nResistance to ICE operations to arrest illegal immigrants also included a Milwaukee judge who allegedly helped an illegal briefly evade ICE agents in April and Democratic Mayor Freddie O’Connell of Nashville, who released the names of ICE agents involved in a crackdown on illegal immigrants in the city in May. (RELATED: Jonathan Turley Explains Why Trump Will ‘Win Either Way’ In Chicago Crime Fight)\n\nIn New York City, ICE agents arrested Democratic mayoral candidate Brad Lander on June 18 after he allegedly interfered with an ICE operation in a Manhattan court. Democratic Rep. LaMonica McIver of New Jersey was charged with assaulting an ICE agent after a May incident at an ICE facility in Newark.\n\nIn Texas, there were two incidents where shots were fired at ICE or Border Patrol facilities since July 4, with ten people being charged with attempted murder in connection with the former incident. In another incident, one person fired at the ICE agents with a pistol when ICE raided two California marijuana farms in July after obtaining a warrant, with the FBI offering a $50,000 reward for information leading to the suspect’s identification, arrest and conviction.\n\nAll content created by the Daily Caller News Foundation, an independent and nonpartisan newswire service, is available without charge to any legitimate news publisher that can provide a large audience. All republished articles must include our logo, our reporter’s byline and their DCNF affiliation. For any questions about our guidelines or partnering with us, please contact licensing@dailycallernewsfoundation.org.",
      "source": "The Daily Caller",
      "url": "https://dailycaller.com/2025/09/09/blue-city-mayor-tells-cnn-just-how-far-hes-gone-to-interfere-with-ice/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Corporation $INTC Position Boosted by Advisors Asset Management Inc.",
      "content": "Advisors Asset Management Inc. increased its holdings in Intel Corporation (NASDAQ:INTC – Free Report) by 124.3% in the first quarter, according to its most recent 13F filing with the Securities and Exchange Commission (SEC). The institutional investor owned 50,247 shares of the chip maker’s stock after buying an additional 27,842 shares during the quarter. Advisors Asset Management Inc.’s holdings in Intel were worth $1,141,000 at the end of the most recent reporting period.\n\nA number of other institutional investors and hedge funds have also added to or reduced their stakes in the business. Vanguard Group Inc. grew its holdings in Intel by 2.2% in the 1st quarter. Vanguard Group Inc. now owns 377,390,437 shares of the chip maker’s stock worth $8,570,537,000 after buying an additional 8,291,233 shares in the last quarter. UBS AM a distinct business unit of UBS ASSET MANAGEMENT AMERICAS LLC grew its holdings in Intel by 8.2% in the 4th quarter. UBS AM a distinct business unit of UBS ASSET MANAGEMENT AMERICAS LLC now owns 63,263,339 shares of the chip maker’s stock worth $1,268,430,000 after buying an additional 4,793,927 shares in the last quarter. Northern Trust Corp grew its holdings in Intel by 0.3% in the 1st quarter. Northern Trust Corp now owns 45,969,843 shares of the chip maker’s stock worth $1,043,975,000 after buying an additional 158,288 shares in the last quarter. Invesco Ltd. grew its holdings in Intel by 1.3% in the 1st quarter. Invesco Ltd. now owns 43,651,076 shares of the chip maker’s stock worth $991,316,000 after buying an additional 562,246 shares in the last quarter. Finally, Amundi grew its holdings in Intel by 22.0% in the 1st quarter. Amundi now owns 37,878,097 shares of the chip maker’s stock worth $849,606,000 after buying an additional 6,829,690 shares in the last quarter. 64.53% of the stock is owned by institutional investors.\n\nGet Intel alerts:\n\nAnalysts Set New Price Targets\n\nA number of equities analysts recently issued reports on INTC shares. Rosenblatt Securities reissued a “sell” rating and issued a $14.00 price objective on shares of Intel in a report on Friday, July 25th. Benchmark reaffirmed a “hold” rating on shares of Intel in a research note on Friday, July 25th. Stifel Nicolaus increased their price target on Intel from $21.00 to $24.50 and gave the company a “hold” rating in a research note on Monday, July 21st. Deutsche Bank Aktiengesellschaft began coverage on Intel in a research note on Wednesday, May 21st. They set a “hold” rating and a $23.00 price target for the company. Finally, Citigroup reaffirmed a “hold” rating on shares of Intel in a research note on Tuesday, July 8th. One investment analyst has rated the stock with a Buy rating, twenty-two have assigned a Hold rating and five have assigned a Sell rating to the company’s stock. According to MarketBeat, the company presently has a consensus rating of “Reduce” and a consensus price target of $22.17.\n\nIntel Price Performance\n\nShares of NASDAQ:INTC opened at $24.48 on Tuesday. Intel Corporation has a one year low of $17.67 and a one year high of $27.55. The stock has a fifty day moving average of $22.75 and a 200-day moving average of $21.81. The company has a market capitalization of $107.15 billion, a PE ratio of -5.13 and a beta of 1.23. The company has a debt-to-equity ratio of 0.42, a quick ratio of 0.92 and a current ratio of 1.24.\n\nIntel (NASDAQ:INTC – Get Free Report) last announced its quarterly earnings data on Thursday, July 24th. The chip maker reported ($0.10) EPS for the quarter, missing analysts’ consensus estimates of $0.01 by ($0.11). Intel had a negative net margin of 38.64% and a negative return on equity of 3.78%. The company had revenue of $12.86 billion for the quarter, compared to analyst estimates of $11.88 billion. During the same quarter last year, the company posted $0.02 EPS. Intel’s revenue was up .5% on a year-over-year basis. Intel has set its Q3 2025 guidance at 0.000-0.000 EPS. As a group, equities analysts anticipate that Intel Corporation will post -0.11 EPS for the current fiscal year.\n\nIntel Company Profile\n\n(Free Report)\n\nIntel Corporation designs, develops, manufactures, markets, and sells computing and related products and services worldwide. It operates through Client Computing Group, Data Center and AI, Network and Edge, Mobileye, and Intel Foundry Services segments. The company's products portfolio comprises central processing units and chipsets, system-on-chips (SoCs), and multichip packages; mobile and desktop processors; hardware products comprising graphics processing units (GPUs), domain-specific accelerators, and field programmable gate arrays (FPGAs); and memory and storage, connectivity and networking, and other semiconductor products.\n\nFeatured Articles\n\nWant to see what other hedge funds are holding INTC? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for Intel Corporation (NASDAQ:INTC – Free Report).\n\nReceive News & Ratings for Intel Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Intel and related companies with MarketBeat.com's FREE daily email newsletter.",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/09/intel-corporation-intc-position-boosted-by-advisors-asset-management-inc/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel shuffles executive deckchairs, tosses 30-year veteran chief overboard",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/bc8de5fbfbdd9420",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel Says Former Co-CEO Johnston Holthaus to Depart",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/57028fb1747c2d28",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Adobe Illustrator 2025 v29.7.1",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/adobe-illustrator-2025-v29-7-1-3/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel’s top Oregon executive, most senior female leader, is leaving the company",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/444eea5fee24237f",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "What to know about the Trump administration's Intel investment",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/a9f519346b5f2b49",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "(PR) Other World Computing (OWC) Launches Thunderbolt 5 Dual 10GbE Network Dock",
      "content": "\"Our goal has always been to remove the friction that slows professionals down, or gets in the way of their doing their work,\" said Larry O'Connor, Founder and CEO, Other World Computing (OWC). \"With the Thunderbolt 5 Dual 10GbE Network Dock, we're giving creatives, IT teams, and power users a smarter, faster, and cleaner way to connect everything they need, without the mess of extra adapters or compromises in speed.\"\n\n\"We can run a live show with 11 cameras on an isolated NDI network, pull footage through the second 10-gig NIC connected to our NAS, plus hook up a second Thunderbolt display—all through a single Thunderbolt 5 cable while keeping the front 2.5GbE port available to run Dante,\" said Guy Cochran, a respected video production consultant with decades of hands-on experience, trusted by creators and major networks such as ESPN and Disney.\n\nMulti-Network Versatility: Dual, fully independent 10 Gb/s Ethernet ports and a front-facing 2.5 Gb/s Ethernet port let you connect up to three separate networks and/or high-speed network devices simultaneously\n\nExtreme Throughput: Bond the 10GbE ports with link aggregation and access your NAS at up to 20 Gb/s from your notebook computer.\n\nOne Simple Solution: Easily handle complex multi-network workflows, unlock high-bandwidth network storage connectivity, and expand your connectivity possibilities with this dock and included Thunderbolt 5 cable.\n\nTransformative: Experience workstation/server-class networking from your notebook and enable workflows that were previously cumbersome or impossible.\n\nConvenient Connectivity: Three Thunderbolt 5 and four USB 10 Gb/s ports give you the flexibility to use both cutting-edge devices and legacy gear.\n\nMore Devices: Create three separate daisy chains of devices - even bus-powered - and remove devices from one chain without affecting the other chains.\n\nGreater Visual Clarity: Enhance your efficiency with sharper details by connecting up to three 8K displays.\n\nSilently Cool: Fanless aluminium enclosure for quiet and cool operation.\n\n\"Thunderbolt 5 opens up entirely new possibilities for creative and production workflows, and OWC's new dock really showcases that. By combining downstream Thunderbolt 5 ports with additional USB connectivity, it gives pros the flexibility to connect everything they need without compromise,\" said Ben Hacker, General Manager, Client Connectivity Division, Intel. \"And for teams working with high-performance NAS solutions like the OWC Jellyfish, this is a game-changer—unlocking the bandwidth and responsiveness they've been waiting for in video and collaborative workflows.\"\n\nOther World Computing (OWC), a trusted leader in high-performance storage, memory, connectivity, software, and accessories that empower creative and business professionals to maximize performance, enhance reliability, and streamline workflows, today announced the launch of its new OWC Thunderbolt 5 Dual 10GbE Network Dock. This powerful dock enables users to connect to multiple high-speed networks, access blazing-fast network-attached storage (NAS), and expand device setups via a single Thunderbolt cable. It is built for pros who need serious speed and flexibility.Creative and IT pros know the struggle—juggling adapters, dealing with too few ports, and waiting on slow network speeds just to get through the day. The OWC Thunderbolt 5 Dual 10GbE Network Dock changes that. With one powerful Thunderbolt connection, you get two 10GbE ports, a 2.5GbE port, three Thunderbolt 5 ports, and four USB ports—all designed to simplify your setup and supercharge your workflow. It's built to handle the demands of media, IT, and production work, whether you are accessing NAS storage at blazing 20 Gb/s speeds or managing multiple networks. Think of it as desktop-class power and flexibility, now available anywhere your Mac or PC takes you.The OWC Thunderbolt 5 Dual 10GbE Network Dock enables:The OWC Thunderbolt 5 Dual 10GbE Network Dock is immediately available and priced at $499.00.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/340813/other-world-computing-owc-launches-thunderbolt-5-dual-10gbe-network-dock",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "neural-compressor-pt 3.5",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/neural-compressor-pt/3.5/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "neural-compressor-tf 3.5",
      "content": "JavaScript is disabled in your browser. Please enable JavaScript to proceed.\n\nA required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.",
      "source": "Pypi.org",
      "url": "https://pypi.org/project/neural-compressor-tf/3.5/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "UK internet user helps stop teenager launching deadly attack on Ukrainian school",
      "content": "A UK internet user helped police stop a teenager from unleashing a deadly attack on his school in Ukraine, the Metropolitan Police has said.\n\nThe anonymous referral was made to the Met's Counter Terrorism Internet Referral Unit on 4 September, according to the force.\n\nIt warned of an \"imminent attack being planned by an individual in Ukraine\" and was immediately passed to Europol to help alert local police.\n\nA day later, a 15-year-old boy was arrested at a school in Zakarpattia, western Ukraine, the country's ministry for internal affairs confirmed in a post on X.\n\nBe the first to get Breaking News Install the Sky News app for free\n\nThe boy was a student at the school and was arrested with a knife in his backpack while he was livestreaming the incident online, the post revealed.\n\nIt was accompanied by an image of the knife, phone, and rucksack seized by police at the scene.\n\nGet Sky News on WhatsApp Follow our channel and never miss an update Tap here to follow\n\nRead more from Sky News\n\nOnline conspiracies over deaths of 16 election candidates\n\nIsrael launches strikes on Hamas in Qatar\n\nSix killed in rush hour bus shooting\n\nCommander Dominic Murphy, of the Met's Counter Terrorism Command, described the intel and subsequent response as a \"truly remarkable piece of work\".\n\n\"The swift actions by our officers alerting Ukrainian counterparts have helped to avert what could have been a potentially devastating attack at a school in Ukraine,\" he said.\n\n\"It's all the more remarkable when you consider the incredible difficulties those in Ukraine are facing while fighting a war, but thanks to our collective efforts, lives have almost certainly been saved.\"\n\nHe urged people in the UK to report anything suspicious they see online to the Met's internet unit so they can work with international partners to thwart other potential incidents.",
      "source": "Sky.com",
      "url": "https://news.sky.com/story/uk-internet-user-helps-stop-teenager-launching-deadly-attack-on-ukrainian-school-13427703",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "PDF Expert 3.10.19 fix",
      "content": null,
      "source": "Rlsbb.cc",
      "url": "https://post.rlsbb.cc/pdf-expert-3-10-19-fix/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Embedded Systems Market Report 2025-2029 and 2034 | Competitive Analysis of Key Players - Samsung, Sony Semiconductor Solutions, Siemens, Intel, Qualcomm Technologies",
      "content": "Dublin, Sept. 09, 2025 (GLOBE NEWSWIRE) -- The \"Embedded Systems Market Report 2025\" report has been added to ResearchAndMarkets.com's offering.\n\n\n\nThis Embedded Systems market report provides a comprehensive analysis of the market's characteristics, size, and growth, including segmentation, regional and country-level breakdowns, competitive landscape, market shares, trends, and strategies. It also tracks historical and forecasted market growth across various geographies.\n\n\n\n\n\n\n\nThe embedded systems market size has grown strongly in recent years. It will grow from $110.89 billion in 2024 to $121.55 billion in 2025 at a compound annual growth rate (CAGR) of 9.6%. The growth in the historic period can be attributed to establishment of standards and certifications ensured the reliability and safety of embedded systems, increasing focus on cybersecurity led to the development of secure embedded systems to protect against vulnerabilities, expansion of global manufacturing capabilities provided cost-effective production of embedded systems, growing consumer demand and energy efficiency.\n\nThe embedded systems market size is expected to see strong growth in the next few years. It will grow to $173.8 billion in 2029 at a compound annual growth rate (CAGR) of 9.4%. The growth in the forecast period can be attributed to demand for systems capable of real-time data processing, decreasing costs of embedded system components, growth in demand for tailored embedded solutions, expansion of embedded systems in developing countries and implementation in solar, wind, and other renewable energy solutions. Major trends in the forecast period include advanced embedded systems for military applications, increasing integration with cloud platforms, growth of Industry 4.0, expansion of telematics services and use of blockchain technology.\n\n\n\nThe growing emphasis on energy efficiency and sustainability is anticipated to drive the growth of the embedded systems market in the future. Energy efficiency and sustainability involve using less energy to perform the same tasks, thereby reducing energy waste, and employing methods and technologies that fulfill current needs without compromising the ability of future generations to meet their own needs. These concepts are increasingly important due to rising concerns about environmental degradation, resource depletion, and climate change\n\n. Embedded systems support energy efficiency and sustainability by optimizing energy usage, integrating renewable energy sources, and enabling intelligent grid technologies. For example, in May 2023, according to the International Energy Agency (IEA), global energy investment increased to $1.74 trillion in 2023 from $1.61 trillion in 2022. In 2023, about USD 2.8 trillion will be invested in energy, with over USD 1.7 trillion allocated to clean energy initiatives, including renewable power, nuclear, grids, storage, low-emission fuels, efficiency enhancements, end-use renewables, and electrification. Therefore, the rising focus on energy efficiency and sustainability is driving the growth of the embedded systems market.\n\n\n\nMajor companies in the embedded systems market are developing security solutions to protect embedded devices and systems from cyber threats. These security solutions implement measures such as encryption, authentication, and secure boot mechanisms to safeguard embedded devices and systems.\n\n\n\nNorth America was the largest region in the embedded systems market in 2024. Asia-Pacific is expected to be the fastest-growing region in the forecast period. The regions covered in the embedded systems market report are Asia-Pacific, Western Europe, Eastern Europe, North America, South America, Middle East, Africa. The countries covered in the embedded systems market report are Australia, Brazil, China, France, Germany, India, Indonesia, Japan, Russia, South Korea, UK, USA, Canada, Italy, Spain.\n\n\n\nKey Attributes:\n\n\n\n\n\nReport Attribute Details No. of Pages 200 Forecast Period 2025 - 2029 Estimated Market Value (USD) in 2025 $121.55 Billion Forecasted Market Value (USD) by 2029 $173.8 Billion Compound Annual Growth Rate 9.4% Regions Covered Global\n\n\n\n\n\nKey Topics Covered:\n\n\n\n1. Executive Summary\n\n\n\n2. Embedded Systems Market Characteristics\n\n\n\n3. Embedded Systems Market Trends and Strategies\n\n\n\n4. Embedded Systems Market - Macro Economic Scenario Including the Impact of Interest Rates, Inflation, Geopolitics, and the Recovery from COVID-19 on the Market\n\n\n\n5. Global Embedded Systems Growth Analysis and Strategic Analysis Framework\n\n5.1. Global Embedded Systems PESTEL Analysis (Political, Social, Technological, Environmental and Legal Factors, Drivers and Restraints)\n\n5.2. Analysis of End Use Industries\n\n5.3. Global Embedded Systems Market Growth Rate Analysis\n\n5.4. Global Embedded Systems Historic Market Size and Growth, 2019-2024, Value ($ Billion)\n\n5.5. Global Embedded Systems Forecast Market Size and Growth, 2024-2029, 2034F, Value ($ Billion)\n\n5.6. Global Embedded Systems Total Addressable Market (TAM)\n\n\n\n6. Embedded Systems Market Segmentation\n\n6.1. Global Embedded Systems Market, Segmentation by Component, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nHardware\n\nSoftware\n\nServices\n\n6.2. Global Embedded Systems Market, Segmentation by Function, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nReal-Time\n\nStandalone\n\nMobile\n\nNetworked\n\n6.3. Global Embedded Systems Market, Segmentation by System Size, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nSmall Size\n\nMedium Size\n\nLarge Size\n\n6.4. Global Embedded Systems Market, Segmentation by End-Use Industry, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nAutomotive\n\nConsumer Electronics\n\nAerospace and Defense\n\nHealthcare\n\nTelecommunication\n\nIndustrial\n\nOther End-Use Industries\n\n6.5. Global Embedded Systems Market, Sub-Segmentation of Hardware, by Type, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nMicrocontrollers (MCUs)\n\nMicroprocessors (MPUs)\n\nDigital Signal Processors (DSPs)\n\nApplication-Specific Integrated Circuits (ASICs)\n\nField-Programmable Gate Arrays (FPGAs)\n\nSensors\n\nPower Management ICs\n\n6.6. Global Embedded Systems Market, Sub-Segmentation of Software, by Type, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nReal-Time Operating Systems (RTOS)\n\nEmbedded Software Development Tools\n\nMiddleware\n\nFirmware\n\n6.7. Global Embedded Systems Market, Sub-Segmentation of Services, by Type, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nDesign and Development Services\n\nConsulting Services\n\nMaintenance and Support Services\n\n7. Embedded Systems Market Regional and Country Analysis\n\n7.1. Global Embedded Systems Market, Split by Region, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\n7.2. Global Embedded Systems Market, Split by Country, Historic and Forecast, 2019-2024, 2024-2029F, 2034F, $ Billion\n\nEmbedded Systems Market Competitive Landscape and Company Profiles\n\nEmbedded Systems Market Competitive Landscape\n\nEmbedded Systems Market Company Profiles\n\nSamsung Electronics Overview, Products and Services, Strategy and Financial Analysis\n\nSony Semiconductor Solutions Corporation Overview, Products and Services, Strategy and Financial Analysis\n\nSiemens AG Overview, Products and Services, Strategy and Financial Analysis\n\nIntel Corporation Overview, Products and Services, Strategy and Financial Analysis\n\nQualcomm Technologies Inc. Overview, Products and Services, Strategy and Financial Analysis\n\nEmbedded Systems Market Other Major and Innovative Companies\n\nHoneywell International Inc.\n\nBroadcom Inc.\n\nNvidia Corporation\n\nAdvanced Micro Devices Inc.\n\nTexas Instruments\n\nSTMicroelectronics\n\nInfineon Technologies AG\n\nNXP Semiconductors\n\nAnalog Devices Inc.\n\nRenesas Electronics Corporation\n\nON Semiconductor\n\nMicrochip Technology Inc.\n\nMarvell\n\nVishay Intertechnology Inc.\n\nArm Limited\n\nFor more information about this report visit https://www.researchandmarkets.com/r/xho2gi\n\nAbout ResearchAndMarkets.com\n\nResearchAndMarkets.com is the world's leading source for international market research reports and market data. We provide you with the latest data on international and regional markets, key industries, the top companies, new products and the latest trends.\n\nAttachment",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/09/3146621/28124/en/Embedded-Systems-Market-Report-2025-2029-and-2034-Competitive-Analysis-of-Key-Players-Samsung-Sony-Semiconductor-Solutions-Siemens-Intel-Qualcomm-Technologies.html",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Belarusian spy network uncovered by Eurojust operation, Moldovan ex-intel chief arrested",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/654d3912b9e089d6",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "ROOKE: Democrats Just Gave Their Dumbest Members Ample Opportunity To Embarrass Their Party",
      "content": "House Republicans formed a new subcommittee to investigate January 6, and Democrats took the bait, sending their loudest mouthpieces to represent them.\n\nHouse Speaker Mike Johnson initially announced plans for the new Republican-led Select Subcommittee to Continue Investigation of the Events Surrounding January 6 shortly after the start of the 119th Congress. Still, the formal vote and authorization occurred Sept. 3.\n\nThe subcommittee operates under the House Judiciary Committee, chaired by Republican Ohio Rep. Jim Jordan, with Republican Georgia Rep. Barry Loudermilk leading the Jan. 6-specific efforts. The panel has subpoena power and is tasked with a comprehensive review, with a final report due by Dec. 31, 2026. Republicans hope to build on their earlier investigations, including an interim report released in December 2024 by a previous subcommittee under the House Administration Committee.\n\nRepublicans argue that the original bipartisan select committee formed in 2021 was politically biased against President Donald Trump, selectively presenting evidence and ignoring alternative perspectives. Democrats, including Minority Leader Hakeem Jeffries, have criticized it as an attempt to “whitewash” the attack.\n\nHowever, if Jeffries really felt like this committee was going to change the narrative they crafted surrounding Jan. 6, why on earth would he send Texas Rep. Jasmine Crockett and California Rep. Eric Swalwell to represent the Democratic Party?\n\n🚨BREAKING: Hakeem Jeffries has tapped Eric Swalwell to be the top Democrat on the new GOP-led J6 subcommittee. pic.twitter.com/RWR3Pn90F1 — Daily Caller (@DailyCaller) September 8, 2025\n\nOne can only conclude their inclusion is to turn the subcommittee into a clown show for extra attention. (Sign up for Mary Rooke’s weekly newsletter here!)\n\nSwalwell isn’t known for his decision-making abilities, nor his strong camera presence. He was removed from the House Intelligence Committee in 2023 due to allegations that he had a sexual relationship with a suspected Chinese spy, Christine Fang (Fang Fang), from 2014 to 2015.\n\nDemocrat Rep. Jasmine Crockett thinks Eric Swalwell — who was removed from the House Intel Committee over his relationship with a Chinese spy — is someone people should “really feel inspired by” 🤡 pic.twitter.com/bsl2vlKoVx — RNC Research (@RNCResearch) April 7, 2024\n\nSince Swalwell was seen as enough of a national security risk to make him unfit for sensitive intelligence, it begs the question of why his leadership thinks he should hold any committee roles, much less take part in investigations like that of January 6. This move opens the door to dismissing anything Swalwell says as unqualified or a distraction, despite the House Ethics Committee clearing him of wrongdoing regarding the relationship with Fang Fang.\n\nHis biased, false, or misleading attacks on Republicans and Trump are well-documented, including being a key figure in promoting the Democrat-led Russian collusion hoax as a member of the House Permanent Select Committee on Intelligence (HPSCI) and a ranking member of its CIA Subcommittee. Swalwell actively participated in the committee’s investigation into alleged Russian interference in the 2016 election and potential ties to the Trump campaign. Swalwell’s statements were often cited in post-Mueller analyses as examples of unsubstantiated claims that fueled the false narrative, which led to Trump’s first impeachment trial.\n\n(And let’s not forget that while promoting the Russian collusion hoax, Swalwell appeared to fart during a live TV interview while discussing Trump’s impeachment on MSNBC’s “Hardball with Chris Matthews” in 2019.)\n\n🚨 WATCH: Hakeem Jeffries gets TRIGGERED by question about Rep. Swalwell comparing J6 to 9/11 and Pearl Harbor@AndiNapier https://t.co/GJGyvBzHQ4 https://t.co/6zmFTDAmTP pic.twitter.com/jnzJyQvjYe — Daily Caller (@DailyCaller) September 8, 2025\n\nSimilarly, Crockett isn’t known for being the Democrats’ best and brightest. While she has a knack for driving headlines, it’s not always in the best interest of her party for her to be front-facing.\n\nI’m honored to serve on the new January 6th subcommittee alongside @RepSwalwell and @RepMoskowitz. Together, we will defend the Constitution, protect the truth, and make sure the American people never forget who was responsible for the defilement of the Capitol. pic.twitter.com/gH9JFUYCGy — Congresswoman Jasmine Crockett (@RepJasmine) September 8, 2025\n\nCrockett often exhibits characteristics of being overly partisan, unserious, and lacking intellectual depth, with fiery rhetoric that is easily perceived as imbecilic. She somehow managed to turn the devastating Texas floods into a story about herself. Crockett has also wildly claimed that Republicans would willingly “enslave her.”\n\n🚨NEW: Jasmine Crockett *laughs and claps* as she jokes Trump’s “HAND LOOK LIKE IT’S ABOUT TO FALL OFF”🚨@DailyCaller pic.twitter.com/h06XWEGVRB — Jason Cohen 🇺🇸 (@JasonJournoDC) September 5, 2025\n\nAnd, in July, Crockett tried to shut down an Atlantic magazine profile on her after a reporter reached out to other House Democrats. The profile portrayed Crockett as a power-hungry narcissist who acts foolishly to appeal to certain voters, as is evident in her constant change in speech patterns depending on the audience. But, more importantly, it exposed that her colleagues don’t even seem to like her. The reporter reached out to 20 other House Democrats, and all of them either ignored the request for comment or declined to comment on the record.\n\nSome interesting details from The Atlantic’s profile of Rep. Jasmine Crockett: 1. Her phone’s lock screen is a photo of herself\n\n2. She thought she deserved to be the top Dem on Oversight because she has the largest social media following\n\n3. She tried to shut down the profile… pic.twitter.com/CvRlFtRNkd — Amber Duke (@ambermarieduke) July 28, 2025\n\nJanuary 6 has become a special event to Crockett, who often uses it as a cudgel to beat Trump and Republicans. On the event’s anniversary, shortly before Trump’s inauguration, Crockett claimed that Trump “premeditated and planned” the riot months in advance, despite there being no evidence to back up her claims. (ROOKE: Democrats Would Rather Die Than Eat The Low-Hanging Fruit)\n\nIncluding Swalwell and Crockett seems to be a self-sabotaging move by Democrats. While they successfully chose their top Trump resisters willing to go on any media outlet that will have them to denounce Trump and Republicans, their inclusion makes the Democratic effort appear like a partisan farce rather than a credible counter to the Republican investigation.\n\nFollow Mary Rooke on X: @MaryRooke\n\nSign up for Mary Rooke’s weekly newsletter here!",
      "source": "The Daily Caller",
      "url": "https://dailycaller.com/2025/09/09/rooke-democrats-trump-jasmine-crockett-eric-swalwell-january-6-committee/",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Intel, Now Backed By Trump Administration, Announces Major Leadership Reshuffle: 30-Year Products Veteran To Step Down",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/a46a58324eab2719",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "The GAIN AI Act Looks More Like Protectionism Than National Security",
      "content": "France plunged into political crisis as Prime Minister Sébastien Lecornu resigned just hours after unveiling a new cabinet, triggering sharp declines in French stocks and bonds amid uncertainty.\n\nMarket Summary Global markets show mixed reactions: Japan's Nikkei surges nearly 5% on new party leader with stimulus plans, Eurozone investor confidence improves slightly but French political shocks drag European stocks down. US futures sit mostly flat amid ongoing government shutdown worries. Oil prices gain on modest OPEC+ production hike; Bitcoin hits fresh highs above $125,000 fueling crypto optimism.\n\nJapan Stocks Soar Nearly 5% After Takaichi’s Win… Yen Sinks Nikkei Hits Record Above 47,000 After Takaichi Election Japan's political landscape shifts dramatically with Sanae Takaichi's election as the first female leader of the ruling Liberal Democratic Party, sparking market rallies and debates about economic stimulus and fiscal policies.\n\nFigure of the Day 125,000 - Bitcoin’s new all-time high price in U.S. dollars\n\nFrance PM Lecornu Resigns Hours After New Cabinet Reveal French political turmoil escalates as Prime Minister Sébastien Lecornu resigns shortly after cabinet appointment, triggering market declines and raising concerns about government stability.\n\nShutdown Grinds On… Lawmakers at Deadlock, No Deal Near White House: Layoffs Pending If Shutdown Talks 'Go Nowhere' US government shutdown persists with mounting political deadlock; stock futures remain mixed while federal layoffs loom and both parties trade blame amid stalled negotiations.\n\nBullish Eli Lilly Commits Over $1 Billion to Expand Manufacturing in India Pharmaceutical giant Eli Lilly announced a substantial investment exceeding $1 billion to boost its manufacturing capacity in India, signaling a strategic growth move in global healthcare production. More on reuters.com\n\nBitcoin Tops $125,000 Mark as Crypto Rally Intensifies Crypto Boom: Bitcoin Hits $125K Amid Market Euphoria Bitcoin surges to new record highs above $125,000 amid investor appetite for safe-haven assets and growing crypto market optimism despite global uncertainties.\n\nTrump Sends California Guard Troops to Oregon Despite Court Ban California Governor Vows Suit Over Trump’s Troop Deployment US National Guard deployment controversy heats up as President Trump sends federalized California troops to Oregon, facing judicial blocks and state lawsuits amid escalating tensions.\n\nBearish Aston Martin Profit Warning Sends Shares Tumbling 10% British luxury carmaker Aston Martin issued a fresh profit warning citing tariff pressures and a challenging outlook, causing its shares to fall sharply and raising doubts about near-term profitability. More on cnbc.com\n\nJaguar Land Rover to Restart Production After Cyberattack UK Businesses Face Rising Tide of Cyberattacks, Survey Finds Cybersecurity risks surge with high-profile attacks forcing Jaguar Land Rover to halt production and UK businesses facing increasing cyber threats, raising alarm over national security.\n\nOPEC+ Approves Small Output Hike as Market Watches Closely Oil Prices Surge Over 1.5% Following OPEC+ Supply Decision OPEC+ agrees to a modest oil output increase in November, shaking energy markets amid concerns of oversupply and geopolitical developments influencing crude prices.\n\nRegulatory Impact Iran Plans Currency redenomination by dropping four zeros amid inflation; UK plans government overhaul to speed homebuying by four weeks; EU to centralize crypto and exchange regulation at EU level.\n\nOpenAI, Jony Ive Hit Roadblocks... AI Device Delayed OpenAI-Jony Ive AI Gadget Faces Serious Technical Hiccups OpenAI and designer Jony Ive face technical difficulties delaying the launch of a new AI device, highlighting challenges even top innovators encounter in AI hardware development.\n\nQuote The burgeoning AI boom could double electricity rates—are we prepared for the cost?\"\n\n— Chamath Palihapitiya, Venture Capitalist\n\nAston Martin Shares Dive 10% After Profit Warning on Tariffs Aston Martin Profit Forecast Slashed as Tariff Troubles Mount Aston Martin's shares plunge following a fresh profit warning amid US tariff pressures and supply chain challenges, signaling tough times ahead for the luxury automaker.\n\nSurvey: 77% of Bitcoin Holders Haven’t Tried BTCFi Yet BTCFi’s user adoption lags as 77% of Bitcoin holders remain inactive, casting doubts on the decentralized finance platform’s growth prospects.\n\nMacron Loyalist Lescure Named Finance Minister in Bid to Stabilize France’s government budget moves forward with Macron loyalist Roland Lescure appointed finance minister, aiming for stability amid political upheaval.\n\nHong Kong Issues Global Green Building Certificates Hong Kong solidifies its position as a green finance hub with new building certifications internationally, backing sustainable development in global real estate markets.\n\nNvidia, Broadcom Lead AI Cash Flow Surge Major AI market players and stocks such as Nvidia and Broadcom continue to generate massive cash flow, reinforcing AI’s role as an economic powerhouse expanding rapidly.\n\nLong-Dated U.S. Treasury Yields Climb on Market Uncertainty U.S. Treasury yields rise on long-dated bonds amid economic uncertainty and shifting investor risk appetite.\n\nEuropean Shares Dip on French Political Turmoil European Stocks Slip With Eyes on French Upheaval European stocks slide as renewed political tensions in France and broader uncertainties weigh on investor sentiment.\n\nCitigroup Bolsters Nordic Investment Banking Team Citigroup strengthens Nordic investment banking presence with key hires, signaling confidence amid shifting regional market dynamics.\n\nSocial Security Sends Up To $5,108 Payments This Week Social Security payments due this week impact about 70 million Americans, underscoring the program’s critical role for retirees and disabled individuals.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b46e3827ffda946c",
      "timestamp": "2025-09-09"
    },
    {
      "headline": "Windows 11 Pro, Intel i7, 2TB SSD, 64GB RAM: HP Slashes $2600 From Its 5/5 Rated Laptop",
      "content": "September is the best month to score amazing laptop deals, thanks to the back-to-school season. Unlike Prime Day in July, which barely had any laptop discounts, Amazon is really stepping up this time: They’re offering a huge $2,600 off this HP business laptop (Intel 13th Gen i7-1355U, Intel Iris Xe Graphics, FHD Touch Screen, 64 GB DDR4, 2 TB SSD) that’s getting perfect 5-star reviews. It’s now available for $1,099 down from $3,699. Plus, you also get some handy extras included like a wireless mouse, a USB-C hub, and a 128GB flash drive.\n\nSee at Amazon\n\nSupercharged HP Laptop\n\nThis HP laptop comes with the latest Intel 13th Gen i7-1355U processor (reaching up to 5.0GHz) and with 10 cores and 12 threads. That simply means it can keep pace with everything you do. It’s paired with Intel Iris Xe Graphics so the visuals are sharp and silky.\n\nWith 64GB of DDR4 RAM and a spacious 2TB SSD, you’ll never be held back by this laptop no matter how many programs you have running or how much data you’re storing.\n\nWhat’s more, the laptop is only 3.5 pounds and 0.73 inches thick so it won’t smother your bag or take up too much space. The 15.6-inch touchscreen screen is also very comfortable and bright with full HD resolution (1920 by 1080 pixels) and 300 nits of brightness: everything will stand out and look alive.\n\nWhen it comes to staying in touch, this laptop has it all covered: It has Wi-Fi 6, which keeps the internet fast and consistent, and Bluetooth 5.3 for rapid pairing with your wireless devices. The camera is excellent for work meetings or online lessons, thanks to HP’s True Vision HD Camera that features a Privacy Guard for keeping things safe. The audio system is optimized for crisp and well-balanced sound so calls and video are clear without the use of headphones.\n\nOne of the standout features is the new Copilot key that launches Microsoft’s AI assistant. You can get help summarizing reports, pulling out insights or automating tedious tasks – all at the touch of a button. Based on Windows 11 Pro, this laptop comes with enhanced security features and tools that business users will appreciate.\n\nDo not delay—September’s the time when it is worth grabbing it before it goes up in price again.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/windows-11-pro-intel-i7-2tb-ssd-64gb-ram-hp-slashes-2600-from-its-5-5-rated-laptop-2000624604",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "HP’s 2025 Laptop Bundle Crashes to Nearly 80% Off, Likely Triggered by Apple’s Latest Launch",
      "content": "Fall is here which means school is back in sessions. If you’re still in need of a laptop for the new semester, first of all, what are you doing? Classes started weeks ago. Thankfully, you’re not out of luck just yet. Multiple retailers still have their back-to-school deals live and many opportunities to save on a new computer can still be found. Take this HP everyday laptop for example. This 2025 model is designed for students and businesses and it comes bundled with a bunch of goodies including a year of Microsoft Office 365. Amazon normally has it listed for $1,500, but for a limited time, the price is down 76% which brings it to just $360.\n\nThis 2025 HP 14 laptop is working with an Intel N150 processor capable of up to 3.4Hz and uses an integrated Intel UHD graphics card. It comes with 16GB of RAM and 128GB of internal storage. It comes pre-installed with Windows 11 Pro and Microsoft Copilot.\n\nSee at Amazon\n\nThe HP 14 is super light, weighing in at only 3.24 lbs. It only 0.71 inches thin. These together make the laptop highly portable as they should have no issue slipping into most backpacks. Great for schlepping back and forth between classes.\n\nBattery life is solid. You’ll get up to 11 hours of use on a single charge. When it dies, it only takes 45 minutes of charging to bring it back over 50%. You can comfortably bring it to your classes without worrying about packing the charger every day.\n\nFree Gifts Included\n\nAlrighty, let’s get to the freebies. With this HP laptop, you’ll get a handful of accessories that will help you on campus. You get a wireless mouse, some dust plugs to keep your ports dust free, a pack of webcam covers to maintain your privacy, and a 256GB microSD card to expand your storage even further.\n\nMost notably, the bundle includes a one year subscription to Microsoft 365. With this, you’ll gain access Microsoft’s full suite of apps such as Word, PowerPoint, Excel, and more — all things you’ll likely be regularly using for your classwork depending on your major.\n\nYou also will have OneDrive storage. This is great for being able to access all your files from a number of devices. Forgot to submit a homework assignment, but now you’ve already left the dorm? Just pull it up on your phone and send it to your professor from there. Easy peasy.\n\nFor a limited time, you can score this HP 14 laptop for students at the discounted price of just $360.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/hps-2025-laptop-bundle-crashes-to-nearly-80-off-likely-triggered-by-apples-latest-launch-2000624470",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Intel promises 'leadership across the board on desktop' when its next-gen Nova Lake CPU launches in late 2026",
      "content": null,
      "source": "Yahoo Entertainment",
      "url": "https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_ba3b95fc-670d-4cb4-a6fc-5ad2e715a1e5",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "iPhone 17 Pro Hands-On: The Most Un-Jony Ive iPhones Apple Has Ever Made",
      "content": "I felt a sense of déjà vu as I picked up the iPhone 17 Pro and 17 Pro Max—in Cosmic Orange, of course—at the “Awe Dropping” Apple Event and tried to pin down what about these new Apple smartphones felt so familiar. Then it hit me as I left the Steve Jobs Theater in a tired daze last night: the iPhone 17 Pros remind me of the MacBook Pros with M1 Pro and M1 Max chips.\n\nLike those first “pro” MacBooks, the iPhone 17 Pros are actually built for pros. It’s not just “pro” for marketing. The iPhone 17 Pros are slightly thicker and heavier, have the longest-lasting batteries of any iPhones ever, the best cameras, and are a whole lot more powerful than the iPhone 16 Pros. You feel all the pro-ness as soon as the brick slabs are in your hands. Everything, including the large camera bump or plateau, screams “professional,” just like those 2021 MacBook Pros. And they should because Apple finally prioritized function over form, just like those MacBook Pros, which brought back the SD card slot and MagSafe charging charging. Pro users want an uncompromised gadget—or at least the closest to it—and Apple delivers it this year.\n\nSee iPhone 17 Series at Apple\n\nSee iPhone 17 Series at Best Buy\n\nUnlike the iPhone Air that I couldn’t help but ogle with my jaw on the floor, the iPhone 17 Pros elicited less awe from me. In every way, they are beefed-up versions of the iPhone Pros that came before them. The aluminum unibody design has a Ceramic Shield cutout on the backside for wireless charging, and the camera plateau stretches across the whole top third. It’s not the most beautiful iPhone design (that award still goes to the iPhone 4 or iPhone X, in my opinion), but it’s functional. I even noticed that the antenna lines that cut into the side of the frames now bleed around the camera plateau. It’s very similar to the antenna lines that wrap around the display on the Apple Watch Ultras. Again, functional design first—this supposedly improves cellular and wireless connectivity, according to Apple.\n\nI have touched the Cosmic Orange iPhone 17 Pro. Here’s your first look #AppleEvent pic.twitter.com/HUiB8dxC8l — Ray Wong (@raywongy) September 9, 2025\n\nEven with a heftier design, the iPhone 17 Pros don’t feel bulky. In fact, the iPhone 17 Pro Max—the Pro Max model has always been too big and heavy for me—felt lighter and thinner than it actually is. For the first time ever, I felt I could use the iPhone 17 Pro Max daily and my hands wouldn’t hurt from gripping it like an old Game Boy. The curved metal frame definitely helps to make the iPhone 17 Pros feel thinner than they really are. Its size still isn’t great if you care about pocketability, though.\n\nJust like I said in my iPhone Air hands-on, I’ll have to test the iPhone 17 Pros to see how well the performance and battery life are, and how good the cameras are. That being said, the thicker designs also meant Apple was able to improve the thermals for sustained performance when the A19 Pro chip is pushed hard for 3D mobile gaming and GPU-intensive tasks like capturing RAW photos and videos (and editing them). If that’s not prioritizing function first over form, I don’t know what is. Who remembers the dark days when the thermals on Intel-equipped MacBook Pros were so bad? Apple, post-Jony Ive, seems to give a sh*t about this now, and I’m all for it.\n\nThe Center Stage camera is easily my new favorite camera feature. The ability to hold the iPhone 17 Pros vertically and take horizontal selfies (works for video, too) is a game-changer if you ask me. No more contorting my hand into a claw to hold my iPhone sideways to shoot a selfie or vlog. I also really liked the “Dual Capture” feature, which lets you record video from both the rear and front cameras. The front camera appears as a picture-in-picture box that you can move to any corner of the screen. It’s going to be great for reaction videos.\n\nI also did a table wobble test. Here’s how that went:\n\niPhone 17 Pro table wobble test! Does it pass? Let’s find out! #AppleEvent pic.twitter.com/jhUv1zxR3K — Ray Wong (@raywongy) September 9, 2025\n\niPhone 17 hands-on\n\nThe iPhone 17 was the least exciting model for me, and I spent the least amount of time playing with it. It’s a straightforward update with an A19 chip, a larger 6.3-inch 120Hz display, a new dual-camera system with twin 48-megapixel main and ultrawide lenses, and some new colors. The Sage green colorway is my favorite of the new bunch, but they also lack the vibrancy of the colors from the iPhone 16 series.\n\nThere’s really not much to say about the iPhone 17… it feels like an iPhone 16 Pro, with the same size screen, but with an aluminum frame. It’s lightweight, but not the thinnest or thinnest in the iPhone lineup. It’s the everyperson’s iPhone, and I don’t foresee that changing.\n\nThe best part is probably that the iPhone 17 still starts at $799, now with 256GB of storage.\n\nSee iPhone 17 Series at Apple\n\nSee iPhone 17 Series at Best Buy",
      "source": "Gizmodo.com",
      "url": "https://gizmodo.com/iphone-17-pro-hands-on-the-most-un-jony-ive-iphones-apple-has-ever-made-2000655964",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Despite cutting the gags, Borderlands 4's PC specs say it still needs 100GB of SSD space",
      "content": "Two days before launch, Borderlands 4 has its PC system requirements. They’re generally on the higher side without teetering over into full-on tech demo lunacy – the RTX 2070 is a minimum-spec graphics card, for instance – though anyone with a smaller SSD will need to make room for the looty FPS sequel’s bumper-size 100GB storage requirement.\n\nI have mixed feelings about this. On the one hand, gargantuan install sizes are kind of obnoxious (even the infamously bloated Call of Duty agrees), and are partly caused by merely visual, high-resolution textures that we increasingly need madly expensive GPUs to even enable. Or at least, to enable without simultaneously committing framerateicide.\n\nOn the other hand, 100 is a very round and satisfying number. Just look at it. Way better than 112 or some garbage. I do wonder if anyone working in Gearbox’s gigabyte dieting department saw it was possible to compress it down to 99GB, potentially avoiding the shock of entering the triple digits, but left it at 100GB just because it’s vaguely nicer. I suspect I’d do the same.\n\nAnyway, here’s the hardware:\n\nBorderlands 4 minimum PC specs\n\nOS: Windows 10 / 11\n\nWindows 10 / 11 CPU: Intel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum)\n\nIntel Core i7-9700 / AMD Ryzen 7 2700X (8 core minimum) RAM: 16GB\n\n16GB GPU: Nvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum)\n\nNvidia GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580 (8GB minimum) Storage: 100GB (SSD required)\n\nBorderlands 4 recommended PC specs\n\nOS: Windows 10 / Windows 11\n\nWindows 10 / Windows 11 CPU: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nIntel Core i7-12700 / AMD Ryzen 7 5800X RAM: 32GB\n\n32GB GPU: Nvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nNvidia GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580 Storage: 100GB (SSD required)\n\nSolid state hungriness aside, it’s a bit strange seeing the Arc B580 in the recommended tier, alongside the RTX 3080 and RX 6800 XT – it’s a good little budget card but not on the same level as those two older, yet bonafide high-end GPUs. Though maybe that means Borderlands 4 performs better-than-recommended on this Nvidia/AMD kit?\n\nAlso, 2K’s post doesn’t mention it specifically, but DLSS 4 Multi Frame Generation is supported as well. This needs a GeForce RTX 50 series card to operate at full pelt, with RTX 40 models making do with DLSS 3-style 2x frame gen.\n\nI’m generally in the 'wait and see how it is' camp on Fourderlands, with its new planet and its many billions of randomly generated firearms, having previously been interested enough to mulch through Borderlands 3 with mates but jointly concluding it wasn’t worth our time. This new one is something of a reset, with its lead writer Taylor Clark claiming it won’t have as many jokes. Which is, at once, likely an improvement and also a weird thing to make a selling point of. B4's out on September 12th.",
      "source": "Rock Paper Shotgun",
      "url": "https://www.rockpapershotgun.com/despite-cutting-the-gags-borderlands-4s-pc-specs-say-it-still-needs-100gb-of-ssd-space",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Advanced Micro Devices, Inc. (AMD) Becomes the Most Under-Owned U.S. Semiconductor Stock",
      "content": "Advanced Micro Devices, Inc. (NASDAQ:AMD) is included in our list of the 14 Tech Stocks to Sell Now According to Ken Fisher.\n\nAdvanced Micro Devices, Inc. (AMD) Becomes the Most Under-Owned U.S. Semiconductor Stock\n\nClose-up of Silicon Die are being Extracted from Semiconductor Wafer and Attached to Substrate by Pick and Place Machine. Computer Chip Manufacturing at Fab. Semiconductor Packaging Process.\n\nBank of America reported on September 3, 2025, that Advanced Micro Devices, Inc. (NASDAQ:AMD), despite being an outperformer in the sector, has become the most under-owned U.S. semiconductor stock among active managers. Active ownership fell to 20% in August from 23% in May and 39% a year earlier.\n\nMeanwhile, Advanced Micro Devices, Inc. (NASDAQ:AMD)’s relative weighting has gone down by 80% year-over-year compared to the S&P 500. This is in line with consensus forecasts, which project 22% sales growth and AMD’s continued gains over the Philadelphia Semiconductor Index. At the same time, the investment firm reiterated its ‘Buy’ rating on AMD, thanks to strong tailwinds from rising artificial intelligence adoption and the company’s sustained market share gains against Intel.\n\nAdvanced Micro Devices, Inc. (NASDAQ:AMD) focuses on designing and developing semiconductors, offering CPUs, GPUs, AI accelerators, and embedded solutions. It serves data centers, client computing, gaming, and specialized applications globally.\n\nWhile we acknowledge the potential of AMD as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 15 Stocks That Will Benefit From AI and 10 Must-Buy Canadian Stocks to Invest in.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/advanced-micro-devices-inc-amd-085831164.html",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "CHILLYHELL macOS Backdoor and ZynorRAT RAT Threaten macOS, Windows, and Linux Systems",
      "content": "Cybersecurity researchers have discovered two new malware families, including a modular Apple macOS backdoor called CHILLYHELL and a Go-based remote access trojan (RAT) named ZynorRAT that can target both Windows and Linux systems.\n\nAccording to an analysis from Jamf Threat Labs, ChillyHell is written in C++ and is developed for Intel architectures.\n\nCHILLYHELL is the name assigned to a malware that's attributed to an uncategorized threat cluster dubbed UNC4487. The hacking group is assessed to have been active since at least October 2022.\n\nAccording to threat intelligence shared by Google Mandiant, UNC4487 is a suspected espionage actor that has been observed compromising the websites of Ukrainian government entities to redirect and socially engineer targets to execute Matanbuchus or CHILLYHELL malware.\n\nThe Apple device management company said it discovered a new CHILLYHELL sample uploaded to the VirusTotal malware scanning platform on May 2, 2025. The artifact, notarized by Apple back in 2021, is said to have been publicly hosted on Dropbox since then. Apple has since revoked the developer certificates linked to the malware.\n\nOnce executed, the malware extensively profiles the compromised host and establishes persistence using three different methods, following which it initializes command-and-control (C2) communication with a hard-coded server (93.88.75[.]252 or 148.72.172[.]53) over HTTP or DNS, and enters into a command loop to receive further instructions from its operators.\n\nTo set up persistence, CHILLYHELL either installs itself as a LaunchAgent or a system LaunchDaemon. As a backup mechanism, it alters the user's shell profile (.zshrc, .bash_profile, or .profile) to inject a launch command into the configuration file.\n\nA noteworthy tactic adopted by the malware is its use of timestomping to modify the timestamps of created artifacts to avoid raising red flags.\n\n\"If it does not have sufficient permission to update the timestamps by means of a direct system call, it will fall back to using shell commands touch -c -a -t and touch -c -m -t respectively, each with a formatted string representing a date from the past as an argument included at the end of the command,\" Jamf researchers Ferdous Saljooki and Maggie Zirnhelt said.\n\nCHILLYHELL supports a wide range of commands that allow it to launch a reverse shell to the C2 IP address, download a new version of the malware, fetch additional payloads, run a module named ModuleSUBF to enumerate user accounts from \"/etc/passwd\" and conduct brute-force attacks using a pre-defined password list retrieved from the C2 server.\n\n\"Between its multiple persistence mechanisms, ability to communicate over different protocols and modular structure, ChillyHell is extraordinarily flexible,\" Jamf said. \"Capabilities such as timestomping and password cracking make this sample an unusual find in the current macOS threat landscape.\"\n\n\"Notably, ChillyHell was notarized and serves as an important reminder that not all malicious code comes unsigned.\"\n\nThe findings dovetail with the discovery of ZynorRAT, a RAT that uses a Telegram bot called @lraterrorsbot (aka lrat) to commandeer infected Windows and Linux hosts. Evidence shows that the malware was first submitted to VirusTotal on July 8, 2025. It does not share any overlaps with other known malware families.\n\nCompiled with Go, the Linux version supports a wide range of functions to enable file exfiltration, system enumeration, screenshot capture, persistence through systemd services, and arbitrary command execution -\n\n/fs_list, to enumerate directories\n\n/fs_get, to exfiltrate files from the host\n\n/metrics, to perform system profiling\n\n/proc_list, to run the \"ps\" Linux command\n\n/proc_kill, to kill a specific process by passing the PID as input\n\n/capture_display, to take screenshots\n\n/persist, to establish persistence\n\nZynorRAT's Windows version is near-identical to its Linux counterpart, while still resorting to Linux-based persistence mechanisms. This likely indicates that development of the Windows variant is a work in progress.\n\n\"Its main purpose is to serve as a collection, exfiltration, and remote access tool, which is centrally managed through a Telegram bot,\" Sysdig researcher Alessandra Rizzo said. \"Telegram serves as the main C2 infrastructure through which the malware receives further commands once deployed on a victim machine.\"\n\nFurther analysis of screenshots leaked via the Telegram bot has revealed that the payloads are distributed via a file-sharing service known as Dosya.co, and that the malware author may have \"infected\" their own machines to test out the functionality.\n\nZynorRAT is believed to be the work of a lone actor possibly of Turkish origin, given the language used in Telegram chats.\n\n\"Although the malware ecosystem has no shortage of RATs, malware developers are still dedicating their time to creating them from scratch,\" Rizzo said. \"ZynorRAT's customization and automated controls underline the evolving sophistication of modern malware, even within their earliest stages.\"",
      "source": "Internet",
      "url": "https://thehackernews.com/2025/09/chillyhell-macos-backdoor-and-zynorrat.html",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "A former manager says a 5-month job hunt has her eyeing a pivot: 'I'm starting to get excited about not managing people'",
      "content": "Karen Del'Olio has struggled to find work since being furloughed from her research program manager role in April.\n\nKaren Del'Olio has struggled to find work since being furloughed from her research program manager role in April. Karen Del'Olio\n\nKaren Del'Olio has struggled to find work since being furloughed from her research program manager role in April. Karen Del'Olio\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nAfter years in management, a frustrating job search has Karen Del'Olio rethinking what she wants next.\n\nIn April, the 59-year-old was furloughed from her role as a research program manager at an academic institution in Massachusetts after a sponsor pulled funding from the project she led. Despite beginning her search in April and applying to dozens of jobs, she said she didn't land any interviews beyond an initial recruiter call during the first four months of her search. While she's since secured two interviews past the recruiter stage, she's still looking for an offer.\n\n\"I just get recruiters who say they're going to send the résumé on, and then I never hear back — I get ghosted,\" she said.\n\nHer furlough is set to end in October, and Del'Olio said she doesn't expect to be rehired — in part because of recent funding cuts from the National Institutes of Health. She was raised to keep a rainy-day fund, and for now, those savings have helped her cover expenses. But she's burning through them quickly, and if her job search stretches much longer, she worries her financial situation could become unstable. While she applied for unemployment benefits in May, she said she wasn't approved until August — at which point she received retroactive payments.\n\nFinancial concerns are one reason she's begun exploring roles outside the management positions she initially targeted. And as her search continues, she's starting to believe the shift might be for the best — that the downsides of management may outweigh the benefits, even with the higher pay.\n\n\"It doesn't have to be in management; though, preferably, that's the pay scale that I'm looking for,\" she said of her next job. \"I'm starting to get excited about not managing people.\"\n\nDel'Olio's experience reflects a broader shift in the US labor market that's made it challenging for workers in managerial positions to find jobs. Several major corporations, including Microsoft, Google, Intel, and Walmart, have cut manager roles in recent years.\n\nIt's not just big businesses. Gusto, a payroll and benefits platform for small and midsize businesses, found that manager firings and layoffs by businesses on the platform had risen 66% between January 2022 and September 2024 for those ages 45 to 54 — and more than 400% for those ages 35 to 44.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nThis trend, dubbed the Great Flattening, reflects a broader push to reduce costs and bureaucracy, moves business leaders say will make their organizations more efficient. But for some laid-off managers, finding new employment has been difficult. Amid economic uncertainty, including tariffs and the early impacts of AI adoption, US businesses are hiring at nearly the slowest pace in more than a decade.\n\nThe pros and cons of management positions\n\nDel'Olio believes she's part of a generation of workers in their 50s and early 60s who are often overlooked in today's job market. She feels they're caught in a gap — not old enough to retire but navigating a workplace that's rapidly evolving, especially with the rise of AI.\n\nShe worries that many job seekers in this age group — many of whom are targeting management roles — may be at a disadvantage as companies prioritize younger, lower-cost workers perceived as more tech-savvy. In addition to needing jobs to continue building retirement savings, many also rely on employment for medical insurance, since Medicare coverage typically doesn't begin until age 65.\n\nGiven these circumstances, Del'Olio said she's torn between focusing her job search on higher-paying manager-level jobs that match her experience and pursuing lower-level roles she may enjoy more — and that could be easier to land.\n\nDel'Olio said she appreciated many aspects of being a manager. She liked establishing strategies, aligning teams toward a shared vision, mentoring others, and designing systems and programs. Her role also gave her broad visibility and allowed her to collaborate across departments. In her job search, she's applied to several clinical research and program management roles in the healthcare sector that she believes would build on her past leadership experience.\n\nBut there were also downsides that have made her reconsider management. Administrative tasks — such as performance reviews and handling team turnover — were time-consuming. She also found it difficult to juggle competing priorities and navigate interpersonal conflicts among coworkers, all while staying accountable for her team's performance. She added that she sometimes wished she could spend less time \"putting out fires\" and working to keep team morale positive.\n\nIn recent months, Del'Olio has spent more time exploring non-managerial roles that allow for more creativity, innovation, and work-life balance — without the day-to-day demands of managing a team. She said she's especially drawn to roles related to health communications, marketing and branding, content development, digital health, and quality improvement.\n\n\"I feel I can be more creative and innovative in non-managerial positions,\" she said. \"I'd rather connect people and build relationships and not manage their tasks.\"\n\nTrying to stay a step ahead of a changing job market\n\nDel'Olio said her job search strategies have included customizing her résumé for each position and reaching out to recruiters on LinkedIn. She's also used ChatGPT to help revise her résumé, hoping it will suggest \"modern\" terms that are more likely to be recognized by applicant tracking systems. She also tries to include relevant language from the job description in her résumé.\n\n\"If you don't match the language specifically, you may get a low score through that AI-powered screening process,\" she said. \"I've even gotten an automatic decline within an hour.\"\n\nDel'Olio said she's also concerned that her age may be working against her. Even if she doesn't list her birth date in an application, she suspects AI hiring systems can estimate her age based on the length of her work history, which could be hurting her chances. To try to counter this, she's removed the dates from her degrees and some of her past jobs.\n\nIn the coming months, Del'Olio plans to learn more about data management and AI technologies to make herself more marketable to employers. She said she intends to join some AI-focused groups on LinkedIn and pursue some online AI certifications.\n\n\"If you can't beat 'em, join 'em,\" she said, referencing the potential for AI to negatively impact employment in certain sectors.\n\nIf her search continues to stall, Del'Olio said she may have to expand it even further — to any role that simply offers a paycheck. In the meantime, she's trying to keep up with a job market that feels like it's constantly shifting.\n\n\"I think the entire world of work has changed,\" she said. \"The way that we hire; the way that we manage; the way that we promote.\"",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/former-manager-cant-find-job-looking-roles-outside-management-2025-9",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Hedgehog-like mini PC doesn't have a fan - silent Mele Cyber X1 is designed to run 24/7 and is cooled by hundreds of metal spikes",
      "content": "MeLe Cyber X1 UHD Graphics supports 4K playback and handles productivity tasks efficiently\n\nHundreds of metal spikes replace fans to achieve completely silent operation\n\nIntel N150 processor delivers modest performance with four cores\n\nThe MeLe Cyber X1 is the latest addition to MeLe’s series of compact mini PCs, following the trend set by the previous Quieter series.\n\nThis mini PC relies on a dense metal fin heatsink made up of hundreds of tightly packed metal spikes covering its top panel.\n\nThis design disperses heat without the need for fans, allowing silent operation even during continuous 24/7 use.\n\nSilent design but with entry-level Intel performance\n\nThe system is powered by the Intel N150, a 12th-gen Twin Lake-N processor with four cores, four threads, and speeds up to 3.6GHz.\n\nThe MeLe Cyber X1 integrates Intel UHD Graphics, which handles video playback, light gaming, and common productivity tasks, with codec support for AV1, VP9, and h.265 up to 4K at 60 frames per second.\n\nWhile it is not intended to rival high-performance systems, the configuration is adequate for Windows 11 Pro, general browsing, office work, and low-demand design applications.\n\nThe unit comes with 16GB of LPDDR5 memory running at 4800MHz, permanently soldered onto the motherboard, making upgrades impossible.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nStorage is provided through a 512GB SSD, complemented by a microSD slot supporting up to 2TB expansion.\n\nFor display and external device support, the MeLe Cyber X1 offers two HDMI 2.0a ports and a USB Type-C 3.2 Gen2 connection capable of video output via DisplayPort 1.4 as well as 10Gbps data transfer and PD 3.0 power delivery.\n\nAdditional connectivity comes from a mix of USB-A 3.2 Gen1, USB-A 3.2 Gen2, USB 2.0, and a 3.5mm audio jack.\n\nNetwork options include Gigabit Ethernet, Wi-Fi 5, and Bluetooth 5.1, although these are not the most recent standards available.\n\nThe package includes a VESA mount and a Kensington lock slot for security, but the absence of newer wireless standards raises questions about long-term suitability for demanding business networks.\n\nThe Cyber X1 is available for €299.99, which is not unreasonable but puts it in competition with systems offering faster processors or more flexible upgrade paths.\n\nIt may not be the best workstation or business PC for power users, but it could find its place as a silent mini PC for offices, digital signage, or continuous low-power tasks.\n\nUltimately, it seems designed less for versatility and more for specialized use where silence and 24/7 reliability matter more than raw performance or expandability.\n\nVia Android PC (originally in Spanish)",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/hedgehog-like-mini-pc-doesnt-have-any-fan-silent-mele-cyber-x1-is-designed-to-run-24-7-and-is-cooled-by-hundreds-of-metal-spikes",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "Intel confirms Arrow Lake refresh set for 2026, Nova Lake later that year — company admits there are 'holes to fill on the desktop front,' says it is 'confident in the roadmap'",
      "content": "Intel confirmed at a recent Goldman Sachs Technology conference that it plans to launch a refresh of its Arrow Lake processors \"next year,\" with its true next-generation Nova Lake designs to follow along before the end of 2026, as per a transcript of the presentation. Although this likely means at least another year of AMD's Ryzen 9000 CPUs holding the gaming performance crown, Intel maintains that it's \"confident in the road map,\" as it stands.\n\nThe statement came from Intel's Corporate Vice President, Investor Relations, John Pitzer. He said: \"We've got a couple of holes we've got to fill on the desktop front. But quite frankly, we feel confident in the road map [...] We'll have a refresh of Arrow Lake next year, which will help start the process on the desktop side, and then we'll conclude that with Nova Lake when we launch late next year into 2027.\"\n\nWe've been hearing hints about a refresh of the Core Ultra 200 generation of CPUs for some time now, with various rumors about what it might involve. Improved binning and clock speed tweaks should result in a higher boost clock for CPUs involved in the refresh, though that may be limited to just K and KF-series models if some rumors are to be believed.\n\nThere was some talk about Intel introducing a newer, more capable neural processing unit (NPU) for AI workloads, but the most recent reports suggest that this is no longer happening, or was never officially planned.\n\nThe upgraded Core Ultra 200 CPUs are expected to maintain the same core counts, though we may see increased power limits in some models.\n\nA 2026 launch for such a refresh, though, feels quite late. By the middle of 2026, Intel's Arrow Lake generation will be almost two years old, and AMD will likely be well on its way to launching its next-generation Zen 6 CPUs. Although some recent rumors suggest mobile Zen 6 CPUs might not launch until 2027, giving Intel some breathing room to launch Nova Lake, the desktop versions should arrive before the end of the year. AMD will release more concrete roadmap details this November, giving us a clearer outline of what to expect over the next 18 months.\n\nWhether Zen 6 and Nova Lake debut before the end of 2026 or just after, though, that's not a huge lead time for any Arrow Lake refresh processors to gain much ground. They'd need to be notably faster than existing Core Ultra 200 CPUs to be particularly relevant, so far from the original launch date, and pricing would need to be exceedingly favorable to attract buyers who can see so many shiny next-generation CPUs just over the horizon. Especially since Nova Lake is expected to use an entirely new socket, severely limiting upgrade paths for Arrow Lake buyers.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/intel-confirms-arrow-lake-refresh-set-for-2026-nova-lake-later-that-year-company-admits-there-are-holes-to-fill-on-the-desktop-front-says-it-is-confident-in-the-roadmap",
      "timestamp": "2025-09-10"
    },
    {
      "headline": "4-bit Single Board Computer Based on the Intel 4004 Microprocessor",
      "content": "[Scott Baker] is at it again and this time he has built a 4-bit single board computer based on the Intel 4004 microprocessor.\n\nIn the board design [Scott] covers the CPU (both the Intel 4004 and 4040 are supported), and its support chips: the 4201A clock-generator, its crystal, and the 4289 Standard Memory Interface. The 4289 irons out the 4-bit interface for use with 8-bit ROMs. Included is a ATF22V10 PLD for miscellaneous logic, a 74HCT138 for chip-select, and a bunch of inverters for TTL compatibility (the 4004 itself uses 15 V logic with +5 V Vss and -10 V Vdd).\n\n[Scott] goes on to discuss the power supply, ROM and page mapper, the serial interface, the RC2014 bus interface, RAM, and the multimodule interface. Then comes the implementation, a very tidy custom PCB populated with a bunch of integrated circuits, some passive components, a handful of LEDs, and a few I/O ports. [Scott] credits Jim Loo’s Intel 4004 SBC project as the genesis of his own build.\n\nIf you’re interested in seeing this board put to work check out the video embedded below. If you’d like to know more about the 4004 be sure to check out Supersize Your Intel 4004 By Over 10 Times, The 4004 Upgrade You’ve Been Waiting For, and Calculating Pi On The 4004 CPU, Intel’s First Microprocessor.",
      "source": "Hackaday",
      "url": "https://hackaday.com/2025/09/11/4-bit-single-board-computer-based-on-the-intel-4004-microprocessor/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "This Elite-Level HP Laptop Bundle (64GB RAM, 2TB SSD) Drops Again Overnight, 72% Off and Likely as Low as It Gets",
      "content": "Amazon is not messing around with this new laptop deal, which is only fitting because it’s on a laptop that also does not mess around. You can get a fully loaded 17-inch HP Business Laptop with a 12-core Intel Ultra 7 255U processor, supercharged AI power, and 2TB of storage for a 72%-off price of $1,119 — that’s a savings of over $2,800.\n\nAlong with this enormously powerful HP touchscreen laptop comes a $200 accessories package including a wireless mouse, USB hub, 128GB flash drive, and 7-in-1 cleaning kit. For additional value, Windows 11 Pro is preinstalled, and the 12 TOPS (Trillions of Operations Per Second) of AI computational power combined with Microsoft Copilot creates a peak AI device.\n\nSee at Amazon\n\nTerrific Touchscreen\n\nThe generously proportioned 17.3-inch touchscreen of this business laptop is not only a perfect interactive device giving the user a rapid-reaction tablet-like experience, but it’s a vivid HD+ (1600 x 900 resolution) display with anti-glare treatment and 250 nits of brightness. The keyboard is also backlit for better accessibility, and the Copilot key is present for one-touch deployment of the powerful AI features.\n\nWhatever you have on that high-performing screen — anything from multiple windows of complex spreadsheets to whatever TV show or movie you’re streaming — will come through without any hesitation or glitching. That’s because the 12-core Intel Ultra 7 255U processor is an absolute beast, able to hit speeds of up to 5.2GHz and bolstered by a maxed-out 64GB of RAM. The huge 2TB SSD reads and writes data with impressive speed, and the huge amount of storage and memory combined with the elite processor makes this HP laptop virtually future-proofed.\n\nAll the Connections\n\nThe Wi-Fi 6 and Bluetooth 5.4 hookups are just the tip of the connectivity spear. This HP laptop has a 720p HD webcam with a privacy shutter built in, and there are two USB-A, one USB-C, and an HDMI 1.4b port at the ready should you want to connect parallel accessories, including the 128GB USB flash drive and 7-in-1 USB hub that come free with this laptop. The pre-tuned stereo speakers complete this truly impressive package.\n\nWhile the $4,000 retail price for this 17.3-inch HP Business Laptop with Windows 11 Pro and accessories bundle is a little bloated, to say the least, the huge 72% Amazon price cut lands it at an exceptionally competitive $1,119. With the powerful Intel processor, huge cache of memory and storage, and hypercharged AI engine, this will be your everyday productivity laptop for years to come.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/this-elite-level-hp-laptop-bundle-64gb-ram-2tb-ssd-drops-again-overnight-72-off-and-likely-as-low-as-it-gets-2000624810",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Spectre haunts CPUs again: VMSCAPE vulnerability leaks cloud secrets",
      "content": "If you thought the world was done with side-channel CPU attacks, think again. ETH Zurich has identified yet another Spectre-based transient execution vulnerability that affects AMD Zen CPUs and Intel Coffee Lake processors by breaking virtualization boundaries.\n\nThe attack, dubbed VMSCAPE (CVE-2025-40300), is said to be the first Spectre-based exploit that allows a malicious guest user in a cloud environment to leak secrets from the hypervisor in the host domain without code changes – injected Return-oriented programming gadgets – and in default configuration.\n\nThe technique is described in a paper [PDF] published on Thursday, \"VMSCAPE: Exposing and Exploiting Incomplete Branch Predictor Isolation in Cloud Environments,\" by Jean-Claude Graf, Sandro Rüegge, Ali Hajiabadi, and Kaveh Razavi. The paper is set to be presented at the 47th IEEE Symposium on Security and Privacy.\n\nCloud computing depends upon virtualization to securely partition physical computing resources into virtual ones, managed by a hypervisor. VMSCAPE targets the Kernel Virtual Machine (KVM) and QEMU (Quick Emulator), as the hypervisor and as the userspace component of the hypervisor in the host.\n\n\"VMSCAPE can leak the memory of the QEMU process at the rate of 32 B/s on AMD Zen 4,\" the authors state in their paper. \"We use VMSCAPE to find the location of secret data and leak the secret data, all within 772 s, extracting the cryptographic key used for disk encryption/decryption as an example.\"\n\nAMD Zen 1-5 processors are affected, as are Intel Coffee Lake processors, which debuted in 2017. Hardware fixes aren't feasible, the authors say, so Linux maintainers have addressed the issue in software. This comes at a cost, however, in terms of performance overhead.\n\nSpectre, a set of vulnerabilities based on processor microarchitecture, has allowed attackers to access sensitive host memory to varying degrees since its disclosure in 2018, alongside another flaw known as Meltdown.\n\nOne of these is known as Spectre v2 or Branch Target Injection, a way to abuse CPU indirect branch predictors, which control speculative execution – executing predicted instructions before they're called for in code, in order to improve performance.\n\nVarious mitigations have been developed and deployed to defend against Spectre-based attacks, generally at the cost of performance. These include: Indirect Branch Restricted Speculation (IBRS), Enhanced IBRS (eIBRS), Automatic IBRS (AutoIBRS), Indirect Branch Prediction Barrier (IBPB), and Single Threaded Indirect Branch Predictor (STIBP).\n\nBut, to date, Spectre v2 attacks have not had much impact because, as the authors note, they assume the attacker has the ability to run local code on the user's system.\n\nThe ETH Zurich boffins took a look at the way AMD and Intel processors handle host-guest boundaries and found the separation isn't sufficient on AMD Zen CPUs and older Intel CPUs. The branch target buffer (BTB) entries between host and guest are not isolated, so the branch predictor mingles predictions across host and guest domains. VMSCAPE exploits this with the help of a set of new attack primitives that the researchers call vBTI (virtualization Branch Target Injection).\n\nAn AMD spokesperson told The Register that a Security Brief will be issued that acknowledges the potential vulnerability. But the fix will be in software.\n\nIn a statement provided to The Register, an Intel spokesperson said, \"Existing mitigations on Intel processors can be used to mitigate this issue. Intel has previously provided guidance for Branch Target Injection (BTI), Branch History Injection (BHI), and Indirect Target Selection (ITS), and Intel engineers are working with Linux to ensure that the appropriate mitigations for these issues as described in these guidance documents are applied to Linux userspace hypervisor software. Linux mitigations are expected to be available on the VMSCAPE public disclosure date, and a CVE for this issue will be assigned by Linux.\"\n\nThe Linux patch, we're told, will be ported to various Linux distributions after its release.\n\nThe authors proposed a mitigation called \"IBPB-on-VMExit\" that Linux developers have optimized under the name \"IBPB before exit to userspace.\" According to the researchers, the overhead depends on the workload and the frequency of userspace exits.\n\n\"For emulated devices (default for QEMU), userspace exits are much more frequent than for virtualized devices (commonly used in enterprise systems),\" the authors observe in a summary note. \"Our benchmarking indicates an overhead of ~10 percent when using an emulated device.\"\n\nWith Zen 4, the authors' benchmark testing suggests \"a marginal 1 percent overhead\" post-patch.\n\nThe Linux mitigation is said to be active for all affected systems, including Zen 5 and even recent Intel CPUs that were not exploitable such as Lunar Lake and Granite Rapids. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/11/vmscape_spectre_vulnerability/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "An Interview with Dan Kim About Intel, Nvidia, and the U.S. Government",
      "content": "Subscribe to Stratechery Plus for full access. Already subscribed? Log in $15 / month or $150 / year\n\nWith Stratechery Plus you get access to the subscriber-only Stratechery Update and Stratechery Interviews, and the Sharp Tech, Sharp China, Dithering, Greatest of All Talk, and Asianometry podcasts.\n\nStratechery Update\n\nSubstantial analysis of the news of the day delivered via three weekly emails or podcasts. Stratechery Interviews\n\nInterviews with leading public CEOs, private company founders, and discussions with fellow analysts. Dithering\n\nA twice-weekly podcast from John Gruber and myself: 15 minutes an episode, not a minute less, not a minute more. Sharp Tech\n\nAndrew Sharp and myself discuss how technology works and the ways it impacts our lives. Sharp China\n\nA weekly podcast from Andrew Sharp and Sinocism’s Bill Bishop about understanding China and how China impacts the world. Greatest Of All Talk\n\nA twice-weekly podcast from Andrew Sharp and Ben Golliver about the NBA, life, and national parks. Asianometry\n\nAudio and transcripts of the Asianometry YouTube channel, the best source for learning about how tech works.\n\nStratechery Updates are also available via SMS, RSS, or on this site. Please see the Stratechery Update Schedule for more details about delivery times and planned days-off. Please note that all subscriptions auto-renew monthly/annually (but can be cancelled at any time). If you are interested in ordering and managing multiple subscriptions for your team or company, please fill in the form here.\n\nFrequently-Asked Questions\n\nHow do I subscribe to the Stratechery Podcast? Once you are subscribed, please visit your Delivery Preferences where you will find easy-to-follow instructions for adding Stratechery Podcasts to your favorite podcast player.\n\nCan I read Stratechery via RSS? Yes! Create a Stratechery Passport account, go to Delivery Preferences, and add your personalized RSS feed. Free accounts will have access to Weekly Articles, while subscribers will have access to the Daily Update as well.\n\nCan I share a Stratechery Update subscription with a friend? No, the Stratechery Update and Stratechery Podcast are intended for one subscriber only. Sharing emails, using shared inboxes, or sharing RSS feeds is a violation of Stratechery’s Terms of Service, and your account may be suspended or your RSS feed reset. Of course occasional forwarding of the Stratechery Update to interested friends or colleagues is totally fine.\n\nCan I buy a subscription for my team? Yes! You can purchase a team subscription here.\n\nCan I switch to an annual plan? Yes! Just go to your account page, choose the ‘Subscriptions’ tab, and click the Annual upgrade button. You will be charged immediately, with a prorated discount applied for the remainder of your current monthly plan.\n\nDo you offer a student discount? Stratechery is purposely kept at a low price — thousands of dollars less than other analyst reports or newsletters — to ensure it is accessible to everyone, including students.\n\nCan you create a custom invoice that meets my government/company requirements? I am happy to create an invoice to your specification for annual subscribers; however, it is simply not viable for me to offer this service to monthly subscribers. Therefore, if you need a custom invoice please subscribe or switch to an annual subscription and contact Stratechery. June 1, 2021 Update: We are hoping to add native support for custom invoices to Passport; you can subscribe to Passport Updates to be notified when it is available.",
      "source": "Stratechery.com",
      "url": "https://stratechery.com/2025/an-interview-with-dan-kim-about-intel-nvidia-and-the-u-s-government/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Hijacker helper VoidProxy boosts Google, Microsoft accounts on demand",
      "content": "Multiple attackers using a new phishing service dubbed VoidProxy to target organizations' Microsoft and Google accounts have successfully stolen users' credentials, multi-factor authentication codes, and session tokens in real time, according to security researchers.\n\nOkta Threat Intelligence uncovered the ongoing attacks, and told The Register that several different criminals and cybercrime gangs are using VoidProxy. The company has issued a detailed report on its findings.\n\n\"We have observed the targeting of multiple industries across multiple geographies, each of which reflects the priorities of the individual customer\" of the phishing-as-a-service operation, the threat hunters said via email, in response to The Register's questions.\n\nThe phishes target any Google and Microsoft accounts, from small businesses to large enterprises, we're told. And while Okta didn't have a confirmed victim count, \"we have observed high-confidence account takeovers in multiple entities,\" the threat intel team told us. \"By extension, we expect Microsoft and Google will have observed a larger number of ATO events, given that VoidProxy proxies non-federated users directly with Microsoft and Google servers.\"\n\n“We regularly see new phishing campaigns like this pop up, which is why we design durable protections to keep users safe from these types of attacks, including defenses against domain spoofing, phishing links, and compromised senders,” a Google spokesperson told The Register. “We also agree with the report’s recommendation that users adopt passkeys as a strong protection against phishing.”\n\nGoogle declined to answer The Register's specific questions, including how many account takeovers it had seen. Microsoft declined to comment.\n\nWhile Okta observed the attacks as beginning around January, the researchers said that they have linked these phishing campaigns to VoidProxy ads on the dark web from as far back as August 2024.\n\nWe have observed high-confidence account takeovers in multiple entities\n\n\"The activity is ongoing,\" the threat intel team said via email. \"We are detecting new infrastructure and generating alerts for customers on a daily basis.\"\n\nHere's how the attacks work. First, the criminals send phishing lures from legitimate, albeit compromised, email accounts from providers including Constant Contact, ActiveCampaign (Postmark app), NotifyVisitors, and others.\n\nThese emails have a link to a URL shortening service (like TinyUrl) embedded within the communication, and the malicious link redirects the victim several times before they land on the first-stage phishing site. The phishing websites are hosted on low-cost domains such as .icu, .sbs, .cfd, .xyz, .top, and .home, and placed behind Cloudflare, which hides the real IP address and makes it more difficult for network defenders to take down the host.\n\nAfter completing a Cloudflare CAPTCHA challenge, thus ensuring the victim is a human and not a bot, the user is sent to the phishing site, which looks exactly like a Google or Microsoft account sign-in page. This service also redirects accounts protected by third-party single sign-on (SSO) providers like Okta.\n\nAttacker-in-the-Middle\n\nThe page looks completely legit to the user, who likely then enters their login credentials. But instead of signing on to their actual Microsoft or Google account, this info is sent to the VoidProxy's attacker-in-the-middle (AiTM) proxy server, where the AiTM attack plays out.\n\n\"It's here that the sophisticated, multi-layered nature of VoidProxy comes into play,\" the report says.\n\nAiTM attacks happen when criminals secretly position themselves between two parties - such as a user and a website - to intercept login and banking credentials, or to listen in on communications and manipulate data flowing between them.\n\nIn this stage of the attacks, the core proxy server, which is hosted on ephemeral infrastructure, captures and relays sensitive information like usernames, passwords, and MFA responses to legitimate Microsoft, Google, and Okta services. These legit services validate and authenticate the users' information and then issue a session cookie, which is also intercepted by the proxy server.\n\n\"A copy of the cookie is exfiltrated and made available to the attacker via their admin panel,\" the report says. \"The attacker is now in possession of a valid session cookie and can access the victim's account.\"\n\nAnd all of these features are offered for sale to other criminals via VoidProxy's phishing-as-a-service operation.\n\nCustomers (aka criminals) receive a full-featured administrative panel that allows them to manage and monitor their phishing campaigns, and a dashboard for each campaign tracks how many credentials and cookies have been stolen on a daily basis. These campaigns and stolen data are also displayed by region with maps of each country showing the victim count.\n\nOkta recommends enrolling in strong authenticators such as Okta FastPass, using FIDO2 WebAuthn (passkeys and security keys), and enforcing phishing-resistance in policy to avoid falling victim to VoidProxy attacks.\n\nThe report authors also tell us that they encourage industry partners - like Microsoft and Google - \"to continue to support and advocate for industry standards like Interoperability Profile for Secure Identity in the Enterprise (IPSIE).\n\n\"A consistent adherence to these standards could, for example, ensure impacted parties can sign a user out of both their device and all their browser apps in real-time whenever a user interacts with known malicious infrastructure,\" the threat intel team told The Register. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/11/voidproxy_phishing_service/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Adaptables Media Timer – An open-source media player for creative code",
      "content": "The Adaptables Media Timer is an open-source media player designed to make complex multimedia scheduling simple and accessible. It supports all the standard audio-visual formats while also being capable of running dynamic formats like web applications and generative coding outputs.\n\nThe Media Timer was developed after noticing that existing media playback devices weren’t very suitable for modern media requirements. Too often, people were stuck with restrictive, basic scheduling limitations or had to convert rich interactive work into simplified video formats. The Media Timer offers a more flexible approach for exhibitions and installations.\n\nThe open-source software lets you easily synchronise your media across an unlimited number of schedules for each day of the week, accepting a much broader range of file types including Processing and Pure Data executables, P5.JS sketches and Python scripts. Built from refurbished hardware, the Media Timers help reduce tech waste while utilising the low power capabilities of single board computers to offer a carbon efficient, environmentally friendly alternative.\n\nThe Media Timer’s custom operating system “AdaptableOS” is built on Debian Linux. The configuration and initialisation software are built using Rust and offer accurate scheduling of media to the second (~10ms). The Media Timer software relies on systemd as the service manager. Acceptable media formats are audio, video, image, slideshow, web applications and executables. Getting started and technical example guides can be found here.\n\nProject Page | Instagram\n\nEco Standard #1 Standard #2 Pro Processor: Intel Atom x5 Z-8350, 1.44GHz\n\nStorage: 8GB/16GB\n\nRAM: 2GB\n\nResolution: 2560 x 1600 32-bit colour\n\nVideo: Display Port (x2)\n\nNetwork: 10/100/1000\n\nUSB: 3×2.0, 1×3.0\n\nPower: 4W/5W Processor: Intel Pentium Silver J5005, 1.5GHz-2.8GHz\n\nStorage: 16GB\n\nRAM: 4GB\n\nGraphics: Intel UHD 600/605\n\nResolution: 2 @ 3840×2160@60Hz, 1 @ 2560×1600@60Hz\n\nVideo: 3 x Display Port\n\nNetwork: 10/100/1000\n\nUSB: 3×2.0, 6×3.2, 1×3.2 type C\n\nPower: 4W/7W Processor: Intel Celeron J4105, 1.5GHz-2.5GHz\n\nStorage: 16GB\n\nRAM: 4GB\n\nGraphics: Intel UHD 600/605\n\nResolution: 2 @ 2560×1600@60Hz\n\nVideo: 2 x Display Port\n\nNetwork: 10/100/1000\n\nUSB: 3×2.0, 6×3.2, 1×3.2 type C\n\nPower: 4W/7W Coming Soon\n\nAll Adaptables kits are made by hand in Glasgow, UK. Our small team crafts each element of every Media Timer, developing our custom operating system and open source software, refurbishing devices and creating multifunctional recyclable cases and packaging.",
      "source": "Creativeapplications.net",
      "url": "https://www.creativeapplications.net/member/adaptables-media-timer-an-open-source-media-player-for-creative-code/",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Dynabook just launched a trio of laptops each weighing 849g - and I can't believe that's barely heavier than two cans of Coke",
      "content": "Dynabook launches three ultraportable laptops weighing only 849g\n\nG8, G6, and GS share 13.3-inch displays, long battery life, and slim design\n\nPort selection includes Thunderbolt 4, HDMI, microSD, and Ethernet\n\nDynabook has launched a trio of laptops in Japan, all weighing just 849g (about 1.87 pounds). The new lineup includes the G8, G6, and GS series, each of which are slightly different but share the same ultra-portability.\n\nThe G8 series is the flagship option and is powered by Intel’s Core Ultra 7 or Ultra 5 processors, paired with 16GB of memory and a 512GB SSD.\n\nThis model comes with a 13.3-inch WUXGA non-glare display, promising wide viewing angles and high color reproduction.\n\nSame, but different\n\nSecurity features include facial recognition, along with a TPM chip and password protection.\n\nThe G6 comes with Intel’s Core Ultra 5 processor. Like the G8, it has 16GB of memory and a 512GB SSD, plus the same 13.3-inch screen.\n\nThe G6 also includes facial recognition and a similar port layout, keeping the weight to the same 849g.\n\nThe GS series, introduced as the standard model, uses Intel’s Core Ultra 5 with 16GB of memory but pairs it with a smaller 256GB SSD.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nWhile it shares the same 13.3-inch WUXGA panel and 849g weight, the GS replaces facial recognition with a fingerprint sensor.\n\nBattery performance is consistent across the range, with about 11 hours during video playback and up to 28 hours when idle.\n\nAll three models share the same port layout. On the right side, users get a microSD card slot, two USB 3.2 Gen1 Type-A connectors, two Thunderbolt 4 USB-C ports with power delivery, a LAN port, and a security lock slot.\n\nOn the left side, there’s another Thunderbolt 4 USB-C port, a microphone and headphone combo jack, an HDMI output, and a third USB 3.2 Gen1 Type-A port.\n\nAll three models support Wi-Fi 6E and Bluetooth 5.3 and come with a 2MP webcam featuring a physical shutter for privacy.\n\nBundled software includes Microsoft 365 Basic and Office Home & Business 2024. The systems are offered in Nebula Black and Celeste Blue finishes.\n\nNo word on pricing but they are set to go on sale in Japan in the coming months.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/dynabook-just-launched-a-trio-of-laptops-each-weighing-849g-and-i-cant-believe-thats-barely-heavier-than-two-cans-of-coke",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Intel's 14nm+++ desktop CPUs are making a comeback — chipmaker inexplicably resurrects Comet Lake from five years ago with 'new' Core i5-110",
      "content": "It appears that Intel is experiencing a sense of nostalgia, as the chipmaker (via momomo_us) has introduced the Core i5-110 processor, based on Comet Lake. Comet Lake is a stroll down memory lane for many of us, as these 14nm+++ chips were introduced around half a decade ago.\n\nWhile the Core i5-110 is clearly a Comet Lake part, Intel markets the new chip under the Core Series 1 moniker. The Core Series 1 mainly comprises mobile and embedded Raptor Lake chips. However, Intel has used the series to mask some of its rebadged processors, such as the Core 5 120, which the chipmaker also silently launched. Therefore, the Core i5-110 is the second desktop chip (that we know of) that Intel has added to the Core Series 1 family.\n\nThe Core i5-110, launched in the third quarter of this year, features a six-core, 12-thread configuration with a maximum of 12MB of L3 cache. It features a base clock speed of 2.9 GHz, with a turbo boost clock speed that reaches up to 4.3 GHz. Comet Lake is built on the Skylake microarchitecture, and these processors are produced using Intel's 14nm+++ process technology.\n\nIntel Core i5-110 Specifications\n\nSwipe to scroll horizontally Processor Cores / Threads Base / Boost Clock (GHz) L3 Cache (MB) TDP (W) MSRP Core i5-110 6 / 12 2.9 / 4.3 12 65 $200 Core i5-10400 6 / 12 2.9 / 4.3 12 65 $200 - $210\n\nThe Core i5-110 is a rebadge of the previous Core i5-10400, launched in 2020. The specifications are identical for the two 14nm+++ chips in every way. Both are 65W processors with an Intel UHD Graphics 630 engine that operates between 350 MHz and 1.1 GHz, supporting up to 128GB of DDR4-2666 memory.\n\nThe Core i5-110 is a desktop processor, meaning it is compatible with an LGA1200 socket and either an Intel 400-series or 500-series motherboard. However, Intel has introduced two new sockets since LGA1200, so it's a mystery just how many consumers still have a LGA1200 motherboard that can accommodate the Core i5-110.\n\nDespite the Core i5-110 being a blatant rebrand, Intel is still charging the same price for the chip as it was when it launched five years ago. The RCP (Recommended Customer Price) for the Core i5-110 is $200, which falls within the same range as the Core i5-10400's $200 to $210. It's an insane price considering that 14nm+++ chips should be dirt cheap to produce by now.\n\nAt $200, the Core i5-110 is supposed to be a value processor, but it's hard to see the value in it.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFollow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/intels-14nm-desktop-cpus-are-making-a-comeback-chipmaker-inexplicably-resurrects-comet-lake-from-five-years-ago-with-new-core-i5-110",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Battlefield 6 Battle Royale details released — shaping up to be EA’s most ambitious mode yet",
      "content": "Battlefield 6 is getting a Battle Royale mode, and the first details have been released.\n\nBattlefield 6 ended its beta on a high note, drawing thousands of eager players who even queued in menus before matches went live. It went on to break 500,000 concurrent players on Steam alone — a clear sign that Battlefield is back in a big way.\n\nBut no competitive shooter launches these days, it seems, without a Battle Royale mode. Like it or not, Battlefield 6 has one, and it’s aiming to be different. I’ll personally be hoping it avoids the missteps of Splitgate 2, whose underwhelming Battle Royale pushed the game back into beta.\n\nA brutal new take on the shrinking ring\n\nBattlefield 6 will be adding a Battle Royale mode with a zero tolerance zone. (Image credit: Michael Hoglund)\n\nUnlike most Battle Royale games where the zone slowly chips away at your health, Battlefield 6 takes a far harsher approach. Traditionally, players can heal through the damage or pull off clutch plays while stuck in the zone, leading to plenty of tense moments and highlight clips. None of that will be possible here; if you touch the zone, you’re instantly eliminated.\n\nIt’s a drastic change, and honestly, I’m here for it. This approach should push players into fights faster and keep matches from dragging, solving the slow starts that often plague the genre. Call of Duty: Warzone has long struggled with players abusing the zone to win, even after multiple balance tweaks. With no way to exploit it in Battlefield 6, it’ll be fun to see just how chaotic things get.\n\nSquad-focused chaos on a massive scale\n\nLarge map combat is a staple of Battlefield already, and its Battle Royale doesn't sound like a mere clone of other popular titles. (Image credit: Electronic Arts)\n\nLike most Battle Royale games, Battlefield 6 will feature 100 players split into 25 squads of four, which is a familiar setup for the genre. What sets it apart is the return of Battlefield’s class system. Players can mix classes to build a balanced squad, or all choose the same class, but once you lock in your choice, it can’t be changed mid-match.\n\nYou won’t start empty-handed, either. Each class begins with two gadgets, and as the match progresses, you can earn XP by eliminating players or completing missions. This XP contributes to both your personal level, unlocking new traits that enhance your chosen class mid-match.\n\nOne example given is the Assault class gaining faster armor plate equip speed, giving them a slight edge in fights. There’s also Intel cases to look out for, which provide XP to whole of your squad.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThe map, progression, loot and second changes…\n\nBattlefield 6 has really captured an audience so far, and it's not even out yet. (Image credit: Electronic Arts)\n\nIn true Battlefield 6 fashion, there’s a brand-new map built entirely around destruction, allowing its layout to shift and change between matches. Vehicles also return, ranging from fast transport options to heavily armored powerhouses that can swing the momentum of a fight.\n\nPlayers can choose from four classes — Assault, Engineer, Support, and Recon — each with distinct roles and gadgets. A training path system lets squads earn XP during matches, unlocking new traits and one-time abilities as they level up their chosen classes.\n\nThe loot system includes five weapon tiers alongside attachments, throwables, gadgets, and strike packages, which are powerful tactical rewards like air strikes that can turn the tide of battle. There’s also a second chance system, with the Support class able to revive teammates and a redeploy feature that lets players return after being eliminated or caught in the zone.\n\nLeaks, launch hopes, and lessons from the past\n\nThe Battle Royale test will be under NDA, but it shouldn't be too long before we see more from it. (Image credit: Electronic Arts)\n\nBattlefield Labs is currently testing the mode, though it’s all under NDA, and some early leaks have already surfaced — something EA is no doubt unhappy about.\n\nThere aren’t many official details yet, and I’ve tried to highlight the most important ones here, but you can find more information in EA's blog post.\n\nThe mode sounds like a genuine breath of fresh air for the genre, and I’m hoping it launches alongside Battlefield 6 in October 2025. It’s still unclear whether it will be bundled with the main game or released as a free-to-play standalone, but hopefully it avoids the fate of Battlefield V and Battlefield 2042, whose Battle Royale attempts were poorly received and quickly abandoned.\n\nI have high hopes for Battlefield, and I want Call of Duty to finally have real competition again. My only concern is that the mode could become the main focus, pulling attention away from the traditional multiplayer experience that made the series great in the first place.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/gaming/battlefield-6-battle-royale-details-released-shaping-up-to-be-eas-most-ambitious-mode-yet",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "This Lenovo Thinkpad laptop is farming pure boardroom aura",
      "content": "The Lenovo Thinkpad X9 Aura Edition is a reinvention of a line going back three decades, and one which is carried out with aplomb. It has enough power for most tasks, a great display, a brilliant keyboard and can be carried anywhere. Plus, it has the battery to make it through a full day of work. But for a better port selection, it would be a slam dunk. If you need a machine to satisfy all of your office needs, you should look no further.\n\nWhy you can trust Creative Bloq Our expert reviewers spend hours testing and comparing products and services so you can choose the best for you. Find out more about how we test.\n\n(Image credit: Future/Sean Cameron)\n\nThe laptop as a form factor has been bound by two dreams: one for power, the other for portability. Neither of them is mutually exclusive, but typically a machine can’t be one and also the other.\n\nAs a designer, one’s job isn’t to pursue philosophical ideals, however, but to render into reality what will best sell to a certain audience. And if we consider the audience as a busy, on-the-go business professional, portability will be the possibility that becomes a priority.\n\nThere are plenty of examples of machines which achieve a light weight, but that isn’t enough to be premium. Vision is needed, and more, a certain je ne sais quoi, without getting too arty farty. Enter the Thinkpad X9 Aura edition, the latest entry by Lenovo in the venerable line of business machines, which looks to make productivity sexy.\n\nIt comes with an all-metal build, a fancy OLED display, advanced biometrics, a new Intel processor, a touted keyboard and more. Perhaps most importantly, distressingly for some, there’s no trackpad nub, no hallmark to laptops from 30 years ago, a sign of a machine with its eyes firmly on the future.\n\nBut as ever, the competition in this space is tight, does the X9 Aura do enough to stand out among, say, laptops for Photoshop?\n\nRead on for our full review.\n\nSwipe to scroll horizontally Specs CPU: Intel Core Ultra 7 258V vPro NPU: Intel NPU Graphics: Intel Arc 140V GPU Memory: 32GB Storage: 1TB SSD Screen size: 14 inch Screen type: OLED Resolution: 2880 x 1800 Refresh rate: 120Hz Colour gamut (measured): 100% DCI-P3 Brightness (measured): 500 nits Ports: 2x Thunderbolt 4 USB-C, 1x HDMI 2.1, Audio Combo Jack Wireless connectivity: Wi-Fi 7, Bluetooth 5.4 Dimensions: 311.2 × 216.7 × 17.95 mm Weight: 1.141kg\n\n(Image credit: Future/Sean Cameron)\n\nDesign, build and display\n\n• Thin and light\n\n• Brilliant 3K display\n\nGet the Creative Bloq Newsletter Daily design news, reviews, how-tos and more, as picked by the editors. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nWith editing, the old maxim is that you know you’re done when there’s nothing left to take away. When it comes to design, things aren’t so straightforward; weight needs to be kept to a minimum, but that can’t come at too much of a sacrifice to power or function.\n\nThat mission in mind, the engineers at Lenovo have clearly been busy, as the X9 Aura makes for a great first impression. The grey colourway might not be designed to set pulses racing, but it catches the eye and is definitely office appropriate; this is one meant to be wielded by executives.\n\nAt 17mm, it is thin, and weighing 1.1kg, it can easily be lifted with one hand. In a backpack, it feels as though it is barely there at all. If you are a student or someone who commutes with their laptop regularly, this should definitely be on your list.\n\nThat’s not least because it also sports MIL standard protection, as has become common for the ThinkPad line. This isn’t to say that it can survive a nuclear explosion, but at a time when most laptops come without sturdiness certifications, the fact that this one can handle a little rough-housing is a differentiating factor.\n\nThe screen can be raised one-handed, and when you do, you’ll see there’s a notch, but not the kind you’ll find on a MacBook. Where those eat up screen space, this one extends into the air above the display, housing the necessary infrared sensors for Windows Hello. It also holds a slightly above-average quality webcam, in all, a sensible use of space.\n\nContinuing to the keyboard, here we find the typical ThinkPad brilliance. Though there’s no trackpad nub in the centre, this is a supremely well-considered option. There’s a nice amount of travel, the keys are well-sized and spaced, and it was easy to build up to a comfortable, fast typing speed with relatively little lead-in time. Truly, it’s a class act of a keyboard.\n\nThankfully, the display is just the same. At over 3K in resolution, everything is pin-sharp given the relatively dinky dimensions of the panel, and it supports full HDR and is Dolby Vision certified. It’s a very nice option for watching video, and the 120Hz refresh rate keeps the interface feeling smooth and fresh.\n\nPeak brightness was also just about enough to battle sunlight, high praise for a laptop, though the slightly glossy nature of the panel means that reflections were sometimes an issue.\n\nWith 100% coverage of the DCI-P3 colour space, it will also suffice for photo work for some, though as ever, if you have specific needs in this area, you’ll be best with a calibrated external monitor.\n\nOne slight sore point, though to be expected on a thin and light, there’s not the best port selection. There are two USB-C slots with support for Thunderbolt 4, a 3.5mm headphone jack and an HDMI port. If you have specific needs, a dongle will be a necessity.\n\nDesign score: 5/5\n\nFeatures\n\n• Bluetooth 5.4 and WiFi 7\n\n• AI inclusions of questionable utility\n\nAs it is 2025, and AI is a mandatory inclusion with every product release, here we can see that it is a headlining ‘feature’ of the X9.\n\nSo there’s a host of inclusions to burnish the ‘AI’ credentials of the ThinkPad. You’ll find camera enhancements to blur your background, intelligent noise suppression for video calls and more. These are typically built into the likes of Teams, but having them more widely across the system could prove to be useful for some.\n\nThere are security optimisations too, which may prove to be useful in a pinch but will be ignored by most. And that sums up the inclusion of AI features on this device. Occasionally, you’ll find something that will prove to be momentarily useful, then the novelty wears off, and its existence is forgotten.\n\nBeyond that, we can see a bevvy of future-proof connectivity options included, such as WiFi 7 and Bluetooth 5.4, which is always a positive. And lastly, there are two speakers tucked into the hinge of the screen, producing a sound which isn’t quite room-filling but certainly good enough for jamming out to while typing up a storm.\n\nFeatures score: 3/5\n\n(Image credit: Future/Sean Cameron)\n\nBenchmark scoring\n\nWe test every one of our laptops using the same benchmarking software suite to give you a thorough overview of its suitability for creatives of all disciplines and levels. This includes:\n\n• Geekbench: Tests the CPU for single-core and multi-core power, and the GPU for the system's potential for gaming, image processing, or video editing. Geekbench AI tests the CPU and GPU on a variety of AI-powered and AI-boosted tasks.\n\n• Cinebench: Tests the CPU and GPU's ability to run 3D software such as Cinema 4D and Redshift.\n\n• UL Procyon: Uses UL Solutions' Procyon software suite to test the system's ability for AI image generation in Stable Diffusion, its Microsoft Office performance and its battery life in a looping video test.\n\n• Topaz Video AI: We use Topaz Video AI to test the system's ability to upscale video and convert video to slow-motion.\n\n• PugetBench for Creators: We use the PugetBench for Creators benchmarking suite to test the system's ability to run several key tasks in Photoshop and Adobe Premiere Pro, as well as its performance when encoding/transcoding video.\n\n• ON1 Resize AI: Tests the system's ability to resize 5 photos to 200% in a batch process. We take the total time taken to resize the images and divide by 5.\n\nPerformance\n\nIf the main benefit of a lighter laptop is portability, the main drawback is power. The smaller the chipset, the smaller the power draw, and the less the power, is the usual calculation applied. But some, especially from the ARM side, have tried hard to counter that narrative, and now Intel has joined the bandwagon. The X9 Aura comes running the latest Core 7 Ultra chip, which promises power efficiency, near instant wake-up and enough oomph to run powerful and demanding programmes. It comes with 32GB of RAM by default and a 1TB SSD to boot, so how does it fare in practice?\n\nAs you might expect, basic tasks like navigating through the slightly infuriating Windows 11 are carried out without a hitch. As is everything from word processing to browsing. There’s not quite the blazing single-core performance of Apple chips, but you’ll certainly not notice any slowdowns.\n\nThe picture then begins to turn when switching to more demanding applications.\n\nStarting with a game, on the Cyberpunk 2077 benchmark, with medium presets, the machine achieved a stable 18fps framerate. As might be expected, this means that if you want to play the latest games, you would be best to look elsewhere.\n\nIt handled lower to medium intensity games and older titles with aplomb, however. And a benefit of the Intel chip is the X86 architecture, meaning that over the Snapdragon competition, there were no compatibility issues.\n\nIn the likes of Geekbench 6, this is borne out, with a single-core score of 2684, keeping up with the likes of more powerful, and power-hungry, H series chips from Intel, though definitely not coming close in multi-core configurations.\n\nWith a score of 6015 overall in Pugetbench Photoshop, we can see that for more CPU-intensive work, the Aura copes well. It’s when the work relies on the GPU, an integrated effort, that things become more complex. While the Aura is capable of tasks such as video editing, it takes a while to do so and gets hot in the process. Lastly, coming to AI workloads, it works surprisingly well, but again, it won’t match a device running a dedicated GPU.\n\nPerformance score: 4/5\n\nPrice\n\nThe X9 Aura is priced starting at £1,300, which gets you a 3K display and all the mod cons, including 32GB of RAM. That puts it right up against several options from Apple and stands it in relatively good stead.\n\n(Image credit: Future/Sean Cameron)\n\nWho is it for?\n\nIf you travel regularly, or have the general need to be mobile, the Lenovo Thinkpad X9 Aura Edition will be of great interest to you. With brilliant ergonomics, a nice display, a great keyboard and plenty of power, it will be able to meet the needs of most professionals. If you want a potent blend of power and portability, this is your bag.\n\nSwipe to scroll horizontally Attributes Comment Rating Design Svelte, comfortable and stylish 5/5 Features Lacks ports but good wireless connectivity options 4/5 Performance Surprisingly powerful 4/5 Value Well priced against MacBook competition 4/5\n\nAlso consider\n\n(Image credit: Apple)\n\nApple MacBook Pro 14 (M4, 2024)\n\nThe MacBook Pro 14 has a few advantages over the Lenovo. It has a longer period of support, an OS that some prefer, better battery life and improved GPU performance. However the Aura holds its own with a pleasant display, still good battery life and a more robust design.\n\n(Image credit: Apple)\n\nMacBook Air 13 (2024)\n\nThe MacBook Air presents an interesting option. In its cheapest configuration it costs nearly £300 less than the Aura, and offers a lot of the same features, along with a competitive RAM allocation. Whether it appeals to you will largely be a matter of whether you need to complete video work, in which case the Mac might be more competitive, and of course where you sit on MacOS vs Windows.\n\n(Image credit: Future)\n\nAsus ProArt PX13\n\nMaybe you need power and mobility, should that be the case then maybe the Asus ProArt PX13 is the machine for you. At 13 inches it may be small, but that also means it is easy to lug around. It’s also possessed of a GeForce RTX 4070 so can game, and make short work of many creative tasks. It can bend too, boasting a tent mode, and with prices on sale starting at £1,899.99, it is at least worth a look in. It is a lot more expensive, but with that spend comes extra flexibility.\n\nFull verdict\n\nThe Lenovo Thinkpad X9 14 Aura Edition is a well-honed laptop clearly targeted at the business professional. It has a great display, a wonderful keyboard, is eminently portable and will fit into almost any workflow, provided said workflow doesn’t also require a GPU. It’s about as close an answer Windows has to the MacBook Air, which is no small praise.",
      "source": "Creative Bloq",
      "url": "https://www.creativebloq.com/tech/laptops/this-lenovo-thinkpad-laptop-is-farming-pure-boardroom-aura",
      "timestamp": "2025-09-11"
    },
    {
      "headline": "Intel Talent Bleed Continues",
      "content": "Intel's long-time Xeon chief architect Ronak Singhal is leaving the company after nearly 30 years , marking yet another high-profile departure amid Intel's leadership churn and intensifying competition from AMD and Arm-based cloud CPUs. The Register reports:",
      "source": "Slashdot.org",
      "url": "https://slashdot.org/story/25/09/12/2136201/intel-talent-bleed-continues",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Borderlands 4 Dev Gearbox Asks PC Gamers to Keep Playing for at Least 15 Minutes After They Tweak Settings to See How Performance Has Changed, as Negative Steam Reviews Pile Up",
      "content": "Borderlands 4 has launched on Steam to big concurrent player numbers, but the release was marred by complaints about PC performance that have resulted in a ‘mixed’ user review rating on Valve’s platform.\n\nBorderlands 4 peaked at 207,479 concurrent player numbers on Steam yesterday, September 11, which was significantly higher than any previous Borderlands before it. However, the game launched to ‘mostly negative’ Steam reviews over performance issues and crashing, before recovering overnight to ‘mixed.’\n\nThe complaints revolve around poor performance even on high powered PCs, with some affected by crashing that makes the game difficult to even start.\n\n“Terrible optimization. Another Unreal Engine 5 casualty. Not worth buying in its current state unless you have a NASA PC,” said one person in a negative review.\n\n“Terrible, terrible performance. Worst I've ever seen. Turned it down to Low graphics presets and couldn't hit 60 FPS, even with FSR upscaling on my RX 6900 XT,” said another.\n\nIn response, Gearbox posted a Borderlands 4 Nvidia Optimization guide on Steam, advising players how to optimize their graphics settings for “better performance and framerates” on PC with the Nvidia app.\n\n“As PC gamers begin their Vault-hunting journeys in Borderlands 4, we've seen early feedback from the community surrounding graphics settings and how to achieve optimal performance,” Gearbox said, before outlining the “expected results” for the Borderlands 4 PC specs:\n\nMinimum PC specs - 1080p @ 30FPS with Low Preset settings\n\nRecommended PC specs - 1440p @ 60FPS with Medium Preset settings\n\nGearbox then issued a piece of advice to PC gamers that to me reads like an effort to prevent players from making knee-jerk reactions to the game's performance as soon as they’ve changed their settings: “Please note that any time you change any of your graphics settings, your shaders will need to recompile. Please keep playing for at least 15 minutes to see how your PC's performance has changed.”\n\nGearbox went on to show the “Optimal Settings” charts provided by Nvidia with suggestions for which graphics settings may work best for your combination of GPU and desired display resolution. Meanwhile, it recommended using the Nvidia app to download and install Nvidia’s newest Game Ready Driver (581.29) and “optimize for your system.” If all else fails, “please contact 2K Support for direct assistance.”\n\nBorderlands 4 Review Screenshots View 159 Images\n\nGearbox and publisher 2K Games will be keen to address the performance complaints early, given the impact negative reviews on Steam can have on a video game’s success. Ahead of launch, Gearbox development chief Randy Pitchford had said the Borderlands 4 Day 1 patch “does a lot,” amid concern about the performance of the looter shooter. Pitchford had responded to concern about Borderlands 4’s pre-release performance on PC from some users on X / Twitter.\n\nDespite the Day 1 patch, playing Borderlands 4 on older hardware won't miraculously unlock \"buttery smooth performance,\" Pitchford added. It should be expected that Borderlands 4 is “unplayable” if you’re trying to use a PC below min-spec, he said, and, generally, playing new AAA games on older hardware won't achieve impressive results.\n\nHere’s Pitchford's comment in full:\n\nThe Day 1 patch does a lot! That said, the expectation for using a below min-spec machine should be that the game is unplayable. That the game runs at all on your system is a miracle. That you can get 55 - 60 fps out of heavy combat is actually incredible given how the engine and what's going on under the hood. Your specification doesn't indicate if you're on SDD or HDD, but that could also explain some of the hitching. It's a big, bold, new, seamless world and I'm sorry to say that older hardware may not provide buttery smooth performance for the latest gen AAA games, as has always been the case since the dawn of PC gaming.\n\nAs a reminder, here are Borderlands 4’s PC specs:\n\nBorderlands 4 System Requirements:\n\nMinimum:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-9700 / AMD Ryzen 7 2700X\n\nMemory: 16 GB RAM\n\nGraphics: NVIDIA GeForce RTX 2070 / AMD Radeon RX 5700 XT / Intel Arc A580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. Requires 8 CPU Cores for processor. Requires 8 GB VRAM for graphics. SSD storage required\n\nRecommended:\n\nRequires a 64-bit processor and operating system\n\nOS: Windows 10 / Windows 11\n\nProcessor: Intel Core i7-12700 / AMD Ryzen 7 5800X\n\nMemory: 32 GB RAM\n\nGraphics: NVIDIA GeForce RTX 3080 / AMD Radeon RX 6800 XT / Intel Arc B580\n\nStorage: 100 GB available space\n\nAdditional Notes: Requires a 64-bit processor and operating system. SSD storage required\n\nIf you are delving into Borderlands 4 don't go without our updated hourly SHiFT codes list. We've also got a huge interactive map ready to go and a badass Borderlands 4 planner tool courtesy of our buds at Maxroll. Plus check out our expert players' choices for which character to choose (no one agreed).\n\nWesley is Director, News at IGN. Find him on Twitter at @wyp100. You can reach Wesley at wesley_yinpoole@ign.com or confidentially at wyp100@proton.me.",
      "source": "IGN",
      "url": "https://www.ign.com/articles/borderlands-4-dev-gearbox-asks-pc-gamers-to-keep-playing-for-at-least-15-minutes-after-they-tweak-settings-to-see-how-performance-has-changed-as-negative-steam-reviews-pile-up",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "HP 17.3″ Laptop Bundle (32GB RAM, 1TB SSD) Is Almost 80% Off, Now Way Cheaper Than iPad Pro M4 With Less Storage",
      "content": "The Fall semester has already started for college students, so why haven’t you gotten yourself a laptop yet? You may not need it for Syllabus week, but soon you’ll be sent home with more homework than you can imagine. Get a computer that can handle it without completely depleting your monthly budget. Right now, this HP student laptop is down 77% at Amazon. It’s list price is $2,800, but the deal is bringing the price to just $645. That’s a difference of $2,154.\n\nOkay, hey now. That over two thousand dollar discount can’t be real right? Well, kind of. If we take a look at the price history of this item, we’ll see it’s only existed on Amazon since June of this year. After a couple weeks, it immediately shot down in price by roughly as much as it has now (mostly around $800). Since then, it’s been back and forth from a crazy discount like this and its full price, but never back up for more than several days at a time.\n\nSee at Amazon\n\nLooking at the specs, the laptop is pretty good—but not nearly-three-thousand-dollars-good. It’s rocking an Intel Core i3 processor, which is fine. It does come with 32GB of RAM and 1TB of internal storage which is really good, but not pushing the starting price up that much.\n\nSo what gives? I’ll tell you. Some Amazon sellers will try to give the illusion you’re getting a better deal than you are. That starting price is just made up. The discounted rate is the real value of the laptop. But now if we’re looking at that, this laptop had spent most of the Summer at around $800. Now that school has started, it’s come down to its new lowest price of $646. For this reason, really we can say this HP laptop is on sale for $154 off. That’s not bad!\n\nThe HP laptop has a nice and large 17.3-inch display. This is great not just for getting schoolwork done, but if you’re in the dorms, you might end up watching a lot of your shows and movies from it too. Good to have a sizeable screen for that. Of course, you can always connect it to a TV or larger display using the HDMI 1.4 port.\n\nWhat Else Your Getting\n\nOther ports include two USB-A slots, one USB-C, and a good ol’ headphone/mic jack. The HP laptop also supports Wi-Fi 6 as well as Bluetooth 5.0 to easily pair wirelessly to some of your accessories.\n\nSpeaking of accessories, the laptop comes with a number of them as a bonus. You get a wireless mouse, and external CD/DVD drive, a full 1TB external hard drive, along with some webcam covers, dust plugs, and a cleaning cloth. All that plus an HP laptop that comes preinstalled with Windows 11 Pro for $646? Sounds like a pretty good deal after all.\n\nSee at Amazon",
      "source": "Kotaku",
      "url": "https://kotaku.com/hp-17-3-laptop-bundle-32gb-ram-1tb-ssd-is-almost-80-off-now-way-cheaper-than-ipad-pro-m4-with-less-storage-2000624999",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Intel resurrects ancient 10th-gen processor for ‘new’ Core i5",
      "content": "Intel would like you to know about a new processor it’s selling. It’s a 6-core, 12-thread, 14-nanometer design that draws 65 watts and runs at 2.9Ghz, called the Core i5-110. If you watch Intel processors like a hawk, that might sound familiar: The specs appear to be identical to the Core i5-10400, a Comet Lake CPU that first debuted in 2020.\n\nIn product terms this is what’s known as a “rebadge,” and it’s hardly unprecedented for both regular chips and other designs. But given the pace of CPU tech, and the issues Intel is facing at the moment, this particular example might rub consumers the wrong way. Assuming they notice, of course — the entire point of a rebadge is getting products out there without making much of a splash. The new listing was spotted by Twitter poster @momomo_US.\n\nDisney/Intel\n\nIntel is calling this a “Core™ processors (Series 1)” though in its defense, it does identify it as “products formerly Comet Lake in the listing. One thing that hasn’t changed is the price. At $200 USD, the i5-110 costs exactly the same as the Core i5-10400 did five years ago. Even if you think that’s a good deal (it’s pretty milquetoast), tracking down the DDR4 RAM to go with it in 2025 might just cancel out any budget plans.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2907842/intel-resurrects-ancient-10th-gen-processor-for-new-core-i5.html",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "New Spectre-based CPU vulnerability allows guests to steal sensitive data from the cloud",
      "content": "ETH Zurich researchers found a new Spectre-BTI attack called VMSCAPE that lets a VM steal host data\n\nIt affects cloud setups using KVM/QEMU on AMD and Intel CPUs, bypassing existing defenses\n\nThey propose flushing the branch predictor on VMEXIT as a low-cost fix\n\nIf Ghostbusters taught us anything, it’s that spectres are notoriously difficult to get rid of.\n\nSecurity researchers from the Swiss public university, ETH Zurich, recently discovered a new Spectre-BTI (Branch Target Injection) attack that allows a malicious virtual machine (VM) to leak sensitive data from the host system, without modifying host software.\n\nThe research team - Jean-Claude Graf, Sandro Rüegge, Ali Hajiabadi, and Kaveh Razavi - conducted a systematic analysis of branch predictor isolation, targeting environments using KVM/QEMU virtualization on AMD Zen 4 and Zen 5 CPUs.\n\nFixing the flaw\n\nIn early June, they developed an exploit and named it VMSCAPE.\n\nAccording to the research paper published earlier this week, VMSCAPE is proof that default mitigations (hardware and software defenses that were previously considered sufficient for speculative execution attacks such as Spectre) are not enough to prevent speculative execution attacks across VM boundaries, and that secrets like disk encryption keys can be leaked in real-world cloud setups.\n\nAll cloud providers running virtualized workloads on vulnerable CPUs using KVM/QEMU are affected by the bug, the researchers further explained, which includes AMD Zen 1-5, and Intel’s Coffee Lake chips. KVM/QEMU is a powerful virtualization stack commonly used in Linux-based cloud environments.\n\nThe bug is now tracked as CVE-2025-40300, but the severity score has not yet been determined.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nChipmakers are already on the move, as well. An AMD spokesperson told The Register that the company is preparing a security brief, as well as a software fix.\n\nAn Intel representative told the same publication that existing mitigations can be used to address this flaw. “Linux mitigations are expected to be available on the VMSCAPE public disclosure date, and a CVE for this issue will be assigned by Linux,\" they added.\n\nThe paper’s authors propose flushing the CPU’s branch predictor using IBPB on VMEXIT as a mitigation for VMSCAPE, as this prevents a malicious guest VM from influencing speculative execution paths in the host. They also stressed that the tests showed negligible performance overhead, and that the fix was practical for deployment.\n\nVia The Register",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/security/new-spectre-based-cpu-vulnerability-allows-guests-to-steal-sensitive-data-from-the-cloud",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Intel Xeon chief architect leaves just 8 months after appointment — Ronak Singhal latest departure in ongoing shakeup",
      "content": "Ronak Singhal, Intel senior fellow and chief architect of Xeon products, will leave the company by the end of the month, as first reported by CRN and confirmed to Tom's Hardware. Singhal appears to be the second chief architect of Xeon products to depart the company in less than a year. His departure emphasizes the deep restructuring under chief executive Lip-Bu Tan, though it remains to be seen who will be responsible for defining the future of Xeon CPUs.\n\nSinghal's departure from Intel just eight months after he succeeded Sailesh Kottapalli as chief architect of Xeon products highlights the turmoil at Intel in general and the company's Data Center Group in particular. Sailesh Kottapalli left in January to join Qualcomm's renewed server CPU initiative, whereas Justin Hotard, general manager of DCG, left the company to become chief executive of Nokia in February. Hotard succeeded Sandra Riviera in early 2024 as Riviera chose to become chief executive of Altera, which was spun off later that year (Riviera was replaced this August). A few days ago, Intel appointed Kevork Kechichian as the head of DCG.\n\nRonak Singhal joined Intel in 1997, right after graduating from Carnegie Mellon University. His most recent role included responsibility for overall Xeon CPU strategy, roadmap execution, and platform-level integration. This included not only chip design but also adjacent technologies such as memory systems, platform security features, and AI acceleration. Singhal was the second chief architect of Xeon products (after Kottapalli) in Intel's history. It is unclear whether he has influenced Intel's Xeon roadmap significantly.\n\nThroughout his 28 years at Intel, Singhal has shaped the architectural direction of several critical product generations. In the late 1990s, he was involved in Pentium 4 validation, and then he led performance optimization for Nehalem and Westmere. He also oversaw the development of Haswell and Broadwell server CPUs. In general, he was quite a cross-disciplinary architect deeply embedded in Intel products as his technical oversight extended beyond cores to encompass CPU microarchitecture, memory systems, platform security, and eventually AI acceleration. Singhal has been granted 30 patents covering CPU architectures.\n\nThe leadership transition aligns with Lip-Bu Tan's strategy to revamp the whole company and Intel's Data Center Group. To accelerate changes, Tan appointed former Arm executive Kevork Kechichian as executive VP and GM of the group. He also shifted accelerators development to a Sachin Katti-led AI subdivision, making CPUs the primary focus within the data center unit.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/pc-components/cpus/intel-xeon-chief-architect-leaves-just-8-months-after-appointment-ronak-singhal-latest-departure-in-ongoing-shakeup",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Get this Ryzen 7 mini PC with 32GB RAM for a crazy low $339",
      "content": "Nowadays, your home or office setup can feature a mini PC without issue because these things aren’t just powerful, but also affordable. The Beelink SER5 Max mini PC is only $339 right now, which is 24 percent off its MSRP at Amazon.\n\nThis tiny device runs on an AMD Ryzen 7 6800H CPU and an amazing 32GB LPDDR5 RAM, which means this thing’ll be uber fast, handling all the tasks you need to get done throughout the day. The 1TB SSD will add plenty of storage space for apps and files, while also booting your system in a blink.\n\nThis Beelink SER5 Max mini PC also supports triple 4K monitors, so you get to multitask like never before.\n\nIf you want a different configuration, there are plenty of mini PCs on sale these days. Here are some alternatives:\n\nFor $319 (20% off) , you can get the Beelink EQi12 with an Intel i5 CPU, 16GB DDR4, a 500GB SSD, and dual screen support.\n\n, you can get the Beelink EQi12 with an Intel i5 CPU, 16GB DDR4, a 500GB SSD, and dual screen support. If you’d rather get a Ryzen system, the Acemagic K1 is down to $315 (28% off) , featuring an AMD Ryzen 7 CPU, 32GB DDR4, a 1TB SSD, and triple display support.\n\n, featuring an AMD Ryzen 7 CPU, 32GB DDR4, a 1TB SSD, and triple display support. If you want something even cheaper, the Acemagic V1 is down to $188.1 (41% off) , featuring an Intel Twin Lake N150 CPU, 16GB DDR4 RAM, and 1TB SSD, as well as dual display support.\n\n, featuring an Intel Twin Lake N150 CPU, 16GB DDR4 RAM, and 1TB SSD, as well as dual display support. The Kamrui GK3Plus is another good option, featuring an Alder Lake N95 CPU, 16GB RAM, and a 512GB SSD, as well as triple-screen support. This one’s only $160, which is 20% under its MSRP, but its CPU will be significantly slower than the Ryzen found in the Beelink SER5 Max.\n\nAll of these are good options, but it does depend on what type of system you prefer and just how much power you’ll need to get your tasks done.\n\nThe Beelink SER5 Max has a fantastic discount, and getting this speedy configuration for $339 is a great deal.\n\nGet a powerful mini PC for $339",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2898428/get-this-ryzen-7-mini-pc-with-32gb-ram-for-a-crazy-low-339.html",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Linux 6.17 Fix Lands To Address Regression With \"Serious Breakage\" In Hibernation",
      "content": "\"Commit 12ffc3b1513e (\"PM: Restrict swap use to later in the suspend sequence\") incorrectly removed a pm_restrict_gfp_mask() call from hibernation_snapshot(), so memory allocations involving swap are not prevented from being carried out in this code path any more which may lead to serious breakage.\n\n\n\nThe symptoms of such breakage have become visible after adding a shrink_shmem_memory() call to hibernation_snapshot() in commit 2640e819474f (\"PM: hibernate: shrink shmem pages after dev_pm_ops.prepare()\") which caused this problem to be much more likely to manifest itself.\n\n\n\nHowever, since commit 2640e819474f was initially present in the DRM tree that did not include commit 12ffc3b1513e, the symptoms of this issue were not visible until merge commit 260f6f4fda93 (\"Merge tag 'drm-next-2025-07-30' of https://gitlab.freedesktop.org/drm/kernel\") that exposed it through an entirely reasonable merge conflict resolution.\"\n\n\"The issue here is that as of 6.17.0-rc1, running hibernate (disk) more than 7 times causes instability on most machines. The hibernate can be run with /sys/power/disk set to any value. The issue is the hibernate image itself becoming corrupted. The instability appears in user space as the timeout and failure of any or all of these commands:\n\n\n\nsudo systemctl is-active systemd-journald\n\nsudo shutdown\n\nsudo reboot\n\nsudo -i exit\n\n\n\nThe system cannot be soft shutdown or rebooted, it has to be power cycled. I believe the init process memory itself is corrupted and thus anything that goes through the init process times out.\"\n\nThis week's round of power management fixes for the in-development Linux 6.17 kernel are on the more notable side with fixes for both AMD and Intel P-State drivers plus addressing a system hibernation issue that could lead to \"serious breakage\" and stems from a Linux 6.16 regression.Intel engineer and power management subsystem maintainer Rafael Wysocki kicked off this week's power management pull request by noting a fix for a \"nasty hibernation regression introduced during the 6.16 cycle.\" The fix elaborates on that nasty regression and ends up being a one-liner to resolve. Wysocki explained in that commit:The issue was brought to light a few days ago in a bug report In addition to fixing that hibernation regression, there are also a few fixes too for the Intel and AMD P-State CPU frequency scaling drivers:- Fix setting of CPPC.min_perf in the active mode with performance governor in the amd-pstate driver to restore its expected behavior changed recently (Gautham Shenoy)- Avoid mistakenly setting EPP to 0 in the amd-pstate driver after system resume as a result of recent code changes (Mario Limonciello)\"Those fixes in the pull request were merged on Thursday ahead of the Linux 6.17-rc6 release coming on Sunday.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.17-PM-Hibernation-FIxes",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "Intel has rebranded the dusty old Core i5 10400 as the Core i5 110, presumably because it found a bunch of them tucked down the back of the couch",
      "content": "Ah, you know how it is. You start looking for a pen, or a sticky note, or maybe some spare change, and suddenly you start finding things you lost years ago. In Intel's case, that appears to be a load of Comet Lake-era Core i5 10400 CPUs, but not to worry—it's simply rebranded them as Core i5 110 CPUs, to sync up with its relentlessly-confusing modern chip naming schemes. Oh, and under code name, it's listed as \"products formerly known as Comet Lake.\" How very Prince.\n\nYes, you too could be the proud owner of a five-year-old six-core, 12-thread CPU with a max boost clock of 4.3 GHz and 12 whole MB of L3 cache—albeit with a fancy new name (via Tom's Hardware). To be honest, it's probably still a reasonably decent CPU in many scenarios, but you can't deny that this sort of rebranding makes things even more complicated for your average user trying to decide on their next upgrade.\n\nThat's not to mention that the Core i5 110 is an LGA 1200 socket chip, which is a whole two generations behind. You can still pick up the odd LGA 1200 motherboard if you trawl the listings, but if you ask me it's a pretty damning indictment of both how old this chip seems in 2025, and how Intel hasn't exactly made it easy for would-be upgraders with its socket-switching since 2020, when this chip was first released.\n\nYou'll be pairing it with DDR4, of course, as that's the fastest memory it supports, and you'll be paying $200 according to the MSRP—although the original Core i5 10400 is currently retailing for $130 at Amazon.\n\nYep, that sure is a significant amount of cash for a chip that's been thoroughly outclassed by more recent (and sometimes cheaper) offerings, like the Core i5 13400F. I suppose those of you looking for an upgrade on the LGA 1200 socket might be interested, but for that sort of cash I'd seriously suggest saving up for a more recent motherboard and CPU bundle instead.\n\n(Image credit: Future)\n\nOr taking a look at the used market, for that matter, where Comet Lake-era chips are often found for very sensible cash. Regardless, Intel's naming scheme these days is confusing enough that even we on the PC Gamer hardware team find ourselves occasionally stumped as to which chip architecture falls under which brand.\n\nSay you buy one of Intel's Series 2 chips, what does that get you? It could be Intel Core Ultra 9 285K, a desktop chip forged out of the Arrow Lake architecture. Or the Intel Core Ultra 9 285HX, an Arrow Lake mobile chip. Or the entirely different Intel Core Ultra 288V, a Lunar Lake mobile chip. Or even an Intel Core 210H, a Raptor Lake rehash for laptops. And you still have some Series 1 chips hanging around, as this latest Comet Lake drop shows, though Series 1 could also mean Meteor Lake or even Raptor Lake chips. The differences in age/ability/power/price between all of these chips is potentially huge.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nI think. I'll be honest, I still consult Jacob's chart in this article from time to time when I get confused, and I still have to look up individual chips to figure out which architecture they're using on the regular. And I do this for a living. As a consumer? All I'll say is check, double check, and check again to make sure you're buying the correct chip for your setup.\n\nHonestly, I need a lie down. To be fair to Intel, it's biggest competitor, AMD, also has very confusing naming schemes and the odd bit of dodgy branding, ala the debacle with the Ryzen 5000 XT-series. Anyone got a decoder wheel I could use? All this is giving me a serious headache.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/processors/intel-has-rebranded-the-dusty-old-core-i5-10400-as-the-core-i5-110-presumably-because-it-found-a-bunch-of-them-tucked-down-the-back-of-the-couch/",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "When it comes to Borderlands 4 and its '8 cores or equivalent' requirement, it's actually core quality, not core count, that matters the most",
      "content": "In case you didn't know, because you've been living on Pluto these past few days, Borderlands 4 has launched. It's not exactly been smooth sailing for 2K Games and Gearbox Software, the publishers and developers, as the game's overall performance is rougher than the Drake Passage.\n\nTo help matters (or make things worse, depending on your point of view), 2K produced a detailed chart of what settings Nvidia GPU owners should use to get the best performance. However, most of this just involved enabling upscaling and frame generation. Borderlands 4 is just plain hard on your hardware.\n\nEspecially the CPU, it would seem, because the minimum system requirements demand an '8 core (or equivalent)' processor, citing an Intel Core i7 9700 as an example. Yesterday, I tested a very similar chip, the 9700K, in a rig with a Radeon RX 5700 XT and 1080p Low quality, and the CPU was frequently hitting 100% utilisation in the open world (see below).\n\nBut what if your gaming PC has a processor with fewer cores, a Core i5 or a Ryzen 5 chip, for example? Does that mean you're going to be in trouble? To find out, I've spent the day running a series of tests on two gaming PCs, where I've decreased the number of cores and/or threads active in the BIOS.\n\nStarting with an Intel Core Ultra 9 285K, with 48 GB of Corsair DDR5-8400 and a GeForce RTX 5080, I ran Borderlands 4 at 1080p with DLSS Performance enabled to minimise the impact of the GPU on the results. However, I did enable the Badass quality preset to ensure that the CPU was pushed as hard as possible.\n\nAs you can see, the unpopular 285K is pretty consistent, irrespective of what P- or E-cores are enabled. To be honest, the fact that the game runs as well as it does on just four P-cores (so four threads, as Arrow Lake doesn't support HyperThreading) is absolutely remarkable. Sure, the 1% low frame rate isn't great, and the game does stutter a bit more than normal, but overall not a bad showing.\n\nAs to why the performance just doesn't consistently decrease with the core count, the answer is two-fold. One, Borderlands 4 distributes its workload across a whole host of threads, and none of them are especially heavy on a single core.\n\nI used PIX on Windows to analyse the threads the game generates, and there are an awful lot of background worker threads to handle asset loading, the precompiled PSO pool, Bink (video compression), etc.\n\nIntel's Arrow Lake architecture is quite complex, as unlike previous designs, which comprised a block of P-cores topped by a block of E-core clusters, the distribution of cores in the 285K is such that disabling a couple of P- or E-cores leads to some odd behaviour on the ring bus that handles all the data traffic.\n\nBut what about a more traditional CPU design, where it's just a block of identical cores that can handle two threads apiece? To answer this question, I used an AMD Ryzen 7 9800X3D with 32 GB of DDR5-6000, and the same RTX 5080 graphics card.\n\nWell, shiver me timbers, just look at those four little cores go! Much better than four Arrow Lake P-cores, that's for sure, but don't forget that the 9800X3D houses an almighty wodge of fast L3 cache, so a handful of Zen 5 cores aren't going to be waiting much for data. What's really remarkable, though, is how little difference there is between using just four cores, four threads and eight cores, 16 threads.\n\nObviously, both CPUs are sporting the very latest architectures from AMD and Intel, and I dare say that I'd get very different results using processors from five or six years ago.\n\nI'm a bit disappointed to have not got to the bottom of why Borderlands 4 is so demanding on older CPUs, but I've not given up, and I plan to use PIX across more platforms to see just what's going on. It could simply be a case that older chips don't play ball as nicely as the latest ones do with Windows 11's thread scheduler, or it could be something that's symptomatic of Unreal Engine 5.\n\nEither way, though, where 2K Games is telling you that eight CPU cores is the minimum, I can tell you now that this is not the case, as long as you're using a relatively new six-core processor. Hurrah for small mercies, however they come.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/when-it-comes-to-borderlands-4-and-its-8-cores-or-equivalent-requirement-its-actually-core-quality-not-core-count-that-matters-the-most/",
      "timestamp": "2025-09-12"
    },
    {
      "headline": "5 reasons you need to be more careful with RAM on Ryzen",
      "content": null,
      "source": "XDA Developers",
      "url": "https://www.xda-developers.com/ryzen-memory-compatibility-stinks-but-so-does-arrow-lake/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Bring back your old Mac: 5 ways to refresh the OS on elderly Apples",
      "content": "Any day now, a new version of Apple's macOS is due to launch, and it will exclude the bulk of the Intel-powered models the company has ever sold. However, there are multiple ways to breathe new life into Macs that go back as far as 10 or even 15 years.\n\nThe Reg FOSS desk has two older Intel Macs in daily use that can't run any currently-supported version of macOS, though. Recently, we've been exploring our available options, and we've found that there are multiple potential routes to keep an old-time Mac productive.\n\nmacOS 26 \"Tahoe\" is due in a few days, and there are a whole four Intel Macs that will be able to run it: the 2019 MacBook Pro and Mac Pro, and the 2020 MacBook Pro and iMac. Those are the official models, anyway. As we covered back in 2023, the OpenCore Legacy Patcher project offers a free tool that lets you create a custom-modified macOS installer that will let you install newer versions of macOS onto Macs too old to officially support them. We reckon there's a good chance that a future update to OCLP will make more older models able to run macOS 26.\n\n\"Tahoe\" is officially the last-ever macOS for Intel hardware, though. The switch to Arm-based Apple Silicon processors is permanently closing the door on the \"Hackintosh\" world, and the world of Arm devices is so wildly heterogeneous that there's basically zero prospect of running Arm macOS on anything else. That's why there's the special Armbian distro just to make the current Linux available on Arm kit.\n\nBefore we tried to upgrade one of our daily drivers with OCLP, though, we wanted to test drive upgrading to an unsupported macOS. To this end, we recently pulled a retired MacBook out of storage. It's a 2010 13-inch MacBook Pro. The last supported macOS for this model is 10.13 \"High Sierra\", and the newest mainstream web browser for this is Firefox 115, which is the ESR release from 2023. When its successor Firefox 128 appeared, Mozilla said it would keep updating version 115 for as long as possible. As The Register reported last week, that currently means March 2026. To get to the subsequent Firefox ESR, we needed at least macOS 10.15 \"Catalina\".\n\nThis shouldn't work, but it does: macOS 10.15 running happily on a MacBook Pro from two years before Apple's cut-off - Click to enlarge\n\nThat poses a slight snag. The 2010 MBP is the only Core 2 Duo machine we've encountered that refuses memory that's faster than the 1066 MHz DDR3 SDRAM for which it's specified. It wants at least one PC3-8500 SO-DIMM, and it won't start with PC3-10600, let alone even faster. (We blame the Nvidia GeForce 320M GPU for this fussiness.) As a result, our MBP only has 6 GB of RAM. That's a snag.\n\nThe current release of OCLP is version 2.4.1 and the oldest macOS it supports is macOS 11 \"Big Sur\". Officially, this will run in 4 GB, but we suspect it might be rather sluggish. However, OCLP doesn't support Catalina.\n\nEnter the DOS dude\n\nHelp is at hand from Collin Mistr, AKA dosdude1. Among other apps, he offers a tool called macOS Catalina Patcher. It's a just-over-200-MB download, although obviously you will need a copy of macOS Catalina as well. Apple has a helpful downloads page for every version from 10.7 to 15 (oddly, except 10.9 Mavericks, which was the first release the company distributed for free).\n\nCatalina Patcher offers three different ways to install, including an in-place upgrade. - Click to enlarge\n\nThe \"Install macOS Catalina.app\" file is an 8.26 GB download, so we didn't download a fresh copy: we copied it from our iMac onto a Mac-formatted USB key, and then onto the MBP. Then we downloaded Mistr's patcher and ran it. (Unsurprisingly, this is not an authorized app, as it does something Apple doesn't want to support, so don't double-click it; right-click it and pick Open.) It offers the choice of creating an installer USB, installing onto the machine it's running on, or creating an ISO file.\n\nSince this is a sacrificial testbed machine – it was replaced by a Core i7 Dell Latitude running ChromeOS Flex a couple of years ago – we just told it to install in place. It creates a modified installer in the /tmp folder, then launches that. First this converted our HFS+ SSD into the newer APFS format, then started the upgrade. Apple's time estimate was just under half an hour, but it took longer. Once the process finished, our 2010 MacBook Pro was running the 2020 version of macOS, even though it officially only supports models from 2012 onwards. On its own, macOS found an update for Safari, downloaded and installed it, and we were done.\n\nThere are no giveaways that this is an unofficial OS. The About this Mac dialog box still identifies the correct model, its GPU, its RAM slots, everything. On first launch, Firefox 115 automatically updated itself to version 128, and we then manually upgraded that to the latest 142. It runs fine – not blazingly fast, but pretty well for a 15-year-old computer based on a CPU launched in 2007.\n\nOur primary objective was successfully accomplished: to get a current, supported web browser. A few applets automatically updated themselves, such as the Rectangle window-tiling tool. We had to manually download Chrome from Google's Other Platforms page, and version 128 is the latest for this old OS, but it works.\n\nEvery silver lining has a cloud\n\nThere are some drawbacks to the upgrade, though. The machine is a little more sluggish than before. Although 10.15 was the first all-64-bit version of macOS, it has multiple new features to offset the removal of the 32-bit subsystems: the APFS filesystem, built-in Siri, several separate apps in place of iTunes, and so on. Our ancient but perfectly serviceable copy of Microsoft Office 2011 was 32-bit only so it no longer works. We grabbed the latest LibreOffice 25.8, which does work, but it's not exactly snappy. Now we have dark mode. Woohoo.\n\nTo be honest, just as Office 2011 did everything we wanted and a very great deal more besides, so did High Sierra. As The Register said in 2017:\n\nAll High Sierra's most interesting features are at the deep system level. 10.13 has no new apps and (almost) no new user-facing features at all. Apple has even resisted to give a cosmetic makeover to what's already there.\n\nIn this, it reminds us of the classic Mac OS X 10.6 \"Snow Leopard\", of which the same writer said:\n\nWhat greeted me was familiar: Snow Leopard starts like Leopard, down to the pixel. Apple promises that Snow Leopard frees about 7 GB from a comparable Leopard installation… there's some serious shrinkage going on. Safari's public beta on Leopard weighs in at 45 MB, but the Snow Leopard Safari at just 14 MB. The Address Book shrinks from 58 MB to 15 MB. Mail is now 77.5 MB.\n\nThat's the kind of upgrade we like. These days, 10.6 is hailed as one of the best-ever releases. Perhaps we should say liked, because High Sierra was the last time Apple managed a new version that looked and worked the same, but tightened everything up under the hood.\n\nNostalgia for old OS releases‽\n\nPart of the reason for this dramatic shrinkage was that Mac OS X 10.5 \"Leopard\" was the last ever PowerPC version. 10.6 removed all the PowerPC code, leaving only Rosetta, licensed from Transitive – which also sold it as QuickTransit to HP and Novell before IBM acquired it in 2008.\n\nOfficially, Snow Leopard is Intel only. That hasn't stopped the hardcore PowerMac enthusiasts, though, who have managed to custom-compile and put out a pre-release version.\n\nSome Mac fans miss old versions, just as some Windows fans do. We've written about running the translucent glories of Windows 7 in 2025, as we did about running Windows XP in 2023.\n\nAlthough it still looks sleek, Snow Leopard is so long in the tooth now that it's more of a Smilodon. This vulture ran it for years on a homemade Hackintosh, but we don't want to go back that far.\n\nWe recently discovered the website of Jonathan \"Wowfunhappy\" Alland, a discerning vintage-macOS aficionado who runs Mavericks Forever, and on it, he explains in detail why he chose this particular version; for instance, it was the first OS X to support memory compression, so it runs well on low-memory machines, and it was one of the last versions to retain the Aqua appearance. He also has a meticulously curated Mavericks App Library.\n\nNow that we've upgraded our elderly MacBook Pro, we're considering maxing out its memory and seeing how far we can upgrade it, but we might end up going backwards instead. However, on the same trip when we retrieved the MBP, we also collected an even older MacBook: a 2008 white MacBook. Sadly, this machine really is maxed out. As far as we can find out, OS X 10.7 \"Lion\" really is the last version of OS X it can run.\n\nLeopards and Lions … why not revenant Foxes, and shiny shiny Chromium?\n\nBut some of the hints on Mavericks Forever made us wonder if we could make Lion a little more useful. Before COVID-19, we had installed Firefox Legacy on the machine. It's based on Firefox 68, but although it's not maintained anymore, it still works and can open most contemporary websites. The Mavericks page told us about Firefox Dynasty. This is a port of the current Firefox for older versions of Mac OS X, back to version 10.8 \"Mountain Lion\".\n\nUnfortunately, it's on GitHub, and Firefox Legacy can't open GitHub's JavaScript-riddled Releases page. But we did recently discover another browser that can: Chromium Legacy. The latest version is from May 2024, based on Chromium 127, but it unzips and runs fine on \"Lion\", and in turn, it enabled us to download Firefox Dynasty.\n\nAnd this definitely shouldn't work, but here's the current Firefox (and Chromium 124) on OS X 10.7. - Click to enlarge\n\nResult: the latest Firefox 142, complete with vertical tab bar, running happily on the version of OS X El Reg reviewed in 2011. And, for any websites that won't work right in Firefox, we have a fairly recent version of Chromium as well. Suddenly, that makes this ancient OS a much more viable proposition.\n\nOne limitation of Chromium Legacy is that it can't check for updates – if there ever will be any more – and you may have difficulties fetching it from GitHub using a very old Firefox. Never fear: Wowfunhappy's Chromium Legacy Downloader is here, and he also offers the corresponding Firefox Dynasty Downloader PrefPane.\n\nSomewhere, we think we have a spare 4 GB DDR2 SO-DIMM lying around. We will try to max out the MacBook's RAM at a massive 6 GB, give the creaky old thing a small SSD, and take it out on the road for a run. With two modern browsers, we should be able to handle most things, and fifteen or twenty-year-old writing tools are still absolutely perfect. Maybe we can dig out a copy of Word from before the \"fluent interface\" and its wretched Ribbon were dreamed up.\n\nBootnote\n\nAs we've seen, a community of dedicated and determined enthusiasts is getting more recent OSes and modern browsers working on ancient Intel Macs and PowerMacs.\n\nBut it's not limited to getting newer OSes running on older kit. The counterpart is Mac OS 9 Lives, which has versions of the real original macOS that have been tweaked to run on some later PowerPC G4 hardware, released after Apple started amending the machines' firmware to compel users to switch to the fancy new Mac OS X.\n\nFor instance, there's a build of Mac OS 9.2.2 for iBook G4, and another one for the Mac mini G4. Somewhere, we have both of those machines, and once we can find them, we plan to try this out. They are both rather underpowered for Mac OS X, but they represent the fastest hardware ever made for Mac OS 9.\n\nOur G4 mini was a gift from the late DJ Walker Morgan, who some Register readers may remember for his Unix column in Personal Computer World under the pseudonym of David Evnull. (\"D. Evnull\" – /dev/null – geddit?) Ave, atque, vale. ®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/13/refresh_an_old_mac/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Intel Loses Another Prominent Linux Engineer - Now Going To NVIDIA",
      "content": "In the past few months at Intel between layoffs / corporate reorganizations and some deciding to pursue job opportunities elsewhere, there have been unfortunate impacts to their Linux engineering resources. Intel over the summer lost some prominent Linux engineering talent and in turn has even led to upstream Linux drivers being orphaned along with other driver maintainers departing and various other staffing changes . Unfortunate for Intel, another notable Linux name has left the company.Colin Ian King announced today that it was his last day at Intel. Colin King had just been employed by Intel for nearly four years but is well known prior to then. Prior to joining Intel, Colin was a kernel engineer at Canonical where he worked on Ubuntu Linux for over 13 years. Colin King was well known for his Ubuntu Linux work and has contributed more than four thousand patches to the upstream Linux kernel over the years. At Intel, Colin continued his kernel contributions with performance optimizations and more.If his name doesn't ring a bell, perhaps you know it from Stress-NG with Colin being the lead developer of those kernel micro-benchmarks. Colin has made incredible contributions to the upstream Linux kernel community over the past many years.Colin announced his departure from Intel today on LinkedIn:\n\nIn there he also announced he will now apparently be working for NVIDIA. For the benefit of the upstream Linux kernel community, hopefully he will be continuing to focus on upstream Linux kernel activity at NVIDIA... Especially given their increasing open-source GPU driver activity as well as growing kernel activity elsewhere from their networking products to other data center offerings and also needing to ensure the Linux kernel is performing effectively for showcasing the power of their products for AI and more.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Colin-King-Leaving-Intel",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "One of our favorite mini PC vendors has launched a ridiculously light laptop with an Intel Core Ultra CPU and a 5-megapixel OLED display",
      "content": "Geekom GeekBook X14 Pro OLED panel delivers 2880×1800 resolution with DCI-P3 coverage.\n\nIntel Core Ultra 200H processors drive performance with integrated Arc graphics.\n\n70 Wh battery promises extended productivity without frequent charging.\n\nGeekom, a company best known for its mini PC range, has stepped into a more competitive space with its first thin-and-light notebooks.\n\nThe GeekBook X14 Pro is only 16.9mm thick, weighs just 999g, and uses a durable aluminum alloy chassis with a 135° hinge.\n\nIts standout feature is a 14-inch OLED screen at 2880 x 1800 resolution and DCI-P3 100% coverage, which roughly equates to a 5-megapixel pixel count.\n\nNot bad for a first attempt\n\nUnder the hood, the X14 Pro features Intel’s Core Ultra 200H “Arrow Lake-H” processors paired with integrated Arc graphics.\n\nThese chips combine Lion Cove and Skymont CPU cores but omit Lunar Lake Xe2 graphics.\n\nThis raises doubts about whether Geekom has chosen the best CPU configuration for sustained performance.\n\nHowever, since this is the company's first attempt, it is probably testing the waters with a modest CPU.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nThis device's power draw peaks at 35W, which is typical for lightweight systems but could limit demanding tasks.\n\nMemory is soldered LPDDR5 running at 7500MHz, with up to 32GB capacity, which means there is no opportunity to upgrade.\n\nHowever, there is a single M.2 2280 NVMe SSD slot that provides storage, which may be restrictive for users expecting multiple drives.\n\nThe laptop is powered by a 70Wh battery, which is a relatively high capacity for a device weighing under one kilogram.\n\nIn theory, this battery can support long hours of typical productivity tasks before needing a recharge.\n\nThe battery is paired with a 65W USB-C GaN charger, chosen for its efficiency and small form factor.\n\nFor connectivity, this device comes with HDMI 2.0, a 40Gbps USB-C, a 5Gbps USB-A, and a headphone jack.\n\nWireless support includes Wi-Fi 6E and Bluetooth 5.4, while integrated DTS:X Ultra speakers suggest attention to audio quality.\n\nThis device also includes a backlit 78-key keyboard, and a power-key fingerprint reader rounds out the input options.\n\nAt the time of writing, Geekom has not announced pricing or release dates, making it difficult to judge the X14 Pro’s competitiveness against established brands.\n\nAt the same event, Geekom also revealed the GeekBook X16 Pro. This larger option uses a 16-inch 2560 x 1600 IPS panel, carries a 75Wh battery, offers dual SSD slots, and weighs 1299g.\n\nTogether, these two devices show Geekom is aiming beyond mini PC products, but their ultimate value depends on competitive pricing and reviews.\n\nVia Notebookcheck (originally in German)",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/one-of-our-favorite-mini-pc-vendors-has-launched-a-ridiculously-light-laptop-with-an-intel-core-ultra-cpu-and-a-5-megapixel-oled-display",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Cloud Hypervisor Will Block AI Generated Code, Raises x86_64 VM Limit To 8,192 vCPUs",
      "content": "Cloud Hypervisor 48.0 is now available for this Intel-started, open-source and Rust-based VMM focused on modern cloud workloads. Cloud Hypervisor continues to tailor to Windows and Linux guests while emphasizing security and cloud-native workloads.Cloud Hypervisor 48 introduces experimental \"fw_cfg\" device support for being able to pass configuration data and files like VM boot configurations from the host to the guest. There is also experimental support for Inter-VM Shared Memory \"ivshmem\" as another new feature.Cloud Hypervisor 48 also brings firmware boot support on RISC-V 64-bit, improved block performance when dealing with 16KB block sizes and smaller, faster VM pause operation especially with larger vCPU counts, and raises the x86_64 KVM vCPU limit. Up to this point Cloud Hypervisor could only handle up to 254 vCPUs with x86_64/KVM while now can handle up to 8,192 vCPUs.Cloud Hypervisor 48 also has removed Intel SGX support after previously deprecating the feature.Another notable change for the Cloud Hypervisor open-source project is they have established a policy against AI-generated code. Cloud Hypervisor will decline any contributions known to contain code generated or derived from Large Language Models.\n\nMore details on all of the Cloud Hypervisor 48 changes and downloads via GitHub",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Cloud-Hypervisor-48",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "AI Will Not Make You Rich",
      "content": null,
      "source": "Joincolossus.com",
      "url": "https://joincolossus.com/article/ai-will-not-make-you-rich/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Linux's New \"Sheaves\" Per-CPU Caching Layer Showing Massive Wins For AMD Performance",
      "content": "\"I ported this patch series on top of v6.17 and ran some benchmarks: will-it-scale, hackbench, redis, unixbench and kernbench. I ran the benchmarks on Intel Granite Rapids (480 cores), AMD Turin (512 cores) and ARM (80 cores)\n\n\n\nSummary of the results:\n\n\n\n- Significant change (meaning >10% difference between base and experiment) on will-it-scale tests in AMD.\n\n- No significant change on other benchmarks ran.\"\n\nEarlier this week I wrote about Sheaves as an opt-in, per-CPU array-based caching layer likely coming for Linux 6.18. The sheaves patches have been queued into the \"slab/for-next\" Git branch ahead of the Linux 6.18 kernel merge window. Patches posted now by Google are showing the Linux Sheaves code having a massive beneficial impact for large AMD systems.Google engineer Sudarsan Mahendran posted some benchmarks of the SLUB per-CPU Sheaves patches on Friday. The patches were applied to a Linux 6.17 base and tested across AMD, Intel, and ARM servers. For the AMD EPYC Turin server the Sheaves work ended up being a massive win for performance on a number of benchmarks but also some regressions.Sudarsan Mahendran commented on the mailing list:Going over his benchmarks on that LKML thread were exciting when seeing \"+28.58%\" mean improvements to get started, but also some 13~20% regressions... But when getting to the higher process counts for these scalability benchmarks was when it was getting really wild with +70.59%, +126.89%, +112.89%, and other massive wins. See all of the Google engineer's data in this thread It will be exciting to see how the Sheaves patches play out in more real-world workloads. Once these patches hit the mainline kernel presumably for Linux 6.18, I'll be firing up a number of benchmarks on my own hardware and thankfully have a lot of AMD EPYC Turin hardware and more for some exciting benchmarks ahead.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-Sheaves-AMD-Performance",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Monster Hunter Stories 3: Twisted Reflection gets a release date — we're also getting a new Monstie that I've been longing to ride since the first game, but everyone else will hate",
      "content": "What new Monsties will you discover in Monster Hunter Stories 3: Twisted Reflection?\n\nThe Nintendo Direct September 2025 event has come and gone, revealing a mountain of new games and more information on already announced titles heading for Xbox and PC.\n\nOne such title that has received new intel is Monster Hunter Stories 3: Twisted Reflection, the latest entry in Monster Hunter's spin-off Monster Hunter Stories series.\n\nDuring the Nintendo Direct, Monster Hunter Stories 3: Twisted Reflection got a new trailer revealing more of its story, playable Monsties, turn-based combat, and most importantly – its release date.\n\nWe know that Monster Hunter Stories 3: Twisted Reflection will be launching on March 13, 2026, for Xbox Series X|S, PlayStation 5, Nintendo Switch 2, and PC via Steam.\n\nHere's everything we know about Monster Hunter Stories 3: Twisted Reflection from the Nintendo Direct and another trailer released shortly afterwards by Capcom.\n\nMonster Hunter Stories 3: Twisted Reflection - Release Date Trailer - YouTube Watch On\n\nThe trailer begins with a recap of the game's premise. Monster Hunter Stories 3 takes place in a world where Rathalos have been driven to extinction.\n\nOne day, however, an egg birthed a pair of Rathalos bearing the mark of the world-ending Skyscale Rathalos. To protect their world from this doomed prophecy, the kingdom of Azuria put one of the baby Rathalos to death.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nMany years later, a horrible plague has begun spreading throughout the land, encasing everything in crystals and making the local monsters turn feral.\n\nYou play as the heir of Azuria, who has been tasked by the kingdom along with the surviving twin, Rathalos, to investigate and find a cure for this crystal plague.\n\nTo make things worse, war is on the horizon as the trailer shows footage of Azuria engulfed in battle with the kingdom of Vermeil, whose armies are led by a warrior riding the other twin Rathalos, which was presumed to be dead for years.\n\nYou can now switch between riding Monsties on the fly without needing to dismount. (Image credit: Capcom)\n\nThe trailer then showcases a montage of Monster Hunter Stories 3: Twisted Reflection's gameplay, which looks to be a full-blown evolution of the Monster Hunter Stories formula compared to the previous game, Monster Hunter Stories 2: Wings of Ruin.\n\nFor starters, while riding your Monsties (which are monsters that a player can tame and control) out in the open world, you can switch which Monstie to ride without dismounting.\n\nFor example, you can jump off a cliff and hover while riding a Tobi-Kadachi, then switch immediately to riding a Rathalos in midair, without needing to dismount from Tobi-Kadachi and plant your feet on the ground to call a Rathalos first.\n\nThis will no doubt make exploring the world go by way faster and potentially allow for some cool platforming tricks where you can jump and forth between multiple Monsties while traversing precarious areas.\n\nCo-ordinate your attacks with Monsties to take out challenging bosses like the explosive Magnamalo. (Image credit: Capcom)\n\nNext, the trailer gives us brief glimpses of Monster Hunter Stories 3: Twisted Reflection's turn-based combat system, which looks to be the same as in previous games.\n\nHuman party members take turns using their weapons to attack enemy monsters or command their pet Monsties to sic them. Combat is waged by employing attacks with either Power, Technical, or Speed tags to overpower opponents in Rock-Paper-Scissors style clashes.\n\nWhat's new about the combat system thus far is that we're getting a new weapon type for the player character to use in battle, the Longsword.\n\nAdditionally, enemy monsters now have a special gauge meter below their health bar that decreases whenever they take damage, which they never had before in previous games.\n\nCould this be a damage mitigation shield counter like Clair Obscur: Expedition 33, or an 'Enrage' meter that causes an enemy monster to instantly perform a devastating attack when the meter is empty? We'll have to wait for more info from Capcom to find out.\n\nAt long last, I can finally ride Plesioth and make everyone's lives miserable in Monster Hunter Stories\n\nMonsters from Monster Hunter Wilds are joining the hunt. (Image credit: Capcom)\n\nPerhaps the most exciting announcement from the trailer is that we'll be getting several new monsters to hunt and potential new Monsties to tame.\n\nThus far, we know that Paolumu, Rathalos, Velocidrome, Tobi-Kadachi, Nerscylla, Yian Kut-Ku, and Anjaneth will return as Monsties from previous games.\n\nGlavenus and Legiana are also potentially returning Monsties, as we see them being ridden in cutscenes but not during gameplay yet.\n\nAs for new monsters, we see a feral Chatacabra and a tease for Rey Dau from Monster Hunter Wilds at the end of the trailer.\n\nDread it, run from it, the hip-check always arrives. (Image credit: Capcom)\n\nBy far the most exciting addition for me personally is that Plesioth is finally going to be a Monstie after being only an enemy for many years in previous games.\n\nFor those who don't know, Plesioth is one of the most reviled and hated monsters in the entire Monster Hunter franchise. It's gigantic, hits like a truck, it can shoot steel-cutting water beams, and it has a venomous bite that puts players to sleep.\n\nWorst of it, Plesioth repeatedly uses an infamous attack now referred to by Monster Hunter Stories 2 as the 'Hyperspace Tackle', which can hit players a million miles away despite not looking like it hit them due to its massive, invisible range.\n\nI've always wanted to have a Monstie version of Plesioth ever since Monster Hunter Stories 1, so I could give enemy Plesioths a taste of their own medicine and prank players in online PVP multiplayer matches.\n\nI'm so happy to finally see my wish come true, along with all the new, exciting monsters and gameplay features Monster Hunter Stories 3: Twisted Reflection is bringing.\n\nI know for a fact that I wasn't expecting to see monsters from Monster Hunter Wilds' monster roster so soon.\n\nHere's hoping we get to see Arkveld, Rey Dau, and Nu Udra as tameable Monsties when Monster Hunter Stories 3: Twisted Reflection launches on Xbox, PlayStation, Nintendo Switch 2, and PC on March 13, 2025.",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/gaming/monster-hunter-stories-3-twisted-reflection-gets-a-release-date-were-also-getting-a-new-monstie-that-ive-been-longing-to-ride-since-the-first-game-but-everyone-else-will-hate",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Western intel funds Serbian unrest - Vucic",
      "content": "https://sputnikglobe.com/20250913/western-intel-funds-serbian-unrest---vucic-1122776022.html\n\nWestern Intel Funds Serbian Unrest - Vucic\n\nWestern Intel Funds Serbian Unrest - Vucic\n\nSputnik International\n\nEfforts to overthrow the government in Serbia have so far cost the organizers from outside $4 billion, Serbian President Aleksandar Vucic said.\n\n2025-09-13T05:28+0000\n\n2025-09-13T05:28+0000\n\n2025-09-13T08:47+0000\n\nworld\n\naleksandar vucic\n\nserbia\n\neurope\n\nprotest\n\nriots\n\ncolor revolutions\n\nhttps://cdn1.img.sputnikglobe.com/img/07e9/08/0f/1122614220_0:0:3072:1728_1920x0_80_0_0_d188aeb6eb283dabe454854d36293679.jpg\n\n\"A total of $4 billion has been invested in the destruction of Serbia. Who are our opponents? The main organizers are from outside, they created a network and gathered people, a network of students and children, which frightens and destroys the basic values ​​of our society. These are employees of various intelligence services of several countries. We know that three countries have particularly used their intelligence networks,\" Vucic said on TV Informer overnight to Saturday, adding that he can't name these countries so as not to complicate Serbia's position. At the end of 2024, he spoke about 2 billion euros ($2.3 billion) invested by the organizers in mass protests in Serbia, at the beginning of 2025 - about 3 billion euros. Student and opposition protests began in Serbia after the canopy collapsed at a train station in Novi Sad on November 1, 2024, killing 16 people. The situation in Serbian cities escalated in mid-August. Protesters stepped up their actions, clashing with the police in the evening and at night, blocking roads.\n\nhttps://sputnikglobe.com/20250826/vucic-compelled-to-take-hard-stance-on-riots-in-serbia-1122674457.html\n\nserbia\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\n2025\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\nNews\n\nen_EN\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\n1920 1080 true\n\n1920 1440 true\n\n1920 1920 true\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\nSputnik International\n\nserbia protests, serbia protests funding, color revolution in serbia,",
      "source": "Sputnikglobe.com",
      "url": "https://sputnikglobe.com/20250913/western-intel-funds-serbian-unrest---vucic-1122776022.html",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "Fist of the North Star: New \"Hokuto No Ken\" Trailer, Visuals Released",
      "content": null,
      "source": "Bleeding Cool News",
      "url": "https://bleedingcool.com/tv/fist-of-the-north-star-new-hokuto-no-ken-trailer-visuals-released/",
      "timestamp": "2025-09-13"
    },
    {
      "headline": "This refurbished MacBook Air is cheaper than most tablets right now",
      "content": "If you’re looking for a dependable, portable, and budget-conscious laptop for day-to-day tasks, look no further. This pre-loved MacBook Air hits the sweet spot—and it’s only $189.97 (reg. $999) with free shipping for a little while longer.\n\nWith a 1.8GHz Intel Core i5 processor, this machine is fast enough for tasks such as email, Google Docs, light streaming, and Zoom calls. It’s not here to replace your gaming rig or your creative workstation, but for the average user who just needs something that works without the drama, this MacBook is a total win.\n\nAt just under 3 pounds, it’s a dream for travel. Toss it in your tote or backpack and you’re good to go—whether you’re hopping on a plane or just working from the library. And thanks to the 12-hour battery, you can leave the charger at home more often than not.\n\nThe 128GB SSD keeps boot-up times snappy and gives you plenty of space for documents, photos, and those videos you swore you’d organize one day. Plus, the 13.3-inch widescreen display delivers a crisp viewing experience, even if you’re just catching up on YouTube.\n\nSure, it’s not brand new—this is a Grade “A” or “B” refurbished device, meaning you might see a minor scuff here or there. But under the hood, it’s fully functional, professionally inspected, and even comes with a 90-day aftermarket parts and labor warranty, just in case.\n\nAt just $189.97 with free shipping, this deal is hard to beat. Grab your own 13.3-inch MacBook Air now before units sell out for good.\n\nApple MacBook Air 13.3″ (2017) 1.8GHz i5 8GB RAM 128GB SSD Silver (Refurbished)See Deal\n\nStackSocial prices subject to change.",
      "source": "Macworld",
      "url": "https://www.macworld.com/article/2905647/this-refurbished-macbook-air-is-cheaper-than-most-tablets-right-now.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "A major AI video editor now has a lifetime subscription for $25",
      "content": "Editing videos used to be time-consuming, incredibly frustrating, and pretty difficult. AI has changed that. Macxvideo AI is part of a new generation of tools designed to make video work faster, simpler, and more accessible, especially for Mac users. A lifetime subscription to Macxvideo is usually $69.95, but right now, it’s only $24.99.\n\nThis all-in-one video toolkit combines more than 20 functions into a single desktop app. You can enhance video quality, upscale to 4K or 8K, convert formats, compress files, record your screen, and make edits without switching between programs. It runs entirely offline and uses GPU acceleration to boost performance, which is helpful when you’re working with high-resolution media.\n\nThe AI models in Macxvideo are trained to handle common issues like motion blur, low resolution, or poor lighting. It includes tools for frame interpolation, face recovery, colorization, and background noise removal. You can also convert videos to GIFs, apply watermarks, and correct fisheye distortion.\n\nMacxvideo is designed specifically for macOS and works on both Intel and Apple Silicon Macs running macOS 10.15 or later. It supports a wide range of formats and settings, so it can handle quick fixes as well as more involved projects.\n\nThis is a one-time purchase with no recurring costs.\n\nRight now, you can get a Macxvideo Lifetime Subscription for only $25.\n\nMacxvideo AI: Lifetime SubscriptionSee Deal\n\nStackSocial prices subject to change.",
      "source": "Macworld",
      "url": "https://www.macworld.com/article/2902398/a-major-ai-video-editor-now-has-a-lifetime-subscription-for-25.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Select Qualcomm X Elite Laptops Seeing IRIS Video Acceleration On Linux",
      "content": "Adding to the list of feature caveats around the different Qualcomm Snapdragon X Elite laptops and the varying Linux state is video acceleration support. But patches were posted this week by a Linaro engineer enabling hardware accelerated video playback for two X Elite laptop models.Linaro engineer Stephan Gerhold posted the patches enabling IRIS video acceleration decoding for the X1 Elite Compute Reference Design (CRD) and the Lenovo ThinkPad T14s. The CRD support isn't too useful for consumers themselves. The Lenovo ThinkPad T14s continues to benefit as one of the best supported X Elite laptops under Linux with even having firmware files upstream in linux-firmware.git.The patches posted on Thursday add the IRIS video acceleration code for the DeviceTree used on the Qualcomm reference board as well as the Lenovo ThinkPad T14s. Besides the DT support, there is also an IRIS firmware requirement.These new patches for those having either X1E platform can find them on the LKML . In time hopefully the other popular X Elite laptop models will also see this support in place.It was back in Linux 6.15 earlier this year that the Qualcomm IRIS video decode driver was upstreamed . In initial form a V4L2 video driver with H.264 decode.\n\nIn case you missed it for more details on the recent X Elite Linux experience, see the recent tests in Qualcomm Snapdragon X Elite Linux Performance Improving But Short Of AMD Ryzen & Intel Core Ultra",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Qualcomm-X-Elite-IRIS-Video",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Linux 6.17-rc6 Released With VMSCAPE Mitigation, FLYDIGI APEX 5 Support & Fixes",
      "content": "The newest weekly test release of Linux 6.17 is now available as we work toward the stable kernel release around the end of September.Linux 6.17-rc6 was just released by Linus Torvalds. Pulled into Linux 6.17-rc6 is a fix to address some \"serious breakage\" around system hibernation support as a regression introduced in Linux 6.16. Fixes to both the Intel and AMD P-State drivers also landed this week as part of the Linux 6.16-rc7 material.Some new material for Linux 6.17-rc6 since it just amounts to new device/vendor IDs is FLYDIGI APEX 5 gaming controller support for those expensive game controller options.This week also saw the public announcement of VMSCAPE as a new CPU security vulnerability issue affecting both AMD and Intel processors . VMSCAPE mitigation support was merged to Linux Git upon embargo lift and also since back-ported to the stable Linux kernel series. Linux 6.17-rc6 has the mitigation if you aren't a daily Git rider.\n\n\"Things remain pretty calm, and for some reason this release seems to just not have a ton of problems. Hopefully I'm not jinxing it.\n\n\n\nIt might just have been people being on vacation in August (read: Europe) which has caused this release to be nice and calm, but whatever the reason I'm certainly not complaining.\n\n\n\nSomewhat unusually, almost a third of the patch is from filesystem fixes, but that seems to be pure coincidence: not because there are any particularly large fixes, but because we just happened to independently have fixes in several different filesystems (ceph, smb client, nfs, erofs, btrfs). So just random timing.\n\n\n\nAnother third is driver fixes (gpu being half of it, the rest being other random drivers), and the final third is just \"misc other stuff\": core networking, another CPU speculation mitigation, somedocumentation fixes, some selftest updates, and minor noise elsewhere.\n\n\n\nBut really, none of it is very large. So everything seems slated for a normal release in two weeks.\"\n\nLinus Torvalds wrote with the 6.17-rc6 announcement There are a lot of great features and improvements in Linux 6.17 with this stable kernel version hopefully coming out two weeks from today on 28 September.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.17-rc6-Released",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Breer: Polk's ‘football character' played role in Patriots-Saints trade",
      "content": "There's no question about it: The Patriots whiffed on Ja'Lynn Polk.\n\nNew England traded Polk to the New Orleans Saints on Saturday. The Patriots acquired a 2027 sixth-round pick in exchange for Polk and a 2028 seventh-round pick, according to The Athletic's Dianna Russini. Terms of the trade were not confirmed by the team.\n\nThe second-year wide receiver was selected 37th overall in the 2024 NFL Draft.\n\nSubscribe to NBC Sports Boston's podcast network to hear our Insiders bring you the latest insights on your favorite teams! PODCASTS\n\n\"It's about as small a return as you can get, and this is really just a flat miss,\" Sports Illustrated's Albert Breer said on Patriots Pregame Live before a Week 2 matchup against the Dolphins on Sunday.\n\nPatriots head coach Mike Vrabel told radio broadcaster Scott Zolak the franchise felt it was best to give Polk a fresh start. Polk was placed on season-ending injured reserve and thus was not eligible to play for the Patriots this season.\n\nBreer's insights aligned with Vrabel's comments, and also included noteworthy detail.\n\n\"This just got to the point where they were hopeful that he would come back in a better place than he had been in 2024, and they still saw a backup player out there on the practice field even before he got hurt,\" Breer said.\n\n\"I think where they feel like they really missed -- this isn't a bad guy, so it's not a personal character thing. I want to make sure I emphasize that,\" Breer continued. \"But the football character wasn't exactly what they thought it would be.\"\n\nThe University of Washington product bragged about having \"the best hands in the league\" during his rookie season. He finished the year catching 12 of the 33 passes thrown his way for a mere 87 yards and two touchdowns in 15 games. When Polk stepped to the microphone in training camp this summer, he said he didn't learn anything from his rookie season and instead was putting it in the rearview.\n\n\"He didn't dig himself out of that hole,\" Breer said. \"They started to view him as more of a backup and then the question became, 'Do we just cut bait now or do we keep chasing a mistake and maybe create a situation where you're not giving other players some opportunity?' And, of course, that issue is exacerbated by the fact that they missed on another receiver in Javon Baker.\"\n\nBaker initially made New England's 53-man roster, but was one of the ensuing cuts after the Patriots claimed a few players off waivers. Baker signed with the Eagles practice squad after being released.\n\nBreer dropped a Baker-related nugget of information, as well.\n\nThe Patriots entered Day 3 of the 2024 NFL Draft planning to draft wide receiver Troy Franklin out of Oregon, Breer said. New England had the third pick in the fourth round. However, the Broncos traded in front of the Patriots and selected Franklin right in front of New England. The Patriots drafted offensive lineman Layden Robinson with their initial fourth-round pick (No. 103) and circled back at wide receiver and selected Baker later in the fourth round (No. 110).\n\nNeither Robinson nor Baker remain in New England while Franklin is a starting wide receiver in Denver.\n\nAnother aspect that makes matters worse for the Patriots is the fact two of Polk's college teammates are flourishing in the league. The Bears selected Rome Odunze with the No. 9 pick and the Buccaneers drafted Jalen McMillan with the 92nd overall pick. The Patriots bypassed McMillan, as well as others like Chargers star Ladd McConkey, and instead drafted Polk.\n\n\"A lot of people in the NFL viewed Ja'Lynn Polk the same way he Patriots did -- tough, smart, high football IQ, a guy that maybe doesn't have the highest ceiling in the world but was going to be able to play right way and be a role player for a long, long time to come in the NFL,\" Breer said. \"Obviously, it did not play out that way.\"\n\nAfter trading Polk, only two members (Drake Maye, Caedan Wallace) of the 2024 eight-player draft class are on New England's active roster.",
      "source": "Nbcsportsboston.com",
      "url": "https://www.nbcsportsboston.com/nfl/new-england-patriots/jalynn-polk-saints-trade-reaction/731243/",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Intel outlines 2026 PC roadmap: Arrow Lake refresh to hold the line before Nova Lake overhaul",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250911PD244/intel-arrow-pc-2026-roadmap.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Beelink ME Mini Review: The mini PC maker’s first NAS supports 6 NVMe SSDs",
      "content": "Over the past few years we’ve seen a bunch of Chinese PC and accessory makers launch affordable network-attached storage (NAS) systems with Intel Alder Lake-N or Twin Lake processors and support for PCIe NVMe SSDs. But the Beelink ME Mini is one of the first to support up to six NVMe drives. Most other models, including the GMK NucBox G9, Maiyunda M1S, and TerraMaster F4 SSD only support four.\n\nThe Beelink ME Mini also features a new design for an NVMe-based NAS: it’s a small cube-shaped computer that measures 99 x 99 x 99mm (3.9″ x 3.9″ x 3.9″). Lift the top cover and you’ll find six M.2 2280 slots and a built-in power supply positioned vertically around a central cooling core.\n\nThe computer features the popular Intel N150 mobile processor, which is a 6-watt processor with low power consumption, but is also a quad-core chip that offers decent performance-per-watt. The integrated Intel Graphics GPU features 24 execution units and support for 4K video at 60 Hz as well as Intel Quick Sync hardware-accelerated video decoding.\n\nFor networking, the ME Mini offers both twin 2.5 Gb Ethernet ports, WiFi 6, and Bluetooth 5.2.\n\nFirst introduced earlier this year, the Beelink ME Mini is available from Amazon or the Beelink website with prices starting at $209 for a basic model with 12GB of LPDDR5-4800 memory and 64GB of eMMC storage. There’s also a $329 for a version that also comes with a 2TB Crucial P3 Plus SSD and Windows 11 Pro license.\n\nBeelink provided Liliputing with an ME Mini unit which included a 2 TB Crucial SSD for free, with no requirement that the computer be returned upon completion of the review. But this review is not sponsored by Beelink, and the company did not modify or approve the content of this article in any way.\n\nPhysical Design\n\nThe ME Mini is available in three colours: pearl white, midnight gray (grey) and peacock blue, which is best described as a dark turquoise or blueish-green (see also the ‘Case Colours’ section below).\n\nEssentially, the device is a small plastic cube with rounded corners, cut-outs for ports, a power button, and ventilation. It sits on two semi-circular rubber feet.\n\nThe front has a symmetrical layout based around a central on/off button. Either side of which are two pin hole indicator lights: the left shows white when it is running whilst the right shows orange when it is sleeping. Then on either side on the front are USB 3.2 Gen 2×1 (10 Gbps) ports. The far left being Type-C, and the far right is a Type-A port.\n\nOn the back are the remaining ports. Over on the left is the power port which takes the included IEC C7 (Figure Eight) power lead. Next comes a vertical USB 2.0 port. Then there are two side-by-side 2.5 Gb (Intel I266-V) Ethernet ports. Finally, on the far right is a vertical HDMI port.\n\nBoth sides have a series of ventilation holes across the bottom and are otherwise plain.\n\nThe top looks like it contains a dial which is full of ventilation holes. However, this is just design aesthetics as it doesn’t rotate because it is in fact glued in.\n\nThe centre of the base has a slightly protruding circular section which is surrounded by ventilation holes for air expulsion. It also has the rubber feet that together lift the ME Mini fractionally off the surface to allow airflow.\n\nNot shown in the picture are tiny rubber plugs located in each corner that conceal the four screws fixing the top to the bottom of the device. There is also a tiny hole between the two feet at the bottom, which enables access, using a paperclip or similar, to the clear CMOS button inside the device.\n\nGetting to the internals like the NVMe drives, is rather awkwardly hindered by these little rubber plugs, as first they have to be prised out before undoing the screws.\n\nTo easily understand the internal layout, Beelink’s website has a great overall view of the ME Mini’s design which shows the device’s basic structure.\n\nEverything orientates around a large heatsink. It has a central core that covers the processor at the bottom of the heatsink, and then runs to the top of the device where it is covered by a 60 mm, 5 volt fan.\n\nOff this core are six struts that run from the bottom to top, and are connected to the outer walls of the heatsink which is square in shape.\n\nThe cooling is based on a reverse-chimney design where colder outside air is pulled into the device from the top and then pushed downwards before being exhausted through the sides and, to a lesser extent, the base. This air movement cools not only the metal heatsink but everything else, as all the components are attached to it.\n\nOn the outside of the heatsink where the NVMe drives are to be located, are thermal pads. Each NVMe drive is then attached by a screw to the heatsink. This ensures that the drives hottest part, its controller, comes into contact with the thermal pad.\n\nAnother notable design feature is that the 45 watt power supply is internal to the device and is embedded within the heatsink.\n\nThis design serves a dual purpose as not only does it take care of incorporating the power supply without increasing the size of the device, but it also allows the heat generating component to face the heatsink, and therefore the heat is wicked away.\n\nOn the other side of the heatsink is the WiFi module and CMOS battery. There’s an M.2 E-Key slot on the left that Beelink uses for an Intel AX101 Wi-Fi 6 (802.11ax) 2230 card. Its two aerials are mounted above on foam pads, the left being the main antenna and the right for the aux or diversity antenna.\n\nBut you can also remove that wireless card and replace it with something else. In the picture above you’ll notice that I’ve replaced the Intel AX101 module with an M.2 adapter to provide additional storage. I’ll cover this in more detail below.\n\nThe plastic base of the ME Mini is attached to the motherboard by four small screws which can only be accessed once the top cover is removed.\n\nOnce removed, this exposes the rear side of the motherboard and the mountings for the heatsink which covers the CPU on the other side.\n\nFinally, inside the box you get your country specific power cable, a HDMI cable and a user manual.\n\nHardware: Storage, memory and networking\n\nWhat makes the ME Mini so interesting to me from a hardware perspective, is how it manages to provide six NVMe slots.\n\nMost NAS mini PCs with Intel Alder Lake or Twin Lake processors have faced the restrictions defined in the Intel Processor and Intel Core i3 and Intel Core 3 N-Series Datasheet. This is a document produced by Intel which is specifically intended for Original Equipment Manufacturers (OEMs), Original Design Manufacturers (ODM) and BIOS vendors creating products based on the N series processors.\n\nThe section relevant to designing a NAS is the PCI Express Port Support Feature Details as this stipulates how many PCIe lanes are provided by the processors and how they can be configured.\n\nOf particular interest is Note 7 that states:\n\nThe PCIe* Lanes can be configured independently from one another but the max number of configured Root Ports (Devices) must not be exceeded\n\nA maximum of 5 PCIe* Root Ports (or devices) can be enabled\n\n\n\nOther manufacturers have built products within this restriction by making use of PCIe express packet switches like the ASM1182e and ASM2806 to switch PCIe lanes and allow more ports to be connected. However, Beelink seem to have simply enabled more Root Ports.\n\nBy looking at the PCIe Root Port assignments when running Ubuntu on the ME Mini, we see that eight PCIe Root Ports are enabled, with two allocated to the two 2.5 GbE ports and the remaining six allocated to NVMe slots.\n\nFive of these NVMe allocations get a single lane of PCIe 3.0.\n\nAnd specifically the fourth NVMe slot, gets two lanes of PCIe 3.0.\n\nAlthough the NVMe slots are PCIe 3.0, they will still work with PCIe 4.0 drives as these drives are backward compatible. The impact from a lower PCIe generation and number of allocated lanes, only affects the speed of the NVMe.\n\nFor example, the included Crucial P3 Plus is a Gen 4.0 drive capable of reaching 5,000 MB/s for sequential read and 4,200 for sequential write when used in a computer with a 4-lane PCIe Gen 4.0 slot.\n\nObviously performance will be lower in systems like the Beelink ME Mini, given it allocates fewer PCIe lanes which are from the previous generation The best performance can be obtained when the SSD is inserted in the fourth NVMe slot where it will get the benefit of two PCIe Gen 3 lanes.\n\nCrystalDiskMark showed the sequential read speed was 1741 MB/s and the sequential write speed was 1692 MB/s. In contrast, all the other NVMe slots are single lane and so technically half the speed.\n\nI can demonstrate by testing with some Lexar NQ790 4TB M.2 2280 PCIe Gen4 NVMe drives in slot 4 and in slot 1. The faster two-lane, slot 4 shown on the left, gave a sequential read speed of 1776 MB/s with a sequential write speed of 1709 MB/s. The single-lane slot 1 shown on the right, only provided a sequential read speed of 891 MB/s and a sequential write speed of 868 MB/s.\n\nThe ME Mini also comes with eMMC storage which is a soldered down HS400 Enhanced strobe MMC card which has a maximum bandwidth of 400 MB/s. When tested I saw a sequential read speed of 310 MB/s and a sequential write speed of 221 MB/s.\n\nWhile it might seem like the computer’s 1 and 2-lane PCIe Gen 3.0 connections will keep you from getting the full benefit of solid state storage by limiting the read/write speeds, it’s actually the Ethernet ports that will be the bottleneck for users who plan to access the NAS over a network.\n\nThe theoretical maximum throughput of 2.5 Gb Ethernet (2.5GbE) is 313 MB/s. When I tested the ports using iperf3 I got slightly less at 294 MB/s for both upload and download.\n\nWhen accessed remotely, the NAS was showing a sequential read speed just under 300 MB/s and a sequential write speed of around 250 MB/s. See the ‘Networking Performance’ section below for further details.\n\nSo any NVMe drives used with this computer will actually be able to transfer data to and from storage faster than it can be accessed over a network connection.\n\nThat doesn’t mean it’s pointless to use SSDs for this NAS instead of hard drives. The solid state drives take up less physical space than hard drives, allowing you to fit as many as six drives into a computer that’s too small to hold a single 3.5 inch hard drive. SSDs also consume less energy and have no moving parts, which means they don’t make noise and aren’t as likely to break. They are, however, more expensive than hard drives. So while the Beelink ME Mini itself is priced competitively with NAS systems that support four or eight hard drives, the costs of storage for an SSD-only device like this can be pretty high.\n\nFinally, another consideration when using a NAS is how much memory is available. Some filesystems, such as ZFS, are known to be memory-intensive and require sufficient memory to work efficiently.\n\nUnfortunately, the ME Mini has soldered down memory which is not user upgradeable. But it does come with 12 GB of LPDDR5, which is more than you get from many other NAS systems in the same price range. Beelink could have included more memory though. Officially Intel says the Intel N150 processor supports up to a maximum of 16 GB of RAM, but it’s been well documented that computers with this processor can support 32 GB or more.\n\nOne further, but untested restriction, is that the Maximum Memory Speed is 4800 MT/s, and this is the speed the ME Mini is configured to run at even though the installed LPDDR5 memory is capable of 6400 MT/s.\n\nWindows Performance\n\nThe ME Mini review unit came with Windows 11 Pro pre-installed on the Crucial P3 Plus NVMe drive.\n\nThe first observation to note is that both Power Limit 1 and 2 are set to 15 watts. This means that the CPU is provided with constant power, and is not provided with extra power to boost its frequency during heavy workloads. In contract, previous N100 mini PCs I’ve reviewed in the past, such as the GEEKOM Mini Air12 has its Power Limit 2 set to 25 watts and the Beelink EQ12 had a higher PL1 value of 20 watts and the same higher PL2 of 25 watts.\n\nSo, the CPU performance of the ME Mini will be slightly degraded compared to other mini PCs with similar processors in order to keep the temperature of the processor lower and more consistent. Given the only difference between the N100 and N150 is that the latter has a slightly higher turbo frequency (3.4 GHz vs 3.6 GHz), no real performance difference is going to be seen with the current power limit settings.\n\nIf you were solely using the ME Mini as a Windows mini PC just with a lot of storage, you might notice this performance impact as the Intel N150 is not a super powerful processor in the first place.\n\nI did run a few benchmarks just for comparison purposes.\n\nFirst let’s look at comparing Geekbench’s CPU results with a couple of arguably equivalent mini PCs which both has an N100 CPU, the GEEKOM Mini Air12 and the Beelink EQ12.\n\nThe single core score achieved by the ME Mini was 1147 and this compares with 1226 and 1199 so minimal impact. However, the multi core score was only 2143, whereas Mini Air12 scored 3249 and the EQ12 scored 3186. Ouch.\n\nAnother CPU benchmark I ran was Cinebench R23. The single core results saw the ME Mini getting 945 pts against 933 for the Mini Air12 and 946 for the EQ12. For multi core, the outcome was better than the Geekbench results, with the ME Mini only slightly lower at 2861 pts vs 3008 for the Mini Air12 and 2947 for the EQ12.\n\nIt is worth noting that these two benchmarks are very different. Geekbench consists of a series of tests and favours the ability to boost, whereas Cinebench is more of a continuous test where the longer it takes to complete the test, the less impact the initial boost has on the result.\n\nThe final benchmark I ran was Performance Test’s Passmark. This is a good benchmark to see how components like the CPU, Memory and Storage perform both individually and all together.\n\nComparing scores between devices will obviously be heavily affected by “what and how much” was installed for each component. Nevertheless, the Passmark score does reflect the overall performance you will get when using the configuration. When running each of the devices with their “as sold” configurations, without any UEFI/BIOS tweaking etc., the ME Mini scored 1549.9, the Mini Air12 scored 2457.6 and the EQ12 scored 2216.8. The ME Mini’s CPU (PL1/2 15W), Disk (PCIe Gen 3 x2) and Memory (12 GB) all play a significant part in affecting this overall score.\n\nHowever, even though customers who purchase a ME Mini with a 2TB SSD will get a system with Windows pre-installed, the computer is marketed as a NAS rather than a general-purpose mini PC. So I wanted to see how it performed as a network-attached storage device.\n\nMy first challenge was how to set up the ME Mini to test as a NAS running Windows. I didn’t want to lose an entire NVMe slot just because it had Windows sitting on a 2 TB drive, as I planned to test the maximum storage configuration the ME Mini supports of using six 4 TB drives.\n\nI first “moved” Windows from the Crucial P3 Plus drive to the eMMC storage. I did this by removing the NVMe drive and then running the Windows reset feature to effectively perform a clean installation of Windows to the eMMC drive. I did find I was missing some drivers, but they are available from Beelink’s support page.\n\nMy initial concern was whether running Windows from the slower eMMC drive would affect performance. So, I reran the earlier benchmarks:\n\n\n\n\n\n\n\n\n\nAs can be seen, all the results are within the margin of testing error with the exception of Passmark, which is singularly affected by the slower Disk mark (16123.0 vs 1692.2).\n\nReassured, I installed six Lexar NQ790 4TB M.2 2280 PCIe Gen4 NVMe drives. The next step was to consider how to set up the NAS storage using these six drives.\n\nWindows 11 includes Storage Spaces which, as they admit, is conceptually similar to redundant array of independent disks (RAID). And as ZFS and Btrfs are not supported by Windows my choice of file system was going to be limited to NTFS.\n\nWhen considering a ZFS configuration for six drives, one of the more frequently suggested options is to create two separate three-wide RAIDZ1 vdevs in the same zpool.\n\nTrying to break this down into [Windows] terminology, I want two RAIDZ1 (parity i.e. RAID 5) virtual disks consisting of three physical drives, combined (stripped i.e. RAID 0) in the same zpool (virtual volume). Simply put, I want RAID 50 (RAID 5+0) using six drives.\n\nI found I couldn’t do all of this using the Storage Spaces GUI so I ended up writing a PowerShell script so I could easily recreate the storage configuration during testing.\n\nFirst, I created two storage pools each consisting of three NVMe drives with parity resilience.\n\nI then striped the resultant two virtual disks to create a single virtual volume I could use as my NAS.\n\nUsing HWiNFO, I set the NVMe temperature sensor for each drive to display on the right of the taskbar. Running CrystalDiskMark gave a sequential read speed of 3538.51 MB/s and a sequential write speed of 657.38 and the maximum drive temperature seen was 50 °C which is perfectly acceptable.\n\nNext, I installed Docker Desktop and located both the installation directory and the docker data directory on my NAS ‘N’ drive to save space on the Windows system drive.\n\nI then created a Jellyfin container with its media on the NAS, so I could further test the performance impact and further monitor the drive temperatures.\n\nLooking at the statistics while Jellyfin was playing music showed plenty of CPU headroom as it created minimal load.\n\nAll six of the drives remained at a safe temperature, showing only a minor degree of a two degree increase from when idle. During this usage the fan remaining whisper quiet.\n\nUbuntu Performance\n\nWhile Windows was pre-installed on the unit Beelink sent me, the ME Mini should support a wide range of different operating systems. Beelink lists some of the more commonly encountered NAS OS that the device supports on their webpage including Proxmox, Unraid, TrueNAS and FNOS, the latter being a new closed-source but free NAS OS specifically for users in China.\n\nI decided to use Ubuntu for the review and set up my NAS manually, so that I had the flexibility of configuring RAID and file systems of my choice, purely for ease of testing.\n\nAs Windows 11 minimum storage requirement is 64 GB or larger, and given the eMMC is only 64 GB, it means that I couldn’t just dual boot Ubuntu from eMMC by creating an additional partition.\n\nTypically, when there is a user-replaceable WiFi card in an M.2 2230 slot, I can just use Key-E to Key-M adapter and use a 2230 NVMe drive at PCIe Gen 3 x1 since the computer can use an Ethernet cable for a wired network connection.\n\nHowever, the installed Intel AX101 card is CNVi and not PCIe. Sometimes, depending on the design, a M.2 may support both the CNVi and standard M.2 Key-E wireless module. I tested with an adapter and confirmed that it is definitely not supported.\n\nHowever, I also tried a Key-E to micro SD card adapter which contained a Sandisk Extreme PRO 256 GB card, and this was recognised both in Windows and Ubuntu.\n\nAs can be seen, the adapter is recognised as USB storage and only runs as USB 2.0.\n\nIt doesn’t matter too much how fast the micro SD card is, as it will be capped at USB 2.0 speeds. Testing gave a sequential read speed of 20.32 MB/s and a sequential write speed of 27.64 MB/s.\n\nWhilst this is not particularly fast, I’ve found that running Ubuntu from an adapter like this is totally fine for a NAS. In fact, the Unraid operating system, which is designed specifically for NAS systems, must be run from a USB drive, which means that it’s often running off a slow storage device.\n\nIf you do want quicker read/write speeds, you could install Ubuntu with separate partitions, and then for quicker write speeds on /var and /tmp for example, they can be moved or bound to directories/partitions on the NAS once configured.\n\nHowever, most users who choose a different operating system to Windows, will likely use the eMMC for OS storage, or install the OS on the NAS. Basically, there is a lot of flexibility available.\n\nSo, my testing setup on the ME-Mini consisted of an installation of Ubuntu 25.04 with ZFS, Docker Desktop, Portainer and Cockpit on the micro SD card. I also removed Snaps to improve performance as this frees up some memory.\n\nI configured each RAID such that it was accessible as ‘/ME-Mini’ and had three sub-directories called ‘media’, ‘linuxium’ and ‘nas’, each of which was made available through SMB. I also created a Jellyfin container that used media from ‘/ME-Mini/media’.\n\nThe first RAID I created had the same storage configuration I used in Windows but implemented using ZFS. As a reminder, this was to create two RAIDZ1 vdevs each with three NVMe drives, in the same zpool which I called ME-Mini.\n\nRunning ldiskmark, which is my Ubuntu implementation of CrystalDiskMark using ‘fio’, I saw a sequential read speed of 1614.8 MB/s and a sequential write speed of 827.0 MB/s. This compares to Windows where the sequential read speed was 3538.51 MB/s and the sequential write speed was 657.38 MB/s.\n\nWhen the Jellyfin container was running and playing music, there was little impact on the drive temperatures, similar to Windows. Using sensors showed that all the temperatures were under 45 °C.\n\nThere was also little load of the CPU, however, due to the filesystem using ZFS, the memory usage was very high at 82 %.\n\nThis RAID configuration is arguably storage-expensive as it uses two drives for parity yet only protects for a single drive failure. Having installed 24 TB of disk space, the available space is only just over 14 TB.\n\nGiven the cost of the drives, a more space-to-cost configuration would be to just create a RAID5 configuration using all six drives, or in ZFS terms, create a zpool of all six drives as RAIDZ1.\n\nThis increases the storage by 4 TB and the RAID’s sequential read and write speeds are similar to before. However, there is an increased risk of data loss during a rebuild as this puts a lot of work on the remaining drives which may cause another one to fail.\n\nBut one thing it doesn’t change is the high demand for memory that ZFS makes.\n\nSo as a final example, I’ve created a RAID50 configuration using ext4 for the filesystem.\n\nThe RAID performance was very much improved for sequential reads at 3027.8 MB/s whilst there was a slight degradation in sequential write speeds to 804.2 MB/s however this still exceeds the available network throughput.\n\nPerformance whilst running Jellyfin was just as good as when running on ZFS.\n\nMoving the filesystem to ext4 also didn’t increase the drive temperatures. If anything, the NVMe temperatures dropped slightly.\n\nBut the main gain, as expected, was the lower memory usage. It dropped from 84% usage with ZFS to 34% with ext4.\n\nAnd just on the point of using ext4, if LVM is also used and ‘md0’ is initialised using ‘pvcreate’ so that the NAS storage is created as a logical volume, then ‘lvcreate–snapshot’ can be used to create snapshots, which is one of the benefits from using ZFS.\n\nWhen running these configurations, neither the CPU nor NVMe drives got hot, resulting in a fan that even though was running, was still too quiet to hear.\n\nNetworking Performance\n\nAs mentioned earlier, given the typical NVMe speeds in the ME Mini, the 2.5 Gb Ethernet ports are a performance bottleneck when accessing the NAS over a network.\n\nIn terms of performance, there is nothing wrong with the 2.5 Gb Ethernet ports. During testing I was getting 2.35 Gbits/sec both up and down which is about the best speed you can get.\n\nWhen accessing the NAS remotely over a network, I was getting a sequential read speed just under 300 MB/s and a sequential write speed of around 250 MB/s.\n\nIn theory, it would have been possible to include a 10 Gigabit Ethernet port in the design of the ME Mini. For example, Beelink could have swapped one of the existing 2.5 GbE ports for an NVMe slot. This would allow PCIe Root Port 4, which currently has two PCIe lanes allocated to it, for a 10 Gb Ethernet port.\n\nAnd whilst there are other combinations that could be used, none will alleviate the two key problems of a 10 GbE port. The first is heat. All of the 10 GbE controllers I’ve used run very hot and require proper cooling for them to work efficiently. The second issue is cost. It would likely add another 50% to the price and by doing so, change the ME Mini’s market position as being a very cheap yet storage-rich NAS device.\n\nHowever, there is a low-cost solution to improving network throughput. The front left port is a 10 Gbps USB 3.2 Gen 2×1 Type-C port giving you the option of using a 5 Gbps USB Ethernet adapter.\n\nI connected a Wavlink WL-NWU340G USB C to 5 Gbps Ethernet Adapter which uses the Realtek RTL8157 controller and has drivers available from Realtek for both Windows and Linux.\n\nUsing this 5 Gb Ethernet adapter, I was getting at least 4.71 Gbits/sec for both upload and download, which is double the speed of the ME Mini’s Ethernet ports.\n\nObviously, this makes accessing the NAS remotely much faster, and I saw sequential read speeds at just under 600 MB/s and a sequential write speed of around 560 MB/s.\n\nFinally, I also checked whether the faster write speeds would create any issue with the NVMe’s temperatures. Transferring a 100 GB file remotely to the ME Mini saw the continuous write speed drop down to around 450 MB/s, and all the drive temperatures still showed under 50 °C indicating no thermal issues or throttling.\n\nCase colours\n\nAs mentioned, the ME Mini is available in three colours: white, grey and dark turquoise.\n\nKnowing that sometimes, colour choices can be regretted or change over time, I’ve arranged with Beelink, for anyone who owns a ME Mini, the option of purchasing just the case in a different colour for only USD 15.\n\nAll you need to do is email their support at [email protected] to request a different case.\n\nThe case actually comprises of several components: an outer shell, perforated top, base, on/off button, on/off spring, rubber feet and rubber screw-covers. Fortunately, the case you receive will have the top and on/off button installed, meaning all you have to do is swap your existing case and base, and then stick on the rubber accessories.\n\nOn a personal note, I wish the case came in a black option as that would better colour-match some routers, switches and PC cases.\n\nIssues and Limitations\n\nI’ve not found any issues with the ME Mini whilst testing it for this review. There are some “but it doesn’t have” type statements that could be claimed, like “no ECC memory support” or “only 12 GB soldered down memory”, but it’s easy to forgive these omissions given the low price of the hardware.\n\nThe only practical limitation I think is worth highlighting is that the Intel N150 processor is not a very powerful CPU, and it only has four cores without hyperthreading. So, whilst running a few containers will be fine, it is not really suitable for multiple VMs, gaming or other demanding tasks. But the processor is suitable for powering the ME Mini for more basic network attached storage applications.\n\nHighlights\n\nWhat you get for your money is very good value. The ME Mini excels as a low cost, low power, low noise, multi NVMe capacity small footprint NAS.\n\nThe ME Mini is available as barebones for $209 or can be purchased with a 2TB Crucial P3 Plus NVMe drive that additionally includes a Windows 11 Pro license for just $329. Different coloured cases for existing owners are available for $15 by emailing Beelink’s support at [email protected].\n\nI’d like to thank Beelink for providing the review unit.\n\nSupport Liliputing Liliputing's primary sources of revenue are advertising and affiliate links (if you click the \"Shop\" button at the top of the page and buy something on Amazon, for example, we'll get a small commission). But there are several ways you can support the site directly even if you're using an ad blocker* and hate online shopping. Contribute to our Patreon campaign or... Contribute via PayPal * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a * If you are using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a guide that may help you disable it.",
      "source": "Liliputing",
      "url": "https://liliputing.com/beelink-me-mini-review-the-mini-pc-makers-first-nas-supports-6-nvme-ssds/",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Refurb Weekend: Silicon Graphics Indigo² Impact 10000",
      "content": "My general vintage computing projects, mostly microcomputers, 6502, PalmOS, 68K/Power Mac and Unix workstations, but that's not all you'll see. While over the decades I've written for publications likeand, these articles are all original and just for you. My promise: No AI-generated article text, ever. All em-dashes are intentional and inserted by hand. Be kind, REWIND and PLAY.Old VCR is advertisement- and donation-funded, and what I get goes to maintaining the hardware here at Floodgap. I don't drink coffee, but the Mr Pibb doesn't buy itself. :-) Thanks for reading.",
      "source": "Blogspot.com",
      "url": "http://oldvcr.blogspot.com/2025/09/refurb-weekend-silicon-graphics-indigo.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "HEARS Perfection from Brainworx",
      "content": "Personalised EQ curves for hearing correction\n\nBrainworx have announced the release of HEARS Perfection. The software applies personalised EQ correction based on a short listening test, and is designed to be used to compensate for natural hearing differences, age-related changes, or fatigue that can affect accurate monitoring.\n\nUnlike room calibration tools which are designed to help balance speakers or headphones, HEARS Perfection focuses on the listener and their individual hearing ability. Users undertake a built-in listening test lasting around five minutes, which identifies frequency dips in the critical mid and high ranges and creates a personalised corrective EQ curve. Users can scale the compensation amount for dialling in more natural results, and the plug-in’s low CPU footprint makes it suitable for permanent use on the master bus.\n\nAdditional features include channel solo options (L, R, mid, or side) for precision listening, a bypass safety reminder to avoid accidental exports with correction active, and a redesigned modern interface with improved stability.\n\nVideo of HEARS Perfection - Quick Overview | Plugin Alliance\n\nThe plug-in supports VST3, AU, and AAX formats, running on macOS (Intel & Apple Silicon) and Windows 10/11.\n\nPricing & Availability\n\nHEARS Perfection is available now via Plugin Alliance at an introductory price of $79.99 (regular price $129).\n\nwww.plugin-alliance.com/en/products/hears_perfection.html",
      "source": "Soundonsound.com",
      "url": "https://www.soundonsound.com/news/hears-perfection-brainworx",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Intel loses key Ohio fab lobbyist and Xeon architect as delays mount",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250912PD239/intel-ceo-xeon-fab-business.html",
      "timestamp": "2025-09-14"
    },
    {
      "headline": "Apple releases macOS Tahoe 26 with more powerful Spotlight search and its own Phone app",
      "content": "is a senior reporter who’s been covering and reviewing the latest gadgets and tech since 2006, but has loved all things electronic since he was a kid.\n\nPosts from this author will be added to your daily email digest and your homepage feed.\n\nmacOS Tahoe 26 is now available to everyone using compatible MacBooks and Mac desktops. It was first announced last June at WWDC 25 and made available for testing through developer and public betas released over the past three months. This will be the last major macOS update for older Intel-based Macs – specifically those featuring Apple’s T2 Security Chip.\n\nVarious UI elements on Tahoe will have a glossy transparent appearance, revealing what’s beneath them. Image: Apple\n\nThe most notable update with Tahoe will also be its most obvious. It includes a major UI overhaul based on Apple’s new Liquid Glass design language that will feature an extensive use of transparent effects on windows, buttons, and notifications. Tahoe’s menu bar will also be completely transparent, making displays seem a bit larger.\n\nmacOS’ Spotlight search tool and launcher will be more useful with Tahoe, ranking search results intelligently based on relevance and allowing users to perform specific actions with apps like sending an email or creating a note without having to actually open those specific apps. If you like to keep your Mac immaculately organized you can now change the colors of folders or add an emoji to make them stand out.\n\nThe new Phone app can route calls from your iPhone to your desktop so you don’t need to reach for your smartphone to answer them. Image: Apple\n\nA new Phone app will mirror the functionality of the one on iOS and can relay calls from your iPhone through your computer. It will include access to recents and voicemails, as well as new iOS features like Call Screening that can answer calls from unknown numbers for you and Hold Assist that can stay on the line until a real person responds. Leveraging Apple Intelligence, Live Translation can translate text, audio during phone calls or FaceTime calls, and even chats in Messages.",
      "source": "The Verge",
      "url": "https://www.theverge.com/news/777521/apple-macos-tahoe-26-now-available-download-update",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Chinese Chipmaker Stocks Rally As U.S. Firms Face Fresh Beijing Scrutiny",
      "content": "This article first appeared on GuruFocus.\n\nSep 15 - China's latest trade move placed U.S. chipmakers in the spotlight after Beijing opened an anti-dumping probe into American semiconductors. The investigation, announced late last week, aims to protect China's domestic industry and support local firms.\n\nChinese chip stocks jumped on the news. SG Micro, Suzhou Novosense Microelectronics, and 3Peak each surged to their daily trading limit. Semiconductor Manufacturing International (SIUIF), the country's top contract chipmaker, gained 1.3% in Hong Kong, while Hua Hong Semiconductor (HHUSF) advanced 2.9%.\n\nThe probe came just one day after the U.S. Commerce Department placed GMC Semiconductor Technology (Wuxi) and Jicun Semiconductor Technology on its restricted trade list. Both firms were accused of acquiring American equipment for SMIC.\n\nInvestors also watched U.S.-listed chip giants. Nvidia (NASDAQ:NVDA), Advanced Micro Devices (NASDAQ:AMD), Broadcom (AVGO), Intel (INTC), Texas Instruments (TXN), Marvell Technology (NASDAQ:MRVL), QUALCOMM (NASDAQ:QCOM), Micron Technology (NASDAQ:MU), and Analog Devices (NASDAQ:ADI) all traded in focus as markets weighed potential fallout.\n\nThe recent moves highlight increasing technological fissure between Washington and Beijing, each of which is seeking to protect their national supply chains, but preserve their place in world chip manufacturing.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/chinese-chipmaker-stocks-rally-u-123058218.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Open source Cloud Hypervisor adds (maybe futile) no-AI-code policy",
      "content": "The Cloud Hypervisor project has introduced a No AI code policy.\n\nCloud Hypervisor started life in 2018 as a joint effort between Google, Intel, Amazon, and Red Hat – all of which wanted to share their work on virtualization components to speed their respective efforts to create virtual machine monitors and hypervisors. The participants decided that work was best undertaken using Rust and the rust-vmm project is the result.\n\nIntel took the project in a slightly different direction and led to the creation of Cloud Hypervisor, a Virtual Machine Monitor for cloud workloads. The Linux Foundation took on the project in 2021, when Alibaba, ARM, ByteDance, and Microsoft were also part of the project, alongside Intel.\n\nAMD, Ampere, Germany’s Cyberus Technology and China’s Tencent Cloud have since become supporters, and the project now describes itself as “an open source Virtual Machine Monitor that runs on top of the KVM hypervisor and the Microsoft Hypervisor.” It’s mostly used by public clouds as the hypervisor in their IaaS services, and is customized to work with the hardware they buy in bulk.\n\nThe project delivered version 48 last week, complete with the new policy to “decline any contributions known to contain contents generated or derived from using Large Language Models.”\n\nAs detailed in the project’s documentation for contributors, the reasons for the ban are “… to avoid ambiguity in license compliance and optimize the use of limited project resources, especially for code review and maintenance.”\n\nThat wording suggests Cloud Hypervisor’s maintainers fear legal complications and/or contributions comprised of AI slop.\n\nAI coding tools are almost certainly trained on open source code, but it’s hard for developers to know if the LLMs helping them to write software also snarfed copyrighted code or projects published under restrictive licenses. All of Cloud Hypervisor’s contributors are likely targets for lawsuits, so politely declining to accept AI makes sense.\n\nEven though the project’s participants know it’s probably a futile gesture.\n\nIn a thread debating the policy, Cyberus Technology’s Philipp Schuster expressed concern “that this policy will basically be violated starting from day 0 after being merged. We never can ensure code is not at least enhanced with/from LLM.”\n\nIn response, a contributor named Bo Chen suggested “we need a procedure to make sure the policy is explicitly acknowledged. One option is to add a pull request template that includes a mandatory checkbox, requiring contributors to affirm they have read and agree to our contribution guide.”\n\nA notable inclusion in version 48 is documentation on how to run Windows 11 guests, which should help those creating cloudy desktop-as-a-service products.\n\nOther additions that may interest include:\n\nLifting the maximum number of supported vCPUs on x86_64 hosts using KVM from 254 to a whopping 8192;\n\nRemoving support for Intel’s Software Guard Extensions (SGX);\n\nAdding support for inter-VM shared memory;\n\nFaster pausing for VMs that run on many vCPUs.\n\n®",
      "source": "Theregister.com",
      "url": "https://www.theregister.com/2025/09/15/cloud_hypervisor_no_ai_policy/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Walmart is emerging as an AI powerhouse with one big advantage",
      "content": "lighning bolt icon An icon in the shape of a lightning bolt.\n\nlighning bolt icon An icon in the shape of a lightning bolt. Impact Link\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nAnalysts have characterized the recent strength in the stock market as an AI rally, but flying under the Magnificent Seven's radar is Walmart — a company so vast that it literally has its own weatherman.\n\nAnd as it turns out, the retail juggernaut's scale and reach are proving to be tremendous assets in the AI race.\n\nThat's because most top AI companies — like OpenAI, Microsoft, Anthropic, or Meta — operate in a primarily virtual space, processing unfathomably complex rivers of information into more digital information. AI-adjacent companies like Nvidia, Intel, and Oracle focus on providing the physical infrastructure upon which the AI machines function. Then there are the companies that are using digital intelligence to deliver physical results through automation and augmented experiences, like Tesla and Amazon.\n\nWalmart, by contrast, has a vast and complicated set of physical challenges to solve as the largest retailer in the US — and the world. Those include everything from cleaning up spills in the dairy aisle to stocking shelves.\n\n\"We move billions of items around every month, every year,\" Walmart US CEO John Furner said Tuesday at the Fortune Brainstorm Tech conference. He said the company has been developing machine learning tools and other automation projects since around 2015.\n\nFurner said that the company's AI models and supply chain automation help plan inventory to arrive at the right aisle at the right time, for example. One technique involves creating \"digital twins\" of each facility to model the movement of merchandise through the system on its way to customers.\n\nFurner also said store associates increasingly have an AI chatbot handy via their handheld devices to help them better set priorities and help customers.\n\n\"It's a combination of people being powered by technology. There's a lot of judgment to retail and decision-making. And we're in a very dynamic industry,\" he said. \"We think this next phase of physical AI in combination with Gen AI is going to be really helpful.\"\n\nThe company's head of e-commerce, David Guggina, told the Goldman Sachs Communicopia and Tech conference last week how AI is helping his team run experiments and fulfill orders at an increasingly rapid rate.\n\nGuggina said his team is now able to work at breathtaking speed behind the scenes, too.\n\n\"What took a data scientist days or weeks before can now be done in minutes,\" he said.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nAI also helps ensure that each of the company's 4,700 stores has the kinds of products best suited to their local markets, slashing delivery times to minutes after a customer places an order.\n\n\"We've just completed the third inning,\" he said by way of the classic baseball game analogy. \"So we're still early with regard to our automation journey in the fulfillment network.\"\n\nThese digital-to-physical uses of AI are also complemented by a myriad of \"micro agents\" that handle tasks like tracking local event calendars or monitoring inventory levels.\n\nWalmart, of course, is still fine-tuning its AI approach, and there have been hiccups.\n\nThe proliferation of bespoke Walmart-made AI agents eventually started to confuse users, the company told the Wall Street Journal.\n\nThe company has rolled many of those micro agents into four \"super agents\" designed to assist shoppers, merchandisers, programmers, and third-party marketplace sellers.\n\nStill, because Walmart's 20,000-strong global tech team builds so many of these digital and physical solutions in-house, the company is emerging as an unexpected AI powerhouse.\n\nThe company snagged former Instacart exec Daniel Danker in July to accelerate its AI efforts.\n\nIt's also deepening its partnership this month with OpenAI via a new training program for associates and enterprise access to ChatGPT tools for frontline Sam's Club employees to help operate their warehouse stores more smoothly.\n\nAfter all, while chatbots might sometimes hallucinate answers, there's no faking a cold gallon of milk on your doorstep.",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/why-walmart-is-emerging-as-an-ai-powerhouse-2025-9",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "AOMedia Announces Year-End Launch of Next-Gen Video Codec AV2",
      "content": "The Future of Innovation Is Open: AOMedia Member Survey Highlights Adoption Trends\n\nWakefield, Mass. — Sept. 15, 2025 — The Alliance for Open Media (AOMedia), a global collaboration of innovators working together to define and deploy open standards that power the next generation of media experiences, today announced the upcoming launch of the next evolution in open video coding: AV2. Set for a year-end release, AV2 is not only an upgrade to the widely adopted AV1 but also a foundational piece of AOMedia’s future tech stack.\n\nAV2, a generation leap in open video coding and the answer to the world’s growing streaming demands, delivers significantly better compression performance than AV1. AV2 provides enhanced support for AR/VR applications, split-screen delivery of multiple programs, improved handling of screen content, and an ability to operate over a wider visual quality range. AV2 marks a milestone on the path to an open, innovative future of media experiences.\n\n“At AOMedia, we believe innovation thrives when it’s open,” said Dr. Pierre-Anthony Lemieux, Executive Director of AOMedia. “Our standards benefit from input from innovators worldwide and are developed under a royalty-free patent policy, bringing next-generation media experiences to more people, faster. We’re excited to share AV2 with the world, as we continue to lead the way in shaping the future of media through open collaboration.”\n\nSurvey Findings: Widespread Support of AV1 and Planned Adoption of AV2\n\nIn conjunction with its 10th anniversary, AOMedia released new member survey findings that underscore strong industry-wide support for its open innovation model and the widespread adoption of its technologies.\n\nThe survey found that 88% of members ranked AV1 as either “extremely critical” or “important” to their current or future product roadmaps. AOMedia’s Adoption Showcase illustrates the real-world benefits members are achieving through AV1 deployment. Looking ahead, 53% of AOMedia members surveyed plan to adopt AV2 within 12 months upon its finalization later this year, with 88% expecting to implement it within the next two years.\n\nJoin the Future of Open Media Innovation\n\nAOMedia invites new members to help shape the future of open, high-performance media standards. To learn more about membership opportunities, contact membership@aomedia.org.\n\nAbout AOMedia\n\nLaunched in 2015, the Alliance for Open Media (AOMedia) develops open standards for media — spanning video, audio, still images, and immersive technologies. AOMedia brings together 49 global innovators — including tech leaders with decades of media tech experience and some of the world’s largest patent holders — to support this mission. Its steering committee consists of Amazon, Apple, Cisco, Google, Intel, Meta, Microsoft, Mozilla, Netflix, NVIDIA, Samsung Electronics, and Tencent. Learn more at www.aomedia.org.\n\nMedia Contact\n\nMelissa Bednar\n\nAOMedia Public Relations\n\nmbednar@virtualinc.com\n\n781.876.8962",
      "source": "Aomedia.org",
      "url": "https://aomedia.org/press%20releases/AOMedia-Announces-Year-End-Launch-of-Next-Generation-Video-Codec-AV2-on-10th-Anniversary/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "How next-gen laptops use NPUs for massive power savings",
      "content": "Current laptops with Intel Core Ultra Series 2 processors rely on a hybrid chip design that is specifically geared towards energy efficiency. The Neural Processing Unit (NPU), used for the first time in consumer systems, plays a central role here. This dedicated computing unit for AI tasks relieves the CPU and GPU of inference-based processes such as image recognition, language processing, or modelling.\n\nWhile the CPU had to take on many of these tasks in conventional systems, the NPU enables a significantly more differentiated load distribution. This lowers the average system load and noticeably reduces energy requirements. As many NPU calculations can be carried out at a low clock frequency and in parallel, the energy balance is significantly improved compared to purely CPU- or GPU-based architectures.\n\nEnergy-saving components in Intel Core Ultra\n\nThe Intel Core Ultra V models in particular combine four performance cores with four efficiency cores and a dedicated NPU to form a tiered computing unit. The P-cores take over performance-critical tasks, while the E-cores and NPU remain continuously active in the background and run routine processes and AI functions with low power requirements.\n\nMark Hachman / IDG\n\nThe integrated Intel Arc Graphics also plays a role in this context: it enables hardware-accelerated video decoding and graphics-intensive display without an additional dedicated GPU, which relieves the cooling system and reduces the overall power consumption. The NPU delivers up to 48 TOPS of computing power with minimal power consumption. This benefits AI applications and AI functions as well as users, as the energy requirements of notebooks can be significantly minimised.\n\nIntel\n\nMicrosoft’s energy-saving mechanisms under Windows 11\n\nParallel to the hardware platform, new energy-saving strategies have been implemented with Windows 11. The “User Interaction-Aware CPU Power Management” analyzes user activity in real time. If no interaction via keyboard, mouse, or touchpad is detected, the system automatically throttles CPU performance without interrupting active media playback or presentations. In addition, the “Adaptive Energy Saver” function also activates the energy-saving mode regardless of the battery status, provided the system load and usage scenario allow this.\n\nSam Singleton\n\nIn both cases, the NPU can ensure that AI-supported functions remain active in the background without negatively impacting the energy balance. The AI also balances priorities in the background, for example by delaying cloud synchronization or adaptive process rest.\n\nHP Omnibook and other Copilot models in comparison\n\nDevices such as the HP’s Omnibook X line already integrate these technologies system-wide. In combination with an Intel Core Ultra 7 258V and an Intel Arc 140V GPU, the NPU enables locally executed features such as Windows Studio Effects or AI functions in HP AI Companion without noticeably draining the battery. Many other models also achieve battery runtimes of over 24 hours in mixed operation thanks to the use of NPUs. Models such as the Surface Laptop 6 or the Surface Pro 10 integrate a dedicated NPU directly into the Intel Core Ultra SoC, supplemented by high-performance CPU cores and integrated graphics.\n\nOther compatible devices also rely on the Copilot concept, which combines powerful NPUs with intelligent energy management. Devices such as the Galaxy Book with RTX 4050/4070 or the Surface Pro 10 with Intel Core Ultra 7 demonstrate these possibilities. In practice, this means that even when language translation, background blurring or real-time image optimization are actively used, power consumption remains low.\n\nSoftware-based optimization and AI offloading\n\nA significant contribution to energy savings is made by shifting compute-intensive workloads to the NPU on the software side. Applications such as Zoom, Adobe Premiere Pro or Amuse are increasingly using native ONNX runtime-based interfaces to offload AI processes such as image generation, object tracking or audio filters to the NPU.\n\nAdobe\n\nThis reduces the energy requirements of the CPU, which is particularly noticeable during long periods of use in video conferences or creative applications. The NPU is accessed via standardized interfaces such as DirectML and Intel and AMD platforms, which have native integration into the ONNX runtime. The resulting reduction in load on the main processors makes a decisive contribution to more even load distribution and therefore longer battery life.\n\nInteraction of CPU, GPU, and NPU in practice\n\nIn modern notebooks, the CPU, GPU, and NPU work as a dynamic processing trio. While the CPU continues to control the operating system and general applications, the GPU takes over graphics-intensive tasks or parallelized computing operations. The NPU concentrates on dedicated AI processes and enables continuous processing with low energy consumption. Windows 11 assigns these tasks specifically, and continuously evaluates which unit is most efficient for execution.\n\nIDG / Mark Hachman\n\nThis means that recurring tasks such as speech transcription, person recognition, or background noise filters can be processed directly on the NPU. This not only lowers power consumption, but also reduces the system temperature, which enables lighter cooling systems and therefore more compact and lighter notebook designs overall.\n\nLocal processing instead of cloud offloading\n\nThe local execution of AI workloads on the NPU replaces the usual cloud access in many cases. This means that image analyses, language models, or layout suggestions no longer have to be calculated online, but run entirely on the device. This not only reduces latencies, but also avoids unnecessary network activity. This is another factor that reduces power consumption.\n\nAt the same time, the availability of these functions is increased even without a network connection, for example on the train or when travelling. Battery life then benefits in two ways: through lower computing load on the CPU and GPU and through reduced Wi-Fi or LTE/5G activity.\n\nWindows 11 shows NPU utilization in Task Manager for the first time\n\nMicrosoft has expanded the Task Manager for control and transparency of this new architecture. In addition to CPU, GPU, and RAM, NPU utilization is now also displayed as a separate measured value. This allows users to understand how much their AI applications are actually benefiting from the dedicated hardware.\n\nFor developers, the ONNX runtime in combination with the Windows Performance Analyzer also offers detailed diagnostic functions that can be used to specifically analyze inference times, operator load, and load curves. This enables fine-tuned optimization for maximum energy gain and minimum runtime delay.\n\nSam Singleton\n\nBattery life as the new benchmark for AI PCs\n\nWhile attention has long focused on computing power and model size, there is now a paradigm shift. The actual runtime of a device is increasingly becoming the most important quality criterion for AI-optimized notebooks. Modern AI notebooks achieve video playback times of over 26 hours under realistic conditions, a value that would be almost impossible to realize without NPU-supported power distribution.\n\nAt the same time, the combination of an adaptive energy-saving mode, local AI offloading, and intelligent load controls opens up new possibilities for mobile applications where the power supply is not always guaranteed.\n\nConclusion: Saving energy with specialized AI hardware\n\nThe integration of NPUs into current notebook platforms not only marks a technological advance in terms of AI performance, but also enables a sustainable reduction in energy consumption through intelligent task sharing for the first time. In combination with the new energy-saving functions of Windows 11, the result is a platform that not only works faster in everyday use, but also noticeably more efficiently. For users, this means longer battery life, less waste heat, quieter systems, and an overall better balance between performance and mobility, without sacrificing modern AI functions.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2888029/how-next-gen-laptops-use-npus-for-massive-power-savings.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "iOS 26, iPadOS 26, macOS Tahoe, watchOS 26, tvOS 26, And visionOS 26 Are Now Available",
      "content": "After three long months of beta testing, Apple has made iOS 26, iPadOS 26, macOS Tahoe, watchOS 26, tvOS 26, and visionOS 26 available to all users. If you have compatible devices, you can download Apple's latest software by going to Settings > General > Software Update.\n\nAll of these software updates feature the new Liquid Glass design. While it's going to be more noticeable on iOS, iPadOS, and macOS, Apple also tweaked the UI of watchOS, tvOS, and visionOS. With this redesign, Apple users can take advantage of new Clear icons, redesigned Control Center, new looks for the apps, and finally having the names of all the updates match.\n\nFor iPadOS 26, Apple is getting more serious about multitasking and productivity features, as the company now offers a new window tiling system, a Preview app for signing documents and sketching, and improved Apple Intelligence features powered by ChatGPT. macOS Tahoe brings improved Continuity functionalities, a revamped Spotlight search, and it also marks the last major OS update for Intel Macs. Apple says macOS 27 will be only available to Apple Silicon computers.",
      "source": "BGR",
      "url": "https://www.bgr.com/1968552/ios-26-ipados-26-macos-tahoe-watchos-26-tvos-26-visionos-26-download-now-available/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Condor Technology to Fly \"Cuzco\" RISC-V CPU into the Datacenter",
      "content": "Once a hyperscaler or a cloud builder gets big enough, it can afford to design custom compute engines that more precisely match its needs. It is not clear that the companies that make custom CPUs and XPUs are saving money, but they are certainly gaining control and that is worth something.\n\nArm made a push based on the power-efficient nature its architecture, and Nvidia has become a key player in AI with its powerful GPUs and now its “Grace” Arm server CPUs. A reinvigorated AMD has given system makers an x86 alternative to an Intel that is still trying to find its footing after a few years of missteps and missed deadlines. And now, the community for RISC-V, the open, modular, and highly customizable architecture overseen by the RISC-V International collective, is looking to make inroads into datacenters.\n\nIt is still early days for RISC-V, much as it was for Arm in the datacenter back in 2010, but the RISC-V architecture is being embraced by a range of well-known tech vendors, from Intel, Western Digital, Google, Nvidia, Meta Platforms, and Qualcomm, and a growing number of pure-plays and startups, such as Andes Technology, SiFive, Microchip Technology, Ventana, and Lattice Semiconductor.\n\nThere also is money backing the effort. Most recently, the European Union continued its on-again, off-again courting of RISC-V for supercomputers and other HPC systems in the region with the launch in March of DARE – Digital Autonomy with RISC-V in Europe – to oversee a six-year, $260 million effort.\n\nCondor Takes Flight\n\nAndes is two decades old and, despite its name, is based in Taiwan, not in Colombia, Chile, Peru, or Argentina where the mountain range of that name is located on the western coast of South America. The company is a founding member of RISC-V International and a maker of efficient and low-power processor cores based on the architecture.\n\nMark Evans, director of business development at Andes and now its Condor Computing subsidiary that was established in Austin, Texas to get indigenous to the United States, gave an overview of the company in a session at the AI Infra Summit in Santa Clara last week. The week before that Ty Garibay, Condor’s founder and president, and Shashank Nemawarkar, Condor’s director of architecture, walked everyone through the “Cuzco” core that the company has created to begin its assault on the datacenter in earnest.\n\nEvans says that Andes has shipped its intellectual property in over 17 billion RISC-V chips since 2005, and further that it has been growing sales at a compound annual growth rate of 29 percent between 2018 and now. Evans put some numbers on it, saying that Andes had $42 million in sales in 2024, and that its IP was present in 30 percent of RISC-V SoCs that were shipped last year.\n\nThe Andes customer base is pretty broad across various industry sectors, including MediaTek and Novatek in mobile devices, Phison in storage, and Meta Platforms and SK Telecom in AI compute engines.\n\nEvans says that 39 percent of the revenue that Andes had in 2024 came from the AI sector, significantly including the MTIA v1 and MTIA v2 coprocessors from Meta.\n\nThat brings us to the “Cuzco” RISC-V core that Condor was showing off at the Hot Chips 2025 conference.\n\nIn July, Condor successfully did full hardware emulation of the Cuzco core, booting multiple operating systems, including Linux, with the first users expected to get the processor sometime in the last quarter. This high-performance RISC-V core has microarchitectural tweaks, including the way it issues instructions and organizes execution units, all with the aim of creating what Garibay said will be “the world’s highest performance licensable RISC-V CPU IP,” with a broad range of use cases.\n\n“We’re entirely focused on bringing an innovative new microarchitecture to the RISC-V CPU market,” Garibay said during a presentation at Hot Chips. “We intend to demonstrate that RISC-V can be competitive in any high-performance computing application, from datacenters to handsets to automotive. … Our goal is to provide much better performance than other high-performance, licensable CPUs while operating at a similar power envelope.”\n\nCuzco is based on the latest RISC-V profile for datacenter computing – RVA-23 – so ensure high software compatibility, can support up to eight cores with up to 8 MB private L2 cache in a coherent cluster with a shared 256 MB L3 cache, and a 12-stage pipeline. There are functional units that execute through a pool after the eight-instruction dispatch. The CPU itself is standard, with fetch, instruction queue, and instruction decode, he said.\n\nBelow is a more detailed block diagram of the Cuzco core:\n\nHere is the cache memory architecture:\n\nAnd here is the socket architecture:\n\nThe structure of the core is what is really interesting with Cuzco, so we are going to spend our time there.\n\nOne area Condor focused on was the structure of the execution units, which Garibay said are pair into two pipelines called a “slice,” with each of the four slices being identical and each having its own pipelines and resources.\n\n“Each slice fully implements RISC-V compatibility,” he said. “The machine is scalable, in theory, down to one slice or pair of pipelines, although. practically probably, only anyone would ever implement is two slices. As a minimum machine, the overhead becomes unwieldy at that point. But it is scalable to six pipelines, three slices by default – eight pipelines, four slices – and then we will extend this architecture into the future, with added features as we grow the slice count.\n\nThe intent, he said, “was to ease the implementation of this in high-performance processes.”\n\nThen comes the time-based architecture for instruction sequencing. The chip starts out with what Nemawarkar called “a standard pipeline for the out-of-order machines. Typically, this is a 12-log stage pipeline. The instruction fetch, nothing different than most of it you have seen.”\n\nChanges come from the point of where instruction decode happens, Nemawarkar said. That’s where the time-based issuing logic kicks in. Most chips use Tomasulo’s algorithm, a process for the out-of-order scheduling of instructions. In these cases, the chips use content-addressable memories (CAMs) to point to instructions to send downstream. CAMs can eat up a lot of power, given the match-line switching and precharge cycles needed.\n\nCuzco uses its register scoreboard to record the write time of an instruction to a register, which then becomes the read time. The scoreboard says when the instruction is available for execution and tracks the future of write time of instructions. The chip’s time resource metrix (TRM) records the use of resources like arithmetic logic units (ALUs), buses, and load and store queues to help predict ahead of time what resource will be available, which enables predictive scheduling. Instructions can be issued with an understand of exact future cycles for operands and resources, according to Andes.\n\nIt also does away with the power-hungry CAMs.\n\n“The reasoning behind that is this allows us to reduce the complexity, which typically happens in the global scheduling or a local scheduling or combination of that, when the machines start to become wider and wider,” Nemawarkar said. “Everybody knows that being a huge problem. Then essentially, with each execution unit, you need to start looking at which instructions are ready, how do I execute based on the priority for which instruction to be given, etc.”\n\nIt’s something that other implementations haven’t tried before, according to Garibay.\n\n“It is a departure, and it’s a good departure in that we’re looking to reduce the overall power and area of what has become the most power-and-area-hungry part of these wide, out-of-order machines – instruction scheduling,” Garibay added.\n\nEnterprises and HCP centers will be able to put Cuzco to the test by the end of the year so see how the new execution units and out-of-order instruction scheduling will work for them.",
      "source": "The Next Platform",
      "url": "https://www.nextplatform.com/2025/09/15/condor-technology-to-fly-cuzco-risc-v-cpu-into-the-datacenter/",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Intel trims full-year expense outlook following Altera stake sale",
      "content": "(Reuters) - Intel said on Monday it has lowered its full-year 2025 adjusted operating expense target to $16.8 billion, from $17 billion earlier, to reflect the deconsolidation of its programmable chip business, Altera.\n\nShares of the struggling chipmaker rose nearly 4% as the trimmed projected expenses provided investors with some respite after burgeoning costs left Intel with a strained balance sheet.\n\nThe company recorded an annual loss of $18.8 billion in 2024, its first such loss since 1986, after former CEO Pat Gelsinger poured billions into expanding its loss-making contract-manufacturing business.\n\nNew CEO Lip-Bu Tan is streamlining operations and making management changes to strengthen the company's finances.\n\nThis comes as the U.S. government has taken a 10% equity stake by converting Biden-era grants into shares.\n\nIn April, Intel agreed to sell 51% of Altera to private equity firm Silver Lake, valuing the unit at $8.75 billion, well below the nearly $17 billion Intel paid in 2015.\n\nIntel completed the transaction on September 12, with Silver Lake acquiring a majority stake in Altera for an equity value of about $3.3 billion, according to a regulatory filing, reflecting debt financing and cash for the business.\n\nAs an Intel segment in the first half of 2025, Altera reported a 55% gross margin on $816 million in revenue and $356 million in operating expenses.\n\nIntel kept its 2026 full-year operating expense target at $16 billion.\n\nThe company said in July it will end this year with a workforce more than a fifth smaller than last year. Tan has pledged tighter cost discipline and “no more blank checks.”\n\n(Reporting by Arsheeya Bajwa in Bengaluru; Editing by Tasim Zahid)",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/intel-lowers-full-expense-target-101915801.html",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Top Stock Movers Now: Tesla, Intel, Nvidia, and More",
      "content": "Key Takeaways U.S. equities mostly rose at midday on optimism about U.S.-China trade and TikTok's future.\n\nTesla CEO Elon Musk purchased about $1 billion in the electric vehicle maker's stock.\n\nChinese regulators are investigating U.S. chipmakers for alleged dumping of analog integrated circuit semiconductors.\n\nU.S. equities were higher at midday on positive comments about China trade and the future of TikTok from President Trump, as well as Tesla (TSLA) news. S&P 500 and Nasdaq gained, while the Dow Jones Industrial Average was little changed.\n\nTesla shares jumped as a regulatory filing showed CEO Elon Musk purchased 2.57 million shares of the electric vehicle's stock valued at about $1 billion.\n\nShares of Seagate Technology Holdings (STX) traded above $200 for the first time on continued excitement over the company's new hard disk drive for artificial intelligence data centers.\n\nIntel (INTC) shares climbed after the struggling semiconductor maker reduced its target for full-year non-GAAP operating expenses after completing the $3.3 billion sale of a majority stake in its Altera programmable chip business to private equity firm Silver Lake.\n\nAlphabet (GOOGL) shares were up for a third straight session, making the parent of Google the fourth company with a $3 trillion market capitalization.\n\nCorteva (CTVA) was among the worst-performing stocks in the S&P 500 following a report that the manufacturer of crop seeds and pesticides is looking into splitting itself into two separate companies.\n\nSome chipmakers, including Nvidia (NVDA) and Texas Instruments (TXN), fell as Chinese regulators were investigating potential dumping of analog integrated circuit semiconductors from the U.S.\n\nU.S.-listed shares of AstraZeneca (AZN) declined after a report the drugmaker had paused a planned $272 million investment in Britain, and received a downgrade from Europe's Handelsbanken.\n\nOil and gold futures rose. The yield on the 10-year Treasury note declined. The U.S. dollar lost ground to the euro, pound, and yen. Prices for most major cryptocurrencies dipped.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/top-stock-movers-now-tesla-intel-nvidia-and-more-11809916",
      "timestamp": "2025-09-15"
    },
    {
      "headline": "Lenovo IdeaPad Slim 3i: 15.6\" FHD, i3-N305, 8GB LPDDR5, 128GB UFS $219.99",
      "content": "You have chosen to downvote this deal.\n\nThere is no voting data on this thread\n\nHelp the community know if this is a good deal.\n\nHeads up, this deal has expired. Want to create a deal alert for this item? Add Deal Alert\n\nexpired Dr.W posted Item 1 of 3 Item 1 of 3 expired Dr.W posted Lenovo IdeaPad Slim 3i: 15.6\" FHD, i3-N305, 8GB LPDDR5, 128GB UFS $219.99 $220 $450 51% off Best Buy 7 There is no voting data on this thread You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther 2,383 Views Visit Best Buy Good Deal Bad Deal You have chosen to downvote this deal. Not a good price\n\nNot a good product\n\nPoor Merchant Reputation\n\nUnable to replicate deal\n\nIncorrect Information\n\nSpam, Self Promotion\n\nRepost\n\nOther Save Share\n\nDeal Details SPECS: 15.6\" FHD (1920x1080) 16:9, 250-nits, 45% NTSC, Anti-glare, TN Display\n\nIntel Core i3-N305 (8C / 8T, Max Turbo up to 3.8GHz, 6MB)\n\n8GB Soldered LPDDR5-4800\n\n128GB UFS 3.1\n\nWindows 11 Home in S mode, English\n\nWi-Fi 6, 802.11ax 2x2 + BT5.2\n\nNon-backlit, English Keyboard\n\nHD 720p with Privacy Shutter\n\n47Whr Battery\n\n1.55 kg (3.42 lbs.)\n\nModel: 82XB00C2US\n\nPorts: 2x USB 3.2 Gen 1 1x USB-C 3.2 Gen 1 (support data transfer, Power Delivery and DisplayPort 1.2) 1x HDMI 1.4 1x Headphone / microphone combo jack (3.5mm) 1x Card reader 1x Power connector\n\n\n\nhttps://www.bestbuy.com/product/l...JJGSHX7VWQ Community Notes This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions. Add Entry About the Poster Dr.W Follow Give Rep Message 8,032 Deal Posts 11,542 Comments Posts 16,996 Reputation Points 10,806 Votes Submitted Deal Details Community Notes About the Poster SPECS: 15.6\" FHD (1920x1080) 16:9, 250-nits, 45% NTSC, Anti-glare, TN Display\n\nIntel Core i3-N305 (8C / 8T, Max Turbo up to 3.8GHz, 6MB)\n\n8GB Soldered LPDDR5-4800\n\n128GB UFS 3.1\n\nWindows 11 Home in S mode, English\n\nWi-Fi 6, 802.11ax 2x2 + BT5.2\n\nNon-backlit, English Keyboard\n\nHD 720p with Privacy Shutter\n\n47Whr Battery\n\n1.55 kg (3.42 lbs.)\n\nModel: 82XB00C2US\n\nPorts: 2x USB 3.2 Gen 1 1x USB-C 3.2 Gen 1 (support data transfer, Power Delivery and DisplayPort 1.2) 1x HDMI 1.4 1x Headphone / microphone combo jack (3.5mm) 1x Card reader 1x Power connector\n\n\n\nhttps://www.bestbuy.com/product/l...JJGSHX7VWQ",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18625735-lenovo-ideapad-slim-3i-15-6-fhd-i3-n305-8gb-lpddr5-128gb-ufs-219-99",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "ASML Stock Upgraded: Morgan Stanley Sees Big Upside Ahead",
      "content": "ASML Holding N.V. (NASDAQ:ASML) is one of the AI Stocks in Focus on Wall Street. On September 22, Morgan Stanley upgraded the stock to “Overweight” from Equal Weight with a price target of €950. The firm sees “early signs of improvement” for ASML.\n\n“Since peaking last year (Jul’24), earnings forecasts have been revised significantly downwards for ASML, as is typical in a downcycle, with a marked effect on the share price (down 45% peak to trough).”\n\nThe firm said its upgrade is a reflection of positive earnings revisions and cyclical recovery despite market concerns.\n\n“Our upgrade reflects the potential for positive earnings revisions and cyclical recovery – focus to shift to 2026-27 debate. FY27e EPS could approach €33 (8% ahead of consensus) on strength in memory, mix effects and cost controls. We expect order momentum to build before year-end 2025 for delivery in late 2026/27. Despite the recent rally, we think the share price still reflects flat layer count, weak China, and minimal sales from Intel and Samsung. We upgrade ASML to Overweight, with a PT of €950, implying 20% upside.”\n\nASML Holding N.V. (NASDAQ:ASML) develops and sells advanced semiconductor equipment, including lithography, metrology, and inspection systems for chip manufacturing.\n\nWhile we acknowledge the potential of ASML as an investment, we believe certain AI stocks offer greater upside potential and carry less downside risk. If you're looking for an extremely undervalued AI stock that also stands to benefit significantly from Trump-era tariffs and the onshoring trend, see our free report on the best short-term AI stock.\n\nREAD NEXT: 10 AI Stocks You Should Not Ignore and 10 Must-Watch AI Stocks on Wall Street.\n\nDisclosure: None.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/asml-stock-upgraded-morgan-stanley-032125937.html",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "AMD Target Raised to $200 on AI Gains, CPU Momentum",
      "content": "This article first appeared on GuruFocus.\n\nAdvanced Micro Devices (AMD, Financials) won fresh support on Wall Street after Bank of America analyst Vivek Arya reiterated a Buy rating and set a $200 price target, pointing to continued growth in artificial intelligence chips and server CPUs. The target represents about 27% upside from current levels.\n\nArya said AMD's share gains in AI and data-center markets outweigh slower trends in cyclical businesses such as consoles and embedded chips. The company's accelerated roadmap includes the MI325X entering mass production this year and the MI350 coming later in 2025, followed by a new AI server platform in 2026.\n\nThe call comes as investors digest Nvidia's $5 billion investment and product pact with Intel, a move seen as strengthening competition in data-center and PC processors. Arya argued the deal could actually benefit AMD, since both companies rely on the x86 ecosystem that AMD also licenses, making the market more robust overall.\n\nAMD stock is up more than 30% this year, though it has been volatile, trading between $76 and $187 over the past 12 months. Analysts hold a Moderate Buy consensus on the stock, with an average target of $188.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/amd-target-raised-200-ai-121944722.html",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Bubblemaps to airdrop 30 million BMT tokens to users uncovering crypto scams",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/e61dadc44d3d0e8e",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Obsidian governs AI agent access in SaaS environments",
      "content": "Obsidian Security has launched a SaaS AI agent defense, providing enterprises with a purpose-built solution to govern how AI agents access data in SaaS environments.\n\nWith SaaS now one of the most targeted layers of the enterprise stack, Obsidian is closing the enterprise AI agent-to-SaaS blindspot, where unmanaged agentic AI integrations and excessive privileges can create cascading risk.\n\nIn the recent Salesforce attack (UNC6040), threat actors used voice phishing campaigns to obtain initial access and run bulk API queries for large-scale data theft and extortion. The Salesloft Salesforce supply chain breach (UNC6395) illustrated the fragility of SaaS-to-SaaS integrations where one compromised chatbot integration expanded into unauthorized access across Salesforce and downstream applications, including Google Workspace, Slack, Amazon S3, Microsoft Azure and other services at hundreds of enterprises.\n\nThe rise of AI agents and its adoption further escalates the SaaS security challenge. Low-code and no-code platforms like Microsoft Copilot Studio, ChatGPT Enterprise, Salesforce Agentforce and n8n let any employee build and deploy agents that act inside SaaS applications, chaining tasks, querying data, and executing decisions autonomously without oversight.\n\nThese agents often carry broad privileges, long-lasting tokens and move sensitive business data at machine speed. If compromised, they can leak data, escalate access and move laterally across connected SaaS applications, causing widespread damage.\n\n“The AI agent shift is well underway, and we’re seeing the risks firsthand as we help our customers scale adoption securely,” said Hasan Imam, CEO at Obsidian. “87% of enterprises have Microsoft Copilot enabled, more than half the agents access sensitive data, 90% are over-permissioned, and move 16 times more data than humans accessing SaaS applications. These risks are not theoretical, they’re active risks inside enterprises today, often without their awareness.”\n\nSecurity tools lack visibility into machine-driven activity, cannot contextualize underlying privileges and are unable to enforce controls at the speed and scale of autonomous agents.\n\n“The difference between a major intrusion and successful containment comes down to speed,” said Sunil Seshadri, EVP and CSO at HealthEquity. “Most security teams already struggle to react to incidents fast enough and AI agents raise the stakes even higher. They can trigger workflows across multiple SaaS apps in seconds, often without anyone noticing until damage is done. Obsidian flips that dynamic by detecting issues in near real-time, faster than most security tools are able to, giving teams the chance to shut them down before they spiral out of control.”\n\nProtecting SaaS environments from AI agent risks\n\nObsidian is uniquely positioned to address the security risks created by autonomous AI agents in SaaS environments. At its core is the SaaS threat dataset repository, over 500 curated real-world threat intelligence, enriched with browser-based activity capture and deep SaaS and AI integrations.\n\nThis intelligence powers the Obsidian Knowledge Graph, a continuously learning model that unifies user and agent activity, identity privileges, and workflows across SaaS and SaaS managed agentic AI platforms into a single correlated view. This live map gives security teams real-time visibility and context to govern agentic AI usage and stop unauthorized agents and behavior inside SaaS environments, where risks emerge and propagate.\n\n“In customer deployments, our continuously learning Knowledge Graph revealed that AI agents in SaaS environments were typically granted ten times more permissions than needed when mapped against real user privileges and entitlements, visibility only Obsidian can deliver,” said Khanh Tran, CPO at Obsidian. “By connecting popular AI platforms like Microsoft Copilot Studio, n8n, Salesforce Agentforce, and ChatGPT Enterprise with the Obsidian Knowledge Graph, security teams can finally see what agents are doing in SaaS. That intel means they can stop risks before they spread and empower users to innovate faster without sacrificing security or governance.”\n\nThis product release is enabling enterprises securely scale AI agent development. Key capabilities in the latest release include:",
      "source": "Help Net Security",
      "url": "https://www.helpnetsecurity.com/2025/09/23/obsidian-ai-agents-saas-environments/",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "High-End Intel Arc GPUs See Another Lifeline as Intel Hires More Engineers",
      "content": "Intel's higher-end Arc GPUs—whether the current Xe2 \"Battlemage\" or the previous Xe \"Alchemist\"—typically arrive later, as the new Arc product family launches with lower-end and mid-range SKUs first. This has historically created rumors that Intel is retreating from the higher-end play, much like AMD did with its current RDNA 4 portfolio. However, Intel's newest job listing suggests that these rumors couldn't be further from the truth, as Intel is now hiring more engineers to work on these high-end GPUs. The job listing notes: \"In this role, you will have the opportunity to work on cutting-edge technology, and you will be responsible for optimizing and validating the Gaming performance of our High-end Desktop System-on-Chip (SoC) designs focusing on dGFX Gaming performance.\" The focus here lies on gaming high-end dGFX SoCs, which are actually higher-end discrete GPUs.Additionally, the company spokesperson recently confirmed that \"Intel will continue to have GPU product offerings,\" despite NVIDIA's $5 billion investment . This has given current and potential future users of Arc a good indication that Intel will continue to invest in its GPU platform for gamers. As a reminder, Intel currently ships Arc \"Battlemage\" GPU generation, with the higher-end Arc B770 reportedly planned for the holiday season. The company plans to use a part of its Xe3 \"Celestial\" for graphics rendering and Xe4 \"Druid\" for media and display duties in its upcoming \"Nova Lake\" SoCs scheduled for 2026. We are yet to see if Intel's upcoming high-end GPUs are a match for current and next-generation offerings from AMD and NVIDIA.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341263/high-end-intel-arc-gpus-see-another-lifeline-as-intel-hires-more-engineers",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Intel Could Kill This Business Unit Thanks to the Nvidia Deal",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/5c5842209639b5bb",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "'Hybrid creep' is spreading as more companies tighten RTO rules",
      "content": "A number of high-profile companies have announced they will require more days of in-office work.\n\nA number of high-profile companies have announced they will require more days of in-office work. Bo Zaunders/Getty Images\n\nA number of high-profile companies have announced they will require more days of in-office work. Bo Zaunders/Getty Images\n\nThis story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.\n\nSorry, home-office enthusiasts. So-called \"hybrid creep\" is gaining traction.\n\nEmployers are gradually increasing the number of days that workers must show up at the office. For example, this month Intel began requiring staffers to come in at least four days a week, up from three previously. NBCUniversal, Starbucks, and Bank of New York Mellon Corp. recently implemented similar mandates.\n\nA new survey of 2,000 full-time US workers found that nearly a third of employers revised their remote or hybrid work policies in the past year. Video-conferencing company Owl Labs, which commissioned the poll and claims it came up with the term \"hybrid creep,\" found that 34% of respondents are now required to be on-site at least four days a week. That is up from 32% in 2024 and 23% in 2023.\n\n\"This is the boiling-frog concept,\" Frank Weishaupt, CEO of Boston-based Owl Labs, told Business Insider. Instead of suddenly demanding workers return to the office full-time after several years of hybrid — and before that, fully remote — schedules, they've been taking things slow, he said.\n\nIt's likely that employers going with a baby-step approach aren't using stricter return-to-office mandates as a way to nudge workers to resign, said Peter Cappelli, a professor of management at the University of Pennsylvania's Wharton School.\n\n\"Nobody's quitting now anyway,\" he said.\n\nInstead, companies may be easing staff back into commuting incrementally to avoid stirring resentment, which can hamper productivity. Just because workers aren't handing in resignations as frequently as they used to doesn't mean they're happy with less flexibility, Cappelli said.\n\nRelated stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know\n\nCompanies generally want workers back at the office so they can monitor them more closely and spur more collaboration. Yet five-day RTO mandates have come with some hiccups, as Business Insider previously reported.\n\nAmazon's shift in January from three to five mandatory office days left workers scrambling for desks and meeting rooms, while Dell's March orders for employees living near an office to come back full time resulted in uneven compliance. Some workers at the tech company resumed eight-hour office days, while \"coffee badgers\" showed up only briefly.\n\nStill, returning to a fully in-person workweek may result in some employees resigning, even in today's job-hugging economy, because of child- or elder-care needs, said Pace University management professor Andrew Coggins.\n\nReturning to fully in-person schedules \"can be a big jump,\" he said.\n\nOwl Labs's survey suggests that more workers are warming up to office life. Some 21% of respondents said they'd like to be on-site as many as four days a week, an increase from 17% in last year's report. Yet nearly half of workers polled said they still lack the overall work flexibility they want, and 37% said they'd decline a job offer from a company that doesn't allow flexible working hours.\n\nIt's possible that hybrid creep is a sign that the era of flexible work is coming to an end — at least at some companies. \"I think employers would prefer five days,\" said Coggins. \"They have more control.\"",
      "source": "Business Insider",
      "url": "https://www.businessinsider.com/hybrid-creep-employers-increasing-rto-days-office-2025-9",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Dean of Valuation Aswath Damodaran Says He’d Rather Have His Money in Intel Than NVIDIA (NVDA)",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/ae54212c4976515f",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Karoline Leavitt demands firings after Trump forced to walk up non-working UN escalator",
      "content": null,
      "source": "Raw Story",
      "url": "https://www.rawstory.com/trump-leavitt-escalator/",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Acer Swift X 14 (Cert. Refurb): 14.5\" 2.8K 120Hz OLED, Intel Ultra 7 155H, RTX 4060, 16GB LPDDR5, 1TB SSD $818.99",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18627175-acer-swift-x-14-cert-refurb-14-5-2-8k-120hz-oled-intel-ultra-7-155h-rtx-4060-16gb-lpddr5-1tb-ssd-818-99",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Stock market today: Nasdaq, Dow, S&P 500 fall with divided Fed, Alibaba in focus",
      "content": "US stocks fell on Wednesday as Wall Street digested mixed messaging from Fed officials on interest rates.\n\nThe S&P 500 (^GSPC) slid 0.3% while the Dow Jones Industrial Average (^DJI) declined by about 0.4%, The tech-heavy Nasdaq Composite (^IXIC) dropped 0.3%. The declines marked a reversal from the indexes' earlier gains.\n\nDebate over the prospects for US interest rate cuts — the big focus for markets right now — appeared to pressure stocks. Comments from Federal Reserve officials this week have hinted at growing disagreement on what the path of policy should be, given cracks showing in the labor market.\n\nFed Chair Jerome Powell reiterated in a speech on Tuesday that the central bank would proceed cautiously on further rate cuts, even as he left the door open to more easing. He also described stocks as \"fairly highly valued.\"\n\nWall Street is now counting down to the release of the Fed's preferred inflation gauge, the Personal Consumption Expenditures index, on Friday. Markets are watching for reassurance that inflation isn't posing a threat to high expectations for two more rate cuts this year.\n\nOn Wednesday, fresh data from the Commerce Department's Census Bureau showed new home sales unexpectedly surged in August as mortgage rates began to ease, bringing homebuyers off the sidelines and releasing pent-up demand. Still, affordability concerns persist.\n\nMeanwhile, some tech stocks are showing gains despite a broader drop across the Nasdaq, which snapped a winning streak on Tuesday amid losses for the \"Magnificent Seven\" Big Tech stocks.\n\nAlibaba stock (BABA) jumped 8% as investors welcomed the Chinese tech giant's pledge to hike its AI spending beyond its original $50 billion target. The boost is needed for Alibaba to keep pace as global investment in AI surges to $4 trillion, its CEO said.\n\nTesla (TSLA) shares climbed 4% and were on track to close at their highest level in 2025 as analysts at investing firm Mizuho Securities lifted their price outlook on the stock to $450. The analysts noted the EV maker is seeing only a \"muted\" impact from tariffs and boosted optimism for the company's robotaxi ambitions.\n\nAt the same time, Micron's (MU) stronger-than-expected quarterly earnings delivered a positive signal for the AI trade, though shares in the memory chipmaker — which supplies semiconductors for Nvidia's (NVDA) AI systems — fell on Wednesday.\n\nLIVE COVERAGE IS OVER\n\n25 updates",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-nasdaq-dow-sp-500-fall-with-divided-fed-alibaba-in-focus-230354294.html",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Analysis: Dell Technologies, Inc. announces Q2 FY2026 financial results",
      "content": "Dell Technologies, Inc. has announced financial results for the second quarter of FY2026 (ending 1st August 2025). Revenue rose 19.0% year-on-year to $29.8 billion for the quarter, a record for the company. The improvement was driven by a massive rise in server revenue year-on-year of 68.7%. However, other parts of the business appear to be languishing behind the drive to sell more GPU-based servers.\n\nBackground\n\nDell Technologies, Inc. declared financial results for Q2 FY2026, the period ending 1st August 2025, on 28th August 2025. Total revenue rose by 19.0% to $29.8 billion. Product sales (as compared to Services) now account for 80.4% of revenue.\n\nWe present the data in eight graphs, labelled Figure 1 to 8.\n\nFigure 1 – Dell Quarterly P&L Figure 2 – Dell Quarterly Financials\n\nBox Shifting\n\nFigure 8 dramatically demonstrates the rise in server sales. We can see a spike upwards in the ISG – Servers & Networking segment revenue of 68.7%, year-on-year, to approximately $12.9 billion, or 43.5% of all revenue generated in the quarter.\n\nThere was a time when Dell made most of its revenue from PC sales. That is no longer the case in the AI-driven world. The CSG – Consumer segment declined another 7.3% year-on-year, while CSG – Commercial rose by only 2.1%. Elsewhere, ISG – Storage declined by 3.0%, year-on-year.\n\nDell is the classic box-shifting business, with Servers & Networking achieving only a 12.1% margin in the current quarter. In contrast, that segment has reached peaks of over 20% in the past.\n\nFigure 3 – Dell Operating Income as % of Revenue Figure 4 – Dell Quarterly Gross Margin\n\nMargin Impact\n\nShould we care about the level of gross margin, when, as shown in Figure 4, the historical trend over the last three years has been 20-25%? Margin is used to fund sales, marketing, admin and research/development. As shown in Figure 6, Dell currently spends approximately 3% on R&D, whereas historically that figure was between 5% and 6%. We’ve shown absolute numbers too, to highlight that spending has declined in relative and absolute terms, not as a function of increased revenue.\n\nInvestment\n\nIn our analysis, we focus on Dell from a data storage perspective, so direct comparisons are difficult to make, but we can look at overall R&D spending as a percentage of revenue compared to Pure Storage (28% in Q1 FY2026) and NetApp, Inc. (16% in Q1 FY2026). Even if we assumed that all Dell R&D funded the storage business, that would translate to just 20% of ISG – Storage revenue, still below Pure Storage.\n\nPurely in the storage business, we believe Dell Technologies is significantly underinvesting in research & development. The flagship PowerStore platform, for example, still uses generation 2 hardware-based Intel Cascade Lake processors first introduced in 2022. The last hardware update was the introduction of QLC NAND into one model of product in May 2024. This solution uses QLC drives of only 15.36TB capacity.\n\nFigure 5 – Dell Quarterly Revenue by BU Stacked Figure 6 – Dell Quarterly R&D Spend\n\nElsewhere in the industry, Pure Storage has already delivered 150TB DFMs (effectively internally developed SSDs), with 300TB expected in 2026. NetApp supports 30.7TB drives in the higher-end solutions, with larger capacity drives on the horizon for Insight 2025.\n\nInnovation\n\nOf course, hardware capability is only one aspect of modern storage delivery. Customers want a cloud-like experience over the lifetime of their storage platforms deployed on-premises. Both Pure Storage and NetApp have better public cloud solutions than Dell. Both companies also offer a better experience than Dell for on-premises deployment and management.\n\nFigure 7 – Dell Quarterly Revenue Figure 8 – Dell Quarterly Revenue by BU\n\nThe Architect’s View®\n\nBy virtue of its acquisition of EMC Corporation, Dell Technologies still holds the #1 place for storage revenue. Both HPE and IBM no longer itemise storage revenue data, but in comparison to Pure Storage or NetApp, these companies in the current quarter represent only 22% and 40% of Dell’s storage revenue, respectively.\n\nThat leading position enables Dell to be relatively complacent about recurring business with their customers. However, it is worth noting that since Dell acquired EMC, its storage business has flatlined at around $4 billion per quarter in revenue, excluding any changes for inflation.\n\nWe are not a business or investment company but are instead focused on technology. When we perform a detailed analysis of the features and functionality of PowerStore and other Dell storage solutions, we see offerings that lag well behind the competition.\n\nHowever, data storage is a “sticky” business. Changing vendors involves data migrations, new processes and procedures and new standards for every aspect of the IT function. Businesses don’t change vendors lightly. Instead, what we are seeing is the gradual attrition of Dell’s storage business, as growth in the market goes elsewhere (to competitors and the public cloud).\n\nIn the long term, Dell Technologies may not care that this process occurs. After all, little will probably change in the next decade, by which time the EMC acquisition will have paid for itself. But, from the customer perspective, it is clear there are better products and solutions available from companies we’ve highlighted here – and many more.\n\nAt some point in the near future, the revenue from GPU-based servers will end. What happens then? The historical strategy of infrastructure vendors acquiring storage companies is arguably over. Dell (or HPE for that matter) are unlikely to buy another storage start-up to replace their existing technology. HPE has also just digested another networking company and sees greater gains there.\n\nThe post-AI boom could be difficult for Dell, as businesses look for efficiencies following the AI spending over-exuberance. We don’t believe Dell, or its customers are positioned to gain from this downturn, unless a significant change in strategy is adopted.\n\nPost #536c. Copyright (c) 2025 Brookend Ltd. No reproduction in whole or part without permission. Dell Technologies is an Architecting IT Tracked Vendor.",
      "source": "Architecting.it",
      "url": "https://www.architecting.it/blog/dell-q2-fy2026-financials/",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "How Major SOCs Achieve Early Threat Detection in 3 Steps",
      "content": "Every SOC leader understands that faster threat detection is better. But the difference between knowing it and building a system that consistently achieves it is massive. The best Security Operations Centers (SOCs) have already proven that early detection is the deciding factor between a minor alert and a full-blown breach. Yet many SOCs still struggle to make their detection processes fast, precise, and actionable.\n\nLet’s break down why early threat detection matters so much, what leading SOCs are doing right, and how you can follow their path in three steps.\n\nWhy Early Threat Detection Is Crucial\n\nAt first glance, “detecting earlier” sounds obvious. But in practice, it defines the resilience of the entire organisation. Five reasons stand out:\n\nReduced Damage Costs – Every minute a threat goes undetected increases potential losses. Stopping ransomware before encryption, for example, saves millions. IBM reports that early detection can slash breach expenses by 30-50%.\n\n– Every minute a threat goes undetected increases potential losses. Stopping ransomware before encryption, for example, saves millions. IBM reports that early detection can slash breach expenses by 30-50%. Faster Incident Response – Analysts can act in real time rather than chasing after an adversary that’s already three steps ahead. Ransomware groups can achieve full domain compromise within hours, not days. Nation-state actors establish persistence and begin data exfiltration within 24-48 hours of initial access.\n\n– Analysts can act in real time rather than chasing after an adversary that’s already three steps ahead. Ransomware groups can achieve full domain compromise within hours, not days. Nation-state actors establish persistence and begin data exfiltration within 24-48 hours of initial access. Countering Advanced Threats – APTs and living-off-the-land techniques are designed to remain hidden. Early spotting makes persistence almost impossible. Early intel lets you block AI and zero-days before they scale across your network.\n\n– APTs and living-off-the-land techniques are designed to remain hidden. Early spotting makes persistence almost impossible. Early intel lets you block AI and zero-days before they scale across your network. Business Continuity – Depends on containment speed. The faster you detect threats, the smaller the containment perimeter needs to be. Early detection often means the difference between taking a single server offline and shutting down entire business units.\n\n– Depends on containment speed. The faster you detect threats, the smaller the containment perimeter needs to be. Early detection often means the difference between taking a single server offline and shutting down entire business units. Regulatory & Reputational Protection – Faster detection helps avoid compliance violations and public breaches that damage trust. Late detection doesn’t just cost money; it creates legal liability.\n\nIn other words, early detection isn’t just a metric: it’s the backbone of organisational defence. It supports revenue by preventing disruptions. Top SOCs tie it to KPIs like uptime and risk scores, proving ROI to the C-suite.\n\nStep 1: Assess and Improve What You Have\n\nBefore building new capabilities, maximise what you already have. Most SOCs can achieve 30-40% faster detection times by optimising existing tools and processes.\n\nStreamline Alert Triage – Ensure analysts don’t waste time on low-value alerts. Enrich them with contextual threat intel right away.\n\n\n\nStart with your alert-to-incident ratio. If your analysts are investigating more than 20-30 alerts to find one real threat, you have a signal-to-noise problem that’s slowing everything down.\n\nOptimise Your Threat Intelligence Integration – Many SOCs have threat intelligence\n\nSet up IOC blocking at perimeter devices and real-time TI enrichment for security alerts. Create custom detection rules based on recent threat campaigns.\n\n\n\nAutomate Repetitive Checks – Use playbooks and SOAR integrations to free human capacity for complex threats. Measure Detection Latency: track the time from threat entry to first alert. Without measuring it, you can’t improve it.\n\nStep 2: Building the Base\n\nHigh-performing SOCs share three foundational capabilities that set them apart:\n\nInteractive Malware Analysis – Instead of static scans, they use sandboxes like ANY.RUN’s Interactive Sandbox, where analysts can interact with suspicious files and URLs to uncover hidden behaviour.\n\nAnalysts can interact with malware demanding user actions in the Sandbox\n\nContext-Rich Threat Intelligence – They don’t just collect IOCs; they maintain lookup and feed services that allow instant pivoting and enrichment. ANY.RUN’s Threat Intelligence Lookup is a relevant solution to this task.\n\nCross-Team Collaboration – Detection isn’t siloed; SOC, IR, and threat hunting teams all have access to the same real-time insights.\n\nThese practices form the baseline for rapid, reliable early detection.\n\n\n\nRequest a demo for ANY.RUN products and lay the foundation for business resilience\n\n\n\nAnd here is what top SOC teams do daily:\n\nTune alerts with data-driven rules to cut noise.\n\nAutomate low-level tasks, freeing humans for complex analysis.\n\nConduct regular simulations (e.g., purple team exercises) to test detection speed.\n\nThis foundation turns reactive firefighting into predictive defence, with clients reporting MTTD dropping from days to hours.\n\nStep 3: Future-Proof Your Detection Capabilities\n\nThe cyber arms race favours the prepared. Hackers evolve weekly, so top SOCs stay ahead by embedding threat intel and AI into workflows. It’s about pace: detect tomorrow’s threats today.\n\nEmbrace AI-Assisted Detection (But Do It Right). Focus on reducing analyst workload, not replacing analysts.\n\nBuild Continuous Threat Hunting Capabilities. Proactive threat hunting finds threats that automated systems miss and generates intelligence that improves those systems.\n\nScale with Automation: Orchestrate responses (e.g., auto-isolate endpoints) while humans oversee escalations.\n\nHow ANY.RUN Accelerates These Steps\n\nNo framework is complete without the right equipment. ANY.RUN’s suite – Interactive Sandbox, TI Lookup, and TI Feeds is specifically designed to support each step, fueling detection for 15,000+ security teams worldwide.\n\nInteractive Sandbox in Steps 1 & 2: Upload suspicious files or URLs for real-time detonation in a safe VM. Interact like a user (type, drag files) to reveal hidden behaviours, IOCs, and TTPs in minutes, not hours. It cuts triage time by providing instant verdicts, helping you audit alerts faster and build accurate detection rules.\n\n\n\nDetonate a malware sample in the safe VM environment, emulate user actions, and observe the whole attack chain:\n\n\n\nView an analysis session of recently active malware\n\nWannaCry live in the Sandbox\n\nTI Lookup Across All Steps: Query a vast database of 1M+ daily IOCs from global investigations. Enrich alerts with context on malware families or APTs, prioritising threats early. Integrates via API with your SIEM/XDR for automated lookups, boosting Step 3’s predictive edge.\n\n\n\nOne lookup exposes an IP address as malicious, delivers additional IOCs, detects the malware they belong to, and links to sandbox analysis sessions:\n\ndestinationIP:”142.93.82.250″\n\nIOC quick verdict and context for further research\n\nTI Feeds for Future-Proofing: Get live feeds of IOAs/IOBs/IOCs from expert analyses. This enhances team hunting in Step 2 and scales intel in Step 3, creating a continuous improvement loop for your detection capabilities.\n\nANY.RUN’s TI Feeds key features and data sources\n\n\n\nTogether, they slash MTTD, reduce costs, and integrate seamlessly with no heavy lifts required.\n\nChallenges on the Path to Early Detection\n\nOf course, no transition is free from obstacles. SOC leaders should prepare for:\n\nData Overload – More intelligence means more noise. Prioritisation and automation are essential.\n\nSkill Gaps – Analysts may need training to use advanced tools like interactive sandboxes effectively.\n\nChange Resistance – Established processes are hard to break; leadership must drive cultural as well as technical change.\n\nBudget Constraints – Faster detection may require upfront investment, but the cost of breaches dwarfs these expenses.\n\nFacing these challenges head-on is part of building a SOC that truly delivers.\n\nConclusion: The Time for Early Detection is Now\n\nThe cybersecurity arms race isn’t slowing down: it’s accelerating. Every month that passes without improving your detection capabilities is a month your adversaries spend developing new ways to evade your current defences.\n\nThe three-step approach outlined here isn’t theoretical; it’s based on what the most successful SOCs are actually doing right now. They’re not waiting for perfect tools or unlimited budgets. They’re optimising what they have, building essential capabilities, and positioning themselves to stay ahead of evolving threats.\n\nThe question isn’t whether your organisation needs early threat detection. It’s whether you implement it before or after your next major security incident. The SOCs that answer “before” are the ones that will still be protecting their organisations effectively five years from now.",
      "source": "HackRead",
      "url": "https://hackread.com/how-major-socs-achieve-threat-detection-3-steps/",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Windows ML is Generally Available with Windows App SDK 1.8.1",
      "content": "Microsoft today announced the first stable release of Windows ML, its AI inferencing runtime for Windows 11. Windows ML (Windows Machine Learning) is optimized for inferencing on-device AI models, like those used by Copilot+ PCs, though it offers streamlined model dependency management across CPUs, GPUs and NPUs. It’s also the basis for the Windows AI Foundry, which was originally called the Windows Copilot Runtime.\n\n“The future of AI is hybrid, utilizing the respective strengths of cloud and client while harnessing every Windows device to achieve more,” Microsoft distinguished engineer Logan Iyer explains. “At Microsoft, we are reimagining what’s possible by bringing powerful AI compute directly to Windows devices, unlocking a new era of intelligence that runs where you are. With groundbreaking advancements in silicon, a modernized software stack and deep OS integration, Windows 11 is transforming into the world’s most open and capable platform for local AI.”\n\nMicrosoft first announced Windows ML (and the Windows AI Foundry) at Build 2025 this past May, so this is a pretty quick turnaround. (Compare this to the Windows Copilot Runtime, which was announced at Build 2024 and never shipped in stable.) With this release, developers can use Windows ML capabilities in production, and that tells me that there must be a new stable release of the Windows App SDK, the framework that developers use to access Windows ML. And there is: Windows App SDK 1.8.1 is now available with support for Windows 11 version 24H2 and newer. (You can download that here.)\n\nIn keeping with the nature of Windows itself, Windows ML acts as a hardware abstraction layer so that developers can target specific local AI capabilities without worrying about which hardware architectures or chipsets are available on the PCs on which their apps will run. Apps built with Windows ML will automatically download any necessary execution providers, so they don’t need to be bundled with specific (or multiple) runtimes. But developers can also create device policies to optimize their apps for low power (NPU) or high performance (GPU), or to specify the silicon used for a model.\n\n“Windows 11 has a diverse hardware ecosystem that includes AMD, Intel, NVIDIA and Qualcomm and spans the CPU, GPU and NPU. Consumers can choose from a range of Windows PCs and this variety empowers developers to create innovative local AI experiences,” Iyer continues. “Windows ML can fully leverage their latest CPUs, GPUs and NPUs for AI workloads … Leading software app developers such as Adobe, BUFFERZONE, Dot Inc., McAfee, Reincubate, Topaz Labs and Wondershare are among many others working on adopting Windows ML in their upcoming releases, accelerating the proliferation of local AI capabilities across a broad spectrum of applications.”\n\nYou can learn more about Windows ML on the Microsoft Learn website.",
      "source": "Thurrott.com",
      "url": "https://www.thurrott.com/a-i/327165/windows-ml-is-generally-available-with-windows-app-sdk-1-8-1",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "The YouTube Tip of the Google Spear",
      "content": "Listen to this post: Log in to listen\n\nAction is happening up-and-down the LLM stack: Nvidia is making deals with Intel, OpenAI is making deals with Oracle, and Nvidia and OpenAI are making deals with each other. Nine years after Nvidia CEO Jensen Huang hand-delivered the first Nvidia DGX-1 AI computer to OpenAI, the chip giant is investing up to $100 billion in the AI lab, which OpenAI will, of course, spend on Nvidia AI systems.\n\nThis ouroboros of a deal certainly does feel a bit frothy, but there is a certain logic to it: Nvidia is uniquely dominant in AI thanks to the company’s multi-year investment in not just superior chips but also an entire ecosystem from networking to software, and has the cash flow and stock price befitting its position in the AI value chain. Doing a deal like this at this point in time not only secures the company’s largest customer — and rumored ASIC maker — but also gives Nvidia equity upside beyond the number of chips it can manufacture. More broadly, lots of public investors would like the chance to invest in OpenAI; I don’t think Nvidia’s public market investors are bothered to have now acquired that stake indirectly.\n\nThe interconnectedness of these investments reflects the interconnectedness of the OpenAI and Nvidia stories in particular: Huang may have delivered OpenAI their first AI computer, but it was OpenAI that delivered Nvidia the catalyst for becoming the most valuable company in the world, with the November 2022 launch of ChatGPT. Ever since, the assumption of many in tech has been that the consumer market in particular has been OpenAI’s to lose, or perhaps more accurately, monetize; no company has ever grown faster in terms of users and revenue, and that’s before they had an advertising model!\n\nAnd beyond the numbers, have you used ChatGPT? It’s so useful. You can look up information, or format text, and best of all you can code! Of course there are other models like Anthropic’s Claude, which has excelled at coding in particular, but surely the sheer usefulness makes ultimate success inevitable!\n\nA Brief History of Social Media\n\nIf a lot of those takes sound familiar, it’s because I’ve made some version of most of them; I also, perhaps relatedly, took to Twitter like a fish to water. Just imagine, an app that was the nearly perfect mixture of content I was interested in and people I wanted to hear from, and interact with. Best of all it was text: the efficiency of information acquisition was unmatched, and it was just as easy to say my piece.\n\nIt took me much longer to warm up to Facebook, and, frankly, I never was much of a user; I’ve never been one to image dump episodes of my life, nor have I had much inclination to wade through others’. I wasn’t interested in party photos; I lusted after ideas and arguments, and Twitter — a view shared by much of both tech and media — was much more up my alley.\n\nDespite that personal predilection, however, and perhaps because of my background in small town Wisconsin and subsequently living abroad, I retained a strong sense of the importance of Facebook. Sure, the people who I was most interested in hearing from and interacting with may have been the types to leave their friends and family for the big city, but for most people, friends and family were the entire point of life generally, and by extension, social media specifically.\n\nTo that end, I was convinced from the beginning that Facebook was going to be a huge deal, and argued so multiple times on Stratechery; social media was ultimately a matter of network effects and scale, and Facebook was clearly on the path to domination, even as much of the Twitterati were convinced the company was the next MySpace. I was similarly bullish about Instagram: no, I wasn’t one to post a lot of personal pictures, but while I personally loved text, most people liked photos.\n\nWhat people really liked most of all, however — and not even Facebook saw this coming — was video. TikTok grew into a behemoth with the insight that social media was only ever a stepping stone to personal entertainment, of which video was the pinnacle. There were no network effects of the sort that everyone — including regulators — assumed would lead to eternal Facebook dominance; rather, TikTok realized that Paul Krugman’s infamous dismissal of the Internet actually was somewhat right: most people actually don’t have anything to say that is particularly compelling, which means that limiting the content you see to your social network dramatically decreases the possibility you’ll be entertained every time you open your social networking app. TikTok dispensed with this artificial limitation, simply showing you compelling videos period, no matter where they came from.\n\nThe Giant in Plain Sight\n\nOf course TikTok wasn’t the first company to figure this out: YouTube was the first video platform, and from the beginning focused on building an algorithm that focused more on giving you videos you were interested in than in showing you what you claimed to want to see.\n\nYouTube, however, was and probably always has been my biggest blind spot: I’m just not a big video watcher in general, and YouTube seemed like more work than short-form video, which married the most compelling medium with the most addictive delivery method — the feed. Sure, YouTube was a great acquisition for Google — certainly in line with the charge to “organize the world’s information and make it universally accessible and useful” — but I — and Google’s moneymaker, Search — was much more interested in text, and pictures if I must.\n\nThe truth, however, is that YouTube has long been the giant hiding in plain sight: the service is the number one streaming service in the living room — bigger than Netflix — and that’s the company’s 3rd screen after mobile and the PC, where it has no peer. More than that, YouTube is not just the center of culture, but the nurturer of it: the company just announced that it has paid out more than $100 billion to creators over the last four years; given that many creators earn more from brand deals than they do from YouTube ads, that actually understates the size of the YouTube economy. Yes, TikTok is a big deal, but TikTok stars hope to make it on YouTube, where they can actually make a living.\n\nAnd yet, YouTube sometimes seems like an afterthought, at least to people like me and others immersed in the text-based Internet. Last week I was in New York for YouTube’s annual “Made on YouTube” event, but the night before I couldn’t remember the name; I turned to Google, natch, and couldn’t figure it out. The reason is that talk about YouTube mostly happens on YouTube; I, and Google itself, still live in a text-based world.\n\nThat is the world that was rocked by ChatGPT, especially Google. The company’s February 2023 introduction of Bard in Paris remains one of the most surreal keynotes I’ve ever watched: most of the content was rehashed, the presenters talked as if they were seeing their slides for the first time, and one of the demos of a phone-based feature neglected to remember to have a phone on hand. This was a company facing a frontal assault on their most obvious and profitable area of dominance — text-based information retrieval — and they were completely flat-footed.\n\nGoogle has, in the intervening years, made tremendous strides to come back, including dumping the Bard name in favor of Gemini, itself based on vastly improved underlying models. I’m also impressed by how the company has incorporated AI into search; not only are AI Overviews generally useful, they’re also incredibly fast, and as a bonus have the links I sometimes prefer already at hand. Ironically, however, you could make the case that the biggest impact LLMs have had on Search is giving a federal judge an excuse to let Google continue paying its biggest would-be competitors (like Apple) to simply offer their customers Google instead. The biggest reason to be skeptical of the company’s fortunes in AI is that they had the most to lose; the company is doing an excellent job of minimizing the losses.\n\nWhat I would submit, however, is that Google’s most important and most compelling AI announcements actually don’t have anything to do with Search, at least not yet. These announcements start, as you might expect, with Google’s Deep Mind Research Lab; where they hit the real world, however, is on YouTube — and that, like the user-generated streaming service, is a really big deal.\n\nThe DeepMind-to-YouTube Pipeline\n\nA perfect example of the DeepMind-to-YouTube pipeline was last week’s announcement of Veo 3-based features for making YouTube Shorts. From the company’s blog post:\n\nWe’ve partnered with Google DeepMind to bring a custom version of their most powerful video generation model, Veo 3, to YouTube. Veo 3 Fast is designed to work seamlessly in YouTube Shorts for millions of creators and users, for free. It generates outputs with lower latency at 480p so you can easily create video clips – and for the first time, with sound – from any idea, all from your phone.\n\nThis initial launch will allow you to not only generate videos, but also use one video to animate another (or a photo), stylize your video with a single touch, and add objects. You can also create an entire video — complete with voiceover — from a collection of clips, or convert speech to song. All of these features are a bit silly, but, well, that’s often where genius — or at least virality — comes from.\n\nCritics, of course, will label this an AI slop machine, and they’ll be right! The vast majority of content created by these tools will be boring and unwatched. That, however, is already the case with YouTube: the service sees 500 hours of content uploaded every minute, and most of that content isn’t interesting to anyone; the magic of YouTube, however, is the algorithm that finds out what is actually compelling and spreads it to an audience that wants exactly that.\n\nTo put it another way, for YouTube AI slop is a strategy credit: given that the service has already mastered organizing overwhelming amounts of content and only surfacing what is good, it, more than anyone else, can handle exponentially more content which, through the sheer force of numbers, will result in an absolute increase of content that is actually compelling.\n\nThat’s not the only strategy credit YouTube has; while the cost of producing AI-generated video will likely be lower than the cost of producing human-generated video, at least in the long run, the latter’s costs are not borne by TikTok or Meta (Facebook and Instagram are basically video platforms at this point). Rather, the brilliance of the user-generated content model is that creators post their content for free! This, however, means that AI-generated video is actually more expensive, at least if it’s made on TikTok or Meta’s servers. YouTube, however, pays its creators, which means that for the service AI-generated video actually has the potential to lower costs in the long run, increasing the incentive to leverage DeepMind’s industry-leading models.\n\nIn short, while everyone immediately saw how AI could be disruptive to Search, AI is very much a sustaining innovation for YouTube: it increases the amount of compelling content in absolute terms, and it does so with better margins, at least in the long run.\n\nHere’s the million billion trillion dollar question: what is going to matter more in the long run, text or video? Sure, Google would like to dominate everything, but if it had to choose, is it better to dominate video or dominate text? The history of social networking that I documented above suggests that video is, in the long run, much more compelling to many more people.\n\nTo put it another way, the things that people in tech and media are interested in has not historically been aligned with what actually makes for the largest service or makes the most money: people like me, or those reading me, care about text and ideas; the services that matter specialize in videos and entertainment, and to the extent that AI matters for the latter YouTube is primed to be the biggest winner, even as the same people who couldn’t understand why Twitter didn’t measure up to Facebook go ga-ga over text generation and coding capabilities.\n\nAI Monetization\n\nThe potential impact of AI on YouTube’s fortunes isn’t just about AI-created videos; rather, the most important announcement of last week’s event was the first indicator that AI can massively increase the monetization potential of every video on the streaming service. You might have missed the announcement, because YouTube underplayed it; from their event blog post:\n\nWe’re adding updates to brand deals and Shopping to make brand collaborations easier than ever. We’re accelerating these deals through a new initiative and new product features to make sure those partnerships succeed – like the ability to add a link to a brand’s site in Shorts. And YouTube Shopping is expanding to more markets and merchants and getting help from AI to make tagging easier.\n\nIt’s just half a sentence — “getting help from AI to make tagging easier” — but the implications of those eight words are profound; here’s how YouTube explained the feature:\n\nWe know tagging products can be time-consuming, so to make the experience better for creators, we’re leaning on an AI-powered system to identify the optimal moment a product is mentioned and automatically display the product tag at that time, capturing viewer interest when it’s highest. We’ll also begin testing the ability to automatically identify and tag all eligible products mentioned in your video later this year.\n\nThe creator who demonstrated the feature — that right there is a great example of how YouTube is a different world than the one I and other people in the media inhabit — was very enthusiastic about the reduction in hassle and time-savings that would come from using AI to do a menial task like tagging sponsored products; that sounds like AI at its best, freeing up creative people to do what they do best.\n\nThere’s no reason, however, why auto-tagging can’t become something much greater; in fact, I already explained the implications of this exact technology in explaining why AI made me bullish on Meta:\n\nThis leads to a third medium-term AI-derived benefit that Meta will enjoy: at some point ads will be indistinguishable from content. You can already see the outlines of that given I’ve discussed both generative ads and generative content; they’re the same thing! That image that is personalized to you just might happen to include a sweater or a belt that Meta knows you probably want; simply click-to-buy. It’s not just generative content, though: AI can figure out what is in other content, including authentic photos and videos. Suddenly every item in that influencer photo can be labeled and linked — provided the supplier bought into the black box, of course — making not just every piece of generative AI a potential ad, but every piece of content period. The market implications of this are profound. One of the oddities of analyzing digital ad platforms is that some of the most important indicators are counterintuitive; I wrote this spring: The most optimistic time for Meta’s advertising business is, counter-intuitively, when the price-per-ad is dropping, because that means that impressions are increasing. This means that Meta is creating new long-term revenue opportunities, even as its ads become cost competitive with more of its competitors; it’s also notable that this is the point when previous investor freak-outs have happened. When I wrote that I was, as I noted in the introduction, feeling more cautious about Meta’s business, given that Reels is built out and the inventory opportunities of Meta AI were not immediately obvious. I realize now, though, that I was distracted by Meta AI: the real impact of AI is to make everything inventory, which is to say that the price-per-ad on Meta will approach $0 for basically forever. Would-be competitors are finding it difficult enough to compete with Meta’s userbase and resources in a probabilisitic world; to do so with basically zero price umbrella seems all-but-impossible.\n\nThis analysis was spot-on; I just pointed it at the wrong company. This opportunity to leverage AI to make basically every pixel monetizable absolutely exists for Meta; Meta, however, has to actually develop the models and infrastructure to do it at scale. Google is already there; it was the company universally decried for being slow-moving that announced the first version of this feature last week.\n\nI can’t overstate what a massive opportunity this is: every item in every YouTube video is well on its way to being a monetizable surface. Yes, that may sound dystopian when I put it so baldly, but if you think about it you can see the benefits; I’ve been watching a lot of home improvement videos lately, and it sure would be useful to be able to not just identify but helpfully have a link to buy a lot of the equipment I see, much of which is basically in the background because it’s not the point of the video. It won’t be long until YouTube has that inventory, which it could surface with an affiliate fee link, or make biddable for companies who want to reach primed customers.\n\nMore generally, you can actually envision Google pulling this off: the company may have gotten off to a horrible start in the chatbot era, but the company has pulled itself together and is increasingly bringing its model and infrastructure leadership to bear, even as Meta has had to completely overhaul their AI approach after hitting a wall. I’m sure CEO Mark Zuckerberg will figure it out, but Google — surprise! — is the company actually shipping.\n\nA Bull’s Journey\n\nOr, rather, YouTube is. Close readers of Stratechery have been observing — and probably, deservedly, smirking — at this most unexpected evolution:\n\nThat quote is from Paradigm Shifts and the Winner’s Curse, an Article that was mostly about my concerns about Apple and Amazon, and reads:\n\nAnd, by the same token, I’m much more appreciative of Google’s amorphous nature and seeming lack of strategy. That makes them hard to analyze — again, I’ve been honest for years about the challenges I find in understanding Mountain View — but the company successfully navigated one paradigm shift, and is doing much better than I originally expected with this one. Larry Page and Sergey Brin famously weren’t particularly interested in business or in running a company; they just wanted to do cool things with computers in a college-like environment like they had at Stanford. That the company, nearly thirty years later, is still doing cool things with computers in a college-like environment may be maddening to analysts like me who want clarity and efficiency; it also may be the key to not just surviving but winning across multiple paradigms.\n\nAppreciating the benefits of Google being an amorphous blob where no one knows what is going on, least of all leadership, is a big part of my evolution; this Article is the second part: that blob ultimately needs a way to manifest the technology it manages to come up with, and if you were to distill my worries about Google in the age of AI it would be to wonder how the company could become an answer machine — which Page and Brin always wanted — when it risked losing the massive economic benefits that came from empowering users to choose the winners of auctions Google conducted for advertisers.\n\nThat, however, is ultimately the text-based world, and there’s a case to be made that, in the long run, it simply won’t matter as much as the world of video. Again, the company is doing better with Search than I expected, and I’ve always been bullish about the impact of AI on the company’s cloud business; the piece I’ve missed, however, is that Google already has the tip of the spear for its AI excellence to actually go supernova: YouTube, the hidden giant in plain sight, a business that is simultaneously unfathomably large, and also just getting started.",
      "source": "Stratechery.com",
      "url": "https://stratechery.com/2025/the-youtube-tip-of-the-google-spear/",
      "timestamp": "2025-09-23"
    },
    {
      "headline": "Qualcomm Unveils Snapdragon 8 Elite Gen 5 SoC With Impressive Performance Claims",
      "content": "As expected, along with the latest laptop-class Arm SoC, the Snapdragon X2 Elite series Qualcomm has officially unveiled its latest flagship mobile SoC, the Snapdragon 8 Elite Gen 5. The 8 Elite Gen 5 launch sees Qualcomm lean even further into AI workloads while adding a handful of spec upgrades to the new SoC. It features an Oryon Gen 3 CPU that has two Prime cores capable of up to 4.60 GHz and six Performance cores that run at up to 3.62 GHz, all of which is paired with 24 MB of cache split into 12 MB chunks—12 MB per core cluster. Qualcomm says this will increase single-core performance by 20% and multicore performance by 17%, compared to the likes of the Snapdragon 8 Elite Gen 2, that is. Based on Geekbench Browser scores and the information shown off by Qualcomm in the presentation, this means the 8 Elite Gen 5 performs about on-par with its true predecessor, the Snapdragon 8 Elite Gen 3, but early benchmarks from hands-on tests at the Snapdragon Summit tell a different story. It seems as though the 8 Elite Gen 5 delivers single-core Geekbench 6 results of around 3,800 points, with multicore scores coming in at around 12,400 points—a remarkable ~3,000 uplift over the current Geekbench leader, the Samsung Galaxy S25 Ultra and its Snapdragon 8 Elite Gen 3 for Galaxy.Of course, as with much of the recent tech announcements, Qualcomm is focusing heavily on AI workloads with the launch of the Snapdragon 8 Elite Gen 5. AI performance improvements and NPU upgrades abound, with Qualcomm claiming the new Hexagon NPU is 37% faster and 16% more power efficient than the previous generation. The new Hexagon NPU now also works together with the ISP to process videos more efficiently and quickly. Similarly to how ISPs typically process images, the NPU in the 8 Elite Gen 5 will be leveraged to manage things lighting, color reproduction, and sharpness. Qualcomm also demonstrated generative image processing with the example of removing glare and artifacts from images \"instantly.\" The new NPU will also enable ModelBest on-device agentic AI with onboard training and a memory of past conversations. Supposedly, this AI will be able to access a number of on-device apps, files, and functions, including location, stored images, and social media in order to automatically post, classify photos, and do other generative tasks.The new Adreno GPU is claimed to be 23% faster and 20% more efficient than its predecessor, and it is introducing mesh shading and hardware accelerated ray tracing. The new GPU features a new \"three-slice\" design, with clock speeds reaching up to 1.2 GHz. It also features new Adreno High Performance Memory (HPM), which is an on-board 18 MB memory cache for improved latency and performance. It supposedly increases memory bandwidth by 38% and allows for 10% more efficient gameplay in some games. Qualcomm says that the benefits of HPM are especially noticeable in longer gaming sessions in games like Honkai Star Rail. Qualcomm has also worked with Epic Games to optimize for Unreal Engine features, like Lumen, Nanite, and Chaos Physics Engine. This is all part of the Unreal x Snapdragon Developer Alliance, which is a program that is meant to help encourage game development for Snapdragon platforms.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341312/qualcomm-unveils-snapdragon-8-elite-gen-5-soc-with-impressive-performance-claims",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Intel Stock Soars Along With Unusual Put Options Activity - Is INTC Stock Overvalued?",
      "content": "Switch the Market flag\n\nOpen the menu and switch the\n\nMarket flag for targeted data from your country of choice.\n\nfor targeted data from your country of choice.",
      "source": "Barchart.com",
      "url": "https://www.barchart.com/story/news/35013298/intel-stock-soars-along-with-unusual-put-options-activity-is-intc-stock-overvalued",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "MSI Vector 16 HX AI 400: 16\" 240Hz QHD+ IPS, Intel Ultra 9 275HX, RTX 5080, 16GB DDR5, 1TB SSD $1999",
      "content": "This collaborative space allows users to contribute additional information, tips, and insights to enhance the original deal post. Feel free to share your knowledge and help fellow shoppers make informed decisions.\n\nAdd Entry",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18630484-msi-vector-16-hx-ai-400-16-240hz-qhd-ips-intel-ultra-9-275hx-rtx-5080-16gb-ddr5-1tb-ssd-1999",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Report: Intel in talks with Apple over potential investment and chip manufacturing deal",
      "content": null,
      "source": "SiliconANGLE News",
      "url": "https://siliconangle.com/2025/09/24/report-intel-talks-apple-potential-investment-chip-manufacturing-deal/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Chinese tech firms rush to list in Hong Kong to fund overseas expansion",
      "content": "From semiconductors to artificial intelligence and robotics, more mainland Chinese technology firms plan to list in Hong Kong, which would serve as their launch pad to expand overseas and transform into global businesses.\n\nSome of the mainland firms currently looking to list in the city include China Micro Semicon (Shenzhen), Suzhou Dongshan Precision Manufacturing and Mech-Mind Robotics Technologies.\n\nThe increased interest from mainland tech firms to list in Hong Kong reflects how the city regained its status as the world's largest market for initial public offerings (IPOs) this year.\n\nDo you have questions about the biggest topics and trends from around the world? Get the answers with SCMP Knowledge, our new platform of curated content with explainers, FAQs, analyses and infographics brought to you by our award-winning team.\n\n\"The Hong Kong market has had a strong rally this year, with international investors chasing mainland technology companies, particularly semiconductor, AI and robotics companies,\" said Tom Chan Pak-lam, permanent honorary president of the Institute of Securities Dealers, an industry body for brokers.\n\n\"This trend will continue as Hong Kong is an international financial centre and a connector between China and the world,\" he said. \"It is natural for mainland technology companies to use Hong Kong as a platform to go global.\"\n\nAs of Friday, some 60 companies had collectively raised US$18.5 billion in Hong Kong, a 158 per cent increase from the previous year.\n\nThat surge enabled the city to reclaim its status as the world's largest IPO market in terms of funds raised for the first time since 2019, according to data from the London Stock Exchange Group.\n\nChinese semiconductor companies are eyeing Hong Kong as a base to raise funds and pursue international expansion. Photo: Shutterstock alt=Chinese semiconductor companies are eyeing Hong Kong as a base to raise funds and pursue international expansion. Photo: Shutterstock>\n\nChina Micro Semicon, which designs chips for smart household products, on Tuesday filed a listing application to the main board of Hong Kong Exchanges and Clearing. The firm went public on Shanghai's Star Market in 2022.\n\n\"We intend to leverage Hong Kong's strategic position as a gateway to international markets - along with its robust research-and-development ecosystem and abundant talent pool - to build a regional base supporting our global expansion,\" the company's filing said.\n\nThe Shenzhen-based company planned to use part of the funds it expected to raise to establish a global operations and research and development centre in Hong Kong, according to its filing.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/chinese-tech-firms-rush-list-093000591.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Intel and Apple hold investment talks, no deal in sight",
      "content": "Following a practically lost decade, Intel has had a busy few months, which culminated in investments by Nvidia and the US government. Now, the chipmaker is looking at Apple to help continue its comeback. Here are the details.\n\nAs reported by Bloomberg, Intel has been trying to secure an investment from Apple as part of its comeback strategy.\n\nThe report says that the companies “ have discussed how to work more closely together,” although no agreement is in sight.\n\nFrom the report:\n\nIntel Corp. has approached Apple Inc. about securing an investment in the ailing chipmaker, according to people familiar with the matter, part of efforts to bolster a business that’s now partially owned by the US government. Apple and Intel also have discussed how to work more closely together, said the people, who asked to not be identified because the deliberations are private. The talks have been early-stage and may not lead to an agreement, the people said.\n\nIn the last few weeks, Intel has secured a $5 billion investment from Nvidia, which followed a very public spat between President Trump and Intel CEO Lip-Bu Tan, that began with Trump calling for Tan’s ouster, and ended with the US government taking a 10% stake in the company.\n\nWhen asked about the deal by Bloomberg, neither Apple nor Intel had any comments, but stockholders were quick to react, with Intel’s stock seeing a 6% bump, while Apple saw a 1% dip.\n\nA reunion for the ages?\n\nIt is not immediately clear how an Intel-Apple agreement would benefit Apple, the initial read is that Intel could possibly package the company’s chips, in case the investment does include a rekindling of the ties between the two companies.\n\nAn Intel investment could also benefit Apple’s efforts to appease the US government and show more commitment to domestic initiatives, which currently has the $600 billion American Manufacturing Program as its centerpiece.\n\nIt would also mark a significant reunion, as for many years, Apple relied on Intel as its processor supplier, mainly for Macs. However, following long delays and changes in Intel’s plans that required Apple to hold off on more frequent Mac updates, Apple decided to invest in its own chips, complete with a full architecture switch from x86 to ARM.\n\nDo you thinkg Apple should invest in Intel? Let us know in the comments.\n\nAccessory deals on Amazon",
      "source": "9to5Mac",
      "url": "https://9to5mac.com/2025/09/24/intel-and-apple-hold-investment-talks-no-deal-in-sight/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Lithium Americas stock soars 90% on news of potential government stake",
      "content": "Lithium Americas (LAC) stock soared on Wednesday, rising 95% after news reports that the Trump administration is looking to take a stake in the operator of what is set to be the largest lithium mine in the country.\n\nOn Tuesday evening, Reuters reported that the administration is seeking a stake of up to 10% in Vancouver, British Columbia-based Lithium Americas as part of renegotiations for a $2.26 billion loan the company received from the Department of Energy for its Thacker Pass lithium mine.\n\nThe report sent shares in Lithium Americas rocketing upward Wednesday morning. Shares in General Motors (GM), which owns a 38% stake in the project, gained a bit more than 2% on Wednesday.\n\nUnder the terms of the prospective Lithium Americas deal, the mining company has offered the administration no-cost warrants on up to 10% of the company's common shares. The administration is also reported to be seeking purchase guarantees from General Motors, which has $625 million in the project.\n\nThe original loan includes terms that allow the administration to seize control of the project if it is delayed or faces major cost overruns, according to Reuters.\n\nRead more about Lithium Americas' stock moves and today's market action\n\nThe proposed mining project in Nevada would be the largest lithium mining project in the Western Hemisphere, producing more than 40,000 metric tons of lithium carbonate in its first phase, set to begin in 2028 — enough of the metal byproduct to construct 800,000 electric vehicles, according to Reuters.\n\nAlbemarle's (ALB) Silver Peak project in Nevada, the only operating lithium mine in the US right now, produces less than 5,000 metric tons of the metal per year.\n\nThe administration has consistently considered lithium production as a key area in building out domestic supply chains for valuable metals and other commodities like copper and uranium. China produces more than 40,000 metric tons per year of the metal, making it the world's third-largest lithium producer, behind only Australia and Chile.\n\nLithium must be refined after the raw metal is removed from the ground to build products like EV batteries. China currently refines 65% or more of the world's lithium, compared to the less than 3% share in the US.\n\nThe Trump administration's interest in a stake in Lithium Americas mirrors similar moves for stakes in mining company MP Materials (MP) and chipmaking giant Intel (INTC), as the federal government looks to strengthen its position in both domestic production and global supply chains.\n\nShares in MP Materials are up more than 50% since the company's July announcement of a multibillion-dollar deal with the Department of Defense that made the government the largest shareholder of the rare earths miner. Shares in Intel (INTC) are up more than 25% since talks between the chipmaker and the administration were publicly reported.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/lithium-americas-stock-soars-90-on-news-of-potential-government-stake-144107890.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Tesla rolls out surprising new update to its older vehicles — here's how it could impact drivers",
      "content": "Tesla is rewarding owners of its older electric vehicles with an impressive update that attempts to make the driving experience as intuitive as possible.\n\nAs noted by Tesalrati, older Tesla vehicles equipped with the Intel processors and ultrasonic sensors will benefit greatly from software update 2025.32.2. The move will bring an enhanced Full Self-Driving visualization to the reverse view. Previously, these vehicles reverted to a simpler Autopilot visual with gray lines when driving in reverse.\n\nThe update was caught by X user Beat (@beat_t1), who first posted the scoop on Sept. 5.\n\nAdvertisement Advertisement\n\nAdvertisement\n\n\"When shifting into reverse, the full FSD visualization now stays on instead of switching to the old plain autopilot visuals,\" they wrote. \"Might be small, but it makes backing up feel more seamless.\"\n\nThe update now allows drivers in older Tesla vehicles to see richer graphics that detect curbs and other objects while backing up. This will align with the reverse-view experience that is equipped in newer, AMD-based models. While the update might not be considered groundbreaking technology for some drivers, it may just help increase the perceived value of used Tesla vehicles.\n\n2025 has not been a kind year to the EV manufacturer. Throughout the majority of the year, Tesla has reported a dramatic decrease in car sales, especially in key automotive markets across the globe. However, with a steady stream of updates designed to improve the driving experience of its vehicles, Tesla appears to be making a concerted effort to listen to its customers.\n\nWhether you own a Tesla or any other EV, the installation of solar panels at home can make a great pairing with a personal EV charging station. Charging with solar energy is cheaper than using public charging stations or relying on the grid. This can greatly increase the savings associated with your EV.\n\nAdvertisement Advertisement\n\nAdvertisement\n\nEnergySage makes it easy to compare quotes from vetted local installers and helps you save up to $10,000 on solar installations. With its free and useful tools, you can find the perfect solar panel option that works for you and your home.\n\nWould you be more willing to buy an EV if it could travel over 600 miles per charge? Definitely Not really Depends on the price Depends on the brand Click your choice to see results and speak your mind.\n\nJoin our free newsletter for good news and useful tips, and don't miss this cool list of easy ways to help yourself while helping the planet.",
      "source": "Yahoo Entertainment",
      "url": "https://tech.yahoo.com/transportation/articles/tesla-rolls-surprising-older-vehicles-010000796.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Market Minute 9-24-25- Feds Eyeing Another Corporate Stake",
      "content": "Stocks rolled over into the close yesterday, but they’re trading mostly flat this morning. Gold and silver are pulling back along with Treasuries, while crude oil and the dollar are rising.\n\nTo get more articles and chart analysis from MoneyShow, subscribe to our Top Pros’ Top Picks newsletter here.)\n\nShares of Lithium Americas Corp. (LAC) are soaring more than 70% after reports the Trump Administration will take a stake of as much as 10% in the firm. The Biden Administration had loaned LAC $2.3 billion to fund a lithium mining project in Nevada. The stake would be granted as part of a renegotiation of that financing package.\n\nLAC, INTC, MP (YTD % Change)\n\nchart\n\nData by YCharts\n\nThe federal government has been increasing its ties with Corporate America under Trump, taking stakes in companies as wide-ranging as chipmaker Intel Corp. (INTC) and rare earth miner MP Materials Corp. (MP). LAC’s Thacker Pass project will be the largest lithium facility in the Western Hemisphere if it opens on schedule in 2028. That, in turn, would reduce the US’ reliance on China for a metal critical for electronics and Electric Vehicles (EVs).\n\nArtificial Intelligence (AI) spending pledges just keep getting bigger – and investors keep rewarding them with higher share prices. Alibaba Group Holding Ltd. (BABA) just said it would spend much more than the $50 billion it originally announced back in February. The news sent US-traded shares of the Chinese company up more than 8% in the early going. The tech conglomerate operates cloud computing facilities in countries like the US and Australia, and will soon add data centers in Brazil, France, and the Netherlands.\n\nSee also: SPX: Two Forces are Sending Stocks Higher Despite Job Worries\n\nLastly, a new wave of cryptocurrency ETFs will soon hit the US markets following the release of updated Securities and Exchange Commission (SEC) guidelines. Those standards will reduce the time it takes to launch crypto ETFs dramatically, likely leading to a flood of new products that will target less-popular cryptos like Solana and XRP...or even Dogecoin. Investors can already choose from a wealth of funds that hold Bitcoin and Ethereum.\n\nMore From MoneyShow.com:",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/market-minute-9-24-25-141500691.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Intel Seeks Investment From Apple to Support Comeback Bid",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/5075e8574e0d928b",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Could Intel's Next Big Investment Come From Apple?",
      "content": "Key Takeaways Intel is seeking an investment from Apple after recently securing a $5 billion commitment from Nvidia, Bloomberg reported Wednesday.\n\nApple was once a big customer for Intel, though the iPhone maker has migrated away in favor of using its own processors in its devices in recent years.\n\nIntel has reportedly set its sights on a deal with Apple, a move that could further boost the struggling chipmaker.\n\nShares of Intel (INTC) surged over 6% Wednesday following a Bloomberg report that it's solicited support from the iPhone maker. Neither company responded to Investopedia's request for comment in time for publication. Shares of Apple fell less than 1%.\n\nWhy This Matters for Intel Investors Wall Street analysts broadly believe Intel likely needs more funds and foundry commitments from customers to succeed with its turnaround plan. Investments from Nvidia and the U.S. government have helped that process along, and one from Apple would mark another step. The stock has clambered higher this year, but it's well off past highs, a reminder that there's plenty of work yet to do.\n\nWith Wednesday's gains, Intel's stock has added a quarter of its value in the week since Intel announced a $5 billion investment from and chip-development partnership with AI chip leader Nvidia (NVDA). The raft of events have excited investors, with the Nvidia news seen as a vote of confidence from the world's most valuable company.\n\nStill, the stock remains well off its highs, with most Wall Street analysts tracked by Visible Alpha sticking by \"hold\" ratings while waiting for evidence of more business for Intel's foundry, which makes chips for other firms and which is central to maintaining support from the U.S. government—itself now a major shareholder.\n\nA deal with Apple could help Intel's case, particularly if it came with foundry commitments. Nvidia's did not, raising speculation about whether a foundry deal could come later or whether the lack of one underscored Intel's challenges in convincing customers.\n\n\"If Intel can prove they can deliver they will have customers lined up around the block,\" Bernstein analysts wrote last week. \"If they can’t, no customer in their right mind will put any meaningful volume there.\"\n\nNew partners might also see a deal with Intel as a way to gain political goodwill, Bernstein said. That may hold some appeal to former Intel customer Apple, which has shown some signs of inroads with the Trump administration, last month winning pledges of tariff exemptions based on its recent investments in U.S. manufacturing.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/could-intel-s-next-big-investment-come-from-apple-nvidia-trump-11816712",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "5 Things to Know Before the Stock Market Opens",
      "content": "Stock futures are edging higher after major indexes snapped a three-day streak of record highs; Micron Technology (MU) shares are in focus after the chipmaker posted record revenue on strong AI demand; Stable coin issuer Tether is reportedly seeking funding that would value the company at $500 billion; shares of Chinese e-commerce giant Alibaba (BABA) are surging on its AI spending plans; and Lithium Americas (LAC) stock is soaring on a report that the U.S. government seeks to own a stake in the mining firm. Here's what investors need to know today.\n\n1. Stock Futures Point to Slightly Higher Open\n\nStock futures are higher this morning after the market lost ground yesterday following comments from Fed Chair Jerome Powell, who said the central bank faces challenges in determining interest rates as the labor market weakens while inflation remains elevated. Futures associated with the benchmark S&P 500, the tech-focused Nasdaq and the Dow Jones Industrial Average are pointing to a slightly higher opens for each of the major indexes. Gold futures, which have hit a series of record highs recently, ticked lower to around $3,800 an ounce. The yield on the 10-year Treasury note, which affects a wide range of consumer loans, was little changed at 4.13%. Bitcoin (BTCUSD) was at $113,100 recently, up from an overnight low of around $111,000.\n\n2. Micron Reports Strong Results, Issues Rosy Outlook Amid Surging AI Demand\n\nMemory chip maker Micron Technology (MU) posted record quarterly sales and delivered an optimistic outlook on surging demand for AI hardware. Micron reported adjusted earnings per share of $3.03 on revenue that jumped 46% year-over-year to $11.32 billion in its fiscal fourth quarter, both above estimates compiled by Visible Alpha. The partner to Nvidia (NVDA) and Advanced Micro Devices (AMD) said it expects adjusted earnings per share of $3.41 to $3.71 on revenue of $12.20 billion to $12.80 billion in the fiscal first quarter, also ahead of expectations. Shares of Micron, which have nearly doubled year-to-date, were down 1% in recent premarket trading.\n\n3. Stable Coin Issuer Tether Seeks $500 Billion Valuation in Fundraising Deal\n\nStable coin issuer Tether is reportedly seeking to raise as much as $20 billion in private investment in a deal that could put the cryptocurrency firm’s value on par with ChatGPT-maker OpenAI and Elon Musk’s SpaceX. Bloomberg reported that the El Salvador-based company is looking to raise between $15 billion and $20 billion in exchange for a 3% stake. The deal could see the company valued at $500 billion. In a social media post, CEO Paolo Ardoino said the funding would help scale by “several orders of magnitude” the firm’s business lines, which also included AI, commodity trading, energy, communications and media.\n\n4. Alibaba Shares Jump on AI Spending Plans\n\nShares of Chinese e-commerce giant Alibaba (BABA) surged after a report that the firm plans to boost its AI spending. Bloomberg reported that CEO Eddie Wu said the company would ramp up AI spending beyond the original plan announced in February of around $53 billion, as overall spending on the technology worldwide is expected to reach $4 trillion over the next five years. The company will invest in the development of AI models and infrastructure, including plans to build data centers in Brazil, France and the Netherlands, the report said. U.S.-traded shares of Alibaba were up more than 8% ahead of the opening bell.\n\n5. Lithium Americas Stock Soars on Report U.S. Government Will Take Stake in Company\n\nShares of Lithium Americas (LAC) soared in premarket trading on a report that the Trump administration may seek a stake in the mining company as part of a government loan deal. Reuters reported that the government may ask for a 10% stake in Lithium Americas as a condition in renegotiation talks over a $2.26 billion Energy Department loan for its Thacker Pass lithium project with General Motors (GM). Lithium is used to make electric vehicle batteries and other key electronic equipment. The move would come after the Trump administration took a similar stake in chipmaker Intel (INTC). Shares of Lithium Americas were up 70% in recent premarket trading, while GM gained more than 2%.",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/5-things-to-know-before-the-stock-market-opens-september-24-2025-11816029",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Terramaster uses the fastest Intel Celeron CPU ever in its new up-to-120TB 4-bay NAS - and I am curious about the new TRAID feature",
      "content": "Intel Celeron N5095 drives TerraMaster’s fastest consumer-grade NAS yet\n\nTerraMaster F4-425's four-bay design allows staggering 120TB capacity for growing media libraries\n\nHardware-level 4K H.265 decoding supports smooth Plex and Emby streaming\n\nTerraMaster has introduced the F4-425, a four-bay network-attached storage device that swaps older ARM chips for an Intel Celeron N5095 quad-core CPU.\n\nThe company promotes this as its “fastest” Celeron-based NAS so far, claiming a 40% performance increase over earlier ARM-based systems.\n\nIt targets home users but borrows traits usually found in higher-end storage units, such as 4GB of DDR4 memory, a 2.5GbE network port, and the ability to handle 4K video encoding and decoding.\n\nMassive storage and the controversial TRAID technology\n\nThe shift to Intel x86 architecture positions it closer to entry-level enterprise devices while still being marketed as a consumer solution.\n\nThe F4-425 supports up to 120TB through four 30TB drives, giving households and small creative teams plenty of headroom.\n\nTerraMaster’s new TRAID feature is the most talked-about addition, promising up to 30% greater storage efficiency than traditional RAID without sacrificing redundancy.\n\nWhile that sounds appealing, the claim warrants scrutiny, as efficiency gains often involve trade-offs in resilience or recovery speed.\n\nAre you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nData protection also includes SPC security settings, 256-bit TLS encryption, TFSS snapshots, and compatibility with CloudSync platforms such as Google Drive, OneDrive, and Dropbox.\n\nTerraMaster pitches the F4-425 as a multimedia hub, supporting hardware-level 4K H.265 decoding and direct streaming via Plex, Emby, Jellyfin, or uPnP/DLNA.\n\nIntegrated TerraPhotos AI algorithms can sort pictures by faces, pets, and scenes, potentially reducing manual organization tasks.\n\nThe TNAS Mobile app allows initial setup without a PC and enables local or remote synchronization for smartphone backups.\n\nTerraSync adds millisecond-level file syncing and a 32-version recovery system, while the Push-Lock tool-free design claims to install drives in ten seconds.\n\nLow noise levels of 21dB(A) are promoted as another home-friendly feature.\n\nThe F4-425 is listed at £369.99 in the UK and $369.99 in the US, with a temporary 10% discount.\n\nThis pricing makes it attractive for home users or small studios.\n\nWhile Intel’s N5095 chip is faster than many ARM options, real-world performance depends on network conditions, drive quality, and firmware maturity.",
      "source": "TechRadar",
      "url": "https://www.techradar.com/pro/terramaster-uses-the-fastest-intel-celeron-cpu-ever-in-its-new-up-to-120tb-4-bay-nas-and-i-am-curious-about-the-new-traid-feature",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Microsoft’s Windows ML is ready to boost local AI",
      "content": "Just in time for the next generation of AI PC processors, Microsoft has announced that Windows ML is finally ready for production. It’s a key development for local AI and the chips that power its use.\n\nOn Tuesday, Microsoft quietly said that Windows ML is now generally available, seven years after first introducing the technology at Build.\n\nWindows ML will hopefully solve a persistent problem: consumers care about AI, they simply don’t care where it lives. For many people, “AI” is synonymous with ChatGPT, which resides in the cloud. Qualcomm, Intel, and AMD all have invested heavily into local AI, and powerful NPUs capable of dozens of TOPS (trillions of operations per second).\n\nAnalysts say that applications need to be specifically coded for NPUs. Windows ML changes that. “Windows ML is the built-in AI inferencing runtime optimized for on-device model inference and streamlined model dependency management across CPUs, GPUs and NPUs,” Microsoft says.\n\n“This ability to run models locally enables developers to build AI experiences that are more responsive, private and cost-effective, reaching users across the broadest range of Windows hardware,” Microsoft adds.\n\nEssentially, Windows ML is designed to tally all the resources on a PC, and allocate the task or app to the most suitable hardware: GPU, CPU, or NPU. It’s unclear whether Windows ML or the developer will prioritize NPU efficiency or GPU power, but that’s beside the point. If the app can take full advantage of the available hardware, that’s a win-win for everyone.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2919289/windows-ml-is-ready-to-save-local-ai.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Qualcomm unveils Snapdragon X2 Elite and X2 Elite Extreme chips that rival Apple M4 Max — specs and release date finally revealed, but you'll have to wait a while",
      "content": "Today at Qualcomm's Snapdragon Summit, the company finally unveiled its next-generation wave of Arm-based PC chips. This time, we're getting two high-end system-on-a-chips (SoCs) in the form of a Snapdragon X2 Elite and Snapdragon X2 Elite Extreme with even more performance designed to rival Apple's latest silicon.\n\nQualcomm has confirmed that these new chips won't launch until early next year, meaning we still have a number of months to wait before we can get our hands on this latest Snapdragon silicon. For now, the company has outlined how these chips are a huge improvement over the original Snapdragon X Elite, built on a new 3nm process that should make these chips more efficient.\n\nThe Snapdragon X2 Elite now features both 12- or 18-core configurations, with 6 performance cores and up to 12 prime cores, with a boost frequency up to 4.7GHz. Qualcomm says the X2 Elite boasts up to 31% faster performance at ISO power, while pulling 43% less power than the original Snapdragon X Elite. That translates to better overall performance and efficiency.\n\nIt's the same story in the GPU and NPU department. Qualcomm says the X2 Elite brings a 2.3X increase in performance per watt and power efficiency over the last gen Adreno GPU, though the company hasn't shared total TFLOPS output just yet. The NPU has also been upgraded, now sporting 80 TOPS of compute power compared to the 45 TOPS of the original generation. That should enable more complex and intensive AI compute workloads on device.\n\nBe sure to check out our in-depth comparison between the Snapdragon X Elite and Snapdragon X2 Elite, where we break down all the technical differences and improvements. Below, you'll find a spec table for all the new Snapdragon X2 Elite chips, including the X2 Elite Extreme:\n\nSwipe to scroll horizontally Feature Snapdragon X2 Elite Extreme Snapdragon X2 Elite (88) Snapdragon X2 Elite (80) Model Number X2E-96-100 X2E-88-100 X2E-80-100 Architecture ARM64 ARM64 ARM64 Total Cores 18 18 12 Prime Cores 12 12 6 Multi-Core Max Frequency 4.4 GHz 4.0 GHz 4.0 GHz Boost Frequency 5.0 GHz Single-Core / 5.0 GHz Dual-Core 4.7 GHz Single-Core / 4.7 GHz Dual-Core 4.7 GHz Single-Core / 4.4 GHz Dual-Core Performance Cores 6 6 6 Performance Cores Max Frequency 3.6 GHz 3.4 GHz 3.4 GHz Total Cache 53 MB 53 MB 34 MB GPU Part Number X2-90 X2-90 X2-85 GPU Max Frequency 1.85 GHz 1.70 GHz 1.70 GHz API Support DirectX 12.2 Ultimate, Vulkan 1.4, OpenCL 3.0 DirectX 12.2 Ultimate, Vulkan 1.4, OpenCL 3.0 DirectX 12.2 Ultimate, Vulkan 1.4, OpenCL 3.0 TOPS (INT8) 80 80 80 Micro NPU Dual Micro NPU on the Qualcomm Sensing Hub Dual Micro NPU on the Qualcomm Sensing Hub Dual Micro NPU on the Qualcomm Sensing Hub Memory Type LPDDR5x LPDDR5x LPDDR5x Max Capacity 128+ GB 128 GB 128 GB Configured Capacity 48 GB Device-Specific Device-Specific Transfer Rate 9523 MT/s 9523 MT/s 9523 MT/s Bus Width 192-bit 128-bit 128-bit Bandwidth 228 GB/s 152 GB/s 152 GB/s\n\nThe Snapdragon X2 Elite Extreme shares many of the same specs with the standard X2 Elite when it comes to GPU and NPU, but the CPU boasts up to 75% more performance than the competition at ISO power. It can boost up to 5GHz, which the company says is a first for an Arm-based chip. It also has a higher memory bandwidth of 228GB/s.\n\nQualcomm says the X2 Elite Extreme is designed for \"expert-level workloads with ultimate performance, multi-day battery life and blazing fast AI-processing power,\" positioning it as a viable alternative to Apple's latest M4 Pro/Max silicon, with a minimum of 48GB RAM and support for more than 128GB if configured.\n\nGet the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nOf course, it isn't just Apple Silicon that Qualcomm is interested in competing with. Both Intel and AMD have high-end mobile chips in the form of Arrow Lake and Strix Point, and Qualcomm is confident that its new Snapdragon X2 Elite chips will beat its x86 competition in performance and efficiency too.\n\nThe X2 series will run on a range of PC hardware. (Image credit: Qualcomm)\n\nQualcomm expects these new X2 Elite chips to ship in a wide variety of Windows hardware, including 2-in-1's like the Surface Pro, thin and light laptops, workstation-grade laptops, and mini PCs. It's also possible that with chips like the Snapdragon X2 Elite Extreme, we'll even see desktop tower PCs with a Snapdragon processor.\n\nThese new Snapdragon chips have come swinging right out of the gate. Qualcomm clearly wants the world to know that its chips are worth considering if you're looking for a Windows PC that's capable of professional grade resource intensive workflows. Notably, Qualcomm didn't announce a lower-tier model of the X2 at this event, as that's likely being saved for 2026.\n\nIf you've been waiting for Qualcomm to refresh its Snapdragon PC chips, the wait is almost over. The company says to expect the first Snapdragon X2 Elite-based PCs to ship in the first half of 2026, with the first devices likely being unveiled at CES 2026 if not sooner. Microsoft intends to ship its own updated Surface Pro 12th Gen and Surface Laptop 8th Gen with the Snapdragon X2 wave of silicon sometime next year.\n\nFollow Windows Central on Google News to keep our latest news, insights, and features at the top of your feeds!",
      "source": "Windows Central",
      "url": "https://www.windowscentral.com/hardware/qualcomm/snapdragon-x2-elite-extreme-announcement-2025",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Stock market today: Dow, S&P 500, Nasdaq fall after back-to-back losses, jobless claims dip",
      "content": "US stocks fell on Thursday for the third session in a row as Wall Street weighed an unexpected drop in jobless claims and a sharp upgrade in GDP growth, developments that complicate the outlook for rate cuts amid uncertainty about Federal Reserve policy.\n\nThe Dow Jones Industrial Average (^DJI) dropped 0.4%, and the S&P 500 (^GSPC) lost roughly 0.5%. The tech-heavy Nasdaq Composite (^IXIC) also around 0.5%. Big Tech stocks took hits, with Oracle (ORCL) adding to recent losses and Tesla (TSLA) off over 4%.\n\nMarkets are putting the brakes on stocks' recent record-breaking rally amid debate over whether AI fervor is stretching valuations too much.\n\nAt the same time, the uplift from the Federal Reserve's switch to lowering rates is fading, as signs of division among policymakers dent hopes for another two cuts this year.\n\nIn a positive sign for the labor market, jobless claims data released Thursday showed that the number of Americans filing for unemployment dropped to 218,000 for the week ending Sept. 20 from 232,000 previously. Continuing claims also fell slightly to 1.92 million.\n\nMeanwhile, US second quarter GDP rose to an annualized pace of 3.8%, rebounding from a 0.6% decline in Q1 and well above estimates for a 3.3% rate of growth.\n\nThat sets the stage for Friday's release of the Personal Consumption Expenditures index, the Fed's preferred gauge of inflation. The PCE print for August is expected to show an easing in price pressures, which could make a case for a shift in rate policy.\n\nIn corporates, Costco (COST) is expected to report its quarterly results after the bell on Thursday. Investors expect to see a jump in sales as shoppers pursue deals amid economic uncertainty.\n\nLIVE COVERAGE IS OVER\n\n27 updates",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-dow-sp-500-nasdaq-fall-after-back-to-back-losses-jobless-claims-dip-234737173.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Possible US Stake in GM Partner Lithium Americas Sparks Stock Surge",
      "content": "Key Takeaways Shares of Lithium Americas soared following a report that the U.S. may take up to a 10% stake in the firm.\n\nThe lithium mine developer is working with General Motors to build the Thacker Pass mine in Nevada to boost domestic production of the metal used in rechargeable batteries.\n\n\n\nLithium Americas (LAC) shares skyrocketed Wednesday after a report that the Trump administration is looking to take as much as a 10% stake in the lithium project developer.\n\nThe company's stock was recently up more than 90%. Shares of General Motors (GM), which is partnering with Lithium Americas to build the Thacker Pass mine in Nevada, also gained.\n\nReuters quoted a White House spokesperson as saying President Donald Trump supports the project, which is seen as key to boosting domestic lithium production. The mineral is an important component of rechargeable batteries, and U.S. officials have expressed concern about China being the major supplier.\n\nWhy This Matters to Investors Predicting the Trump administration's next moves regarding acquiring stakes in companies can be difficult. A deal involving Lithium Americas would mark the latest such move, following others with companies including Intel and MP Materials—and today's move in the company's stock illustrates how investors are looking to get ahead of official announcements if they can.\n\nThacker Pass, expected to open in 2028, is expected to be the largest supplier of lithium in the Western Hemisphere.\n\n\n\nThe Department of Energy approved a $2.26 billion loan to develop Thacker Pass at the end of the Biden administration. Reuters said Lithium Americas was scheduled to take the first tranche earlier this month, but Trump officials moved to renegotiate the agreement over fears the company wouldn’t be able to repay the money because of low lithium prices.\n\nThe administration has already invested in other companies it sees as critical to U.S. national security, notably Intel (INTC) and MP Materials (MP).\n\nLithium Americas is in discussions with the Department of Energy and General Motors \"regarding first draw on the DOE Loan,\" the company said in a statement.\n\nShares of Lithium Americas were up about 3% year-to-date ahead of Wednesday’s session.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/possible-us-stake-in-gm-partner-lithium-americas-sparks-stock-surge-11816045",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Two New LG gram Laptops Now Available in Canada, Alongside New Speakers and Monitor Swing",
      "content": "LG has announced a collection of new devices now available in Canada. The new lineup includes two new models of its LG gram laptops as well as the new LG xboom speakers, made in collaboration with Will.i.am.\n\nThe LG gram laptop series for this year includes a 16-inch Pro model, featuring an Intel Core Ultra 7 processor and Nvidia’s GeForce RTX 5050 GPU. The device is designed to be an ultra-light workstation, supporting Copilot+ PC and LG gram Link innovations.\n\nThe base Pro model is joined by the 16-inch 2-in-1 LG gram Pro, which offers up to 32 GB RAM, Intel Core Ultra processing and next-gen AI integrations. What makes this model stand out is the use of a vibrant OLED touchscreen with a 360-degree hinge. The 2-in-1 model combines the traditional structure of a laptop with the flexibility of a tablet.\n\nLG is also partnering with Will.i.am, developing a series of portable Bluetooth xboom speakers. This includes the $199 xboom Grab, the xboom Bounce, available for $299, and the $499 xboom Stage 301. Each model is designed with a distinct use case and provides sound when on the go. The high-end Stage 301 offers deep bass, LED lighting and vocal effects.\\\n\nLG states the xboom speakers made with Will.i.am have AI Sound capabilities. The tech is able to analyze sound and adjust it to suit the genre. AI Lighting can also detect the music genre and compliment it with lighting that syncs up.\n\nFinally, a brand-new $1,499 Smart Monitor Swing is also available in Canada. The model includes a 31.5-inch 4K UHD IPS Smart Monitor attatched to a 180-degree rotating 32-inch touch screen. The monitor includes webOS for streaming content as well a fluid navigations.",
      "source": "iPhone in Canada",
      "url": "https://www.iphoneincanada.ca/2025/09/24/two-new-lg-gram-laptops-canada/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Stock market today: Dow, S&P 500, Nasdaq fall amid sharp GDP expansion, jobless claims dip",
      "content": "US stocks fell on Thursday for the third session in a row as Wall Street weighed an unexpected drop in jobless claims and a sharp upgrade in GDP growth, developments that complicate the outlook for rate cuts amid uncertainty about Federal Reserve policy.\n\nThe Dow Jones Industrial Average (^DJI) dropped 0.4%, and the S&P 500 (^GSPC) lost roughly 0.5%. The tech-heavy Nasdaq Composite (^IXIC) also around 0.5%. Big Tech stocks took hits, with Oracle (ORCL) adding to recent losses and Tesla (TSLA) off over 4%.\n\nMarkets are putting the brakes on stocks' recent record-breaking rally amid debate over whether AI fervor is stretching valuations too much.\n\nAt the same time, the uplift from the Federal Reserve's switch to lowering rates is fading, as signs of division among policymakers dent hopes for another two cuts this year.\n\nIn a positive sign for the labor market, jobless claims data released Thursday showed that the number of Americans filing for unemployment dropped to 218,000 for the week ending Sept. 20 from 232,000 previously. Continuing claims also fell slightly to 1.92 million.\n\nMeanwhile, US second quarter GDP rose to an annualized pace of 3.8%, rebounding from a 0.6% decline in Q1 and well above estimates for a 3.3% rate of growth.\n\nThat sets the stage for Friday's release of the Personal Consumption Expenditures index, the Fed's preferred gauge of inflation. The PCE print for August is expected to show an easing in price pressures, which could make a case for a shift in rate policy.\n\nIn corporates, Costco (COST) is expected to report its quarterly results after the bell on Thursday. Investors expect to see a jump in sales as shoppers pursue deals amid economic uncertainty.\n\nLIVE COVERAGE IS OVER\n\n27 updates",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-dow-sp-500-nasdaq-fall-amid-sharp-gdp-expansion-jobless-claims-dip-234737367.html",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "High-End Intel Arc GPUs See Another Lifeline as Intel Hires More Engineers",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/high-end-intel-arc-gpus-see-another-lifeline-as-intel-hires-more-engineers/",
      "timestamp": "2025-09-24"
    },
    {
      "headline": "Jaguar Land Rover says some systems back online following cyber attack",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b7e98e0b503d3e97",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Magid Adds New Exec Role to Court Agencies",
      "content": "Minneapolis-based research and consultancy firm Magid is courting agencies with a new executive hire: Alec Bardzik joins the firm as senior vice president of brand and agency strategy, a newly created role aimed at expanding its presence on Madison Avenue.\n\nLaunched in 1957 with roots in local TV, Magid has grown into a consumer insights firm providing market research and data to retail, entertainment, travel, and CPG brands. Its clients include Amazon, Planet Fitness, Holiday Inn, Campbell’s, Hershey’s, Dr Pepper, Mastercard, and Best Buy.\n\nNow, Magid sees agencies as a key growth area for its future, with potential “multi-million dollar upside,” said chief marketing officer John Rood.\n\n“The pressure is on for agencies to deliver both breakthrough creative and measurable results for their clients’ businesses,” Bardzik told ADWEEK.\n\nBardzik joins from BarkleyOKRP, where he was senior vice president of strategic intelligence. He has also held senior strategy roles at The Wonderful Company and worked in Deloitte’s strategy and operations consulting practice, with a focus on consumer packaged goods and agribusiness.\n\nIn his new role, he will help Magid’s agency clients tap into what the firm calls its “EmotionalDNA” data set, which captures insights from more than 1 million respondents on consumer emotions, motivations, and behaviors on an ongoing basis. Agencies can use this data to accelerate briefs, sharpen strategy, and optimize workflows.\n\nMagid also offers AI-powered tools that help agencies work more efficiently. For instance, Collaborator Strategy generates marketing strategy briefs in minutes, and Collaborator Publisher creates on-brand, long-form content.\n\n“We make the digestion of intelligence inputs and translation to a brief that actually gets teams in the direction they need go from weeks or days to minutes,” Bardzik said.\n\nHe added: “We see this as the make or break of daily agency life—we want to make challenging and rewarding the norm and tedious and inefficient a relic.”\n\nMagid’s push into the agency space builds on its nearly decade-long partnership with Horizon Media, which uses the firm’s EmotionalDNA data set to inform client campaigns.\n\n“We’re really proud of our partnership with Horizon, which can serve its clientele with additional intel and help them make better decisions, especially when it comes to category competition and which partners to find,” Rood said.\n\nBardzik added that agencies today are eager for tools that help them streamline workflows without impeding their creativity.\n\n“We rarely speak to an agency that isn’t seeking a way to accelerate and strengthen the briefing process across their clients, more fully put AI to work, and not get in the ways of their strategy and creative teams,” he said.",
      "source": "Adweek",
      "url": "https://www.adweek.com/agencies/magid-adds-new-exec-role-to-court-agencies/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Athlon 64: How AMD turned the tables on Intel",
      "content": "22 years ago, on September 23, 2003, AMD changed the game for x86 once and for all. They released the Athlon 64 CPU, a chip that did something Intel didn’t want. Intel didn’t want to extend x86 to 64 bits. But when AMD did it, it forced Intel to clone AMD, rather than the other way around.\n\nWhy Intel didn’t want to go 64-bit\n\nEven in 2001, x86 had decades of baggage attached to it. It was a 32-bit architecture that had been extended from a 16-bit architecture. But that in turn had been extended from an 8-bit CPU design from 1972 that, believe it or not, originated at Datapoint, not Intel.\n\nThis was great for backward compatibility. 8-bit applications were very easy to port to x86 in the early 1980s, and those early DOS applications still ran flawlessly on modern systems 30 years later. For that matter, it’s not impossible to get them running even today.\n\nRemoval of the ability to run 16-bit applications in 64-bit Windows was a design decision, not a technical limitation.\n\nIntel wanted to start over to go 64-bit. Without having to worry about backward compatibility, they could design something that would be faster and more efficient. In theory at least, it would be able to scale higher in clock speed. And there was no question a new design would outperform a theoretical 64-bit x86 when running at the same speed because of efficiency.\n\nAnd if you are cynical, there was one more motivation. If Intel could start over, they wouldn’t have to worry about competing CPU designs, at least not for a very long time. The new design would be encumbered with so many patents, it might be 20 years before someone could clone it.\n\nKeep in mind that in 2003, not only was AMD in the picture, but Transmeta was still in the picture, and Cyrix was fading but not completely gone.\n\nStarting over with a new CPU architecture outright was massively attractive to Intel.\n\nThis new 64-bit architecture wasn’t theoretical, either. Intel was producing it. It was called Itanium, and Intel first released it in June 2001.\n\nAMD’s risky bet and why they made it\n\nAMD was well aware of the shortcomings of extending x86 to 64 bits. And they did it anyway. For them, the stakes were completely different.\n\nAMD knew that if Itanium caught on, that would be the end for them as a CPU company, unless maybe they wanted to become just another ARM licensee. Being just another ARM licensee is more attractive in 2025 than it was in 2003.\n\nBut they could see Itanium wasn’t catching on. It had its uses, and it was doing well enough in those niches, but Windows on Itanium was a non-starter. So much so, The Register called it “Itanic.”\n\nAMD bet that there would be appeal in a 64-bit architecture that was fully backward compatible with x86 and natively ran 32-bit applications at full speed. People would be able to run 32-bit Windows and 32-bit applications on it if they needed to, and then when they were ready for 64-bit software, the hardware was there and ready to go. And they could continue to run 32-bit apps in 64-bit operating systems as long as needed to ease the transition.\n\nThe transition to 32 bits took a decade. AMD reasoned more people would be willing to upgrade to 64 bits if they made that transition as similar as the transition from the 286 to the 386 as possible.\n\nThey believed the market would willingly trade lower 64-bit performance in the long term for better 32-bit performance right away. They also believed that if Microsoft was willing to build Windows on Itanium, they would be willing to take a chance on 64-bit x86 as well.\n\nSo on September 23, 2003, AMD launched its Athlon 64, the first 64-bit x86 CPU.\n\nWhy the Athlon 64 was a hit\n\nAMD64 was everything AMD hoped it would be. It was backward compatible with 32-bit x86. The 64-bit builds of Windows weren’t available immediately, and they didn’t catch on immediately, but you cannot say nobody used them. People did, in fact, use them. In late 2005, I was in charge of administering the complimentary antivirus software that Charter Communications provided to its subscribers. I’m not going to say say someone called me every day wanting 64-bit antivirus for 64-bit Windows. But it did happen once a week.\n\nThe transition took at least as long as AMD expected. When I finally bought an Athlon 64 in 2011, I found native 64-bit software was still scarce. I’m an outspoken Firefox fan; the reason I briefly switched to Google Chrome was to get a 64-bit web browser.\n\nThe Athlon 64 in the enterprise\n\nA few months later, I got a better job with more pay and better growth potential. I can’t talk a lot about the job, but I was administering a mission critical system that ran on Windows, mostly on Dell hardware. I mention Dell because they were exclusively an Intel vendor for years. Cofounder and longtime AMD CEO Jerry Sanders once said of Michael Dell, “I can’t sell him a[n AMD] K6 no matter what I do.”\n\nIt was the Athlon 64 that made Dell relent and finally start using AMD CPUs. Not only were they using them on desktop systems, but they were putting AMD CPUs in servers, an idea that would have been extremely controversial 5 years before. At least in the circles I ran in.\n\nThe Athlon 64 caught on because, in spite of its name, it was an outstanding 32-bit CPU. It was faster than an Intel CPU running at the same clock rate, and it used less power as well. The power consumption was the key to getting into the data center. The Intel name was a security blanket, even though AMD had been making x86 CPUs exactly as long as Intel. But certain decision makers bought Intel marketing and saw AMD as a second tier brand.\n\nThe thing is, when you have a data center with hundreds of systems in it, the money you save on a more efficient CPU really talks.\n\nReplacing Intel Prescott-based servers with AMD64 servers was not a universally popular idea. But you could tell a difference when you were standing behind a rack full of Intel-based servers versus a rack full of AMD based servers. The Intels ran hotter.\n\nFrom an uptime perspective, we couldn’t see a difference. The performance metrics I collected showed there was a slight difference, and that difference was in AMD’s favor. So the AMD critics quickly ate their words.\n\nIntel giving in and cloning AMD64\n\nIn 2004, Intel wrote off the Itanium and cloned AMD64. They called it Intel64, but it was a blatant copy of the AMD implementation. A quirk in the agreements that allowed AMD to use the x86 instruction set also gave Intel the rights to use the AMD64 instructions. So there was nothing illegal about what Intel did. Itanium continued to see use in specialized applications, but Intel quietly discontinued it in 2020.\n\nAMD and Intel have been chasing and catching each other ever since. One of them will pass the other for a CPU generation or two, and then they will change positions. It’s not terribly different from the situation in 1999 with the original Athlon, when AMD outperformed Intel for the first time. The question in everyone’s mind was whether they would do it a second time. The Athlon 64 was the second time.\n\nIt was a big step forward. Eight years before, AMD was trying to pass off a high-clocked 486 as a Pentium equivalent. With the Athlon 64, AMD was innovating.\n\nIf you found this post informative or helpful, please share it! share\n\nshare\n\nsave\n\nshare\n\nshare\n\npocket\n\nshare\n\nemail\n\nRSS feed\n\nDavid Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000.\n\nLike this: Like Loading...",
      "source": "Homeip.net",
      "url": "https://dfarq.homeip.net/athlon-64-how-amd-turned-the-tables-on-intel/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Amazon's grocery ambitions stumble in Britain",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/c3fd05686ffe9280",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Brazil’s Market Momentum Builds. 3 Stocks With Bullish Charts",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/2915e8261d15cda4",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "AI Is Democratizing Strategy- And Creating Savings For Consumers",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/jaimecatmull/2025/09/25/ai-is-democratizing-strategyand-creating-savings-for-consumers/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "How Enterprise AI Agents Can Reach Their Potential",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/cio/2025/09/25/how-enterprise-ai-agents-can-reach-their-potential/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "How Corintis Helps AI Pioneers To Keep Their Cool",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/davidprosser/2025/09/25/how-corintis-helps-ai-pioneers-to-keep-their-cool/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "S&P 500 Gains & Losses Today: CarMax Stock Skids, Oracle Retreats; Intel Pushes Higher",
      "content": "A soft earnings report pressured shares of the nation's largest independent used car retailer, while a semiconductor giant extended its rally following reports of investment talks with another tech powerhouse.\n\n\n\nMajor U.S. equities indexes lost ground Thursday, declining for a third straight day ahead of a key inflation report set for release Friday. The S&P 500 and the Nasdaq were down 0.5%, while the Dow ended 0.4% lower. See here for Investopedia's full roundup of the day's market action.\n\nCarMax (KMX) shares plunged 20%, falling the furthest of any stock in the S&P 500, after the used car retailer reported lower-than-expected sales and profits for its fiscal second quarter. CEO Bill Nash pointed to challenges including a pull-forward of demand into the previous quarter along with depreciation in the inventory CarMax built up to support sales.\n\nIntel (INTC) shares added to their recent string of gains, popping 8.9% to secure the S&P 500's top daily performance. The move followed reports that the semiconductor maker has been seeking an investment from Apple (AAPL). The iPhone maker was once a major Intel customer but has more recently moved toward the use of its own chips. Shares of Apple were off 1.8% today.\n\nAlthough Jabil (JBL) topped revenue and earnings per share forecasts in its latest quarterly report, shares of the electronic parts supplier slipped 6.7%. CEO Mike Dastoor said artificial intelligence helped drive demand in Jabil's capital equipment, data center, and networking markets, but the integrated circuit maker acknowledged pressure facing its automotive and renewable energy segments.\n\nRothschild Redburn initiated coverage of Oracle (ORCL) stock with a \"sell\" rating. The research firm believes markets could be pricing in an overly optimistic outlook on Oracle's contracted cloud revenue, optimism about which has driven enthusiasm for the stock since its latest quarterly report arrived. Shares of the enterprise software giant dropped 5.6%.\n\nGlobal banking giant HSBC (HSBC) said that it had conducted a successful bond trading trial using quantum computers from International Business Machines (IBM) to optimize market predictions. According to the financial firm, incorporating IBM's quantum computing resources resulted in a 34% improvement in predicting the likelihood that a trade would be executed at a particular price compared with using only classical computing techniques. IBM shares powered 5.2% higher, while HSBC's American depository receipts slipped.\n\nAfter nearly doubling Wednesday after reports that the Trump administration was considering a government stake in the company, shares of Canada-based miner Lithium Americas (LAC) added another 23% Thursday. The company holds a majority stake in the Thacker Pass lithium mine in Nevada, which is on track to become one of the largest sources in North America for the battery component. Shares of Albemarle (ALB), the world's largest lithium miner, gained 4%.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/s-and-p-500-gains-and-losses-today-carmax-stock-skids-oracle-retreats-intel-pushes-higher-11817526",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Intel has reportedly approached Apple for an investment, after CEO Tim Cook said 'we'd love to see Intel come back'",
      "content": "After receiving a cash injection from SoftBank Group, Nvidia, and even the US government, Intel is now seeking investment from iPhone creator and longtime collaborator Apple.\n\nAs reported by Bloomberg, and citing \"people familiar with the matter\", Apple and Intel are reportedly in the early stages of conversations about \"how to work more closely together\". No specifics are given on what investments are being asked for or what kinds of conversations are happening, but this is part of a broader comeback attempt from Intel.\n\nIntel has fallen behind in recent times, with the 13th and 14th Gen chip crashes only painting part of the picture. Its recent CPUs haven't been very good for gaming (while AMD has smashed it out of the park in that regard), and Intel admits it \"fumbled the football\" with Arrow Lake. As a result, a lot is riding on Nova Lake, and increased funding would certainly help it make an impact. More funding would help catch up to supply needs for any deals the company can make, too.\n\nApple has a bit of a history with Intel. Prior to the swap to its own M-series chips in 2020, Intel was the central CPU supplier for all MacBooks and Macs. Apple also purchased Intel Mobile Communications back in 2019 for $1B.\n\nApple hasn't really worked with Intel in a public manner in a few years, actively removing all Intel parts from its products and cutting support. But just last week, Apple CEO Tim Cook told Jim Cramer, \"You know, competition is very good for the foundry business… we’d love to see Intel come back.\"\n\nTrays and trays of chips awaiting testing. (Image credit: Intel)\n\nIntel Foundry is Intel's semiconductor fabrication company, and it's been in a bit of a strange spot for some time. Four former Intel board members pushed for a joint venture between Nvidia, Qualcomm, Google, Amazon, Apple, and Broadcom just last year, before \"the rust of time makes them worthless\". Apple itself has announced renewed investment in American manufacturing in the wake of Trump's tariffs. This is all to say that any investment would likely push towards Intel's manufacturing goals, and not chip design.\n\nAs an everyday MacBook user, the switch to in-house silicon chips is one of the best choices Apple has made in the last decade. Working with TSMC on the latest (and tiniest) node technology, and built with its hardware in mind, the M chips represent a big leap forward in computing power and efficiency. The hardware has become more bespoke without the challenge of having to take off-the-shelf Intel parts and put them in its devices.\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nCapable of running games like Baldur's Gate 3 and Lies of P, MacBooks have even become decent gaming devices. Though more competition is certainly good for the market, I'd hope any potential investment from Apple comes at arm's length, as those M-chips feel like a real wonder for the fruit-titled company.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/intel-has-reportedly-approached-apple-for-an-investment-after-ceo-tim-cook-said-wed-love-to-see-intel-come-back/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Who Won Mel Owens’ Season of ‘The Golden Bachelor’? Here’s What Reality Steve Has to Say",
      "content": "The Golden Bachelor season 2 premiered on Wednesday, Sept. 24.\n\nReality Steve is known for having intel on Bachelor Nation shows, including their winners.\n\nSteve revealed that his coverage for Mel’s season of The Golden Bachelor is going to look a bit different.\n\n\n\nThe Golden Bachelor season 2 may have just premiered on September 24, but true Bachelor Nation fans know that Reality Steve is probably already hard at work gathering intel on who won Mel Owens’ heart (and the show, ofc). But, if you’re looking for spoilers on who won Mel’s season of The Golden Bachelor, you’re in for quite the surprise.\n\nAccording to a recent podcast episode from the reality TV blogger, his coverage on the spin-off is going to look different down the line. In the past, he would already have the finalist’s names ready to go, thanks to insiders on set—but for the second installment of The Golden Bachelor, he’s changing this up.\n\nJohn Fleenor // ABC Mel Owens and his contestants on The Golden Bachelor season 2.\n\n“Hopefully, at some point, I’ll get spoilers. Right now, I have none,” Steve said during the September 23 episode of his pod. “I couldn’t tell you where they went for Final Rose ceremony. I can’t tell you who the final three are.”\n\nHe added, “And for the first two seasons of Golden Bachelor and Golden Bachelorette, I had all that info and you knew it, at least for Gerry’s season, you knew who the final two were.”\n\nAs for Mel’s season? He only has one spoiler, which is that Peg makes it to a one-on-one date with Mel at the Orange County Fair at some point. Even the timing is unclear, which is unlike RS!\n\n“I’ve got nothing. I got nothing right now. If I did, I would tell you, but, the days of me coming on the next day after a Golden Bachelorette or a Golden Bachelor and breaking down what we saw on the episode, certainly not gonna be writing anything about it,” he shared. “The coverage of Golden Bachelor is gonna be very, very minimal from me, just because I don’t care, and that’s my stance.”\n\nReality Steve not caring about a season of The Bachelor is low-key groundbreaking. Guess we’ll have to tune in and snoop for all the spoilers ourselves this time around!",
      "source": "Cosmopolitan.com",
      "url": "https://www.cosmopolitan.com/entertainment/tv/a68058097/who-won-mel-owens-season-golden-bachelor-reality-steve/",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Oracle initiated, Ulta Beauty upgraded: Wall Street's top analyst calls",
      "content": "The most talked about and market moving research calls around Wall Street are now in one place. Here are today's research calls that investors need to know, as compiled by The Fly.\n\n\n\nTop 5 Upgrades:\n\n\n\nArgus upgraded Ulta Beauty (ULTA) to Buy from Hold with a $570 price target. Last month the company reported its fourth consecutive earnings beat, though shares have underperformed the S&P 500 and the industry ETF IYC over the past quarter, the firm says.\n\nScotiabank upgraded CrowdStrike (CRWD) to Outperform from Sector Perform with a price target of $600, up from $440. The firm's latest channel checks indicate that CrowdStrike is \"more competitively entrenched than ever\" in core endpoint security.\n\nBNP Paribas Exane upgraded Arista Networks (ANET) to Outperform from Neutral with a price target of $172, up from $125, calling the company a \"key beneficiary\" of the multi-year AI data center capex supercycle.\n\nMoffettNathanson upgraded Chewy (CHWY) to Buy from Neutral with a $48 price target. As pet household formation continues its recovery, the volatility on Chewy's quarterly customer additions should decrease, says the firm, which cautions that Chewy's path forward to the firm's above-consensus customer additions and adjusted EBITDA in FY26 \"will not be linear.\"",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/oracle-initiated-ulta-beauty-upgraded-133846264.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Commentary: Nvidia’s US$5B Intel deal revives memories of Microsoft’s 1997 Apple lifeline",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250924PD211/intel-nvidia-apple-microsoft-investment.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "MGM’s $2.3 Billion New York Casino Proposal Wins Key Support",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/7db7b24e8a692223",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Intel Investors Snap Up Bullish Options to Chase Furious Rally",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/3ba12a36ee8834eb",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "A smart backup MacBook for just $190 + free shipping",
      "content": "TL;DR: A reliable second laptop for just $189.97 (MSRP $999) — a refurbished MacBook Air with a 13.3″ display, 128GB SSD, and all-day battery life.\n\nSometimes you don’t need the latest and greatest. Sometimes you just need a solid laptop that works. Cleaned, inspected, and ready to go, this refurbished Apple MacBook Air 13.3″ (2017) is yours for just $189.97 with free shipping.\n\nPerfect as a second computer for the family, a travel laptop that won’t break your heart if it gets banged up, or just something light for bill-paying, streaming, and everyday browsing. This MacBook Air is still very much the real deal.\n\nHere’s what you get:\n\n13.3″ display: Crisp, clear, and easy on the eyes.\n\nIntel Core i5 processor: Smooth performance for daily tasks.\n\n128GB SSD storage: Quick file access, plenty of room for essentials.\n\nWi-Fi + Bluetooth: Stay connected wherever you are.\n\nUp to 12 hours of battery life.\n\nIt’s slim, it’s portable, and it’s Apple — for much less.\n\nGet a refurbished MacBook Air from 2017 for just $189.97 (MSRP $999) and free shipping while you can.\n\nApple MacBook Air 13.3″ (2017) i5 1.8GHz 8GB RAM 128GB SSD (Refurbished)See Deal\n\nStackSocial prices subject to change.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2918416/a-smart-backup-macbook-for-just-190-free-shipping.html",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Bloomberg: ‘Intel Is Seeking an Investment From Apple as Part of Its Comeback Bid’",
      "content": "Intel Corp. has approached Apple Inc. about securing an investment in the ailing chipmaker, according to people familiar with the matter, part of efforts to bolster a business that’s now partially owned by the US government.\n\nApple and Intel also have discussed how to work more closely together, said the people, who asked not to be identified because the deliberations are private. The talks have been early-stage and may not lead to an agreement, the people said.",
      "source": "Bloomberg",
      "url": "https://www.bloomberg.com/news/articles/2025-09-24/intel-is-seeking-an-investment-from-apple-as-part-of-its-comeback-bid?embedded-checkout=true",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "US opens tariff investigations into medical equipment, robotics and industrial machinery",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/875aebbfb91fec3c",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Intel Updates First-Party Performance Claims of Core Ultra \"Arrow Lake-S,\" How They Stack Up Against AMD",
      "content": "Intel this month released a presentation updating its channel partners and end-users how its Core Ultra 200-series \"Arrow Lake-S\" desktop processors stack up against AMD Ryzen 9000 series \"Zen 5\" processors, including the latest 9000X3D series chips with 3D V-Cache. The company claims a superior balance of gaming and productivity performance at comparable prices. These performance claims take into account the various software and microcode updates the platform received since its October 2024 debut—nearing a year in the market—particularly taking into account advances Intel made to its APO (application performance optimization) software in this time.Intel begins its presentation by layout out its entire Socket LGA1851 desktop processor lineup. The maxed-out Core Ultra 9 8P+16E processors are shown as being competitive to the entire Ryzen 9 9000 series high core-count processors. The Core Ultra 7 265K/KF 8P+12E chips are compared to the Ryzen 7 9800X3D, which remains the fastest processor for PC gaming. The non-K Core Ultra 7 265 and 265F are compared to the Ryzen 7 9700X. And then the bulk of the Core Ultra 5 6P+8E and 6P+4E lineup is compared to the Ryzen 5 9600X and 9600.The flagship Core Ultra 9 285K is pitted against AMD's flagship part, the Ryzen 9 9950X3D. The gaming performance is shown to be mostly trailing by single-digit percentages, while content creation performance sees performance gains in favor of the 285K in 4 out of 5 tests. Then, in a separate slide, the 285K is pitted against the Ryzen 9 9950X, the chip lacking 3D V-Cache. Here, the gaming performance is mostly at par, while productivity performance sees Intel post leads in all five tests. Sticking with the 285K and 9950X (non-X3D) comparison, and Intel put out a slide with a wider selection of games, where the performance is shown being at par, or favoring the 285K in three out of nine tests. A much wider selection of productivity tests sees the 285K convincingly ahead of the 9950X (non-X3D).Next up, Intel compared the Core Ultra 7 265K with the Ryzen 7 9700X in a wide selection of games. Here, the 265K is shown either at-par or lagging behind the 9700X in 7 out of 9 game tests, and posting gains in 2 of them. Intel's latest pricing sees the 265K go for $299, putting it at an advantage against the 9700X with its $360 price. Armed with 8P+12E cores, particularly those high performance-Watt \"Skymont\" E-cores, the 265K predictably smokes the Ryzen 7 9700X in productivity performance, posting performance gains as high as 84% in multithreaded productivity benchmarks.Interestingly, Intel compared the 265K with the Ryzen 7 9800X3D in a much narrower set of game tests, because the AMD chip bludgeons Intel in 4 out of 5 game tests. \"Starfield\" is the only test where the 265K is shown performing on par. The 265K posts much higher productivity performance owing to its higher core count. Then comes an interesting slide from Intel, where it is comparing the performance-per-Dollar of the $299 Core Ultra 7 265K with the $479 Ryzen 7 9800X3D, and is claiming a 25% lead. Intel compares the 265K to the 9800X3D across a broader set of productivity benchmarks to make its point.Intel also makes an interesting comparison between the Core Ultra 7 265K and the Ryzen 9 9900X 12-core/24-thread non-X3D processor, where the gaming performance is shown to be mostly on-par, however, no comparisons have been made between their productivity performance.We now jump down to the Core Ultra 5 245K, which springs a mixed bag when it comes to gaming. Out of the nine game tests, the 245K trails the Ryzen 5 9600X in three of them, is at par in three others, while leading the 9600X in three. Barring two single-thread heavy productivity benchmarks, namely Photoshop and Cinebench 2004 ST, The 245K dominates the 9600X in multithreaded productivity owing to its higher core-count of 6P+8E.Intel compared the Core Ultra 5 225 with its predecessor, the Core i5-14400, and claimed a geomean of 20% higher gaming performance.Here are some important performance footnotes by Intel:",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341351/intel-updates-first-party-performance-claims-of-core-ultra-arrow-lake-s-how-they-stack-up-against-amd",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "CATL Surges to Overtake Moutai as China’s Third Largest Stock",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/997858880cfa58dd",
      "timestamp": "2025-09-25"
    },
    {
      "headline": "Stocks to Watch Friday: GlobalFoundries, Oracle, Intel, Paccar",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/f32faf943a9adf71",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "NVIDIA CEO Jensen Huang Thinks OpenAI Could Be the Next Multi-trillion Hyperscaler",
      "content": "Nvidia CEO Jensen Huang gives a comprehensive Year in AI Recap and forward-looking discussion on the explosive growth of AI infrastructure, scaling laws, partnerships, competitive dynamics, and geopolitical implications. Nvidia’s recently announced an OpenAI Stargate partnership and an investment in OpenAI. AI computing is an industrial revolution on par with electricity or jet engines. Huang dismisses skeptics on bubbles/gluts and emphasizes Nvidia’s moat through extreme co-design, and advocates for U.S. leadership via pro-growth policies.\n\nAI has evolved from one-shot inference (pre-training + post-training) to thinking AI via chain-of-thought reasoning, tool use, multimodality, and agent systems. This integrates training and inference in reinforcement learning.\n\nThere are now three scaling laws.\n\n1. Pre-training: Memorizing/generalizing data (like 8×8=64).\n\n2. Post-training: AI “practicing” skills through iterative inference.\n\n3. Inference: From one-shot answers to prolonged “thinking” (research, ground-truth checks). This potentially scales compute needs by a billion times. Not just 100× or 1,000× as Huang predicted a year ago.\n\nToken generation doubles every few months.\n\nPerformance per watt must match to avoid cost explosions.\n\nThis drives Nvidia’s annual advanced chip release cadence.\n\nHopper → Blackwell: 30× perf via NVLink\n\nThen Rubin → Ultra → Feynman next.\n\nNvidia invests $100B over time in OpenAI. This is optional and is not tied to sales. Nvidia becomes a preferred partner for self-built AI infrastructure.\n\nNvidia is more critical to OpenAI than Microsoft.\n\nOpenAI’s Stargate: 10GW data centers (additive to existing Azure/OCI/CoreWeave builds, totaling 5-7GW+). If Nvidia supplies, ~$400B revenue potential.\n\nOpenAI transitions from outsourcing (to Microsoft or others) and OpenAI strategy becomes a hyperscaler-like self-build.\n\nAI Productivity\n\nAI augments human intelligence. Human intelligence is now ~$50T of global GDP, 55-65%.\n\nIf a $100K employee gets $10K AI → 2-3× productivity then this is hugely valuable\n\nNvidia’s 100% co-agent coverage boosts hiring/growth.\n\n$10T augmentation → $5T capex (50% gross margins) for AI factories generating tokens continuously versus static software.\n\nTAM Estimate: Current $400B annual. 4-5× growth to $1-2T+ by decade-end/ Alibaba: 10× data center power by 2030. This correlates to Nvidia revenue via watts.\n\nNvidia’s Moat: Extreme Co-Design and Annual Cadence\n\nNvidia pace of annual releases would be impossible without internal AI co-design.\n\nProgress has been exponential. Over the last ten years performance from the Kepler→Hopper increased 100,000×.\n\nHopper→Blackwell: 30× via NVLink).\n\nRoadmap: Blackwell (2025), Rubin (H2 2026), Ultra (2027), Feynman (2028).\n\nExtreme Co-Design is used to optimize model/algorithm/system/chip simultaneously. This is beyond Moore’s Law. There are 6-8 chips variants each year.\n\nThere are GPU/CPU/networking/NVLink/Spectrum-X Ethernet. Fastest growing business is the ethernet side of Nvidia. Scales to multi-factory clusters.\n\nMoat Strength is increasing. There is more competition, but it is harder due to scale/wafer costs.\n\n$50B purchase orders on unproven arches only for Nvidia only. Only Nvidia has a proven ecosystem. Supply chain pre-builds $hundreds of billions on Nvidia visibility.\n\nCUDA programmability enables transformer experiments.\n\nASICsc ompetitors are Limited to niches (like transcoders). Large markets demand customer-owned tooling.\n\nGoogle TPUs are going to → v7 (version 7). Google still buys Nvidia GPUs. Even free ASICs lose to Nvidia’s 30× perf/watt (2GW power → 2× revenue).\n\nDisaggregated factories. Dynamo open-sourced. NV Fusion integrates Intel/ARM.\n\nEcosystem and Broader Impacts\n\nElon/xAI/Tesla. Jensen praises Elon as the ultimate GPU. XAI Colossus 1: 230K H100s/H200/B200. Colossus 2 is 500K GB200s and soon 1M. They are potentially at a 1GW first. xAI investment is incredible and XAI has a full-stack build advantage.\n\nSovereign AI is an existential need. Nvidia as global infrastructure partner. There is and will be an energy renaissance with nuclear and gas.\n\nThe US – Trump admin is pro-growth/energy/tech. They provide an Open-door for CEO access. Exports will accelerate. Reindustrialization/upskilling. AI can be an equalizer. It can close tech divide—no coding needed.\n\nIndustrial/digital revolutions accelerated GDP. AI will be co-workers for billions → 4%+ growth.\n\nAbundance age: Raise floor (reindustrialize; AI for all 8B people).\n\nNBF commentary.\n\nOpenAI could go to $2-5 trillion by 2030. Nvidia could go to $8-15 trillion by 2030.\n\nIf XAI is the AI winner then it could go to $5-10 trillion by 2030.",
      "source": "Next Big Future",
      "url": "https://www.nextbigfuture.com/2025/09/nvidia-ceo-jensen-huang-thinks-openai-could-be-the-next-multi-trillion-hyperscaler.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "How QCOM Stock Doubles To $360",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/greatspeculations/2025/09/26/how-qcom-stock-doubles-to-360/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Trump's new tariffs on drugs, trucks and furniture: Top Story",
      "content": "00:09 Speaker A\n\nWell, the president was pretty busy on Truth Social last night. He unveiled a fresh round of punishing tariffs on a broad range of imported goods, including 100% duties on branded drugs and 25% levies on heavy duty trucks, set to come into force next week.\n\n00:30 Speaker A\n\nNow, stocks of pharmaceuticals across Asia fell heavily and in fact, in Australia too. And though there was an initial slump in European pharma stocks, the declines were less pronounced.\n\n00:41 Speaker A\n\nIt's interesting to note that GSK's London-listed shares are higher. Now, remember, the UK pharma agreed to invest in the US earlier this month.\n\n00:51 Speaker A\n\nUnsurprisingly, US heavyweight Eli Lilly has seen its shares rise in the pre-market up over 1% there.\n\n01:00 Speaker A\n\nNow, Trump also said he would start charging a 50% tariff on imported kitchen cabinets and bathroom vanities, and a 30% tariff on upholstered furniture. All the new duties take effect from October the 1st.\n\n01:13 Speaker A\n\nAdditionally, according to the Wall Street Journal, the US is also planning to ask chip makers to manufacture at home as many chips as the their customers import in a bid to curb reliance on foreign supply.\n\n01:27 Speaker A\n\nThe Trump administration would levy tariffs on firms that do not maintain a one-to-one ratio over time. The plan is the result of what President Trump referred to last month when he said tech companies that invest more in the US would avoid roughly 100% tariffs on semiconductors.\n\n01:44 Speaker A\n\nNow, if implemented, this could prove to be a big headache for the likes of Apple. It imports chips from all over the world. But firms like Micron and Intel who are increasing production in the US, well, they could benefit.\n\n01:55 Speaker A\n\nOkay, well, here's my colleague Josh Lipton on what else you need to watch today.\n\n02:02 Josh Lipton\n\nAll right, starting off on the Federal Reserve. We're going to be getting some more commentary on Friday from a couple of Fed officials, Richmond Fed President Tom Barkin, Michelle Bowman, the Fed's top bank cop.\n\n02:14 Josh Lipton\n\nThis coming after a big batch of commentary on Thursday, including Michelle Bowman, Bowman saying that the fragile job market justifies more interest rate cuts.\n\n02:22 Josh Lipton\n\nSpeaking of the Central Bank, the Fed preferred inflation gauge that's coming out on Friday, that's personal consumption expenditures or PCE. Economist forecasting total PCE for August to accelerate to 0.3%, while core PCE slowed to 0.2% on a month-over-month basis.\n\n02:39 Josh Lipton\n\nAnd finally, I'm going to be getting the final reading of consumer sentiment from the University of Michigan. That number expected to hold steady compared to the prior reading at 55.4, signaling no change in consumer's attitude toward the economy.\n\n02:51 Josh Lipton\n\n55.4 is a historically low reading, indicating consumers still relatively downbeat about current conditions.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/video/trumps-tariffs-drugs-trucks-furniture-123540158.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Trump's TikTok deal payment criticized as 'shake-down scheme' by experts",
      "content": "Trump's TikTok deal payment criticized as 'shakedown scheme' by experts\n\ntoggle caption Andrew Harnik/Getty Images\n\nThe Trump administration recently approached a coalition of U.S. investors set to take over TikTok's U.S. operations with an ask: Will the group make a payment to the federal government \"in the low billions,\" according to a person with direct knowledge of the talks.\n\nThe response from the investors, which includes tech mogul Larry Ellison, the Murdochs and venture capital heavyweight Andreessen Horowitz, was an unequivocal yes.\n\n\"Not a single member balked,\" said the person, who was not authorized to speak publicly. \"They see it as something of a finders' fee.\"\n\nWelcome to President Trump's new business agenda: extracting payments as if the federal government is brokering deals like a white-shoe consulting firm fueled by lucrative \"fees for service.\"\n\nSponsor Message\n\nWhether it's the U.S. taking 15% of Nvidia and AMD's chip sales to China, the federal government securing a \"golden share\" in U.S. Steel or the Trump administration reportedly seeking an equity stake in Lithium Americas as part of a government loan negotiation, the White House is on a campaign of squeezing businesses with few parallels in modern history.\n\n\"At a minimum, this now means there is a tax imposed on every major business transaction,\" said Luigi Zingales, a professor of finance at the University of Chicago. \"But even worse, businesses will no longer be focused on innovating and creating value and instead the whole game now is rent-seeking. It's all about ingratiating yourself with Trump.\"\n\nThe White House did not return a request for comment.\n\nAsked on Thursday about the multibillion-dollar fee expected to be tacked onto the TikTok deal, which was earlier reported by The Wall Street Journal, Trump was evasive.\n\n\"We're going to be announcing different things, but the U.S. comes out great,\" Trump said from the Oval Office.\n\ntoggle caption Mario Tama/Getty Images\n\nTrump has been more direct about defending his administration's private business interventions, including after Intel agreed to sell a 10% stake of the company to the U.S. government following Trump's calls for its chief executive to resign.\n\nSponsor Message\n\n\"The United States paid nothing for these Shares, and the Shares are now valued at approximately $11 Billion Dollars. This is a great Deal for America and, also, a great Deal for INTEL,\" Trump posted last month.\n\nMany media companies capitulate to Trump pressure\n\nThis pattern has played out across media, where Trump's longtime war against news organizations has escalated into marshaling the might of the federal government to force concessions.\n\nThe parent companies for ABC and CBS both paid $16 million to settle lawsuits Trump lawsuits filed alleging mistreatment by the networks. The payments went to Trump's presidential library foundation and Trump's legal fees. Shortly after CBS' payment, federal regulators approved the sale of its parent company, Paramount, to Skydance Media, which is controlled by the Ellison family.\n\nMedia companies were already signaling their acquiescence to Trump before he won a second term.\n\nAhead of the election, the billionaire owners of The Washington Post and The Los Angeles Times killed parallel editorial endorsements of Kamala Harris. They soon rewired their editorial pages to be less critical of Trump. Both owners — Amazon founder Jeff Bezos for the Post and medical innovator Dr. Patrick Soon-Shiong for the Los Angeles Times — have major business interests that hinge on decisions by federal officials.\n\nThen there is Jimmy Kimmel. Last week, Disney — which owns ABC — suspended the late-night host after Federal Communications Chairman Brendan Carr threatened action over Kimmel's remarks about the assassination of conservative activist Charlie Kirk. After a public outcry, including from First Amendment scholars, Kimmel returned on Tuesday with the blessing of ABC and Disney.\n\ntoggle caption Michael Loccisano/Getty Images\n\nTrump lashed out at the network's reversal.\n\n\"I can't believe ABC Fake News gave Jimmy Kimmel his job back,\" Trump wrote on Truth Social, writing in the same post: \"I think we're going to test ABC out on this. Let's see how we do. Last time I went after them, they gave me $16 Million Dollars.\"\n\nSponsor Message\n\nTrump allies landing deals sparks criticism of \"crony capitalism\"\n\nAmong those the Trump White House has lined up to take the reins of TikTok's U.S. operation are Rupert and Lachlan Murdoch, the controlling owners of Fox News, The New York Post and The Wall Street Journal.\n\nFrom one view, it can be seen as recognition of the friendly coverage the president often receives from Fox and The Post.\n\nBut Trump and Murdoch have also been at odds. That strife was highlighted in July when Trump sued The Journal and Murdoch over the paper's reporting on the disgraced late financier Jeffrey Epstein.\n\nThe Murdochs' role in the takeover of America's most popular video app is a remarkable victory for the family and follows a relationship that has at times been combative.\n\ntoggle caption Monica Schipper/Getty Images\n\n\"If you look at Fox News on the one hand and The Wall Street Journal editorial page on the other, I think it's very clear that Rupert Murdoch wants to have bets on every square on the roulette table,\" says Richard Tofel, who was the former assistant publisher of The Wall Street Journal prior to Murdoch's 2007 acquisition of the paper.\n\nBut most of the stakeholders in the TikTok investment group are business leaders who have shown sustained loyalty to the president, which makes the deal look like a reward for fealty, Tofel says.\n\n\"There is a growing set of examples of crony capitalism that the Trump administration is putting into place across this country,\" says Tofel, a lawyer who later went on to become president of the nonprofit investigative news site ProPublica. \"American industry — which would have regarded this behavior from a Democrat as anathema and inconsistent with the tenets of unfettered capitalism — is rolling over for it time after time.\"\n\nExperts say U.S. economy being undermined by \"shakedown schemes\"\n\nThe exact template has varied. In the case of TikTok, the administration is seeking a fee for service. With Intel, the federal government is acquiring an equity stake. For chipmakers Nvidia and AMD, meanwhile, the demand was for a slice of future profits. And with the network television settlements, the payouts arose after personal legal disputes.\n\nSponsor Message\n\n\"There is no consistent principle at play, just the exercise of Trump's personal power over other people's money,\" said Dael Norwood, associate professor of history at the University of Delaware, who notes that the winners and losers are clear.\n\n\"All Americans — taxpayers, investors, customers, and workers — lose with crony capitalism,\" he said. \"It increases everyone's costs, makes everyone more vulnerable to extortion (or worse), and profoundly degrades our expectations for honesty and fair dealing, society-wide.\"\n\nIn public, corporate executives show support to the president and appear to back such deals, but behind closed doors, some business leaders are expressing deep concern.\n\nYale School of Management professor Jeffrey Sonnenfeld recently helped organize a gathering of more than 100 top CEOs, and he said there was near-unanimous consensus in surveys conducted at the event that Trump's interventions in private business are undermining America's free market principles.\n\n\"These are shakedown schemes. It's a gross violation of what capitalism is supposed to stand for. I'd even call it extortion,\" Sonnenfeld said. \"Privately, CEOs are horrified.\"\n\nBut Sonnenfeld said executives are not banding together to push back on Trump, as top business leaders did following Trump's election denialism in November 2020.\n\n\"CEOs need to speak up, like they did then, but they aren't doing it publicly,\" Sonnenfeld said. \"Fear of retaliation is motivating the silence, but there has got to be a trigger line to stop this. We just don't know what that is yet.\"\n\nTalks with American investors for a potential acquisition of TikTok's U.S. enterprise have been moving in fits and starts for the past five years, starting back when the Trump administration declared the Chinese-owned hit video app to be a national security threat and sought to have it banned.\n\nSince Trump's about-face and embrace of TikTok, it has been clear that software and cloud-computing company Oracle would be a major player in the bid to take over the app's American presence.\n\nSponsor Message\n\nOracle co-founder Larry Ellison is a close confidante of Trump and the president has said both publicly and in private that he'd like to see TikTok controlled by Oracle.\n\nAccording to the source with direct knowledge of the talks, many of the deal's provisions have been under discussion for months, including that Oracle will host and oversee all of Americans' TikTok data. Beijing-based ByteDance will license its algorithm to the U.S. entity to be retrained based only on the 170 million U.S. users of the app and ByteDance will keep a minority stake in the company.\n\nThe one part of the agreement that caught investors by surprise? The multibillion-dollar fee request.\n\n\"They were taken aback when they were told they'd have to kick in,\" the source said. \"But I think they see it as just the price of doing business right now.\"",
      "source": "NPR",
      "url": "https://www.npr.org/2025/09/26/g-s1-90598/tiktok-deal-trump-oracle",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Why Is Intel Stock Jumping Today?",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/5021f1310e875bfa",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "U.S. Could Impose 100% Semiconductor Tariff If Chips Are Not \"Made in America\"",
      "content": "The U.S. government is considering imposing massive tariffs on semiconductor products unless manufacturers can match those volumes with chips produced in the United States. Under the current draft, companies that do not match foreign-sourced chip volumes with domestic output over time could face tariffs that, in some versions, reach 100%. The idea is an act of forceful action to speed up onshore capacity and reduce strategic dependence on overseas foundries, but they also admit that the plan faces serious practical hurdles. The core concept is simple to draft on paper, but hard to implement. For every unit brought into the U.S. from an overseas plant, such as TSMC in Taiwan and Samsung in South Korea, a corresponding unit would need to be produced domestically within a specified timeframe, or tariffs would be applied. This means that for every batch of chips NVIDIA, AMD, Intel, or Apple produce overseas, the same chip would need to be produced in the U.S.Counting and comparing chip \"units\" is extremely complicated. Every semiconductor design differs wildly by complexity, cost, and function, and the typical semiconductor supply chain moves wafers, packages, and finished devices across several countries before a product reaches consumers. Even TSMC, the very maker of the chip, sometimes has a hard time confirming if the designs it makes are on the U.S. sanctions list. Like it experienced with Huawei, TSMC couldn't determine that a third-party shell company was ordering Ascend accelerator IP on behalf of Huawei —which sits on the U.S. blacklist—even with advanced detection tools. Officials are reportedly considering transitional credits and carve-outs for companies that commit to building U.S. fabs, which would allow them to import while new plants come online. Even with those credits, a question arises about how to compare a million small mobile processors against a million high-performance data center accelerators.Enforcing tariffs would require tight coordination among chip designers, contract manufacturers, electronics assemblers, and customs authorities. Companies that send silicon overseas for assembly and then re-import devices would have to trace the origin of every integrated circuit inside complex products, a task that would add compliance costs and could slow procurement, especially for higher-end parts like AI accelerators. Smaller suppliers and niche component makers could be hit hardest if the rules focus only on raw volume rather than product value or technical capability. On the other hand, firms already expanding U.S. manufacturing would stand to gain, as customers look to avoid increasing duties.The ultimate game plan for this tariff proposal would be to create manufacturing jobs at home and to reduce what officials view as a national security risk from concentrated overseas production. However, it could also risk breaking global supply chains: buyers might stockpile, redesign products to use fewer foreign parts, or shift sourcing strategies, any of which could spark short-term volatility for processors, memory, and specialty chips and invite legal and diplomatic challenges from trading partners. For now, the idea remains under discussion, and no final decision has been announced.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341409/u-s-could-impose-100-semiconductor-tariff-if-chips-are-not-made-in-america",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Intel’s Big Comeback Plan Might Rely on Apple",
      "content": "Intel is working hard on a comeback after years of struggle in the semiconductor market. Once a leader, it fell behind rivals like NVIDIA and lost Apple as a customer in 2020. Now, Intel is trying to rebuild its position and is seeking investment from the Cupertino-based tech giant to stay in the race.\n\nIntel wants Apple’s investment to push its comeback\n\nAccording to a report published by Bloomberg, Intel is in early talks with Apple about a possible investment plan. The discussions are still in the initial phase and may not necessarily lead to a final deal. However, this move surely reveals Intel’s commitment to making a comeback in the market.\n\nAs a part of its comeback plan, Intel has attracted major funding from other companies across the globe. NVIDIA, one of its rivals, invested around $55 billion for a stake in the company. Softbank has also proposed $2 billion investment, and the US government has also taken a 10% equity position in the firm. While these investments will surely boost the company’s financials, it now needs customers for its foundry business.\n\nThe Intel-Apple deal is special because, if Apple decides to invest in Intel, it would become the company’s biggest business partner. Apple currently relies on TSMC for the manufacture of its M and A-series chipsets. This deal might very well push it to diversify its chipset supply chain by adding another American manufacturer.\n\nIntel-Apple deal is more than an investment\n\nAs said earlier, the company is already good in terms of finances. But it needs customers to push its comeback. Apple’s support might very well bring the much-needed demand for its most advanced chip-making process, called 14A. Without big customers like Apple, Intel may struggle to make a comeback or become a leader in the semiconductor business again.\n\nHowever, the road ahead is tough for Intel. It lost ground when Apple shifted to its own silicon in 2020, and catching up with TSMC will take time and money. Industry analysts suggests that Intel should try to regain the confidence of its potential customers before pushing for other financial deals.",
      "source": "Android Headlines",
      "url": "https://www.androidheadlines.com/2025/09/intels-big-comeback-plan-might-rely-on-apple.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Trump may impose per-chip tariff on foreign electronics",
      "content": "In an exclusive report published today, Reuters says that President Trump is considering “imposing tariffs on foreign electronic devices based on the number of chips in each one.” Here are the details.\n\nSince the late-April round of “reciprocal tariffs,” Trump has threatened to impose several measures specifically aimed at curbing US companies’ reliance on foreign chip manufacturers.\n\nDuring the early days of the tariff war with China, he excluded “smartphones, laptop computers, hard drives and computer processors and memory chips” from the levies, a measure Commerce Secretary Howard Lutnick said was temporary.\n\nHe claimed that a “special focus type of tariff” would soon be imposed on these products, but this never materialized. As time passed, several US officials, including Trump himself, floated different measures and tariff percentages.\n\nJust last month, after Apple CEO Tim Cook handed Trump a golden tribute, the President said:\n\n“We’ll be putting a tariff on of approximately 100% on chips and semiconductors. But if you’re building in the United States of America, there’s no charge even though you’re building and you’re not producing yet in terms of the big numbers of jobs and all of the things that you’re building. If you’re building, there will be no charge. So I just want everyone to know that and I didn’t even tell you that inside. We discussed the concept, but I didn’t. So it’s a big factor. So 100% tariff on all chips and semiconductors coming into the United States. But if you’ve made a commitment to build or if you’re in the process of building, as many are, there is no tariff.”\n\nIn the following weeks, the US would go on to take a 10% stake in Intel, but the 100% tariff also never materialized.\n\nFast-forward to this morning, the Wall Street Journal reported that the Trump administration was considering requiring domestic chip manufacturing to match imports “and would impose tariffs on those companies that don’t step up production.”\n\nReuters, meanwhile, just reported the tariff plan based on the number of chips inside foreign-made electronics:\n\nAccording to the plan, which has not previously been reported and could change, the Commerce Department would impose a tariff equal to a percentage of the estimated value of the product’s chip content.\n\nThis new plan, as economist Michael Strain told Reuters, might increase prices even for domestically produced items, “thanks to new tariffs on key inputs needed to make those goods.”\n\n9to5Mac’s take\n\nAs much as Trump has promised to keep Apple and other companies in the clear as long as they keep signaling domestic infrastructure investment, it is a tall order to blindly assume the rules won’t change.\n\nWhatever tariff plan the administration finally settles on, will likely add or change the rules that have been floated in previous unconfirmed plans.\n\nGiven Tim Cook’s recent displays of obedience and submission, it is likely that Apple would get a favorable deal, if not an outright exemption. But as long as the government keeps floating different strategies, and its agenda keeps changing (e.g., Intel stake), there will be very few guarantees Apple will actually get its promised free pass.\n\nAccessory deals on Amazon",
      "source": "9to5Mac",
      "url": "https://9to5mac.com/2025/09/26/trump-may-impose-per-chip-tariff-on-foreign-electronics/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Asus introduces ExpertCenter P500SV desktop for SMBs in Malaysia",
      "content": "Asus has launched the ExpertCenter P500SV in Malaysia, a business-focused desktop designed to meet the needs of small and medium-sized businesses (SMBs) seeking reliable performance and long-term value.\n\nPrice and availability in Malaysia\n\nThe ExpertCenter P500SV is available in two configurations:\n\nIntel Core i5-13420H, 16GB DDR5 RAM, 512GB SSD – RM3,449\n\n– Intel Core i7-13620H, 16GB DDR5 RAM, 512GB SSD – RM3,949\n\nBoth models come with Microsoft Windows 11 Pro pre-installed.\n\nWhat do you get for the money?\n\nThe Asus ExpertCenter P500SV is powered by 13th Gen Intel Core processors, with options for the i5-13420H and i7-13620H, paired with up to 64GB DDR5 memory and dual storage support. While these processors are not Intel’s latest generation (launched in early 2023), they remain reliable choices for everyday business workloads, balancing performance and efficiency at this price point.\n\nFor businesses requiring extra graphics power, an optional Nvidia RTX A400 GPU is available.\n\nThermal design is a major highlight, with copper heat pipes and rear-mounted fans that efficiently expel heat while maintaining whisper-quiet acoustics. Even under heavy workloads, noise levels stay below 31 dB, quieter than rustling leaves, making it suitable for offices or shared spaces.\n\nConnectivity is comprehensive, offering front-facing USB-A ports, a USB-C port, an optional SD card reader, and a full range of rear I/O, including HDMI, DisplayPort, and 1Gb LAN. Wireless connectivity is supported with Wi-Fi 6 and Bluetooth 5.4.\n\nSecurity and manageability are built in, featuring ASUS ExpertGuardian enterprise security, hardware TPM, and one year of McAfee Premium security. To support scalability, the system allows upgrades with dual DIMM slots, dual storage, and Asus-certified parts.\n\nThe P500SV comes with a 3-year on-site Next Business Day (NBD) service warranty across Malaysia, with optional upgrades of up to five years. This is paired with Asus ExpertCare, offering additional support options for businesses.\n\nThe ExpertCenter P500SV is part of Asus’s Expert series, which focuses on providing business-grade solutions that balance performance, efficiency, and long-term serviceability for professional environments.",
      "source": "SoyaCincau.com",
      "url": "https://soyacincau.com/2025/09/26/asus-introduces-expertcenter-p500sv-desktop-for-smbs-in-malaysia/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Trump All But Admits Direct Involvement in Comey Charges",
      "content": "The president didn’t hesitate to celebrate the charges. Rather than await the results of a fair and honest trial, Trump appeared to set the tone for the prosecution of the ex-federal official, openly slandering Comey as a “dirty cop” and a “destroyer of lives” who needed to pay a “big price.”\n\n“Whether you like Corrupt James Comey or not, and I can’t imagine too many people liking him, HE LIED!” Trump posted on Truth Social Friday morning. “It is not a complex lie, it’s a very simple, but IMPORTANT one. There is no way he can explain his way out of it.”\n\n“He is a Dirty Cop, and always has been, but he was just assigned a Crooked Joe Biden appointed Judge, so he’s off to a very good start,” Trump continued. “Nevertheless, words are words, and he wasn’t hedging or in dispute. He was very positive, there was no doubt in his mind about what he said, or meant by saying it. He left himself ZERO margin of error on a big and important answer to a question. He just got unexpectedly caught.”",
      "source": "The New Republic",
      "url": "https://newrepublic.com/post/200993/trump-admits-direct-involvement-comey-charges",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "TSMC in Intel’s investment talks, as Andrew Ng flags Taiwan risk",
      "content": "Save my User ID and Password\n\nSome subscribers prefer to save their log-in information so they do not have to enter their User ID and Password each time they visit the site. To activate this function, check the 'Save my User ID and Password' box in the log-in section. This will save the password on the computer you're using to access the site.\n\nNote: If you choose to use the log-out feature, you will lose your saved information. This means you will be required to log-in the next time you visit our site.",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250926VL203/intel-apple-tsmc-government-nvidia.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Jim Cramer Explains Morgan Stanley’s Coverage Of ASML Holding N.V. (ASML)",
      "content": "We recently published 14 Stocks Jim Cramer Discussed Including His 2 Top Quantum Computing Stocks. ASML Holding N.V. (NASDAQ:ASML) is one of the stocks Jim Cramer recently discussed.\n\nASML Holding N.V. (NASDAQ:ASML) is a leading player in the global chip fabrication industry since it is the only firm capable of manufacturing advanced High-NA chip manufacturing machines. Cramer does not discuss the stock often, but during the times that he has discussed it, the CNBC TV host linked the firm’s performance to the broader semiconductor industry. ASML Holding N.V. (NASDAQ:ASML)’s shares were upgraded by Morgan Stanley to Overweight from Equal-Weight earlier this week, with a price target bump to €950. The upgrade followed Bank of America’s decision to raise the share price target to €941 from €742 on September 19th after NVIDIA’s decision to invest $5 billion in Intel. Cramer discussed the upgrade:\n\nJim Cramer Explains Morgan Stanley's Coverage Of ASML Holding N.V. (ASML)\n\nClose-up of Silicon Die are being Extracted from Semiconductor Wafer and Attached to Substrate by Pick and Place Machine. Computer Chip Manufacturing at Fab. Semiconductor Packaging Process.\n\n“[Commenting on Morgan Stanley upgrading ASML and AMAT] Well I don’t know, Morgan was, they were too negative on it. But the reason why they were was because we didn’t feel that Micron had gained. We didn’t think that NAND, we were worried about Western Dig, worried about the SanDisk, worried about anything involving Seagate. And they’re all back. I mean they’re all at their highs. They’re now starting to sell at a premium multiple for the first time, maybe in 30 years.”\n\nWhile we acknowledge the potential of ASML as an investment, our conviction lies in the belief that some AI stocks hold greater promise for delivering higher returns and have limited downside risk. If you are looking for an extremely cheap AI stock that is also a major beneficiary of Trump tariffs and onshoring, see our free report on the best short-term AI stock.\n\nREAD NEXT: 30 Stocks That Should Double in 3 Years and 11 Hidden AI Stocks to Buy Right Now.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/jim-cramer-explains-morgan-stanley-125431284.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Planning Is A Practice, Not A Product: Why Practices Make It Work",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/melissadaimler/2025/09/26/planning-is-a-practice-not-a-product-why-practices-make-it-work/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Intel Stock Is Soaring. This Chip Giant Could Be the Latest to Invest",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/d13344bcfe79c601",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Intel Shares Rise on U.S. Plan to Cut Chip Import Reliance",
      "content": "This article first appeared on GuruFocus.\n\nIntel (INTC, Financials) shares climbed in premarket U.S. trading Friday after reports that the Trump administration is considering new measures to reduce reliance on imported semiconductors by requiring chipmakers to expand domestic production.\n\nBefore the opening bell, Intel rose 2.9%, while GlobalFoundries (GFS) gained more than 5%. The Wall Street Journal reported that the White House is reviewing a policy that would mandate companies produce in the U.S. the same number of chips they import. Those that fail to meet the threshold could face tariffs.\n\nThe proposal follows last month's move to impose a 100% tariff on all chip imports, with exemptions for companies maintaining U.S. manufacturing operations. Commerce Secretary Howard Lutnick has held discussions with industry executives about the plan, according to the report.\n\nShares of European chipmakers fell after the report. ASML fell 0.3%, ASM International fell 1.4%, and Infineon fell 2.7%. Taiwan Semiconductor Manufacturing sank 1.5%, Samsung Electronics down 3.3%, and SK Hynix plummeted 5.6% in Asia.\n\nThe plan reflects attempts to bolster domestic semiconductor supply chains, however analysts expressed questions around practicality given greater labor and infrastructure costs in the U.S. As chipmakers think about where to put their money, they will be quite interested in the result of the policy debate.\n\nIn October, third-quarter earnings reports will be the next thing that moves the sector.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/intel-shares-rise-u-plan-155259291.html",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "'Are we going to bet the company's road map on chiplets?' AMD's CEO Lisa Su reminds us how fortunate it was that its executives all said yes",
      "content": "Possible Ep 94 | AMD’s Comeback and Vision for Chipmaking w/ CEO Lisa Su - YouTube Watch On\n\nGiven how much AMD dominates the world of CPUs and gaming in general, it might seem strange to picture such a company on the verge of bankruptcy, being billions of dollars in debt and with few good products on offer. That was the state of AMD over 20 years ago, but thanks to some inspired engineering decisions, those days are now in the distant past. And in a recent interview, CEO Lisa Su tells us that one such choice was betting almost everything on chiplets.\n\nThe interview took place on Reid Hoffman's YouTube channel, a venture capitalist and co-founder of LinkedIn, amongst many other strings to his bow. The two hosts chatted with AMD's CEO, Dr Lisa Su, about her past and what led her to become a chip engineer, as well as all things AI, of course.\n\nFor me, the most interesting part was when Su talked about AMD's decision-making process, which ultimately led to the likes of the Ryzen 7 9800X3D being the most sought-after CPU by PC gamers.\n\n\"We were in a place where the world in semiconductors, for 30 years, really was driven by Moore's law—the idea that every two years or every 18 months you could double the productivity—and so it was all about scaling, scaling, scaling, scaling. But scaling was changing and we saw that change, and yes, we made a few bets.\"\n\nWhen it comes to designing any kind of HPC (high performance computing) processor, any bet that you make takes time to bear fruit, if at all. I'm not talking about a period of a few months, or even a year or two. The timescales involved are around a decade or so, and while that might seem like a ludicrously long time, in the world of processors, that only covers a handful of product cycles.\n\nIntegrated Circuits & Moore's Law: Crash Course Computer Science #17 - YouTube Watch On\n\nIn other words, such bets carry considerable risk. But one in particular turned out to be more than worth it.\n\nSu continued: \"We made the bet that scaling would slow down, and we had to innovate in different ways, and perhaps one of the largest innovations is we were the first to really put high performance computing in sort of breaking it up into what we would call chiplets.\"\n\nThe biggest gaming news, reviews and hardware deals Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nIt's hard to overstate just how important this move was for AMD and perhaps the CPU industry as a whole. Its Zen architecture, launched eight years ago in 2017, was considerably better than earlier designs but still relied on monolithic fabrication (i.e. everything in a single die), which can be costly to scale across every sector.\n\nSplitting its CPUs up into multiple dies, aka chiplets, meant that AMD only needed to make three discrete chips, but it could then use them to make processors for laptops, desktop PCs, workstations, and full-blown servers. Intel, on the other hand, was making completely different chips for each market.\n\nImage 1 of 3 (Image credit: Fritzchens Fritz) (Image credit: AMD) (Image credit: AMD)\n\nIt might seem like such an obvious move these days, but given how earlier mistakes backfired drastically for AMD, you'd be forgiven for thinking that its leaders were cautious about it all. Not so, it would seem.\n\n\"You know those meetings, back in the day, when I would sit with our technical fellows and we would make that big decision of 'hey, are we going to bet the company's roadmap on chiplets?' and we said yes,\" said Su, looking pleased as punch. \"We had a lot of learning. I mean, I can say there were products that worked really, really well, and there were products that worked not so well, but we learned a ton from the process of that.\"\n\nAnother interesting topic that's discussed in the interview is how AMD has focused almost entirely on HPC. For example, despite the breadth of its processor portfolio, it doesn't make chips for phones. Dr Su explains why this is:\n\n\"Our driving force at the time was to decide what we could be best at. I really believed—my CTO Mark Papermaster has been my partner on this journey—we believed that we could be bet the best in high performance computing, and at the time, high performance computing wasn't as exciting as it is today because AI wasn't as big as it is today and the cloud was you know kind of on a different path.\"\n\n(Image credit: AMD)\n\nMore specifically, she remarks: \"There was a lot of conversation on 'hey Lisa, you know AMD should be making smartphone chips' and then when you look at where things have evolved, you actually realise that companies have sort of fundamental DNA in terms of what they're good at. We are just really good at building big computers, that's what we think about every single day.\"\n\nIt's certainly all worked out very well for AMD. It makes the best CPUs, it dominates the console sector, it has a significant foot in the FPGA market, and as things currently stand, it boasts share prices more than 4.5 times higher than Intel. Despite its vast AI revenue stream, Nvidia's shares are just 10% higher than AMD's.\n\nWith everything Su says in the interview, it's clear what the next decade of AMD will look like: more chiplets, more HPC, more being the best at something. A stark contrast to 20 years ago.",
      "source": "PC Gamer",
      "url": "https://www.pcgamer.com/hardware/processors/are-we-going-to-bet-the-companys-road-map-on-chiplets-amds-ceo-lisa-su-reminds-us-how-fortunate-it-was-that-its-executives-all-said-yes/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Intel splashes more cash on ASML’s magic machines",
      "content": "The technical storage or access that is used exclusively for statistical purposes.\n\nThe technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.",
      "source": "Madshrimps.be",
      "url": "https://www.madshrimps.be/news/intel-splashes-more-cash-on-asmls-magic-machines/",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "With Comey, Brennan, Soros, Trump steps up his retribution campaign",
      "content": "Critics have decried what they say is an unlawful campaign of retribution.\n\nPresident Donald Trump with granddaughter Kai Madison Trump speaks to the media as he leaves the White House to board Marine One, in Washington, September 26, 2025.\n\nPresident Donald Trump with granddaughter Kai Madison Trump speaks to the media as he leaves the White House to board Marine One, in Washington, September 26, 2025.\n\nPresident Donald Trump with granddaughter Kai Madison Trump speaks to the media as he leaves the White House to board Marine One, in Washington, September 26, 2025.\n\nPresident Donald Trump with granddaughter Kai Madison Trump speaks to the media as he leaves the White House to board Marine One, in Washington, September 26, 2025.\n\nPresident Donald Trump, who took office in January with a pledge to seek retribution against his political foes, made clearer than ever his eagerness to use the weight of the Justice Department against his perceived enemies this week.\n\nAsked by reporters Friday who was next on his list a day after the DOJ brought a two-count indictment against former FBI Director James Comey, Trump said, \"It’s not a list -- but I think there will be others.\"\n\nComey, who Trump fired from his post in 2017, had been a target of Trump since he oversaw the FBI’s investigation into alleged Russian interference in the 2016 election.\n\n\"JUSTICE IN AMERICA! One of the worst human beings this Country has ever been exposed to is James Comey,\" Trump wrote on social media following Thursday’s indictment. \"He has been so bad for our Country, for so long, and is now at the beginning of being held responsible for his crimes against our Nation.\"\n\nThe former FBI chief has been charged with making a false statement to Congress and obstruction of an investigative proceeding before Congress, related to his 2020 congressional testimony regarding the FBI's Russia probe.\n\nComey, who said in a statement that he was innocent of the charges, said in an Instagram video, \"My family and I have known for years that there are costs for standing up to Donald Trump, but we couldn't imagine ourselves living any other way. We will not live on our knees and you shouldn't either.\"\n\nThe charges were brought by the newly appointed U.S. attorney for the Eastern District of Virginia, former White House aide Lindsey Halligan, who took over the role after Trump ousted U.S. attorney Erik Siebert after sources say Siebert expressed doubts internally about bringing a case against Comey.\n\nPresident Donald Trump with granddaughter Kai Madison Trump speaks to the media as he leaves the White House to board Marine One, in Washington, September 26, 2025. Will Oliver/EPA/Shutterstock\n\n\"What they did was so terrible and so corrupt,\" Trump told Fox News Digital on Thursday, referring to those involved in the Russia probe. \"Comey placed a cloud over the entire nation.\"\n\nTrump, in the same interview, hinted at potentially charging former CIA Director John Brennan in relation to the Russia probe.\n\n\"We’ll have to see what happens. It is up to the Justice Department, but I can tell you, it is a group of people that was very disappointing,\" Trump said. \"This makes Watergate look like peanuts.\"\n\nComey's indictment came just days after top federal prosecutors at U.S. attorney's offices around the country received a directive to prepare to launch investigations into the Open Society Foundations, a group funded by the billionaire Democratic donor George Soros, on potential charges ranging from support of terrorism to racketeering, sources told ABC News.\n\n\"This DOJ, along with our hard-working and dedicated U.S. Attorneys, will always prioritize public safety and investigate organizations that conspire to commit acts of violence or other federal violations of law,\" a DOJ spokesperson said.\n\nA spokesperson for the Open Society Foundations called the accusations \"politically motivated attacks.\"\n\nFBI Director Kash Patel disputed accusations that the DOJ's probes were motivated by politics.\n\n\"Career FBI agents, intel analysts, and staff led the investigation into Comey and others,\" he posted online Friday. \"They called the balls and strikes and will continue to do so. The wildly false accusations attacking this FBI for the politicization of law enforcement comes from the same bankrupt media that sold the world on Russia Gate -- it’s hypocrisy on steroids.\"\n\nDemocrats like Sen. Peter Welch weren't buying it.\n\n\"President Trump and his Justice Department's indictment of James Comey is a new low for our democracy. The reason for the indictment is clear: Comey is Trump's political adversary,\" Welch wrote on X.\n\nAsked by reporters about the indictment on Friday, Trump said, \"They weaponized the Justice Department like nobody in history. What they've done is terrible. And so I hope -- frankly, I hope there are others, because you can’t let this happen to a country.\"\n\n\"It's about justice, not revenge,\" Trump said. \"It’s about justice.\"\n\nABC News' Rachel Scott contributed to this report.",
      "source": "ABC News",
      "url": "https://abcnews.go.com/US/comey-brennan-soros-trump-steps-retribution-campaign/story?id=125972721",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Taiwan rescuers battle thick mud to look for missing from Super Typhoon Ragasa",
      "content": "AMD teams with OpenAI in a multibillion-dollar chip supply deal fueling the AI boom, with OpenAI poised to acquire up to 10% of AMD's stock as strategic partnership deepens.\n\nMarket Summary Equities showed resilience as U.S. stock futures edged up despite the ongoing government shutdown. Japan stocks rallied near record highs after electing Sanae Takaichi as ruling party leader. Oil prices climbed following a modest OPEC+ output hike, while gold and Bitcoin soared on safe-haven demand amid geopolitical tensions.\n\nAMD Strikes Multibillion-Dollar AI Chip Deal With OpenAI... Future Stake Looms OpenAI and AMD Seal AI Chip Supply Pact - OpenAI Eyes 10% Stake OpenAI and AMD cement a landmark partnership fueling the AI chip boom, with OpenAI poised to take a 10% stake as AMD supplies thousands of GPUs for AI infrastructure over multiple years.\n\nFigure of the Day 10% - OpenAI’s potential stake in AMD as part of chip supply deal fueling AI infrastructure expansion.\n\nSanae Takaichi to Become Japan’s First Female PM Amid Political Upheaval French PM Resigns After Weeks - Macron’s Government in Further Turmoil Political shocks hit Japan and France as Japan elects its first female PM amid turmoil, stirring markets, while France faces deeper crisis with several rapid prime minister resignations.\n\nBullish Tesla Breaks Q3 Delivery Records, Reignites Growth Optimism Tesla closed Q3 with record vehicle deliveries, boosting confidence in its core electric vehicle business despite looming challenges. More on thestreet.com\n\nBearish Aston Martin Plummets as Tariff Woes Trigger Fresh Profit Warning Luxury automaker Aston Martin slashed profit guidance amid ongoing tariff impacts and supply chain pressures, sending shares tumbling 10%. More on cnbc.com\n\nOPEC+ Approves Minor Oil Production Increase, Market Reacts EU Set to Boost US LNG Imports This Winter, Raising Price Volatility European energy and natural resources markets are in flux as OPEC+ agrees to a modest oil output hike amid looming supply concerns, and EU gas imports from the US surge, fuelling price volatility.\n\nRegulatory Impact European Securities and Markets Authority to centralize stock exchange and crypto regulation, enhancing oversight across the EU capital markets.\n\nPrivate Capital Firms Target €17 Billion in European Data Center Deals European private equity eyes AI boom with major €17 billion data center sales deals underway, leveraging growing demand for cloud and AI infrastructure.\n\nQuote Streamlining that process and aligning financial incentives seems good to me.\n\n— OpenAI CEO Sam Altman on AMD partnership\n\nEli Lilly Commits $1 Billion+ to Expand Indian Manufacturing Capacity Major pharmaceutical expansion as Eli Lilly pledges over $1 billion investment to boost manufacturing capacity in India, underscoring the company’s global growth strategy.\n\nFirefly Aerospace Buys SciTec for $855 Million - Defense Push Intensifies Firefly Aerospace expands defense ambitions with a $855 million acquisition of SciTec, positioning itself deeper into the AI-powered national security sector.\n\nMonzo Considers Fresh US Banking License Bid Amid Market Shakeup London’s Stock Market Revival Hinges on Dual Listing Reforms Rapid niche banking consolidation and IPO activity with new stock exchange reforms and major UK Fintechs targeting US licenses indicate evolving global finance landscape.\n\nUkraine Sets $35 Billion Arms Production Ambition for 2026 Zelensky: Ukraine to Mass-Produce Drones and Missiles Amid War Ukraine escalates military preparations with plans to produce $35 billion worth of drones and missiles in 2026, signaling a ramp-up in the ongoing conflict dynamics.\n\nIsrael and Hamas Start Mediated Gaza Ceasefire Talks in Egypt Trump Presses Israel-Hamas for Swift Agreement Amid War Risks Geopolitics shape markets as Biden urges Israel and Hamas for quick Gaza ceasefire talks amid mounting threats of escalation and humanitarian concerns.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/264fdb4d8087cc5e",
      "timestamp": "2025-09-26"
    },
    {
      "headline": "Stinky is preparing for a special military operation in Venezuela, you say? Will it last three days? [Asinine]",
      "content": "If you can read this, either the style sheet didn't load or you have an older browser that doesn't support style sheets. Try clearing your browser cache and refreshing the page.",
      "source": "Fark.com",
      "url": "https://www.fark.com/comments/13826196/Stinky-is-preparing-for-a-special-military-operation-in-Venezuela-you-say-Will-it-last-three-days",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "thinkpad e14 gen 7 intel acpi ec bios error",
      "content": "I recently purchased a Lenovo Thinkpad E14 gen 7 Intel (255H) model 21SX005CMX preinstalled with Windows on it. I did a firmware update for the bios version to the latest version included on the website at the moment (BIOS R30ET35W(1.09)). After that I removed the windows installation and replaced it with Ubuntu 24.04.3 from a USB-stick. Installation went fine until browsing and doing configuration after a few hours the computer freezes. I troubleshooted the problem and located that the acpi ec throws an error on boot in the journalctl logs. Then I realised the fans are not working.\n\nI've tried to change the acpi_osi kernel parameter to Windows 2022, which didn't help. Any advice I could look into? Fans work fine in bios setup, so no problem with the fans themselves, just the acpi embedded controller. I'll put in the logs below with the relevant parts I've found:",
      "source": "Askubuntu.com",
      "url": "https://askubuntu.com/questions/1556634/thinkpad-e14-gen-7-intel-acpi-ec-bios-error",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Intel Stock Rockets: Here’s What Top Analyst Ruben Roy Says Comes Next",
      "content": "Narratives on Wall Street can change in the blink of an eye, and boy, Intel (NASDAQ:INTC) reflects such a shift. Once considered a big AI loser amidst a host of ongoing issues, INTC shares have jumped over 40% since news broke last week that Nvidia and Intel had formed a major…\n\nThis story appeared on tipranks.com , 2025-09-27 23:09:17.584000.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/2be97b2d6d4a94a5",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Show HN: An open source Launchpad for macOS 26",
      "content": "LaunchNext\n\nLanguages: English | 中文 | 日本語 | 한국어 | Français | Español | Deutsch | Русский | हिन्दी | Tiếng Việt | Italiano | Čeština\n\n📥 Download\n\nDownload here - Get the latest release\n\n⭐ Consider starring LaunchNext and especially LaunchNow!\n\nMacOS Tahoe removed launchpad,and it's so hard to use, it's doesn't use your Bio GPU, please apple, at least give people an option to switch back. Before that, here is LaunchNext\n\nBuilt upon LaunchNow by ggkevinnnn - huge thanks to the original project! I hope this enhanced version can be merged back to the original repository\n\nLaunchNow has chosen the GPL 3 license. LaunchNext follows the same licensing terms.\n\n⚠️ If macOS blocks the app, run this in Terminal:\n\nsudo xattr -r -d com.apple.quarantine /Applications/LaunchNext.app\n\nWhy: I can't afford Apple's developer certificate ($99/year), so macOS blocks unsigned apps. This command removes the quarantine flag to let it run. Only use this command on apps you trust.\n\nWhat LaunchNext Delivers\n\n✅ One-click import from old system Launchpad - directly reads your native Launchpad SQLite database ( /private$(getconf DARWIN_USER_DIR)com.apple.dock.launchpad/db/db ) to perfectly recreate your existing folders, app positions, and layout\n\n- directly reads your native Launchpad SQLite database ( ) to perfectly recreate your existing folders, app positions, and layout ✅ Classic Launchpad experience - works exactly like the beloved original interface\n\n- works exactly like the beloved original interface ✅ Multi-language support - full internationalization with English, Chinese, Japanese, French, Spanish, German, and Russian\n\n- full internationalization with English, Chinese, Japanese, French, Spanish, German, and Russian ✅ Hide icon labels - clean, minimalist view when you don't need app names\n\n- clean, minimalist view when you don't need app names ✅ Custom icon sizes - adjust icon dimensions to fit your preferences\n\n- adjust icon dimensions to fit your preferences ✅ Smart folder management - create and organize folders just like before\n\n- create and organize folders just like before ✅ Instant search and keyboard navigation - find apps quickly\n\nWhat We Lost in macOS Tahoe\n\n❌ No custom app organization\n\n❌ No user-created folders\n\n❌ No drag-and-drop customization\n\n❌ No visual app management\n\n❌ Forced categorical grouping\n\nData Storage\n\nApplication data is safely stored in:\n\n~/Library/Application Support/LaunchNext/Data.store\n\nNative Launchpad Integration\n\nReads directly from the system Launchpad database:\n\n/private $( getconf DARWIN_USER_DIR ) com.apple.dock.launchpad/db/db\n\nInstallation\n\nRequirements\n\nmacOS 26 (Tahoe) or later\n\nApple Silicon or Intel processor\n\nXcode 26 (for building from source)\n\nBuild from Source\n\nClone the repository git clone https://github.com/yourusername/LaunchNext.git cd LaunchNext Open in Xcode open LaunchNext.xcodeproj Build and run Select your target device\n\nPress ⌘+R to build and run\n\nto build and run Or ⌘+B to build only\n\nCommand Line Build\n\nRegular Build:\n\nxcodebuild -project LaunchNext.xcodeproj -scheme LaunchNext -configuration Release\n\nUniversal Binary Build (Intel + Apple Silicon):\n\nxcodebuild -project LaunchNext.xcodeproj -scheme LaunchNext -configuration Release ARCHS= \" arm64 x86_64 \" ONLY_ACTIVE_ARCH=NO clean build\n\nUsage\n\nGetting Started\n\nFirst Launch: LaunchNext automatically scans all installed applications Select: Click to select apps, double-click to launch Search: Type to instantly filter applications Organize: Drag apps to create folders and custom layouts\n\nImport Your Launchpad\n\nOpen Settings (gear icon) Click \"Import Launchpad\" Your existing layout and folders are automatically imported\n\nDisplay Modes\n\nWindowed : Floating window with rounded corners\n\n: Floating window with rounded corners Fullscreen : Full-screen mode for maximum visibility\n\n: Full-screen mode for maximum visibility Switch modes in Settings\n\nAdvanced Features\n\nSmart Background Interaction\n\nIntelligent click detection prevents accidental dismissal\n\nContext-aware gesture handling\n\nSearch field protection\n\nPerformance Optimization\n\nIcon Caching : Intelligent image caching for smooth scrolling\n\n: Intelligent image caching for smooth scrolling Lazy Loading : Efficient memory usage\n\n: Efficient memory usage Background Scanning: Non-blocking app discovery\n\nMulti-Display Support\n\nAutomatic screen detection\n\nPer-display positioning\n\nSeamless multi-monitor workflows\n\nTroubleshooting\n\nCommon Issues\n\nQ: App won't start? A: Ensure macOS 26.0+ and check system permissions.\n\nContributing\n\nWe welcome contributions! Please:\n\nFork the repository Create a feature branch ( git checkout -b feature/amazing-feature ) Commit changes ( git commit -m 'Add amazing feature' ) Push to branch ( git push origin feature/amazing-feature ) Open a Pull Request\n\nDevelopment Guidelines\n\nFollow Swift style conventions\n\nAdd meaningful comments for complex logic\n\nTest on multiple macOS versions\n\nMaintain backward compatibility\n\nThe Future of App Management\n\nAs Apple moves away from customizable interfaces, LaunchNext represents the community's commitment to user control and personalization. I hope apple cound bring launchpad back.\n\nLaunchNext isn't just a Launchpad replacement—it's a statement that user choice matters.\n\nLaunchNext - Reclaim Your App Launcher 🚀\n\nBuilt for macOS users who refuse to compromise on customization.\n\nDevelopment Tools",
      "source": "Github.com",
      "url": "https://github.com/RoversX/LaunchNext",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Bitsum ParkControl Pro 5.5.0.8",
      "content": "Description: ParkControl is Pro Windows app to adjust CPU core parking and heterogenous processor scheduling settings.\n\nPro Benefits\n\nBitsum Dynamic Boost\n\nAutomatically switch power plans when your PC enters and leaves the idle state\n\nPower Plan change Notifications\n\nNotifications of when and what process changed your active power plan (image)\n\nSupport Bitsum’s Independent Innovation\n\nYour support enables us to create new tools, and maintain our existing ones!\n\nIntroduction to CPU Core Parking\n\nCPU Parking is a low-power sleep state (C6) supported by most modern processors and operating systems. It dynamically disables CPU cores in an effort to conserve power when idle. Unfortunately, this power saving comes at a price: Latency when CPUs need unparked to execute code.\n\nInitially, core parking was controlled entirely by the operating system. The aggressive core parking of Windows led to a great deal of inefficiency during bursting CPU loads. Intel moved core parking control onto the chip in the Skylake generation, and AMD followed, but still the parameters of the Windows power plans are set to aggressively park CPU cores. Even the default ‘High Performance’ power plan is not immune. The new ‘Ultra Performance’ power plan copies what Bitsum did with our own ‘Bitsum Highest Performance’ power plan and finally disables core parking entirely.\n\nParkControl (and Process Lasso) not only let one more easily configure CPU core parking and frequency scaling, but also allow for dynamic entrance into a higher performance power plan. For instance, with Process Lasso, you can automatically enter ‘Bitsum Highest Performance’ will you start a game, then go back to ‘Balanced’ when you exit.\n\nParkControl has Dynamic Boost to allow you to set active and idle power plans. Process Lasso has a similar feature with its IdleSaver.\n\nEfficacy of Disabling Core Parking\n\nEmpirical evidence shows that disabling CPU core parking can make a tangible improvement in system performance. There are many factors that will determine precisely how effective it will be for a given situation. However, generally, Windows is too aggressive in its core parking, resulting in high latency during bursting CPU loads, stemming from the overhead of having to unpark CPU cores. Since bursting CPU loads are the most common type for many workloads, core parking can be a substantial drag on system performance and responsiveness.\n\nUsing ParkControl\n\nParkControl lets you easily set CPU core parking and frequency scaling parameters for both AC (plugged-in) and DC (battery) power states of your device.\n\nBoth CPU core parking and frequency scaling are power saving features of modern CPUs. CPU core parking is when cores are put into a sleep-like state when demand is low. Similarly, CPU frequency scaling allows the CPU base frequency to be lowered, again to conserve energy.\n\nEach power plan has its own settings, and can be selected via the power plan drop-down. When you select a power plan, the user interface will populate with that power plan’s settings. After making changes, click the ‘Apply’ button to save them. Use the ‘Make active’ button to switch the PC to that power plan.\n\nRelease Name: Bitsum ParkControl Pro 5.5.0.8\n\nSize: 3.6 MB\n\nLinks: HOMEPAGE – NFO – Torrent Search\n\nDownload: RAPiDGATOR",
      "source": "Rlsbb.to",
      "url": "https://post.rlsbb.to/bitsum-parkcontrol-pro-5-5-0-8/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Qualcomm Unveils NEW Chips for Phones & Computers! ",
      "content": "Qualcomm Unveils New Chips with Enhanced Security Features for PCs and Phones\n\nQualcomm has recently announced the release of its latest chips designed for both PCs and phones. This exciting launch includes a brand-new PC chip featuring unprecedented security features targeted at business users, a development that analysts are calling a first of its kind.\n\nBased in San Diego, Qualcomm stands as one of the world’s largest vendors of mobile chips, specializing in the technology that connects phones to wireless data networks. For the past couple of years, the company has strategically expanded its reach into the PC market, aiming to compete directly with giants like Apple. The goal is to offer energy-efficient chips for laptops and PCs operating on the Windows operating system.\n\nAccording to reports, Qualcomm’s new laptop chip, the ‘Snapdragon X Elite,’ is slated for release next year. It will come equipped with a groundbreaking new security feature named ‘Guardian,’ explicitly tailored for large business clients purchasing desktops and laptops.\n\nDuring a presentation, Kedar Kondap, senior vice president of gaming and compute at Qualcomm, explained that this innovative security feature will enable business IT departments to securely update or provide tech support to computers, even when they are turned off.\n\nWhile Intel has offered similar functionalities for business computer management for over a decade, Qualcomm plans to differentiate itself by integrating its security capabilities with its 5G and mobile network-connected modem chips. This synergy will allow the computer’s owner to monitor their device from anywhere in the world, provided they have access to a mobile network. This presents major implications for data protection and remote access.\n\n“No one else can offer this kind of feature,” noted Ben Bajarin, CEO of tech advisory firm Creative Strategies. “This could be incredibly useful for a significant portion of the workforce and will likely generate even more interest in Qualcomm within the business sector.” This innovative offering represents a major step forward in computer security and enterprise solutions, solidifying Qualcomm’s position in the competitive technology market and creating exciting business opportunities.",
      "source": "Nep123.com",
      "url": "https://nep123.com/qualcomm-unveils-new-chips-for-phones-computers-%f0%9f%93%b1%f0%9f%92%bb%f0%9f%9a%80/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Trojan",
      "content": null,
      "source": "BleepingComputer",
      "url": "https://www.bleepingcomputer.com/forums/t/810920/trojan/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "From Wall Street to academia, who is in Trump's line of fire?",
      "content": "US President Donald Trump has escalated his criticism and actions against executives, corporations and institutions. His unprecedented actions — from novel export deals to frozen university grants — have upended the status quo between the government, law, academia and corporate America.\n\nOn Friday, Trump called for the firing of Lisa Monaco, Microsoft's global affairs president, calling her a \"menace to US National Security.\"\n\nGoldman's economic research arm had published a note in August that said US consumers had absorbed 22 per cent of tariff costs through June, and their share could rise to 67 per cent if the recent levies follow the same pattern as the earliest ones.\n\n\"David Solomon and Goldman Sachs refuse to give credit where credit is due,\" Trump said in a post on Truth Social, shortly thereafter.\n\nTrump said it was mostly \"companies and governments, many of them foreign, picking up the tabs.\" He also took a dig at Solomon for his former DJ-ing hobby.\n\nINTEL\n\nIn early August, Trump demanded Intel CEO Lip-Bu Tan step down due to China ties. Reuters had reported in April that Tan invested at least $200 million in hundreds of Chinese advanced manufacturing and chip firms, some of which were linked to the Chinese military.\n\n\"The CEO of INTEL is highly CONFLICTED and must resign, immediately. There is no other solution to this problem,\" Trump said in a post on his Truth Social platform.\n\nTan responded to Trump, saying he shared the president's commitment to advancing US national and economic security and that the Intel board was \"fully supportive of the work we are doing to transform our company.\"\n\nAfter a meeting between the two, Trump praised Tan and the US government decided to take a stake in the chipmaker.\n\nMICROSOFT\n\nTrump on Friday said that the tech giant should fire its global affairs president Lisa Monaco, who served in the administrations of past Democratic presidents.\n\n\"She is a menace to US National Security, especially given the major contracts that Microsoft has with the United States Government,\" Trump said on Truth Social. \"It is my opinion that Microsoft should immediately terminate the employment of Lisa Monaco.\"\n\nTrump said Monaco, in her position at Microsoft, would have access to highly sensitive information and her \"having that kind of access is unacceptable, and cannot be allowed to stand.\"\n\nMonaco, who started working at Microsoft in July, was a security aide in former president Barack Obama's administration and served as the deputy attorney general in former president Joe Biden's administration.\n\nTESLA\n\nThe electric automaker's billionaire tech CEO Elon Musk spent hundreds of millions of dollars supporting Trump's re-election, a move investors who bid up Tesla stock expected to benefit Musk's empire.\n\nTrump and Musk, however, fell out in June after Musk criticised Trump's sweeping tax-cut and spending bill because it was projected to increase federal debt.\n\nResponding to that on Truth Social, Trump threatened to cut federal subsidies and contracts to Musk's companies and said the billionaire \"just went CRAZY\" after losing the electric-vehicle mandate in the bill.\n\nADRIAN MARDELL, FORMER CEO, JAGUAR LAND ROVER\n\nTrump criticised Jaguar's rebranding effort in August, calling the campaign \"woke\" and \"stupid,\" and linking it to the departure of the company's CEO.\n\nThe remarks from Trump came as the British carmaker, owned by India's Tata Motors, announced the retirement of CEO Adrian Mardell, who spent more than three decades at the company.\n\nJaguar last year unveiled a new logo and visual identity as part of a brand refresh aimed at repositioning itself as an electric automaker, a move that drew sharp online backlash and criticism from brand loyalists.\n\nAPPLE\n\nTrump has repeatedly targeted Apple and its boss, Tim Cook, for making US-sold iPhones outside the country and has threatened company-specific tariffs.\n\nIn May, Trump recalled, after a meeting in the Qatari capital Doha, that he had confronted Cook about the company's plan to make most of its iPhones sold in the US at factories in India by the end of 2026.\n\nTrump had said in a social media post he told Cook \"long ago\" that \"I expect their iPhones that will be sold in the United States of America will be manufactured and built in the United States, not India, or anyplace else.\"\n\nTrump in early August announced Apple would invest an additional $100 billion in the US, raising its total domestic commitment to $600 billion over the next four years. Cook also gave Trump a US-made souvenir with a 24-karat gold base.\n\nTrump called Amazon's former CEO Jeff Bezos in April to complain about a news report that said the company planned to display prices showing the impact of tariffs on e-commerce retailer Amazon.com.\n\nHowever, Amazon said it had only briefly considered listing import charges for some goods in April following Trump's tariff announcement, but dropped the plan as the White House accused the company of a \"hostile political act.\"\n\nTrump later told reporters that Bezos had solved the problem \"very quickly\" and was \"very nice.\"\n\nTrump in August alleged that BofA CEO Brian Moynihan and JPMorgan chief Jamie Dimon discriminated against him and his supporters. Earlier he had said they did not provide banking services to conservatives.\n\n\"What you're doing is wrong,\" Trump said, in a video address at the World Economic Forum in Davos, Switzerland. Trump did not cite evidence or specifics of any wrongdoing, in a question-and-answer session with corporate leaders and CEOs assembled on stage.\n\nHe also referenced JPMorgan's Dimon. \"You and Jamie and everybody, I hope you're gonna open your bank to conservatives.\"\n\nBoth lenders have denied the allegations of \"debanking\" on multiple occasions.\n\nTrump said in May Walmart and China should \"eat the tariffs\" and not burden American shoppers, after CEO Doug McMillon said the retailer could not absorb all tariff-related costs because of narrow retail margins.\n\n\"Walmart should STOP trying to blame Tariffs as the reason for raising prices throughout the chain. Walmart made BILLIONS OF DOLLARS last year, far more than expected,\" Trump said in a social media post.\n\nWhile Trump did not call out McMillon personally, he publicly criticised Walmart for attributing its price hikes in May to tariffs imposed by his administration.\n\nCRACKER BARREL\n\nThe restaurant chain's brief change in its logo — removing the long-standing image of an overall-clad man known as \"Uncle Herschel\" leaning against a barrel — is the most recent in a series of dustups where an unexpected response has blindsided retail chains.\n\nCracker Barrel in late August said it will stick with its decades-old logo, scrapping plans for a new one following social media backlash, including from President Donald Trump.\n\n\"Congratulations 'Cracker Barrel' on changing your logo back to what it was. All of your fans very much appreciate it,\" Trump said on Truth Social after the company's reversal.\n\nCOMCAST\n\nTrump criticised Comcast and its cable news network MSNBC for its news coverage of his administration. He said to reporters, \"They're changing the name because they're ashamed of it, and they're disassociating it from NBC,\" referring to MSNBC's name change to MS NOW.\n\nIn a post on his social media platform in August, Trump also called Comcast a \"weak and ineffective owner ... headed by ... Brian Roberts.\"\n\nSMITHSONIAN INSTITUTION\n\nThe White House has said it will lead an internal review of some Smithsonian museums and exhibitions ahead of the 250th anniversary of the US Declaration of Independence.\n\nIn an executive order in March, Trump said the institution had come under the influence of a \"divisive, race-centered ideology\" in recent years.\n\nHARVARD UNIVERSITY\n\nTrump targeted the country's oldest and richest university, cancelling about $2.5 billion federal grants, and mounted efforts to cut off research funding to Harvard, as a part of a larger campaign to force change at US universities, which Trump says are gripped by antisemitic and \"radical left\" ideologies.\n\n\"We are going to be taking away Harvard's Tax Exempt Status. It's what they deserve!\" Trump wrote in a post on his social media platform in May.\n\nCOLUMBIA UNIVERSITY\n\nIn March, the Trump administration said it was penalising Columbia University over how it handled last year's protests by cancelling $400 million in federal funding.\n\n\"This is the first arrest of many to come. We know there are more students at Columbia and other Universities across the Country who have engaged in pro-terrorist, anti-Semitic, anti-American activity, and the Trump Administration will not tolerate it,\" Trump said in a social media post.\n\nThe comments came after the arrest of Palestinian graduate student Mahmoud Khalil played a prominent role in the protests.\n\nIn July, the university said it will pay over $200 million to the US government in a settlement with Trump's administration.\n\nLAW FIRMS\n\nTrump targeted law firm Perkins Coie in March with an executive order that suspended security clearances for its employees and restricted their access to federal buildings over its ties to Hillary Clinton and DEI policies.\n\nTrump had said it was \"an absolute honor to sign\" the order. Trump also targeted New York law firm Paul, Weiss, Rifkind, Wharton & Garrison in March with a similar order, which he later withdrew after striking a deal.\n\nLaw firm Covington & Burling faced Trump's presidential memorandum in February, which suspended security clearances for Peter Koski and all Covington employees who assisted former special counsel Jack Smith, who prosecuted Trump.\n\nCovington had said it would continue representing Jack Smith despite these measures.\n\n\"We're going to continue holding the people who were responsible for the weaponization of government — who supported it — accountable,\" Trump had said.\n\nPublished on September 27, 2025",
      "source": "BusinessLine",
      "url": "https://www.thehindubusinessline.com/news/world/from-wall-street-to-academia-who-is-in-trumps-line-of-fire/article70101549.ece",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Trump demands Microsoft fire global affairs head Lisa Monaco | TechCrunch",
      "content": "President Donald Trump declared Friday that Microsoft needs to fire Lisa Monaco, the company’s president of global affairs.\n\nCiting her roles as “a senior National Security aide under Barack Hussein Obama, and a Lawfare and Weaponization obsessed Deputy Attorney General under Crooked Joe Biden and Lisa’s Puppet ‘Boss’ Attorney General Merrick Garland,” Trump posted on Truth Social that Monaco’s current role gives her access to “Highly Sensitive Information,” which he deemed “unacceptable.”\n\n“It is my opinion that Microsoft should immediately terminate the employment of Lisa Monaco,” he wrote.\n\nAs Trump noted, Monaco worked with both Barack Obama and Joe Biden, including as a deputy attorney general under the Biden administration. Trump rescinded Monaco’s security clearance earlier this year, in an order that did the same for Biden, Kamala Harris, Hillary Clinton, and the Biden family.\n\nA Microsoft spokesperson declined to comment. Monaco joined the company in May, taking on a role overseeing the company’s cybersecurity policy and its relationship with world governments.\n\nFar-right activist and Trump ally Laura Loomer has repeatedly criticized Microsoft for hiring Monaco in posts on X, complaining in one post that Microsoft CEO Satya Nadella was “born in India” and accusing him of “disgraceful scammer behavior.” On Friday, Loomer triumphantly quoted Trump’s post and again called on the president to “cancel all of Microsoft’s government contracts.”\n\nThis isn’t the first time Trump has targeted a tech executive since returning to office. He previously said that Intel president Lip-Bu Tan must “resign immediately” over alleged conflicts of interest. Then, after Intel gave the government a 10% stake in exchange for funding already committed by the Biden administration, Trump described Tan as a “Highly Respected Chief Executive Officer.”",
      "source": "TechCrunch",
      "url": "https://techcrunch.com/2025/09/27/trump-demands-microsoft-fire-global-affairs-head-lisa-monaco/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "NVIDIA Expands AI Presence with Intel Partnership and £2 Billion UK Investment",
      "content": "NVIDIA Corporation (NASDAQ:NVDA) is one of the 12 High-Risk High-Reward Growth Stocks to Buy Right Now.\n\nThe company announces investment in the UK AI market amid new partnerships and a positive Q2.\n\nThe company reported revenue of $46.74 billion in Q2 2025, achieving a 56% year-over-year…\n\nThis story appeared on finance.yahoo.com , 2025-09-27 18:16:18.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/e81e9a0981027d6d",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Nvidia CEO bets $100 billion on OpenAI becoming a multi-trillion-dollar company — Jensen outlines his view on OpenAI's path to becoming one of the biggest companies in the world",
      "content": "Nvidia CEO Jensen Huang believes OpenAI is on track to become a multi-trillion-dollar company, citing explosive growth and scale as the foundation for what could be the fastest rise to that valuation in the industry’s history. Speaking on the BG2 podcast, Huang said that OpenAI “is likely going to be the next multi-trillion-dollar hyperscaler company.”\n\nHis comments come on the heels of a high-stakes infrastructure pact between Nvidia and OpenAI. Earlier this week, the companies announced a letter of intent for up to 10 GW of GPU-powered data centers to be deployed through OpenAI’s preferred cloud partners. Nvidia, in turn, agreed to invest as much as $100 billion in those systems as capacity comes online, making it one of the largest vendor-led bets on AI infrastructure to date.\n\nIn doing so, Nvidia is effectively underwriting the next generation of AI growth by ensuring its silicon roadmap stays in sync with OpenAI’s compute ambitions. The deal anchors future demand for Nvidia’s Rubin-class platforms and next-gen networking hardware, while also giving OpenAI early access to systems that may not reach general availability for years.\n\nIt also helps to bolster Nvidia’s dominance in the AI supply chain. Major cloud providers, such as Microsoft, Amazon, and Google, have an insatiable appetite for GPU capacity, and Nvidia’s partnership strategy effectively pulls demand forward, locking hyperscalers like them into multi-year commitments while competitors like AMD and Intel are still playing catch-up. Expand the tweet below to see Jensen's explanation of OpenAI's path to a multi-trillion-dollar valuation.\n\n📁 Jensen Huang believes OpenAI is the next trillion-dollar company, and that’s why he’s investing. pic.twitter.com/bwI3ELEa4tSeptember 26, 2025\n\nAt 10 GW, OpenAI’s planned footprint and its associated capital expenditure have already pushed the plans into high-risk, high-reward territory. OpenAI recently struck a $6.5 billion expansion deal with CoreWeave, one of Nvidia’s key hosting partners, to help finance the rollout.\n\nNvidia also holds a stake in CoreWeave, and critics have raised concerns about the concentration of capital, hardware, and access among a small number of companies. However, that doesn’t seem to matter to Huang, who apparently believes that AI’s future will be defined by those who can scale infrastructure the fastest. OpenAI is outpacing even the most aggressive growth curves seen during the rise of cloud computing.\n\nNvidia’s ability to pre-sell entire generations of high-end GPUs into AI deployments will also have knock-on effects on the wider industry, including gaming card availability and workstation pricing. If OpenAI consumes a significant portion of future Rubin or Rubin Ultra supply, it could widen the gap between data center and consumer release cycles, making it even harder for consumers to obtain timely access to Nvidia’s latest hardware.\n\nStay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors\n\nFor now, though, Huang seems unconcerned. He’s betting $100 billion that OpenAI’s growth definitely isn’t part of a wider AI bubble.\n\nFollow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/jensen-huang-says-open-ai-will-be-a-multi-trillion-dollar-company",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "New Intel Panther Lake leak highlights 45 W TDP for top-spec variant",
      "content": "Moore's Law is Dead has leaked new information about Intel's Panther Lake laptop CPUs. The top-spec model will come with a 16-core CPU (4 P + 8 E + 4 LPE) and a 12 EU Celestial iGPU.\n\n4 Reviews ← exclude selected types\n\nYouTuber Moore's Law is Dead has revealed what Intel has in store for laptops with the Panther Lake platform. The latest leak says Intel's top-spec Panther Lake-H chip will come with 4 Cougar Cove performance cores, 8 Darkmont efficiency cores, and 4 Darkmont LPE cores.\n\nIts CPU tile will be made on Intel 18A, the GPU die on TSMC N3E, and the Platform Control Die on TSMC N6. On the GPU side, Panther Lake was tipped to arrive with up to a 12 EU iGPU based on Intel's Celestial architecture.\n\nThis is at odds with a leak from last year, which predicted a total of five Panther Lake CPUs with the top-spec model tipped to arrive with 6 P-cores, 8 E-cores and 4 LPE cores. Then again, the same leak stated that the two SKUs with 6 P-cores were further behind in development than the aforementioned SKU with 4 P-cores.\n\nThe leak adds that Panther Lake's LPE cores will actually be usable by applications this time, something that wasn't possible in previous generations. Moore's Law is dead estimates a 5-13% IPC increase, but states it has been challenging to predict IPC uplift in recent Intel CPUs.\n\nThe top-spec Panther Lake SKU will have a maximum TDP of up to 45 Watts, which is slightly higher than the Core Ultra 9 288V's 30 Watts. Additionally, it might be possible to push other (non-Core Ultra 9) SKUs to that figure, something that wasn't possible with Lunar Lake.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/New-Intel-Panther-Lake-leak-highlights-45-W-TDP-for-top-spec-variant.1125040.0.html",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "From Wall Street to academia, who is in Trump's line of fire?",
      "content": "GOLDMAN SACHS\n\nLive Events\n\nINTEL\n\nTESLA\n\nADRIAN MARDELL, FORMER CEO, JAGUAR LAND ROVER\n\nAPPLE\n\nAMAZON.COM\n\nBANK OF AMERICA AND JPMORGAN CHASE\n\nWALMART\n\nCRACKER BARREL\n\nCOMCAST\n\nSMITHSONIAN INSTITUTION\n\nHARVARD UNIVERSITY\n\nCOLUMBIA UNIVERSITY\n\nLAW FIRMS\n\nas a Reliable and Trusted News Source Addas a Reliable and Trusted News Source Add Now!\n\n\n\n\n\n(You can now subscribe to our\n\n(You can now subscribe to our Economic Times WhatsApp channel\n\nU.S. President Donald Trump has escalated his criticism and actions against executives, corporations and institutions. His unprecedented actions - from novel export deals to frozen university grants - have upended the status quo between the government, law, academia and corporate America.On Friday, Trump called for the firing of Lisa Monaco, Microsoft 's global affairs president, calling her a \"menace to U.S. National Security.\"Here are some influential figures and entities that Trump has publicly criticized:Goldman's economic research arm had published a note in August that said U.S. consumers had absorbed 22% of tariff costs through June, and their share could rise to 67% if the recent levies follow the same pattern as the earliest ones.\"David Solomon and Goldman Sachs refuse to give credit where credit is due,\" Trump said in a post on Truth Social , shortly thereafter.Trump said it was mostly \"companies and governments, many of them foreign, picking up the tabs\". He also took a dig at Solomon for his former DJ-ing hobby.In early August, Trump demanded Intel CEO Lip-Bu Tan step down due to China ties. Reuters had reported in April that Tan invested at least $200 million in hundreds of Chinese advanced manufacturing and chip firms, some of which were linked to the Chinese military.\"The CEO of INTEL is highly CONFLICTED and must resign, immediately. There is no other solution to this problem,\" Trump said in a post on his Truth Social platform.Tan responded to Trump, saying he shared the president's commitment to advancing U.S. national and economic security and that the Intel board was \"fully supportive of the work we are doing to transform our company.\"After a meeting between the two, Trump praised Tan and the U.S. government decided to take a stake in the chipmaker. MICROSOFTTrump on Friday said that the tech giant should fire its global affairs president Lisa Monaco, who served in the administrations of past Democratic presidents.\"She is a menace to U.S. National Security, especially given the major contracts that Microsoft has with the United States Government,\" Trump said on Truth Social. \"It is my opinion that Microsoft should immediately terminate the employment of Lisa Monaco.\"Trump said Monaco, in her position at Microsoft, would have access to highly sensitive information and her \"having that kind of access is unacceptable, and cannot be allowed to stand.\"Monaco, who started working at Microsoft in July, was a security aide in former president Barack Obama's administration and served as the deputy attorney general in former president Joe Biden's administration.The electric automaker's billionaire tech CEO Elon Musk spent hundreds of millions of dollars supporting Trump's re-election, a move investors who bid up Tesla stock expected to benefit Musk's empire.Trump and Musk, however, fell out in June after Musk criticized Trump's sweeping tax-cut and spending bill because it was projected to increase federal debt.Responding to that on Truth Social, Trump threatened to cut federal subsidies and contracts to Musk's companies and said the billionaire \"just went CRAZY\" after losing the electric-vehicle mandate in the bill.Trump criticized Jaguar's rebranding effort in August, calling the campaign \"woke\" and \"stupid\", and linking it to the departure of the company's CEO.The remarks from Trump came as the British carmaker, owned by India's Tata Motors, announced the retirement of CEO Adrian Mardell, who spent more than three decades at the company.Jaguar last year unveiled a new logo and visual identity as part of a brand refresh aimed at repositioning itself as an electric automaker, a move that drew sharp online backlash and criticism from brand loyalists.Trump has repeatedly targeted Apple and its boss, Tim Cook, for making U.S.-sold iPhones outside the country and has threatened company-specific tariffs.In May, Trump recalled, after a meeting in the Qatari capital Doha, that he had confronted Cook about the company's plan to make most of its iPhones sold in the U.S. at factories in India by the end of 2026.Trump had said in a social media post he told Cook \"long ago\" that \"I expect their iPhones that will be sold in the United States of America will be manufactured and built in the United States, not India, or anyplace else.\"Trump in early August announced Apple would invest an additional $100 billion in the U.S., raising its total domestic commitment to $600 billion over the next four years. Cook also gave Trump a U.S.-made souvenir with a 24-karat gold base.Trump called Amazon's former CEO Jeff Bezos in April to complain about a news report that said the company planned to display prices showing the impact of tariffs on e-commerce retailer Amazon.com.However, Amazon said it had only briefly considered listing import charges for some goods in April following Trump's tariff announcement, but dropped the plan as the White House accused the company of a \"hostile political act.\"Trump later told reporters that Bezos had solved the problem \"very quickly\" and was \"very nice.\"Trump in August alleged that BofA CEO Brian Moynihan and JPMorgan chief Jamie Dimon discriminated against him and his supporters. Earlier he had said they did not provide banking services to conservatives.\"What you're doing is wrong,\" Trump said, in a video address at the World Economic Forum in Davos, Switzerland. Trump did not cite evidence or specifics of any wrongdoing, in a question-and-answer session with corporate leaders and CEOs assembled on stage.He also referenced JPMorgan's Dimon. \"You and Jamie and everybody, I hope you're gonna open your bank to conservatives.\"Both lenders have denied the allegations of \"debanking\" on multiple occasions.Trump said in May Walmart and China should \"eat the tariffs\" and not burden American shoppers, after CEO Doug McMillon said the retailer could not absorb all tariff-related costs because of narrow retail margins.\"Walmart should STOP trying to blame Tariffs as the reason for raising prices throughout the chain. Walmart made BILLIONS OF DOLLARS last year, far more than expected,\" Trump said in a social media post.While Trump did not call out McMillon personally, he publicly criticized Walmart for attributing its price hikes in May to tariffs imposed by his administration.The restaurant chain's brief change in its logo - removing the long-standing image of an overall-clad man known as \"Uncle Herschel\" leaning against a barrel - is the most recent in a series of dustups where an unexpected response has blindsided retail chains.Cracker Barrel in late August said it will stick with its decades-old logo, scrapping plans for a new one following social media backlash, including from President Donald Trump.\"Congratulations 'Cracker Barrel' on changing your logo back to what it was. All of your fans very much appreciate it,\" Trump said on Truth Social after the company's reversal.Trump criticized Comcast and its cable news network MSNBC for its news coverage of his administration. He said to reporters, \"They're changing the name because they're ashamed of it, and they're disassociating it from NBC,\" referring to MSNBC's name change to MS NOW.In a post on his social media platform in August, Trump also called Comcast a \"weak and ineffective owner ... headed by ... Brian Roberts.\"The White House has said it will lead an internal review of some Smithsonian museums and exhibitions ahead of the 250th anniversary of the U.S. Declaration of Independence.In an executive order in March, Trump said the institution had come under the influence of a \"divisive, race-centered ideology\" in recent years.Trump targeted the country's oldest and richest university, canceling about $2.5 billion federal grants, and mounted efforts to cut off research funding to Harvard, as a part of a larger campaign to force change at U.S. universities, which Trump says are gripped by antisemitic and \"radical left\" ideologies.\"We are going to be taking away Harvard's Tax Exempt Status. It's what they deserve!\" Trump wrote in a post on his social media platform in May.In March, the Trump administration said it was penalizing Columbia University over how it handled last year's protests by canceling $400 million in federal funding.\"This is the first arrest of many to come. We know there are more students at Columbia and other Universities across the Country who have engaged in pro-terrorist, anti-Semitic, anti-American activity, and the Trump Administration will not tolerate it,\" Trump said in a social media post.The comments came after the arrest of Palestinian graduate student Mahmoud Khalil played a prominent role in the protests.In July, the university said it will pay over $200 million to the U.S. government in a settlement with Trump's administration.Trump targeted law firm Perkins Coie in March with an executive order that suspended security clearances for its employees and restricted their access to federal buildings over its ties to Hillary Clinton and DEI policies.Trump had said it was \"an absolute honor to sign\" the order. Trump also targeted New York law firm Paul, Weiss, Rifkind, Wharton & Garrison in March with a similar order, which he later withdrew after striking a deal.Law firm Covington & Burling faced Trump's presidential memorandum in February, which suspended security clearances for Peter Koski and all Covington employees who assisted former special counsel Jack Smith, who prosecuted Trump.Covington had said it would continue representing Jack Smith despite these measures.\"We're going to continue holding the people who were responsible for the weaponization of government - who supported it - accountable,\" Trump had said.",
      "source": "The Times of India",
      "url": "https://economictimes.indiatimes.com/news/international/global-trends/from-wall-street-to-academia-who-is-in-trumps-line-of-fire/articleshow/124175936.cms",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Lowes.com - Toro Flex-Force 60-volt max 16-in Straight Shaft Battery String Trimmer 2.5 Ah (Battery/Charger Included) - $112.75 + Tax (3 replies)",
      "content": "Toro Flex-Force 60-volt max 16-in Straight Shaft Battery String Trimmer 2.5 Ah (Battery Included) (Charger Included)Item #5657201 | Model #51830$229.99 elsewhere - the 2.5AH battery alone is $150 on AmazonThe Toro 60V Max 16-in Brushless String Trimmer (Battery manufacturer rating = 60V maximum & 54V typical usage. Actual voltage varies with load) lets you choose either 14-in of whippin' or 16-in of whoopin' which means you get to accelerate performance and productivity whenever you want. Unlike the other guys, ours comes standard with a pro-grade 0.095-in line that can handle the thickest grass and toughest weeds. You choose the speed that's right for the job. Brushless motor with RunSmart onboard intel optimizes RPMs and torque in real time, for peak cutting performance in the toughest conditions. As part of the Toro 60V Max Flex-Force Power System, it's got power like no other that commands a full line of tools. Count on it.Up to 60 minutes of runtime with 2.5 Ah battery (varies with usage condition)Pro-grade 0.095-in line with quick-feed, no spools, and customizable performance length between 14-in to 16-in cutsVariable speed and high/low selector for ultimate control based on the job at handCast-aluminum motor head built to take a beating when you're weedingErgonomic comfort grip handle-for easy gripping and less vibrationOptimized weight balance makes it more comfortable to hold and easier to maneuver3-phase brushless motor with RunSmart™ technology for increased runtime and optimized performanceInnovative \"3P\" battery stack design gives you 3 times the power with higher max performanceUse the 60V Max Flex-Force battery to power any and all of the Toro interchangeable tools in the Flex-Force all-season lineup, including commercial-grade handheld tools, walk mowers, and snow blowers",
      "source": "Slickdeals.net",
      "url": "https://slickdeals.net/f/18639955-lowes-com-toro-flex-force-60-volt-max-16-in-straight-shaft-battery-string-trimmer-2-5-ah-battery-charger-included-112-75-tax",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Pam Bondi Claims ‘Weaponization Has Ended’ As She Lists Trump Opponents She Will Crush In Same Breath",
      "content": "Attorney General Pam Bondi told Fox News host Sean Hannity that “weaponization has ended” — in the same breath as she listed Trump opponents she intends to target for investigation and potential prosecution.\n\nPresident Donald Trump gave Bondi marching orders to go after a list of enemies in a DM-style Truth Social post and again in remarks to reporters this week, after which the James Comey indictment dropped.\n\nIn a gaggle with reporters Friday, Trump denied the indictment was about revenge, and claimed he has no enemies list — but predicted more indictments.\n\nBondi was a guest on Friday night’s edition of Fox News Channel’s Hannity, during which she picked up where Trump left off even as she assured Hannity that “weaponization” is a thing of the past:\n\nSEAN HANNITY: I would imagine you’re not allowed to get into the specifics of the case. I won’t waste your time asking you however, when you look at the magnitude of what Kash Patel is saying, a grand conspiracy that from the minute he came down the escalator with Melania all the way through. You know Russia Russia, two impeachments. All the way through the Hunter Biden laptop suppressed. All the way, through weaponization. Pam I’m nervous for the country when I put it all together AG PAM BONDI: You shouldn’t be nervous any longer because donald trump is in office and the weaponization has ended! We’ve made that very clear. Whether you’re a former FBI director, whether you’re a former head of an intel community. Whether you are a current state or local elected official. Whether you are a billionaire funding organizations to try to keep donald Trump out of office. Everything is on the table. We will investigate you and we will end the weaponization. No longer will there be a two-tier system of justice and we are working hand-in-hand, Director Patel and I, Todd Blanche, with our incredible intel community. Tulsi Gabbard, John Ratcliffe going non-stop around the clock. People will be held accountable\n\nWatch above via Fox News Channel’s Hannity.",
      "source": "Mediaite",
      "url": "https://www.mediaite.com/media/news/pam-bondi-claims-weaponization-has-ended-as-she-lists-trump-opponents-she-will-crush-in-same-breath/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Obama’s final booby trap",
      "content": "In the final days of the Obama presidency — while Americans were focused on inaugurating a new president and turning the page on a divisive era — President Barack Obama signed a quiet but sweeping executive order that many now see as a ticking time bomb planted in the heart of our Intelligence Community.\n\nOn January 3, 2017, just 17 days before Donald Trump’s inauguration, Obama signed a modification to Executive Order 12333, authorizing the National Security Agency (NSA) to share raw signals intelligence (SIGINT) with all 16 other intelligence agencies — including the FBI, the CIA, and even obscure agencies like the Drug Enforcement Administration’s intel wing.\n\nAt face value, the stated purpose was to “streamline intelligence sharing” and “improve coordination” in the age of global terrorism. But conservatives saw something else: a calculated move to weaponize the intelligence apparatus against a political outsider — Donald J. Trump — before he could even take the oath of office.\n\nFrom Terrorism to Trump? The Convenient Shift\n\nPrior to this change, the NSA — which vacuumed up massive amounts of phone calls, emails, texts, and metadata — could share only filtered, “minimized” intelligence with other agencies. That meant masking the names of American citizens incidentally caught up in foreign surveillance.\n\nBut Obama’s executive order reversed that policy, allowing raw, unredacted data — including conversations of U.S. citizens — to be freely distributed across the Intelligence Community. In short, the firewalls were gone. The surveillance spigot was opened.\n\nWhy now? Why not during his eight years in office?\n\nThese are the questions conservatives have been asking ever since.\n\nA Leak Pipeline Disguised as Reform\n\nWithin weeks of the order, classified leaks about members of Trump’s incoming administration began flowing.\n\nThe most prominent example? Lt. General Michael Flynn.\n\nIn early 2017, intelligence officials leaked transcripts of Flynn’s phone calls with Russian ambassador Sergey Kislyak — conversations recorded by the NSA and circulated under the new data-sharing regime. The leaks forced Flynn’s resignation as national security adviser after just 24 days and ignited a firestorm that crippled the Trump presidency for years.\n\nFlynn was later cleared of criminal wrongdoing, but the damage was done.\n\nSo let’s connect the dots: Obama expanded access to unfiltered NSA data in his final weeks. Those raw data were then used — and leaked — to undermine a sitting president. If that’s not a setup, what is?\n\nThe “Unmasking” Epidemic\n\nEven more disturbing was the surge in “unmasking” requests from Obama-era officials during the transition period.\n\nUnmasking is the process by which an official asks to reveal the identity of a U.S. citizen caught up in foreign surveillance. According to declassified records, senior Obama officials — including then–vice president Joe Biden, U.N. ambassador Samantha Power, and even James Clapper — submitted dozens of such requests targeting the Trump team.\n\nThe justification? Vague national security concerns. But in hindsight, it’s clear these unmasking requests were part of a broader strategy to surveil, leak, and neutralize political opponents before they could govern.\n\nAnd it was all made possible — or at least much easier — thanks to Obama’s executive order.\n\nDeep State Entrenchment 101\n\nTo critics, this wasn’t just an intelligence reform; it was the institutionalization of the Deep State.\n\nThe order ensured that hundreds, if not thousands, of additional analysts and bureaucrats across 17 agencies could now legally access the NSA’s digital gold mine. With more hands on the data, leaks were harder to trace. And with a hostile press eager to delegitimize Trump, the stage was set for a political slow-motion ambush disguised as “whistleblowing.”\n\nWhile the term “Deep State” may sound conspiratorial, what else do you call a network of entrenched bureaucrats using classified tools to sabotage an elected president?\n\nWas It Legal? Sure. Was It Ethical? Not Even Close.\n\nDefenders of the order point out that it was technically within Obama’s legal authority. But legality is not the same as legitimacy.\n\nA president expanding intelligence access to his loyalists — weeks before handing power to a political rival — doesn’t pass the smell test. If a Republican had done this to a Democrat, the media would have howled about authoritarianism and privacy violations.\n\nBut in this case? Crickets.\n\nIn fact, most mainstream outlets didn’t even report on the executive order until months later, long after the leaks had done their damage.\n\nThe Real Legacy of Executive Order 12333\n\nFor all of Obama’s claims about “transparency” and “civil liberties,” his final act expanded the surveillance state more than any other modern president.\n\nAnd for what? To catch terrorists? Or to target political opponents under the guise of national security?\n\nHere’s what we know:\n\nThe order enabled widespread access to sensitive, raw intelligence.\n\nThat data were leaked in unprecedented ways — targeting Trump officials.\n\nThe leaks disrupted a duly elected administration.\n\nAnd the media cheered it on.\n\nThis wasn’t a glitch in the system. It was the system.\n\nConclusion: A Blueprint for Future Abuse\n\nObama’s parting gift was a booby-trapped surveillance infrastructure, tailor-made to hinder anyone who dared challenge the political establishment. In that light, the Flynn leak wasn’t a scandal; it was a preview.\n\nConservatives must never forget this moment. Executive orders may not make headlines, but their impact can reshape the Republic. The next time a “national security” measure is rolled out in the dead of night, we should all ask: Who gains power — and who loses his freedom?\n\nBecause once the intelligence machine is turned inward, the target is no longer terrorists. It’s you.\n\nImage: Gage Skidmore via Flickr, CC BY-SA 2.0.",
      "source": "Americanthinker.com",
      "url": "https://www.americanthinker.com/blog/2025/09/obama_s_final_booby_trap.html",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "‘Bombshell report’: Tulsi Gabbard uncovers documents showing Obama doctored intel to create Russiagate",
      "content": "Jesse Watters ran a very damning segment on the origins of the Trump-Russia hoax.\n\nDirector of National Intelligence Tulsi Gabbard uncovered documents that were hidden for ten years that show Barack Obama was leading efforts to make it look like President Trump and Vladimir Putin stole the 2016 election from Hillary Clinton.\n\nObama ordered his corrupt CIA Director John Brennan to create this fake assessment.\n\nThis ties the former President Obama directly to the Trump-Russia hoax.\n\nDirty Obama was leading the efforts to take down Trump.\n\nBarack Obama, who offered ‘hope and change,’ was actually a blight on our country’s history.\n\nJesse Watters reported: The Director of National Intelligence, Tulsi Gabbard, released a bombshell report today that shows a conspiracy by a sitting President, Barack Obama, and his intel agencies to sabotage the President-elect, Donald Trump, brainwash the electorate, and undermine the legitimacy of an election. There is irrefutable evidence that detail how President Obama and his national security team directed the creation of an intelligence community assessment that they knew was false. They knew it would promote this contrived narrative that Russia interfered in the 2016 election to help President Trump win, selling it to the American people as though it were true. It wasn’t. Gabbard got her hands on a House intel report that’s been locked away in a CIA vault for almost a decade. Investigators spent over 2,000 hours looking into how the Russia hoax was born, interviewing 20 CIA and FBI officials. It turns out that the Obama administration doctored the intelligence to make it look like Putin and Trump stole the election… …Senior CIA officials repeatedly refused to traffic in these allegations. But they were repeatedly overruled by CIA Director Brennan and FBI Director Comey, who insisted that they be pushed even without verifiable evidence. The Obama administration cherry-picked the intelligence, lied about their sources, misquoted sources, didn’t corroborate their claims, suppressed intelligence that ran counter to their narratives, and even used anonymous internet postings. Rank and file CIA admitted what they were doing violated their own Tradecraft standards. There was a massive pressure campaign that came right from the top. Cia analysts say they received unusual directives from political appointees, the CIA director and Obama himself.\n\nNow we have the proof – It was Obama leading the efforts to destroy Donald Trump.\n\nSo much for hope and change!\n\nThis right here should be enough evidence to lock up Obama, Brennan, and Jim Comey for years.\n\nTREASON Tulsi has uncovered documents that were hidden for ten years, showing Obama doctored the intel to make it look like Putin and Trump stole the 2016 election Obama ordered Brennan to create a fake assessment ALL ROADS LEAD DIRECTLY TO OBAMA pic.twitter.com/Bt9kiC8vQD — @Chicago1Ray (@Chicago1Ray) September 26, 2025\n\n[Editor’s note: This article originally appeared on The Gateway Pundit.com.]",
      "source": "Wnd.com",
      "url": "https://www.wnd.com/2025/09/bombshell-report-tulsi-gabbard-uncovers-documents-showing-obama/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Amazon leads H-1B visa approvals in early 2025; TCS, Microsoft, Meta close behind",
      "content": "Synopsis\n\nAmazon received the highest number of H-1B visa approvals in the first half of 2025, with 10,044 approvals by June 30, according to USCIS. Tech companies are the main users of the programme. TCS came second, followed by Microsoft, Meta, Apple, and Google with thousands of approved visa applications.",
      "source": "The Times of India",
      "url": "https://economictimes.indiatimes.com/tech/technology/amazon-leads-h-1b-visa-approvals-in-early-2025-tcs-microsoft-meta-close-behind/articleshow/124182638.cms",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Promising Value Stocks To Add to Your Watchlist – September 25th",
      "content": "Invesco QQQ, Intel, CoreWeave, Oklo, Rigetti Computing, AltC Acquisition, and Opendoor Technologies are the seven Value stocks to watch today, according to MarketBeat’s stock screener tool. Value stocks are shares of companies that appear to trade for less than their intrinsic worth based on fundamental measures such as price-to-earnings or price-to-book ratios. They often offer stable earnings and dividends but may be overlooked or out of favor in the market. Value investors buy these stocks believing the market will eventually correct their prices upward. These companies had the highest dollar trading volume of any Value stocks within the last several days.\n\nGet alerts:\n\nInvesco QQQ (QQQ)\n\nPowerShares QQQ Trust, Series 1 is a unit investment trust that issues securities called Nasdaq-100 Index Tracking Stock. The Trust’s investment objective is to provide investment results that generally correspond to the price and yield performance of the Nasdaq-100 Index. The Trust provides investors with the opportunity to purchase units of beneficial interest in the Trust representing proportionate undivided interests in the portfolio of securities held by the Trust, which consists of substantially all of the securities, in substantially the same weighting, as the component securities of the Nasdaq-100 Index.\n\nIntel (INTC)\n\nIntel Corporation designs, develops, manufactures, markets, and sells computing and related products and services worldwide. It operates through Client Computing Group, Data Center and AI, Network and Edge, Mobileye, and Intel Foundry Services segments. The company's products portfolio comprises central processing units and chipsets, system-on-chips (SoCs), and multichip packages; mobile and desktop processors; hardware products comprising graphics processing units (GPUs), domain-specific accelerators, and field programmable gate arrays (FPGAs); and memory and storage, connectivity and networking, and other semiconductor products.\n\nRead Our Latest Research Report on INTC\n\nCoreWeave (CRWV)\n\nRead Our Latest Research Report on CRWV\n\nOklo (OKLO)\n\nOklo Inc. designs and develops fission power plants to provide reliable and commercial-scale energy to customers in the United States. It also provides used nuclear fuel recycling services. The company was founded in 2013 and is based in Santa Clara, California.\n\nRead Our Latest Research Report on OKLO\n\nRigetti Computing (RGTI)\n\nRigetti Computing, Inc., through its subsidiaries, builds quantum computers and the superconducting quantum processors. The company offers cloud in a form of quantum processing unit, such as 9-qubit chip and Ankaa-2 system under the Novera brand name; and sells access to its quantum computers through quantum computing as a service.\n\nRead Our Latest Research Report on RGTI\n\nAltC Acquisition (ALCC)\n\nAltC Acquisition Corp. does not have significant operations. It intends to effect a merger, capital stock exchange, asset acquisition, stock purchase, reorganization, or other business combination with one or more businesses. The company was formerly known as Churchill Capital Corp VIII and changed its name to AltC Acquisition Corp.\n\nRead Our Latest Research Report on ALCC\n\nOpendoor Technologies (OPEN)\n\nOpendoor Technologies Inc. operates a digital platform for residential real estate transactions in the United States. It buys and sells homes. The company's product offerings comprise sell to opendoor product that enables homeowners to sell their home directly to it and resell the home to a home buyer; list with opendoor product that allows customers to list their home on the MLS with opendoor and receive cash offer; and opendoor marketplace product that connects the home seller with an institutional or retail buyer.\n\nRead Our Latest Research Report on OPEN\n\nFurther Reading",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/27/promising-value-stocks-to-add-to-your-watchlist-september-25th/",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "ECS Liva Z11 Plus mini PC debuts with up to Intel Arrow Lake processor",
      "content": "The ECS Liva Z11 Plus was officially introduced at Computex 2025, and now, the company has shared more details about the mini PC. As ECS reveals, the system can be equipped with up to Intel Core Ultra 7 255H and 96 GB of RAM.\n\n4 Reviews ← exclude selected types\n\nECS has detailed the Z11 Plus mini PC, which was officially introduced back at Computex 2025. The company now shares that the system will be available in four CPU configurations, with the base configuration featuring the Intel Core Ultra 5 125H from the Meteor Lake series.\n\nThere is another Meteor Lake CPU option available, the Core Ultra 7 155H, and ECS is also offering the option to equip the mini PC with Intel Core Ultra 5 225H or Core Ultra 7 255H from the Arrow Lake lineup. Users can pair the processor with up to 96 GB of DDR5 RAM.\n\nHowever, it's worth noting that the Meteor Lake configurations support DDR5-5600 memory, while the Arrow Lake options support DDR5-6400 RAM. For storage, there are two M.2 slots that can that can hold PCIe 4.0 SSDs, but among the two, one is a 2242 slot (2 TB Crucial P310 curr. $148.50 on Amazon).\n\nThe mini PC has a separate M.2 2230 slot for a wireless card. As for the port configuration, the ECS Liva Z11 Plus features the following ports:\n\n3x USB 3.2 Gen 2 Type-A\n\n3x USB 2.0 Type-A\n\n1x USB 3.2 Gen 2x2 Type-C\n\n2x USB\n\n2x HDMI\n\n1x 2.5G Ethernet\n\n1x Gigabit Ethernet\n\nWith the dual HDMI and USB4 ports, the mini PC supports quad-4K display output. Among the other highlights are a compact form factor and a sleek design. ECS hasn't shared the pricing info of the mini PC yet, and it's also unclear when the system will be available to purchase.",
      "source": "Notebookcheck.net",
      "url": "https://www.notebookcheck.net/ECS-Liva-Z11-Plus-mini-PC-debuts-with-up-to-Intel-Arrow-Lake-processor.1125796.0.html",
      "timestamp": "2025-09-27"
    },
    {
      "headline": "Is Your MacBook Pro Too Good To Upgrade?",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/ewanspence/2025/09/27/apple-macbook-pro-macbook-air-m1-m5-should-you-upgrade-new-macbook/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Devin Nunes on Fox News Says of Comey Indictment – “Comey has Long Been a Liar, a Leaker. He’s Dishonest. He Ruined the FBI” (VIDEO)",
      "content": "Trump Media CEO Devin Nunes was on “Sunday Morning Futures” with Maria Bartiromo to discuss former FBI director James Comey’s indictment.\n\n“We continue to look at the indictment of former FBI director, Jim Comey for making false statements and obstruction of Congress,” Bartiromo said.\n\n“Devin, thanks very much for being here this morning. Give us your reaction to the indictment of Jim Comey,” Bartiromo said.\n\n“I think Comey should consider himself lucky Maria, number one, that he wasn’t treated like Roger Stone was treated,” Nunes said.\n\n“They actually raided his home at 6 am, dragged him out, and that was before they actually called the CNN cameras,” Nunes said of Roger Stone.\n\n“Secondly, what also didn’t happen to him is what happened to General Flynn, where Comey himself admitted that they ambushed Flynn in the White House, charged him on very similar charges, even though the FBI agents themselves said that they didn’t believe Flynn had lied,” Nunes said.\n\n“Comey has long been a liar, a leaker. He’s dishonest. He Ruined the FBI,” Nunes said.\n\n“Most importantly, he will be lucky if there is not a grand conspiracy charge brought, which is really what should be brought against probably about two dozen characters in the United States over the last seven, eight years,” Nunes explained.\n\nWatch:\n\nToday, exclusively on @SundayFutures with @MariaBartiromo, Former House Intel Chairman Devin Nunes @DevinNunes reacted to Former FBI Director James Comey indicted on two counts.@FoxNews pic.twitter.com/E9W0kLBUkI — SundayMorningFutures (@SundayFutures) September 28, 2025\n\nBartiromo asked Nunes if there should be more charges and indictments on former FBI Director Comey.\n\n“Devin, my question to you is number one, should there be more charges against Jim Comey, and number two, should there be more indictments? What do you think?” Bartiromo asked.\n\n“So, on Comey, I think the answer for this is, it’s very specific and it’s over whether or not he lied on this one part. The larger part is whether or not you can bring a kind of grand conspiracy case,” Nunes said.\n\n“There is also a term in there called misleading. And what a lot of what these guys did is they made up things using intelligence that didn’t exist but acted like they knew something that actually wasn’t there, and they lied and mislead the American people,” Nunes said.\n\n“Everything that has been declassified, is that they didn’t have any intelligence on Russia colluding with Trump,” Nunes explained.\n\nWatch:",
      "source": "Thegatewaypundit.com",
      "url": "https://www.thegatewaypundit.com/2025/09/devin-nunes-fox-news-says-comey-indictment-comey/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Show HN: Production-ready macOS dev environment setup with 10 preset configs",
      "content": "Environment Setup v1.0\n\nA comprehensive, production-ready development environment setup for macOS with AI tools, designed for full-stack JavaScript/TypeScript development.\n\n✨ Features\n\n🚀 One-command setup : Install everything with a single script\n\n: Install everything with a single script 🔄 Idempotent : Safe to run multiple times without side effects\n\n: Safe to run multiple times without side effects 🧩 Modular : Install only what you need by category\n\n: Install only what you need by category 🤖 AI-powered : Local LLMs, AI coding tools, and intelligent editors\n\n: Local LLMs, AI coding tools, and intelligent editors 📚 Comprehensive documentation : Auto-generated complete setup documentation\n\n: Auto-generated complete setup documentation 🛡️ Production-ready : CI/CD, linting, security scanning, and error handling\n\n: CI/CD, linting, security scanning, and error handling ⚙️ Highly configurable : YAML-driven configuration system\n\n: YAML-driven configuration system 🌍 Complete environment : 50+ environment variables for seamless development\n\n: 50+ environment variables for seamless development 📁 Full dotfile management : Shell, Git, SSH, and editor configurations\n\n: Shell, Git, SSH, and editor configurations 🔌 VS Code extensions : 20+ essential extensions automatically installed\n\n: 20+ essential extensions automatically installed 💻 Modern terminals : AI-powered Warp, iTerm2, Alacritty, WezTerm, Kitty\n\n: AI-powered Warp, iTerm2, Alacritty, WezTerm, Kitty 🚀 Services management : Database, AI, and development services with ports\n\n: Database, AI, and development services with ports 🖥️ macOS optimization: Automatic system preferences configuration for optimal development experience\n\n🚀 Quick Start\n\nOption 1: Use a Preset Configuration (Recommended)\n\n# Clone the repository git clone https://github.com/davidsilvestrehenao-hub/env-setup.git cd env-setup # Choose a configuration that fits your needs ./setup-env.sh install --config configs/webdev.yaml # Web development ./setup-env.sh install --config configs/ai.yaml # AI/ML development ./setup-env.sh install --config configs/minimal.yaml # Essential tools only ./setup-env.sh install --config configs/everything.yaml # Complete setup # Or preview first ./setup-env.sh preview --config configs/webdev.yaml\n\nOption 2: Use Default Configuration\n\n# Clone and run with default config git clone https://github.com/davidsilvestrehenao-hub/env-setup.git cd env-setup ./setup-env.sh install # Or preview first ./setup-env.sh preview\n\nOption 3: Create Custom Configuration\n\n# Copy a preset as starting point cp configs/webdev.yaml configs/my-custom.yaml # Edit to your needs nano configs/my-custom.yaml # Use your custom config ./setup-env.sh install --config configs/my-custom.yaml\n\n⚙️ Configuration System\n\nThis tool is highly configurable with 10+ preset configurations for different user types:\n\nConfiguration Description Packages Perfect For everything Complete setup with all packages 113+ Power users, new Mac setups minimal Essential tools only ~20 Quick setup, basic development webdev Web development focused ~50 Frontend/backend developers ai AI/ML development ~60 AI researchers, data scientists mobile Mobile development ~50 iOS/Android developers devops DevOps & infrastructure ~80 DevOps engineers, SREs design Design & creative tools ~30 UI/UX designers, creators gaming Gaming & entertainment ~30 Gamers, streamers student Student & learning ~50 Students, bootcamp participants senior Senior developer tools ~90 Senior devs, tech leads\n\n🎯 Choose Your Configuration\n\nNew to development? → Start with minimal or student\n\n→ Start with or Web developer? → Use webdev or everything\n\n→ Use or AI/ML work? → Choose ai or senior\n\n→ Choose or DevOps engineer? → Go with devops or everything\n\n→ Go with or Want everything? → Use everything (default)\n\n📁 Configuration Files\n\nAll configurations are in the configs/ directory. Each file:\n\nExtends the main config.yaml for base settings\n\nfor base settings Overrides specific package categories\n\nCan be customized further for your needs\n\nServes as an example for creating your own configs\n\n📦 What's Included\n\nCore Development Tools\n\nVersion Control : Git, GitHub CLI\n\n: Git, GitHub CLI Runtimes : Node.js, Bun, Python\n\n: Node.js, Bun, Python Package Managers : pnpm, Yarn, pipx\n\n: pnpm, Yarn, pipx Containers : Docker, Colima\n\n: Docker, Colima Databases : PostgreSQL, MongoDB, Redis, SQLite, ClickHouse, DuckDB, OpenSearch\n\n: PostgreSQL, MongoDB, Redis, SQLite, ClickHouse, DuckDB, OpenSearch Terminal Tools : Starship, eza, bat, fzf, ripgrep, fd, zoxide\n\n: Starship, eza, bat, fzf, ripgrep, fd, zoxide Terminal Apps : Warp (AI-powered), iTerm2, Alacritty, WezTerm, Kitty\n\n: Warp (AI-powered), iTerm2, Alacritty, WezTerm, Kitty Development: Pre-commit, ShellCheck, direnv, git-delta, gitleaks\n\nAI Tools & Models\n\nLocal LLMs : Ollama with Llama2 and DeepSeek Coder 33B\n\n: Ollama with Llama2 and DeepSeek Coder 33B Model Management : LM Studio for GUI model management\n\n: LM Studio for GUI model management AI Editors : Void IDE, Cursor IDE with AI capabilities\n\n: Void IDE, Cursor IDE with AI capabilities APIs : OpenAI CLI for cloud AI access\n\n: OpenAI CLI for cloud AI access Web UI: Open WebUI for local model interaction\n\nCode Editors & Extensions\n\nEditors : VS Code, Cursor, Void IDE\n\n: VS Code, Cursor, Void IDE Terminals : Warp (AI-powered), iTerm2, Alacritty, WezTerm, Kitty\n\n: Warp (AI-powered), iTerm2, Alacritty, WezTerm, Kitty Extensions : 30+ essential extensions for TypeScript, React, Vue, Docker, Kubernetes, and more\n\n: 30+ essential extensions for TypeScript, React, Vue, Docker, Kubernetes, and more AI Integration: GitHub Copilot, AI-powered code completion\n\nProductivity & Business Apps\n\nCommunication : WhatsApp, Signal, Telegram, Slack, Discord\n\n: WhatsApp, Signal, Telegram, Slack, Discord Note-taking : Notion, Obsidian\n\n: Notion, Obsidian Productivity : Raycast, Rectangle, MeetingBar, AltTab\n\n: Raycast, Rectangle, MeetingBar, AltTab Media : VLC, HandBrake, Spotify\n\n: VLC, HandBrake, Spotify Utilities: Keka, AppCleaner, Hidden Bar, MonitorControl, Stats\n\n🎯 Installation Options\n\nUsing Setup Script (Easiest)\n\n# Full installation ./setup-env.sh install # Preview installation ./setup-env.sh preview # Install specific categories ./setup-env.sh core # Core development tools ./setup-env.sh frontend # Frontend tools and editors ./setup-env.sh backend # Backend tools and databases ./setup-env.sh business # Productivity and business apps ./setup-env.sh ai # AI tools and models # Cleanup ./setup-env.sh cleanup # Help ./setup-env.sh help\n\nUsing Make (Advanced)\n\n# Full installation make install # Preview installation make setup-dry-run # Category-specific installation make setup-core # Core development tools make setup-frontend # Frontend tools and editors make setup-backend # Backend tools and databases make setup-business # Productivity and business apps make setup-ai # AI tools and models make setup-webui # Web interfaces # Quick setups make setup-minimal # Minimal setup (core only) make setup-dev # Developer setup (core + frontend + backend) make setup-ai-focused # AI-focused setup\n\nUsing Scripts Directly\n\n# Full installation ./scripts/setup-env.sh # Dry run (preview only) ./scripts/setup-env.sh --dry-run # Install specific categories ./scripts/setup-env.sh --only core ./scripts/setup-env.sh --only frontend ./scripts/setup-env.sh --only backend ./scripts/setup-env.sh --only business # Advanced options ./scripts/setup-env.sh --skip-models # Skip AI model downloads ./scripts/setup-env.sh --skip-webui # Skip web UI setup ./scripts/setup-env.sh --config my-config.yaml # Use custom config\n\n⚙️ Configuration\n\nThe entire setup is driven by config.yaml , which serves as the single source of truth for:\n\nPackage lists by category\n\nVS Code extensions by role\n\nAI model configuration\n\nService port settings\n\nTool descriptions and documentation links\n\n# Example configuration categories : core : name : \" Core Development Tools \" enabled : true packages : core : brew : [\"git\", \"node\", \"docker\"] cask : [] extensions : core : [\"dbaeumer.vscode-eslint\", \"esbenp.prettier-vscode\"]\n\n📚 Documentation\n\nWhat's in the Complete Documentation\n\n113+ Packages - Complete list with descriptions and status\n\n- Complete list with descriptions and status 20+ VS Code Extensions - Essential development extensions\n\n- Essential development extensions Complete Dotfiles - Shell, Git, SSH, and editor configurations\n\n- Shell, Git, SSH, and editor configurations 50+ Environment Variables - Development environment setup\n\n- Development environment setup AI Tools & Models - Local LLMs and AI development tools\n\n- Local LLMs and AI development tools Terminal Applications - Modern terminals with configurations\n\n- Modern terminals with configurations Services & Ports - Database, AI, and development services\n\n- Database, AI, and development services macOS System Preferences - Automatic configuration of Dock, Finder, Keyboard, Trackpad, Display, and more\n\n🛠️ Maintenance\n\nUsing Make\n\n# Update packages make update # Run health checks make health-check # Clean up (remove everything) make clean # Preview cleanup make clean-dry-run # Check service status make services-status make ai-status make db-status\n\nUsing Scripts\n\n# Health checks ./scripts/setup.sh --dry-run # Cleanup ./scripts/cleanup.sh # Generate comprehensive documentation ./scripts/generate-csv-readme.sh\n\n🔧 Development\n\nPrerequisites\n\nmacOS (Intel or Apple Silicon)\n\nInternet connection\n\nAdministrator access\n\nAt least 10GB free disk space\n\nDevelopment Workflow\n\n# Install development dependencies make install # Run tests and linting make test make lint # Generate comprehensive documentation make docs # Run pre-commit hooks make pre-commit\n\nGitHub Actions : Automated testing, linting, and security scanning\n\n: Automated testing, linting, and security scanning Pre-commit hooks : Code quality and security checks\n\n: Code quality and security checks Automated releases: Tag-based releases with changelog generation\n\n🏗️ Architecture\n\nModular Design\n\nconfig.yaml : Single source of truth for all configuration\n\n: Single source of truth for all configuration scripts/lib/ : Reusable library functions\n\n: Reusable library functions scripts/setup-env.sh : Main setup script with CLI flags\n\n: Main setup script with CLI flags scripts/cleanup.sh : Safe removal of all components\n\n: Safe removal of all components Makefile : Common tasks and shortcuts\n\nSafety Features\n\nIdempotent operations : Safe to run multiple times\n\n: Safe to run multiple times Dry run mode : Preview changes before applying\n\n: Preview changes before applying Lock file protection : Prevent concurrent executions\n\n: Prevent concurrent executions Comprehensive logging : Detailed logs for troubleshooting\n\n: Detailed logs for troubleshooting Health checks : Pre and post-installation validation\n\n: Pre and post-installation validation Error handling: Robust error handling with retries\n\n🤝 Contributing\n\nFork the repository Create a feature branch: git checkout -b feature/amazing-feature Make your changes Update config.yaml if adding new tools Run tests: make test Run linting: make lint Commit your changes: git commit -m 'Add amazing feature' Push to the branch: git push origin feature/amazing-feature Open a Pull Request\n\nDevelopment Guidelines\n\nFollow shell scripting best practices\n\nAdd comprehensive error handling\n\nUpdate documentation for new features\n\nInclude tests for new functionality\n\nUse semantic commit messages\n\n📊 Project Status\n\nVersion : 4.0.0\n\n: 4.0.0 Status : Production Ready\n\n: Production Ready CI/CD : ✅ GitHub Actions\n\n: ✅ GitHub Actions Security : ✅ Gitleaks, ShellCheck, Pre-commit\n\n: ✅ Gitleaks, ShellCheck, Pre-commit Documentation : ✅ Comprehensive auto-generated documentation\n\n: ✅ Comprehensive auto-generated documentation Testing: ✅ Dry-run validation\n\n📄 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n🙏 Acknowledgments",
      "source": "Github.com",
      "url": "https://github.com/davidsilvestrehenao-hub/env-setup",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "These people grew up under dictators. They're worried about what's happening here.",
      "content": "As a child in Cuba, Mike Fernandez watched as his teachers were replaced with government instructors, books vanished from classroom shelves and ultimately, Communist Party officials took over his dad's tiny sandwich stand.\n\nNow the self-made billionaire and longtime Republican campaign donor watches uncomfortably from South Florida as President Donald Trump takes many of the same steps he saw under Fidel Castro.\n\nLike many people who fled to the United States from authoritarian regimes, Fernandez says the United States appears to be at a tipping point, with Trump centralizing power to silence dissent and punish people he's declared enemies, while bullying private businesses to fall in line.\n\n\"There's something wrong, and we all know it,\" Fernandez told USA TODAY. \"Many people are hoping it's going to go away on its own, and it's not going to go away on its own.\"\n\nThe billionaire émigré added: \"I'm scared of how fast we're moving.\"\n\nTrump argues that the 2024 election he won represents a mandate from American voters who endorsed his muscular leadership approach. Trump has justified his actions as necessary to secure the United States from both an \"invasion\" of immigrants and what he describes as the unwillingness of Democratic officials to stamp out visible homelessness, halt certain types of crimes and prevent civil disorder.\n\nA historical analysis by Gallup shows Trump's approval ratings in August of his first years in office − both as the 45th and 47th presidents − are lower than any other modern president at the same time in their administrations. In Gallup's polling, roughly 40% currently approve of Trump's job performance.\n\nDespite the unfavorable polling, Trump has repeatedly suggested that he would serve a third term as president ‒ although the Constitution prevents him from being elected again ‒ and openly mused about how other countries have canceled elections during war or other national emergencies.\n\nWarning signs of authoritarianism\n\nPeople who have fled authoritarian regimes say it's a combination of actions that are cause for concern right now in the United States, especially after Trump declared at activist Charlie Kirk's funeral that he \"hates\" his opponents. Those interviewed by USA TODAY raised a host of parallels they see between the authoritarian leadership of their native countries and Trump's actions over the last eight months:\n\n◾Routine use of military forces to disperse anti-government protests, especially over the objection of local officials, as happened in California and Washington, DC.\n\n◾Declarations that certain rights, especially for certain groups, must be curtailed because of a national emergency, such as ending due process hearings for accused undocumented immigrants.\n\n◾Singling out minority groups for harsh and selective prosecutions, often based on old laws. The White House has argued its immigration crackdown largely reflects a return to enforcing existing law that successive past presidents ignored.\n\n◾Reduced access to legal counsel, especially for those targeted minority groups.\n\n◾Nationalization of businesses deemed critical to the government's success. Trump announced on Aug. 22 that the federal government would purchase a 10% stake in struggling chipmaker Intel, and has expressed interest in buying into other companies as well.\n\n◾Frequent reminders of the government's power and role in dominating public life, in part. with monuments and banners dedicated to the leader. Earlier this year, three federal buildings in Washington were festooned with giant images of the president.\n\n◾Lack of free and fair elections, with leaders manipulating the system to remain in power. Trump has pressured several Republican-led states, including Texas, to redistrict to make it easier for Republicans to win seats in Congress. He has also spoken against popular mail-in ballots, saying without evidence that they are ripe for fraud.\n\n◾Using government power to punish or silence opponents and journalists, and declaring them enemies, as Trump has most recently done with late-night host Jimmy Kimmel.\n\nThe Trump administration has argued that each one of these actions is necessary and consistent with its Make America Great Again agenda, and that the Biden administration was guilty of many seemingly authoritarian measures, too.\n\nTanks as common as ice cream trucks\n\nFor Eddie Flores, growing up in El Salvador meant seeing military tanks rolling through neighborhoods as often as ice cream trucks. Flores' family fled the country's devastating civil war when he was 7.\n\nLast year, he became the first Salvadoran-born immigrant elected mayor of South San Francisco.\n\nNow, along with balancing the city's biotech cluster and creeping gentrification, he's also helping coordinate neighborhood groups opposed to Trump's mass immigration sweeps. More than a third of the city’s residents are Hispanic, and despite concerns ahead of the city’s popular Cultura Fest in August, no disruptions occurred.\n\nIn the Los Angeles area, Trump's Immigration and Customs Enforcement agents have swept up thousands of undocumented immigrants, sometimes chasing them through the streets or farm fields. Protests against the ICE raids became violent, and Trump then deployed active-duty Marines and members of the California National Guard onto city streets over the objection of local officials.\n\nTrump has also deployed the National Guard to Washington, DC, and has threatened to unleash his newly renamed \"Department of War\" into Chicago.\n\n\"I constantly tell my staff that we have to remain proactive and have systems in place before any harm arrives,\" Flores said. \"It's about consistently showing up for your neighbors, not just when they are in need, so they don't have to live in the shadows.\"\n\nHe added: \"Authoritarianism has no place in a country built on pluralism, and we as leaders have to safeguard that promise.\"\n\nRecognizing patterns of behavior\n\nFor a 41-year-old immigrant from the Middle East, the United States had long been a bastion of freedoms ‒ a place where the right to criticize the government is written into the nation's founding documents. Several members of his family have been detained in his home country for years for speaking out against their leaders.\n\n\"We came here to express ourselves and have found ourselves in this dilemma that we'd never thought we'd face,\" said the man, who USA TODAY agreed not to identify.\n\nThe man, a legal researcher who lives legally in the United States, is worried he might be targeted by the federal government for speaking freely. \"It's very, very ironic that we now suggest to folks who are visiting us from outside the United States to delete apps, delete text conversations, delete images, even though they are completely innocent.\"\n\nThe man, who is also a human rights expert for a nonprofit, said he's watched in fear as Trump has attacked the rule of law, singled out minority groups for harsh prosecution and declared emergencies or accused people of terrorism to justify some of his actions. He said Americans should heed the warnings of refugees like him who have lived under oppressive regimes and can recognize the patterns playing out.\n\nIt's easy for people in society's mainstream to think what's happening to minority groups will never happen to them, he said, adding that he has been disappointed more Americans haven't been trying to halt Trump, given the country's founding system of checks and balances brought by the courts, Congress and a free press.\n\n\"It's going to reach you at some point, and when it does, there'll be nobody there for you because you were never there for them,\" he said.\n\nEchoing childhood memories\n\nLike many other people who sought safety in the United States, Davis, California, resident Griselda Gonzalez said watching federal troops patrolling Los Angeles conjured up painful childhood memories.\n\nThe Salvadoran native can vividly recall when she was 10, as guerrilla fighters stormed her hometown of San Salvador, the nation’s capital. The complex and brutal civil war in her country killed thousands. Visions of explosions and constant gunfire, even in the smallest neighborhoods, sometimes pop into her head.\n\nToday, she's a married mother of three with a successful family-owned commercial moving company. But she said she's shocked by how much the United States now resembles the country she fled: constant threats of military deployments, along with ICE raids targeting people who look like her.\n\n\"Five years ago, we were all fighting for our lives with COVID-19,\" said Gonzalez, who became a naturalized citizen in 2014. \"Now we're worried about fighting for our basic rights?\"\n\nDone staying quiet\n\nFernandez, the Cuban refugee and American-made billionaire, became a U.S. citizen after serving as an Army paratrooper. He said he's long been content to influence U.S. politics by funding political candidates, most of them Republicans.\n\nBut after watching how Trump and the people around him are behaving ‒ including Secretary of State Marco Rubio, whom he once strongly supported ‒ Fernandez said he's done staying quiet.\n\nHe has begun funding a pro-immigrant campaign, bought anti-Trump advertisements in newspapers and is preparing to spend his fortune fighting what he sees as creeping authoritarianism and tyranny within the United States.\n\n\"If I go back to zero, I will do so because I came here with nothing and I owe this country to reinvest to defend it from within,\" Fernandez said. \"I think I owe it to the country. I owe it to my children and grandchildren to come back to a place where due process matters.\"\n\nThe American people have more power than they think, Fernandez said.\n\n\"The more we speak as a group, the less likely we are to be targeted. I see myself being targeted already. Will I stop? No,\" he said, encouraging everyone to speak out against what he sees as the president's anti-Americanism.\n\n\"America used to be a great country,\" he added. \"It isn't anymore, in the way it's been designed by the current administration.\"\n\nTrevor Hughes and Terry Collins are National Correspondents at USA TODAY.",
      "source": "USA Today",
      "url": "https://www.usatoday.com/story/news/politics/2025/09/28/trump-makes-immigrants-nervous-authoritarian-dictator/86064657007/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Nvidia’s $100 billion OpenAI investment raises eyebrows and a key question: How much of the AI boom is just Nvidia’s cash being recycled?",
      "content": "Nvidia’s announcement earlier this week that it is investing $100 billion into OpenAI to help fund its massive data center build out has added to a growing sense of unease among investors that there is a dangerous financial bubble around AI, and that the revenues and earnings math underpinning the valuations of both public and private companies in the sector just doesn’t add up.\n\nWhile Nvidia’s latest announcement is by far the largest example, the AI chipmaker has engaged in a series of “circular” deals in which it invests in, or lends money to, its own customers. Vendor financing exists to some degree in many industries, but in this case, circular transactions may give investors an inflated perception of the true demand for AI.\n\nIn past technology bubbles, revenue “roundtripping” and tech companies financing their own customers have exacerbated the damage when those bubbles eventually popped. While the share of Nvidia’s revenues that are currently being driven by such financing appears to be relatively small, the company’s dominance as the world’s most valuable publicly-traded company means that its stock is “priced for perfection” and that even minor missteps could have outsized impact on its valuation—and on financial markets and perhaps even the wider economy.\n\nThe extent to which the entire AI boom is backstopped by Nvidia’s cash isn’t easy to answer precisely, which is also one of the unsettling things about it. The company has struck a number of investment and financing deals, many of which are too small individually for the company to consider “material” and report in its financial filings, even though collectively they may be significant.\n\nIn addition, there are so many interlocking rings of circularity—where Nvidia has invested in a company, such as OpenAI, that in turn purchases services from a cloud service provider that Nvidia has also invested in, which then also buys or leases GPUs from Nvidia—that disentangling what money is flowing where is far from easy.\n\nTangled webs of investment\n\nTwo of the most prominent examples of Nvidia’s web of circuitous investments are OpenAI and Coreweave. In addition to the latest investment in OpenAI, Nvidia had previously participated in a $6.6 billion investment round in the fast-growing AI company in October 2024. Nvidia also has invested in CoreWeave, which supplies data center capacity to OpenAI and is also an Nvidia customer. As of the end of June, Nvidia owned about 7% of Coreweave, a stake worth about $3 billion currently.\n\n\n\nThe benefits that companies get from a Nvidia investment extend beyond the cash itself. Nvidia’s equity stakes in companies such as OpenAI and Coreweave enable these companies to access debt financing for data center projects at potentially significantly lower interest rates than they would be able to access without such backing. Jay Goldberg, an analyst with Seaport Global Securities, compares such deals to someone asking their parents to be a co-signer on their mortgage. It gives lenders some assurance that they may actually get their money back.\n\nStartups financing data centers have often had to borrow money at rates as high as 15%, compared to 6% to 9% that a large, established corporation such as Microsoft might have to pay. With Nvidia’s backing, OpenAI and Coreweave have been able to borrow at rates closer to what Microsoft or Google might pay.\n\n\n\nNvidia has also signed a $6.3 billion deal to purchase any cloud capacity that CoreWeave can’t sell to others. The chipmaker had previously agreed to spend $1.3 billion over four years on cloud computing with CoreWeave. Coreweave, meanwhile, has purchased at least 250,000 Nvidia GPUs so far—the majority of which it says are H100 Hopper models, which cost about $30,000 each—which means Coreweave has spent about $7.5 billion buying these chips from Nvidia. So in essence, all of the money Nvidia has invested in Coreweave has come back to it in the form of revenue.\n\n\n\nNvidia has struck similar cloud computing deals with other so-called “neo-cloud” companies. According to a story in The Information, Nvidia agreed this summer to spend $1.3 billion over four years renting some 10,000 of its own AI chips from Lambda, which like Coreweave runs data centers, as well as a separate $200 million deal to rent some 8,000 more over an unspecified time period.\n\nFor those who believe there’s an AI bubble, the Lambda deal is clear evidence of froth. Those Nvidia chips Lambda is renting time on back to Nvidia? It bought them with borrowed money collateralized by the value of the GPUs themselves.\n\n\n\nBesides its large investments in OpenAI and Coreweave, AI chipmaker also holds multi-million dollar stakes in several other publicly-traded companies that either purchase its GPUs or work on related chip technology. These include chip design firm Arm, high-performance computing company Applied Digital, cloud services company Nebius Group, and biotech company Recursion Pharmaceuticals. (Nvidia also recently purchased a 4% stake in Intel for $5 billion. Like Arm, Intel makes chips that in some cases are alternatives to Nvidia’s GPUs, but which for the most part are complementary to them.)\n\nEarlier this month, Nvidia also pledged to invest £2 billion ($2.7 billion) in U.K. AI startups, including at least £500 million in Nscale, a U.K.-based data center operator that will, presumably, be using some of that money to purchase Nvidia GPUs to provision the data centers it is building. Nvidia also said it would invest in a number of British startups, both directly and through local venture capital firms, and some of that money too, will likely come back to OpenAI in the form of computing purchases, either directly, or through cloud service providers, who in turn will need to buy Nvidia GPUs.\n\n\n\nIn 2024, Nvidia invested about $1 billion in AI startups globally either directly or through its corporate venture capital arm NVentures, according to data from Dealroom and The Financial Times. This amount was up significantly from what Nvidia invested in 2022, the year the generative AI boom kicked off with OpenAI’s debut of ChatGPT.\n\n\n\nHow much of this money winds up coming right back to Nvidia in the form of sales is again, difficult to determine. Wall Street research firm NewStreet Research has estimated that for every $10 billion Nvidia invests in OpenAI, it will see $35 billion worth of GPU purchases or GPU lease payments, an amount equal to about 27% of its annual revenues last fiscal year.\n\nEchoes of the dotcom era\n\nThat kind of return would certainly make this sort of customer financing worthwhile. But it does raise concerns among analysts about a bubble in AI valuations. These kinds of circular deals have been a hallmark of previous technology bubbles and have often come back to haunt investors.\n\nIn this case, the lease arrangements that Nvidia is entering into with OpenAI as part of its latest investment could prove problematic. By leasing GPUs to OpenAI, rather than requiring them to buy the chips outright, Nvidia is sparing OpenAI from having to take an accounting charge for the high depreciation rates on the chips, which will ultimately help OpenAI’s bottom line. But it means that instead Nvidia will have to bear this depreciation costs. What’s more, Nvidia will also take on the risk of being stuck with an inventory of GPUs no one wants if demand for AI workloads don’t match Nvidia CEO Jensen Huang’s rosy predictions.\n\n\n\nTo some market watchers, Nvidia’s latest deals feel all-too-similar to the excesses of past technology booms. During the dot com bubble at the turn of the 21st Century, telecom equipment makers such as Nortel, Lucent, and Cisco lent money to startups and telecom companies to purchase their equipment. Just before the bubble burst in 2001, the amount of financing Cisco and Nortel had extended to their customers exceeded 10% of annual revenues, and the amount of financing the top five telecom equipment makers had provided to customers exceeded 123% of their combined earnings.\n\n\n\nUltimately, the amount of fiber-optic cabling and switching equipment installed far exceeded demand, and when the bubble burst and many of those customers went bust, the telecom equipment makers were left holding the bad debt on their balance sheets. This contributed to a greater loss of value when the bubble burst than would have otherwise been the case, with networking equipment businesses losing more than 90% of their value over the ensuing decade.\n\n\n\nWorse yet were companies such as fiber-optic giant Global Crossing that engaged in direct “revenue roundtripping.” These companies cut deals—often at the end of a quarter in order to hit topline forecasts—in which they paid money to another company for services, and then that company agreed to purchase equipment of exactly equal value. When the bubble burst, Global Crossing went bankrupt, and its executives ultimately paid large legal settlements related to revenue roundtripping.\n\n\n\nIt is memories of these kinds of transactions that have caused analysts to at least raise an eyebrow at some of Nvidia’s circular investments. Goldberg, the Seaport Global analyst, said the deals had a whiff of circular financing and were emblematic of “bubble-like behavior.”\n\n“The action will clearly fuel ‘circular’ concerns,” Stacy Rasgon, an analyst with Bernstein Research, wrote in an investor note following Nvidia’s announcement of its blockbuster investment in OpenAI. It’s a long way from a concern to a crisis, of course, but as AI company valuations get higher, that distance is starting to close.",
      "source": "Fortune",
      "url": "https://fortune.com/2025/09/28/nvidia-openai-circular-financing-ai-bubble/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Intel quietly makes aggressive move to repair recent failures",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/96e713cbf767d8ca",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Top Wall Street analysts favor these 3 stocks for their robust growth outlook",
      "content": "The Nvidia logo is displayed on a building at Nvidia headquarters on Aug. 27, 2025 in Santa Clara, California.\n\nDespite macroeconomic uncertainties, several companies are well-positioned to deliver strong returns to investors from rapid technological advancements and artificial intelligence (AI) adoption.\n\nTo pick attractive stocks with strong prospects, investors can track top Wall Street analysts, whose recommendations are based on in-depth research and analysis of a company's financials and growth drivers.\n\nHere are three stocks favored by the Street's top pros, according to TipRanks, a platform that ranks analysts based on their past performance.\n\nNvidia\n\nWe start with semiconductor giant Nvidia (NVDA), which has strengthened its dominant position through continued innovation and strategic deals, such as the recently announced $5 billion investment in Intel and massive $100 billion investment in OpenAI.\n\nFollowing a conversation with Nvidia's CFO on the OpenAI deal, Evercore analyst Mark Lipacis reiterated a buy rating on NVDA, saying the chip company is the \"AI ecosystem of choice, not just with its CUDA software stack, but also with its connectivity solution, NVLink, which we think is poised to become a de facto standard.\"\n\nThe top-rated analyst increased his price target on Nvidia to $225 from $214 and said that Nvidia remains a top pick for Evercore. TipRanks' AI Analyst has an \"outperform\" rating on Nvidia stock with a price target of $204.\n\nHighlighting the key takeaways from his conversation with the company's CFO, Lipacis said that Nvidia will be the preferred supplier to OpenAI, adding that the ChatGPT platform has underestimated demand for its solution and wants to get ahead of future demand. Nvidia is well-positioned to help OpenAI with this infrastructure buildout.\n\nLipacis noted that the deal specifies at least 10 GW (gigawatts) of AI infrastructure, and Nvidia management confirmed that, historically, the company's total addressable market (TAM) was $30 billion to $40 billion per GW, although it could increase in the future. The analyst increased his 2026 revenue and earnings per share (EPS) estimates by 2% for Nvidia, but thinks that his forecast may be conservative.\n\nLipacis ranks No. 53 among more than 10,000 analysts tracked by TipRanks. His ratings have been successful 66% of the time, delivering an average return of 26.5%. See Nvidia ETF Exposure on TipRanks.\n\nMongoDB\n\nNext is database management software company MongoDB (MDB). The company recently held a MongoDB.local event in New York City, hosting an Investor Session focused on profitable growth and providing a 3- to 5-year financial framework.\n\nFollowing the event, Needham analyst Mike Cikos reiterated a buy rating on MongoDB and increased his price target to $365 from $325. TipRanks' AI Analyst is also bullish on MDB stock, giving it an \"outperform\" rating and a price target of $355.\n\nCikos said that while investors' initial reaction to the high-teens revenue growth forecast was underwhelming, he expects both AI and competitive migrations to drive incremental growth for MongoDB.\n\nThe 5-star analyst noted that management plans to continue investing in the business, though at a slower rate than revenue and gross profit growth. MongoDB's investments will mainly focus on developer awareness, research & development and its sales force.The company has also identified areas for optimization and expects its scale to drive profitable growth through efficiencies.\n\nCikos said that following the MongoDB.local event he is \"incrementally more positive on MongoDB's AI positioning,\" driven by embeddings, which bridge data and Large Language Models (LLMs), and the continued integration of Voyage's best-in-class models.\n\nCikos ranks No. 581 among more than 10,000 analysts tracked by TipRanks. His ratings have been profitable 59% of the time, delivering an average return of 14.1%. See MongoDB Ownership Structure on TipRanks.",
      "source": "CNBC",
      "url": "https://www.cnbc.com/2025/09/28/top-wall-street-analysts-favor-these-3-stocks-for-robust-growth.html",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Obama’s final booby trap",
      "content": "Skip to comments.\n\nObama’s final booby trap\n\nAmerican Thinker ^ | 27 Sep, 2025 | Gerald McGlothlin\n\nPosted on by MtnClimber\n\nIn the final days of the Obama presidency — while Americans were focused on inaugurating a new president and turning the page on a divisive era — President Barack Obama signed a quiet but sweeping executive order that many now see as a ticking time bomb planted in the heart of our Intelligence Community.\n\nOn January 3, 2017, just 17 days before Donald Trump’s inauguration, Obama signed a modification to Executive Order 12333, authorizing the National Security Agency (NSA) to share raw signals intelligence (SIGINT) with all 16 other intelligence agencies — including the FBI, the CIA, and even obscure agencies like the Drug Enforcement Administration’s intel wing.\n\nAt face value, the stated purpose was to “streamline intelligence sharing” and “improve coordination” in the age of global terrorism. But conservatives saw something else: a calculated move to weaponize the intelligence apparatus against a political outsider — Donald J. Trump — before he could even take the oath of office.\n\nFrom Terrorism to Trump? The Convenient Shift\n\nPrior to this change, the NSA — which vacuumed up massive amounts of phone calls, emails, texts, and metadata — could share only filtered, “minimized” intelligence with other agencies. That meant masking the names of American citizens incidentally caught up in foreign surveillance.\n\nBut Obama’s executive order reversed that policy, allowing raw, unredacted data — including conversations of U.S. citizens — to be freely distributed across the Intelligence Community. In short, the firewalls were gone. The surveillance spigot was opened.\n\nWhy now? Why not during his eight years in office?\n\nThese are the questions conservatives have been asking ever since.\n\nA Leak Pipeline Disguised as Reform\n\nWithin weeks of the order, classified leaks about members of Trump’s incoming administration began flowing.\n\nThe most prominent example? Lt. General Michael Flynn.\n\n\n\n(Excerpt) Read more at americanthinker.com ...\n\nTOPICS:\n\nSociety\n\nKEYWORDS:\n\nantichristobama\n\nbarackhusseinobama\n\nlawfare\n\nmuslim\n\nobama\n\nr\n\nspiritofantichrist\n\ntraitor\n\n\n\n\n\nTo: MtnClimber\n\nNow it President Trump’s duty to defuse the weaponized government.\n\n\n\nby 2 posted onby MtnClimber (For photos of scenery, wildlife and climbing, click on my screen name for my FR home page.)\n\nTo: MtnClimber\n\n“When we’re done he’ll claim Kenyan citizenship as a way to escape.”\n\n\n\nby 3 posted onby C210N (Mundus vult decipi, ergo decipiatur.)\n\nTo: MtnClimber\n\nWhere is that meme of jug ears listening to Trump on his super secret headphones? They bugged Emporer Trump!\n\n\n\nby 4 posted onby Kudsman (Emulate Charlie, not the left.)\n\nTo: MtnClimber\n\nObama’s parting gift was a booby-trapped surveillance infrastructure, tailor-made to hinder anyone who dared challenge the political establishment. Well turn it on! Turn it on the Antifa in Portland. Turn it on the Mayor in Chicago, turn it on those NGO’s and their funders like Soto and lastly turn it on a few select Democrats. After all Omaba did the same and worst so no complaints boys and girls! Trump is just following the law!\n\n\n\nby 5 posted onby Lockbox (politicians, they all seemed like game show host to me.... Sting)\n\nTo: C210N\n\nFine by me if they can permanently deport him there.\n\n\n\nby 6 posted onby Vigilanteman (The politicized state destroys many aspects of civil society, human kindness and private charity.)\n\nTo: C210N\n\nFine by me if they can permanently deport him there.\n\n\n\nby 7 posted onby Vigilanteman (The politicized state destroys many aspects of civil society, human kindness and private charity.)\n\nTo: MtnClimber\n\nWouldn’t Pres. Trump be allowed to nail Obama’s hide to the barn door if possible? Obama was a sneaky underhanded individual if there ever was one, it seems.....masquerading as a president. If he ever did anything good for this country,I don’t know what it was.\n\n\n\nTo: C210N\n\nBarekeh Hussein Obama covered his tracks well but apparently, not enough. The Faker and Chief thought he was immune from a critical eye and review. Now his only concerns are his luxurious properties, his so-called “Presidential Library” (which looks like something out of “Blade Runner” and how not to anger Michelle Obama who would easily put the metrosexual Barekeh in a full Nelson and snap his spine.\n\n\n\nby 9 posted onby Netz ( and looking for a way ti IMPROVE mankind.)\n\nTo: MtnClimber\n\nThere were reports in the press bragging about the land mines Obama planted to destroy the incoming Trump admin. Nothing was secret. We knew the details of the Obama coup for years. It’s sad that after all these years we have only an indictment of Comey.\n\n\n\nTo: MtnClimber\n\nForty years ago, while in the\n\npolice academy, our class was addressed by an F B.I. agent\n\nWho informed us of the toxic\n\nhubris of many his fellow agents, especially, the supervisors, generally.\n\nThe disease is common among\n\nsupervising climbers in those kinds of vocations.\n\nI was 37 years on the trade...\n\nSame as it always has been.\n\nNo surprise: ego kills honesty and rational perspective.\n\nSome people simply just suck.\n\n\n\nby 11 posted onby dasboot (Nuanced foreign relations is the germ of international misunderstanding. )\n\nTo: MtnClimber\n\nForty years ago, while in the\n\npolice academy, our class was addressed by an F B.I. agent\n\nWho informed us of the toxic\n\nhubris of many his fellow agents, especially, the supervisors, generally.\n\nThe disease is common among\n\nsupervising climbers in those kinds of vocations.\n\nI was 37 years on the trade...\n\nSame as it always has been.\n\nNo surprise: ego kills honesty and rational perspective.\n\nSome people simply just suck.\n\n\n\nby 12 posted onby dasboot (Nuanced foreign relations is the germ of international misunderstanding. )\n\nTo: MtnClimber\n\nForty years ago, while in the\n\npolice academy, our class was addressed by an F B.I. agent\n\nWho informed us of the toxic\n\nhubris of many his fellow agents, especially, the supervisors, generally.\n\nThe disease is common among\n\nsupervising climbers in those kinds of vocations.\n\nI was 37 years on the trade...\n\nSame as it always has been.\n\nNo surprise: ego kills honesty and rational perspective.\n\nSome people simply just suck.\n\n\n\nby 13 posted onby dasboot (Nuanced foreign relations is the germ of international misunderstanding. )\n\nTo: MtnClimber\n\nForty years ago, while in the\n\npolice academy, our class was addressed by an F B.I. agent\n\nWho informed us of the toxic\n\nhubris of many his fellow agents, especially, the supervisors, generally.\n\nThe disease is common among\n\nsupervising climbers in those kinds of vocations.\n\nI was 37 years on the trade...\n\nSame as it always has been.\n\nNo surprise: ego kills honesty and rational perspective.\n\nSome people simply just suck.\n\n\n\nby 14 posted onby dasboot (Nuanced foreign relations is the germ of international misunderstanding. )\n\nTo: MtnClimber\n\n.\n\n\n\nTo: MtnClimber\n\n“President Trump’s duty to defuse the weaponized government.” Getting himself free must be a priority since he is POTUS and leader of MAGA.\n\n\n\nby 16 posted onby equaviator (Nobody's perfect. That's why they put pencils on erasers!)\n\nTo: MtnClimber\n\n\"Now it President Trump’s duty to defuse the weaponized government. Yet there was a time many on FR advocated for removing the firewalls between law enforcement and intelligence agencies so as to prevent terrorism. Even with a Trump EO had do you put the surveillance genie back in the bottle given the Patriot Act is still in the books.\n\n\n\nby 17 posted onby buckalfa (More chaos and disruption please.)\n\nTo: MtnClimber\n\nI wonder who created the document for Barry Soetero to sign?\n\n\n\nTo: GOPJ; poconopundit; Jane Long; Diana in Wisconsin; Grampa Dave; Godzilla; Vaduz; null and void; ...\n\nOn January 3, 2017, just 17 days before Donald Trump’s inauguration, Obama signed a modification to Executive Order 12333, authorizing the National Security Agency to “share raw signals intelligence” (SIGINT) with all 16 other intelligence agencies — including the FBI, the CIA, and even obscure agencies like the Drug Enforcement Administration’s intel wing....... Obama’s stated purpose was to “streamline intelligence sharing” and “improve coordination” in the age of global terrorism. But conservatives saw a calculated Obama move to “weaponize” the intelligence apparatus against Donald J. Trump — before he could even take the oath of office.\n\n\n\nby 19 posted onby Liz (May you be in Heaven half an hour before the devil knows you're dead (Irish blessing))\n\nTo: MtnClimber\n\nWe should not forget George W. Bush’s Patriot Act, which preceded Barack Obama, was a major factor in the weaponization of federal power against US citizens. The secret courts created in the name of counter terrorism were a major violation of the Bill of Rights. The Patriot Act allowed the government to trample on due process rights guaranteed by the Constitution. This was the product of a Republican president who claimed to be a conservative.\n\n\n\nDisclaimer: Opinions posted on Free Republic are those of the individual posters and do not necessarily represent the opinion of Free Republic or its management. All materials posted herein are protected by copyright law and the exemption for fair use of copyrighted works.\n\nFreeRepublic , LLC, PO BOX 9771, FRESNO, CA 93794\n\nFreeRepublic.com is powered by software copyright 2000-2008 John Robinson",
      "source": "Freerepublic.com",
      "url": "https://freerepublic.com/focus/f-chat/4343088/posts",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "IBM Intellistation 185 AIX workstation",
      "content": "Released in 2006 after the 285, this system used the PowerPC 970 processors (sometimes erroneously categorized under POWER5 by 3rd parties and at IBM--it would technically be closer to a POWER4). Despite POWER5+ and DDR2 already being used on the 285, the 185 took a few steps back and used DDR1 and didn't bother with the POWER chips. While this may seem rather strange, it can be explained with System p5 185 (7037-A50). Perhaps IBM wanted to create a machine of their own with the PPC 970 or it was stuck in developmental hell for a bit, whatever the case IBM used the 7037 guts to be modified into the IntelliStation 185. This move could have been done to offer a workstation that used less power and was quieter / while still maintaining AIX compatibility. Hundreds went to use in government offices and engineering firms; as a result they mainly show up in the U.S. and Japan.\n\nMost of the POWER and AIX people don't even know that IBM badged the 970 under POWER and popped it into a workstation; therefore making the IntelliStation \"POWER\" 185 a source of confusion, horror and intrigue--and the fact it's relatively unknown means you'll get different responses as to what it can and cannot do. It is still a POWER system in firmware, and supports hardware virtualization like any other POWER system, which makes it completely different from a Power Mac G5 which uses the same CPU. If it didn't support hardware virtualization IBM wouldn't have been able to call the original System p5 185 a System p5... it would just be a plain PowerPC box. But this wasn't too unfamiliar as other AIX systems in the past also leveraged PowerPC chips like RS/6000s and PowerPC ThinkPads. I suspect the whole reason why the PowerPC 970MP had virtualization in the first place was because of IBM's exact requirement for this on their System p5 that they were intending to use it in (which Apple never did on the G5 as far as I know), and then of course Apple wanted AltiVec (which IBM didn't use in AIX as far as I know, but that doesn't mean you couldn't write AIX software to leverage it).\n\nDownloads\n\n--> Latest System Firmware (AT071-156, RPM package) - 05/11/2007\n\nDue to IBM's licensing agreements I am not entitled to distribute the firmware update as it's licensed code. Therefore the above link redirects to IBM's legacy firmware page where it can be downloaded. If the firmware ever gets pulled from the website I will consider mirroring it.\n\n--> IBM IntelliStation POWER 185 Hardware Announcement - February 14, 2006\n\n--> IBM IntelliStation POWER 185 RedBook Overview\n\n--> Quick Start Guide for IntelliStation POWER 185\n\n--> Installing SUSE Linux Enterprise Server 9 SP3 on POWER 185\n\n--> Installing Red Hat Enterprise Linux AS 4 Update 3 on POWER 185\n\n--> TAGITT-CATIA V4/ENOVIA DMU Evaluation\n\n---\n\n--> UNIX Workstations Facts and Features (2006)\n\n--> System i & p PCI adapters (44 MB!)\n\n--> System i & p fans\n\n--> IBM IntelliStation POWER and IBM RS/6000 Graphics Performance Report\n\n--> IBM Installation Toolkit 4.2 Release Notes\n\n--> IBM Installation Toolkit 4.2 User's Manual\n\n--> RS/6000 SpaceBall Announcement on AIX\n\n---\n\n--> 3Dconnexion 3DxWare AIX Driver (1.6.0 11/29/2011)\n\n--> 3Dconnexion Xdriver AIX 5+ (4.66 11/18/2005)\n\nNote: it seems that the 3DxWare driver should support the SpaceBall and SpaceMouse, along with offering new support for the SpacePilot and SpaceExplorer on AIX. However if that's not the case the older Xdriver can be used.\n\n--> Open Sound System for AIX (OSS/AIX v3.9.8g)\n\nNote: you must purchase a license from 4Front Technologies to activate OSS/AIX (while it's released as open source the old UNIX versions are not).\n\nPowerPC 970MP running in single-core?\n\nIt may sound strange but the IntelliStation POWER 185 is in fact running the PowerPC 970MP \"dual core\" chip in single core mode. This is undocumented on the PPC 970MP datasheet and not implemented on anything else as far as I can tell. I'm not exactly sure how this was achieved but it's either a hidden switch on the PPC970MP or a special switch done through firmware. The reason why this was done was to reduce the thermal requirements for a smaller system and smaller heatsink; as a work-around IBM then offered adding a second PowerPC 970MP in the IntelliStation 185 (also running in single-core mode) to simulate a \"dual-core\" PowerPC 970MP setup through two discreet chips instead of one.\n\n7037-A50 or 7047-185, which came first\n\nIt's easy to tell the 7037-A50 came first based on the fact documentation always shows the system with a 7037 bezel instead of the characteristic one present on 7047: even on the IntelliStation POWER 185's service diagram on the metal door. Furthermore based on the timing, where IBM felt they needed a lower-end IntelliStation POWER to complement the already released 285 / why create a system from scratch when the upcoming 7037 design could be used. It gets somewhat interesting because this means the IntelliStation 185's bezel was designed after-the-fact, as a result that's why it is so thick on the front to compensate for the slanting that's characeristic of (most) IntelliStations. However, vendors and IBM constantly mix 7037 and 7047 in stock photos and documentation. The photo below shows a 7037 and you can see how it is inspired by 9228--oh and the bezel is flush against the front:\n\nThe story doesn't end there... System p5 185 sold *so* poorly (and was more work for IBM to support due to the PPC 970 that really should have never been considered p5) that IBM discontinued it a year after its release in 2007, while the IntelliStation 185 continued to be sold until 2009.\n\nDeceptive as a Greyghost (PC Server 500)\n\nThe IntelliStation 185 POWER was aimed towards CAD running under AIX, and had a specific emphasis on quiet operations, as mentioned in the hardware announcement \"A quiet deskside form factor\". Unlike System x and the IntelliStation 9228 (which is based on a System x), these run amazingly quiet for what they are--which begs the question why couldn't have IBM calibrated the cooling of System x like the POWER 185 as the design (internally) is very similar to 9228?* In fact the original external appearance of 7037-A50 could be confused with 9228; so there was some inspiration between the two. A lot of attention was put into the acoustics as the system is lined extensively with foam, unlike the 9228 or even 7382 which hails as one of the poorest 'acoustic' performers and makes a similar sound to an IntelliStation POWER 285. The characteristic front fold baffle is also meant to reduce noise (and is actually a separate piece clipped in to the main bezel: the design would be rather complex to injection mold as a single piece).in).\n\n*I have confirmed System x towers can run fine with noctua fans / of course I suppose System x is not design to reside as a workstation, but still. The servers have thermal sensors so it would be VERY little effort for IBM to calibrate the fans at a slower RPM instead of hard-lining at a higher-than-necessary value--'desktop mode' could even be added to the UEFI. Even worse, the IntelliStation 6225 was never shipped with a rear fan when it's REALLY ideal to have one (else the FSB can get up to 90C), and when a rear fan is installed the controller throttles it down to a few *hundred* RPM. I suppose different engineers were involved with the RPM tuning on 7047-185, 7382, 9228, 9229 and 6225 so I shouldn't be that critical.\n\nHere with the IntelliStation POWER 185 opened up into pieces you can see the foam lining behind the front bezel along with the interior baffles being lined with foam. The foam on the front bezel was actually manually cut near the intake bezel to angle it off:\n\nIt's a workstation not a server\n\nSome mistake the IntelliStation POWER 185 as a \"server\" or try to say that IntelliStation POWERs in general are servers, but it was always meant as an end-user workstation typically involving CAD or industrial design. The correct \"server\" product would be system type 7037-A50, the A50 was modified to perform as a server and not a CAD workstation / and also features some differences supported PCI add-ons. It's still hard to distinguish the two when the workstations are directly derived from the servers.\n\nBy all means you can use an IntelliStation POWER as a server, but then it's being under-utilizing for what it can really do and missing an opportunity for getting the most out of AIX as a \"desktop\" OS. Something which is rarely exhibited with the phasing out of the CAD components the IntelliStations first brought to the table.\n\nUNIX high-end CAD meets its death\n\nWhen the ancients roamed the earth (2006), Dassault Systemes ported CATIA V5 and V6 to AIX, most likely by request from IBM. What's weird about this is that you'll be hard-pressed to find any references to CATIA being run on UNIX now, Dassault completely removed it but there's probably a story behind this as to why. If you go back to the Dassault Systemes website in early 2007, you'll see that they still reference support for Windows and all major flavours of UNIX--but there's one key phrase near the end where they say: \"Dassault Systemes has set up a certification program... (blah blah blah)... since the launch of V5, natively developed on windows NT Platform\". At that point Windows XP 32-bit was the most commonly used variant, and while you could run XP 64-bit (and IBM did have native support for it on the IntelliStation 9228), XP 64-bit had so many problems so most users were stuck with 3.9 GB of RAM. Therefore if we were to assume that UNIX and said UNIX hardware offered way more memory, it starts to make sense (not to mention that the drivers and video cards would be extremely optimized and had features nVidia and ATI didn't offer*--at the time--). This may be even supported further from the POWER 185 RedBook where IBM states: \"The addition of native 64-bit capability brings significant performance enhancements of CATIA V5 and ENOVIA DMU Navigator. Initial benchmarks indicate that for memory-intensive operations, such as analysis of large models, global performance is significantly increased. In addition, improvements to clash analysis greatly reduces processing times for analysis of large assemblies.\" It's also worth pointing out that CATIA predates Windows, so Dassault probably rewrote V5 from scratch on NT.\n\n*HP's HP-UX hardware being an exception since they just sloppily hacked in standard ATI cards / which means you wouldn't get the extra benefits of running a GXT6500 on AIX as you would with a FireGL X3 on HP-UX. HP probably had the lowest share of the UNIX CAD market so they probably felt little need to invest much R&D: not to mention HP can't make a proper enterprise workstation or server ANYWAYS.\n\nWhile the IntelliStation lineup was never involved with the sale of the PC division to Lenovo (and continued to press on for awhile), IBM dropped the x86 IntelliStations in 2006 and the POWER IntelliStations in 2009. Why did IBM bother to dedicate CAD resources to AIX when they were deliberately planning to phase out the platform? As established already, UNIX workstations were 'still a thing' back then and had advantages over the terrible x86 machines at the time (Windows XP with Pentium 4), and it was profitable for IBM (along with HP, SGI and Sun) to manufacture such computers. When x64 Windows 7 rolled by various changes in the market happened alongside it: Sun and SGI went out of business, HP started downsizing and split their enterprise into HPE, and Dassault Systemes dropped support for CAITA on UNIX. The UNIX CAD market had the carpet pulled from underneath and now UNIX was set aside for even more specialized applications.\n\nThe IntelliStation POWER lineup left a few remnants which are still gawked at by users of newer POWER7/8 systems, such as the high-performance CAD GPUs. AIX has never again received high performance video cards / apparently some IBM customers have complained of this, but not enough to warrant development on better AIX graphics cards. As a result, for more realistic graphics performance AIX users continue to use the IntelliStation cards.\n\nThere is a story underneath the death march of AIX workstations, if you look carefully you'll notice the GXT6500P was originaly announced in 2002 (along with the IntelliStation POWER 265). IBM never refreshed any of the GXT135P, GXT4500P and GXT6500P cards, still keeping them as \"current\" offerings for the IntelliStation POWER 185 and 285 . And soon as the last two of the POWER IntelliStations were made, other OEMs stopped making UNIX CAD stations and IBM quietly killed all IntelliStations, only leaving System x and System i behind (of course IBM has now even sold System x off in 2014 after the U.S. government reviewed the case as they used System x servers internally).\n\nPOWER Linux vs AIX on the IntelliStation POWER 185\n\nLet's get it out of the way: many think AIX will be dead soon and stipulate IBM is wanting clients to all mass migrate to POWER Linux (in fact, Watson was even programmed in POWER Linux and not AIX). The truth of the matter is that AIX contains more features that IBM or anyone else does not add in Linux. For instance, going through the RedBooks and Hardware Announcement, the higher-end CAD cards are not supported under Linux, RAS is not supported, the sound card is not supported and it goes on and on. In other words you're not going to use be using Linux for CAD, graphical operations or sound any time soon. While it may 'seem' IBM wants everyone on POWER Linux and not AIX, you can't use it as a workstation operating system unlike AIX.\n\nBecause the IntelliStation POWER 185 uses the aforementioned PowerPC 970, POWER Linux itself has limited support on the system. In the June 23 2009 hardware announcement, IBM confirms that SUSE Linux Enterprise Server 11 has dropped support for the PowerPC 970:\n\n\"SUSE Linux Enterprise Server 11 (SLES 11) for POWER supports all POWER5 and POWER6 technology-based systems with the exception of the OpenPower line of servers. It does not support any 970 based systems, which includes JS20, JS21, IBM System p5 185, and the IBM Intellistation POWER 185.\"\n\nWhereas on AIX 7.1 PPC 970 is still supported (note that AIX 7.2 dropped it, but so was the IntelliStation POWER 285):\n\n\"Only 64-bit Common Hardware Reference Platform (CHRP) machines running selected PowerPC 970, POWER4, POWER5, POWER6, and POWER7 processors that implement the POWER architecture Platform Requirements (PAPR) are supported.\"\n\nIt's therefore far more logical to use AIX to get the most out of the IntelliStation's workstation-oriented hardware, since POWER Linux has virtually nothing to offer for graphics support. While AIX and UNIX workstations in general are dead, you won't see such features revisted on newer AIX hardware / and it's *completely* omitted under POWER Linux.\n\nMeanwhile HPE and Intel seem to be having a hard time maintaining their Itanium contracts and want HP-UX to die / whereas AIX and POWER are in a much better position due to IBM's contributions to Linux and (now) OpenPOWER.\n\nOS Support\n\nAIX\n\nAIX 7.2 Not Supported\n\nAIX 5.1 Not Supported\n\nAIX 4.3.3 Not Supported\n\nAIX 4.2.1 Not Supported\n\nAIX 3.2.5 Not Supported\n\nAIX 7.1 SupportedAIX 6.1 SupportedAIX 5.3 SupportedAIX 5.2 Supported\n\nI'm not sure why (some) IBM documentation claims AIX 7.1 is not supported on the IntelliStation POWER 185 when it in fact is (yes! You can in fact run AIX 7.1 on a PowerPC 970 CPU).\n\nWARNING: AIX 7.1 wasn't designed with the System p5 185, or AIX workstations in mind anymore; so if you run AIX 7.1 on a system with a single PSU, you will get the rc.powerfail:2 being generated in the console every so often because AIX 7.1 is looking for a redundant power supply that does not exist. Kind of strange considering the System p5 185 lacks a second power supply as well and was sold as a server rack unit.\n\nPOWER Linux\n\nSUSE Linux Enterprise SLES 9 SP3\n\nRed Hat Enterprise AS4U3\n\n\n\nThe Great Purge of 2016\n\nThe U.S. Department of Defense was using a mass horde of IntelliStation POWER 185 units / and much of them have now been tossed back to IBM reselling channels. So, in early 2016 many appeared and obtaining one became a LOT cheaper. The timing is not a coincidence, IBM is phasing out the 185 in mid 2017 so corporate customers are being told to upgrade, or their leases are expiring (requiring a forced upgrade). The fact that some of these computers have been in service for 10 years is an example of how UNIX moves slowly and that the hardware was well built. Unlike other IBM systems, the IntelliStation POWER 185 is uniquely elusive for its age, I don't know if they will continue to drop in price or get more expensive as they reach unobtanium.\n\nIn one of IBM's client case studies, it is explained that they sold the Polish government 400 IntelliStation POWER 185 workstations / so we can assume a similar amount was also sold to the U.S. government (and in other places, too):\n\n\"The organization teamed with IBM Global Technology Services to implement a solution based on IBM Lotus Domino Collaboration Express software and the Lotus software-based iDoc offering from IBM Business Partner Advatech. The IBM staff loaded the new software on the client's fleet of 400 newly purchased IBM IntelliStation(R) POWER(TM) 185 Express workstations.\"\n\nI'm not sure how many of these IntelliStations were sold, maybe a few thousand at best? But if we were to take into consideration that a typical system would probably be around $8,000, times that by four hundred and you're looking at $3.2 million! Later the document explains that operating costs for the client were reduced as a result of using that IBM solution. I suppose in the grand scheme of things they would be--since they probably used them for 10 years / and since the hardware was so robust IBM wouldn't have to do any work on the service agreement.\n\nGPU options and caveats\n\nAs mentioned throughout, the IntelliStation 185 was geared towards CAD design and as such supported GPU options. Here are the three main GPUs that the system supports, it may be possible to run others but I have not tried it:\n\nGXT4500P (FC 2842 - IBM)\n\nGXT6500P (FC 2843 - IBM)\n\nGXT135P (FC 1980 - Matrox)\n\n\n\nThe GXT4500P and GXT6500P are the premier cards designed in-house by IBM; they only run properly on AIX and no Linux support exists. The GXT135P is a rebadged Matrox GT series card and runs under both AIX and Linux, but is far more limited in graphical capabilities. Apparently two GXT4500Ps can be ran in the IntelliStation, however I don't know if this will enable dual-monitor support. Only one GXT6500P can be ran in a system at a time. Up to FOUR GXT135Ps can be stuffed into an IntelliStation, this could theoreitcally allow eight monitors to be connected, however again, that would all depend if AIX could support it.\n\nFirmware options\n\nThe IntelliStation POWER 185 has an array of its own unique firmware options, similar to a BIOS/UEFI on a regular x86 computer. Below is what options you get when selecting to go into the firmware menu upon when the machine first starts up:\n\nMain Menu\n\n\n\n1 Select Language\n\n2 Setup Remote IPL (Initial Program Load)\n\n3 Change SCSI Settings\n\n4 Select Console\n\n5 Select Boot Options\n\n6 Power/Restart Control\n\n7 System Service Aids\n\n8 Set Beep Volume\n\n9 Select Keyboard\n\n\n\n\n\n--------------------------------------------------------------------------------\n\nNavigation keys:\n\nM = return to Main Menu N = Next page of list\n\nESC key = return to previous screen X = eXit System Management Services\n\n--------------------------------------------------------------------------------\n\nType menu item number and press Enter or select Navigation key\n\n\n\nBasically all of the options are self-explanatory really. I had to change the sound of the system beep since it was WAY too loud on its default setting. I chose 6.\n\nPCI adapter placement\n\nUnlike most computers, the IntelliStation POWER series can be sensitive what adapter is placed where: this is due to the way each slot is tied to the north bridge via the hyper transport tunnels and individual sub PCI bridges. There are a total of four PCI-X slots with a regular 32-bit PCI slot at the very top. Slots 2 & 3 have direct access and operate at 133 Mhz, slots 4 & 5 are shared and operate at 100 Mhz, slot 1 is a regular PCI slot and operates at 33 Mhz. Slot 5 can operate at 133 Mhz but only if slot 4 is empty, otherwise it runs at 100 Mhz.\n\nFeature code (FC) Base unit slot priority 7047-185 max. allowed adapters 2842 (GXT4500P) 2, 3 2 2843 (GXT6500P) 2 1 1954* 2, 3, 5/4 2 5740* 2, 3 2 1984* 2, 3, 5/4 3 5706* 2, 3, 5/4 3 5707* 2, 3, 5/4 3 1983* 2, 3, 5/4 3 1978* 2, 3, 5, 4 4 1979* 2, 3, 5, 4 4 5700* 2, 3, 5, 4 4 5701* 2, 3, 5, 4 4 5759** 2, 3, 5, 4 3 3 1910** 2, 3, 5, 4 3 3 1905* 2, 3, 5, 4 4 5758* 2, 3, 5, 4 4 1986* 2, 3, 5, 4 3 1987* 2, 3, 5, 4 3 5713* 2, 3, 5, 4 3 5714* 2, 3, 5, 4 3 1977, 5716* (Fibre Channel Adapter) 2, 3, 5, 4 1 1912* (Ultra320 LVD SCSI Adapter) 2, 3, 5, 4, 1 4 5736* 2, 3, 5, 4, 1 4 1913* (Ultra320 LVD SCSI RAID Adapter) 2, 3, 5, 4 4 5737* (Disk Controller) 2, 3, 5, 4 4 2849, 1980 (GXT135P) 2, 3, 4, 5 4 2947 (4-Port Multiprotocol Adapter) 4, 5, 3, 2 3 5723 (2-Port asynchronous Serial Adapter) 1, 4, 5, 3, 2 2 2943 (8-Port asynchronous Serial Adapter) 1, 4, 5, 3, 2 2 8244 (Crystal PCI Audio Adapter) 1 1\n\n** Extra-high bandwidth (EHB) adapter. See the Performance notes before installing this adapter.\n\n* High bandwidth (HB) adapter. See the Performance notes before installing this adapter.\n\n\n\nPerformance notes (for optimum performance)\n\nSystem unit information:\n\n-No more than three EHB adapters can be placed in the system. If an EHB adapter is placed in the system, it must be the only EHB or HB adapter attached to the PHB it uses.\n\n-No more than four HB adapters can be placed in the system\n\n-No more than three Gb Ethernet ports per PHB.\n\n-No more than three 1 Gb Ethernet ports per one CPU in a system. More Ethernet adapters can be added for connectivity.\n\n-If an adapter lists slot 5/4, this indicates the adapter can go in slot 5 or 4, but not both 5 and 4.\n\n\n\nControl Panel Functions\n\nOn the front of the IntelliStation POWER 185 the control panel pops out (pushing the tab sideways) and there are a fair bit of functions to choose from / the default boot (or IPL) would be set to 'N, F, P', then you simply press the power button and away it goes; you can also choose the 'service IPL' mode from the Open Firmware menu as well without ever having to touch the panel. Since some of these functions are specific to the IntelliStation 185 they're not entirely agnostic to other \"IPL\" systems or mainframes. I've extracted the function help from the IBM knowledgebase below. Quick trivia: the IntelliStation POWER 185's specific control panel has been borrowed and re-used in later POWER systems such as the Power 720 and Power S814, it's funny because not many know of this particular machine, yet parts of it live on, photo of it below.\n\nFunction 01: Display selected system operating mode, IPL speed, and firmware IPL mode\n\nThis function displays the selected system operating mode, speed, and firmware mode for the next IPL on the 7037-A50 server and the 7047-185 workstation. This function is available in both normal and manual operating mode. This function displays the following information:\n\n\n\nThe valid logical key modes (N).\n\nThe IPL speed (F).\n\nThe firmware mode (P or T).\n\n\n\nFunction/Data Action or description 0 1 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nUse the Increment or Decrement buttons to scroll to function 01. 0 1 _ _ _ _ _ N _ _ _ _ F _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ P _ _ _\n\nValid system operating mode is N.\n\nValid IPL speed display is F.\n\nValid firmware IPL modes are P and T.\n\nP = permanent side boot\n\nT = temporary side boot\n\n0 1 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nUse the Increment or Decrement buttons to scroll through the control panel functions.\n\nFunction 02: Select firmware IPL mode\n\nThis function allows you to select the firmware IPL mode on the 7037-A50 server and the 7047-185 workstation. This function is available in both normal and manual operating mode.\n\n\n\nFunction/Data Action or description 0 2 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nUse the Increment or Decrement buttons to scroll to function 02.. 0 2 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ P _ _ _ Press Enter to start function 02. The current firmware mode is displayed. 0 2 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ T < _ _\n\nUse the Increment or Decrement buttons to scroll through the firmware IPL modes. Valid firmware IPL modes are P and T.\n\nP = permanent side boot\n\nT = temporary side boot\n\n0 2 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Press Enter to select the firmware IPL mode and exit function 02. 0 2 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Use the Increment or Decrement buttons to scroll through the control panel functions.\n\nFunction 04: Lamp test\n\nThis function performs a lamp test on the 7037-A50 server and the 7047-185 workstation. This function is available in both normal and manual operating mode. This function shows whether any control panel indicators are burned out and whether characters that are displayed in the Function/Data display on the control panel are valid. When you activate this test, all the control panel lights and indicators are lit.\n\n\n\nThe lamp test continues on the system control panel for four minutes. Use this procedure to verify that the lights on the system control panel are working correctly. If you cannot complete these steps, see \"Starting Point for All Problems\" in the Problem Analysis information for your system to start problem analysis.\n\n1. Power on the system.\n\n2. Press the Increment (up) or Decrement (down) buttons on the control panel to display function 04.\n\nPress Enter on the control panel.\n\n3. Do all of the lights and indicators on the system control panel come on?\n\nYes No\n\n-> Exchange the control panel or the replaceable unit that contains the control panel function [system unit backplane (MB1) or tower card (CB1)]. See \"Removal and Installation Procedures\" in the Problem Analysis information for your system.\n\n4. Do the expansion unit control panel lights all come on?\n\nYes No\n\n-> Exchange the control panel on the expansion unit.\n\n\n\nThe lights on the system control panel are working correctly. This ends the procedure.\n\nFunction 05: Remind mode\n\nThis function allows you to place the system fault-indicator LED in remind mode on the 7037-A50 server and the 7047-185 workstation. This function is available in both normal and manual operating mode.\n\n\n\nWhen the system fault-indicator LED is on solid, an error condition exists on the system. If you want to defer the repair of the error, you can place the system fault-indicator LED in remind mode. Placing the system in remind mode causes the system fault-indicator LED to flash instead of being on solid. The remind mode lets you know that a system fault that you have deferred still exists on the system. If any other serviceable event occurs on the system, the remind mode is changed back to system fault mode, where the LED is on solid.\n\nFunction/Data Action or description 0 5 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nUse the Increment or Decrement buttons to scroll to function 05. R E M I N D M O D E O N _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Press Enter to start function 05. Valid options are:\n\nRemind mode ON\n\nRemind mode OFF\n\nR E M I N D M O D E O F F _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nPress Enter to toggle the option on or off. 0 5 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Use the Increment or Decrement buttons to scroll through the control panel functions.\n\n\n\nLight path diagnostic card indicator LED layout for the 7037-A50 and 7047-185 models\n\n\n\n1 Power supply fault-indicator LED\n\n2 Voltage-regulator module fault-indicator LED\n\n3 Disk-drive bay fan fault-indicator LED\n\n4 Optical-media bay fault-indicator LEDs\n\n5 Disk-drive bay fault-indicator LEDs\n\n6 System backplane fault-indicator LED\n\n7 Front fan fault-indicator LED\n\n8 Battery fault-indicator LED\n\n9 PCI adapter fault-indicator LED\n\n10 Thermal fault-indicator LED\n\n11 Rear fan fault-indicator LED\n\n12 Memory fault-indicator LED\n\n\n\nFunction 06: Display the BMC version\n\nThis function displays the base motherboard controller (BMC) version on the 7037-A50 server and the 7047-185 workstation. This function is available in both normal and manual operating mode.\n\n\n\nFunction/Data Action or description 0 6 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nUse the Increment or Decrement buttons to scroll to function 06. B M C: A W 8 T x x A _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Press Enter to start function 06. An example of the BMC version is AW8T23A. 0 6 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nUse the Increment or Decrement buttons to scroll through the control panel functions.\n\nFunction 09: Display the BMC fan speed\n\nThis function displays the base motherboard controller (BMC) fan speed on the 7037-A50 server and the 7047-185 workstation. This function is available in both normal and manual operating mode. The display alternates every two seconds between MAIN, DASD, and PCI fan speed.\n\n\n\nThe following table provides details about this function.\n\n\n\nFunction/Data Action or description 0 9 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nUse the Increment or Decrement buttons to scroll to function 09. M A I N: 7 b 0 _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Press Enter to start function 09. The main fan speed is listed in hexadecimal (rpm). D A S D: 7 0 0 _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Press Enter to start function 09. The DASD fan speed is listed in hexadecimal (rpm). P C I: 7 b 0 _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nPress Enter to start function 09. The PCI (I/O) fan speed is listed in hexadecimal (rpm). 0 9 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nUse the Increment or Decrement buttons to scroll through the control panel functions.\n\nFunction 10: Display the temperature\n\nThis function displays the temperature on the 7037-A50 server and the 7047-185 workstation. This function is available in both normal and manual operating mode. The display alternates every two seconds between ambient, CPU1, and CPU2 temperature. The following table provides details about this function.\n\n\n\nFunction/Data Action or description 1 0 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nUse the Increment or Decrement buttons to scroll to function 10. A m b i e n t : 3 e , 3 e _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Press Enter to start function 10. The ambient temperature is listed in hexadecimal (degrees Celsius).\n\nThe first value is the average temperature over a time span.\n\nThe last value is the most recent temperature reading.\n\nC P U 1 : 5 0 , 6 f _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Press Enter to start function 10. The CPU1 temperature is listed in hexadecimal (degrees Celsius).\n\nThe first value is the average temperature over a time span.\n\nThe last value is the most recent temperature reading.\n\nC P U 2 : 0 , 0 _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Press Enter to start function 10. The CPU2 temperature is listed in hexadecimal (degrees Celsius).\n\nThe first value is the average temperature over a time span.\n\nThe last value is the most recent temperature reading.\n\nThe reading is 0 if the system is one-way.\n\n1 0 _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nUse the Increment or Decrement buttons to scroll through the control panel functions.\n\nFunction 20: System type and model\n\nThis function displays the machine type and model on the 7037-A50 server and the 7047-185 workstation. This function is available in both normal and manual operating mode. The machine type and model is displayed in the following format:\n\n\n\np p p p - m m m _ _ _ _ _ _ _ _\n\n\n\nThe values are indicated as follows:\n\nValues for p indicate the machine type.\n\nValues for m indicate the machine model.\n\n\n\nFunction 22: Partition dump\n\nThis function initiates a dump of a partition's operating system data on the 7037-A50 server and the 7047-185 workstation. This function is available in both normal and manual operating mode. You must perform two consecutive function 22 selections to initiate a partition dump. The following table shows an example of function 22.",
      "source": "Ibmfiles.com",
      "url": "http://www.ibmfiles.com/pages/intellipower185.htm",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "More and more family adventure campers are looking beyond the tent",
      "content": "Camping, in all its modern manifestations, has become an increasingly popular and affordable go-to strategy for families eager to get outside and enjoy meaningful time together.\n\nIf you are inclined to camp with the kids, here are five ideas to consider.\n\nHang out in Huttopia\n\nFor an affordable and fun family outing, check out Huttopia’s eight “ready to camp” locations in the U.S. and Canada. Each inspired destination offers a stunning setting and unique accommodations. You’ll find traditional tents or a tiny house. Some offer wood-structured, glamping-style tents or cozy cabins, each with a kitchenette, making it simple to manage varied snack or snoozing schedules. No need to shop for gear ahead of your visit as tents, cooking utensils, sleeping bags and more will be awaiting your arrival. Your job is simply to settle in and revive in a nature-centric setting. Look forward to pool, pond, lake or river swimming (depending on location), paddling, hiking, star-gazing and special activities for the younger set that might include nature art, magic shows, concerts or candle-making.\n\nThe most recent additions to the Huttopia clan include properties in the Berkshires of Massachusetts and in the Quebec wilderness, 90 minutes outside Montreal.\n\nFor more: www.huttopia.com\n\nDiscover state park possibilities\n\nMany state parks provide affordable and accessible lodging where families can enjoy a relaxing getaway in a natural environment. For example, in Ohio’s Deer Creek State Park, your crew can check in to what was once the private hideaway of President Warren G. Harding. The restored, yet rustic multilevel cabin reportedly served as a getaway for Harding and his close circle of friends known as the “Ohio Gang.” Listed on the National Register of Historic Places, the cabin was constructed on the banks of Deer Creek by U.S. Attorney General Harry M. Daugherty at the close of World War I.\n\nWith a full-length screened porch overlooking the 1,277-acre lake, it’s easy to imagine why Harding might have retreated to the picturesque spot to gain a little perspective.\n\nFor more: www.deercreekstateparklodge.com\n\nSleep in a yurt\n\nIt’s fun to spend the night in a better-than-ordinary kind of space. Increasingly popular, yurts, a Mongolian original, fit the bill. At the Snow Mountain Ranch at the YMCA in Winter Park, Colorado, your family can snooze the night away in a yurt featuring one queen bed and two sets of bunk beds, accommodating up to six people. An outdoor tent pad enables you to expand the party by adding another two persons (guests must bring their own tents).\n\nThe yurts also include a microwave, mini fridge, prep table, picnic table, outdoor grill and fire ring. All yurts offer electricity and complimentary Wi-Fi. The bathhouse, located nearby, has flush toilets, handicapped-accessible hot showers, hair dryers, a coin-operated washer and dryer, and deep well sinks. Yurts are available year-round and are pet friendly.\n\nFor more: www.ymcarockies.org\n\nConnect at the campground\n\nKOA, the world’s largest system of open-to-the-public family campgrounds, has continued to evolve since its inception in 1962. Choose your camping style and destination from more than 500 locations in North America and access tent sites, RV hookups, cabins, teepees, playgrounds, pools and a range of recreational facilities. Many locations are pet friendly.\n\nFor more: www.koa.com\n\nThere’s no place like home\n\nFamily camping can help stir a deep and lifelong interest in the natural world. Therefore, early, positive experiences matter. Talk through the details and set clear expectations. For the youngest set, consider a practice round in the backyard or nearby park.\n\nPut up the tent, toast marshmallows for s’mores and tell not-so-scary stories. That way, if the weather or unforeseen forces create a kink in your plans, warm and dry shelter is nearby.\n\nLynn O’Rourke Hayes (LOHayes.com) is an author, family travel expert and enthusiastic explorer. Gather more travel intel on Twitter @lohayes, Facebook, or via FamilyTravel.com/Tribune News Service",
      "source": "Boston Herald",
      "url": "https://www.bostonherald.com/2025/09/28/more-and-more-family-adventure-campers-are-looking-beyond-the-tent/",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Intel quietly makes aggressive move to repair recent failures",
      "content": "In recent months, Intel (INTC) has been making drastic moves to repair its business, which has significantly underperformed compared to its top competitors in the tech industry.\n\nIts lack of innovation in its chip manufacturing processes has allowed competitors such as Nvidia (NVDA) ,…\n\nThis story appeared on thestreet.com , 2025-09-28 14:33:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b3d3dcf2415bb2fd",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "TSMC says Intel didn’t ask for investments — denies existence of talks for partnership, joint venture",
      "content": "Taiwan Semiconductor Manufacturing Corporation (TSMC) has denied engaging in talks with Intel regarding any sort of investment or partnership. According to the Taipei Times, the company disputed a recent Wall Street Journal report saying that Intel solicited a joint venture with the fab. The WSJ news, based on the publications' sources, also indicated that Intel was reaching out to Apple to explore ways in which these tech companies can collaborate. All this comes close on the heels of Nvidia buying $5 billion worth of Intel stock, alongside the announcement of a joint development of an x86 RTX SOC.\n\nThere have previously been reports of an Intel and TSMC partnership, but the latter has always denied this. The embattled Intel, whose shaky financial situation was revealed last year, has been on the hunt for partners and investors recently. Just last month, SoftBank invested $2 billion in the company, while the U.S. government released the remaining $5.7 billion it had yet to receive from its CHIPS and Science Act grant in exchange for a 10% stake.\n\nThis massive cash inflow is crucial for the company, allowing it to increase spending on investments and capital expenditure. Aside from that, Intel CEO Lip-Bu Tan has been slashing costs, including reducing the company’s workforce by over 12,000 personnel — effectively gutting its personnel numbers by around 20%. He also divested some divisions, choosing to focus the company on its core competencies.\n\nDespite all this, Intel still has a long way to go before it can get back in the green. It has long been working on its next-generation chips, but has had trouble with the yield of its 18A node. Tan also said that the company might cancel the Intel 14A and its following leading-edge nodes if it cannot win a big customer for these products. Aside from that, the company projects that its foundry business won’t break even until 2027, which will coincide with the arrival of 14A — if that ever happens.\n\nIntel has also been facing issues on the consumer side. Analysts say that uptake of the company’s Lunar Lake processors has been slow, particularly because buyers aren’t interested in AI chips. The company is even raising prices of its last-generation Raptor Lake processors because of increased demand for the “outdated” chip.\n\nThese complications might be a big reason why TSMC does not want to entangle itself with Intel’s affairs. More than that, it likely doesn’t want to work with a chipmaker with its own foundry, which could potentially be a competitor. And unless it gets massive upside, whether in technology or geopolitics, it’s unlikely that we’ll see any sort of investment or strategic partnership between these two companies.\n\nFollow Tom's Hardware on Google News , or add us as a preferred source , to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/big-tech/tsmc-says-intel-didnt-ask-for-investments-denies-existence-of-talks-for-partnership-joint-venture",
      "timestamp": "2025-09-28"
    },
    {
      "headline": "Daily Tech News 29 September 2025",
      "content": "Daily Tech News 29 September 2025 Top Story\n\n\n\nIntel plans production of its next-gen Panther Lake laptop chips starting in Q1 of next year on its brand new 18A (1.8nm) process node. (WCCFTech)\n\n\n\nChips take a good six months to make it from production start to consumer devices on store shelves, so expect these to appear in laptops in late Q3 next year.\n\n\n\nPanther Lake will offer up to 4 performance cores, which is... Not a lot. They will pair these with up to 8 efficiency cores and 4 low-power cores, but at the moment all the models except the fastest are looking pretty anemic.\n\n\n\nTech News\n\n\n\nAMD's Strix Halo CPU has a 40 core graphics chip paired with two much smaller 8 core CPU chiplets. But those 8 core chiplets are different from the 8 core chiplets used in all socket AM4 and AM5 CPUs. (WCCFTech)\n\n\n\nAll multi-die AMD CPUs use Infinity Fabric over a high-speed serial link to wire things together. This limits the memory bandwidth for a single consumer CPU chiplet to a fair bit less than fast DDR5 RAM can offer.\n\n\n\nExcept for Strix Halo, where the 16 CPU cores have twice the write bandwidth of a 16 core 9950X.\n\n\n\nThat's because it doesn't a serial bus of any kind to connect the chiplets; the CPU dies are placed directly adjacent to the GPU die and the gap is bridged by a direct parallel connection over an advanced multilayer substrate from TSMC.\n\n\n\nWe'll have to wait and see what happens with Zen 6 next year, but it's interesting that AMD was willing to spend the money on a different CPU chiplet just for Strix Halo.\n\n\n\n\n\n\n\nAll multi-die AMD CPUs use Infinity Fabric over a high-speed serial link to wire things together. This limits the memory bandwidth for a single consumer CPU chiplet to a fair bit less than fast DDR5 RAM can offer. Except for Strix Halo, where the 16 CPU cores have twice the write bandwidth of a 16 core 9950X. That's because it doesn't a serial bus of any kind to connect the chiplets; the CPU dies are placed directly adjacent to the GPU die and the gap is bridged by a direct parallel connection over an advanced multilayer substrate from TSMC. We'll have to wait and see what happens with Zen 6 next year, but it's interesting that AMD was willing to spend the money on a different CPU chiplet just for Strix Halo. Looking for a new switch? Want two 400Gb ports, two 200Gb, eight 50Gb, and a 10GB management port? Think that would be wildly expensive? $1295 from Mikrotik. (Serve the Home)\n\n\n\nWhich is still a lot for a home network switch - gigabit switches are so cheap these days you find them as toys in the better brands of breakfast cereal - but networking is one of the few places where you can get 20x the speed for not even 20x the cost, rather than prices shooting straight into the ionosphere.\n\n\n\n\n\n\n\nWhich is still a lot for a home network switch - gigabit switches are so cheap these days you find them as toys in the better brands of breakfast cereal - but networking is one of the few places where you can get 20x the speed for not even 20x the cost, rather than prices shooting straight into the ionosphere. Asus will be releasing a fix for its stuttering gaming laptops. (Hot Hardware)\n\n\n\nReal soon now.\n\n\n\n\n\n\n\nReal soon now. Got a shipping notice for my Beelink Me Mini, a little under three days after I placed the order. Which is quite a bit less than the 30-35 days quoted by the site, even in knot math.\n\n\n\n\n\n\n\nMathematical Interlude\n\n\n\nIf you read that story the other day about knotting numbers and said, basically, as I did, huh? , here it is physically demonstrated.\n\n\n\n\n\n\n\nTwo conjectures - unproven, but previously considered very likely to be true - said that combining two knots of a known complexity would produce a combined knot with a complexity neither less nor more than the sum of the complexity of the two individual knots.\n\n\n\nHere Matt physically combines two knots each with a complexity of 3, and shows the combined knot has a complexity of 5.\n\n\n\nThe procedure is actually a little complicated which explains why this sat unnoticed until someone could write a Python program to try out all the possible permutations, but once you know how to do it, still simple enough to prove the counterexample really works.\n\n\n\n\n\n\n\n\n\nMusical Interlude\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisclaimer: Get it off! Get it off!!! Posted by: Pixy Misa at 04:30 AM\n\n\n\n\n\nIf you read that story the other day about knotting numbers and said, basically, as I did,, here it is physically demonstrated.Two conjectures - unproven, but previously considered very likely to be true - said that combining two knots of a known complexity would produce a combined knot with a complexity neither less nor more than the sum of the complexity of the two individual knots.Here Matt physically combines two knots each with a complexity of 3, and shows the combined knot has a complexity of 5.The procedure is actually a little complicated which explains why this sat unnoticed until someone could write a Python program to try out all the possible permutations, but once you know how to do it, still simple enough to prove the counterexample really works.\n\n\n\n\n\nMuNuvians MeeNuvians",
      "source": "Acecomments.mu.nu",
      "url": "https://acecomments.mu.nu/?post=416673",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Oh the joy: OpenNvidia may be the AI generation's WinTel",
      "content": "Oh the joy: OpenNvidia may be the AI generation's WinTel\n\nDuo could dominate in the same way Microsoft and Intel ruled PCs for decades\n\nOpinion The OpenAI and Nvidia $100 billion partnership sure sounds impressive. $100 billion isn't chicken feed, even as more and more tech companies cross…\n\nThis story appeared on go.theregister.com , 2025-09-29 10:15:10.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/83db429ced4014e8",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Watch These Intel Price Levels After Stock Surged 20% Last Week",
      "content": "Key Takeaways Intel shares remain in the spotlight after soaring 20% last week, boosted by reports the chipmaker is soliciting investments from Apple and Taiwan Semiconductor Manufacturing Co.\n\nSince breaking out above a multi-month trading range earlier this month, the stock has continued to trend sharply higher and closed above the closely watched 200-week moving average last week.\n\nInvestors should watch critical overhead areas on Intel's chart around $45 and $56, while also monitoring major support levels near $30 and $26.\n\nIntel (INTC) shares remain in the spotlight after soaring last week amid investor optimism that the embattled chipmaker could secure additional investments.\n\nThe stock gained 20% last week and has risen more than 40% since the start of the month, boosted recently by reports that the chipmaker is soliciting investments from Apple (AAPL) and Taiwan Semiconductor Manufacturing Co. (TSM). Intel earlier this month receiving a $5 billion pledge from AI Favorite Nvidia (NVDA), which came not long after the U.S. government announced it had taken a 10% stake in the company.\n\nAnalysts say they anticipate new developments on the investment front spurring more gains for the stock in the near term, though cautioned they still have concerns about the company's fundamentals. Intel shares were down 4% at around $34 in the opening minutes of Monday's session.\n\nBelow, we take a closer look at the technicals on Intel’s weekly chart and identify critical price levels worth monitoring.\n\nMulti-Month Trading Range Breakout\n\nSince breaking out above a multi-month trading range earlier this month, Intel shares have continued to trend sharply higher and closed above the closely watched 200-week moving average last week.\n\nImportantly, the stock’s recent advance has occurred on above-average trading volume, raising the prospect of follow-through buying.\n\nMeanwhile, the relative strength index confirms bullish price momentum, though the indicator sits in overbought territory near a reading that marked local tops in the stock in January 2020 and December 2023.\n\nLet’s identify major overhead areas on Intel’s chart to watch if the shares keep climbing and also point out support levels worth monitoring during potential retracements.\n\nCritical Overhead Areas to Watch\n\nThe first overhead area to watch sits around $45. This location may provide resistance near a trendline that connects a range of peaks and troughs on the chart stretching all the way back to May 2019. This level also roughly coincides with the 78.6% Fibonacci retracement level when applying a grid from the December 2023 high to the lower trendline of the stock’s multi-month trading range.\n\nA successful close above this critical level could trigger a rally toward $56. Investors who have accumulated shares at lower prices may decide to lock in profits in this region near a horizontal line that links a series of comparable trading activity on the chart between October 2019 and January 2022.\n\nMajor Support Levels to Monitor\n\nDuring retracements in the stock, investors should initially monitor the $30 level. The shares could attract buying interest in this location near several countertrend highs in late 2022 and early 2023, which also closely align with a sideways trend on the chart from May to July last year.\n\nFinally, a deeper pullback in Intel shares may see a retest of major support around $26. This area on the chart marks the top of the stock's multi-month trading range and could flip from prior resistance into future support.\n\nThe comments, opinions, and analyses expressed on Investopedia are for informational purposes only. Read our warranty and liability disclaimer for more info.\n\nAs of the date this article was written, the author does not own any of the above securities.\n\n",
      "source": "Investopedia",
      "url": "https://www.investopedia.com/watch-these-intel-price-levels-after-stock-surged-20-percent-last-week-11820262",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Want to be CEO? These 5 employers give you the best shot",
      "content": "If your career goal is the corner office, history suggests five employers give you the best odds. McKinsey tops the list, with 18 of today’s Fortune 500 chiefs wearing its alumni badge. General Electric and PepsiCo follow with 15 each, trailed by Procter & Gamble with 11 and JPMorgan Chase with 10.\n\nFor decades, these organizations have served as corporate academies, renowned for their rigorous leadership training and development. In essence, they’ve operated as high-intensity finishing schools.\n\nAt McKinsey, recruits rotate across industries and geographies, dissecting sprawling problems and creating and defending solutions before skeptical executives. General Electric built its reputation on world-class management programs that groomed future chiefs through exacting operating roles. PepsiCo and Procter & Gamble are known for giving young managers full P&L responsibility early and demanding sharp marketing instincts. JPMorgan Chase exposes rising leaders to complex global markets, risk management, and high-stakes client relationships.\n\nEach environment has historically forced ambitious talent to build range, master financial discipline, and develop the judgment boards look for when filling the top job.\n\nOf course, past performance is no guarantee of future dominance. And with the advent of AI, the very factors that once made these companies reliable CEO factories are shifting.\n\n“The value of traditional backgrounds hasn’t been discarded,” says Christine Greybe, president of leadership consulting at DHR Global. “But it’s being supplemented by more progressive, digital-first thinking.”\n\nBoards now prize leaders who can operationalize AI, manage its risks, and weave data into core strategy. Chief product and data officers, along with executives who have driven large-scale digital transformations, are increasingly landing on CEO shortlists.\n\nAI also threatens the old apprenticeship model itself. At firms like McKinsey, the analytical grind that once built leadership muscle—benchmarking, research synthesis, even presentation work—is rapidly automated. And as technology reshapes every industry, companies such as Amazon and Microsoft are becoming prime hunting grounds for boards seeking digital fluency at the top, several executive recruiters told me in private conversations.\n\nTo be sure, the pedigrees of McKinsey, GE, PepsiCo, P&G, and JPMorgan still carry weight, but tomorrow’s chiefs will need more than classic strategy and P&L discipline. They will have to pair those fundamentals with product sense, data literacy, and comfort managing AI-driven change. For ambitious professionals, these storied academies remain powerful launchpads, provided they’re matched with experiences suited to a business world being rewritten by technology.\n\nREAD: How McKinsey built an empire of influence and filled the world’s corner offices with its own\n\nRuth Umoh\n\nruth.umoh@fortune.com\n\nSmarter in seconds\n\nAgility advantage. Why Kind Snacks’ CEO says adaptability is the ultimate leadership skill\n\nGrounded growth. Wayfair’s president on the power of humility and IRL shopping\n\nTotal commitment. LinkedIn’s cofounder says seeking work-life balance is a red flag that you’re ‘not committed to winning'\n\nLeadership lesson\n\nJon Blotner, Wayfair's president of commercial and operations, on career reflections: \"The thing that I always look for, and have always looked for, is just a space that's got really hard challenges...where I get a lot of autonomy, and where I can learn from others.\"\n\nNews to know\n\nCitadel CEO Ken Griffin, who backed Trump’s election but has since criticized key policies, called it “nauseating” to see CEOs seek tariff exemptions. Fortune\n\nMassive government subsidies and investments from industry partners have given Intel a path to redemption, but its fate hinges on flawless execution. Fortune\n\nThe retail industry was already unforgiving, but new CEOs now face even sharper headwinds, from margin-crushing tariffs to shoppers pulling back their spending. NYT\n\nOracle is testing an unusual succession strategy, handing the reins of the $870 billion enterprise to four top executives who will share leadership. Fortune\n\nNYC Mayor Eric Adams dropped his reelection bid amid sinking poll numbers and pressure from business leaders seeking a stronger contender against Zohran Mamdani. The New Yorker\n\nCitigroup’s investment-banking revival has turned Vis Raghavan into a top contender for the CEO role. Bloomberg",
      "source": "Fortune",
      "url": "https://fortune.com/article/want-to-be-ceo-these-5-employers-give-you-the-best-shot/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Cameraman Captures Scott Bessent’s Texts, Exposing White House Panic",
      "content": "“Roger Goodell and the NFL just decided to make the Super Bowl political by picking Bad Bunny as the 2026 Super Bowl music act. The guy literally says he isn’t touring the US because of Trump’s ICE raids and just released a video mocking President Trump,” conservative Cuban American commentator Robby Starbuck chimed in. “Also, most of his songs aren’t even in English. This is not a pick designed to unite football fans or let people just enjoy the show. It was a pick designed to divide fans and no doubt Bad Bunny will find some way to push a woke message.\n\n“Are NFL owners in on this idiocy or are they just culturally that disconnected from reality and how Roger uses the NFL to push left wing social issues?” Starbuck continued. “Is it that hard to pick a unifying music act who doesn’t want to peddle woke propaganda? Does this guy really scream American football to anyone? Be for real with me. No one thinks he does. This isn’t about music, it’s about putting a guy on stage who hates Trump and MAGA.”\n\nBad Bunny is easily one of the most popular artists in the entire world. He has won three Grammys, 11 Latin Grammys, eight BillBoard Music awards, and 13 Lo Nuestro Awards. He was named Billboard Artist of the Year in 2022, was the most streamed artist on Spotify for two years straight, and has sold over seven million records. He is more than qualified to headline the Super Bowl halftime show.",
      "source": "The New Republic",
      "url": "https://newrepublic.com/post/201064/donald-trump-scott-bessent-texts-argentina-china-trade-panic",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Intel shares surge on rumors of potential Apple investment",
      "content": "As Intel seeks to bolster its financial position, rumors of discussions with tech industry giants have sent the company's shares skyrocketing, prompting speculation about its future direction.\n\nThis story appeared on bizjournals.com , 2025-09-29 17:40:41.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/5dbfde29a56a94ee",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Linux 6.18 Preps KVM x86 CET Virtualization For AMD & Intel CPUs",
      "content": "Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via Twitter, LinkedIn, or contacted via MichaelLarabel.com.",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-KVM-CET-Virt",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "ASML Builds Machines that Make AI Chips. Why It’s Missing Out on the Boom",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/3a3861ca3e419f06",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Scouting the long-snapper: Intel helped Bears block Raiders' kick, flip script on wild win",
      "content": "Open Extended Reactions\n\nLAS VEGAS -- As the Las Vegas Raiders lined up for a 54-yard field goal attempt with 38 seconds remaining Sunday, trailing 25-24, Chicago Bears cornerback Josh Blackwell leaned on the intel he received from his teammate, Scott Daly.\n\nDaly, the Bears long-snapper, gave a player report during the week on the Raiders' field goal unit and disclosed a tendency he spotted on film. It appeared subtle, but Las Vegas long-snapper Jacob Bobenmoyer would sometimes move the ball before snapping it on point-after attempts and field goals. Blackwell knew if he saw it in the game, he could get a jump on the snap and have a chance to block a kick.\n\nThis tiny detail paid off in a big way when Blackwell burst off the left edge and dove to block Daniel Carlson's 54-yard field goal attempt, securing the Bears' wild win.\n\n\"It's an incredible win, and that's just a testament to the team we have,\" Blackwell said. \"I think we stacked a good week of practice and we kind of got this quote-unquote monkey off our back that we're not the 'same old Bears', we're different.\"\n\nInstead of going back to Chicago on the familiar end of a heartbreaking loss and with a losing record, the Bears (2-2) head into their Week 5 bye encouraged.\n\nSince he arrived in Chicago in 2022, Blackwell has been part of his fair share of losses that resembled how the Raiders felt on Sunday. He's experienced failure to close out a game because of missed opportunities and gut-wrenching losses being cemented on the final play.\n\nThat was the theme of the 2024 season for the Bears, from a tipped Hail Mary in Washington to a blocked field goal against the Packers to letting the clock run out in Detroit with a chance to win.\n\nBears cornerback Josh Blackwell saw the Raiders move the ball slightly before the snap and relied on his pregame intel in timing his rush. It worked with a game-saving blocked kick. AP Photo/John Locher\n\nRewriting the narrative around their ability to close out opponents amid in-game struggles is a central theme to the changes taking place under first-year Bears coach Ben Johnson.\n\n\"I'm proud of our guys,\" Johnson said. \"They came through for us. We're building something special here, and I think they're feeling it, just the belief they have in each other, the belief they have in this coaching staff, I thought it really showed through.\n\n\"This is a huge win for our team, finding a way in the fourth quarter to come out on top. I just thought that was outstanding for us.\"\n\nThe Bears' offense was stuck in a rut until halftime. Quarterback Caleb Williams was 2-for-7 with an interception in the first quarter while averaging 1.6 yards per attempt. Chicago's defense came away with two interceptions and recovered a fumble, yet the offense generated six points off two field goals.\n\nPre-snap penalties -- six of them on offense -- continued to stifle momentum. The run game netted just 2 yards in the first half. Raiders defensive end Maxx Crosby ran through Chicago's offensive line from multiple spots and terrorized Williams when he made his way into the backfield.\n\n\"It's easy to get frustrated, but we don't panic,\" Johnson said. \"I could see where the defense would get frustrated with the offense, and the offense frustrated with ourselves. That didn't happen. Everybody stayed the course, no one panicked whatsoever.\n\n\"I thought we came in at halftime and we hit that reset button. That's what we talked about, take a deep breath, and let's come out and play for 30 minutes and find a way to win.\"\n\nWilliams completed 20 of his 30 pass attempts after a rough first quarter. After failing to connect with Rome Odunze in the first half, Williams sent a 27-yard pass over the middle of the field to his top wideout on Chicago's first possession of the third quarter. The touchdown pass wrested back the lead for the Bears and sparked a back-and-forth battle.\n\nThe Bears defense came away with four turnovers, a bright spot on a day when they let Raiders running back Ashton Jeanty explode onto the scene with a 3-touchdown day while Vegas racked up 240 rushing yards.\n\nOn the Raiders' second-to-last possession, deep in Chicago territory, the Bears held them to a field goal.\n\nAs Williams and the offense got ready to take the field, Johnson shared a moment of encouragement.\n\n\"I remember talking to Caleb before he took the field,\" Johnson said. \"I said, 'This is what you're built for', and these are the moments that he thrives in the most.\n\n\"I think that's really been the story of his life, to be honest with you and I know he came through for us in a big way.\"\n\nWilliams strung together an 11-play, 69-yard game-winning drive, and running back D'Andre Swift -- despite a disastrous day on the ground -- found the end zone on a 2-yard run to give the Bears the go-ahead touchdown.\n\nAs Swift put his fingers up to his lips to silence the home-team crowd in a stadium overrun by Bears fans, the veteran back felt the shift that was taking place.\n\n\"Maybe the good luck is on our side this time going around,\" Swift said.\n\nChicago has plenty to sort through during its bye week self-scout. Whether Braxton Jones will come back as the left tackle in Washington in Week 6 after being pulled before halftime in Las Vegas is one of the biggest decisions Johnson will have to make. Figuring out ways to build consistency on offense is multifaceted, from eliminating penalties to finding effective ways to establish the run.\n\nBut for now, Johnson's proof of concept seems to be paying off. The Bears aren't following the same script that played out a year ago when ugly games led to predictable losses in devastating fashion. Taking a rough day at the office and coming away with a \"grimy\" win proved something to Williams.\n\n\"I think being able to portray the belief that, 'Guys, this is all we got, it's all we need. We're not in a favorable position,'\" Williams said. \"We're down. It's all 11 of us on the field, and we got to go do a job. The belief, the trust, the hard work that we put in, those are the moments that you wish for. Those are moments that you dream about. So, being able to have those moments and come through is important, for one, the confidence. Especially in the moment where it's not a favorable position. You're away, you're down, you got to go win the game.\n\n\"So, it's a confidence builder, it's a culture builder for us.\"",
      "source": "ESPN",
      "url": "https://www.espn.com/nfl/story/_/id/46419635/nfl-chicago-bears-field-goal-raiders",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Watch These Intel Price Levels After Stock Surged 20% Last Week",
      "content": "Key Takeaways\n\n-\n\nIntel shares remain in the spotlight after soaring 20% last week, boosted by reports the chipmaker is soliciting investments from Apple and Taiwan Semiconductor Manufacturing Co.\n\n-\n\nSince breaking out above a multi-month trading range earlier this month, the stock has…\n\nThis story appeared on finance.yahoo.com , 2025-09-29 13:34:37.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/90f796de0d238498",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Analog in-memory Computing Attention Mechanism for Fast and Energy-efficient Large Language Models",
      "content": "A Nature paper describes an innovative analog in-memory computing (IMC) architecture tailored for the attention mechanism in large language models (LLMs). They want to drastically reduce latency and energy consumption during inference. The design leverages gain-cell crossbar arrays—capacitor-based memory devices made from oxide semiconductor field-effect transistors (IGZO or ITO)—to store key (K) and value (V) projections from the KV cache directly in memory. This enables simultaneous storage and computation of dot products with query (Q) projections in the analog domain. It avoids the energy-hungry data movement between memory and processors typical in digital systems like GPUs.\n\nAnalog Computation is done via dot products performed via charge-to-pulse circuits that convert stored charges into pulse-width modulated signals, avoiding power-intensive analog-to-digital converters (ADCs). Activation uses a hardware-friendly HardSigmoid function (approximating softmax) for sliding window attention, supporting causal and local processing.\n\nHardware-Aware Training: Pre-trained models (e.g., GPT-2) are fine-tuned with scaling factors to account for non-idealities like capacitor leakage and gain-cell nonlinearity, ensuring minimal accuracy loss.\n\nImplementation Details: The system supports sub-tiling for large dimensions, non-destructive reads, and 3D stacking for density. Simulations model real-world effects using third-order polynomials.\n\nFor a single attention head in GPT-2, it achieves 65 ns latency and 6.1 nJ energy per token, yielding up to 7,000× speedup and 90,000× energy reduction compared to NVIDIA A100 GPUs. Area efficiency is high, with KV cache footprints as low as 3.1 × 10⁻³ mm² using 3D integration. On NLP benchmarks (ARC-Easy, WinoGrande, WikiText-2), adapted models match or closely approach baseline perplexity and task accuracies, with minor gaps in larger networks attributable to training differences.\n\nThe authors emphasize co-optimization of hardware and algorithms as key to overcoming analog non-idealities, positioning this as a scalable path for generative AI. Limitations include reliance on emerging OSFETs (still maturing for mass production) and potential scaling challenges for ultra-large models without further tiling optimizations. Future work suggests hybrid integrations with other IMC techniques for full transformers.\n\nThey are going at the main area of energy usage for LLM which is the attention mechanism’s bottleneck of data transfer overheads in KV caching and softmax computations. These use ~70-80% of LLM inference energy in digital accelerators. By shifting to analog IMC with volatile, low-power gain cells, it exploits physics-level parallelism (crossbar matrix multiplications) for near-memory processing, achieving orders-of-magnitude gains without sacrificing much accuracy. The hardware-aware adaptation is a clever bridge, using simple statistical matching to detune ideal models for real circuits, making it practical for deployment.\n\nThe 90,000× energy win is huge. It is driven by eliminating von Neumann bottlenecks and even conservative estimates (factoring in leakage) still shows 10,000×+ gains.\n\n3D stacking and sub-tiling make it viable for billion-parameter models like Mistral 7B.\n\nHardSigmoid simplifies analog operations while preserving sliding window efficacy. It does not require a full softmax redesign.\n\nAll of the major LLMs ( OpenAI GPT 5, XAI Grok, Google Deepmind Gemini, Anthropic Claude) can adopt. It will require chip fabrication (TSMC, Intel or Samsung for OSFETs). The paper’s simulations suggest drop-in compatibility, potentially unlocking exaflop-scale efficiency for these trillion-parameter behemoths.\n\nWork by TSMC or Other Chip Makers on Analog In-Memory Computing (AIMC)\n\nThe authors are from Forschungszentrum Jülich and RWTH Aachen University in Germany—not affiliated with the queried companies. Simulations in the paper demonstrate viability for a 1.5B-parameter LLM, but it’s conceptual/prototype-level, not production-ready.\n\nTSMC has ongoing research in analog non-volatile Compute-in-Memory (nvCIM) technologies, which overlap with AIMC principles for AI acceleration. Their work focuses on tradeoffs in signal margins, accumulation cycles, and latency for embedded ferroelectric memory array computing (EFMAC), but not explicitly on attention mechanisms for LLMs. No direct TSMC involvement in the specific gain-cell-based attention design.\n\nChip makers show tangential progress\n\nIBM: Actively advancing AIMC for transformer models, including attention layers in Mixture-of-Experts (MoE) LLMs. Their chips integrate memory and computation to cut energy/latency costs, outperforming GPUs in edge AI scenarios. A January 2025 IBM Research blog highlights AIMC’s suitability for accelerating attention in MoE models, with prototypes showing noise-resilient rescaling for LLMs.\n\nSynopsys is Developing AI-powered tools for analog circuit design in AIMC, emphasizing simulation complexity reduction to speed up development. This supports broader AIMC innovation but isn’t LLM-specific.\n\nEmerging players like Mythic or Aspinity explore AIMC for edge AI, but nothing ties directly to LLM attention. Commercial AIMC remains in prototype/trial stages, with no widespread adoption yet.\n\nAIMC for LLM attention is in early research (2024-2025 papers), with prototypes demonstrating feasibility but facing challenges like noise sensitivity, precision limits, and scaling to billion-parameter models.\n\nDevelopment Timeline: How Quickly Could It Be Done?\n\nAIMC prototypes demonstrate feasibility but facing challenges like noise sensitivity, precision limits, and scaling to billion-parameter models.\n\nPrototypes/Validation for 6-18 months. Gain-cell designs are CMOS-compatible, leveraging existing fabs, so small-scale chips could be taped out quickly via multi-project wafers (MPWs).\n\nCommercial Production seem like 2-4 years. Analog noise and yield issues slow scaling; IBM’s work suggests MoE integration by 2027.\n\nFull LLM deployment (inference at scale) might hit 2028-2030, per industry trends.\n\nPartnerships with fabs like TSMC could shave 6-12 months. Open-source simulations enable faster iteration.\n\nHypothetically an aggressive player like Elon and XAI could compress a rollout tp 12-24 months for a proof-of-concept cluster. This would need heavy investment in custom silicon—similar to Tesla’s Dojo.\n\nA plan would be parallel experimentation over sequential caution.\n\nParallel Pilots in Non-Core Sites (0-3 Months): Dedicate a small, isolated cluster (10-50 MW) for AIMC prototypes. Train/infer a subset of Grok workloads (7B-70B params) on hybrid racks: 80% NVIDIA GPUs for baseline, 20% AIMC for attention layers. Use containerized orchestration (Kubernetes + Ray) for seamless A/B switching.\n\nPhased Retrofit with Shadow Testing (3-6 Months): In Memphis, insert AIMC pods as shadow compute—run inference in parallel to GPUs, comparing outputs/latency/energy via canary deployments. Monitor with Prometheus/Grafana for drift (e.g., <1% accuracy loss from analog noise). Scale to 10% of pods if KPIs hit (50x energy savings on attention). Bold Scale-Up with Rollback (6-12 Months), if the early tests work. Maybe try 50% Memphis retrofit by Q2 2026. Use xAI's vertical integration (custom PCBs via Tesla supply chain) for rapid fab-to-rack. Test via chaos engineering (inject failures) and user-facing betas (Grok API endpoints). Fallback: Auto-route traffic to GPU backups if >0.1% SLA hit.\n\nRisk Mitigation: Multi-site redundancy ensures <1% downtime. Start with open-source AIMC sims for software validation before hardware. Total cost: $100-500M, offset by 2-5x efficiency gains. Tesla AI5 Softmax Efficiency Improvements\n\nTesla’s AI5 chip (aka HW5 or next-generation Full Self-Driving computer) introduces significant optimizations for inference workloads, particularly targeting the softmax function—a key component in transformer-based models for normalizing probabilities during attention mechanisms. This aligns with Tesla’s focus on accelerating AI for autonomous driving, Optimus robots, and potentially broader applications like xAI’s Grok models.\n\nElon Musk confirrmed a 40x improvement in softmax performance compared to the AI4 chip. On AI4, softmax was emulated in software via a 40-step process on the CPU, creating a major bottleneck. AI5 implements softmax natively in hardware as a single (or few-step) operation directly in silicon, drastically reducing latency and compute overhead. This is part of broader gains: 8x raw compute, 9x memory, 5x bandwidth, and up to 500-5,000 TOPS overall.\n\nThe softmax optimizations in AI5 do not include Analog In-Memory Computing (AIMC) changes. The improvements are achieved through digital hardware acceleration—specifically, co-designing the chip’s silicon to handle softmax operations natively, integrated tightly with Tesla’s software stack for FSD and Optimus. This is a conventional ASIC-style enhancement, not analog in-memory techniques, which would involve performing computations\n\ndirectly within analog memory arrays to minimize data movement and power use. Tesla’s descriptions emphasize “moving core operations into silicon” without any reference to analog paradigms, noise-resilient analog circuits, or in-memory compute for attention/softmax.\n\nAI6 Designs\n\nAI6 is still being designed. AI6 is said to be a bold gamble on semiconductor physics. It could be a logical entry point for prototyping, given its training-inference hybrid nature.",
      "source": "Next Big Future",
      "url": "https://www.nextbigfuture.com/2025/09/analog-in-memory-computing-attention-mechanism-for-fast-and-energy-efficient-large-language-models.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Intel \"Panther Lake\" B0_3 Stepping Surfaces in Firmware Patches",
      "content": "A new set of patches has hit the \"coreboot\" project, an open-source UEFI/BIOS alternative, adding another Intel \"Panther Lake\" stepping to our portfolio of leaks. This time, it is the PTL_B0_3 C06C3 stepping, a new version Intel could be preparing for shipment to clients. Silicon revisions typically begin at A0 and increment as the design evolves. It is rare to see any silicon shipping with the A0 stepping, as later modifications and refinements are made to meet the original specification. Hence, this B0 stepping indicates that this is likely the final revision Intel has prepared for Panther Lake, which is expected to start shipping by the end of 2025, with more SKUs in 2026.As a reminder, the low-power PTL-U models are designed for a 15 W TDP and are expected to come in 6-core and 8-core versions. Some SKUs will feature four high-performance P-cores paired with four LPE-cores, while others will have only two LPE-cores complementing four P-cores. Both families will utilize Xe3-based integrated graphics, with entry models featuring four GPU cores. The more powerful PTL-H line will scale up to around 16 CPU cores, comprising four P-Cores, eight E-cores, and four LPE-cores. Some H-series parts might include up to 12 GPU Xe3 cores for integrated graphics, but the final configurations will be revealed when Intel officially launches the Panther Lake product family.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341446/intel-panther-lake-b0-3-stepping-surfaces-in-firmware-patches",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Intel’s sixth foundry push tests its future in the AI factory race",
      "content": null,
      "source": "SiliconANGLE News",
      "url": "https://siliconangle.com/2025/09/29/ai-factory-foundry-intel-next-era-data-centers-aifactoriesdatacenters/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "This Analyst’s Prediction About NVIDIA (NVDA) Was Right",
      "content": "We recently published Analysts Are Talking About These 10 Stocks as AI Investments Continue to Grow. NVIDIA Corporation (NASDAQ:NVDA) is one of the stocks analysts were recently talking about.\n\nIn December last year, Joseph Moore, Morgan Stanley semiconductor analyst, commented on the volatility NVIDIA Corp (NASDAQ:NVDA) was going through at the time and said the stock would have a strong second half of 2025. The analyst’s call turned out to be correct. Here is what he said at the time:\n\n“I still think when you think about 2025 and AI the story is Blackwell, the product cycle that Nvidia has. I think they’re going to have a huge second half of the year and I think we do have these transitional issues as we’re moving there but I think the stock is very attractive this level. I’m not going to say absolute bottom because it’s volatile but you know it’s very attractive at this level. I think you’re trading at a much lower multiple than some of the AI peers and I really believe that they actually gain share versus custom silicon in 2025. I’m very excited for this custom silicon trend but I still think Nvidia can gain share relative to that in 2025.”\n\nNVIDIA Corp (NASDAQ:NVDA) shares are up 28% so far this year.\n\nNvidia’s latest deal with OpenAI and Intel, along with Oracle’s partnership with OpenAI are showing signs that companies are continuing to spend a fortune on compute, and AI demand won’t slow down anytime soon. But can NVDA shares keep gaining?\n\nNvidia’s Hopper Infrastructure and now Blackwell form the core of AI infrastructure for LLM training and inference. But Nvidia’s growth is slowing compared to previous quarters amid competition and capex spending limitations from major companies. In the recently reported quarter, Nvidia’s annual revenue growth came in at 56%, compared with nearly 100% YoY growth in the past.\n\nWith its strong position in the data center market and rising demand, Nvidia is likely to keep growing, though not at the same pace it has in the past. Increasing competition from major companies like Broadcom is also expected to impact Nvidia’s margins in the long term.\n\nNvidia recently impressed the market by signing an AI infrastructure deal with Intel. Nvidia will invest $5 billion in Intel. Jensen Huang said the deal would open up $50B in TAM for both companies in the data center and PC business.\n\nMacquarie Core Equity Fund stated the following regarding NVIDIA Corporation (NASDAQ:NVDA) in its second quarter 2025 investor letter:",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/analyst-prediction-nvidia-nvda-130104159.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "iOS 26.0.1 Release Date: The Next iPhone Update Is Just Hours Away",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/davidphelan/2025/09/29/ios-2601-release-date-when-the-next-iphone-update-will-land-for-all-users/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Promising Large Cap Stocks To Consider – September 27th",
      "content": "Tesla, Invesco QQQ, NVIDIA, Apple, and Intel are the five Large Cap stocks to watch today, according to MarketBeat’s stock screener tool. Large-cap stocks are shares of publicly traded companies with a market capitalization generally exceeding $10 billion. Investors often view them as relatively stable, blue-chip holdings that tend to offer steady earnings, dividend payouts, and lower volatility compared with smaller-cap firms. These companies had the highest dollar trading volume of any Large Cap stocks within the last several days.\n\nGet alerts:\n\nTesla (TSLA)\n\nTesla, Inc. designs, develops, manufactures, leases, and sells electric vehicles, and energy generation and storage systems in the United States, China, and internationally. The company operates in two segments, Automotive, and Energy Generation and Storage. The Automotive segment offers electric vehicles, as well as sells automotive regulatory credits; and non-warranty after-sales vehicle, used vehicles, body shop and parts, supercharging, retail merchandise, and vehicle insurance services.\n\nInvesco QQQ (QQQ)\n\nPowerShares QQQ Trust, Series 1 is a unit investment trust that issues securities called Nasdaq-100 Index Tracking Stock. The Trust’s investment objective is to provide investment results that generally correspond to the price and yield performance of the Nasdaq-100 Index. The Trust provides investors with the opportunity to purchase units of beneficial interest in the Trust representing proportionate undivided interests in the portfolio of securities held by the Trust, which consists of substantially all of the securities, in substantially the same weighting, as the component securities of the Nasdaq-100 Index.\n\nRead Our Latest Research Report on QQQ\n\nNVIDIA (NVDA)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nRead Our Latest Research Report on NVDA\n\nApple (AAPL)\n\nApple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal computers; iPad, a line of multi-purpose tablets; and wearables, home, and accessories comprising AirPods, Apple TV, Apple Watch, Beats products, and HomePod.\n\nRead Our Latest Research Report on AAPL\n\nIntel (INTC)\n\nIntel Corporation designs, develops, manufactures, markets, and sells computing and related products and services worldwide. It operates through Client Computing Group, Data Center and AI, Network and Edge, Mobileye, and Intel Foundry Services segments. The company's products portfolio comprises central processing units and chipsets, system-on-chips (SoCs), and multichip packages; mobile and desktop processors; hardware products comprising graphics processing units (GPUs), domain-specific accelerators, and field programmable gate arrays (FPGAs); and memory and storage, connectivity and networking, and other semiconductor products.\n\nRead Our Latest Research Report on INTC\n\nRead More",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/29/promising-large-cap-stocks-to-consider-september-27th/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Stock market today: Dow, S&P 500, Nasdaq nudge higher as Wall Street grapples with shutdown risk",
      "content": "US stocks edged higher on Monday as investors eyed a looming US government shutdown that risks delaying the release of the all-important monthly jobs report later in the week.\n\nThe S&P 500 (^GSPC) gained 0.3%, while the tech-heavy Nasdaq Composite (^IXIC) rose 0.5%, with the two gauges building on Friday's rebound. Meanwhile, the Dow Jones Industrial Average (^DJI) rose almost 0.2%.\n\nMarkets are assessing the odds of a US government shutdown on Wednesday this week, as a standoff between Republicans and Democrats goes down to the wire. Trump set a meeting with congressional leaders on Monday, likely the last hope of avoiding a halt to federal funding. Odds of a shutdown are near 80%, according to Polymarket.\n\nThe Department of Labor on Monday said that the Bureau of Labor Statistics, which releases key economic data, including Friday's planned monthly jobs report, will \"suspend all operations.\"\n\n\"Economic data that are scheduled to be released during the lapse will not be released,\" the department said as part of a shutdown contingency plan.\n\nThe BLS's monthly job updates, as well as its release of consumer and producer inflation reports, have been key to the Federal Reserve's policy setting and the bets on interest rate cuts that have helped buoy stocks.\n\nLast week, jobless claims fell short and GDP growth was revised higher, fueling speculation that the Fed may not cut rates as aggressively as hoped. That puts even more weight on the jobs report, amid forecasts that nonfarm payrolls grew 43,000 and the unemployment rate stayed at 4.3% for the month.\n\nAt the same time, investors are regrouping after a losing week that saw cracks emerge in AI-focused stock trading as well as surprise tariff announcements from President Trump for Oct. 1. On Monday, Trump added to those tariff announcements by proposing new duties on movies and furniture.\n\nDespite that, stocks are still on pace to finish September — and the third quarter — with gains. The S&P 500 is up 2.8% month-to-date, while the Dow has added 1.5%. The Nasdaq, boosted by tech, has rallied 2.9%.\n\nLIVE COVERAGE IS OVER\n\n24 updates",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/live/stock-market-today-dow-sp-500-nasdaq-nudge-higher-as-wall-street-grapples-with-shutdown-risk-133119017.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "New Snapdragon Mobile And PC Platforms Set To Fuel A New Breed Of Agentic AI",
      "content": null,
      "source": "Forbes",
      "url": "https://www.forbes.com/sites/davealtavilla/2025/09/29/new-snapdragon-mobile-and-pc-platforms-set-to-fuel-a-new-breed-of-agentic-ai/",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Numerion Carbon 3.0.1 (Maya 2023-2026) Win",
      "content": "Numerion Carbon 3.0.1 (Maya 2023-2026) Win\n\nNumerion Carbon 3.0.1 (Maya 2023-2026) Win\n\n\n\n\n\nTitle: Numerion Carbon 3.0.1 (Maya 2023-2026) Win\n\nInfo:\n\nIn 2014, Carbon made its big screen debut in DreamWorks Animation’s “How to Train Your Dragon 2” where it was used for some of the most challenging CFX shots.\n\nEver since then, Carbon has been used extensively in the VFX industry for a variety of applications, ranging from sails, ropes, chains, plants, to the most demanding Hero cloth and skin simulations for animated and Digi-double simulations.\n\nMost of your favorite blockbuster movies from the past 10 odd years have been relying on Carbon in one way or another.\n\nOur Carbon For Houdini and Carbon For Maya plugins are created by the same team, and using the same underlying c++ libraries, so users can easily use either platform and find themselves in a familiar environment with comparable features and simulation behavior.\n\nUniversal, Flexible, and Lightweight\n\nCarbon itself is not integrated in an inaccessible closed-up larger software package, like most other Cloth solvers on the market. Carbon at its heart is a lightweight, dynamic and innovative c++ library, developed from the ground up by our UK based team without relying on any third party libraries aside from Intel TBB. Which means you can easily and quickly integrate Carbon into any c++ based application, no hoops – no headaches.\n\nWe have created commercial Maya and Houdini plugins, but also integrated into UE5 and Unity for custom projects. Some of our customers brought Carbon into their own plugins in applications like UE5 and Rhino.\n\nQuality and Performance\n\nCarbon Cloth uses an advanced cloth model to deliver high quality cloth simulation which combined with robust multi-layer collision, supports the very highest quality Hero cloth simulation. Highly optimized code combined with a multi-threaded design from the ground up, ensures that Carbon delivers high quality with maximum performance.\n\nCarbon Cloth is production proven for simulation of clothing, ropes, sails, nets, and deformable skin.\n\nToday, Carbon Cloth is used by many large and small studios, around the world.\n\nRobust Collision handling\n\nCarbon Cloth provides very advanced collision and can handle collision between fast moving objects with ease.\n\nThe Carbon Cloth collision supports action AND reaction between:\n\nCloth and Character\n\nCloth and Cloth as layers\n\nCloth and Cloth as self collision within one cloth\n\nCloth and Rigid Bodies like buttons, chains etc.\n\nCloth and Character skin (where character skin is also a Carbon Morph)\n\n\n\nhttps://rg.to/file/d0d576e77f6b37731321f83c919088a8/NumerionCarbon3.0.1Maya2023-2026Win.part1.rar.html https://rg.to/file/baaece03d750270ca792ca8006e1f627/NumerionCarbon3.0.1Maya2023-2026Win.part2.rar.html https://rg.to/file/865fe1786102cab16d5d3c6eb898872a/NumerionCarbon3.0.1Maya2023-2026Win.part3.rar.html https://rg.to/file/3a8038863293f0f61985ec67820db56c/NumerionCarbon3.0.1Maya2023-2026Win.part4.rar.html\n\nhttps://alfafile.net/file/A3wsE https://alfafile.net/file/A3ws7 https://alfafile.net/file/A3wsm https://alfafile.net/file/A3wsb\n\nhttps://nitroflare.com/view/A7DF2765DA46C43/NumerionCarbon3.0.1Maya2023-2026Win.part1.rar https://nitroflare.com/view/300CDE05D53E018/NumerionCarbon3.0.1Maya2023-2026Win.part2.rar https://nitroflare.com/view/E9D4DB031D7F90D/NumerionCarbon3.0.1Maya2023-2026Win.part3.rar https://nitroflare.com/view/6FD992BA947A8F9/NumerionCarbon3.0.1Maya2023-2026Win.part4.rar",
      "source": "Cgpersia.com",
      "url": "https://cgpersia.com/2025/09/numerion-carbon-3-0-1-maya-2023-2026-win-200606.html",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "Top Stock Movers Now: Electronic Arts, Western Digital, Intel, and More",
      "content": "Key Takeaways\n\n-\n\nMajor U.S. equities indexes climbed in recent trading as tech stocks gained.\n\n-\n\nElectronic Arts agreed to go private in a $55 billion deal with a consortium of investors, sending shares higher.\n\n-\n\nShares of oil companies lost ground as OPEC+ announced plans to increase oil…\n\nThis story appeared on finance.yahoo.com , 2025-09-29 17:03:48.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/6af1c3f98ae6e11c",
      "timestamp": "2025-09-29"
    },
    {
      "headline": "China's Zhaoxin breaks into healthcare: 6,000+ hospital PCs run x86 chips against Intel, AMD",
      "content": "China's Zhaoxin breaks into healthcare: 6,000+ hospital PCs run x86 chips against Intel, AMD\n\nShanghai Zhaoxin Semiconductor has scored a breakthrough in China's healthcare sector. On September 23, the x86 chipmaker announced that over 6,000 of its processor-powered desktops won a major hospital procurement bid, an important step for Chinese x86 CPUs in mission-critical medical deployments.\n\nChina's healthcare system is in the midst of rapid digital transformation, with ambitious goals to modernize core hospital information systems by 2025. The transition requires computing platforms that are both powerful and easy to deploy, critical traits in an industry long burdened by fragmented IT ecosystems.\n\nChina's healthcare IT fragmentation\n\nFragmentation remains one of healthcare IT's biggest challenges. Core systems such as hospital information systems (HIS), laboratory information systems (LIS), and picture archiving and communication systems (PACS) still depend on foreign databases like Oracle and SQL Server, which command over 80% market share. Domestic databases account for less than 15%, and migrating decades of records is complicated by format incompatibility and strict real-time demands.\n\nAt one leading provincial hospital, 40% of legacy HIS systems still run on outdated VB6 architecture, with upgrades costing up to CNY800,000 (approx. US$112,500) per system. Provinces are now piloting phased adaptation, rushing \"emergency fixes\" for critical platforms like PACS, while allowing a three-year transition for non-core systems such as office software. The dual-track approach underscores the clash between policy mandates and technical realities.\n\nSmaller hospitals face even sharper challenges: nearly 30% of their systems are too old to run domestic operating systems or new applications, leaving them stuck between costly legacy reuse and risky data migration.\n\nZhaoxin's processor ecosystem strategy\n\nZhaoxin is tackling these pain points with processors that combine compatibility and performance. The firm has independently developed six generations of high-performance CPUs, including the KaiXian desktop and KaiSheng server lines, with products spanning AI PCs, desktops, notebooks, all-in-ones, servers, and embedded platforms.\n\nThe chips support both domestic operating systems: UnionTech Software UOS, NeoKylin, Zhongkefangde Software, and Microsoft Windows. They are compatible with mainstream applications, cloud platforms, databases, development tools, and AI models, while keeping software migration costs low.\n\nFor healthcare, Zhaoxin has introduced \"seamless migration\" and \"one-stop support\" solutions. It has also set up medical application innovation centers with partners, offering hospitals end-to-end guidance from chips to operating systems and applications.\n\nToday, Zhaoxin works with nearly 4,000 partners across systems integration, software, and hardware. Together with domestic OS vendors, it has completed more than 200,000 software-hardware adaptation projects, building a full-stack ecosystem from processors to databases and applications.\n\nFrom 2022 to 2024, Zhaoxin recorded revenues of CNY340 million, CNY555 million, and CNY889 million, respectively, with a compound annual growth rate of 61.71%.\n\nRivaling Intel and AMD in hospitals\n\nBeating out Intel and AMD in a high-profile bid highlights Zhaoxin's progress in performance, compatibility, and cost efficiency. Its processors are built to handle demanding healthcare workloads — from electronic medical records to telemedicine platforms — while maintaining stable operations.\n\nWith integrated security, Zhaoxin CPUs protect patient data across its lifecycle: collection, transmission, storage, and use. This meets China's strict compliance standards, as hospitals lean on secure, high-performance platforms for data-heavy applications.\n\nAs digitalization accelerates, medical data will expand from text records and lab reports to imaging archives and real-time vital signs. Zhaoxin's processors can manage these workloads, minimizing downtime and enabling use cases such as AI diagnostics and cross-regional data sharing.\n\nChina's x86 chips gain traction\n\nThe hospital bid underscores the rising role of Chinese x86 chips in public welfare sectors. By offering strong performance and ecosystem compatibility, Zhaoxin is gaining ground in healthcare digitalization, an arena once dominated by foreign technology.\n\nIf sustained, these gains could speed the localization of hospital IT infrastructure, supporting China's drive for tech independence while laying the groundwork for smarter, more secure healthcare systems.\n\nArticle edited by Jack Wu",
      "source": "Digitimes",
      "url": "https://www.digitimes.com/news/a20250924VL209/x86-chips-smart-healthcare-shanghai.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "These Stocks Are Moving the Most Today: Wolfspeed, Boeing, Nvidia, Intel, Jefferies, Firefly Aerospace, and More",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/b51f9bf708268820",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Qualcomm’s Snapdragon X2 Elite: The good, the bad, and the ugly",
      "content": "Qualcomm’s scintillating new Snapdragon X2 Elite chips have prompted a ton of conversations in the past few days. Can they make it? What do you like about them? And so on.\n\nWhile I can’t say whether or not the Snapdragon X2 Elite and Elite Extreme will eventually succeed, I can offer you an inside look at what people are talking about–at least what I’ve heard and overheard–at Qualcomm’s Snapdragon Summit in Hawaii. If you want to catch up on all the news, the Snapdragon X2 and X2 Elite offer more cores at up to 5GHz speeds, includes optional embedded memory, and preserves the performance on battery from the first generation.\n\nThe good: eye-watering performance\n\nIf you want a general-purpose productivity laptop, the first-generation Snapdragon X Elite was nearly perfect. The new X2 Elite Extreme looks to be even better, with (controlled) benchmarks that simply blow away Intel’s Core Ultra (Lunar Lake) and AMD’s Ryzen AI 300 chips, from CPU to GPU to the AI-enabling NPU. Qualcomm is really doing almost everything consumers are asking of it in this space.\n\nThe CPU benchmarks look particularly juicy. Compared against rival chips in today’s laptops, the Snapdragon X2 Elite absolutely smokes all comers in the Cinebench benchmark beloved by reviewers, in both single- and multi-core tests.\n\nMark Hachman / Foundry\n\nAnd the Snapdragon X2 Elite’s NPU offers a whopping 80 TOPs, leaving the competition in the dust. Whether consumers are asking for more TOPS from an NPU, though, is a question mark.\n\nRoughly doubling the TOPS from the first version looks great on paper, and certainly bigger numbers are better. But there’s a lot being bet on whether consumer applications will be able to take advantage of its prowess, including this concept of agentic AI everyone is talking about. No one is still quite sure whether that will happen.\n\nUL’s Procyon Computer Vision benchmark tests AI inference performance and can tap into NPUs, unlike some other AI benchmarks. Mark Hachman / Foundry\n\nIt depends on how you see it: Is local AI still a selling point? Either way, the Snapdragon X2 Elite appears loaded with hardware capable of blasting through most of the tasks you throw at it, AI or not.\n\nThe bad: Lukewarm PC vendor support, games, and lack of battery life talk\n\nI couldn’t help but notice that only Asus and HP endorsed the Snapdragon X2 architecture, and via video to boot — not in person at the Snapdragon Summit. The odd “agentic AI” Humain Horizon Pro laptop (which won’t use the X2, but the X1) was there, but not Qualcomm’s established customers. And where was longtime Qualcomm backer, Lenovo?\n\nSure, new partners could always be announced. But I had questions.\n\nAnother question: 3D graphics performance. Yes, supposedly the Snapdragon X2 Elite about doubles the performance of the first-gen X Elite platform, which played (some) games at roughly 30 frames per second at 1080p Low performance. Doubling that is, what, 60 fps at the same resolution and image quality? What about all the games that simply refuse to run well on the first-gen Snapdragon chips?\n\nOn the more enthusiast end of things, “there’s nothing preventing” the Snapdragon X2 from connecting to a discrete GPU like Nvidia’s GeForce RTX, according to Qualcomm’s senior vice president Kedar Kondap…but it doesn’t appear like it has, or will. This is a tough one: Gaming is often seen as a high-profile design win, and proof that a chip like the X2 Elite should be seen as a sexy, high-margin gaming CPU. But doing so would immediately cut into a key Snapdragon benefit: long battery life.\n\nGaming on a phone, weirdly, seems more viable with a Qualcomm Snapdragon processor than on a PC. Qualcomm\n\nAnd that was weird, too: Qualcomm really downplayed the battey life of a Snapdragon X2 laptop, referring it to “multi-day” on a couple of occasions. I’m not sure if that was because the competitive landscape had erased that advantage, or what. But it simply was not a big focus.\n\nAgain, Qualcomm does have a cross to bear in its Arm legacy, and how that affects application compatibility. This only really affects some weird, dusty old business utilities, the occasional printer, and games. But games are the one area where it can make inroads, though Snapdragon simply can’t offer the “it just works” assurance of its X86 rivals anytime soon.\n\nThe ugly: A grab bag\n\nNaturally, any new launch offers opportunities for criticism.\n\nNot only did people take issue with the Microsoft-esque naming scheme — the X2 Elite Extreme, really?! — critics made the very valid point that this was Qualcomm’s first major architecture launch in years. Reviewers got hands-on tests of the X1 Elite two long years ago, in October 2023, ahead of the Snapdragon’s launch alongside Copilot+ PCs in May 2024. Qualcomm followed it up with the cut-down X1 Plus and X in the interim.\n\nAs one attendee pointed out, “You can’t play on that timetable and expect to win against Intel and AMD,” which launch a new or updated mobile chip architecture on an annual cadence.\n\nIntel has been talking about Panther Lake for months…and has already shown more demo systems than Qualcomm has for the X2 Elite. Adam Patrick Murray / Foundry\n\nQualcomm’s X1 Elite also signaled to Intel and AMD that those rivals needed to have their own chips in order. But tying Snapdragon X to Copilot+ and Microsoft’s beleaguered Recall didn’t do much for Qualcomm, if anything. Qualcomm was the flag-bearer for Windows on Arm, and its (now largely undeserved) reputational concerns about app compatibility. Then Intel’s Lunar Lake came along, and offered a very competitive — and maybe even better — chip without any of that baggage.\n\nOne laptop maker told me that they had bought into the original X1 Elite in part as a bargaining chip with Intel. People had a lot of questions about what that meant for Intel’s upcoming “Panther Lake” chip, which should be unveiled this fall.\n\nIn my personal opinion, one of the best things Qualcomm ever did was to simply offer a compelling third option to Intel and AMD. That means we all benefited from an competitive market for PC processors that only continues to heat up.\n\nDisclosure: Qualcomm held its press briefings in Hawaii, and would not pre-brief reporters in other locations or over video meetings. They paid for my room, boarding, and travel expenses, but did not ask for or exert any editorial control over this story or other PCWorld content.",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2922904/qualcomms-snapdragon-x2-elite-the-good-the-bad-the-ugly.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Intel, AMD & Arm All Have Notable EDAC Driver Additions For Linux 6.18",
      "content": "The Error Detection And Correction \"EDAC\" subsystem continues seeing a lot of new hardware support and code churn across AMD, Intel, and Arm hardware platforms for the Linux kernel. With Linux 6.18 there are several notable additions.A new EDAC driver for Linux 6.18 is \"a72_edac\" as EDAC support for the Arm Cortex-A72 . While the Arm Cortex-A72 cores have been out for years, with Linux 6.18 there is finally this EDAC driver for being able to report L1 and L2 cache errors with the mainline kernel.Another new EDAC driver for Linux 6.18 is for the AMD Versal NET DDR memory controller for these AMD-Xilinx Versal SoCs.Also on the AMD side, and as noted in the earlier article about the many AMD CPU features in Linux 6.18 , there are a number of new AMD CPU models added to the AMD64 EDAC driver. As explained there the new CPU support appears to include both next-gen AMD EPYC Zen 6 processors with up to 16 memory channels as well as some unreleased Family 26 models limited to 8 memory channels -- perhaps next-gen AMD EPYC 8004 parts?\n\nOn the Intel side, there is support for two more Alder Lake S SoCs added to the ie31200_edac driver. Those Alder Lake S parts added are the Intel Core i7-12700K and Core i5-12600K processors that were mistakenly left out of the driver previously for those prior-generation CPUs.The Intel EDAC driver code has also become more flexible for better handling the addition of new generations of CPUs with more memory controllers.More details on all of the EDAC feature changes for Linux 6.18 via this pull request",
      "source": "Phoronix",
      "url": "https://www.phoronix.com/news/Linux-6.18-EDAC",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "US Stock Markets Today: S&P 500, Nasdaq Open In Red Amid Government Shutdown Indications",
      "content": "Wall Street benchmarks witnessed a slippery start on Tuesday, with investor sentiment taking a hit on US Vice President JD Vance's indication of a government shutdown.\n\nAn hour into trade, the Dow Jones Industrial Average saw a decline of 0.18%, the S&P 500 was also down 0.14% while Nasdaq fell 0.10%.\n\nThe uncertainty comes as the S&P 500 is headed for its best September in 15 years, fuelled by looser policy and optimism over artificial intelligence as per news agency Bloomberg.\n\n“The main focus will be the US labor market, which should either confirm or challenge expectations of two more rate cuts in 2025,” said Susana Cruz, a strategist at Panmure Liberum told Bloomberg. “If the shutdown delays the release, that could spark some anxiety.”\n\nSix of the 11 sectoral indices was trading in green. Energy sector led the decline, while the healthcare sector led the advancing sectors.\n\nNvidia Corp., Palantir Technologies, and Alibaba ADR were amongst the gainers for the day. On the other hand, Tilray Inc., Intel Corp., and Tesla were in the red.\n\nSpot gold rose 0.34% to $3,847.03 an ounce after paring record highs. After surging more than 10% this month on optimism over US interest rate cuts and haven demand, traders speculated that Chinese investors pared exposure ahead of the Golden Week holiday, as per Bloomberg.\n\nCrude oil prices slipped, with the West Texas trading 1.77% lower at $62.33 per barrel.\n\nThe Bloomberg Dollar Index fell 0.16%, with the British Pound rising 0.15% at $1.3449 and the Japanese yen down to 147.82 per dollar. Bitcoin, the largest traded cryptocurrency saw a decline of 0.95% to $113,233.9700.\n\nAs the US market opened, the Dow Jones Industrial Average fell 12 points or 0.03%, the S&P 500 was also down 0.12% while Nasdaq fell 0.22% or nearly 50 points.",
      "source": "Ndtvprofit.com",
      "url": "https://www.ndtvprofit.com/markets/us-stock-markets-today-sp-500-nasdaq-open-in-red-amid-government-shutdown-indications",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Stock Market Today: Dow, S&P 500, Nasdaq Set to Open Down as Government Shutdown Nears; Dollar Falls; Bitcoin Prices Recover; China Data; Wolfspeed Stock, Intel, Nvidia and More Movers",
      "content": "LIVE\n\nStock Market News Today: Dow Set to Open Down Amid Government Shutdown Risk\n\nThe S&P 500 and the Nasdaq are also falling in premarket trading. Treasury yields are down and Bitcoin prices are up.\n\nLast Updated:\n\nSep. 30, 2025 at 4:00 AM ET\n\nKey Events\n\nLatest Updates\n\nStock futures were…\n\nThis story appeared on barrons.com , 2025-09-30 07:24:23.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/30e44d3fa686ff85",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "The Linux kernel just got some important upgrades - here's what's new in 6.17",
      "content": "Jon Hicks/Stone/Getty Images\n\nFollow ZDNET: Add us as a preferred source on Google.\n\nZDNET's key takeaways\n\nLinux 6.17 features significant CPU improvements.\n\nIt addresses the eternal Spectre and Meltdown security holes.\n\nThe next release, 6.18, will be a long-term support kernel.\n\nLinus Torvalds is the first to admit that there have been more exciting Linux kernel releases. He announced the release of the 6.17 Linux kernel by writing, \"It's not exciting, which is all good. I think the biggest patch in there is some locking fixes for some Bluetooth races that could cause use-after-free situations. Whee -- that's about as exciting as it gets.\"\n\nAlso: 5 of my favorite Linux distros ready to use out of the box - no setup required\n\nWith that said, 6.17 does come with some notable performance boosts, expanded hardware support, and a medley of improvements aimed at server, desktop, and embedded systems.\n\nThe most important of these improvements is for the AMD Ryzen chip. By delivering improved hardware feedback scheduling for Ryzen chips via the new Hardware Feedback Interface (HFI) driver, hybrid-core laptops and desktops will be more intelligent in handling workload distribution with SmartMux support. The feature works by auto-switching between integrated and discrete graphics based on your workload. So, depending on what you're doing, it can either save power or boost your performance as needed.\n\nAlso: Is this Arch distro the 'ultimate' Linux? That depends on your GPU\n\nMeanwhile, Intel-powered computers are gaining better graphics support. That's especially true for the forthcoming Xe3 (Panther Lake) systems. You'll see these chips in Core Ultra Series 3 laptops by the holidays. Early tests indicated that Linux desktop gamers can expect significant speed improvements in some of their favorite games. Linux 6.17 also comes with Error Detection and Correction (EDAC) support for Intel's Bartlett Lake processors. EDAC is the mechanism used to spot, report, and correct memory errors.\n\nNot every processor will see improvements with 6.17. Some proposed RISC-V patches ticked off Torvalds because they were both late and poorly written. He described them as: \"Garbage. And by 'garbage,' I really mean it. This is stuff that nobody should ever send me, never mind late in a merge window.\" Better luck next release, folks.\n\nThis release also revamps CPU vulnerability management by unifying kernel command-line mitigation options for ancient security holes, such as Spectre and Meltdown. Despite their age, these security problems persist. The new kernel makes it easier for server administrators to streamline performance tweaks and security controls.\n\nOn the storage front, Btrfs gains experimental large-folio support for efficient memory access. In the same release, the most popular Linux file system, Ext4, introduces buffered I/O control. Two new system calls, file_getattr() and file_setattr(), are included for advanced inode file system attribute management.\n\nAlso: I install these 11 apps on every new Linux system, and you should, too - here's why\n\nFor networking, the enhancements include new gateway routing for the Management Component Transport Protocol (MCTP), expansion of the multipath TCP feature, and added support for the DualPI2 congestion control protocol.\n\nLinux 6.17 is not a long-term support (LTS) release. Users who require extended support can stick to 6.12 or wait for the anticipated 6.18 LTS milestone.\n\nAlso: How much RAM does your Linux PC really need in 2025? I did the math so you don't have to\n\nDistributions such as the forthcoming Ubuntu 25.10, currently in beta, have already adopted 6.17 in their latest builds. You can expect to see cutting-edge, rolling distributions, such as Arch Linux, openSUSE Tumbleweed, and Fedora Rawhide, release the 6.17 kernel in the next few days and weeks.\n\nAs usual, the release opens the merge window for kernel 6.18, with dozens of pull requests queued up for review by Torvalds and the core maintainers. Since it will be an LTS release, I expect to see significant improvements in this anticipated end-of-the-year release.",
      "source": "ZDNet",
      "url": "https://www.zdnet.com/article/the-linux-kernel-just-got-some-important-upgrades-heres-whats-new-in-6-17/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Intel's original 64bit extensions for x86",
      "content": "Intel’s original 64bit extensions for x86\n\nIntroduction\n\nIn the late 1900s, Intel was fully invested in Itanium (IA-64) being their future 64bit architecture.\n\nAt that time (allegedly around 1997-1998), some Intel engineers – who were more cautious than their management – built a 64bit extension for their x86 processors as a backstop. It never shipped:\n\nIntel’s Pentium 4 had our own internal version of x86–64. But you could not use it: we were forced to “fuse it off”, meaning that even though the functionality was in there, it could not be exercised by a user.\n\nThis was a marketing decision by Intel — they believed, probably rightly, that bringing out a new 64-bit feature in the x86 would be perceived as betting against their own native-64-bit Itanium, and might well severely damage Itanium’s chances.\n\n– Bob Colwell\n\nAMD announced AMD64, their own 64bit extension to x86, in 1999 (and shipped it in 2003), condemning both Itanium and Intel’s own x86 extension to obscurity.\n\nIntel implemented AMD’s design in Project Yamhill and shipped its first processors with AMD64 in 2004.\n\nHow did Intel’s design look like?\n\nWhile AMD’s 64bit extension design that repurposed inc/dec instructions as the REX prefix is well-documented, there is very little known about Intel’s own 64bit extension design.\n\nHere is what can be reconstructed from Intel’s patent applications from 2000 and 2003:\n\nAn instruction having [a] format […] — where the mode field is 01B , the R/M field is 100B , the index field is 100B — has addressing mode information that is currently unsupported in the IA-32 architecture regardless of the value of the scale field.\n\nAn instruction of [that] format […] thereby includes heretofore unused bit fields (e.g., the two bits of scale field, bits of displacement, etc.), that can support an expanded logical register set for existing instructions formats and legacy operands.\n\nMaterial from the Bristol Community College also mentions this specific combination of bits:\n\nNote that this addressing mode does not allow the use of the ESP register as an index register.\n\nPresumably, Intel left this particular mode undefined to provide the ability to extend the addressing modes in a future version of the CPU.\n\nDifferences from AMD64\n\nAMD’s REX prefix introduced 1 bit R to extend the 3-bit register to 4 bits, allowing access to 16 registers.\n\nThe prefix also added 1 bit W to extend operand size, 1 bit X to extend SIB byte’s index and 1 bit B to extend SIB byte’s base.\n\nIntel’s approach would have added 2 additional bits to the existing 3-bit register encoding, and introduced a second, additional 5-bit register encoding.\n\nIt appears this encoding would have provided a future expansion possibility to 32 registers, even if the implementation may have been limited to 16 registers at first.\n\nIt is unclear what the equivalent of (or the alternative to) AMD64’s W , X and B bits would have been under Intel’s design.\n\nConclusion\n\nSadly, there is no definitive information on how close the patents were to what was shipped (fused-off) in Intel processors of that specific time period.",
      "source": "Soc.me",
      "url": "https://soc.me/interfaces/intels-original-64bit-extensions-for-x86.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Dave Bautista & Jack Champion in 'Trap House' Action Thriller Trailer",
      "content": "Dave Bautista & Jack Champion in 'Trap House' Action Thriller Trailer\n\n\"If we don't get 'em, the cartel will, right? And they don't forget...\" Aura Entertainment has unveiled the official trailer for Trap House, an action thriller from filmmaker Michael Dowse (of Fubar, Goon, What If, Stuber, 8-Bit Christmas). This is set for a full nationwide release in November just before the Thanksgiving holiday. Dave Bautista leading this story about rogue teens getting into big trouble! Trap House is centered on a team of elite DEA agents whose rebellious teenage children use their parents' own tactics—surveillance, infiltration, non-lethal weapons, and special intel—to rob a ruthless drug cartel. Along with Dave Bautista, the movie also stars Jack Champion, Sophia Lillis, Tony Dalton, Whitney Peak, Kate Del Castillo, Zaire Adams, and Bobby Cannavale. The tagline within the trailer: \"This isn't a raid. It's a reckoning.\" This is a totally nuts plot - the kids want to get revenge because the death benefits for a DEA agent are bad, so they decide to go rob the cartels all on their own? Yeah um that seems dangerous, remarkably dangerous.\n\nHere's the main official trailer (+ poster) for Michael Dowse's film Trap House, direct from YouTube:\n\nIn El Paso, Texas, an undercover DEA agent (Dave Bautista) and his partner embark on a game of cat and mouse with their own teenage children, who are using their parents' tactics – surveillance, infiltration, and non-lethal weapons – to rob a dangerous drug cartel. Trap House is directed by acclaimed Canadian filmmaker Michael Dowse, director of the movies Fubar & Fubar: Balls to the Wall , It's All Gone Pete Tong, Take Me Home Tonight, Goon, What If, Stuber, Coffee & Kareem, 8-Bit Christmas, plus the TV series \"Me\" and \"The Sticky\" most recently. The screenplay is written by Gary Scott Thompson and Tom O'Connor; from a story by Gary Scott Thompson. It's produced by Dave Bautista, Rebecca Feuer, Sarah Gabriel, Marc Goldberg, Todd Lundbohm, Jonathan Meisner, Christian Mercuri, and Michael Pruss. Aura Entertainment will debut Dowse's Trap House movie in US theaters starting November 14th, 2025 this fall. Look good?",
      "source": "First Showing",
      "url": "https://www.firstshowing.net/2025/dave-bautista-jack-champion-in-trap-house-action-thriller-trailer/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Intel Corporation (INTC): A Bull Case Theory",
      "content": "We came across a bullish thesis on Intel Corporation on Long-term Investing’s Substack by Sanjiv. In this article, we will summarize the bulls’ thesis on INTC. Intel Corporation's share was trading at $31.22 as of September 24th. INTC’s trailing and forward P/E were 88.08 and 47.39 respectively according to Yahoo Finance.\n\nIntel (INTC) Stock: Morgan Stanley Reiterates Equal Weight, Cautious on Turnaround\n\nPhoto by Slejven Djurakovic on Unsplash\n\nIntel Corporation (INTC) has been navigating a turbulent period following setbacks in 2020, with the company working to regain its footing in advanced chip manufacturing. As of mid-2024, Intel had returned to leading-edge production through substantial investments, under a dual strategy of partially outsourcing manufacturing while trying to make Intel Foundry Services (IFS) profitable—a goal management does not expect to achieve until 2030.\n\nDespite these efforts, the company’s competitive position remains challenging, particularly versus TSMC and Samsung, the dominant players in 3nm–5nm semiconductor manufacturing, and the market initially remained skeptical, with INTC shares declining sharply after disappointing Q2 results in August 2024.\n\nMomentum shifted dramatically in 2025 following a series of strategic developments. Pat Gelsinger’s departure as CEO in March and the appointment of Lip-Bu Tan coincided with the U.S. government acquiring a 10% equity stake in Intel through undisbursed CHIPS Act grants and the Secured Enclave program, effectively designating Intel as a national champion for domestic chip production. This move was followed by major strategic investments from SoftBank and Nvidia, with Nvidia taking a $5 billion stake at $23.26 per share, signaling collaboration on AI-focused chips integrating Intel CPUs with Nvidia GPUs and expanding AI computing infrastructure.\n\nThese developments have propelled INTC shares sharply higher, with year-to-date gains of over 36% leading up to the Nvidia investment. While the market momentum is undeniable, Intel’s future performance will be influenced by government involvement in strategic decision-making and its ability to execute on these collaborations. The investment case now balances the potential upside from increased AI-related orders and strategic positioning against the complexity and uncertainty of government influence, making valuation challenging but the stock an intriguing prospect for investors watching U.S.-based semiconductor growth.\n\nPreviously we covered a bullish thesis on Intel Corporation (INTC) by DeepValue Capital in April 2025, which highlighted AI inference, domestic chip manufacturing, leadership under Lip-Bu Tan, and cost-cutting initiatives. The company's stock price has appreciated approximately by 59% since our coverage. This is because the thesis played out amid renewed investor confidence. Sanjiv shares a similar perspective but emphasizes government stakes and strategic partnerships with Nvidia and SoftBank as key catalysts.",
      "source": "Yahoo Entertainment",
      "url": "https://finance.yahoo.com/news/intel-corporation-intc-bull-case-144310896.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Ambitious Wee Beastie Project Aims To Put Desktop NVIDIA RTX 4070 GPU Into 4.75 L Chassis",
      "content": "A rift appears to be forming in the desktop PC market, with full-size desktops on one side and mini PCs on the other side. Of course, there is small, but dedicated community that has sprung up around SFF PCs, but those are often limited, with many calling for flex PSUs and other compromises. The Wee Beastie, a new project on Kickstarter , is a small form-factor PC that hopes to cut back on the compromises, claiming to offer a powerful gaming and LLM-oriented system with an upgradeable dGPU in just 4.75 L volume—this is just 0.25 L more than the Framework Desktop PC , which uses an AMD Ryzen AI+ 395 Max with an iGPU. That said, even the pre-release Kickstarter marketing leaves some questions.The Wee Beastie Super Mini Fishtank, as it is called, is a mini PC with up to an Intel Core Ultra 7 255H CPU and NVIDIA GeForce RTX 4070 12 GB GPU. It will also be available with up to 128 GB of DDR5 RAM and a 16 TB SSD, and it boasts Wi-Fi 7 and room for up to 13 case fans. It will also contain an internal PSU capable of 400 W, which technically falls well below the 550 W we recommend for a desktop RTX 4070. Although the GPU shown on the Kickstarter page has the \" AD104-251-A1\" associated with the desktop variants of the RTX 4070 , the PSU output suggests that there will be some power throttling or down-tuning at play, so RTX 4070 Mobile performance might be what's to be expected here. Often, the most challenging part of projects like these, as was the case with the custom expansion modules on the Framework Laptop 16 until recently, is supporting the MXM standard for future hardware revisions. Although MXM modules are technically an open standard, like ATX, it is not commonly used due to limited demand and size constraints. Currently, the Kickstarter has completed funding, having reached $53,763 of its $2,570 goal, and the SFF PC looks to be going into production as soon as 2026.",
      "source": "Techpowerup.com",
      "url": "https://www.techpowerup.com/341473/ambitious-wee-beastie-project-aims-to-put-desktop-nvidia-rtx-4070-gpu-into-4-75-l-chassis",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Hance will demo its kilobyte-size AI audio processing software at TechCrunch Disrupt 2025",
      "content": "Hance is working on low energy-consuming, on-device processing that's already attracted the likes of Intel.\n\nThis story appeared on techcrunch.com , 2025-09-30 16:22:28.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/31a4a17bbcaa9dbc",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Optional Windows 11 September update adds tons of new preview features",
      "content": "Other Windows 11 bug fixes\n\nIn addition to new features, here are some noteworthy bug fixes:\n\nIn File Explorer, accented backgrounds are removed in the “Open with” list, overlapping icons and text is fixed when using increased text scaling, and cloud files launch faster now.\n\nAn issue when starting Hyper-V virtual machines with TPM on Arm64 devices has been fixed.\n\nAn issue where some characters didn’t display correctly when Chinese IME was being used.\n\nAn issue where you couldn’t connect to shared files and folders when using the SMB v1 protocol over NetBT was fixed.\n\nThere is still an issue where DRM content can fail to play in Blu-ray/DVD apps (but not in streaming apps like Netflix).",
      "source": "PCWorld",
      "url": "https://www.pcworld.com/article/2925329/optional-windows-11-september-update-adds-tons-of-new-preview-features.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Ukraine Preparing New High-Profile Provocation – Russian Intel",
      "content": "https://sputnikglobe.com/20250930/ukraine-preparing-new-high-profile-provocation--russian-intel-1122889214.html\n\nZelensky Preparing New High-Profile Provocation - Russian Foreign Intel\n\nZelensky Preparing New High-Profile Provocation - Russian Foreign Intel\n\nSputnik International\n\nRussian Foreign Intelligence Service reports that the Kiev regime, after organizing provocations with UAVs in the airspace of Poland and Romania, is not abandoning its attempts to draw European NATO countries into armed confrontation with Moscow.\n\n2025-09-30T08:45+0000\n\n2025-09-30T08:45+0000\n\n2025-09-30T09:22+0000\n\nworld\n\nukraine\n\nrussian foreign intelligence service\n\nrussia\n\nvolodymyr zelensky\n\nkiev\n\npoland\n\nnato\n\nhttps://cdn1.img.sputnikglobe.com/img/07e9/04/14/1121899180_0:160:3072:1888_1920x0_80_0_0_d7a560df4d542add4f92166fe5b4d4bb.jpg\n\n\"Kiev is preparing a new high-profile provocation. The Press Bureau of the Russian Foreign Intelligence Service reports that, according to information received by the Russian Foreign Intelligence Service, the Kiev regime, following its organized drone provocations in the airspace of Poland and Romania, is continuing its attempts to draw European NATO countries into an armed confrontation with Moscow. Another provocation is being developed,\" the SVR said in a statement.The new provocation includes a sabotage and reconnaissance group deployed to Polish territory, allegedly consisting of servicepeople from Russian and Belarusian special forces, the SVR also said, adding that the plan will be implemented by militants from the \"Freedom of Russia Legion*\" and the Belarusian \"Kalinouski Regiment\" fighting on the side of the Ukrainian armed forces.The provocation scenario was developed by the Main Intelligence Directorate of the Ukrainian Ministry of Defense jointly with Polish intelligence services, the SVR said.Kiev plans that after the \"neutralization\" of the sabotage and reconnaissance group by Polish security forces, its members will expose Russia and Belarus for attempting to destabilize the situation in Poland, the SVR said.*recognized as a terrorist organization, banned in Russia\n\nhttps://sputnikglobe.com/20250804/russian-intel-warns-of-uk-plan-to-stage-tanker-incident-1122550775.html\n\nukraine\n\nrussia\n\nkiev\n\npoland\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\n2025\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\nNews\n\nen_EN\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\n1920 1080 true\n\n1920 1440 true\n\n1920 1920 true\n\nSputnik International feedback@sputniknews.com +74956456601 MIA „Rossiya Segodnya“ 252 60\n\nSputnik International\n\nhigh-profile provocation, russian foreign intelligence service, organizing provocations",
      "source": "Sputnikglobe.com",
      "url": "https://sputnikglobe.com/20250930/ukraine-preparing-new-high-profile-provocation--russian-intel-1122889214.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Computer Vision Systems Market Expected to Reach USD 75.52 Billion by 2032, Fueled by Widespread AI and ML Adoption Worldwide | SNS Insider",
      "content": "Austin, Sept. 30, 2025 (GLOBE NEWSWIRE) -- The Computer Vision Systems Market Size was valued at USD 19.29 billion in 2024 and is expected to reach USD 75.52 billion by 2032 and grow at a CAGR of 18.63% over the forecast period 2025-2032.\n\nIncreasing use of computer vision due to the need for automation in the logistics, manufacturing, quality control, and medical diagnostics industries. Real-time processing made possible by developments in 3D vision, high-resolution imagery, and synchronized sensors to increase accuracy in areas like gesture tracking, facial identification, object detection, and automated optical inspection are some of the noteworthy results. Organizations may implement scalable and low-latency computer vision solutions thanks to the expanding trend of edge computing and cloud-based deployment models, which greatly boosts industry growth. Over 1,200 warehouses and logistics centers currently use real-time item detection, which enhances automated sorting and inventory tracking, according to the report.\n\n\n\n\n\nDownload PDF Sample of Computer Vision Systems Market @ https://www.snsinsider.com/sample-request/8447\n\nKey Players:\n\nNVIDIA\n\nIntel\n\nAMD\n\nQualcomm\n\nAmbarella\n\nTeledyne Technologies\n\nOmron Corporation\n\nKeyence Corporation\n\nMicrosoft\n\nAmazon Web Services (AWS)\n\nGoogle Cloud\n\nIBM\n\nOpenCV.ai\n\nRoboflow\n\nMatrox Imaging\n\nAllied Vision Technologies\n\nMobileye (Intel)\n\nTesla\n\nAptiv\n\nWorld Labs\n\nComputer Vision Systems Market Report Scope:\n\nReport Attributes Details Market Size in 2024 USD 19.29 Billion Market Size by 2032 USD 75.52 Billion CAGR CAGR of 18.63% From 2025 to 2032 Base Year 2024 Forecast Period 2025-2032 Historical Data 2021-2023 Report Scope & Coverage Market Size, Segments Analysis, Competitive Landscape, Regional Analysis, DROC & SWOT Analysis, Forecast Outlook Key Segments • By Component (Hardware, Software, Services)\n\n• By Deployment Mode (Cloud-based, On-premises, Edge computing devices)\n\n• By Application (Facial recognition, Image classification, Object detection, Object tracking, Optical Character Recognition (OCR), Image Segmentation, Automated optical inspection, 3D vision and depth sensing, Gesture recognition, Others)\n\n• By Industry Vertical (Manufacturing, Healthcare, Retail, Automotive, Security and surveillance, Agriculture, Smart cities, Consumer electronics, Energy and utilities, Others) Customization Scope Available upon request Pricing Available upon request\n\nIf You Need Any Customization on Computer Vision Systems Market Report, Inquire Now @ https://www.snsinsider.com/enquiry/8447\n\nSegmentation Analysis:\n\nBy Component, in 2024, Hardware Segment Led the Market with a Share 58.40%, while Services are the Fastest-growing Segment with a CAGR of 20.38%\n\nHardware component segment occupies a majority share in the Computer Vision Systems Market, largely owing to the large-scale deployment of high-resolution cameras, sensors and GPUs across various industrial verticals. The Services segment is experiencing the highest growth, supported by the growing need for software integration, training and support with AI models, maintenance, consulting, and assistance with cloud-based deploy.\n\nBy Deployment Mode, in 2024, On-premises Dominated the Market with a Share of 65.10%, while Edge Computing Devices Fastest-growing Segment with a CAGR 19.96%\n\nOn-premises deployment is leading the Computer Vision Systems Market, as many organizations like to process their sensitive data locally in order to guarantee security and have control over their critical operations, especially in industries, such as healthcare, manufacturing, and automotive Edge computing devices are having the highest growth rate due to the demand for data processing at real time, low latency applications, and AI based decision making at-edge level.\n\nBy Application, in 2024, Facial Recognition Led the Market with a Share 25.07%, while Object Detection the Fastest-growing Segment with a CAGR 20.24%\n\nFacial Recognition application segment dominated the Computer Vision Systems Market globally, in which computer vision technology is extensively adopted by the government, retail, and corporate sectors for security, surveillance, access control, and identity verification. Object Detection is growing fastest due to increasing need for real-time tracking, anomaly detection, and process optimization from autonomous vehicles, robotics, industrial automation, smart logistics, and others.\n\nBy Industry Vertical, in 2024, Manufacturing Dominated the Market with a Share of 32.03%, while Healthcare is the Fastest-growing Segment with a CAGR of 20.91%\n\nManufacturing tops the industry vertical in the Computer Vision Systems Market, as computer vision is increasingly used for factory deployment for quality inspection, defect detection, assembly verification, and automation globally. Healthcare is experiencing the quickest growth, which is attributed to the rise in uptake of diagnostic imaging, surgical assistance, patient monitoring, and medical image analysis powered by AI.\n\nIn 2024, North America Led the Market in 2024; Asia Pacific is Projected to be the Fastest Growing Region in the Market During 2025-2032\n\nThe computer vision systems market is propelled by the North America region as the market share 32.50%, owned by the early adopters of AI, machine learning, and advanced imaging technologies for various industries. Asia Pacific is a key and fast-growing market for Computer Vision System with a CAGR 19.74%, due to the rapid industrialization and urbanization along with the adoption of the latest technologies.\n\nRecent Developments:\n\nIn May 2024 , Ambarella launched the CV75S AI SoC family built on 5nm technology, enabling power-efficient multi-modal vision-language models and AI inference for cameras and robotics.\n\n, Ambarella launched the CV75S AI SoC family built on 5nm technology, enabling power-efficient multi-modal vision-language models and AI inference for cameras and robotics. In April 2024, Intel announced the Gaudi 3 AI accelerator at Intel Vision 2024, enhancing inference throughput and efficiency for large AI models in data centers and edge devices.\n\nBuy Full Research Report on Computer Vision Systems Market 2025-2032 @ https://www.snsinsider.com/checkout/8447\n\nExclusive Sections of the Report (The USPs):\n\nAlgorithm & Model Performance Metrics – helps you assess the efficiency and maturity of computer vision systems through accuracy and precision rates, real-time processing latency, and the frequency of model updates or optimizations.\n\n– helps you assess the efficiency and maturity of computer vision systems through accuracy and precision rates, real-time processing latency, and the frequency of model updates or optimizations. Human-Machine Interaction Metrics – helps you understand the impact of CV adoption on workforce efficiency by tracking reductions in manual errors, improvements in operator productivity, and user engagement across retail, AR/VR, and industrial applications.\n\n– helps you understand the impact of CV adoption on workforce efficiency by tracking reductions in manual errors, improvements in operator productivity, and user engagement across retail, AR/VR, and industrial applications. Security & Fraud Detection Metrics – helps you evaluate the reliability of CV systems in high-risk environments by analyzing false positive/negative rates, anomaly detection accuracy, and threat response time in surveillance and security applications.\n\n– helps you evaluate the reliability of CV systems in high-risk environments by analyzing false positive/negative rates, anomaly detection accuracy, and threat response time in surveillance and security applications. Product Lifecycle & Reliability Index – helps you measure the operational resilience of CV hardware by monitoring metrics like mean time between failures (MTBF), lifecycle duration of sensors and cameras, and maintenance cost savings achieved through automation.\n\n– helps you measure the operational resilience of CV hardware by monitoring metrics like mean time between failures (MTBF), lifecycle duration of sensors and cameras, and maintenance cost savings achieved through automation. Real-Time Processing Efficiency – helps you benchmark system responsiveness by analyzing average milliseconds per frame in real-time CV applications, enabling performance comparisons across industrial and edge deployments.\n\n– helps you benchmark system responsiveness by analyzing average milliseconds per frame in real-time CV applications, enabling performance comparisons across industrial and edge deployments. Operational Cost Optimization – helps you quantify ROI and cost-effectiveness by assessing reductions in maintenance expenses and productivity gains from automation-driven CV integration.\n\nAbout Us:\n\nSNS Insider is one of the leading market research and consulting agencies that dominates the market research industry globally. Our company's aim is to give clients the knowledge they require in order to function in changing circumstances. In order to give you current, accurate market data, consumer insights, and opinions so that you can make decisions with confidence, we employ a variety of techniques, including surveys, video talks, and focus groups around the world.",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/30/3158449/0/en/Computer-Vision-Systems-Market-Expected-to-Reach-USD-75-52-Billion-by-2032-Fueled-by-Widespread-AI-and-ML-Adoption-Worldwide-SNS-Insider.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "OpenAI might be building its own chip, but it’ll still be dependent on Nvidia — custom chip developed with Broadcom reportedly slips to Q3 2026",
      "content": "OpenAI's long-rumored $10 billion partnership with Broadcom is already showing cracks. The company is widely understood to be developing a custom chip designed specifically for OpenAI's inference workloads, but according to individuals familiar with the matter, the project has \"hit snags\": OpenAI wanted more power, sooner, than Broadcom could deliver, and an internal push to roll the chip out in Q2 2026 has already slipped to Q3 at the earliest, according to a report from The Information.\n\nThe project, which has been kept deliberately quiet, is set to have manufacturing run through TSMC. Once live, the chip could handle inference jobs across OpenAI’s growing fleet of data centers, cutting its exposure to GPU bottlenecks and potentially lowering costs.\n\nHowever, even as OpenAI lays the groundwork for its own silicon, it’s doubling down with Nvidia. A recent infrastructure agreement between the two companies, potentially worth more than $100 billion, would see Nvidia supply GPUs for the next wave of OpenAI-hosted AI clusters. Nvidia’s CEO Jensen Huang recently said that OpenAI “is likely going to be the next multi-trillion-dollar hyperscaler company,” with OpenAI remaining a cornerstone customer for Nvidia’s highest-end systems.\n\nThis, then, highlights the same paradoxical situation we’ve seen time and time again with AI. Amazon, Google, Microsoft, Meta, and now OpenAI are all building their own chips to reduce their reliance on Nvidia, while simultaneously relying on Nvidia more than ever.\n\nA hedge with no clear endgame\n\nBroadcom executives first confirmed what is believed to be the OpenAI deal late last year, saying that a large AI customer had booked billions in long-term orders. Reports quickly tied the deal to OpenAI, which has been growing a small, specialized in-house silicon team since at least mid-2023. The chip is understood to be designed for internal inference tasks and is not intended for commercial release. Broadcom handles the physical design, with TSMC expected to fabricate the chips.\n\nThis deal made OpenAI the latest entrant in a long line of hyperscalers trying to build their own chips. Amazon has its Trainium and Inferentia platforms. Google is now on its fifth-generation TPU. Microsoft is working on its Maia accelerators. Each was billed as a shift away from GPU dependency. Each still runs major workloads on Nvidia silicon.\n\nOpenAI doesn’t shy away from this fact. Its GPT-4 model was trained on Nvidia H100s, and its hosting partners — including CoreWeave and Microsoft — continue to deploy Nvidia hardware at scale. The new custom chip effort might eventually take over some inference jobs, but there’s no evidence it will replace H100 or Blackwell-class GPUs for training. And even if the silicon performs well, it won’t come bundled with Nvidia’s competitive software stack.\n\nThere’s no matching CUDA\n\nThis is the piece challengers still can’t match. Nvidia’s CUDA platform remains the default target for nearly every AI framework in use today. From PyTorch and TensorFlow to popular model compilers and quantization toolkits, most of the AI software stack is optimized for Nvidia’s architecture. Migrating off it means rewriting core libraries, retraining engineers, and adapting models to new hardware, which, ultimately, is a cost few companies are willing to absorb.\n\nOpenAI, like others, is unlikely to abandon CUDA without a compelling reason. Broadcom doesn’t offer its own software ecosystem, which means OpenAI’s team would need to build its own toolchain or adopt one of the open standards still struggling to reach parity. In the meantime, the easiest, fastest way to build and run large-scale models is still with Nvidia’s chips and software.\n\nJensen Huang knows this. Holding an iron grip over the industry, he’s reportedly given a heads-up by the likes of Amazon and Google before they announce a new chip that might compete with Nvidia’s. All this is done on the down low and, according to reports, has become something of an unwritten rule. It’s not required, but it happens, and it shows the degree to which Nvidia still commands power among its customers, even those building chips to hedge against Nvidia.\n\nIt’s not difficult to understand why this is the case. Nvidia is pouring billions into partnerships, infrastructure, and component sourcing. It recently agreed to buy up to $6.3 billion in unused GPU capacity from CoreWeave, invested nearly $1 billion to license Enfabrica’s networking tech, and paid Intel $5 billion as part of a joint development pact. It even agreed to support OpenAI’s next generation of GPU data centers despite OpenAI’s clear intent to use its own chips at some point.\n\nSupply chain headwinds\n\nEven if the OpenAI chip meets its performance goals, it faces supply chain headwinds. CoWoS packaging is still bottlenecked at TSMC, with Nvidia and AMD making up much of the near-term capacity. Advanced HBM memory is also under pressure, with SK hynix and Samsung prioritizing existing customers. So, while Broadcam can bring design expertise, it has no control over the back-end. Nor does OpenAI.\n\nThere’s also the question of scale. Nvidia’s Blackwell platform uses multi-chip modules, enormous memory bandwidth, and proprietary NVLink switching, a monolithic combination that Broadcom can’t offer. If OpenAI’s chip is simpler, it may be cheaper or more efficient per watt, but it also won’t be competitive on peak performance, which limits its value in training future large models.\n\nAll of these point toward a long-term hybrid model, where OpenAI uses both Nvidia and its own custom hardware depending on workload. Which, again, is what all the other hyperscalers are already doing.\n\nThe Broadcam partnership does make some sense for OpenAI from a strategic standpoint. If it ships on time (which looks unlikely) and performs well, it could reduce cost per token and give the company a touch more control over its infrastructure. But early signs aren't encouraging, and, in any case, it won’t be a silver bullet that replaces Nvidia's hardware for training cutting-edge models.\n\nFollow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.",
      "source": "Tom's Hardware UK",
      "url": "https://www.tomshardware.com/tech-industry/semiconductors/open-ai-building-its-own-chip-still-dependent-on-nvidia",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Qualcomm promises it can be an AI winner. What does it know that Nvidia and Intel don’t?",
      "content": "Qualcomm shares may have more growth potential than the market is currently pricing in —but some big hurdles lie ahead.\n\nThis story appeared on marketwatch.com , 2025-09-30 20:58:00.",
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/f4b81fbd766411b5",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Synopsys, Inc. (SNPS) Shares Suffer Worst Day Ever Amid Q325 Results Revealing Problems With Major Foundry Customer -- Hagens Berman",
      "content": "SAN FRANCISCO, Sept. 30, 2025 (GLOBE NEWSWIRE) -- On September 10, 2025, investors in Synopsys, Inc. (NASDAQ: SNPS) saw the price of their shares crater over $216 (-36%) after the company reported its Q3 2025 financial results and revealed significant problems with a major foundry customer.\n\nThe development has prompted national shareholders rights firm Hagens Berman to open an investigation into whether Synopsys may have misled investors about its customer risks and growth prospects.\n\nThe firm urges investors in Synopsys who suffered significant losses to submit your losses now. The firm also encourages persons with knowledge who may be able to assist in the investigation to contact its attorneys.\n\nVisit: www.hbsslaw.com/investor-fraud/snps\n\nContact the Firm Now: SNPS@hbsslaw.com\n\n844-916-0895\n\nSynopsys, Inc. (SNPS) Investigation:\n\nIn the past Synopsys has assured investors that, while its largest customer (Intel) had reduced its R&D spend, “it does not impact generally the EDA software[]” and downplayed risks based on its “committed, non-cancellable” agreements with Intel involving a mix of EDA software, IP, and hardware.\n\nThe company’s assurances may have come into question on September 9, 2025, when Synopsys reported its Q3 2025 financial results and shockingly guided for Q4 2025 GAAP EPS of negative $0.27 to negative $0.16.\n\nDuring the earnings call, management revealed the company’s underperformance in its IP business and said it was significantly due to “challenges at a major foundry customer” that is “also having a sizeable impact on the year[.]”\n\nThis news drove the price of Synopsys shares down 36% the next day, its worst-ever single-day percentage decline since going public in 1992.\n\n“We’re investigating whether Synopsys may have misled investors about risks posed by its high concentration with a single customer,” said Reed Kathrein, the Hagens Berman partner leading the investigation.\n\nIf you invested in Synopsys and have substantial losses, or have knowledge that may assist the firm’s investigation, submit your losses now »\n\nIf you’d like more information and answers to frequently asked questions about the Synopsys investigation, read more »\n\nWhistleblowers: Persons with non-public information regarding Synopsys should consider their options to help in the investigation or take advantage of the SEC Whistleblower program. Under the new program, whistleblowers who provide original information may receive rewards totaling up to 30 percent of any successful recovery made by the SEC. For more information, call Reed Kathrein at 844-916-0895 or email SNPS@hbsslaw.com.\n\nAbout Hagens Berman\n\nHagens Berman is a global plaintiffs’ rights complex litigation firm focusing on corporate accountability. The firm is home to a robust practice and represents investors as well as whistleblowers, workers, consumers and others in cases achieving real results for those harmed by corporate negligence and other wrongdoings. Hagens Berman’s team has secured more than $2.9 billion in this area of law. More about the firm and its successes can be found at hbsslaw.com. Follow the firm for updates and news at @ClassActionLaw.",
      "source": "GlobeNewswire",
      "url": "https://www.globenewswire.com/news-release/2025/09/30/3158809/32716/en/Synopsys-Inc-SNPS-Shares-Suffer-Worst-Day-Ever-Amid-Q325-Results-Revealing-Problems-With-Major-Foundry-Customer-Hagens-Berman.html",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Technology Stocks To Follow Today – September 28th",
      "content": "NVIDIA, Apple, Intel, Microsoft, Palantir Technologies, Oracle, and Meta Platforms are the seven Technology stocks to watch today, according to MarketBeat’s stock screener tool. Technology stocks are shares of companies whose core businesses involve developing, manufacturing or distributing technology products and services—ranging from software, hardware and semiconductors to internet platforms and IT consulting. Investors are often drawn to these stocks for their high growth potential driven by rapid innovation, though they can also exhibit above-average volatility and sector-specific risks such as regulatory shifts or technological disruption. These companies had the highest dollar trading volume of any Technology stocks within the last several days.\n\nGet alerts:\n\nNVIDIA (NVDA)\n\nNVIDIA Corporation provides graphics and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications.\n\nApple (AAPL)\n\nApple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal computers; iPad, a line of multi-purpose tablets; and wearables, home, and accessories comprising AirPods, Apple TV, Apple Watch, Beats products, and HomePod.\n\nRead Our Latest Research Report on AAPL\n\nIntel (INTC)\n\nIntel Corporation designs, develops, manufactures, markets, and sells computing and related products and services worldwide. It operates through Client Computing Group, Data Center and AI, Network and Edge, Mobileye, and Intel Foundry Services segments. The company's products portfolio comprises central processing units and chipsets, system-on-chips (SoCs), and multichip packages; mobile and desktop processors; hardware products comprising graphics processing units (GPUs), domain-specific accelerators, and field programmable gate arrays (FPGAs); and memory and storage, connectivity and networking, and other semiconductor products.\n\nRead Our Latest Research Report on INTC\n\nMicrosoft (MSFT)\n\nMicrosoft Corporation develops and supports software, services, devices and solutions worldwide. The Productivity and Business Processes segment offers office, exchange, SharePoint, Microsoft Teams, office 365 Security and Compliance, Microsoft viva, and Microsoft 365 copilot; and office consumer services, such as Microsoft 365 consumer subscriptions, Office licensed on-premises, and other office services.\n\nRead Our Latest Research Report on MSFT\n\nPalantir Technologies (PLTR)\n\nPalantir Technologies, Inc. engages in the business of building and deploying software platforms that serve as the central operating systems for its customers. It operates under the Commercial and Government segments. The Commercial segment focuses on customers working in non-government industries. The Government segment is involved in providing services to customers that are the United States government and non-United States government agencies.\n\nRead Our Latest Research Report on PLTR\n\nOracle (ORCL)\n\nOracle Corporation offers products and services that address enterprise information technology environments worldwide. Its Oracle cloud software as a service offering include various cloud software applications, including Oracle Fusion cloud enterprise resource planning (ERP), Oracle Fusion cloud enterprise performance management, Oracle Fusion cloud supply chain and manufacturing management, Oracle Fusion cloud human capital management, Oracle Cerner healthcare, Oracle Advertising, and NetSuite applications suite, as well as Oracle Fusion Sales, Service, and Marketing.\n\nRead Our Latest Research Report on ORCL\n\nMeta Platforms (META)\n\nMeta Platforms, Inc. engages in the development of products that enable people to connect and share with friends and family through mobile devices, personal computers, virtual reality headsets, and wearables worldwide. It operates in two segments, Family of Apps and Reality Labs. The Family of Apps segment offers Facebook, which enables people to share, discuss, discover, and connect with interests; Instagram, a community for sharing photos, videos, and private messages, as well as feed, stories, reels, video, live, and shops; Messenger, a messaging application for people to connect with friends, family, communities, and businesses across platforms and devices through text, audio, and video calls; and WhatsApp, a messaging application that is used by people and businesses to communicate and transact privately.\n\nRead Our Latest Research Report on META\n\nFeatured Articles",
      "source": "ETF Daily News",
      "url": "https://www.etfdailynews.com/2025/09/30/technology-stocks-to-follow-today-september-28th/",
      "timestamp": "2025-09-30"
    },
    {
      "headline": "Trump Has Created an ‘Unusual Bull Case’ for Intel Stock. Should You Buy INTC Now?",
      "content": null,
      "source": "Biztoc.com",
      "url": "https://biztoc.com/x/0242fe27211b4a8f",
      "timestamp": "2025-09-30"
    }
  ]
}