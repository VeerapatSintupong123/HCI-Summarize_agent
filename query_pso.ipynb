{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576d7597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.9\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ecbe7d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import imageio\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f8a59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_DB_FOLDER = r\"chunk_news\\23092025_vector_db\"\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6df4803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vector(path: Path):\n",
    "    \"\"\"\n",
    "    Loads an existing FAISS vector database from a local path.\n",
    "\n",
    "    Args:\n",
    "        path: The directory path where the vector database is stored.\n",
    "\n",
    "    Returns:\n",
    "        The loaded FAISS database object.\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Loading vector database from: {path}\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
    "    db = FAISS.load_local(str(path), embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"‚úÖ Vector DB loaded successfully.\")\n",
    "    return db\n",
    "\n",
    "\n",
    "def get_retriever(db_path):\n",
    "    \"\"\"\n",
    "    Constructs the path to the vector DB, loads it, and returns a retriever.\n",
    "    This is the primary function to be imported by other scripts like worker.py.\n",
    "    \n",
    "    Returns:\n",
    "        A LangChain retriever object.\n",
    "    \"\"\"\n",
    "    db = load_vector(db_path)\n",
    "    \n",
    "    retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9002b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading vector database from: chunk_news\\23092025_vector_db\n",
      "‚úÖ Vector DB loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "retriever = get_retriever(db_path=VECTOR_DB_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d67ebb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Document ---\n",
      ". This announcement affects both desktops and laptop chips. The 11th to 14th-generation Intel CPUs are still relatively new ‚Äî the 14th-generation Raptor Lake Refresh CPUs first arrived in 2023, with n\n",
      "\n",
      "--- Document ---\n",
      ". This announcement affects both desktops and laptop chips. The 11th to 14th-generation Intel CPUs are still relatively new ‚Äî the 14th-generation Raptor Lake Refresh CPUs first arrived in 2023, with n\n",
      "\n",
      "--- Document ---\n",
      "Category: Intel\n",
      "Headline: Arm is the future of desktop computing, and the writing is on the wall for x86\n",
      "Source: XDA Developers\n",
      "Content: Arm has been slowly picking up pace in the last two decades, bu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Intel news 07/10/2025\"\n",
    "results = retriever.invoke(query)\n",
    "\n",
    "for result in results:\n",
    "    print(\"--- Document ---\")\n",
    "    print(result.page_content[:200])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3daa1a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    a = a / np.linalg.norm(a)\n",
    "    b = b / np.linalg.norm(b, axis=-1, keepdims=True)\n",
    "    return np.dot(b, a)\n",
    "\n",
    "def get_topk_embeddings(db, query_emb, k=4):\n",
    "    q = np.array(query_emb, dtype=np.float32).reshape(1, -1)\n",
    "    distances, indices = db.index.search(q, k)\n",
    "    doc_embs = [db.index.reconstruct(int(i)) for i in indices[0]]\n",
    "    docs = [db.docstore.search(db.index_to_docstore_id[int(i)]) for i in indices[0]]\n",
    "    return docs, np.array(doc_embs), distances[0]\n",
    "\n",
    "def fitness(query_embedding, db, k=4):\n",
    "    docs, doc_embs, _ = get_topk_embeddings(db, query_embedding, k)\n",
    "    if len(doc_embs) == 0:\n",
    "        return -9999\n",
    "    sims = cosine_similarity(query_embedding, doc_embs)\n",
    "    sim_score = np.mean(sims)\n",
    "    dd_sims = [cosine_similarity(doc_embs[i], doc_embs[j])\n",
    "               for i in range(len(doc_embs))\n",
    "               for j in range(i+1, len(doc_embs))]\n",
    "    coherence = np.mean(dd_sims) if dd_sims else 0\n",
    "    return 0.7 * sim_score + 0.3 * coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e60edb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading vector database from: chunk_news\\23092025_vector_db\n",
      "‚úÖ Vector DB loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "db = load_vector(VECTOR_DB_FOLDER)\n",
    "embedding_fn = HuggingFaceEmbeddings(model_name=EMBED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ca1fd201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pso_optimize(init_embedding, db, w, c1, c2, num_particles=20, iters=40):\n",
    "    DIM = len(init_embedding)\n",
    "\n",
    "    particles = np.random.randn(num_particles, DIM) * 0.05 + init_embedding\n",
    "    velocities = np.zeros((num_particles, DIM))\n",
    "\n",
    "    personal_best = particles.copy()\n",
    "    personal_scores = np.array([fitness(p, db) for p in particles])\n",
    "\n",
    "    global_best = personal_best[np.argmax(personal_scores)]\n",
    "    global_best_score = np.max(personal_scores)\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for t in range(iters):\n",
    "        history.append(particles.copy())\n",
    "        for i in range(num_particles):\n",
    "            r1, r2 = np.random.rand(), np.random.rand()\n",
    "            velocities[i] = (\n",
    "                w * velocities[i] +\n",
    "                c1 * r1 * (personal_best[i] - particles[i]) +\n",
    "                c2 * r2 * (global_best - particles[i])\n",
    "            )\n",
    "            particles[i] += velocities[i]\n",
    "            score = fitness(particles[i], db)\n",
    "            if score > personal_scores[i]:\n",
    "                personal_best[i] = particles[i]\n",
    "                personal_scores[i] = score\n",
    "                if score > global_best_score:\n",
    "                    global_best = particles[i]\n",
    "                    global_best_score = score\n",
    "        print(f\"Iter {t+1}/{iters}: score = {global_best_score:.4f}\")\n",
    "\n",
    "    history.append(particles.copy())\n",
    "    return global_best, global_best_score, np.array(history)\n",
    "\n",
    "def retrieve(query_emb, db, k=4):\n",
    "    q = np.array(query_emb, dtype=np.float32).reshape(1, -1)\n",
    "    dists, idxs = db.index.search(q, k)\n",
    "    docs = [db.docstore.search(db.index_to_docstore_id[int(i)]) for i in idxs[0]]\n",
    "    return docs\n",
    "\n",
    "def make_gif_3d(history, filename=\"pso3d.gif\"):\n",
    "    T, N, D = history.shape\n",
    "    flat = history.reshape(T*N, D)\n",
    "    proj = PCA(n_components=3).fit_transform(flat)\n",
    "    proj = proj.reshape(T, N, 3)\n",
    "\n",
    "    images = []\n",
    "    for t in range(T):\n",
    "        fig = plt.figure(figsize=(6,6))\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "        ax.scatter(proj[t,:,0], proj[t,:,1], proj[t,:,2], s=40)\n",
    "        ax.set_title(f\"Iteration {t}\")\n",
    "        mn = proj.min(axis=(0,1))\n",
    "        mx = proj.max(axis=(0,1))\n",
    "        ax.set_xlim(mn[0], mx[0])\n",
    "        ax.set_ylim(mn[1], mx[1])\n",
    "        ax.set_zlim(mn[2], mx[2])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"frame3d.png\")\n",
    "        plt.close()\n",
    "        images.append(imageio.imread(\"frame3d.png\"))\n",
    "\n",
    "    imageio.mimsave(filename, images, fps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f410975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.6414233449287092\n",
      "\n",
      "---- RESULT 1 ----\n",
      "Category: Nvidia\n",
      "Headline: More questions than answers in Nvidia‚Äôs $100 billion OpenAI deal\n",
      "Source: The Indian Express\n",
      "Content: Nvidia‚Äôs move to invest up to $100 billion into OpenAI at the same time it plans to supply millions of its market-leading artificial intelligence chips to the ChatGPT creator has little precedent in the tech industry. Under the deal, Nvidia will be taking a f‚Ä¶\n",
      "Timestamp: 2025-09-23\n",
      "\n",
      "---- RESULT 2 ----\n",
      "Category: Nvidia\n",
      "Headline: MRVL Stock vs. NVIDIA\n",
      "Source: Forbes\n",
      "Content: NVIDIA presents superior revenue growth in key periods, enhanced profitability, and a comparatively lower valuation...\n",
      "Timestamp: 2025-09-23\n",
      "\n",
      "---- RESULT 3 ----\n",
      "Category: Nvidia\n",
      "Headline: \"The next leap forward\" - Nvidia is investing $100bn in OpenAI, and will start by deploying as much power for 10 nuclear reactors\n",
      "Source: TechRadar\n",
      "\n",
      "---- RESULT 4 ----\n",
      ". ‚ÄúWe‚Äôre excited to deploy 10 gigawatts of compute with NVIDIA to push back the frontier of intelligence and scale the benefits of this technology to everyone,‚Äù OpenAI President Greg Brockman concluded.\n"
     ]
    }
   ],
   "source": [
    "query = \"Nvidia news 07/10/2025\"\n",
    "init_emb = embedding_fn.embed_query(query)\n",
    "score = fitness(init_emb, db, k=4)\n",
    "print(f\"score: {score}\")\n",
    "\n",
    "docs = retrieve(init_emb, db, k=4)\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"\\n---- RESULT {i+1} ----\")\n",
    "    print(d.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "19e4c7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50: score = 0.6546\n",
      "Iter 2/50: score = 0.6599\n",
      "Iter 3/50: score = 0.6625\n",
      "Iter 4/50: score = 0.6659\n",
      "Iter 5/50: score = 0.6722\n",
      "Iter 6/50: score = 0.6738\n",
      "Iter 7/50: score = 0.6768\n",
      "Iter 8/50: score = 0.6797\n",
      "Iter 9/50: score = 0.6838\n",
      "Iter 10/50: score = 0.6866\n",
      "Iter 11/50: score = 0.6872\n",
      "Iter 12/50: score = 0.6892\n",
      "Iter 13/50: score = 0.6922\n",
      "Iter 14/50: score = 0.6944\n",
      "Iter 15/50: score = 0.6963\n",
      "Iter 16/50: score = 0.6977\n",
      "Iter 17/50: score = 0.7006\n",
      "Iter 18/50: score = 0.7191\n",
      "Iter 19/50: score = 0.7207\n",
      "Iter 20/50: score = 0.7256\n",
      "Iter 21/50: score = 0.7267\n",
      "Iter 22/50: score = 0.7277\n",
      "Iter 23/50: score = 0.7285\n",
      "Iter 24/50: score = 0.7298\n",
      "Iter 25/50: score = 0.7303\n",
      "Iter 26/50: score = 0.7315\n",
      "Iter 27/50: score = 0.7325\n",
      "Iter 28/50: score = 0.7335\n",
      "Iter 29/50: score = 0.7340\n",
      "Iter 30/50: score = 0.7357\n",
      "Iter 31/50: score = 0.7370\n",
      "Iter 32/50: score = 0.7380\n",
      "Iter 33/50: score = 0.7387\n",
      "Iter 34/50: score = 0.7402\n",
      "Iter 35/50: score = 0.7413\n",
      "Iter 36/50: score = 0.7418\n",
      "Iter 37/50: score = 0.7427\n",
      "Iter 38/50: score = 0.7430\n",
      "Iter 39/50: score = 0.7442\n",
      "Iter 40/50: score = 0.7444\n",
      "Iter 41/50: score = 0.7458\n",
      "Iter 42/50: score = 0.7460\n",
      "Iter 43/50: score = 0.7463\n",
      "Iter 44/50: score = 0.7472\n",
      "Iter 45/50: score = 0.7477\n",
      "Iter 46/50: score = 0.7482\n",
      "Iter 47/50: score = 0.7487\n",
      "Iter 48/50: score = 0.7488\n",
      "Iter 49/50: score = 0.7490\n",
      "Iter 50/50: score = 0.7496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Auto\\AppData\\Local\\Temp\\ipykernel_24128\\2419073974.py:63: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(\"frame3d.png\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized embedding fitness: 0.749609676145354\n"
     ]
    }
   ],
   "source": [
    "query = \"Nvidia news 07/10/2025\"\n",
    "init_emb = embedding_fn.embed_query(query)\n",
    "best_emb, best_score, hist = pso_optimize(\n",
    "    init_emb, db,\n",
    "    w=0.8,\n",
    "    c1=1.2,\n",
    "    c2=1.0, \n",
    "    num_particles=384, \n",
    "    iters=50\n",
    ")\n",
    "\n",
    "make_gif_3d(hist, \"pso.gif\")\n",
    "print(\"Optimized embedding fitness:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fa28d36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- RESULT 1 ----\n",
      "Category: Nvidia\n",
      "Headline: More questions than answers in Nvidia‚Äôs $100 billion OpenAI deal\n",
      "Source: The Indian Express\n",
      "Content: Nvidia‚Äôs move to invest up to $100 billion into OpenAI at the same time it plans to supply millions of its market-leading artificial intelligence chips to the ChatGPT creator has little precedent in the tech industry. Under the deal, Nvidia will be taking a f‚Ä¶\n",
      "Timestamp: 2025-09-23\n",
      "\n",
      "---- RESULT 2 ----\n",
      "Category: AMD\n",
      "Headline: Nvidia promises its $100 billion OpenAI deal won't impact GPU supply ‚Äî 'we will continue to make every customer a top priority'\n",
      "Source: Tom's Hardware UK\n",
      "Content: Nvidia has released a statement to make it clear that, no matter what deals it does with companies to provide hardware or take an equity stake in their business, it will ensure all companies have equal access to next-generation GPU hardware.\n",
      "Timestamp: 2025-09-23\n",
      "\n",
      "---- RESULT 3 ----\n",
      "Category: Nvidia\n",
      "Headline: \"The next leap forward\" - Nvidia is investing $100bn in OpenAI, and will start by deploying as much power for 10 nuclear reactors\n",
      "Source: TechRadar\n",
      "\n",
      "---- RESULT 4 ----\n",
      ". Details have yet to be finalised, but a letter of intent signed by the two companies announced plans to deploy 10 gigawatts of Nvidia systems for use in OpenAI's data centres. The two companies were hardly strangers to begin with, but this latest deal gives Nvidia a stake in one of its biggest customers. Nvidia's investment in OpenAI will eventually take the form of non-voting shares in the company. OpenAI will then use the resulting cash flow to buy the aforementioned AI chips\n"
     ]
    }
   ],
   "source": [
    "docs = retrieve(best_emb, db, k=4)\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"\\n---- RESULT {i+1} ----\")\n",
    "    print(d.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb22cd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50: score = 0.6490\n",
      "Iter 2/50: score = 0.6614\n",
      "Iter 3/50: score = 0.6636\n",
      "Iter 4/50: score = 0.6692\n",
      "Iter 5/50: score = 0.6728\n",
      "Iter 6/50: score = 0.6781\n",
      "Iter 7/50: score = 0.6815\n",
      "Iter 8/50: score = 0.6849\n",
      "Iter 9/50: score = 0.6871\n",
      "Iter 10/50: score = 0.6881\n",
      "Iter 11/50: score = 0.6895\n",
      "Iter 12/50: score = 0.6912\n",
      "Iter 13/50: score = 0.6933\n",
      "Iter 14/50: score = 0.6947\n",
      "Iter 15/50: score = 0.6960\n",
      "Iter 16/50: score = 0.6966\n",
      "Iter 17/50: score = 0.6972\n",
      "Iter 18/50: score = 0.6976\n",
      "Iter 19/50: score = 0.6977\n",
      "Iter 20/50: score = 0.6980\n",
      "Iter 21/50: score = 0.6982\n",
      "Iter 22/50: score = 0.6986\n",
      "Iter 23/50: score = 0.6989\n",
      "Iter 24/50: score = 0.6989\n",
      "Iter 25/50: score = 0.6990\n",
      "Iter 26/50: score = 0.6990\n",
      "Iter 27/50: score = 0.6991\n",
      "Iter 28/50: score = 0.6991\n",
      "Iter 29/50: score = 0.6992\n",
      "Iter 30/50: score = 0.6992\n",
      "Iter 31/50: score = 0.6992\n",
      "Iter 32/50: score = 0.6992\n",
      "Iter 33/50: score = 0.6993\n",
      "Iter 34/50: score = 0.6993\n",
      "Iter 35/50: score = 0.6993\n",
      "Iter 36/50: score = 0.6994\n",
      "Iter 37/50: score = 0.6994\n",
      "Iter 38/50: score = 0.6996\n",
      "Iter 39/50: score = 0.6997\n",
      "Iter 40/50: score = 0.7000\n",
      "Iter 41/50: score = 0.7001\n",
      "Iter 42/50: score = 0.7002\n",
      "Iter 43/50: score = 0.7002\n",
      "Iter 44/50: score = 0.7002\n",
      "Iter 45/50: score = 0.7002\n",
      "Iter 46/50: score = 0.7002\n",
      "Iter 47/50: score = 0.7002\n",
      "Iter 48/50: score = 0.7003\n",
      "Iter 49/50: score = 0.7003\n",
      "Iter 50/50: score = 0.7003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Auto\\AppData\\Local\\Temp\\ipykernel_24128\\2419073974.py:63: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(\"frame3d.png\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized embedding fitness: 0.700344254755069\n"
     ]
    }
   ],
   "source": [
    "query = \"Nvidia news 07/10/2025\"\n",
    "init_emb = embedding_fn.embed_query(query)\n",
    "best_emb, best_score, hist = pso_optimize(\n",
    "    init_emb, db,\n",
    "    w=0.5,\n",
    "    c1=0.4,\n",
    "    c2=0.8, \n",
    "    num_particles=384, \n",
    "    iters=50\n",
    ")\n",
    "\n",
    "make_gif_3d(hist, \"pso2.gif\")\n",
    "print(\"Optimized embedding fitness:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "34789070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- RESULT 1 ----\n",
      "Category: Nvidia\n",
      "Headline: More questions than answers in Nvidia‚Äôs $100 billion OpenAI deal\n",
      "Source: The Indian Express\n",
      "Content: Nvidia‚Äôs move to invest up to $100 billion into OpenAI at the same time it plans to supply millions of its market-leading artificial intelligence chips to the ChatGPT creator has little precedent in the tech industry. Under the deal, Nvidia will be taking a f‚Ä¶\n",
      "Timestamp: 2025-09-23\n",
      "\n",
      "---- RESULT 2 ----\n",
      "Category: Nvidia\n",
      "Headline: \"The next leap forward\" - Nvidia is investing $100bn in OpenAI, and will start by deploying as much power for 10 nuclear reactors\n",
      "Source: TechRadar\n",
      "\n",
      "---- RESULT 3 ----\n",
      "Category: Nvidia\n",
      "Headline: MRVL Stock vs. NVIDIA\n",
      "Source: Forbes\n",
      "Content: NVIDIA presents superior revenue growth in key periods, enhanced profitability, and a comparatively lower valuation...\n",
      "Timestamp: 2025-09-23\n",
      "\n",
      "---- RESULT 4 ----\n",
      "Category: Nvidia\n",
      "Headline: NVIDIA to invest $100 billion in OpenAI ‚Äî after Microsoft backed out of two data center deals to escape additional ChatGPT training support\n",
      "Source: Windows Central\n"
     ]
    }
   ],
   "source": [
    "docs = retrieve(best_emb, db, k=4)\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"\\n---- RESULT {i+1} ----\")\n",
    "    print(d.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7c6ca1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50: score = 0.6480\n",
      "Iter 2/50: score = 0.6566\n",
      "Iter 3/50: score = 0.6587\n",
      "Iter 4/50: score = 0.6620\n",
      "Iter 5/50: score = 0.6665\n",
      "Iter 6/50: score = 0.6703\n",
      "Iter 7/50: score = 0.6767\n",
      "Iter 8/50: score = 0.6955\n",
      "Iter 9/50: score = 0.7103\n",
      "Iter 10/50: score = 0.7180\n",
      "Iter 11/50: score = 0.7203\n",
      "Iter 12/50: score = 0.7225\n",
      "Iter 13/50: score = 0.7256\n",
      "Iter 14/50: score = 0.7269\n",
      "Iter 15/50: score = 0.7316\n",
      "Iter 16/50: score = 0.7355\n",
      "Iter 17/50: score = 0.7394\n",
      "Iter 18/50: score = 0.7411\n",
      "Iter 19/50: score = 0.7433\n",
      "Iter 20/50: score = 0.7448\n",
      "Iter 21/50: score = 0.7474\n",
      "Iter 22/50: score = 0.7494\n",
      "Iter 23/50: score = 0.7517\n",
      "Iter 24/50: score = 0.7536\n",
      "Iter 25/50: score = 0.7551\n",
      "Iter 26/50: score = 0.7564\n",
      "Iter 27/50: score = 0.7570\n",
      "Iter 28/50: score = 0.7582\n",
      "Iter 29/50: score = 0.7593\n",
      "Iter 30/50: score = 0.7601\n",
      "Iter 31/50: score = 0.7606\n",
      "Iter 32/50: score = 0.7613\n",
      "Iter 33/50: score = 0.7616\n",
      "Iter 34/50: score = 0.7622\n",
      "Iter 35/50: score = 0.7629\n",
      "Iter 36/50: score = 0.7634\n",
      "Iter 37/50: score = 0.7641\n",
      "Iter 38/50: score = 0.7655\n",
      "Iter 39/50: score = 0.7657\n",
      "Iter 40/50: score = 0.7664\n",
      "Iter 41/50: score = 0.7668\n",
      "Iter 42/50: score = 0.7671\n",
      "Iter 43/50: score = 0.7673\n",
      "Iter 44/50: score = 0.7675\n",
      "Iter 45/50: score = 0.7678\n",
      "Iter 46/50: score = 0.7679\n",
      "Iter 47/50: score = 0.7683\n",
      "Iter 48/50: score = 0.7686\n",
      "Iter 49/50: score = 0.7689\n",
      "Iter 50/50: score = 0.7692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Auto\\AppData\\Local\\Temp\\ipykernel_24128\\2419073974.py:63: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(\"frame3d.png\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized embedding fitness: 0.7691645658636433\n"
     ]
    }
   ],
   "source": [
    "query = \"Nvidia news 07/10/2025\"\n",
    "init_emb = embedding_fn.embed_query(query)\n",
    "best_emb, best_score, hist = pso_optimize(\n",
    "    init_emb, db,\n",
    "    w=0.8,\n",
    "    c1=0.8,\n",
    "    c2=0.8, \n",
    "    num_particles=500, \n",
    "    iters=50\n",
    ")\n",
    "\n",
    "make_gif_3d(hist, \"pso3.gif\")\n",
    "print(\"Optimized embedding fitness:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4d9ebf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- RESULT 1 ----\n",
      "Category: Nvidia\n",
      "Headline: More questions than answers in Nvidia‚Äôs $100 billion OpenAI deal\n",
      "Source: The Indian Express\n",
      "Content: Nvidia‚Äôs move to invest up to $100 billion into OpenAI at the same time it plans to supply millions of its market-leading artificial intelligence chips to the ChatGPT creator has little precedent in the tech industry. Under the deal, Nvidia will be taking a f‚Ä¶\n",
      "Timestamp: 2025-09-23\n",
      "\n",
      "---- RESULT 2 ----\n",
      "Category: Nvidia\n",
      "Headline: NVIDIA to invest $100 billion in OpenAI ‚Äî after Microsoft backed out of two data center deals to escape additional ChatGPT training support\n",
      "Source: Windows Central\n",
      "\n",
      "---- RESULT 3 ----\n",
      "Category: Nvidia\n",
      "Headline: \"The next leap forward\" - Nvidia is investing $100bn in OpenAI, and will start by deploying as much power for 10 nuclear reactors\n",
      "Source: TechRadar\n",
      "\n",
      "---- RESULT 4 ----\n",
      "Category: Nvidia\n",
      "Headline: Nvidia plans to splash OpenAI with cash, pouring out $100 billion for ChatGPT's creator and making last week's Intel investment look like a drop in the money bucket\n",
      "Source: PC Gamer\n"
     ]
    }
   ],
   "source": [
    "docs = retrieve(best_emb, db, k=4)\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"\\n---- RESULT {i+1} ----\")\n",
    "    print(d.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
